Total duration: 104.375s
File: /apps/open_spiel/open_spiel/python/games/clock_auction.py
File duration: 58.027s (55.59%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|from collections import defaultdict
     2|      4047|   0.00889683|  2.19838e-06|  0.01%|from dataclasses import dataclass, field
     3|      4047|    0.0161748|  3.99674e-06|  0.02%|from distutils.command.build import build
(call)|      1349|   0.00463271|  3.43418e-06|  0.00%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:87 <lambda>
     4|      4047|    0.0134912|  3.33362e-06|  0.01%|from multiprocessing.sharedctypes import Value
(call)|      1349|   0.00423455|  3.13903e-06|  0.00%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:88 <lambda>
     5|      2698|   0.00547147|  2.02797e-06|  0.01%|from tkinter.messagebox import NO
     6|      2698|   0.00526714|  1.95224e-06|  0.01%|import numpy as np
     7|      2698|   0.00522804|  1.93775e-06|  0.01%|import pandas as pd
     8|      2698|   0.00545263|  2.02099e-06|  0.01%|from open_spiel.python.examples.ubc_utils import players_not_me, pulp_solve, random_string
     9|         0|            0|            0|  0.00%|import pyspiel
    10|         0|            0|            0|  0.00%|import json
    11|         0|            0|            0|  0.00%|import os
    12|         0|            0|            0|  0.00%|import logging
    13|         0|            0|            0|  0.00%|import enum
    14|         0|            0|            0|  0.00%|import itertools
    15|         0|            0|            0|  0.00%|from typing import List, Dict, Tuple, Optional, Any, Union, Iterable
    16|         0|            0|            0|  0.00%|import math
    17|         0|            0|            0|  0.00%|from open_spiel.python.games import clock_auction_bidders
    18|         0|            0|            0|  0.00%|from functools import cached_property
    19|         0|            0|            0|  0.00%|from pulp import LpProblem, LpMinimize, LpVariable, LpStatus, LpBinary, lpSum, lpDot, LpMaximize, LpInteger, value
    20|         0|            0|            0|  0.00%|
    21|         0|            0|            0|  0.00%|DEFAULT_MAX_ROUNDS = 100
    22|         0|            0|            0|  0.00%|DEFAULT_AGENT_MEMORY = 3
    23|         0|            0|            0|  0.00%|
    24|         0|            0|            0|  0.00%|class ActivityPolicy(enum.IntEnum):
    25|         0|            0|            0|  0.00%|  ON = 0
    26|         0|            0|            0|  0.00%|  OFF = 1
    27|         0|            0|            0|  0.00%|
    28|         0|            0|            0|  0.00%|class UndersellPolicy(enum.IntEnum):
    29|         0|            0|            0|  0.00%|  UNDERSELL = 0
    30|         0|            0|            0|  0.00%|  UNDERSELL_ALLOWED = 1
    31|         0|            0|            0|  0.00%|
    32|         0|            0|            0|  0.00%|class InformationPolicy(enum.IntEnum):
    33|         0|            0|            0|  0.00%|  SHOW_DEMAND = 0
    34|         0|            0|            0|  0.00%|  HIDE_DEMAND = 1
    35|         0|            0|            0|  0.00%|
    36|         0|            0|            0|  0.00%|class ValueFormat(enum.IntEnum):
    37|         0|            0|            0|  0.00%|  LINEAR = 0
    38|         0|            0|            0|  0.00%|  FULL = 1
    39|         0|            0|            0|  0.00%|  MARGINAL = 2
    40|         0|            0|            0|  0.00%|
    41|         0|            0|            0|  0.00%|@dataclass
    42|         0|            0|            0|  0.00%|class AuctionParams:
    43|         0|            0|            0|  0.00%|  opening_prices: List[float] = field(default_factory=lambda : [])
    44|         0|            0|            0|  0.00%|  licenses: List[int] = field(default_factory=lambda : [])
    45|         0|            0|            0|  0.00%|  activity: List[int] = field(default_factory=lambda : [])
    46|         0|            0|            0|  0.00%|  num_products: int = 0
    47|         0|            0|            0|  0.00%|  increment: float = 0.1
    48|         0|            0|            0|  0.00%|
    49|         0|            0|            0|  0.00%|  max_round: int = DEFAULT_MAX_ROUNDS
    50|         0|            0|            0|  0.00%|  player_types: Dict = None
    51|         0|            0|            0|  0.00%|
    52|         0|            0|            0|  0.00%|  all_bids: List[List[int]] = None
    53|         0|            0|            0|  0.00%|  all_bids_activity: List[int] = None
    54|         0|            0|            0|  0.00%|
    55|         0|            0|            0|  0.00%|  activity_policy: ActivityPolicy = ActivityPolicy.ON
    56|         0|            0|            0|  0.00%|  undersell_policy: UndersellPolicy = UndersellPolicy.UNDERSELL
    57|         0|            0|            0|  0.00%|  information_policy: InformationPolicy = InformationPolicy.SHOW_DEMAND
    58|         0|            0|            0|  0.00%|  default_player_order: List[List[int]] = None
    59|         0|            0|            0|  0.00%|
    60|         0|            0|            0|  0.00%|  tiebreaks: bool = True
    61|         0|            0|            0|  0.00%|  agent_memory: int = DEFAULT_AGENT_MEMORY
    62|         0|            0|            0|  0.00%|
    63|         0|            0|            0|  0.00%|  @cached_property
    64|         0|            0|            0|  0.00%|  def max_activity(self):
    65|         0|            0|            0|  0.00%|    return np.array(self.activity) @ np.array(self.licenses)
    66|         0|            0|            0|  0.00%|
    67|         0|            0|            0|  0.00%|  def max_budget_for_player(self, player_id):
    68|         0|            0|            0|  0.00%|    return max([t['bidder'].get_budget() for t in self.player_types[player_id]])
    69|         0|            0|            0|  0.00%|
    70|         0|            0|            0|  0.00%|  @cached_property
    71|         0|            0|            0|  0.00%|  def max_budget(self):
    72|         0|            0|            0|  0.00%|    return max([self.max_budget_for_player(p) for p in range(len(self.player_types))])
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|  @cached_property
    75|         0|            0|            0|  0.00%|  def max_total_spend(self):
    76|         0|            0|            0|  0.00%|    return sum([self.max_budget_for_player(p) for p in range(len(self.player_types))])
    77|         0|            0|            0|  0.00%|
    78|         0|            0|            0|  0.00%|  def max_opponent_spend(self, player_id):
    79|         0|            0|            0|  0.00%|    return sum([self.max_budget_for_player(p) for p in range(len(self.player_types)) if p != player_id])
    80|         0|            0|            0|  0.00%|
    81|         0|            0|            0|  0.00%|  @cached_property
    82|         0|            0|            0|  0.00%|  def max_opponent_spends(self):
    83|         0|            0|            0|  0.00%|    return np.array([self.max_opponent_spend(p) for p in range(len(self.player_types))])
    84|         0|            0|            0|  0.00%|
    85|         0|            0|            0|  0.00%|@dataclass
    86|         0|            0|            0|  0.00%|class TieBreakState:
    87|      2698|   0.00463271|  1.71709e-06|  0.00%|  tie_breaks_needed: List = field(default_factory=lambda : [])
    88|      2698|   0.00423455|  1.56952e-06|  0.00%|  selected_order: List = field(default_factory=lambda : [])
    89|         0|            0|            0|  0.00%|
    90|      7867|    0.0142851|  1.81582e-06|  0.01%|  def reset(self):
    91|      7867|    0.0199258|  2.53284e-06|  0.02%|    self.tie_breaks_needed = []
    92|      7867|    0.0160506|  2.04024e-06|  0.02%|    self.selected_order = []
    93|         0|            0|            0|  0.00%|
    94|         0|            0|            0|  0.00%|@dataclass
    95|         0|            0|            0|  0.00%|class BidderState:
    96|         0|            0|            0|  0.00%|  processed_demand: List[List[int]] = field(default_factory=lambda : [])
    97|         0|            0|            0|  0.00%|  submitted_demand: List[List[int]] = field(default_factory=lambda : [])
    98|         0|            0|            0|  0.00%|  activity: int = None
    99|         0|            0|            0|  0.00%|  bidder: clock_auction_bidders.Bidder = None
   100|         0|            0|            0|  0.00%|  type_index: int = None
   101|         0|            0|            0|  0.00%|  drop_out_heuristic: bool = True
   102|         0|            0|            0|  0.00%|
   103|         0|            0|            0|  0.00%|def action_to_bundles(licenses):
   104|         0|            0|            0|  0.00%|    bids = []
   105|         0|            0|            0|  0.00%|    for n in licenses:
   106|         0|            0|            0|  0.00%|        b = []
   107|         0|            0|            0|  0.00%|        for i in range(n + 1):
   108|         0|            0|            0|  0.00%|            b.append(i)
   109|         0|            0|            0|  0.00%|        bids.append(b)
   110|         0|            0|            0|  0.00%|    actions = np.array(list(itertools.product(*bids)))
   111|         0|            0|            0|  0.00%|    return actions
   112|         0|            0|            0|  0.00%|
   113|         0|            0|            0|  0.00%|_GAME_TYPE = pyspiel.GameType(
   114|         0|            0|            0|  0.00%|    short_name="python_clock_auction",
   115|         0|            0|            0|  0.00%|    long_name="Python Clock Auction",
   116|         0|            0|            0|  0.00%|    dynamics=pyspiel.GameType.Dynamics.SEQUENTIAL,
   117|         0|            0|            0|  0.00%|    chance_mode=pyspiel.GameType.ChanceMode.EXPLICIT_STOCHASTIC,
   118|         0|            0|            0|  0.00%|    information=pyspiel.GameType.Information.IMPERFECT_INFORMATION,
   119|         0|            0|            0|  0.00%|    utility=pyspiel.GameType.Utility.GENERAL_SUM,
   120|         0|            0|            0|  0.00%|    reward_model=pyspiel.GameType.RewardModel.TERMINAL,
   121|         0|            0|            0|  0.00%|    max_num_players=10,
   122|         0|            0|            0|  0.00%|    min_num_players=2,
   123|         0|            0|            0|  0.00%|    provides_information_state_string=False,
   124|         0|            0|            0|  0.00%|    provides_information_state_tensor=False,
   125|         0|            0|            0|  0.00%|    provides_observation_string=True,
   126|         0|            0|            0|  0.00%|    provides_observation_tensor=True,
   127|         0|            0|            0|  0.00%|    provides_factored_observation_string=False,
   128|         0|            0|            0|  0.00%|    parameter_specification={
   129|         0|            0|            0|  0.00%|      "filename": 'parameters.json'
   130|         0|            0|            0|  0.00%|      }
   131|         0|            0|            0|  0.00%|    )
   132|         0|            0|            0|  0.00%|
   133|         0|            0|            0|  0.00%|def parse_auction_params(file_name):
   134|         0|            0|            0|  0.00%|  if file_name.startswith('/'):
   135|         0|            0|            0|  0.00%|    full_path = file_name
   136|         0|            0|            0|  0.00%|  else:
   137|         0|            0|            0|  0.00%|    logging.info("Reading from env variable CLOCK_AUCTION_CONFIG_DIR. If it is not set, there will be trouble.")
   138|         0|            0|            0|  0.00%|    config_dir = os.environ.get('CLOCK_AUCTION_CONFIG_DIR')
   139|         0|            0|            0|  0.00%|    if config_dir is None:
   140|         0|            0|            0|  0.00%|      raise ValueError("CLOCK_AUCTION_CONFIG_DIR env variable is not set.")
   141|         0|            0|            0|  0.00%|    logging.info(f"CLOCK_AUCTION_CONFIG_DIR={config_dir}")
   142|         0|            0|            0|  0.00%|    full_path = f'{config_dir}/{file_name}';
   143|         0|            0|            0|  0.00%|
   144|         0|            0|            0|  0.00%|  logging.info(f"Parsing configuration from {full_path}")
   145|         0|            0|            0|  0.00%|  with open(full_path, 'r') as f:
   146|         0|            0|            0|  0.00%|    game_params = json.load(f)
   147|         0|            0|            0|  0.00%|
   148|         0|            0|            0|  0.00%|    players = game_params['players']
   149|         0|            0|            0|  0.00%|
   150|         0|            0|            0|  0.00%|    opening_prices = game_params['opening_price']
   151|         0|            0|            0|  0.00%|    licenses = np.array(game_params['licenses'])
   152|         0|            0|            0|  0.00%|    num_products = len(licenses)
   153|         0|            0|            0|  0.00%|
   154|         0|            0|            0|  0.00%|    if len(opening_prices) != num_products:
   155|         0|            0|            0|  0.00%|      raise ValueError("Number of opening prices must match number of products.")
   156|         0|            0|            0|  0.00%|
   157|         0|            0|            0|  0.00%|    activity = game_params['activity']
   158|         0|            0|            0|  0.00%|    if len(activity) != num_products:
   159|         0|            0|            0|  0.00%|      raise ValueError("Number of activity must match number of products.")
   160|         0|            0|            0|  0.00%|
   161|         0|            0|            0|  0.00%|    activity_policy = game_params.get('activity_policy', ActivityPolicy.ON)
   162|         0|            0|            0|  0.00%|    if isinstance(activity_policy, bool):
   163|         0|            0|            0|  0.00%|      activity_policy = ActivityPolicy.ON if activity_policy else ActivityPolicy.OFF
   164|         0|            0|            0|  0.00%|
   165|         0|            0|            0|  0.00%|    information_policy = game_params.get('information_policy', InformationPolicy.SHOW_DEMAND)
   166|         0|            0|            0|  0.00%|    if isinstance(information_policy, str):
   167|         0|            0|            0|  0.00%|      information_policy = InformationPolicy[information_policy.upper()]
   168|         0|            0|            0|  0.00%|
   169|         0|            0|            0|  0.00%|    undersell_policy = game_params.get('undersell_rule', UndersellPolicy.UNDERSELL)
   170|         0|            0|            0|  0.00%|    if isinstance(undersell_policy, str):
   171|         0|            0|            0|  0.00%|      undersell_policy = UndersellPolicy[undersell_policy.upper()]
   172|         0|            0|            0|  0.00%|
   173|         0|            0|            0|  0.00%|    all_bids = action_to_bundles(licenses)
   174|         0|            0|            0|  0.00%|    all_bids_activity = np.array([activity @ bid for bid in all_bids])
   175|         0|            0|            0|  0.00%|
   176|         0|            0|            0|  0.00%|    types = defaultdict(list)
   177|         0|            0|            0|  0.00%|
   178|         0|            0|            0|  0.00%|    for player_id, player in enumerate(players):
   179|         0|            0|            0|  0.00%|      player_types = player['type']
   180|         0|            0|            0|  0.00%|      for player_type in player_types:
   181|         0|            0|            0|  0.00%|        values = player_type['value']
   182|         0|            0|            0|  0.00%|        if np.array(values).ndim == 2:
   183|         0|            0|            0|  0.00%|          default_assumption = ValueFormat.MARGINAL
   184|         0|            0|            0|  0.00%|        else:
   185|         0|            0|            0|  0.00%|          default_assumption = ValueFormat.LINEAR
   186|         0|            0|            0|  0.00%|        value_format = player_type.get('value_format', default_assumption)
   187|         0|            0|            0|  0.00%|        if isinstance(value_format, str):
   188|         0|            0|            0|  0.00%|          value_format = ValueFormat[value_format.upper()]
   189|         0|            0|            0|  0.00%|        budget = player_type['budget']
   190|         0|            0|            0|  0.00%|        prob = player_type['prob']
   191|         0|            0|            0|  0.00%|        pricing_bonus = player_type.get('pricing_bonus', 0)
   192|         0|            0|            0|  0.00%|        drop_out_heuristic = player_type.get('drop_out_heuristic', True)
   193|         0|            0|            0|  0.00%|
   194|         0|            0|            0|  0.00%|        if value_format == ValueFormat.LINEAR:
   195|         0|            0|            0|  0.00%|          if len(values) != num_products:
   196|         0|            0|            0|  0.00%|            raise ValueError("Number of values must match number of products.")
   197|         0|            0|            0|  0.00%|          bidder = clock_auction_bidders.LinearBidder(values, budget, pricing_bonus, all_bids, drop_out_heuristic)
   198|         0|            0|            0|  0.00%|        elif value_format == ValueFormat.FULL:
   199|         0|            0|            0|  0.00%|          if len(values) != len(all_bids):
   200|         0|            0|            0|  0.00%|            raise ValueError("Number of values must match number of bids.")
   201|         0|            0|            0|  0.00%|          bidder = clock_auction_bidders.EnumeratedValueBidder(values, budget, pricing_bonus, all_bids, drop_out_heuristic)
   202|         0|            0|            0|  0.00%|        elif value_format == ValueFormat.MARGINAL:
   203|         0|            0|            0|  0.00%|          bidder = clock_auction_bidders.MarginalValueBidder(values, budget, pricing_bonus, all_bids, drop_out_heuristic)
   204|         0|            0|            0|  0.00%|        else:
   205|         0|            0|            0|  0.00%|          raise ValueError("Unknown value format")
   206|         0|            0|            0|  0.00%|
   207|         0|            0|            0|  0.00%|        types[player_id].append(dict(prob=prob, bidder=bidder))
   208|         0|            0|            0|  0.00%|
   209|         0|            0|            0|  0.00%|  logging.info("Done config parsing")
   210|         0|            0|            0|  0.00%|  return AuctionParams(
   211|         0|            0|            0|  0.00%|      opening_prices=opening_prices,
   212|         0|            0|            0|  0.00%|      licenses=licenses,
   213|         0|            0|            0|  0.00%|      num_products=num_products,
   214|         0|            0|            0|  0.00%|      activity=activity,
   215|         0|            0|            0|  0.00%|      increment=game_params.get('increment', 0.1),
   216|         0|            0|            0|  0.00%|      max_round=game_params.get('max_rounds', DEFAULT_MAX_ROUNDS),
   217|         0|            0|            0|  0.00%|      player_types=types,
   218|         0|            0|            0|  0.00%|      all_bids=all_bids,
   219|         0|            0|            0|  0.00%|      all_bids_activity=all_bids_activity,
   220|         0|            0|            0|  0.00%|      activity_policy=activity_policy,
   221|         0|            0|            0|  0.00%|      undersell_policy=undersell_policy,
   222|         0|            0|            0|  0.00%|      information_policy=information_policy,
   223|         0|            0|            0|  0.00%|      tiebreaks=game_params.get('tiebreaks', True),
   224|         0|            0|            0|  0.00%|      agent_memory=game_params.get('agent_memory', DEFAULT_AGENT_MEMORY),
   225|         0|            0|            0|  0.00%|      default_player_order=[[p for p in range(len(players))] for _ in range(num_products)]
   226|         0|            0|            0|  0.00%|    )
   227|         0|            0|            0|  0.00%|
   228|         0|            0|            0|  0.00%|class ClockAuctionGame(pyspiel.Game):
   229|         0|            0|            0|  0.00%|
   230|         0|            0|            0|  0.00%|  def __init__(self, params=None):
   231|         0|            0|            0|  0.00%|    file_name = params.get('filename', 'parameters.json')
   232|         0|            0|            0|  0.00%|    self.auction_params = parse_auction_params(file_name)
   233|         0|            0|            0|  0.00%|    num_players = len(self.auction_params.player_types)
   234|         0|            0|            0|  0.00%|
   235|         0|            0|            0|  0.00%|    # Max of # of type draws and tie-breaking
   236|         0|            0|            0|  0.00%|    max_chance_outcomes = max(max([len(v) for v in self.auction_params.player_types.values()]), math.factorial(num_players))
   237|         0|            0|            0|  0.00%|
   238|         0|            0|            0|  0.00%|    # You can bid for [0...M_j] for any of the j products
   239|         0|            0|            0|  0.00%|    num_actions = (1 + np.array(self.auction_params.licenses)).prod()
   240|         0|            0|            0|  0.00%|
   241|         0|            0|            0|  0.00%|    # MAX AND MIN UTILITY
   242|         0|            0|            0|  0.00%|    self.upper_bounds = []
   243|         0|            0|            0|  0.00%|    self.lower_bounds = []
   244|         0|            0|            0|  0.00%|    open_prices_per_bundles = np.array([self.auction_params.opening_prices @ bid for bid in self.auction_params.all_bids])
   245|         0|            0|            0|  0.00%|    for player_id, types in self.auction_params.player_types.items():
   246|         0|            0|            0|  0.00%|      player_upper_bounds = []
   247|         0|            0|            0|  0.00%|      player_lower_bounds = []
   248|         0|            0|            0|  0.00%|      for t in types:
   249|         0|            0|            0|  0.00%|        bidder = t['bidder']
   250|         0|            0|            0|  0.00%|        # What if you won your favorite package at opening prices?
   251|         0|            0|            0|  0.00%|        bound = bidder.get_profits(open_prices_per_bundles).max()
   252|         0|            0|            0|  0.00%|        player_upper_bounds.append(bound)
   253|         0|            0|            0|  0.00%|        # What if you spent your entire budget and got nothing? (A tighter not implemented bound: if you got the single worst item for you, since you must be paying for something)
   254|         0|            0|            0|  0.00%|        player_lower_bounds.append(-bidder.budget)
   255|         0|            0|            0|  0.00%|      self.upper_bounds.append(max(player_upper_bounds))
   256|         0|            0|            0|  0.00%|      self.lower_bounds.append(min(player_lower_bounds))
   257|         0|            0|            0|  0.00%|
   258|         0|            0|            0|  0.00%|    game_info = pyspiel.GameInfo(
   259|         0|            0|            0|  0.00%|        num_distinct_actions=num_actions,
   260|         0|            0|            0|  0.00%|        max_chance_outcomes=max_chance_outcomes,
   261|         0|            0|            0|  0.00%|        num_players=num_players,
   262|         0|            0|            0|  0.00%|        min_utility=-99999,
   263|         0|            0|            0|  0.00%|        max_utility=max(self.upper_bounds),
   264|         0|            0|            0|  0.00%|        utility_sum=-99999,
   265|         0|            0|            0|  0.00%|        max_game_length=9999)
   266|         0|            0|            0|  0.00%|
   267|         0|            0|            0|  0.00%|    super().__init__(_GAME_TYPE, game_info, params)
   268|         0|            0|            0|  0.00%|
   269|      1349|   0.00263405|  1.95259e-06|  0.00%|  def new_initial_state(self):
   270|         0|            0|            0|  0.00%|    """Returns a state corresponding to the start of a game."""
   271|      1349|    0.0108149|  8.01698e-06|  0.01%|    return ClockAuctionState(self)
(call)|      1349|     0.172895|  0.000128166|  0.17%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:287 __init__
   272|         0|            0|            0|  0.00%|
   273|         0|            0|            0|  0.00%|  def make_py_observer(self, iig_obs_type=None, params=None):
   274|         0|            0|            0|  0.00%|    """Returns an object used for observing game state."""
   275|         0|            0|            0|  0.00%|    if params is None:
   276|         0|            0|            0|  0.00%|      params = dict()
   277|         0|            0|            0|  0.00%|
   278|         0|            0|            0|  0.00%|    params['auction_params'] = self.auction_params
   279|         0|            0|            0|  0.00%|
   280|         0|            0|            0|  0.00%|    return ClockAuctionObserver(
   281|         0|            0|            0|  0.00%|        iig_obs_type or pyspiel.IIGObservationType(perfect_recall=False),
   282|         0|            0|            0|  0.00%|        params)
   283|         0|            0|            0|  0.00%|
   284|         0|            0|            0|  0.00%|class ClockAuctionState(pyspiel.State):
   285|         0|            0|            0|  0.00%|  """A python version of the Atari Game state."""
   286|         0|            0|            0|  0.00%|
   287|      1349|   0.00283909|  2.10459e-06|  0.00%|  def __init__(self, game):
   288|         0|            0|            0|  0.00%|    """Constructor; should only be called by Game.new_initial_state."""
   289|      1349|    0.0125756|  9.32218e-06|  0.01%|    super().__init__(game)
   290|      1349|   0.00378728|  2.80747e-06|  0.00%|    self.auction_params = game.auction_params
   291|      1349|   0.00274444|  2.03442e-06|  0.00%|    self._game_over = False
   292|      1349|   0.00263524|  1.95348e-06|  0.00%|    self._auction_finished = False
   293|      1349|   0.00259018|  1.92007e-06|  0.00%|    self._is_chance = True
   294|      1349|    0.0105445|  7.81656e-06|  0.01%|    self.tie_break_state = TieBreakState()
(call)|      1349|    0.0285039|  2.11296e-05|  0.03%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:2 __init__
   295|      1349|   0.00297832|   2.2078e-06|  0.00%|    self.bidders = []
   296|      1349|   0.00648308|  4.80584e-06|  0.01%|    self.posted_prices = [np.array(self.auction_params.opening_prices)]
   297|      1349|   0.00418997|  3.10598e-06|  0.00%|    self.sor_prices = [np.array(self.auction_params.opening_prices)]
   298|      1349|   0.00413418|  3.06462e-06|  0.00%|    self.clock_prices = [np.array(self.auction_params.opening_prices)]
   299|      1349|   0.00688887|  5.10665e-06|  0.01%|    self.aggregate_demand = [np.zeros(self.auction_params.num_products, dtype=int)]
   300|      1349|   0.00274205|  2.03266e-06|  0.00%|    self.round = 1
   301|      1349|   0.00264859|  1.96337e-06|  0.00%|    self._cur_player = 0
   302|      1349|   0.00265026|  1.96461e-06|  0.00%|    self._final_payments = None
   303|      1349|   0.00441313|  3.27141e-06|  0.00%|    self.price_increments = np.zeros(self.auction_params.num_products, dtype=int)
   304|      1349|    0.0112503|   8.3397e-06|  0.01%|    self.legal_action_mask = np.ones(len(self.auction_params.all_bids), dtype=bool)
(call)|      1349|    0.0582964|  4.32146e-05|  0.06%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/numeric.py:149 ones
   305|         0|            0|            0|  0.00%|
   306|    485016|     0.865139|  1.78373e-06|  0.83%|  def current_player(self) -> pyspiel.PlayerId:
   307|         0|            0|            0|  0.00%|    """Returns the current player.
   308|         0|            0|            0|  0.00%|
   309|         0|            0|            0|  0.00%|    If the game is over, TERMINAL is returned. If the game is at a chance
   310|         0|            0|            0|  0.00%|    node then CHANCE is returned. Otherwise SIMULTANEOUS is returned.
   311|         0|            0|            0|  0.00%|    """
   312|    485016|     0.841593|  1.73519e-06|  0.81%|    if self._game_over:
   313|      5966|    0.0118902|  1.99299e-06|  0.01%|      return pyspiel.PlayerId.TERMINAL
   314|    479050|     0.753323|  1.57253e-06|  0.72%|    elif self._is_chance:
   315|     25823|    0.0461707|  1.78797e-06|  0.04%|      return pyspiel.PlayerId.CHANCE
   316|         0|            0|            0|  0.00%|    else:
   317|    453227|     0.711013|  1.56878e-06|  0.68%|      return self._cur_player
   318|         0|            0|            0|  0.00%|
   319|     53971|     0.184179|  3.41255e-06|  0.18%|  def _legal_actions(self, player):
   320|         0|            0|            0|  0.00%|    """Returns a list of legal actions, sorted in ascending order."""
   321|     53971|     0.177001|  3.27956e-06|  0.17%|    assert player >= 0
   322|     53971|     0.159315|  2.95187e-06|  0.15%|    legal_actions = []
   323|     53971|     0.160414|  2.97222e-06|  0.15%|    bidder = self.bidders[player]
   324|         0|            0|            0|  0.00%|
   325|     53971|     0.451558|  8.36668e-06|  0.43%|    if len(bidder.submitted_demand) > 1 and sum(bidder.submitted_demand[-1]) == 0:
   326|         0|            0|            0|  0.00%|      # Don't need to recalculate - can only bid 0
   327|         0|            0|            0|  0.00%|      return [0]
   328|         0|            0|            0|  0.00%|
   329|     53971|     0.229387|  4.25019e-06|  0.22%|    price = np.array(self.clock_prices[-1])
   330|     53971|     0.173845|  3.22107e-06|  0.17%|    budget = bidder.bidder.budget
   331|     53971|     0.142741|  2.64477e-06|  0.14%|    hard_budget_on = True # TODO: Make param
   332|     53971|     0.136541|   2.5299e-06|  0.13%|    positive_profit_on = False # TODO: Make param
   333|         0|            0|            0|  0.00%|
   334|     53971|     0.439938|  8.15137e-06|  0.42%|    prices = self.auction_params.all_bids @ price
   335|     53971|     0.395088|  7.32038e-06|  0.38%|    profits = bidder.bidder.get_profits(prices)
(call)|     53971|     0.677741|  1.25575e-05|  0.65%|# /apps/open_spiel/open_spiel/python/games/clock_auction_bidders.py:25 get_profits
   336|         0|            0|            0|  0.00%|
   337|         0|            0|            0|  0.00%|    # Note we assume all drops go through. A more sophisticated bidder might think differently (e.g., try to fulfill budget in expectation)
   338|         0|            0|            0|  0.00%|    # Consider e.g. if you drop a product you might get stuck! So you can wind up over your budget if your drop fails
   339|         0|            0|            0|  0.00%|    # Also consider that if you drop a product and get stuck, you only pay SoR on that product
   340|         0|            0|            0|  0.00%|
   341|     53971|     0.193045|  3.57684e-06|  0.18%|    legal_actions = self.legal_action_mask.copy()
   342|         0|            0|            0|  0.00%|
   343|     53971|     0.173944|  3.22291e-06|  0.17%|    if self.auction_params.activity_policy == ActivityPolicy.ON:
   344|     53971|     0.763489|  1.41463e-05|  0.73%|      legal_actions[np.where(bidder.activity < self.auction_params.all_bids_activity)[0]] = 0
(call)|     53971|      1.20428|  2.23135e-05|  1.15%|# <__array_function__ internals>:177 where
   345|         0|            0|            0|  0.00%|
   346|     53971|     0.128681|  2.38427e-06|  0.12%|    if hard_budget_on:
   347|     53971|     0.375275|  6.95326e-06|  0.36%|      legal_actions[prices > budget] = 0
   348|         0|            0|            0|  0.00%|
   349|     53971|     0.128941|  2.38908e-06|  0.12%|    if positive_profit_on:
   350|         0|            0|            0|  0.00%|      legal_actions[profits < 0] = 0
   351|         0|            0|            0|  0.00%|
   352|         0|            0|            0|  0.00%|    # TODO: Shouldn't I be using LegalProfits here? (i.e., accounting for the fact that it needs to be a legal bundle?)
   353|     53971|     0.665589|  1.23323e-05|  0.64%|    if not (profits[legal_actions] > 0).any():
(call)|     53971|      0.53292|  9.87419e-06|  0.51%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/_methods.py:54 _any
   354|         0|            0|            0|  0.00%|      # If you have no way to make a profit ever going forwards, just drop out. Helps minimize game size
   355|       198|  0.000465155|  2.34927e-06|  0.00%|      return [0]
   356|         0|            0|            0|  0.00%|    else:
   357|     53773|     0.130729|  2.43112e-06|  0.13%|      if bidder.bidder.drop_out_heuristic:
   358|         0|            0|            0|  0.00%|        # At least one bid leads to positive profit. Dropping out is never the right thing to do in this case. It will always be action 0
   359|     53773|     0.138652|  2.57846e-06|  0.13%|        legal_actions[0] = 0
   360|         0|            0|            0|  0.00%|
   361|     53773|      3.88012|  7.21573e-05|  3.72%|    if sum(legal_actions) == 0:
   362|         0|            0|            0|  0.00%|      print(self)
   363|         0|            0|            0|  0.00%|      raise ValueError("No legal actions!")
   364|         0|            0|            0|  0.00%|
   365|     53773|     0.217635|  4.04729e-06|  0.21%|    return legal_actions.nonzero()[0]
   366|         0|            0|            0|  0.00%|
   367|     24324|    0.0840433|  3.45516e-06|  0.08%|  def _apply_action(self, action):
   368|         0|            0|            0|  0.00%|    """Applies the specified action to the state.
   369|         0|            0|            0|  0.00%|    """
   370|     24324|     0.288553|  1.18629e-05|  0.28%|    if not self.is_chance_node():
(call)|     24324|     0.163225|  6.71046e-06|  0.16%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:306 current_player
   371|         0|            0|            0|  0.00%|      # Colelct the bid in submitted demand
   372|     18432|    0.0585539|  3.17675e-06|  0.06%|      assert not self._game_over
   373|     18432|    0.0608842|  3.30318e-06|  0.06%|      bidder = self.bidders[self._cur_player]
   374|     18432|    0.0659807|  3.57968e-06|  0.06%|      assert len(bidder.processed_demand) == len(bidder.submitted_demand)
   375|     18432|    0.0567696|  3.07995e-06|  0.05%|      assert self.round == len(bidder.submitted_demand)
   376|     18432|    0.0798652|  4.33297e-06|  0.08%|      bid = self.auction_params.all_bids[action]
   377|         0|            0|            0|  0.00%|
   378|     18432|    0.0699005|  3.79235e-06|  0.07%|      if self.auction_params.activity_policy == ActivityPolicy.ON:
   379|     18432|    0.0656385|  3.56112e-06|  0.06%|        bid_activity_cost = self.auction_params.all_bids_activity[action]
   380|     18432|    0.0595264|  3.22952e-06|  0.06%|        if bidder.activity < bid_activity_cost:
   381|         0|            0|            0|  0.00%|          raise ValueError(f"Bidder {self._cur_player} is not active enough ({bidder.activity}) to bid on {bid} with cost of {bid_activity_cost}")
   382|         0|            0|            0|  0.00%|
   383|     18432|    0.0984697|  5.34232e-06|  0.09%|      bidder.submitted_demand.append(np.array(bid))
   384|         0|            0|            0|  0.00%|
   385|         0|            0|            0|  0.00%|      # Collect bids until we've got from all players: only then can we process the demand
   386|     18432|     0.108806|  5.90311e-06|  0.10%|      if self._cur_player == self.num_players() - 1:
   387|      9216|    0.0818157|  8.87757e-06|  0.08%|        self._handle_bids()
(call)|      9216|      6.44246|  0.000699052|  6.17%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:431 _handle_bids
   388|         0|            0|            0|  0.00%|      else:
   389|      9216|    0.0326591|  3.54373e-06|  0.03%|        self._cur_player += 1 # Advance player and collect more bids
   390|         0|            0|            0|  0.00%|
   391|         0|            0|            0|  0.00%|    else: # CHANCE NODE
   392|      5892|    0.0192335|  3.26434e-06|  0.02%|      if self.round == 1:
   393|      2698|    0.0149572|  5.54381e-06|  0.01%|        if len(self.bidders) < self.num_players(): # Chance node assigns a value and budget to a player
   394|      5396|    0.0169077|  3.13338e-06|  0.02%|          self.bidders.append(
   395|      5396|    0.0345469|  6.40231e-06|  0.03%|            BidderState(
(call)|      2698|    0.0403454|  1.49538e-05|  0.04%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:2 __init__
   396|      2698|     0.014106|  5.22833e-06|  0.01%|              submitted_demand=[np.zeros(self.auction_params.num_products, dtype=int)], # Start with this dummy entry so we can always index by round
   397|      2698|    0.0113153|  4.19398e-06|  0.01%|              processed_demand=[np.zeros(self.auction_params.num_products, dtype=int)],
   398|      2698|   0.00905156|  3.35492e-06|  0.01%|              bidder=self.auction_params.player_types[len(self.bidders)][action]['bidder'],
   399|      2698|   0.00813055|  3.01355e-06|  0.01%|              activity=self.auction_params.max_activity,
   400|      2698|   0.00766325|  2.84034e-06|  0.01%|              type_index=action,
   401|         0|            0|            0|  0.00%|            )
   402|         0|            0|            0|  0.00%|          )
   403|      2698|    0.0153937|  5.70561e-06|  0.01%|        if len(self.bidders) == self.num_players(): # All of the assignments have been made
   404|      1349|   0.00435781|   3.2304e-06|  0.00%|          self._is_chance = False
   405|         0|            0|            0|  0.00%|      else:
   406|         0|            0|            0|  0.00%|        # Tie breaking
   407|      3194|    0.0095973|  3.00479e-06|  0.01%|        ts = self.tie_break_state
   408|         0|            0|            0|  0.00%|
   409|         0|            0|            0|  0.00%|        # Assign ordering for this product by indexing into the list of permutations with action
   410|      3194|     0.010361|  3.24388e-06|  0.01%|        j = len(ts.selected_order)
   411|      3194|    0.0163879|  5.13085e-06|  0.02%|        order = list(list(itertools.permutations(ts.tie_breaks_needed[j]))[action])
   412|         0|            0|            0|  0.00%|
   413|         0|            0|            0|  0.00%|        # Pad with players that aren't in the list so we have a complete ordering (recall that tie_breaks_needed has only the players in conflict)
   414|      9582|    0.0360167|  3.75879e-06|  0.03%|        for player_id in range(self.num_players()):
   415|      6388|    0.0175498|   2.7473e-06|  0.02%|          if player_id not in order:
   416|      2637|   0.00721455|  2.73589e-06|  0.01%|            order.append(player_id)
   417|      3194|   0.00836778|  2.61984e-06|  0.01%|        ts.selected_order.append(order)
   418|      3194|   0.00826812|  2.58864e-06|  0.01%|        j += 1
   419|         0|            0|            0|  0.00%|
   420|         0|            0|            0|  0.00%|        # Skip ahead to the next point we need a tie
   421|      3212|   0.00891328|  2.77499e-06|  0.01%|        while j < self.auction_params.num_products:
   422|       924|   0.00260925|  2.82387e-06|  0.00%|          if len(ts.tie_breaks_needed[j]) <= 1:
   423|        18|  5.65052e-05|  3.13918e-06|  0.00%|            ts.selected_order.append(list(self.auction_params.default_player_order[j]))
   424|        18|  5.74589e-05|  3.19216e-06|  0.00%|            j += 1
   425|         0|            0|            0|  0.00%|          else:
   426|         0|            0|            0|  0.00%|            break # We need to actually do this one and it will require another chance node
   427|         0|            0|            0|  0.00%|
   428|      3194|   0.00878048|  2.74905e-06|  0.01%|        if j == self.auction_params.num_products: # Done with chance nodes
   429|      2288|    0.0245864|  1.07458e-05|  0.02%|          self._process_bids(ts.selected_order)
(call)|      2288|      1.85054|  0.000808801|  1.77%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:565 _process_bids
   430|         0|            0|            0|  0.00%|
   431|      9216|    0.0238199|  2.58463e-06|  0.02%|  def _handle_bids(self):
   432|         0|            0|            0|  0.00%|    # Demand Processing
   433|      9216|    0.0315232|  3.42049e-06|  0.03%|    if self.round == 1 or self.auction_params.undersell_policy == UndersellPolicy.UNDERSELL_ALLOWED:
   434|         0|            0|            0|  0.00%|      # Just copy it straight over
   435|      4047|    0.0090425|  2.23437e-06|  0.01%|      for bidder in self.bidders:
   436|      2698|   0.00615525|  2.28141e-06|  0.01%|        bid = bidder.submitted_demand[-1]
   437|      2698|   0.00679851|  2.51983e-06|  0.01%|        bidder.processed_demand.append(np.asarray(bid))
   438|      1349|    0.0111794|  8.28721e-06|  0.01%|      self._post_process()
(call)|      1349|     0.319458|  0.000236811|  0.31%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:523 _post_process
   439|      7867|    0.0210295|  2.67312e-06|  0.02%|    elif self.auction_params.undersell_policy == UndersellPolicy.UNDERSELL:
   440|      7867|    0.0716374|  9.10606e-06|  0.07%|      tiebreaks_not_needed = self._determine_tiebreaks()
(call)|      7867|      1.97308|  0.000250805|  1.89%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:631 _determine_tiebreaks
   441|      7867|    0.0186751|  2.37385e-06|  0.02%|      if tiebreaks_not_needed: # No chance node required. Just get on with the game
   442|      5579|    0.0564032|  1.01099e-05|  0.05%|        self._process_bids(self.auction_params.default_player_order)
(call)|      5579|      3.88804|  0.000696907|  3.73%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:565 _process_bids
   443|         0|            0|            0|  0.00%|      else:
   444|      2288|    0.0056138|  2.45359e-06|  0.01%|        self._is_chance = True
   445|         0|            0|            0|  0.00%|    else:
   446|         0|            0|            0|  0.00%|      raise ValueError("Unknown undersell policy")
   447|         0|            0|            0|  0.00%|
   448|         0|            0|            0|  0.00%|  def _action_to_string(self, player, action):
   449|         0|            0|            0|  0.00%|    """Action -> string."""
   450|         0|            0|            0|  0.00%|    if player == pyspiel.PlayerId.CHANCE:
   451|         0|            0|            0|  0.00%|      if len(self.bidders) < self.num_players():
   452|         0|            0|            0|  0.00%|        return f'Assign player {len(self.bidders)} type {self.auction_params.player_types[len(self.bidders)][action]["bidder"]}'
   453|         0|            0|            0|  0.00%|      else:
   454|         0|            0|            0|  0.00%|        return f'Tie-break action {action}'
   455|         0|            0|            0|  0.00%|    else:
   456|         0|            0|            0|  0.00%|      bid = self.auction_params.all_bids[action]
   457|         0|            0|            0|  0.00%|      activity = self.auction_params.all_bids_activity[action]
   458|         0|            0|            0|  0.00%|      price = bid @ self.clock_prices[-1]
   459|         0|            0|            0|  0.00%|      return f'Bid for {bid} licenses @ ${price:.2f} with activity {activity}'
   460|         0|            0|            0|  0.00%|
   461|    223914|     0.425018|  1.89813e-06|  0.41%|  def is_terminal(self):
   462|         0|            0|            0|  0.00%|    """Returns True if the game is over."""
   463|    223914|     0.405691|  1.81182e-06|  0.39%|    return self._game_over
   464|         0|            0|            0|  0.00%|
   465|      2682|    0.0078001|  2.90832e-06|  0.01%|  def returns(self):
   466|         0|            0|            0|  0.00%|    """Total reward for each player over the course of the game so far."""
   467|      2682|   0.00760722|   2.8364e-06|  0.01%|    assert self._game_over
   468|      2682|   0.00687337|  2.56278e-06|  0.01%|    assert self._auction_finished
   469|         0|            0|            0|  0.00%|
   470|      2682|    0.0207283|  7.72869e-06|  0.02%|    self._final_payments = np.zeros(self.num_players())
   471|      2682|    0.0212717|  7.93128e-06|  0.02%|    returns = np.zeros_like(self._final_payments)
(call)|      2682|     0.232314|  8.66198e-05|  0.22%|# <__array_function__ internals>:177 zeros_like
   472|      2682|   0.00788426|   2.9397e-06|  0.01%|    final_prices = self.posted_prices[-1]
   473|         0|            0|            0|  0.00%|
   474|      8046|    0.0212729|  2.64391e-06|  0.02%|    for player_id, bidder in enumerate(self.bidders):
   475|      5364|    0.0123823|   2.3084e-06|  0.01%|      final_bid = bidder.processed_demand[-1]
   476|      5364|    0.0376787|  7.02437e-06|  0.04%|      payment = final_bid @ final_prices
   477|      5364|     0.014056|  2.62043e-06|  0.01%|      self._final_payments[player_id] = payment
   478|      5364|    0.0353966|  6.59891e-06|  0.03%|      value = bidder.bidder.value_for_package(final_bid)
(call)|      5364|     0.271354|  5.05879e-05|  0.26%|# /apps/open_spiel/open_spiel/python/games/clock_auction_bidders.py:61 value_for_package
   479|      5364|    0.0435607|  8.12094e-06|  0.04%|      returns[player_id] = value - payment
   480|         0|            0|            0|  0.00%|
   481|      2682|   0.00506949|  1.89019e-06|  0.00%|    return returns
   482|         0|            0|            0|  0.00%|
   483|         0|            0|            0|  0.00%|  def __str__(self):
   484|         0|            0|            0|  0.00%|    with np.printoptions(precision=3):
   485|         0|            0|            0|  0.00%|
   486|         0|            0|            0|  0.00%|      """String for debug purposes. No particular semantics are required."""
   487|         0|            0|            0|  0.00%|      result = f'Round: {self.round}\n'
   488|         0|            0|            0|  0.00%|
   489|         0|            0|            0|  0.00%|      # Player types
   490|         0|            0|            0|  0.00%|      for player_id, bidder in enumerate(self.bidders):
   491|         0|            0|            0|  0.00%|        result += f'Player {player_id}: {bidder.bidder}\n'
   492|         0|            0|            0|  0.00%|
   493|         0|            0|            0|  0.00%|      if self.round > 1:
   494|         0|            0|            0|  0.00%|        result += f'Price: {self.posted_prices[-1]}\n'
   495|         0|            0|            0|  0.00%|
   496|         0|            0|            0|  0.00%|        result += 'Processed Demand:\n'
   497|         0|            0|            0|  0.00%|        for player_id, player in enumerate(self.bidders):
   498|         0|            0|            0|  0.00%|          if len(player.processed_demand) > 0:
   499|         0|            0|            0|  0.00%|            result += f'{player.processed_demand[-1]}\n'
   500|         0|            0|            0|  0.00%|
   501|         0|            0|            0|  0.00%|        result += f'Aggregate demand: {self.aggregate_demand[-1]}\n'
   502|         0|            0|            0|  0.00%|
   503|         0|            0|            0|  0.00%|      if self._auction_finished:
   504|         0|            0|            0|  0.00%|        for player_id, player in enumerate(self.bidders):
   505|         0|            0|            0|  0.00%|          result += f'Final bids player {player_id}: {player.processed_demand[-1]}\n'
   506|         0|            0|            0|  0.00%|
   507|         0|            0|            0|  0.00%|    return result
   508|         0|            0|            0|  0.00%|
   509|      5892|    0.0147002|  2.49494e-06|  0.01%|  def chance_outcomes(self):
   510|         0|            0|            0|  0.00%|    """Returns the possible chance outcomes and their probabilities."""
   511|      5892|    0.0160573|  2.72526e-06|  0.02%|    assert self._is_chance
   512|      5892|    0.0298843|  5.07202e-06|  0.03%|    if len(self.bidders) < self.num_players(): # Chance node is assigning a type
   513|      2698|   0.00712943|  2.64249e-06|  0.01%|      player_index = len(self.bidders)
   514|      2698|   0.00706077|  2.61704e-06|  0.01%|      player_types = self.auction_params.player_types[player_index]
   515|     21584|    0.0518334|  2.40147e-06|  0.05%|      probs = [t['prob'] for t in player_types]
(call)|      2698|    0.0326509|  1.21019e-05|  0.03%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:515 <listcomp>
   516|         0|            0|            0|  0.00%|    else: # Chance node is breaking a tie
   517|      3194|   0.00832033|  2.60499e-06|  0.01%|      ts = self.tie_break_state
   518|      3194|    0.0119205|  3.73214e-06|  0.01%|      chance_outcomes_required = math.factorial(len(ts.tie_breaks_needed[len(ts.selected_order)]))
   519|      3194|   0.00988817|  3.09586e-06|  0.01%|      probs = [1 / chance_outcomes_required] * chance_outcomes_required
   520|         0|            0|            0|  0.00%|
   521|      5892|    0.0209765|  3.56017e-06|  0.02%|    return list(enumerate(probs))
   522|         0|            0|            0|  0.00%|
   523|      9216|    0.0303962|   3.2982e-06|  0.03%|  def _post_process(self):
   524|         0|            0|            0|  0.00%|    # Calculate aggregate demand
   525|      9216|    0.0496788|   5.3905e-06|  0.05%|    aggregate_demand = np.zeros(self.auction_params.num_products, dtype=int)
   526|     27648|    0.0732117|  2.64799e-06|  0.07%|    for bidder in self.bidders:
   527|     18432|    0.0652647|  3.54084e-06|  0.06%|      bid = bidder.processed_demand[-1].copy()
   528|         0|            0|            0|  0.00%|
   529|         0|            0|            0|  0.00%|      # Lower activity based on processed demand (TODO: May want to revisit this for grace period)
   530|     18432|     0.170093|  9.22813e-06|  0.16%|      bidder.activity = bid @ self.auction_params.activity
   531|     18432|    0.0942564|  5.11374e-06|  0.09%|      aggregate_demand += bid
   532|         0|            0|            0|  0.00%|
   533|         0|            0|            0|  0.00%|    # Calculate excess demand
   534|      9216|    0.0402918|  4.37194e-06|  0.04%|    excess_demand = aggregate_demand > self.auction_params.licenses
   535|         0|            0|            0|  0.00%|
   536|      9216|    0.0251164|  2.72531e-06|  0.02%|    self.aggregate_demand.append(aggregate_demand)
   537|         0|            0|            0|  0.00%|
   538|      9216|    0.0883582|  9.58747e-06|  0.08%|    if excess_demand.any():
(call)|      9216|     0.104225|  1.13092e-05|  0.10%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/_methods.py:54 _any
   539|         0|            0|            0|  0.00%|      # Normal case: Increment price for overdemanded items, leave other items alone
   540|      7875|    0.0367322|  4.66441e-06|  0.04%|      next_price = np.zeros(self.auction_params.num_products)
   541|      7875|    0.0612042|  7.77196e-06|  0.06%|      next_clock = np.zeros_like(next_price)
(call)|      7875|     0.695668|  8.83389e-05|  0.67%|# <__array_function__ internals>:177 zeros_like
   542|     31500|    0.0725553|  2.30334e-06|  0.07%|      for j in range(self.auction_params.num_products):
   543|     23625|      0.05075|  2.14815e-06|  0.05%|        if excess_demand[j]:
   544|      9118|    0.0274966|  3.01564e-06|  0.03%|          self.price_increments[j] += 1
   545|     23625|    0.0634017|  2.68367e-06|  0.06%|        next_price[j] = self.clock_prices[-1][j] if excess_demand[j] else self.sor_prices[-1][j]
   546|     23625|    0.0647075|  2.73894e-06|  0.06%|        next_clock[j] = next_price[j] * (1 + self.auction_params.increment)
   547|      7875|    0.0167384|  2.12551e-06|  0.02%|      self.posted_prices.append(next_price)
   548|      7875|    0.0164132|  2.08422e-06|  0.02%|      self.sor_prices.append(next_price)
   549|      7875|    0.0160964|  2.04398e-06|  0.02%|      self.clock_prices.append(next_clock)
   550|         0|            0|            0|  0.00%|    else:
   551|         0|            0|            0|  0.00%|      # Demand <= supply for each item. We are finished
   552|      1341|    0.0036571|  2.72715e-06|  0.00%|      self._auction_finished = True
   553|      1341|   0.00328231|  2.44766e-06|  0.00%|      self._game_over = True
   554|      1341|   0.00513577|  3.82981e-06|  0.00%|      self.posted_prices.append(np.array(self.posted_prices[-1]))
   555|         0|            0|            0|  0.00%|
   556|      9216|    0.0189917|  2.06073e-06|  0.02%|    if not self._auction_finished:
   557|      7875|    0.0182531|  2.31785e-06|  0.02%|      self.round += 1
   558|      7875|    0.0174966|  2.22179e-06|  0.02%|      if self.round > self.auction_params.max_round:
   559|         0|            0|            0|  0.00%|        # An alternative: set game_over = True (auction_finished will still be false) and simply track this. Maybe give large negative rewards. But right now this seems more obvious as a way of triggering
   560|         0|            0|            0|  0.00%|        raise ValueError("Auction went on too long")
   561|         0|            0|            0|  0.00%|
   562|      9216|    0.0195518|   2.1215e-06|  0.02%|    self._cur_player = 0
   563|      9216|    0.0195613|  2.12254e-06|  0.02%|    self._is_chance = False
   564|         0|            0|            0|  0.00%|
   565|      7867|    0.0359418|  4.56868e-06|  0.03%|  def _process_bids(self, player_order):
   566|      7867|    0.0356472|  4.53123e-06|  0.03%|    assert len(player_order) == self.auction_params.num_products
   567|     31468|     0.127877|   4.0637e-06|  0.12%|    for j in range(self.auction_params.num_products):
   568|     23601|     0.143797|  6.09283e-06|  0.14%|      assert len(player_order[j]) == self.num_players()
   569|         0|            0|            0|  0.00%|
   570|      7867|    0.0424623|  5.39753e-06|  0.04%|    current_agg = self.aggregate_demand[-1].copy()
   571|         0|            0|            0|  0.00%|
   572|         0|            0|            0|  0.00%|    # Copy over the current aggregate demand
   573|         0|            0|            0|  0.00%|    # TODO: For now points is a zero vector, but possible grace period implementations would change that
   574|         0|            0|            0|  0.00%|
   575|      7867|    0.0341418|  4.33987e-06|  0.03%|    bids = []
   576|      7867|    0.0333011|  4.23301e-06|  0.03%|    requested_changes = []
   577|     39335|     0.131443|  3.34162e-06|  0.13%|    points = [bidder.activity for bidder in self.bidders]
(call)|      7867|    0.0604286|  7.68128e-06|  0.06%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:577 <listcomp>
   578|     23601|    0.0852358|  3.61153e-06|  0.08%|    for player_id, bidder in enumerate(self.bidders):
   579|     15734|    0.0664835|  4.22547e-06|  0.06%|      last_round_holdings = bidder.processed_demand[-1].copy()
   580|     15734|    0.0543749|  3.45589e-06|  0.05%|      bids.append(last_round_holdings)
   581|         0|            0|            0|  0.00%|
   582|     15734|    0.0844023|  5.36433e-06|  0.08%|      rq = np.zeros(self.auction_params.num_products)
   583|     62936|     0.204203|  3.24461e-06|  0.20%|      for j in range(self.auction_params.num_products):
   584|     47202|     0.171632|  3.63612e-06|  0.16%|        delta = bidder.submitted_demand[-1][j] - last_round_holdings[j]
   585|     47202|     0.162111|  3.43441e-06|  0.16%|        rq[j] = delta
   586|     47202|     0.187706|  3.97664e-06|  0.18%|        points[player_id] -= last_round_holdings[j] * self.auction_params.activity[j]
   587|     15734|    0.0492358|  3.12926e-06|  0.05%|      requested_changes.append(rq)
   588|         0|            0|            0|  0.00%|
   589|      7867|    0.0233798|  2.97188e-06|  0.02%|    changed = True
   590|         0|            0|            0|  0.00%|
   591|     20382|    0.0555096|  2.72346e-06|  0.05%|    while changed:
   592|     12515|    0.0346234|  2.76655e-06|  0.03%|      changed = False
   593|     50060|      0.13798|  2.75629e-06|  0.13%|      for j in range(self.auction_params.num_products):
   594|    112635|     0.301451|  2.67636e-06|  0.29%|        for player_id in player_order[j]:
   595|     75090|     0.196472|  2.61649e-06|  0.19%|          bid = bids[player_id]
   596|     75090|      0.19198|  2.55666e-06|  0.18%|          changes = requested_changes[player_id]
   597|         0|            0|            0|  0.00%|
   598|         0|            0|            0|  0.00%|          # Process drops
   599|     75090|     0.222228|  2.95949e-06|  0.21%|          if changes[j] < 0:
   600|     13738|    0.0439966|  3.20255e-06|  0.04%|            drop_room = current_agg[j] - self.auction_params.licenses[j]
   601|     13738|    0.0427063|  3.10862e-06|  0.04%|            if drop_room > 0:
   602|      3857|    0.0160594|   4.1637e-06|  0.02%|              amount = min(drop_room, -changes[j])
   603|      3857|     0.015511|  4.02153e-06|  0.01%|              bid[j] -= amount
   604|      3857|     0.011878|   3.0796e-06|  0.01%|              assert bid[j] >= 0
   605|      3857|    0.0100532|  2.60647e-06|  0.01%|              changed = True
   606|      3857|    0.0150042|  3.89011e-06|  0.01%|              points[player_id] += amount * self.auction_params.activity[j]
   607|      3857|    0.0127652|  3.30961e-06|  0.01%|              current_agg[j] -= amount
   608|      3857|    0.0129292|  3.35214e-06|  0.01%|              changes[j] += amount
   609|         0|            0|            0|  0.00%|
   610|         0|            0|            0|  0.00%|          # Process pickups
   611|     77858|     0.240411|  3.08782e-06|  0.23%|          while changes[j] > 0 and (self.auction_params.activity_policy == ActivityPolicy.OFF or points[player_id] >= self.auction_params.activity[j]):
   612|      2768|   0.00866675|  3.13105e-06|  0.01%|            bid[j] += 1
   613|      2768|   0.00855899|  3.09212e-06|  0.01%|            assert bid[j] <= self.auction_params.licenses[j]
   614|      2768|   0.00810933|  2.92967e-06|  0.01%|            current_agg[j] += 1
   615|      2768|   0.00694466|  2.50891e-06|  0.01%|            changed = True
   616|      2768|   0.00872946|  3.15371e-06|  0.01%|            points[player_id] -= self.auction_params.activity[j]
   617|      2768|   0.00938106|  3.38911e-06|  0.01%|            changes[j] -= 1
   618|         0|            0|            0|  0.00%|
   619|         0|            0|            0|  0.00%|    # Finally, copy over submitted -> processed
   620|     23601|     0.063163|  2.67629e-06|  0.06%|    for player_id, bidder in enumerate(self.bidders):
   621|     62936|     0.160278|  2.54668e-06|  0.15%|      for product_id in range(self.auction_params.num_products):
   622|     47202|     0.131669|  2.78948e-06|  0.13%|        assert bids[player_id][product_id] >= 0
   623|     47202|     0.132273|  2.80228e-06|  0.13%|        assert bids[player_id][product_id] <= self.auction_params.licenses[product_id]
   624|     47202|     0.159762|  3.38464e-06|  0.15%|        assert bids[player_id][product_id] <= max(bidder.submitted_demand[-1][product_id], bidder.processed_demand[-1][product_id]) # Either what you asked for, or what you used to have
   625|         0|            0|            0|  0.00%|
   626|     15734|    0.0448084|  2.84787e-06|  0.04%|      bidder.processed_demand.append(np.asarray(bids[player_id]))
   627|     15734|    0.0425131|  2.70199e-06|  0.04%|      assert len(bidder.processed_demand) == len(bidder.submitted_demand)
   628|         0|            0|            0|  0.00%|
   629|      7867|    0.0696659|  8.85546e-06|  0.07%|    self._post_process()
(call)|      7867|      1.64913|  0.000209626|  1.58%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:523 _post_process
   630|         0|            0|            0|  0.00%|
   631|      7867|    0.0244038|  3.10205e-06|  0.02%|  def _determine_tiebreaks(self):
   632|         0|            0|            0|  0.00%|    # Step 1: Figure out for each product whether we may be in a tie-breaking situation. Note that we can have false positives, they "just" make the game bigger.
   633|         0|            0|            0|  0.00%|    #         One necessary condition: At least two people want to drop the same product AND the combined dropping will take the product below supply
   634|         0|            0|            0|  0.00%|    #         Note that this doesn't consider demand that might be added to the product - this could resolve the issue, but if that pick-up can only be processed conditional on another drop, it gets more complicated... We ignore this for now.
   635|         0|            0|            0|  0.00%|    #
   636|         0|            0|            0|  0.00%|
   637|         0|            0|            0|  0.00%|    # TODO: A much simpler impl would just select one of factorial(num_players) arrangements for each product in advance and use that, tie breaks required or not (i.e., always put a chance node before bids are processed that determines processing order). So why do it this way? Because that's much worse for tabular algorithms, and they can help debug
   638|         0|            0|            0|  0.00%|
   639|      7867|    0.0267057|  3.39465e-06|  0.03%|    ts = self.tie_break_state
   640|      7867|    0.0611837|  7.77726e-06|  0.06%|    ts.reset()
(call)|      7867|    0.0502615|   6.3889e-06|  0.05%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:90 reset
   641|         0|            0|            0|  0.00%|
   642|      7867|    0.0260091|   3.3061e-06|  0.02%|    if not self.auction_params.tiebreaks or self.round == 1:
   643|         0|            0|            0|  0.00%|      return False
   644|         0|            0|            0|  0.00%|
   645|      7867|    0.0557621|   7.0881e-06|  0.05%|    drops_per_product = np.zeros((self.num_players(), self.auction_params.num_products))
   646|     23601|    0.0786185|  3.33115e-06|  0.08%|    for player_id, bidder in enumerate(self.bidders):
   647|     15734|     0.115176|   7.3202e-06|  0.11%|      drops_per_product[player_id] = np.abs(bidder.processed_demand[-1] - bidder.submitted_demand[-1])
   648|         0|            0|            0|  0.00%|
   649|      7867|    0.0690405|  8.77597e-06|  0.07%|    total_drops = np.sum(drops_per_product, axis=0)
(call)|      7867|     0.674296|  8.57119e-05|  0.65%|# <__array_function__ internals>:177 sum
   650|         0|            0|            0|  0.00%|
   651|      7867|    0.0227971|  2.89781e-06|  0.02%|    tie_breaking_not_needed = True
   652|      7867|    0.0320525|   4.0743e-06|  0.03%|    current_agg = self.aggregate_demand[-1].copy()
   653|     31468|    0.0824354|  2.61966e-06|  0.08%|    for j in range(self.auction_params.num_products):
   654|     23601|    0.0510585|  2.16341e-06|  0.05%|      tiebreaks = []
   655|     23601|     0.200882|   8.5116e-06|  0.19%|      if current_agg[j] - total_drops[j] < self.auction_params.licenses[j]:
   656|     32709|     0.114947|  3.51422e-06|  0.11%|        for player_id in range(self.num_players()):
   657|     21806|     0.069392|  3.18224e-06|  0.07%|          if drops_per_product[player_id][j] > 0:
   658|     13795|    0.0313804|  2.27477e-06|  0.03%|            tiebreaks.append(player_id)
   659|     23601|    0.0543764|  2.30399e-06|  0.05%|      if len(tiebreaks) > 1:
   660|      3212|    0.0066843|  2.08104e-06|  0.01%|        tie_breaking_not_needed = False
   661|         0|            0|            0|  0.00%|      else:
   662|     20389|    0.0567505|  2.78339e-06|  0.05%|        ts.selected_order.append(list(self.auction_params.default_player_order[j]))
   663|     23601|     0.052669|  2.23164e-06|  0.05%|      ts.tie_breaks_needed.append(tiebreaks)
   664|         0|            0|            0|  0.00%|
   665|      7867|    0.0162003|  2.05927e-06|  0.02%|    return tie_breaking_not_needed
   666|         0|            0|            0|  0.00%|
   667|         0|            0|            0|  0.00%|
   668|         0|            0|            0|  0.00%|  def get_final_payments(self):
   669|         0|            0|            0|  0.00%|    assert self._game_over
   670|         0|            0|            0|  0.00%|    return self._final_payments
   671|         0|            0|            0|  0.00%|
   672|         0|            0|            0|  0.00%|  @property
   673|         0|            0|            0|  0.00%|  def revenue(self):
   674|         0|            0|            0|  0.00%|    assert self._game_over
   675|         0|            0|            0|  0.00%|    return sum(self.get_final_payments())
   676|         0|            0|            0|  0.00%|
   677|         0|            0|            0|  0.00%|  # METRICS
   678|         0|            0|            0|  0.00%|  @property
   679|         0|            0|            0|  0.00%|  def revenue_potential(self):
   680|         0|            0|            0|  0.00%|    if self.round == 1:
   681|         0|            0|            0|  0.00%|      return 0
   682|         0|            0|            0|  0.00%|
   683|         0|            0|            0|  0.00%|    # TODO: Assumes undersell is turned on, or this is completely wrong
   684|         0|            0|            0|  0.00%|    guaranteed_to_sell = np.minimum(self.auction_params.licenses, self.aggregate_demand[-1])
   685|         0|            0|            0|  0.00%|    return guaranteed_to_sell @ self.posted_prices[-1]
   686|         0|            0|            0|  0.00%|
   687|         0|            0|            0|  0.00%|  @property
   688|         0|            0|            0|  0.00%|  def revenue_potential_normalized(self):
   689|         0|            0|            0|  0.00%|    return self.revenue_potential / self.auction_params.max_total_spend
   690|         0|            0|            0|  0.00%|
   691|         0|            0|            0|  0.00%|  @property
   692|         0|            0|            0|  0.00%|  def pricing_potential(self):
   693|         0|            0|            0|  0.00%|      if self.round == 1:
   694|         0|            0|            0|  0.00%|        return np.zeros(self.num_players())
   695|         0|            0|            0|  0.00%|
   696|         0|            0|            0|  0.00%|      # Define pricing as opponent payments - oppnonent cost of bundle at starting prices
   697|         0|            0|            0|  0.00%|      increased_cost = np.zeros(self.num_players())
   698|         0|            0|            0|  0.00%|      allocation = [bidder.processed_demand[-1] for bidder in self.bidders]
   699|         0|            0|            0|  0.00%|      for player_id, bidder in enumerate(self.bidders):
   700|         0|            0|            0|  0.00%|        increased_cost[player_id] = (self.posted_prices[-1] - self.auction_params.opening_prices) @ allocation[player_id]
   701|         0|            0|            0|  0.00%|      pricing = np.zeros_like(increased_cost)
   702|         0|            0|            0|  0.00%|      for player_id in range(self.num_players()):
   703|         0|            0|            0|  0.00%|        for other_player_id in players_not_me(player_id,  self.num_players()):
   704|         0|            0|            0|  0.00%|            pricing[player_id] += increased_cost[other_player_id]
   705|         0|            0|            0|  0.00%|      return pricing
   706|         0|            0|            0|  0.00%|
   707|         0|            0|            0|  0.00%|  @property
   708|         0|            0|            0|  0.00%|  def pricing_potential_normalized(self):
   709|         0|            0|            0|  0.00%|    return self.pricing_potential / self.auction_params.max_opponent_spends
   710|         0|            0|            0|  0.00%|
   711|         0|            0|            0|  0.00%|  @property
   712|         0|            0|            0|  0.00%|  def auction_length_potential(self):
   713|         0|            0|            0|  0.00%|    return self.round
   714|         0|            0|            0|  0.00%|
   715|         0|            0|            0|  0.00%|  @property
   716|         0|            0|            0|  0.00%|  def auction_length_potential_normalized(self):
   717|         0|            0|            0|  0.00%|    return self.round / self.auction_params.max_round
   718|         0|            0|            0|  0.00%|
   719|         0|            0|            0|  0.00%|  @property
   720|         0|            0|            0|  0.00%|  def welfare_potential(self):
   721|         0|            0|            0|  0.00%|    # Calculate on-demand welfare of current solution
   722|         0|            0|            0|  0.00%|    return self.get_welfare()
   723|         0|            0|            0|  0.00%|
   724|         0|            0|            0|  0.00%|  @property
   725|         0|            0|            0|  0.00%|  def welfare_potential_normalized(self):
   726|         0|            0|            0|  0.00%|    # TODO: This is a real bound but too expensive to compute. No reason we couldn't use something much looser.
   727|         0|            0|            0|  0.00%|    # For example, you could find the type of each player that values the full bundle the most and then sum over the best-types for each player
   728|         0|            0|            0|  0.00%|    return self.get_welfare() / self.efficent_allocation()[0]
   729|         0|            0|            0|  0.00%|
   730|         0|            0|            0|  0.00%|  def get_allocation(self):
   731|         0|            0|            0|  0.00%|    assert self._game_over
   732|         0|            0|            0|  0.00%|    return [bidder.processed_demand[-1] for bidder in self.bidders]
   733|         0|            0|            0|  0.00%|
   734|         0|            0|            0|  0.00%|  def get_welfare(self):
   735|         0|            0|            0|  0.00%|    welfare = 0
   736|         0|            0|            0|  0.00%|    allocation = [bidder.processed_demand[-1] for bidder in self.bidders]
   737|         0|            0|            0|  0.00%|    for bidder, package in zip(self.bidders, allocation):
   738|         0|            0|            0|  0.00%|      welfare += bidder.bidder.value_for_package(package)
   739|         0|            0|            0|  0.00%|    return float(welfare)
   740|         0|            0|            0|  0.00%|
   741|         0|            0|            0|  0.00%|  def get_welfare_sparse_normalized(self):
   742|         0|            0|            0|  0.00%|    if self._game_over:
   743|         0|            0|            0|  0.00%|      max_welfare, alloc = self.efficent_allocation()
   744|         0|            0|            0|  0.00%|      return self.get_welfare() / max_welfare
   745|         0|            0|            0|  0.00%|    else:
   746|         0|            0|            0|  0.00%|      return 0
   747|         0|            0|            0|  0.00%|
   748|         0|            0|            0|  0.00%|  def efficient_allocation(self):
   749|         0|            0|            0|  0.00%|    num_actions = len(self.auction_params.all_bids)
   750|         0|            0|            0|  0.00%|    num_players = self.num_players()
   751|         0|            0|            0|  0.00%|    n_vars = num_players * num_actions
   752|         0|            0|            0|  0.00%|    var_id_to_player_bundle = dict() # VarId -> (player, bundle)
   753|         0|            0|            0|  0.00%|
   754|         0|            0|            0|  0.00%|    values = []
   755|         0|            0|            0|  0.00%|    q = 0
   756|         0|            0|            0|  0.00%|    for player, bidder in enumerate(self.bidders):
   757|         0|            0|            0|  0.00%|        v = bidder.bidder.get_values()
   758|         0|            0|            0|  0.00%|        values += v
   759|         0|            0|            0|  0.00%|        for val, bundle in zip(v, self.auction_params.all_bids):
   760|         0|            0|            0|  0.00%|          var_id_to_player_bundle[q] = (player, bundle)
   761|         0|            0|            0|  0.00%|          q += 1
   762|         0|            0|            0|  0.00%|
   763|         0|            0|            0|  0.00%|    problem = LpProblem(f"EfficientAllocation", LpMaximize)
   764|         0|            0|            0|  0.00%|    bundle_variables = LpVariable.dicts("X", np.arange(n_vars), cat=LpBinary)
   765|         0|            0|            0|  0.00%|
   766|         0|            0|            0|  0.00%|    # OBJECTIVE
   767|         0|            0|            0|  0.00%|    problem += lpDot(values, bundle_variables.values())
   768|         0|            0|            0|  0.00%|
   769|         0|            0|            0|  0.00%|    # Constraint: Only 1 bundle per bidder
   770|         0|            0|            0|  0.00%|    for i in range(num_players):
   771|         0|            0|            0|  0.00%|        problem += lpSum(list(bundle_variables.values())[i * num_actions: (i+1) * num_actions]) == 1, f"1-per-bidder-{i}"
   772|         0|            0|            0|  0.00%|
   773|         0|            0|            0|  0.00%|    # Constraint: Can't overallocate any items
   774|         0|            0|            0|  0.00%|    supply = self.auction_params.licenses
   775|         0|            0|            0|  0.00%|    for i in range(self.auction_params.num_products):
   776|         0|            0|            0|  0.00%|        product_amounts = [bundle[i] for (player, bundle) in var_id_to_player_bundle.values()]
   777|         0|            0|            0|  0.00%|        problem += lpDot(bundle_variables.values(), product_amounts) <= supply[i], f"supply-{i}"
   778|         0|            0|            0|  0.00%|
   779|         0|            0|            0|  0.00%|    allocation = []
   780|         0|            0|            0|  0.00%|    try:
   781|         0|            0|            0|  0.00%|        problem.writeLP(f'efficient_allocation_{random_string(10)}.lp')
   782|         0|            0|            0|  0.00%|        obj = pulp_solve(problem, save_if_failed=True)
   783|         0|            0|            0|  0.00%|        for var_id in range(n_vars):
   784|         0|            0|            0|  0.00%|            # print(var_id, bundle_variables[var_id], value(bundle_variables[var_id]), var_id_to_player_bundle[var_id])
   785|         0|            0|            0|  0.00%|            if value(bundle_variables[var_id]) > .99: # Rounding stupidness
   786|         0|            0|            0|  0.00%|                allocation.append(var_id_to_player_bundle[var_id][1])
   787|         0|            0|            0|  0.00%|    except ValueError as e:
   788|         0|            0|            0|  0.00%|        # if MIP is infeasible, drop out - TODO: Should this ever happen?
   789|         0|            0|            0|  0.00%|        feasible_result = False
   790|         0|            0|            0|  0.00%|        logging.warning(f'Failed to solve MIP; dropping out')
   791|         0|            0|            0|  0.00%|
   792|         0|            0|            0|  0.00%|    return obj, allocation
   793|         0|            0|            0|  0.00%|
   794|         0|            0|            0|  0.00%|
   795|         0|            0|            0|  0.00%|class ClockAuctionObserver:
   796|         0|            0|            0|  0.00%|  """Observer, conforming to the PyObserver interface (see observation.py)."""
   797|         0|            0|            0|  0.00%|
   798|         0|            0|            0|  0.00%|  def __init__(self, iig_obs_type, params):
   799|         0|            0|            0|  0.00%|    auction_params = params.get('auction_params')
   800|         0|            0|            0|  0.00%|    self.normalize = params.get('normalize', True) # Raw features? Or normalized ones
   801|         0|            0|            0|  0.00%|    if not isinstance(auction_params, AuctionParams):
   802|         0|            0|            0|  0.00%|      raise ValueError("params must be an AuctionParams object")
   803|         0|            0|            0|  0.00%|    self.auction_params = auction_params
   804|         0|            0|            0|  0.00%|
   805|         0|            0|            0|  0.00%|    num_players = len(auction_params.player_types)
   806|         0|            0|            0|  0.00%|    num_products = auction_params.num_products
   807|         0|            0|            0|  0.00%|
   808|         0|            0|            0|  0.00%|    # self.round_buffer = 100 if iig_obs_type.perfect_recall else auction_params.agent_memory
   809|         0|            0|            0|  0.00%|    self.round_buffer = auction_params.agent_memory # TODO: We are abusing the API here a bit. Only offers binary perfect recall or not, but we want to interpolate.
   810|         0|            0|            0|  0.00%|    length = self.round_buffer * num_products
   811|         0|            0|            0|  0.00%|    shape = (self.round_buffer, num_products)
   812|         0|            0|            0|  0.00%|
   813|         0|            0|            0|  0.00%|    """Initializes an empty observation tensor."""
   814|         0|            0|            0|  0.00%|    # Determine which observation pieces we want to include.
   815|         0|            0|            0|  0.00%|    # NOTE: It should be possible to use the params to exclude some of these if we want a smaller input to the NN (or to have the NN reassamble the tensor from specific pieces).
   816|         0|            0|            0|  0.00%|
   817|         0|            0|            0|  0.00%|    pieces = [("player", num_players, (num_players,))]
   818|         0|            0|            0|  0.00%|    if iig_obs_type.private_info == pyspiel.PrivateInfoType.SINGLE_PLAYER:
   819|         0|            0|            0|  0.00%|      # 1-hot type encoding
   820|         0|            0|            0|  0.00%|      max_num_types = max([len(p) for p in auction_params.player_types.values()])
   821|         0|            0|            0|  0.00%|      pieces.append(("bidder_type", max_num_types, (max_num_types,)))
   822|         0|            0|            0|  0.00%|      pieces.append(("activity", 1, (1,)))
   823|         0|            0|            0|  0.00%|      pieces.append(("sor_exposure", 1, (1,)))
   824|         0|            0|            0|  0.00%|
   825|         0|            0|            0|  0.00%|      pieces.append(("submitted_demand_history", length, shape))
   826|         0|            0|            0|  0.00%|      pieces.append(("processed_demand_history", length, shape))
   827|         0|            0|            0|  0.00%|      num_bundles = len(auction_params.all_bids)
   828|         0|            0|            0|  0.00%|      pieces.append(("sor_profits", num_bundles, (num_bundles,)))
   829|         0|            0|            0|  0.00%|      pieces.append(("clock_profits", num_bundles, (num_bundles,)))
   830|         0|            0|            0|  0.00%|
   831|         0|            0|            0|  0.00%|    if iig_obs_type.public_info:
   832|         0|            0|            0|  0.00%|      # 1-hot round encoding
   833|         0|            0|            0|  0.00%|      pieces.append(("round", self.auction_params.max_round, (self.auction_params.max_round,))) # Always remember what round you are in, regardless of anything else
   834|         0|            0|            0|  0.00%|      pieces.append(("agg_demand_history", length, shape))
   835|         0|            0|            0|  0.00%|      pieces.append(("posted_price_history", self.round_buffer * num_products, (self.round_buffer, num_products)))
   836|         0|            0|            0|  0.00%|      pieces.append(("clock_prices", num_products, (num_products,)))
   837|         0|            0|            0|  0.00%|      pieces.append(("price_increments", num_products, (num_products,)))
   838|         0|            0|            0|  0.00%|
   839|         0|            0|            0|  0.00%|    # Build the single flat tensor.
   840|         0|            0|            0|  0.00%|    total_size = sum(size for name, size, shape in pieces)
   841|         0|            0|            0|  0.00%|    self.tensor = np.zeros(total_size, np.float32)
   842|         0|            0|            0|  0.00%|
   843|         0|            0|            0|  0.00%|    # Build the named & reshaped views of the bits of the flat tensor.
   844|         0|            0|            0|  0.00%|    self.dict = {}
   845|         0|            0|            0|  0.00%|    index = 0
   846|         0|            0|            0|  0.00%|    for name, size, shape in pieces:
   847|         0|            0|            0|  0.00%|      self.dict[name] = self.tensor[index:index + size].reshape(shape)
   848|         0|            0|            0|  0.00%|      index += size
   849|         0|            0|            0|  0.00%|
   850|    113306|     0.480692|  4.24242e-06|  0.46%|  def set_from(self, state, player):
   851|         0|            0|            0|  0.00%|    """Updates `tensor` and `dict` to reflect `state` from PoV of `player`."""
   852|         0|            0|            0|  0.00%|
   853|         0|            0|            0|  0.00%|    # BE VERY VERY CAREFUL NOT TO OVERRIDE THE DICT ENTRIES FROM POINTING INTO THE TENSOR
   854|         0|            0|            0|  0.00%|    # Very subtle e.g., self.dict["sor_profits"][:] = profits vs self.dict["sor_profits"] = profits
   855|    113306|     0.651799|  5.75256e-06|  0.62%|    self.tensor.fill(0)
   856|         0|            0|            0|  0.00%|
   857|    113306|     0.569597|  5.02707e-06|  0.55%|    length = min(state.round, self.round_buffer)
   858|    113306|     0.512405|  4.52231e-06|  0.49%|    start_ind = max(1, state.round - self.round_buffer)
   859|    113306|     0.459421|   4.0547e-06|  0.44%|    end_ind = start_ind + length
   860|         0|            0|            0|  0.00%|
   861|    113306|     0.440241|  3.88542e-06|  0.42%|    if "player" in self.dict:
   862|    113306|     0.499526|  4.40864e-06|  0.48%|      self.dict["player"][player] = 1
   863|    113306|     0.411513|  3.63187e-06|  0.39%|    if "round" in self.dict:
   864|    113306|     0.443715|  3.91608e-06|  0.43%|      self.dict["round"][state.round - 1] = 1
   865|         0|            0|            0|  0.00%|
   866|         0|            0|            0|  0.00%|    # These require the bidder to be initialized
   867|    113306|     0.432778|  3.81955e-06|  0.41%|    if len(state.bidders) > player:
   868|    113306|     0.405091|   3.5752e-06|  0.39%|      if "bidder_type" in self.dict:
   869|    113306|     0.461713|  4.07492e-06|  0.44%|        self.dict["bidder_type"][state.bidders[player].type_index] = 1
   870|    113306|     0.407991|  3.60079e-06|  0.39%|      if "activity" in self.dict:
   871|    113306|     0.418322|  3.69197e-06|  0.40%|        activity = state.bidders[player].activity
   872|    113306|     0.404259|  3.56786e-06|  0.39%|        if self.normalize:
   873|    113306|     0.465258|  4.10621e-06|  0.45%|          activity /= self.auction_params.max_activity
   874|    113306|     0.492174|  4.34376e-06|  0.47%|        self.dict["activity"][0] = activity
   875|    113306|     0.409235|  3.61177e-06|  0.39%|      if "sor_profits" in self.dict:
   876|    113306|     0.590526|  5.21178e-06|  0.57%|        price = np.array(state.sor_prices[-1])
   877|    113306|      1.12735|  9.94956e-06|  1.08%|        prices = self.auction_params.all_bids @ price
   878|    113306|      1.03774|  9.15876e-06|  0.99%|        profits = state.bidders[player].bidder.get_profits(prices)
(call)|    113306|      1.50593|  1.32908e-05|  1.44%|# /apps/open_spiel/open_spiel/python/games/clock_auction_bidders.py:25 get_profits
   879|    113306|     0.441912|  3.90017e-06|  0.42%|        if self.normalize:
   880|    113306|     0.917645|  8.09882e-06|  0.88%|          profits = profits / self.auction_params.max_budget
   881|    113306|     0.566051|  4.99578e-06|  0.54%|        self.dict["sor_profits"][:] = profits
   882|    113306|      0.38974|  3.43971e-06|  0.37%|      if "clock_profits" in self.dict:
   883|    113306|     0.494119|  4.36092e-06|  0.47%|        price = np.array(state.clock_prices[-1])
   884|    113306|     0.778177|  6.86792e-06|  0.75%|        prices = self.auction_params.all_bids @ price
   885|    113306|     0.944427|  8.33519e-06|  0.90%|        profits = state.bidders[player].bidder.get_profits(prices)
(call)|    113306|      1.32838|  1.17239e-05|  1.27%|# /apps/open_spiel/open_spiel/python/games/clock_auction_bidders.py:25 get_profits
   886|    113306|     0.375811|  3.31678e-06|  0.36%|        if self.normalize:
   887|    113306|     0.702608|  6.20098e-06|  0.67%|          profits = profits / self.auction_params.max_budget
   888|    113306|     0.498827|  4.40248e-06|  0.48%|        self.dict["clock_profits"][:] = profits
   889|         0|            0|            0|  0.00%|
   890|    113306|      0.37007|  3.26611e-06|  0.35%|    if state.round > 1:
   891|     99688|     0.323882|  3.24895e-06|  0.31%|      if "agg_demand_history" in self.dict:
   892|     99688|     0.843197|  8.45836e-06|  0.81%|        agg_demand_history = np.array(state.aggregate_demand)[start_ind:end_ind]
   893|     99688|     0.352674|  3.53778e-06|  0.34%|        if self.normalize:
   894|     99688|     0.769079|  7.71486e-06|  0.74%|          agg_demand_history = agg_demand_history / self.auction_params.licenses
   895|     99688|     0.556408|  5.58149e-06|  0.53%|        self.dict["agg_demand_history"][:min(length, len(agg_demand_history))] = agg_demand_history
   896|     99688|     0.335421|  3.36471e-06|  0.32%|      if "submitted_demand_history" in self.dict:
   897|     99688|     0.744542|  7.46873e-06|  0.71%|        submitted_demand_history = np.array(state.bidders[player].submitted_demand)[start_ind:end_ind]
   898|     99688|     0.320308|   3.2131e-06|  0.31%|        if self.normalize:
   899|     99688|     0.608057|  6.09961e-06|  0.58%|          submitted_demand_history = submitted_demand_history / self.auction_params.licenses
   900|     99688|     0.487627|  4.89153e-06|  0.47%|        self.dict["submitted_demand_history"][:min(length, len(submitted_demand_history))] = submitted_demand_history
   901|     99688|     0.321822|   3.2283e-06|  0.31%|      if "processed_demand_history" in self.dict:
   902|     99688|      0.66887|  6.70963e-06|  0.64%|        processed_demand_history = np.array(state.bidders[player].processed_demand)[start_ind:end_ind]
   903|     99688|     0.308125|  3.09089e-06|  0.30%|        if self.normalize:
   904|     99688|      0.55592|   5.5766e-06|  0.53%|          processed_demand_history = processed_demand_history / self.auction_params.licenses
   905|     99688|     0.469867|  4.71338e-06|  0.45%|        self.dict["processed_demand_history"][:min(length, len(processed_demand_history))] = processed_demand_history
   906|     99688|     0.311322|  3.12297e-06|  0.30%|      if "sor_exposure" in self.dict:
   907|     99688|     0.731359|  7.33648e-06|  0.70%|        sor_exposure = state.bidders[player].processed_demand[-1] @ state.sor_prices[-1]
   908|     99688|     0.314524|  3.15509e-06|  0.30%|        if self.normalize:
   909|     99688|     0.409477|  4.10758e-06|  0.39%|          sor_exposure = sor_exposure / self.auction_params.max_budget # TODO: Why not use a player specific bound here?
   910|     99688|     0.350538|  3.51636e-06|  0.34%|        self.dict["sor_exposure"][0] = sor_exposure
   911|         0|            0|            0|  0.00%|
   912|    113306|     0.332498|  2.93451e-06|  0.32%|    if "posted_price_history" in self.dict:
   913|    113306|     0.758988|  6.69857e-06|  0.73%|      posted_prices = np.array(state.posted_prices)[start_ind:end_ind]
   914|    113306|     0.339901|  2.99985e-06|  0.33%|      if self.normalize:
   915|    113306|     0.736046|  6.49609e-06|  0.71%|        posted_prices = posted_prices / self.auction_params.max_budget
   916|    113306|      0.54608|  4.81951e-06|  0.52%|      self.dict["posted_price_history"][:min(length, len(posted_prices))] = posted_prices
   917|         0|            0|            0|  0.00%|
   918|    113306|     0.343958|  3.03566e-06|  0.33%|    if "clock_prices" in self.dict:
   919|    113306|      0.41086|  3.62611e-06|  0.39%|      clock_prices = np.array(state.clock_prices[-1])
   920|    113306|      0.32043|    2.828e-06|  0.31%|      if self.normalize:
   921|    113306|     0.611639|  5.39811e-06|  0.59%|        clock_prices = clock_prices / self.auction_params.max_budget
   922|    113306|     0.437147|  3.85811e-06|  0.42%|      self.dict['clock_prices'][:] = clock_prices
   923|         0|            0|            0|  0.00%|
   924|    113306|       0.3156|  2.78538e-06|  0.30%|    if "price_increments" in self.dict:
   925|    113306|     0.376586|  3.32362e-06|  0.36%|      price_increments = np.array(state.price_increments)
   926|    113306|      0.29703|  2.62149e-06|  0.28%|      if self.normalize:
   927|    113306|     0.691339|  6.10152e-06|  0.66%|        price_increments = price_increments / self.auction_params.max_round
   928|    113306|     0.402627|  3.55345e-06|  0.39%|      self.dict['price_increments'][:] = price_increments
   929|         0|            0|            0|  0.00%|
   930|    113306|      1.28369|  1.13294e-05|  1.23%|    if np.isnan(self.tensor).any():
(call)|    113306|      1.21898|  1.07583e-05|  1.17%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/_methods.py:54 _any
   931|         0|            0|            0|  0.00%|      raise ValueError(f"NaN in observation {self.dict}")
   932|         0|            0|            0|  0.00%|
   933|         0|            0|            0|  0.00%|  def string_from(self, state, player):
   934|         0|            0|            0|  0.00%|    """Observation of `state` from the PoV of `player`, as a string."""
   935|         0|            0|            0|  0.00%|    pieces = []
   936|         0|            0|            0|  0.00%|    if "player" in self.dict:
   937|         0|            0|            0|  0.00%|      pieces.append(f"p{player}")
   938|         0|            0|            0|  0.00%|    if "bidder_type" in self.dict:
   939|         0|            0|            0|  0.00%|      pieces.append(f"t{state.bidders[player].type_index}")
   940|         0|            0|            0|  0.00%|    if "activity" in self.dict:
   941|         0|            0|            0|  0.00%|      pieces.append(f"a{state.bidders[player].activity}")
   942|         0|            0|            0|  0.00%|    if "round" in self.dict:
   943|         0|            0|            0|  0.00%|      pieces.append(f"r{state.round}")
   944|         0|            0|            0|  0.00%|    if "agg_demand_history" in self.dict:
   945|         0|            0|            0|  0.00%|      pieces.append(f"agg{state.aggregate_demand}")
   946|         0|            0|            0|  0.00%|    if "submitted_demand_history" in self.dict:
   947|         0|            0|            0|  0.00%|      pieces.append(f"sub{state.bidders[player].submitted_demand}")
   948|         0|            0|            0|  0.00%|    if "processed_demand_history" in self.dict:
   949|         0|            0|            0|  0.00%|      pieces.append(f"proc{state.bidders[player].processed_demand}")
   950|         0|            0|            0|  0.00%|    if "posted_price_history" in self.dict:
   951|         0|            0|            0|  0.00%|      pieces.append(f"posted{state.posted_prices}")
   952|         0|            0|            0|  0.00%|    if "clock_prices" in self.dict:
   953|         0|            0|            0|  0.00%|      pieces.append(f"clock{state.clock_prices[-1]}")
   954|         0|            0|            0|  0.00%|    if "sor_exposure" in self.dict and state.round > 1:
   955|         0|            0|            0|  0.00%|      pieces.append(f"sor_exposure{state.bidders[player].processed_demand[-1] @ state.sor_prices[-1]}")
   956|         0|            0|            0|  0.00%|    if "price_increments" in self.dict and state.round > 1:
   957|         0|            0|            0|  0.00%|      pieces.append(f"increments{state.price_increments}")
   958|         0|            0|            0|  0.00%|
   959|         0|            0|            0|  0.00%|    return " ".join(str(p) for p in pieces)
   960|         0|            0|            0|  0.00%|
   961|         0|            0|            0|  0.00%|# Register the game with the OpenSpiel library
   962|         0|            0|            0|  0.00%|pyspiel.register_game(_GAME_TYPE, ClockAuctionGame)
File: /apps/open_spiel/open_spiel/python/rl_environment.py
File duration: 21.9336s (21.01%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|# Copyright 2019 DeepMind Technologies Limited
     2|         0|            0|            0|  0.00%|#
     3|         0|            0|            0|  0.00%|# Licensed under the Apache License, Version 2.0 (the "License");
     4|         0|            0|            0|  0.00%|# you may not use this file except in compliance with the License.
     5|         0|            0|            0|  0.00%|# You may obtain a copy of the License at
     6|         0|            0|            0|  0.00%|#
     7|         0|            0|            0|  0.00%|#      http://www.apache.org/licenses/LICENSE-2.0
     8|         0|            0|            0|  0.00%|#
     9|         0|            0|            0|  0.00%|# Unless required by applicable law or agreed to in writing, software
    10|         0|            0|            0|  0.00%|# distributed under the License is distributed on an "AS IS" BASIS,
    11|         0|            0|            0|  0.00%|# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    12|         0|            0|            0|  0.00%|# See the License for the specific language governing permissions and
    13|         0|            0|            0|  0.00%|# limitations under the License.
    14|         0|            0|            0|  0.00%|
    15|         0|            0|            0|  0.00%|"""Reinforcement Learning (RL) Environment for Open Spiel.
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|This module wraps Open Spiel Python interface providing an RL-friendly API. It
    18|         0|            0|            0|  0.00%|covers both turn-based and simultaneous move games. Interactions between agents
    19|         0|            0|            0|  0.00%|and the underlying game occur mostly through the `reset` and `step` methods,
    20|         0|            0|            0|  0.00%|which return a `TimeStep` structure (see its docstrings for more info).
    21|         0|            0|            0|  0.00%|
    22|         0|            0|            0|  0.00%|The following example illustrates the interaction dynamics. Consider a 2-player
    23|         0|            0|            0|  0.00%|Kuhn Poker (turn-based game). Agents have access to the `observations` (a dict)
    24|         0|            0|            0|  0.00%|field from `TimeSpec`, containing the following members:
    25|         0|            0|            0|  0.00%| * `info_state`: list containing the game information state for each player. The
    26|         0|            0|            0|  0.00%|   size of the list always correspond to the number of players. E.g.:
    27|         0|            0|            0|  0.00%|   [[0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]].
    28|         0|            0|            0|  0.00%| * `legal_actions`: list containing legal action ID lists (one for each player).
    29|         0|            0|            0|  0.00%|   E.g.: [[0, 1], [0]], which corresponds to actions 0 and 1 being valid for
    30|         0|            0|            0|  0.00%|   player 0 (the 1st player) and action 0 being valid for player 1 (2nd player).
    31|         0|            0|            0|  0.00%| * `current_player`: zero-based integer representing the player to make a move.
    32|         0|            0|            0|  0.00%|
    33|         0|            0|            0|  0.00%|At each `step` call, the environment expects a singleton list with the action
    34|         0|            0|            0|  0.00%|(as it's a turn-based game), e.g.: [1]. This (zero-based) action must correspond
    35|         0|            0|            0|  0.00%|to the player specified at `current_player`. The game (which is at decision
    36|         0|            0|            0|  0.00%|node) will process the action and take as many steps necessary to cover chance
    37|         0|            0|            0|  0.00%|nodes, halting at a new decision or final node. Finally, a new `TimeStep`is
    38|         0|            0|            0|  0.00%|returned to the agent.
    39|         0|            0|            0|  0.00%|
    40|         0|            0|            0|  0.00%|Simultaneous-move games follow analogous dynamics. The only differences is the
    41|         0|            0|            0|  0.00%|environment expects a list of actions, one per player. Note the `current_player`
    42|         0|            0|            0|  0.00%|field is "irrelevant" here, admitting a constant value defined in spiel.h, which
    43|         0|            0|            0|  0.00%|defaults to -2 (module level constant `SIMULTANEOUS_PLAYER_ID`).
    44|         0|            0|            0|  0.00%|
    45|         0|            0|            0|  0.00%|See open_spiel/python/examples/rl_example.py for example usages.
    46|         0|            0|            0|  0.00%|"""
    47|         0|            0|            0|  0.00%|
    48|         0|            0|            0|  0.00%|import collections
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|import enum
    51|         0|            0|            0|  0.00%|from absl import logging
    52|         0|            0|            0|  0.00%|import numpy as np
    53|         0|            0|            0|  0.00%|from open_spiel.python.observation import make_observation
    54|         0|            0|            0|  0.00%|from copy import deepcopy
    55|         0|            0|            0|  0.00%|
    56|         0|            0|            0|  0.00%|import pyspiel
    57|         0|            0|            0|  0.00%|
    58|         0|            0|            0|  0.00%|SIMULTANEOUS_PLAYER_ID = pyspiel.PlayerId.SIMULTANEOUS
    59|         0|            0|            0|  0.00%|
    60|    113306|     0.235485|  2.07831e-06|  0.23%|def fastcopy(d):
    61|         0|            0|            0|  0.00%|  """assumes d is a dict of np arrays"""
    62|   1812896|      4.75398|  2.62231e-06|  4.55%|  return {k: v.copy() for k, v in d.items()}
(call)|    113306|      3.93374|  3.47179e-05|  3.77%|# /apps/open_spiel/open_spiel/python/rl_environment.py:62 <dictcomp>
    63|         0|            0|            0|  0.00%|
    64|         0|            0|            0|  0.00%|
    65|         0|            0|            0|  0.00%|class TimeStep(
    66|         0|            0|            0|  0.00%|    collections.namedtuple(
    67|         0|            0|            0|  0.00%|        "TimeStep", ["observations", "rewards", "discounts", "step_type"])):
    68|         0|            0|            0|  0.00%|  """Returned with every call to `step` and `reset`.
    69|         0|            0|            0|  0.00%|
    70|         0|            0|            0|  0.00%|  A `TimeStep` contains the data emitted by a game at each step of interaction.
    71|         0|            0|            0|  0.00%|  A `TimeStep` holds an `observation` (list of dicts, one per player),
    72|         0|            0|            0|  0.00%|  associated lists of `rewards`, `discounts` and a `step_type`.
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|  The first `TimeStep` in a sequence will have `StepType.FIRST`. The final
    75|         0|            0|            0|  0.00%|  `TimeStep` will have `StepType.LAST`. All other `TimeStep`s in a sequence will
    76|         0|            0|            0|  0.00%|  have `StepType.MID.
    77|         0|            0|            0|  0.00%|
    78|         0|            0|            0|  0.00%|  Attributes:
    79|         0|            0|            0|  0.00%|    observations: a list of dicts containing observations per player.
    80|         0|            0|            0|  0.00%|    rewards: A list of scalars (one per player), or `None` if `step_type` is
    81|         0|            0|            0|  0.00%|      `StepType.FIRST`, i.e. at the start of a sequence.
    82|         0|            0|            0|  0.00%|    discounts: A list of discount values in the range `[0, 1]` (one per player),
    83|         0|            0|            0|  0.00%|      or `None` if `step_type` is `StepType.FIRST`.
    84|         0|            0|            0|  0.00%|    step_type: A `StepType` enum value.
    85|         0|            0|            0|  0.00%|  """
    86|         0|            0|            0|  0.00%|  __slots__ = ()
    87|         0|            0|            0|  0.00%|
    88|         0|            0|            0|  0.00%|  def first(self):
    89|         0|            0|            0|  0.00%|    return self.step_type == StepType.FIRST
    90|         0|            0|            0|  0.00%|
    91|         0|            0|            0|  0.00%|  def mid(self):
    92|         0|            0|            0|  0.00%|    return self.step_type == StepType.MID
    93|         0|            0|            0|  0.00%|
    94|     18432|     0.021939|  1.19027e-06|  0.02%|  def last(self):
    95|     18432|    0.0356388|  1.93353e-06|  0.03%|    return self.step_type == StepType.LAST
    96|         0|            0|            0|  0.00%|
    97|         0|            0|            0|  0.00%|  def is_simultaneous_move(self):
    98|         0|            0|            0|  0.00%|    return self.observations["current_player"] == SIMULTANEOUS_PLAYER_ID
    99|         0|            0|            0|  0.00%|
   100|         0|            0|            0|  0.00%|  def current_player(self):
   101|         0|            0|            0|  0.00%|    return self.observations["current_player"]
   102|         0|            0|            0|  0.00%|
   103|         0|            0|            0|  0.00%|
   104|         0|            0|            0|  0.00%|class StepType(enum.Enum):
   105|         0|            0|            0|  0.00%|  """Defines the status of a `TimeStep` within a sequence."""
   106|         0|            0|            0|  0.00%|
   107|         0|            0|            0|  0.00%|  FIRST = 0  # Denotes the first `TimeStep` in a sequence.
   108|         0|            0|            0|  0.00%|  MID = 1  # Denotes any `TimeStep` in a sequence that is not FIRST or LAST.
   109|         0|            0|            0|  0.00%|  LAST = 2  # Denotes the last `TimeStep` in a sequence.
   110|         0|            0|            0|  0.00%|
   111|         0|            0|            0|  0.00%|  def first(self):
   112|         0|            0|            0|  0.00%|    return self is StepType.FIRST
   113|         0|            0|            0|  0.00%|
   114|         0|            0|            0|  0.00%|  def mid(self):
   115|         0|            0|            0|  0.00%|    return self is StepType.MID
   116|         0|            0|            0|  0.00%|
   117|         0|            0|            0|  0.00%|  def last(self):
   118|         0|            0|            0|  0.00%|    return self is StepType.LAST
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|
   121|         0|            0|            0|  0.00%|# Global pyspiel members
   122|         0|            0|            0|  0.00%|def registered_games():
   123|         0|            0|            0|  0.00%|  return pyspiel.registered_games()
   124|         0|            0|            0|  0.00%|
   125|         0|            0|            0|  0.00%|
   126|         0|            0|            0|  0.00%|class ChanceEventSampler(object):
   127|         0|            0|            0|  0.00%|  """Default sampler for external chance events."""
   128|         0|            0|            0|  0.00%|
   129|         0|            0|            0|  0.00%|  def __init__(self, seed=None):
   130|         0|            0|            0|  0.00%|    self.seed(seed)
   131|         0|            0|            0|  0.00%|
   132|         0|            0|            0|  0.00%|  def seed(self, seed=None):
   133|         0|            0|            0|  0.00%|    self._rng = np.random.RandomState(seed)
   134|         0|            0|            0|  0.00%|
   135|         0|            0|            0|  0.00%|  def __call__(self, state):
   136|         0|            0|            0|  0.00%|    """Sample a chance event in the given state."""
   137|         0|            0|            0|  0.00%|    actions, probs = zip(*state.chance_outcomes())
   138|         0|            0|            0|  0.00%|    return self._rng.choice(actions, p=probs)
   139|         0|            0|            0|  0.00%|
   140|         0|            0|            0|  0.00%|
   141|         0|            0|            0|  0.00%|class ObservationType(enum.Enum):
   142|         0|            0|            0|  0.00%|  """Defines what kind of observation to use."""
   143|         0|            0|            0|  0.00%|  OBSERVATION = 0  # Use observation_tensor
   144|         0|            0|            0|  0.00%|  INFORMATION_STATE = 1  # Use information_state_tensor
   145|         0|            0|            0|  0.00%|
   146|         0|            0|            0|  0.00%|
   147|         0|            0|            0|  0.00%|class Environment(object):
   148|         0|            0|            0|  0.00%|  """Open Spiel reinforcement learning environment class."""
   149|         0|            0|            0|  0.00%|
   150|         0|            0|            0|  0.00%|  def __init__(self,
   151|         0|            0|            0|  0.00%|               game,
   152|         0|            0|            0|  0.00%|               discount=1.0,
   153|         0|            0|            0|  0.00%|               chance_event_sampler=None,
   154|         0|            0|            0|  0.00%|               history_prefix=None,
   155|         0|            0|            0|  0.00%|               observation_type=None,
   156|         0|            0|            0|  0.00%|               include_full_state=False,
   157|         0|            0|            0|  0.00%|               mfg_distribution=None,
   158|         0|            0|            0|  0.00%|               mfg_population=None,
   159|         0|            0|            0|  0.00%|               enable_legality_check=False,
   160|         0|            0|            0|  0.00%|               use_observer_api=False,
   161|         0|            0|            0|  0.00%|               observer_params=None,
   162|         0|            0|            0|  0.00%|               **kwargs):
   163|         0|            0|            0|  0.00%|    """Constructor.
   164|         0|            0|            0|  0.00%|
   165|         0|            0|            0|  0.00%|    Args:
   166|         0|            0|            0|  0.00%|      game: [string, pyspiel.Game] Open Spiel game name or game instance.
   167|         0|            0|            0|  0.00%|      discount: float, discount used in non-initial steps. Defaults to 1.0.
   168|         0|            0|            0|  0.00%|      chance_event_sampler: optional object with `sample_external_events` method
   169|         0|            0|            0|  0.00%|        to sample chance events.
   170|         0|            0|            0|  0.00%|      observation_type: what kind of observation to use. If not specified, will
   171|         0|            0|            0|  0.00%|        default to INFORMATION_STATE unless the game doesn't provide it.
   172|         0|            0|            0|  0.00%|      include_full_state: whether or not to include the full serialized
   173|         0|            0|            0|  0.00%|        OpenSpiel state in the observations (sometimes useful for debugging).
   174|         0|            0|            0|  0.00%|      mfg_distribution: the distribution over states if the game is a mean field
   175|         0|            0|            0|  0.00%|        game.
   176|         0|            0|            0|  0.00%|      mfg_population: The Mean Field Game population to consider.
   177|         0|            0|            0|  0.00%|      enable_legality_check: Check the legality of the move before stepping.
   178|         0|            0|            0|  0.00%|      **kwargs: dict, additional settings passed to the Open Spiel game.
   179|         0|            0|            0|  0.00%|    """
   180|         0|            0|            0|  0.00%|    self._chance_event_sampler = chance_event_sampler or ChanceEventSampler()
   181|         0|            0|            0|  0.00%|    if history_prefix is None:
   182|         0|            0|            0|  0.00%|      history_prefix = []
   183|         0|            0|            0|  0.00%|    self._history_prefix = history_prefix
   184|         0|            0|            0|  0.00%|    self._include_full_state = include_full_state
   185|         0|            0|            0|  0.00%|    self._mfg_distribution = mfg_distribution
   186|         0|            0|            0|  0.00%|    self._mfg_population = mfg_population
   187|         0|            0|            0|  0.00%|    self._enable_legality_check = enable_legality_check
   188|         0|            0|            0|  0.00%|
   189|         0|            0|            0|  0.00%|    if isinstance(game, str):
   190|         0|            0|            0|  0.00%|      if kwargs:
   191|         0|            0|            0|  0.00%|        game_settings = {key: val for (key, val) in kwargs.items()}
   192|         0|            0|            0|  0.00%|        logging.info("Using game settings: %s", game_settings)
   193|         0|            0|            0|  0.00%|        self._game = pyspiel.load_game(game, game_settings)
   194|         0|            0|            0|  0.00%|      else:
   195|         0|            0|            0|  0.00%|        logging.info("Using game string: %s", game)
   196|         0|            0|            0|  0.00%|        self._game = pyspiel.load_game(game)
   197|         0|            0|            0|  0.00%|    else:  # pyspiel.Game or API-compatible object.
   198|         0|            0|            0|  0.00%|      logging.info("Using game instance: %s", game.get_type().short_name)
   199|         0|            0|            0|  0.00%|      self._game = game
   200|         0|            0|            0|  0.00%|
   201|         0|            0|            0|  0.00%|    self._num_players = self._game.num_players()
   202|         0|            0|            0|  0.00%|    self._state = None
   203|         0|            0|            0|  0.00%|    self._should_reset = True
   204|         0|            0|            0|  0.00%|
   205|         0|            0|            0|  0.00%|    # Discount returned at non-initial steps.
   206|         0|            0|            0|  0.00%|    self._discounts = [discount] * self._num_players
   207|         0|            0|            0|  0.00%|
   208|         0|            0|            0|  0.00%|    # Determine what observation type to use.
   209|         0|            0|            0|  0.00%|    if observation_type is None:
   210|         0|            0|            0|  0.00%|      if self._game.get_type().provides_information_state_tensor:
   211|         0|            0|            0|  0.00%|        observation_type = ObservationType.INFORMATION_STATE
   212|         0|            0|            0|  0.00%|      else:
   213|         0|            0|            0|  0.00%|        observation_type = ObservationType.OBSERVATION
   214|         0|            0|            0|  0.00%|
   215|         0|            0|            0|  0.00%|    # Check the requested observation type is supported.
   216|         0|            0|            0|  0.00%|    if observation_type == ObservationType.OBSERVATION:
   217|         0|            0|            0|  0.00%|      if not self._game.get_type().provides_observation_tensor:
   218|         0|            0|            0|  0.00%|        raise ValueError(f"observation_tensor not supported by {game}")
   219|         0|            0|            0|  0.00%|    elif observation_type == ObservationType.INFORMATION_STATE:
   220|         0|            0|            0|  0.00%|      if not self._game.get_type().provides_information_state_tensor:
   221|         0|            0|            0|  0.00%|        raise ValueError(f"information_state_tensor not supported by {game}")
   222|         0|            0|            0|  0.00%|    self._use_observation = (observation_type == ObservationType.OBSERVATION)
   223|         0|            0|            0|  0.00%|
   224|         0|            0|            0|  0.00%|    if self._game.get_type().dynamics == pyspiel.GameType.Dynamics.MEAN_FIELD:
   225|         0|            0|            0|  0.00%|      assert mfg_distribution is not None
   226|         0|            0|            0|  0.00%|      assert mfg_population is not None
   227|         0|            0|            0|  0.00%|      assert 0 <= mfg_population < self._num_players
   228|         0|            0|            0|  0.00%|
   229|         0|            0|            0|  0.00%|    # MODIFIED
   230|         0|            0|            0|  0.00%|    self.observer = None
   231|         0|            0|            0|  0.00%|    if use_observer_api:
   232|         0|            0|            0|  0.00%|      self.observer = make_observation(self._game, params=observer_params)
   233|         0|            0|            0|  0.00%|
   234|         0|            0|            0|  0.00%|  def seed(self, seed=None):
   235|         0|            0|            0|  0.00%|    self._chance_event_sampler.seed(self._game)
   236|         0|            0|            0|  0.00%|
   237|     55304|      0.16784|  3.03485e-06|  0.16%|  def get_time_step(self):
   238|         0|            0|            0|  0.00%|    """Returns a `TimeStep` without updating the environment.
   239|         0|            0|            0|  0.00%|
   240|         0|            0|            0|  0.00%|    Returns:
   241|         0|            0|            0|  0.00%|      A `TimeStep` namedtuple containing:
   242|         0|            0|            0|  0.00%|        observation: list of dicts containing one observations per player, each
   243|         0|            0|            0|  0.00%|          corresponding to `observation_spec()`.
   244|         0|            0|            0|  0.00%|        reward: list of rewards at this timestep, or None if step_type is
   245|         0|            0|            0|  0.00%|          `StepType.FIRST`.
   246|         0|            0|            0|  0.00%|        discount: list of discounts in the range [0, 1], or None if step_type is
   247|         0|            0|            0|  0.00%|          `StepType.FIRST`.
   248|         0|            0|            0|  0.00%|        step_type: A `StepType` value.
   249|         0|            0|            0|  0.00%|    """
   250|     55304|     0.176487|  3.19122e-06|  0.17%|    observations = {
   251|     55304|     0.168046|  3.03859e-06|  0.16%|        "info_state": [],
   252|     55304|     0.159644|  2.88666e-06|  0.15%|        "legal_actions": [],
   253|     55304|     0.153152|  2.76927e-06|  0.15%|        "current_player": [],
   254|     55304|     0.156918|  2.83737e-06|  0.15%|        "serialized_state": [],
   255|         0|            0|            0|  0.00%|    }
   256|     55304|     0.165931|  3.00035e-06|  0.16%|    if self.observer is not None:
   257|     55304|     0.162097|  2.93101e-06|  0.16%|      observations['info_dict'] = []
   258|     55304|     0.158423|  2.86458e-06|  0.15%|    rewards = []
   259|     55304|       0.4542|  8.21279e-06|  0.44%|    step_type = StepType.LAST if self._state.is_terminal() else StepType.MID
(call)|     55304|     0.193906|  3.50618e-06|  0.19%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:461 is_terminal
   260|     55304|     0.191955|  3.47091e-06|  0.18%|    self._should_reset = step_type == StepType.LAST
   261|         0|            0|            0|  0.00%|
   262|     55304|      1.09986|  1.98875e-05|  1.05%|    cur_rewards = self._state.rewards()
(call)|     55304|     0.192806|  3.48629e-06|  0.18%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:461 is_terminal
(call)|     52622|      0.35018|  6.65464e-06|  0.34%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:306 current_player
(call)|      2682|      0.74525|  0.000277871|  0.71%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:465 returns
   263|    165912|     0.799058|  4.81616e-06|  0.77%|    for player_id in range(self.num_players):
(call)|     55304|     0.385669|  6.97361e-06|  0.37%|# /apps/open_spiel/open_spiel/python/rl_environment.py:463 num_players
   264|    110608|      0.30613|   2.7677e-06|  0.29%|      rewards.append(cur_rewards[player_id])
   265|    110608|     0.284828|  2.57512e-06|  0.27%|      if self.observer is None:
   266|         0|            0|            0|  0.00%|        info_state = self._state.observation_tensor(player_id) if self._use_observation else self._state.information_state_tensor(player_id)
   267|         0|            0|            0|  0.00%|      else:
   268|    110608|      1.26848|  1.14683e-05|  1.22%|        self.observer.set_from(self._state, player=player_id)
(call)|    110608|      38.9103|  0.000351785| 37.28%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:850 set_from
   269|    110608|     0.453152|  4.09692e-06|  0.43%|        info_state = np.array(self.observer.tensor)
   270|    110608|     0.888658|   8.0343e-06|  0.85%|        observations['info_dict'].append(fastcopy(self.observer.dict))
(call)|    110608|      4.86879|  4.40185e-05|  4.66%|# /apps/open_spiel/open_spiel/python/rl_environment.py:60 fastcopy
   271|         0|            0|            0|  0.00%|
   272|    110608|     0.310329|  2.80567e-06|  0.30%|      observations["info_state"].append(info_state)
   273|    110608|      3.78145|  3.41878e-05|  3.62%|      observations["legal_actions"].append(self._state.legal_actions(player_id))
(call)|    110608|     0.433462|   3.9189e-06|  0.42%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:461 is_terminal
(call)|    263110|      1.74455|  6.63051e-06|  1.67%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:306 current_player
(call)|     52622|      11.5736|  0.000219939| 11.09%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:319 _legal_actions
   274|     55304|     0.407606|  7.37028e-06|  0.39%|    observations["current_player"] = self._state.current_player()
(call)|     55304|     0.368354|  6.66053e-06|  0.35%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:306 current_player
   275|     55304|     0.145851|  2.63727e-06|  0.14%|    discounts = self._discounts
   276|     55304|     0.177608|  3.21148e-06|  0.17%|    if step_type == StepType.LAST:
   277|         0|            0|            0|  0.00%|      # When the game is in a terminal state set the discount to 0.
   278|     13410|    0.0398951|  2.97502e-06|  0.04%|      discounts = [0. for _ in discounts]
(call)|      2682|    0.0203643|  7.59295e-06|  0.02%|# /apps/open_spiel/open_spiel/python/rl_environment.py:278 <listcomp>
   279|         0|            0|            0|  0.00%|
   280|     55304|     0.133586|  2.41548e-06|  0.13%|    if self._include_full_state:
   281|         0|            0|            0|  0.00%|      observations["serialized_state"] = pyspiel.serialize_game_and_state(
   282|         0|            0|            0|  0.00%|          self._game, self._state)
   283|         0|            0|            0|  0.00%|
   284|    110608|     0.601687|  5.43982e-06|  0.58%|    return TimeStep(
(call)|     55304|      0.29046|  5.25206e-06|  0.28%|# <string>:1 __new__
   285|     55304|     0.119844|    2.167e-06|  0.11%|        observations=observations,
   286|     55304|        0.119|  2.15175e-06|  0.11%|        rewards=rewards,
   287|     55304|     0.118093|  2.13534e-06|  0.11%|        discounts=discounts,
   288|     55304|     0.115803|  2.09394e-06|  0.11%|        step_type=step_type)
   289|         0|            0|            0|  0.00%|
   290|         0|            0|            0|  0.00%|  def _check_legality(self, actions):
   291|         0|            0|            0|  0.00%|    if self.is_turn_based:
   292|         0|            0|            0|  0.00%|      legal_actions = self._state.legal_actions()
   293|         0|            0|            0|  0.00%|      if actions[0] not in legal_actions:
   294|         0|            0|            0|  0.00%|        raise RuntimeError(f"step() called on illegal action {actions[0]}")
   295|         0|            0|            0|  0.00%|    else:
   296|         0|            0|            0|  0.00%|      for p in range(len(actions)):
   297|         0|            0|            0|  0.00%|        legal_actions = self._state.legal_actions(p)
   298|         0|            0|            0|  0.00%|        if legal_actions and actions[p] not in legal_actions:
   299|         0|            0|            0|  0.00%|          raise RuntimeError(f"step() by player {p} called on illegal " +
   300|         0|            0|            0|  0.00%|                             f"action: {actions[p]}")
   301|         0|            0|            0|  0.00%|
   302|     18432|    0.0341599|  1.85329e-06|  0.03%|  def step(self, actions):
   303|         0|            0|            0|  0.00%|    """Updates the environment according to `actions` and returns a `TimeStep`.
   304|         0|            0|            0|  0.00%|
   305|         0|            0|            0|  0.00%|    If the environment returned a `TimeStep` with `StepType.LAST` at the
   306|         0|            0|            0|  0.00%|    previous step, this call to `step` will start a new sequence and `actions`
   307|         0|            0|            0|  0.00%|    will be ignored.
   308|         0|            0|            0|  0.00%|
   309|         0|            0|            0|  0.00%|    This method will also start a new sequence if called after the environment
   310|         0|            0|            0|  0.00%|    has been constructed and `reset` has not been called. Again, in this case
   311|         0|            0|            0|  0.00%|    `actions` will be ignored.
   312|         0|            0|            0|  0.00%|
   313|         0|            0|            0|  0.00%|    Args:
   314|         0|            0|            0|  0.00%|      actions: a list containing one action per player, following specifications
   315|         0|            0|            0|  0.00%|        defined in `action_spec()`.
   316|         0|            0|            0|  0.00%|
   317|         0|            0|            0|  0.00%|    Returns:
   318|         0|            0|            0|  0.00%|      A `TimeStep` namedtuple containing:
   319|         0|            0|            0|  0.00%|        observation: list of dicts containing one observations per player, each
   320|         0|            0|            0|  0.00%|          corresponding to `observation_spec()`.
   321|         0|            0|            0|  0.00%|        reward: list of rewards at this timestep, or None if step_type is
   322|         0|            0|            0|  0.00%|          `StepType.FIRST`.
   323|         0|            0|            0|  0.00%|        discount: list of discounts in the range [0, 1], or None if step_type is
   324|         0|            0|            0|  0.00%|          `StepType.FIRST`.
   325|         0|            0|            0|  0.00%|        step_type: A `StepType` value.
   326|         0|            0|            0|  0.00%|    """
   327|     18432|      0.12811|   6.9504e-06|  0.12%|    assert len(actions) == self.num_actions_per_step, (
(call)|     18432|     0.625137|  3.39159e-05|  0.60%|# /apps/open_spiel/open_spiel/python/rl_environment.py:467 num_actions_per_step
   328|         0|            0|            0|  0.00%|        "Invalid number of actions! Expected {}".format(
   329|         0|            0|            0|  0.00%|            self.num_actions_per_step))
   330|     18432|     0.037775|  2.04943e-06|  0.04%|    if self._should_reset:
   331|         0|            0|            0|  0.00%|      return self.reset()
   332|         0|            0|            0|  0.00%|
   333|     18432|    0.0385914|  2.09372e-06|  0.04%|    if self._enable_legality_check:
   334|         0|            0|            0|  0.00%|      self._check_legality(actions)
   335|         0|            0|            0|  0.00%|
   336|     18432|      0.10929|  5.92934e-06|  0.10%|    if self.is_turn_based:
(call)|     18432|      0.28326|  1.53679e-05|  0.27%|# /apps/open_spiel/open_spiel/python/rl_environment.py:472 is_turn_based
   337|     18432|     0.399684|  2.16842e-05|  0.38%|      self._state.apply_action(actions[0])
(call)|     18432|     0.131608|  7.14018e-06|  0.13%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:306 current_player
(call)|     18432|      7.68711|  0.000417053|  7.36%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:367 _apply_action
   338|         0|            0|            0|  0.00%|    else:
   339|         0|            0|            0|  0.00%|      self._state.apply_actions(actions)
   340|     18432|     0.146343|  7.93964e-06|  0.14%|    self._sample_external_events()
(call)|     18432|      3.73559|  0.000202669|  3.58%|# /apps/open_spiel/open_spiel/python/rl_environment.py:398 _sample_external_events
   341|         0|            0|            0|  0.00%|
   342|     18432|     0.157891|  8.56614e-06|  0.15%|    return self.get_time_step()
(call)|     18432|       24.715|   0.00134088| 23.68%|# /apps/open_spiel/open_spiel/python/rl_environment.py:237 get_time_step
   343|         0|            0|            0|  0.00%|
   344|      1349|   0.00391126|  2.89937e-06|  0.00%|  def reset(self):
   345|         0|            0|            0|  0.00%|    """Starts a new sequence and returns the first `TimeStep` of this sequence.
   346|         0|            0|            0|  0.00%|
   347|         0|            0|            0|  0.00%|    Returns:
   348|         0|            0|            0|  0.00%|      A `TimeStep` namedtuple containing:
   349|         0|            0|            0|  0.00%|        observations: list of dicts containing one observations per player, each
   350|         0|            0|            0|  0.00%|          corresponding to `observation_spec()`.
   351|         0|            0|            0|  0.00%|        rewards: list of rewards at this timestep, or None if step_type is
   352|         0|            0|            0|  0.00%|          `StepType.FIRST`.
   353|         0|            0|            0|  0.00%|        discounts: list of discounts in the range [0, 1], or None if step_type
   354|         0|            0|            0|  0.00%|          is `StepType.FIRST`.
   355|         0|            0|            0|  0.00%|        step_type: A `StepType` value.
   356|         0|            0|            0|  0.00%|    """
   357|      1349|   0.00436282|  3.23412e-06|  0.00%|    self._should_reset = False
   358|      1349|    0.0256333|  1.90017e-05|  0.02%|    if self._game.get_type().dynamics == pyspiel.GameType.Dynamics.MEAN_FIELD and self._num_players > 1:
   359|         0|            0|            0|  0.00%|      self._state = self._game.new_initial_state_for_population(self._mfg_population)
   360|         0|            0|            0|  0.00%|    else:
   361|      1349|    0.0261326|  1.93718e-05|  0.03%|      self._state = self._game.new_initial_state()
(call)|      1349|     0.186344|  0.000138135|  0.18%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:269 new_initial_state
   362|      1349|   0.00469947|  3.48367e-06|  0.00%|    for action in self._history_prefix:
   363|         0|            0|            0|  0.00%|      if self.is_turn_based:
   364|         0|            0|            0|  0.00%|        self._state.apply_action(action)
   365|         0|            0|            0|  0.00%|      else:
   366|         0|            0|            0|  0.00%|        self._state.apply_actions(action)
   367|      1349|    0.0128427|  9.52013e-06|  0.01%|    self._sample_external_events()
(call)|      1349|      1.08677|  0.000805609|  1.04%|# /apps/open_spiel/open_spiel/python/rl_environment.py:398 _sample_external_events
   368|         0|            0|            0|  0.00%|
   369|      1349|   0.00381541|  2.82833e-06|  0.00%|    observations = {
   370|      1349|   0.00379944|  2.81649e-06|  0.00%|        "info_state": [],
   371|      1349|   0.00342226|  2.53689e-06|  0.00%|        "legal_actions": [],
   372|      1349|   0.00337315|  2.50048e-06|  0.00%|        "current_player": [],
   373|      1349|   0.00327015|  2.42413e-06|  0.00%|        "serialized_state": []
   374|         0|            0|            0|  0.00%|    }
   375|      1349|   0.00367999|  2.72794e-06|  0.00%|    if self.observer is not None:
   376|      1349|   0.00340843|  2.52664e-06|  0.00%|      observations['info_dict'] = []
   377|      4047|    0.0185201|  4.57626e-06|  0.02%|    for player_id in range(self.num_players):
(call)|      1349|   0.00918627|  6.80969e-06|  0.01%|# /apps/open_spiel/open_spiel/python/rl_environment.py:463 num_players
   378|      2698|   0.00714064|  2.64664e-06|  0.01%|      if self.observer is None:
   379|         0|            0|            0|  0.00%|        info_state = self._state.observation_tensor(player_id) if self._use_observation else self._state.information_state_tensor(player_id)
   380|         0|            0|            0|  0.00%|      else:
   381|      2698|    0.0305996|  1.13416e-05|  0.03%|        self.observer.set_from(self._state, player=player_id)
(call)|      2698|      0.73118|  0.000271008|  0.70%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:850 set_from
   382|      2698|    0.0105948|  3.92693e-06|  0.01%|        info_state = np.array(self.observer.tensor)
   383|      2698|    0.0210023|  7.78439e-06|  0.02%|        observations['info_dict'].append(fastcopy(self.observer.dict))
(call)|      2698|     0.120667|  4.47245e-05|  0.12%|# /apps/open_spiel/open_spiel/python/rl_environment.py:60 fastcopy
   384|      2698|   0.00699425|  2.59238e-06|  0.01%|      observations["info_state"].append(info_state)
   385|      2698|    0.0945716|  3.50525e-05|  0.09%|      observations["legal_actions"].append(self._state.legal_actions(player_id))
(call)|      2698|    0.0105364|  3.90528e-06|  0.01%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:461 is_terminal
(call)|      6745|     0.044332|  6.57258e-06|  0.04%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:306 current_player
(call)|      1349|     0.287877|    0.0002134|  0.28%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:319 _legal_actions
   386|      1349|    0.0091362|  6.77257e-06|  0.01%|    observations["current_player"] = self._state.current_player()
(call)|      1349|   0.00851035|  6.30864e-06|  0.01%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:306 current_player
   387|         0|            0|            0|  0.00%|
   388|      1349|   0.00330949|  2.45329e-06|  0.00%|    if self._include_full_state:
   389|         0|            0|            0|  0.00%|      observations["serialized_state"] = pyspiel.serialize_game_and_state(
   390|         0|            0|            0|  0.00%|          self._game, self._state)
   391|         0|            0|            0|  0.00%|
   392|      2698|    0.0149512|   5.5416e-06|  0.01%|    return TimeStep(
(call)|      1349|   0.00725412|  5.37741e-06|  0.01%|# <string>:1 __new__
   393|      1349|   0.00301933|   2.2382e-06|  0.00%|        observations=observations,
   394|      1349|   0.00303531|  2.25004e-06|  0.00%|        rewards=None,
   395|      1349|   0.00288057|  2.13534e-06|  0.00%|        discounts=None,
   396|      1349|   0.00398374|   2.9531e-06|  0.00%|        step_type=StepType.FIRST)
   397|         0|            0|            0|  0.00%|
   398|     19781|     0.060626|  3.06486e-06|  0.06%|  def _sample_external_events(self):
   399|         0|            0|            0|  0.00%|    """Sample chance events until we get to a decision node."""
   400|     45454|     0.494377|  1.08764e-05|  0.47%|    while self._state.is_chance_node() or (self._state.current_player()
(call)|     45454|     0.298595|  6.56918e-06|  0.29%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:306 current_player
   401|     19781|    0.0539808|  2.72892e-06|  0.05%|                                           == pyspiel.PlayerId.MEAN_FIELD):
   402|      5892|    0.0625789|   1.0621e-05|  0.06%|      if self._state.is_chance_node():
(call)|      5892|    0.0387475|   6.5763e-06|  0.04%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:306 current_player
   403|      5892|    0.0501649|  8.51408e-06|  0.05%|        outcome = self._chance_event_sampler(self._state)
(call)|      5892|      1.15491|  0.000196013|  1.11%|# /apps/open_spiel/open_spiel/python/examples/ubc_utils.py:150 __call__
   404|      5892|     0.133077|  2.25861e-05|  0.13%|        self._state.apply_action(outcome)
(call)|      5892|    0.0430939|  7.31397e-06|  0.04%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:306 current_player
(call)|      5892|      2.33535|   0.00039636|  2.24%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:367 _apply_action
   405|      5892|    0.0589321|   1.0002e-05|  0.06%|      if self._state.current_player() == pyspiel.PlayerId.MEAN_FIELD:
(call)|      5892|    0.0379276|  6.43714e-06|  0.04%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:306 current_player
   406|         0|            0|            0|  0.00%|        dist_to_register = self._state.distribution_support()
   407|         0|            0|            0|  0.00%|        dist = [
   408|         0|            0|            0|  0.00%|            self._mfg_distribution.value_str(str_state, default_value=0.0)
   409|         0|            0|            0|  0.00%|            for str_state in dist_to_register
   410|         0|            0|            0|  0.00%|        ]
   411|         0|            0|            0|  0.00%|        self._state.update_distribution(dist)
   412|         0|            0|            0|  0.00%|
   413|         0|            0|            0|  0.00%|  def observation_spec(self):
   414|         0|            0|            0|  0.00%|    """Defines the observation per player provided by the environment.
   415|         0|            0|            0|  0.00%|
   416|         0|            0|            0|  0.00%|    Each dict member will contain its expected structure and shape. E.g.: for
   417|         0|            0|            0|  0.00%|    Kuhn Poker {"info_state": (6,), "legal_actions": (2,), "current_player": (),
   418|         0|            0|            0|  0.00%|                "serialized_state": ()}
   419|         0|            0|            0|  0.00%|
   420|         0|            0|            0|  0.00%|    Returns:
   421|         0|            0|            0|  0.00%|      A specification dict describing the observation fields and shapes.
   422|         0|            0|            0|  0.00%|    """
   423|         0|            0|            0|  0.00%|    return dict(
   424|         0|            0|            0|  0.00%|        info_state=tuple([
   425|         0|            0|            0|  0.00%|            self._game.observation_tensor_size() if self._use_observation else
   426|         0|            0|            0|  0.00%|            self._game.information_state_tensor_size()
   427|         0|            0|            0|  0.00%|        ]),
   428|         0|            0|            0|  0.00%|        legal_actions=(self._game.num_distinct_actions(),),
   429|         0|            0|            0|  0.00%|        current_player=(),
   430|         0|            0|            0|  0.00%|        serialized_state=(),
   431|         0|            0|            0|  0.00%|    )
   432|         0|            0|            0|  0.00%|
   433|         0|            0|            0|  0.00%|  def action_spec(self):
   434|         0|            0|            0|  0.00%|    """Defines per player action specifications.
   435|         0|            0|            0|  0.00%|
   436|         0|            0|            0|  0.00%|    Specifications include action boundaries and their data type.
   437|         0|            0|            0|  0.00%|    E.g.: for Kuhn Poker {"num_actions": 2, "min": 0, "max":1, "dtype": int}
   438|         0|            0|            0|  0.00%|
   439|         0|            0|            0|  0.00%|    Returns:
   440|         0|            0|            0|  0.00%|      A specification dict containing per player action properties.
   441|         0|            0|            0|  0.00%|    """
   442|         0|            0|            0|  0.00%|    return dict(
   443|         0|            0|            0|  0.00%|        num_actions=self._game.num_distinct_actions(),
   444|         0|            0|            0|  0.00%|        min=0,
   445|         0|            0|            0|  0.00%|        max=self._game.num_distinct_actions() - 1,
   446|         0|            0|            0|  0.00%|        dtype=int,
   447|         0|            0|            0|  0.00%|    )
   448|         0|            0|            0|  0.00%|
   449|         0|            0|            0|  0.00%|  # Environment properties
   450|         0|            0|            0|  0.00%|  @property
   451|         0|            0|            0|  0.00%|  def use_observation(self):
   452|         0|            0|            0|  0.00%|    """Returns whether the environment is using the game's observation.
   453|         0|            0|            0|  0.00%|
   454|         0|            0|            0|  0.00%|    If false, it is using the game's information state.
   455|         0|            0|            0|  0.00%|    """
   456|         0|            0|            0|  0.00%|    return self._use_observation
   457|         0|            0|            0|  0.00%|
   458|         0|            0|            0|  0.00%|  # Game properties
   459|         0|            0|            0|  0.00%|  @property
   460|         0|            0|            0|  0.00%|  def name(self):
   461|         0|            0|            0|  0.00%|    return self._game.get_type().short_name
   462|         0|            0|            0|  0.00%|
   463|     56653|    0.0963559|  1.70081e-06|  0.09%|  @property
   464|         0|            0|            0|  0.00%|  def num_players(self):
   465|     56653|     0.298499|   5.2689e-06|  0.29%|    return self._game.num_players()
   466|         0|            0|            0|  0.00%|
   467|     18432|    0.0302358|   1.6404e-06|  0.03%|  @property
   468|         0|            0|            0|  0.00%|  def num_actions_per_step(self):
   469|     18432|     0.116397|  6.31494e-06|  0.11%|    return 1 if self.is_turn_based else self.num_players
(call)|     18432|     0.478504|  2.59605e-05|  0.46%|# /apps/open_spiel/open_spiel/python/rl_environment.py:472 is_turn_based
   470|         0|            0|            0|  0.00%|
   471|         0|            0|            0|  0.00%|  # New RL calls for more advanced use cases (e.g. search + RL).
   472|     36864|    0.0550363|  1.49296e-06|  0.05%|  @property
   473|         0|            0|            0|  0.00%|  def is_turn_based(self):
   474|    110592|     0.618252|  5.59039e-06|  0.59%|    return ((self._game.get_type().dynamics
   475|     36864|    0.0884762|  2.40007e-06|  0.08%|             == pyspiel.GameType.Dynamics.SEQUENTIAL) or
   476|         0|            0|            0|  0.00%|            (self._game.get_type().dynamics
   477|         0|            0|            0|  0.00%|             == pyspiel.GameType.Dynamics.MEAN_FIELD))
   478|         0|            0|            0|  0.00%|
   479|         0|            0|            0|  0.00%|  @property
   480|         0|            0|            0|  0.00%|  def max_game_length(self):
   481|         0|            0|            0|  0.00%|    return self._game.max_game_length()
   482|         0|            0|            0|  0.00%|
   483|         0|            0|            0|  0.00%|  @property
   484|         0|            0|            0|  0.00%|  def is_chance_node(self):
   485|         0|            0|            0|  0.00%|    return self._state.is_chance_node()
   486|         0|            0|            0|  0.00%|
   487|         0|            0|            0|  0.00%|  @property
   488|         0|            0|            0|  0.00%|  def game(self):
   489|         0|            0|            0|  0.00%|    return self._game
   490|         0|            0|            0|  0.00%|
   491|         0|            0|            0|  0.00%|  def set_state(self, new_state):
   492|         0|            0|            0|  0.00%|    """Updates the game state."""
   493|         0|            0|            0|  0.00%|    assert new_state.get_game() == self.game, (
   494|         0|            0|            0|  0.00%|        "State must have been created by the same game.")
   495|         0|            0|            0|  0.00%|    self._state = new_state
   496|         0|            0|            0|  0.00%|
   497|         0|            0|            0|  0.00%|  @property
   498|         0|            0|            0|  0.00%|  def get_state(self):
   499|         0|            0|            0|  0.00%|    return self._state
   500|         0|            0|            0|  0.00%|
   501|         0|            0|            0|  0.00%|  @property
   502|         0|            0|            0|  0.00%|  def mfg_distribution(self):
   503|         0|            0|            0|  0.00%|    return self._mfg_distribution
   504|         0|            0|            0|  0.00%|
   505|         0|            0|            0|  0.00%|  def update_mfg_distribution(self, mfg_distribution):
   506|         0|            0|            0|  0.00%|    """Updates the distribution over the states of the mean field game."""
   507|         0|            0|            0|  0.00%|    assert (
   508|         0|            0|            0|  0.00%|        self._game.get_type().dynamics == pyspiel.GameType.Dynamics.MEAN_FIELD)
   509|         0|            0|            0|  0.00%|    self._mfg_distribution = mfg_distribution
File: /apps/open_spiel/open_spiel/python/games/clock_auction_bidders.py
File duration: 3.6333s (3.48%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import numpy as np
     2|         0|            0|            0|  0.00%|
     3|         0|            0|            0|  0.00%|class Bidder:
     4|         0|            0|            0|  0.00%|
     5|         0|            0|            0|  0.00%|  def __init__(self, values, budget, pricing_bonus, all_bids, drop_out_heuristic) -> None:
     6|         0|            0|            0|  0.00%|    self.values = np.array(values)
     7|         0|            0|            0|  0.00%|    self.budget = budget
     8|         0|            0|            0|  0.00%|    self.pricing_bonus = pricing_bonus
     9|         0|            0|            0|  0.00%|    self.all_bids = all_bids
    10|         0|            0|            0|  0.00%|    self.bundle_values = None
    11|         0|            0|            0|  0.00%|    self.drop_out_heuristic = drop_out_heuristic
    12|         0|            0|            0|  0.00%|
    13|         0|            0|            0|  0.00%|  def value_for_package(package, package_index=None):
    14|         0|            0|            0|  0.00%|    raise NotImplementedError()
    15|         0|            0|            0|  0.00%|
    16|         0|            0|            0|  0.00%|  def get_budget(self):
    17|         0|            0|            0|  0.00%|    return self.budget
    18|         0|            0|            0|  0.00%|
    19|         0|            0|            0|  0.00%|  def get_pricing_bonus(self):
    20|         0|            0|            0|  0.00%|    return self.price_bonus
    21|         0|            0|            0|  0.00%|
    22|    280583|     0.360037|  1.28317e-06|  0.34%|  def get_values(self):
    23|    280583|     0.467209|  1.66514e-06|  0.45%|    return self.bundle_values
    24|         0|            0|            0|  0.00%|
    25|    280583|     0.525451|  1.87271e-06|  0.50%|  def get_profits(self, prices):
    26|    280583|      2.15935|  7.69595e-06|  2.07%|    return self.get_values() - prices
(call)|    280583|     0.827245|  2.94831e-06|  0.79%|# /apps/open_spiel/open_spiel/python/games/clock_auction_bidders.py:22 get_values
    27|         0|            0|            0|  0.00%|
    28|         0|            0|            0|  0.00%|class LinearBidder(Bidder):
    29|         0|            0|            0|  0.00%|
    30|         0|            0|            0|  0.00%|  def __init__(self, values, budget, pricing_bonus, all_bids, drop_out_heuristic) -> None:
    31|         0|            0|            0|  0.00%|    super().__init__(values, budget, pricing_bonus, all_bids, drop_out_heuristic)
    32|         0|            0|            0|  0.00%|    self.bundle_values = all_bids @ self.values
    33|         0|            0|            0|  0.00%|
    34|         0|            0|            0|  0.00%|  def value_for_package(self, package, package_index=None):
    35|         0|            0|            0|  0.00%|    return np.array(package) @ self.values
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|  def __str__(self) -> str:
    38|         0|            0|            0|  0.00%|    return f'LinearValues: {self.values} Budget: {self.budget}'
    39|         0|            0|            0|  0.00%|
    40|         0|            0|            0|  0.00%|class MarginalValueBidder(Bidder):
    41|         0|            0|            0|  0.00%|
    42|         0|            0|            0|  0.00%|  def __init__(self, values, budget, pricing_bonus, all_bids, drop_out_heuristic) -> None:
    43|         0|            0|            0|  0.00%|    super().__init__(values, budget, pricing_bonus, all_bids, drop_out_heuristic)
    44|         0|            0|            0|  0.00%|    self.bundle_values = [self.value_for_package(bid) for bid in all_bids]
    45|         0|            0|            0|  0.00%|
    46|         0|            0|            0|  0.00%|  def value_for_package(self, package, package_index=None):
    47|         0|            0|            0|  0.00%|    value = 0
    48|         0|            0|            0|  0.00%|    for i, quantity in enumerate(package):
    49|         0|            0|            0|  0.00%|      value += self.values[i][:quantity].sum()
    50|         0|            0|            0|  0.00%|    return value
    51|         0|            0|            0|  0.00%|
    52|         0|            0|            0|  0.00%|  def __str__(self) -> str:
    53|         0|            0|            0|  0.00%|    return f'MarginalValues: {self.values} Budget: {self.budget}'
    54|         0|            0|            0|  0.00%|
    55|         0|            0|            0|  0.00%|class EnumeratedValueBidder(Bidder):
    56|         0|            0|            0|  0.00%|
    57|         0|            0|            0|  0.00%|  def __init__(self, values, budget, pricing_bonus, all_bids, drop_out_heuristic) -> None:
    58|         0|            0|            0|  0.00%|    super().__init__(values, budget, pricing_bonus, all_bids, drop_out_heuristic)
    59|         0|            0|            0|  0.00%|    self.bundle_values = self.values
    60|         0|            0|            0|  0.00%|
    61|      5364|   0.00940681|  1.75369e-06|  0.01%|  def value_for_package(self, package, package_index=None):
    62|      5364|   0.00985694|  1.83761e-06|  0.01%|    if package_index is None:
    63|      5364|    0.0890481|  1.66011e-05|  0.09%|      package_index = np.where((self.all_bids == package).all(axis=1))[0][0]
(call)|      5364|    0.0534978|  9.97349e-06|  0.05%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/_methods.py:60 _all
(call)|      5364|    0.0966074|  1.80103e-05|  0.09%|# <__array_function__ internals>:177 where
    64|      5364|    0.0129366|  2.41174e-06|  0.01%|    return self.values[package_index]
    65|         0|            0|            0|  0.00%|
    66|         0|            0|            0|  0.00%|  def __str__(self) -> str:
    67|         0|            0|            0|  0.00%|    return f'EnumeratedValues: {self.values} Budget: {self.budget}'
File: /apps/open_spiel/open_spiel/python/env_decorator.py
File duration: 3.19802s (3.06%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|from builtins import classmethod
     2|         0|            0|            0|  0.00%|from open_spiel.python.rl_environment import Environment
     3|         0|            0|            0|  0.00%|import torch
     4|         0|            0|            0|  0.00%|from collections import defaultdict
     5|         0|            0|            0|  0.00%|import numpy as np
     6|         0|            0|            0|  0.00%|import collections
     7|         0|            0|            0|  0.00%|from typing import Callable
     8|         0|            0|            0|  0.00%|
     9|         0|            0|            0|  0.00%|class EnvDecorator(object):
    10|         0|            0|            0|  0.00%|
    11|         0|            0|            0|  0.00%|    def __init__(self, env: Environment) -> None:
    12|         0|            0|            0|  0.00%|        self._env = env
    13|         0|            0|            0|  0.00%|        self.env_attributes = [attribute for attribute in self._env.__dict__.keys()]
    14|         0|            0|            0|  0.00%|        self.env_methods = [m for m in dir(self._env) if not m.startswith('_') and m not in self.env_attributes]
    15|         0|            0|            0|  0.00%|
    16|         0|            0|            0|  0.00%|    def __getattr__(self, func):
    17|         0|            0|            0|  0.00%|        if func in self.env_methods:
    18|         0|            0|            0|  0.00%|            def method(*args):
    19|         0|            0|            0|  0.00%|                return getattr(self._env, func)(*args)
    20|         0|            0|            0|  0.00%|            return method
    21|         0|            0|            0|  0.00%|        elif func in self.env_attributes:
    22|         0|            0|            0|  0.00%|            return getattr(self._env, func)
    23|         0|            0|            0|  0.00%|        else:
    24|         0|            0|            0|  0.00%|            # For nesting decorators
    25|         0|            0|            0|  0.00%|            if isinstance(self._env, EnvDecorator):
    26|         0|            0|            0|  0.00%|                return self._env.__getattr__(func)
    27|         0|            0|            0|  0.00%|            raise AttributeError(func)
    28|         0|            0|            0|  0.00%|
    29|     18432|    0.0340729|  1.84857e-06|  0.03%|    def step(self, step_outputs):
    30|     18432|     0.138387|    7.508e-06|  0.13%|        _ = self._env.step(step_outputs)
(call)|     18432|      38.2296|   0.00207409| 36.63%|# /apps/open_spiel/open_spiel/python/rl_environment.py:302 step
    31|     18432|     0.138699|  7.52488e-06|  0.13%|        return self.get_time_step()
(call)|     18432|       25.876|   0.00140386| 24.79%|# /apps/open_spiel/open_spiel/python/env_decorator.py:48 get_time_step
    32|         0|            0|            0|  0.00%|
    33|      1349|   0.00248146|  1.83948e-06|  0.00%|    def reset(self):
    34|      1349|    0.0114603|  8.49541e-06|  0.01%|        _ = self._env.reset()
(call)|      1349|      2.82474|   0.00209395|  2.71%|# /apps/open_spiel/open_spiel/python/rl_environment.py:344 reset
    35|      1349|   0.00977659|  7.24729e-06|  0.01%|        return self.get_time_step()
(call)|      1349|      1.64988|   0.00122304|  1.58%|# /apps/open_spiel/open_spiel/python/env_decorator.py:48 get_time_step
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|    @property
    38|         0|            0|            0|  0.00%|    def env(self) -> Environment:
    39|         0|            0|            0|  0.00%|        return self._env
    40|         0|            0|            0|  0.00%|
    41|         0|            0|            0|  0.00%|
    42|         0|            0|            0|  0.00%|class NormalizingEnvDecorator(EnvDecorator):
    43|         0|            0|            0|  0.00%|
    44|         0|            0|            0|  0.00%|    def __init__(self, env: Environment, reward_normalizer: torch.tensor = None) -> None:
    45|         0|            0|            0|  0.00%|        super().__init__(env)
    46|         0|            0|            0|  0.00%|        self.reward_normalizer = reward_normalizer
    47|         0|            0|            0|  0.00%|
    48|     36872|    0.0684385|  1.85611e-06|  0.07%|    def get_time_step(self):
    49|     36872|     0.315333|  8.55211e-06|  0.30%|        time_step = self._env.get_time_step()
(call)|     36872|      48.6279|   0.00131883| 46.59%|# /apps/open_spiel/open_spiel/python/rl_environment.py:237 get_time_step
    50|         0|            0|            0|  0.00%|
    51|     36872|     0.090749|  2.46119e-06|  0.09%|        if self.reward_normalizer is not None:
    52|     36872|      1.72447|  4.67691e-05|  1.65%|            time_step.rewards[:] = (torch.tensor(time_step.rewards) / self.reward_normalizer).tolist()
    53|         0|            0|            0|  0.00%|
    54|     36872|     0.593881|  1.61066e-05|  0.57%|        if np.isnan(time_step.rewards).any():
(call)|     36872|     0.426454|  1.15658e-05|  0.41%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/_methods.py:54 _any
    55|         0|            0|            0|  0.00%|            raise ValueError("Nan reward after normalization!")
    56|     36872|    0.0702674|  1.90571e-06|  0.07%|        return time_step
    57|         0|            0|            0|  0.00%|
    58|         0|            0|            0|  0.00%|
    59|         0|            0|            0|  0.00%|class PotentialShapingEnvDecorator(EnvDecorator):
    60|         0|            0|            0|  0.00%|
    61|         0|            0|            0|  0.00%|    def __init__(self, env: Environment, potential_function: Callable, n_players: int) -> None:
    62|         0|            0|            0|  0.00%|        super().__init__(env)
    63|         0|            0|            0|  0.00%|        self.potential_function = potential_function
    64|         0|            0|            0|  0.00%|        self.n_players = n_players
    65|         0|            0|            0|  0.00%|        self.last_potential = np.zeros(self.n_players)
    66|         0|            0|            0|  0.00%|        # TODO: Store potentials for wandb and decide how to log them
    67|         0|            0|            0|  0.00%|        # TODO: Are these way too small to be useful?
    68|         0|            0|            0|  0.00%|
    69|         0|            0|            0|  0.00%|    def step(self, step_outputs):
    70|         0|            0|            0|  0.00%|        state = self._env._state
    71|         0|            0|            0|  0.00%|        current_player = state.current_player()
    72|         0|            0|            0|  0.00%|        if current_player == self.n_players - 1:
    73|         0|            0|            0|  0.00%|            # Update potentials once
    74|         0|            0|            0|  0.00%|            current_potential = self.potential_function(state)
    75|         0|            0|            0|  0.00%|            self.last_potential= current_potential
    76|         0|            0|            0|  0.00%|        _ = self._env.step(step_outputs)
    77|         0|            0|            0|  0.00%|        return self.get_time_step()
    78|         0|            0|            0|  0.00%|
    79|         0|            0|            0|  0.00%|    def get_time_step(self):
    80|         0|            0|            0|  0.00%|        time_step = self._env.get_time_step()
    81|         0|            0|            0|  0.00%|        state = self._env._state
    82|         0|            0|            0|  0.00%|        if time_step.last():
    83|         0|            0|            0|  0.00%|            # There's no reason to add the current potential just to subtract it - it won't make a difference. So let's just undo all the potentials right now
    84|         0|            0|            0|  0.00%|            shaped_reward = -self.last_potential
    85|         0|            0|            0|  0.00%|        else:
    86|         0|            0|            0|  0.00%|            current_potential = self.potential_function(state)
    87|         0|            0|            0|  0.00%|            shaped_reward = current_potential - self.last_potential
    88|         0|            0|            0|  0.00%|
    89|         0|            0|            0|  0.00%|        new_rewards = torch.tensor(time_step.rewards) + shaped_reward
    90|         0|            0|            0|  0.00%|
    91|         0|            0|            0|  0.00%|        # Logging chage in rewards as a percentage due to potential function
    92|         0|            0|            0|  0.00%|        # TODO: zeros...
    93|         0|            0|            0|  0.00%|        # diff = ((new_rewards - torch.tensor(time_step.rewards)) / torch.tensor(time_step.rewards).abs()) * 100
    94|         0|            0|            0|  0.00%|        # print(diff)
    95|         0|            0|            0|  0.00%|
    96|         0|            0|            0|  0.00%|        time_step.rewards[:] = new_rewards
    97|         0|            0|            0|  0.00%|        return time_step
    98|         0|            0|            0|  0.00%|
    99|         0|            0|            0|  0.00%|    def reset(self):
   100|         0|            0|            0|  0.00%|        _ = self._env.reset()
   101|         0|            0|            0|  0.00%|        self.last_potential = np.zeros(self.n_players)
   102|         0|            0|            0|  0.00%|        return self.get_time_step()
   103|         0|            0|            0|  0.00%|
   104|         0|            0|            0|  0.00%|class RewardShapingEnvDecorator(EnvDecorator):
   105|         0|            0|            0|  0.00%|
   106|         0|            0|            0|  0.00%|    def __init__(self, env: Environment, reward_function: Callable, schedule_function: Callable) -> None:
   107|         0|            0|            0|  0.00%|        super().__init__(env)
   108|         0|            0|            0|  0.00%|        self.reward_function = reward_function
   109|         0|            0|            0|  0.00%|        self.schedule_function = schedule_function
   110|         0|            0|            0|  0.00%|        self.t = 0
   111|         0|            0|            0|  0.00%|
   112|         0|            0|            0|  0.00%|    def get_time_step(self):
   113|         0|            0|            0|  0.00%|        time_step = self._env.get_time_step()
   114|         0|            0|            0|  0.00%|        state = self._env._state
   115|         0|            0|            0|  0.00%|        lam = self.schedule_function(self.t)
   116|         0|            0|            0|  0.00%|        new_rewards = lam * self.reward_function(state) + (1 - lam) * torch.tensor(time_step.rewards)
   117|         0|            0|            0|  0.00%|        time_step.rewards[:] = new_rewards
   118|         0|            0|            0|  0.00%|        return time_step
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|    def step(self, step_outputs):
   121|         0|            0|            0|  0.00%|        _ = self._env.step(step_outputs)
   122|         0|            0|            0|  0.00%|        self.t += 1
   123|         0|            0|            0|  0.00%|        return self.get_time_step()
   124|         0|            0|            0|  0.00%|
   125|         0|            0|            0|  0.00%|class StateSavingEnvDecorator(EnvDecorator):
   126|         0|            0|            0|  0.00%|
   127|         0|            0|            0|  0.00%|    def __init__(self, env: Environment, num_states_to_save = 100) -> None:
   128|         0|            0|            0|  0.00%|        super().__init__(env)
   129|         0|            0|            0|  0.00%|        self.num_states_to_save = num_states_to_save
   130|         0|            0|            0|  0.00%|        self.num_players = env.num_players
   131|         0|            0|            0|  0.00%|        self.states = [collections.deque() for _ in range(self.num_players)]
   132|         0|            0|            0|  0.00%|
   133|         0|            0|            0|  0.00%|    def step(self, step_outputs):
   134|         0|            0|            0|  0.00%|        time_step = self._env.get_time_step()
   135|         0|            0|            0|  0.00%|        if not time_step.last():
   136|         0|            0|            0|  0.00%|            current_player = time_step.current_player()
   137|         0|            0|            0|  0.00%|            self.states[current_player].append(time_step.observations['info_state'][current_player])
   138|         0|            0|            0|  0.00%|
   139|         0|            0|            0|  0.00%|        _ = self._env.step(step_outputs)
   140|         0|            0|            0|  0.00%|        return time_step
   141|         0|            0|            0|  0.00%|
   142|         0|            0|            0|  0.00%|    def get_states(self):
   143|         0|            0|            0|  0.00%|        return [list(d) for d in self.states]
   144|         0|            0|            0|  0.00%|
   145|         0|            0|            0|  0.00%|    @staticmethod
   146|         0|            0|            0|  0.00%|    def merge_states(sync_env):
   147|         0|            0|            0|  0.00%|        d = []
   148|         0|            0|            0|  0.00%|        for e in sync_env.envs:
   149|         0|            0|            0|  0.00%|            d += e.get_states()
   150|         0|            0|            0|  0.00%|        return d
   151|         0|            0|            0|  0.00%|
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|class AuctionStatTrackingDecorator(EnvDecorator):
   154|         0|            0|            0|  0.00%|
   155|         0|            0|            0|  0.00%|    def __init__(self, env: Environment, clear_on_report: bool = False) -> None:
   156|         0|            0|            0|  0.00%|        super().__init__(env)
   157|         0|            0|            0|  0.00%|        self.clear_on_report = clear_on_report
   158|         0|            0|            0|  0.00%|        self.clear()
   159|         0|            0|            0|  0.00%|
   160|         0|            0|            0|  0.00%|    def clear(self):
   161|         0|            0|            0|  0.00%|        self.rewards = defaultdict(list)
   162|         0|            0|            0|  0.00%|        self.payments = defaultdict(list)
   163|         0|            0|            0|  0.00%|        self.allocations = defaultdict(list)
   164|         0|            0|            0|  0.00%|        self.auction_lengths = []
   165|         0|            0|            0|  0.00%|        self.welfares = []
   166|         0|            0|            0|  0.00%|        self.revenues = []
   167|         0|            0|            0|  0.00%|
   168|         0|            0|            0|  0.00%|    def step(self, step_outputs):
   169|         0|            0|            0|  0.00%|        _ = self._env.step(step_outputs)
   170|         0|            0|            0|  0.00%|        time_step = self._env.get_time_step()
   171|         0|            0|            0|  0.00%|        state = self._env._state
   172|         0|            0|            0|  0.00%|
   173|         0|            0|            0|  0.00%|        if time_step.last():
   174|         0|            0|            0|  0.00%|            for player_id, reward in enumerate(time_step.rewards):
   175|         0|            0|            0|  0.00%|                self.rewards[player_id].append(reward)
   176|         0|            0|            0|  0.00%|            for player_id, payment in enumerate(state.get_final_payments()):
   177|         0|            0|            0|  0.00%|                self.payments[player_id].append(payment)
   178|         0|            0|            0|  0.00%|            self.revenues.append(state.revenue)
   179|         0|            0|            0|  0.00%|            for player_id, allocation in enumerate(state.get_allocation()):
   180|         0|            0|            0|  0.00%|                self.allocations[player_id].append(allocation.tolist())
   181|         0|            0|            0|  0.00%|            self.auction_lengths.append(state.round)
   182|         0|            0|            0|  0.00%|            self.welfares.append(state.get_welfare())
   183|         0|            0|            0|  0.00%|
   184|         0|            0|            0|  0.00%|        return self.get_time_step()
   185|         0|            0|            0|  0.00%|
   186|         0|            0|            0|  0.00%|    def stats_dict(self):
   187|         0|            0|            0|  0.00%|        return {
   188|         0|            0|            0|  0.00%|            'raw_rewards': self.rewards,
   189|         0|            0|            0|  0.00%|            'allocations': self.allocations,
   190|         0|            0|            0|  0.00%|            'payments': self.payments,
   191|         0|            0|            0|  0.00%|            'auction_lengths': self.auction_lengths,
   192|         0|            0|            0|  0.00%|            'revenues': self.revenues,
   193|         0|            0|            0|  0.00%|            'welfares': self.welfares,
   194|         0|            0|            0|  0.00%|        }
   195|         0|            0|            0|  0.00%|
   196|         0|            0|            0|  0.00%|    @staticmethod
   197|         0|            0|            0|  0.00%|    def merge_stats(sync_env):
   198|         0|            0|            0|  0.00%|        d = []
   199|         0|            0|            0|  0.00%|        for e in sync_env.envs:
   200|         0|            0|            0|  0.00%|            if hasattr(e, 'stats_dict'):
   201|         0|            0|            0|  0.00%|                d.append(e.stats_dict())
   202|         0|            0|            0|  0.00%|                if e.clear_on_report:
   203|         0|            0|            0|  0.00%|                    e.clear()
   204|         0|            0|            0|  0.00%|            else:
   205|         0|            0|            0|  0.00%|                d.append(dict())
   206|         0|            0|            0|  0.00%|
   207|         0|            0|            0|  0.00%|        stats_dict = d[0]
   208|         0|            0|            0|  0.00%|        for other_dict in d[1:]:
   209|         0|            0|            0|  0.00%|            for k, v in other_dict.items():
   210|         0|            0|            0|  0.00%|                if isinstance(v, collections.defaultdict):
   211|         0|            0|            0|  0.00%|                    for k2, v2 in v.items():
   212|         0|            0|            0|  0.00%|                        stats_dict[k][k2] += v2
   213|         0|            0|            0|  0.00%|                else:
   214|         0|            0|            0|  0.00%|                    stats_dict[k] += v
   215|         0|            0|            0|  0.00%|        return stats_dict
   216|         0|            0|            0|  0.00%|
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/_methods.py
File duration: 2.34187s (2.24%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|"""
     2|         0|            0|            0|  0.00%|Array methods which are called by both the C-code for the method
     3|         0|            0|            0|  0.00%|and the Python code for the NumPy-namespace function
     4|         0|            0|            0|  0.00%|
     5|         0|            0|            0|  0.00%|"""
     6|         0|            0|            0|  0.00%|import warnings
     7|         0|            0|            0|  0.00%|from contextlib import nullcontext
     8|         0|            0|            0|  0.00%|
     9|         0|            0|            0|  0.00%|from numpy.core import multiarray as mu
    10|         0|            0|            0|  0.00%|from numpy.core import umath as um
    11|         0|            0|            0|  0.00%|from numpy.core.multiarray import asanyarray
    12|         0|            0|            0|  0.00%|from numpy.core import numerictypes as nt
    13|         0|            0|            0|  0.00%|from numpy.core import _exceptions
    14|         0|            0|            0|  0.00%|from numpy._globals import _NoValue
    15|         0|            0|            0|  0.00%|from numpy.compat import pickle, os_fspath
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|# save those O(100) nanoseconds!
    18|         0|            0|            0|  0.00%|umr_maximum = um.maximum.reduce
    19|         0|            0|            0|  0.00%|umr_minimum = um.minimum.reduce
    20|         0|            0|            0|  0.00%|umr_sum = um.add.reduce
    21|         0|            0|            0|  0.00%|umr_prod = um.multiply.reduce
    22|         0|            0|            0|  0.00%|umr_any = um.logical_or.reduce
    23|         0|            0|            0|  0.00%|umr_all = um.logical_and.reduce
    24|         0|            0|            0|  0.00%|
    25|         0|            0|            0|  0.00%|# Complex types to -> (2,)float view for fast-path computation in _var()
    26|         0|            0|            0|  0.00%|_complex_to_float = {
    27|         0|            0|            0|  0.00%|    nt.dtype(nt.csingle) : nt.dtype(nt.single),
    28|         0|            0|            0|  0.00%|    nt.dtype(nt.cdouble) : nt.dtype(nt.double),
    29|         0|            0|            0|  0.00%|}
    30|         0|            0|            0|  0.00%|# Special case for windows: ensure double takes precedence
    31|         0|            0|            0|  0.00%|if nt.dtype(nt.longdouble) != nt.dtype(nt.double):
    32|         0|            0|            0|  0.00%|    _complex_to_float.update({
    33|         0|            0|            0|  0.00%|        nt.dtype(nt.clongdouble) : nt.dtype(nt.longdouble),
    34|         0|            0|            0|  0.00%|    })
    35|         0|            0|            0|  0.00%|
    36|         0|            0|            0|  0.00%|# avoid keyword arguments to speed up parsing, saves about 15%-20% for very
    37|         0|            0|            0|  0.00%|# small reductions
    38|         0|            0|            0|  0.00%|def _amax(a, axis=None, out=None, keepdims=False,
    39|         0|            0|            0|  0.00%|          initial=_NoValue, where=True):
    40|         0|            0|            0|  0.00%|    return umr_maximum(a, axis, None, out, keepdims, initial, where)
    41|         0|            0|            0|  0.00%|
    42|         0|            0|            0|  0.00%|def _amin(a, axis=None, out=None, keepdims=False,
    43|         0|            0|            0|  0.00%|          initial=_NoValue, where=True):
    44|         0|            0|            0|  0.00%|    return umr_minimum(a, axis, None, out, keepdims, initial, where)
    45|         0|            0|            0|  0.00%|
    46|         0|            0|            0|  0.00%|def _sum(a, axis=None, dtype=None, out=None, keepdims=False,
    47|         0|            0|            0|  0.00%|         initial=_NoValue, where=True):
    48|         0|            0|            0|  0.00%|    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|def _prod(a, axis=None, dtype=None, out=None, keepdims=False,
    51|         0|            0|            0|  0.00%|          initial=_NoValue, where=True):
    52|         0|            0|            0|  0.00%|    return umr_prod(a, axis, dtype, out, keepdims, initial, where)
    53|         0|            0|            0|  0.00%|
    54|    213365|     0.508885|  2.38504e-06|  0.49%|def _any(a, axis=None, dtype=None, out=None, keepdims=False, *, where=True):
    55|         0|            0|            0|  0.00%|    # Parsing keyword arguments is currently fairly slow, so avoid it for now
    56|    213365|     0.492209|  2.30689e-06|  0.47%|    if where is True:
    57|    213365|      1.28148|  6.00606e-06|  1.23%|        return umr_any(a, axis, dtype, out, keepdims)
    58|         0|            0|            0|  0.00%|    return umr_any(a, axis, dtype, out, keepdims, where=where)
    59|         0|            0|            0|  0.00%|
    60|      5364|   0.00994563|  1.85414e-06|  0.01%|def _all(a, axis=None, dtype=None, out=None, keepdims=False, *, where=True):
    61|         0|            0|            0|  0.00%|    # Parsing keyword arguments is currently fairly slow, so avoid it for now
    62|      5364|    0.0104036|  1.93953e-06|  0.01%|    if where is True:
    63|      5364|    0.0331485|  6.17981e-06|  0.03%|        return umr_all(a, axis, dtype, out, keepdims)
    64|         0|            0|            0|  0.00%|    return umr_all(a, axis, dtype, out, keepdims, where=where)
    65|         0|            0|            0|  0.00%|
    66|        36|  9.70364e-05|  2.69545e-06|  0.00%|def _count_reduce_items(arr, axis, keepdims=False, where=True):
    67|         0|            0|            0|  0.00%|    # fast-path for the default case
    68|        36|  9.17912e-05|  2.54975e-06|  0.00%|    if where is True:
    69|         0|            0|            0|  0.00%|        # no boolean mask given, calculate items according to axis
    70|        36|  8.70228e-05|   2.4173e-06|  0.00%|        if axis is None:
    71|        36|  0.000150204|  4.17233e-06|  0.00%|            axis = tuple(range(arr.ndim))
    72|         0|            0|            0|  0.00%|        elif not isinstance(axis, tuple):
    73|         0|            0|            0|  0.00%|            axis = (axis,)
    74|        36|  0.000212193|  5.89424e-06|  0.00%|        items = nt.intp(1)
    75|        72|  0.000187635|  2.60605e-06|  0.00%|        for ax in axis:
    76|        36|  0.000186682|   5.1856e-06|  0.00%|            items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
    77|         0|            0|            0|  0.00%|    else:
    78|         0|            0|            0|  0.00%|        # TODO: Optimize case when `where` is broadcast along a non-reduction
    79|         0|            0|            0|  0.00%|        # axis and full sum is more excessive than needed.
    80|         0|            0|            0|  0.00%|
    81|         0|            0|            0|  0.00%|        # guarded to protect circular imports
    82|         0|            0|            0|  0.00%|        from numpy.lib.stride_tricks import broadcast_to
    83|         0|            0|            0|  0.00%|        # count True values in (potentially broadcasted) boolean mask
    84|         0|            0|            0|  0.00%|        items = umr_sum(broadcast_to(where, arr.shape), axis, nt.intp, None,
    85|         0|            0|            0|  0.00%|                        keepdims)
    86|        36|  7.10487e-05|  1.97358e-06|  0.00%|    return items
    87|         0|            0|            0|  0.00%|
    88|         0|            0|            0|  0.00%|# Numpy 1.17.0, 2019-02-24
    89|         0|            0|            0|  0.00%|# Various clip behavior deprecations, marked with _clip_dep as a prefix.
    90|         0|            0|            0|  0.00%|
    91|         0|            0|            0|  0.00%|def _clip_dep_is_scalar_nan(a):
    92|         0|            0|            0|  0.00%|    # guarded to protect circular imports
    93|         0|            0|            0|  0.00%|    from numpy.core.fromnumeric import ndim
    94|         0|            0|            0|  0.00%|    if ndim(a) != 0:
    95|         0|            0|            0|  0.00%|        return False
    96|         0|            0|            0|  0.00%|    try:
    97|         0|            0|            0|  0.00%|        return um.isnan(a)
    98|         0|            0|            0|  0.00%|    except TypeError:
    99|         0|            0|            0|  0.00%|        return False
   100|         0|            0|            0|  0.00%|
   101|         0|            0|            0|  0.00%|def _clip_dep_is_byte_swapped(a):
   102|         0|            0|            0|  0.00%|    if isinstance(a, mu.ndarray):
   103|         0|            0|            0|  0.00%|        return not a.dtype.isnative
   104|         0|            0|            0|  0.00%|    return False
   105|         0|            0|            0|  0.00%|
   106|         0|            0|            0|  0.00%|def _clip_dep_invoke_with_casting(ufunc, *args, out=None, casting=None, **kwargs):
   107|         0|            0|            0|  0.00%|    # normal path
   108|         0|            0|            0|  0.00%|    if casting is not None:
   109|         0|            0|            0|  0.00%|        return ufunc(*args, out=out, casting=casting, **kwargs)
   110|         0|            0|            0|  0.00%|
   111|         0|            0|            0|  0.00%|    # try to deal with broken casting rules
   112|         0|            0|            0|  0.00%|    try:
   113|         0|            0|            0|  0.00%|        return ufunc(*args, out=out, **kwargs)
   114|         0|            0|            0|  0.00%|    except _exceptions._UFuncOutputCastingError as e:
   115|         0|            0|            0|  0.00%|        # Numpy 1.17.0, 2019-02-24
   116|         0|            0|            0|  0.00%|        warnings.warn(
   117|         0|            0|            0|  0.00%|            "Converting the output of clip from {!r} to {!r} is deprecated. "
   118|         0|            0|            0|  0.00%|            "Pass `casting=\"unsafe\"` explicitly to silence this warning, or "
   119|         0|            0|            0|  0.00%|            "correct the type of the variables.".format(e.from_, e.to),
   120|         0|            0|            0|  0.00%|            DeprecationWarning,
   121|         0|            0|            0|  0.00%|            stacklevel=2
   122|         0|            0|            0|  0.00%|        )
   123|         0|            0|            0|  0.00%|        return ufunc(*args, out=out, casting="unsafe", **kwargs)
   124|         0|            0|            0|  0.00%|
   125|         0|            0|            0|  0.00%|def _clip(a, min=None, max=None, out=None, *, casting=None, **kwargs):
   126|         0|            0|            0|  0.00%|    if min is None and max is None:
   127|         0|            0|            0|  0.00%|        raise ValueError("One of max or min must be given")
   128|         0|            0|            0|  0.00%|
   129|         0|            0|            0|  0.00%|    # Numpy 1.17.0, 2019-02-24
   130|         0|            0|            0|  0.00%|    # This deprecation probably incurs a substantial slowdown for small arrays,
   131|         0|            0|            0|  0.00%|    # it will be good to get rid of it.
   132|         0|            0|            0|  0.00%|    if not _clip_dep_is_byte_swapped(a) and not _clip_dep_is_byte_swapped(out):
   133|         0|            0|            0|  0.00%|        using_deprecated_nan = False
   134|         0|            0|            0|  0.00%|        if _clip_dep_is_scalar_nan(min):
   135|         0|            0|            0|  0.00%|            min = -float('inf')
   136|         0|            0|            0|  0.00%|            using_deprecated_nan = True
   137|         0|            0|            0|  0.00%|        if _clip_dep_is_scalar_nan(max):
   138|         0|            0|            0|  0.00%|            max = float('inf')
   139|         0|            0|            0|  0.00%|            using_deprecated_nan = True
   140|         0|            0|            0|  0.00%|        if using_deprecated_nan:
   141|         0|            0|            0|  0.00%|            warnings.warn(
   142|         0|            0|            0|  0.00%|                "Passing `np.nan` to mean no clipping in np.clip has always "
   143|         0|            0|            0|  0.00%|                "been unreliable, and is now deprecated. "
   144|         0|            0|            0|  0.00%|                "In future, this will always return nan, like it already does "
   145|         0|            0|            0|  0.00%|                "when min or max are arrays that contain nan. "
   146|         0|            0|            0|  0.00%|                "To skip a bound, pass either None or an np.inf of an "
   147|         0|            0|            0|  0.00%|                "appropriate sign.",
   148|         0|            0|            0|  0.00%|                DeprecationWarning,
   149|         0|            0|            0|  0.00%|                stacklevel=2
   150|         0|            0|            0|  0.00%|            )
   151|         0|            0|            0|  0.00%|
   152|         0|            0|            0|  0.00%|    if min is None:
   153|         0|            0|            0|  0.00%|        return _clip_dep_invoke_with_casting(
   154|         0|            0|            0|  0.00%|            um.minimum, a, max, out=out, casting=casting, **kwargs)
   155|         0|            0|            0|  0.00%|    elif max is None:
   156|         0|            0|            0|  0.00%|        return _clip_dep_invoke_with_casting(
   157|         0|            0|            0|  0.00%|            um.maximum, a, min, out=out, casting=casting, **kwargs)
   158|         0|            0|            0|  0.00%|    else:
   159|         0|            0|            0|  0.00%|        return _clip_dep_invoke_with_casting(
   160|         0|            0|            0|  0.00%|            um.clip, a, min, max, out=out, casting=casting, **kwargs)
   161|         0|            0|            0|  0.00%|
   162|         0|            0|            0|  0.00%|def _mean(a, axis=None, dtype=None, out=None, keepdims=False, *, where=True):
   163|         0|            0|            0|  0.00%|    arr = asanyarray(a)
   164|         0|            0|            0|  0.00%|
   165|         0|            0|            0|  0.00%|    is_float16_result = False
   166|         0|            0|            0|  0.00%|
   167|         0|            0|            0|  0.00%|    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
   168|         0|            0|            0|  0.00%|    if rcount == 0 if where is True else umr_any(rcount == 0, axis=None):
   169|         0|            0|            0|  0.00%|        warnings.warn("Mean of empty slice.", RuntimeWarning, stacklevel=2)
   170|         0|            0|            0|  0.00%|
   171|         0|            0|            0|  0.00%|    # Cast bool, unsigned int, and int to float64 by default
   172|         0|            0|            0|  0.00%|    if dtype is None:
   173|         0|            0|            0|  0.00%|        if issubclass(arr.dtype.type, (nt.integer, nt.bool_)):
   174|         0|            0|            0|  0.00%|            dtype = mu.dtype('f8')
   175|         0|            0|            0|  0.00%|        elif issubclass(arr.dtype.type, nt.float16):
   176|         0|            0|            0|  0.00%|            dtype = mu.dtype('f4')
   177|         0|            0|            0|  0.00%|            is_float16_result = True
   178|         0|            0|            0|  0.00%|
   179|         0|            0|            0|  0.00%|    ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)
   180|         0|            0|            0|  0.00%|    if isinstance(ret, mu.ndarray):
   181|         0|            0|            0|  0.00%|        ret = um.true_divide(
   182|         0|            0|            0|  0.00%|                ret, rcount, out=ret, casting='unsafe', subok=False)
   183|         0|            0|            0|  0.00%|        if is_float16_result and out is None:
   184|         0|            0|            0|  0.00%|            ret = arr.dtype.type(ret)
   185|         0|            0|            0|  0.00%|    elif hasattr(ret, 'dtype'):
   186|         0|            0|            0|  0.00%|        if is_float16_result:
   187|         0|            0|            0|  0.00%|            ret = arr.dtype.type(ret / rcount)
   188|         0|            0|            0|  0.00%|        else:
   189|         0|            0|            0|  0.00%|            ret = ret.dtype.type(ret / rcount)
   190|         0|            0|            0|  0.00%|    else:
   191|         0|            0|            0|  0.00%|        ret = ret / rcount
   192|         0|            0|            0|  0.00%|
   193|         0|            0|            0|  0.00%|    return ret
   194|         0|            0|            0|  0.00%|
   195|        36|  0.000153065|   4.2518e-06|  0.00%|def _var(a, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *,
   196|         0|            0|            0|  0.00%|         where=True):
   197|        36|  0.000139952|  3.88755e-06|  0.00%|    arr = asanyarray(a)
   198|         0|            0|            0|  0.00%|
   199|        36|  0.000347853|  9.66258e-06|  0.00%|    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
(call)|        36|   0.00108361|  3.01003e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/_methods.py:66 _count_reduce_items
   200|         0|            0|            0|  0.00%|    # Make this warning show up on top.
   201|        36|  0.000156641|  4.35114e-06|  0.00%|    if ddof >= rcount if where is True else umr_any(ddof >= rcount, axis=None):
   202|         0|            0|            0|  0.00%|        warnings.warn("Degrees of freedom <= 0 for slice", RuntimeWarning,
   203|         0|            0|            0|  0.00%|                      stacklevel=2)
   204|         0|            0|            0|  0.00%|
   205|         0|            0|            0|  0.00%|    # Cast bool, unsigned int, and int to float64 by default
   206|        36|  0.000165224|  4.58956e-06|  0.00%|    if dtype is None and issubclass(arr.dtype.type, (nt.integer, nt.bool_)):
   207|         0|            0|            0|  0.00%|        dtype = mu.dtype('f8')
   208|         0|            0|            0|  0.00%|
   209|         0|            0|            0|  0.00%|    # Compute the mean.
   210|         0|            0|            0|  0.00%|    # Note that if dtype is not of inexact type then arraymean will
   211|         0|            0|            0|  0.00%|    # not be either.
   212|        36|  0.000441313|  1.22587e-05|  0.00%|    arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)
   213|         0|            0|            0|  0.00%|    # The shape of rcount has to match arrmean to not change the shape of out
   214|         0|            0|            0|  0.00%|    # in broadcasting. Otherwise, it cannot be stored back to arrmean.
   215|        36|  0.000130653|  3.62926e-06|  0.00%|    if rcount.ndim == 0:
   216|         0|            0|            0|  0.00%|        # fast-path for default case when where is True
   217|        36|  0.000115633|  3.21203e-06|  0.00%|        div = rcount
   218|         0|            0|            0|  0.00%|    else:
   219|         0|            0|            0|  0.00%|        # matching rcount to arrmean when where is specified as array
   220|         0|            0|            0|  0.00%|        div = rcount.reshape(arrmean.shape)
   221|        36|  0.000128508|  3.56966e-06|  0.00%|    if isinstance(arrmean, mu.ndarray):
   222|        72|  0.000632048|  8.77844e-06|  0.00%|        arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',
   223|        36|  9.89437e-05|  2.74844e-06|  0.00%|                                 subok=False)
   224|         0|            0|            0|  0.00%|    elif hasattr(arrmean, "dtype"):
   225|         0|            0|            0|  0.00%|        arrmean = arrmean.dtype.type(arrmean / rcount)
   226|         0|            0|            0|  0.00%|    else:
   227|         0|            0|            0|  0.00%|        arrmean = arrmean / rcount
   228|         0|            0|            0|  0.00%|
   229|         0|            0|            0|  0.00%|    # Compute sum of squared deviations from mean
   230|         0|            0|            0|  0.00%|    # Note that x may not be inexact and that we need it to be an array,
   231|         0|            0|            0|  0.00%|    # not a scalar.
   232|        36|  0.000293255|  8.14597e-06|  0.00%|    x = asanyarray(arr - arrmean)
   233|         0|            0|            0|  0.00%|
   234|        36|  0.000144005|  4.00013e-06|  0.00%|    if issubclass(arr.dtype.type, (nt.floating, nt.integer)):
   235|        36|  0.000254393|  7.06646e-06|  0.00%|        x = um.multiply(x, x, out=x)
   236|         0|            0|            0|  0.00%|    # Fast-paths for built-in complex types
   237|         0|            0|            0|  0.00%|    elif x.dtype in _complex_to_float:
   238|         0|            0|            0|  0.00%|        xv = x.view(dtype=(_complex_to_float[x.dtype], (2,)))
   239|         0|            0|            0|  0.00%|        um.multiply(xv, xv, out=xv)
   240|         0|            0|            0|  0.00%|        x = um.add(xv[..., 0], xv[..., 1], out=x.real).real
   241|         0|            0|            0|  0.00%|    # Most general case; includes handling object arrays containing imaginary
   242|         0|            0|            0|  0.00%|    # numbers and complex types with non-native byteorder
   243|         0|            0|            0|  0.00%|    else:
   244|         0|            0|            0|  0.00%|        x = um.multiply(x, um.conjugate(x), out=x).real
   245|         0|            0|            0|  0.00%|
   246|        36|  0.000245571|  6.82142e-06|  0.00%|    ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)
   247|         0|            0|            0|  0.00%|
   248|         0|            0|            0|  0.00%|    # Compute degrees of freedom and make sure it is not negative.
   249|        36|  0.000472307|  1.31196e-05|  0.00%|    rcount = um.maximum(rcount - ddof, 0)
   250|         0|            0|            0|  0.00%|
   251|         0|            0|            0|  0.00%|    # divide by degrees of freedom
   252|        36|  0.000148296|  4.11934e-06|  0.00%|    if isinstance(ret, mu.ndarray):
   253|         0|            0|            0|  0.00%|        ret = um.true_divide(
   254|         0|            0|            0|  0.00%|                ret, rcount, out=ret, casting='unsafe', subok=False)
   255|        36|  0.000124931|  3.47031e-06|  0.00%|    elif hasattr(ret, 'dtype'):
   256|        36|   0.00037694|  1.04705e-05|  0.00%|        ret = ret.dtype.type(ret / rcount)
   257|         0|            0|            0|  0.00%|    else:
   258|         0|            0|            0|  0.00%|        ret = ret / rcount
   259|         0|            0|            0|  0.00%|
   260|        36|  0.000139713|  3.88092e-06|  0.00%|    return ret
   261|         0|            0|            0|  0.00%|
   262|         0|            0|            0|  0.00%|def _std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *,
   263|         0|            0|            0|  0.00%|         where=True):
   264|         0|            0|            0|  0.00%|    ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,
   265|         0|            0|            0|  0.00%|               keepdims=keepdims, where=where)
   266|         0|            0|            0|  0.00%|
   267|         0|            0|            0|  0.00%|    if isinstance(ret, mu.ndarray):
   268|         0|            0|            0|  0.00%|        ret = um.sqrt(ret, out=ret)
   269|         0|            0|            0|  0.00%|    elif hasattr(ret, 'dtype'):
   270|         0|            0|            0|  0.00%|        ret = ret.dtype.type(um.sqrt(ret))
   271|         0|            0|            0|  0.00%|    else:
   272|         0|            0|            0|  0.00%|        ret = um.sqrt(ret)
   273|         0|            0|            0|  0.00%|
   274|         0|            0|            0|  0.00%|    return ret
   275|         0|            0|            0|  0.00%|
   276|         0|            0|            0|  0.00%|def _ptp(a, axis=None, out=None, keepdims=False):
   277|         0|            0|            0|  0.00%|    return um.subtract(
   278|         0|            0|            0|  0.00%|        umr_maximum(a, axis, None, out, keepdims),
   279|         0|            0|            0|  0.00%|        umr_minimum(a, axis, None, None, keepdims),
   280|         0|            0|            0|  0.00%|        out
   281|         0|            0|            0|  0.00%|    )
   282|         0|            0|            0|  0.00%|
   283|         0|            0|            0|  0.00%|def _dump(self, file, protocol=2):
   284|         0|            0|            0|  0.00%|    if hasattr(file, 'write'):
   285|         0|            0|            0|  0.00%|        ctx = nullcontext(file)
   286|         0|            0|            0|  0.00%|    else:
   287|         0|            0|            0|  0.00%|        ctx = open(os_fspath(file), "wb")
   288|         0|            0|            0|  0.00%|    with ctx as f:
   289|         0|            0|            0|  0.00%|        pickle.dump(self, f, protocol=protocol)
   290|         0|            0|            0|  0.00%|
   291|         0|            0|            0|  0.00%|def _dumps(self, protocol=2):
   292|         0|            0|            0|  0.00%|    return pickle.dumps(self, protocol=protocol)
File: /apps/open_spiel/open_spiel/python/pytorch/ppo.py
File duration: 2.31475s (2.22%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|# Note: code adapted (with permission) from https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/ppo.py and https://github.com/vwxyzjn/ppo-implementation-details/blob/main/ppo_atari.py
     2|         0|            0|            0|  0.00%|
     3|         0|            0|            0|  0.00%|import time
     4|         0|            0|            0|  0.00%|
     5|         0|            0|            0|  0.00%|import numpy as np
     6|         0|            0|            0|  0.00%|import torch
     7|         0|            0|            0|  0.00%|import torch.nn as nn
     8|         0|            0|            0|  0.00%|import torch.optim as optim
     9|         0|            0|            0|  0.00%|from torch.distributions.categorical import Categorical
    10|         0|            0|            0|  0.00%|
    11|         0|            0|            0|  0.00%|from open_spiel.python.rl_agent import StepOutput
    12|         0|            0|            0|  0.00%|
    13|         0|            0|            0|  0.00%|INVALID_ACTION_PENALTY = -1e6
    14|         0|            0|            0|  0.00%|def layer_init(layer, std=np.sqrt(2), bias_const=0.0):
    15|         0|            0|            0|  0.00%|    torch.nn.init.orthogonal_(layer.weight, std)
    16|         0|            0|            0|  0.00%|    torch.nn.init.constant_(layer.bias, bias_const)
    17|         0|            0|            0|  0.00%|    return layer
    18|         0|            0|            0|  0.00%|
    19|         0|            0|            0|  0.00%|class CategoricalMasked(Categorical):
    20|      2610|   0.00641704|  2.45863e-06|  0.01%|    def __init__(self, probs=None, logits=None, validate_args=None, masks=[], mask_value=None):
    21|      2610|    0.0482233|  1.84763e-05|  0.05%|        logits = torch.where(masks.bool(), logits, mask_value)
    22|      2610|    0.0289536|  1.10933e-05|  0.03%|        super(CategoricalMasked, self).__init__(probs, logits, validate_args)
(call)|      2610|     0.754652|  0.000289139|  0.72%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/categorical.py:49 __init__
    23|         0|            0|            0|  0.00%|
    24|         0|            0|            0|  0.00%|class PPOAgent(nn.Module):
    25|         0|            0|            0|  0.00%|    def __init__(self, num_actions, observation_shape, device):
    26|         0|            0|            0|  0.00%|        super().__init__()
    27|         0|            0|            0|  0.00%|        self.critic = nn.Sequential(
    28|         0|            0|            0|  0.00%|            layer_init(nn.Linear(np.array(observation_shape).prod(), 64)),
    29|         0|            0|            0|  0.00%|            nn.Tanh(),
    30|         0|            0|            0|  0.00%|            layer_init(nn.Linear(64, 64)),
    31|         0|            0|            0|  0.00%|            nn.Tanh(),
    32|         0|            0|            0|  0.00%|            layer_init(nn.Linear(64, 1), std=1.0),
    33|         0|            0|            0|  0.00%|        )
    34|         0|            0|            0|  0.00%|        self.actor = nn.Sequential(
    35|         0|            0|            0|  0.00%|            layer_init(nn.Linear(np.array(observation_shape).prod(), 64)),
    36|         0|            0|            0|  0.00%|            nn.Tanh(),
    37|         0|            0|            0|  0.00%|            layer_init(nn.Linear(64, 64)),
    38|         0|            0|            0|  0.00%|            nn.Tanh(),
    39|         0|            0|            0|  0.00%|            layer_init(nn.Linear(64, num_actions), std=0.01),
    40|         0|            0|            0|  0.00%|        )
    41|         0|            0|            0|  0.00%|        self.device = device
    42|         0|            0|            0|  0.00%|        self.num_actions = num_actions
    43|         0|            0|            0|  0.00%|        self.register_buffer("mask_value", torch.tensor(INVALID_ACTION_PENALTY))
    44|         0|            0|            0|  0.00%|
    45|        18|  2.90871e-05|  1.61595e-06|  0.00%|    def get_value(self, x):
    46|        18|  0.000249147|  1.38415e-05|  0.00%|        return self.critic(x)
(call)|        18|   0.00035882|  1.99344e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194 __getattr__
(call)|        18|   0.00850272|  0.000472373|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1124 _call_impl
    47|         0|            0|            0|  0.00%|
    48|      2610|   0.00621653|  2.38181e-06|  0.01%|    def get_action_and_value(self, x, legal_actions_mask=None, action=None):
    49|      2610|   0.00634384|  2.43059e-06|  0.01%|        if legal_actions_mask is None:
    50|         0|            0|            0|  0.00%|            legal_actions_mask = torch.ones((len(x), self.num_actions)).bool()
    51|         0|            0|            0|  0.00%|
    52|      2610|    0.0405116|  1.55217e-05|  0.04%|        logits = self.actor(x)
(call)|      2610|    0.0556247|  2.13122e-05|  0.05%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194 __getattr__
(call)|      2610|      1.32071|   0.00050602|  1.27%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1124 _call_impl
    53|      2610|    0.0728765|   2.7922e-05|  0.07%|        if torch.isnan(logits).any():
    54|         0|            0|            0|  0.00%|            raise ValueError("Training is messed up - logits are NaN")
    55|         0|            0|            0|  0.00%|
    56|      2610|    0.0485265|  1.85925e-05|  0.05%|        probs = CategoricalMasked(logits=logits, masks=legal_actions_mask, mask_value=self.mask_value)
(call)|      2610|    0.0501595|  1.92182e-05|  0.05%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194 __getattr__
(call)|      2610|     0.838245|  0.000321167|  0.80%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:20 __init__
    57|      2610|   0.00673985|  2.58232e-06|  0.01%|        if action is None:
    58|      2304|    0.0211234|  9.16815e-06|  0.02%|            action = probs.sample()
(call)|      2304|     0.323711|  0.000140499|  0.31%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/categorical.py:112 sample
    59|      2610|    0.0803447|  3.07834e-05|  0.08%|        return action, probs.log_prob(action), probs.entropy(), self.critic(x), probs.probs
(call)|      2610|     0.598071|  0.000229146|  0.57%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/categorical.py:119 log_prob
(call)|      2610|     0.162954|  6.24345e-05|  0.16%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/categorical.py:127 entropy
(call)|      2610|    0.0820956|  3.14543e-05|  0.08%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194 __getattr__
(call)|      2610|      1.27189|  0.000487315|  1.22%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1124 _call_impl
    60|         0|            0|            0|  0.00%|
    61|         0|            0|            0|  0.00%|
    62|         0|            0|            0|  0.00%|class PPOAtariAgent(nn.Module):
    63|         0|            0|            0|  0.00%|    def __init__(self, num_actions, observation_shape, device):
    64|         0|            0|            0|  0.00%|        super(PPOAtariAgent, self).__init__()
    65|         0|            0|            0|  0.00%|        # Note: this network is intended for atari games, taken from https://github.com/vwxyzjn/ppo-implementation-details/blob/main/ppo_atari.py
    66|         0|            0|            0|  0.00%|        self.network = nn.Sequential(
    67|         0|            0|            0|  0.00%|            layer_init(nn.Conv2d(4, 32, 8, stride=4)),
    68|         0|            0|            0|  0.00%|            nn.ReLU(),
    69|         0|            0|            0|  0.00%|            layer_init(nn.Conv2d(32, 64, 4, stride=2)),
    70|         0|            0|            0|  0.00%|            nn.ReLU(),
    71|         0|            0|            0|  0.00%|            layer_init(nn.Conv2d(64, 64, 3, stride=1)),
    72|         0|            0|            0|  0.00%|            nn.ReLU(),
    73|         0|            0|            0|  0.00%|            nn.Flatten(),
    74|         0|            0|            0|  0.00%|            layer_init(nn.Linear(64 * 7 * 7, 512)),
    75|         0|            0|            0|  0.00%|            nn.ReLU(),
    76|         0|            0|            0|  0.00%|        )
    77|         0|            0|            0|  0.00%|        self.actor = layer_init(nn.Linear(512, num_actions), std=0.01)
    78|         0|            0|            0|  0.00%|        self.critic = layer_init(nn.Linear(512, 1), std=1)
    79|         0|            0|            0|  0.00%|        self.num_actions = num_actions
    80|         0|            0|            0|  0.00%|        self.device = device
    81|         0|            0|            0|  0.00%|        self.register_buffer("mask_value", torch.tensor(INVALID_ACTION_PENALTY))
    82|         0|            0|            0|  0.00%|
    83|         0|            0|            0|  0.00%|    def get_value(self, x):
    84|         0|            0|            0|  0.00%|        return self.critic(self.network(x / 255.0))
    85|         0|            0|            0|  0.00%|
    86|         0|            0|            0|  0.00%|    def get_action_and_value(self, x, legal_actions_mask=None, action=None):
    87|         0|            0|            0|  0.00%|        if legal_actions_mask is None:
    88|         0|            0|            0|  0.00%|            legal_actions_mask = torch.ones((len(x), self.num_actions)).bool()
    89|         0|            0|            0|  0.00%|
    90|         0|            0|            0|  0.00%|        hidden = self.network(x / 255.0)
    91|         0|            0|            0|  0.00%|        logits = self.actor(hidden)
    92|         0|            0|            0|  0.00%|        probs = CategoricalMasked(logits=logits, masks=legal_actions_mask, mask_value=self.mask_value)
    93|         0|            0|            0|  0.00%|
    94|         0|            0|            0|  0.00%|        if action is None:
    95|         0|            0|            0|  0.00%|            action = probs.sample()
    96|         0|            0|            0|  0.00%|        return action, probs.log_prob(action), probs.entropy(), self.critic(hidden), probs.probs
    97|         0|            0|            0|  0.00%|
    98|      2304|   0.00713968|  3.09882e-06|  0.01%|def legal_actions_to_mask(legal_actions_list, num_actions):
    99|         0|            0|            0|  0.00%|    '''Convert a list of legal actions to a mask of size num actions with a 1 in a legal position'''
   100|      2304|    0.0314915|  1.36682e-05|  0.03%|    legal_actions_mask = torch.zeros((len(legal_actions_list), num_actions), dtype=torch.bool)
   101|     20736|    0.0498955|  2.40623e-06|  0.05%|    for i, legal_actions in enumerate(legal_actions_list):
   102|     18432|     0.296649|  1.60942e-05|  0.28%|        legal_actions_mask[i, legal_actions] = 1
   103|      2304|   0.00398278|  1.72864e-06|  0.00%|    return legal_actions_mask
   104|         0|            0|            0|  0.00%|
   105|         0|            0|            0|  0.00%|class PPO(nn.Module):
   106|         0|            0|            0|  0.00%|    """PPO Agent implementation in PyTorch.
   107|         0|            0|            0|  0.00%|
   108|         0|            0|            0|  0.00%|    See open_spiel/python/examples/ppo_example.py for an usage example.
   109|         0|            0|            0|  0.00%|
   110|         0|            0|            0|  0.00%|    Note that PPO runs multiple environments concurrently on each step (see
   111|         0|            0|            0|  0.00%|    open_spiel/python/vector_env.py). In practice, this tends to improve PPO's
   112|         0|            0|            0|  0.00%|    performance. The number of parallel environments is controlled by the
   113|         0|            0|            0|  0.00%|    num_envs argument.
   114|         0|            0|            0|  0.00%|    """
   115|         0|            0|            0|  0.00%|    def __init__(
   116|         0|            0|            0|  0.00%|        self,
   117|         0|            0|            0|  0.00%|        input_shape,
   118|         0|            0|            0|  0.00%|        num_actions,
   119|         0|            0|            0|  0.00%|        num_players,
   120|         0|            0|            0|  0.00%|        player_id=0,
   121|         0|            0|            0|  0.00%|        num_envs=1,
   122|         0|            0|            0|  0.00%|        steps_per_batch=128,
   123|         0|            0|            0|  0.00%|        num_minibatches=4,
   124|         0|            0|            0|  0.00%|        update_epochs=4,
   125|         0|            0|            0|  0.00%|        learning_rate=2.5e-4,
   126|         0|            0|            0|  0.00%|        num_annealing_updates=None,
   127|         0|            0|            0|  0.00%|        gae=True,
   128|         0|            0|            0|  0.00%|        gamma=0.99,
   129|         0|            0|            0|  0.00%|        gae_lambda=0.95,
   130|         0|            0|            0|  0.00%|        normalize_advantages=True,
   131|         0|            0|            0|  0.00%|        clip_coef=0.2,
   132|         0|            0|            0|  0.00%|        clip_vloss=True,
   133|         0|            0|            0|  0.00%|        entropy_coef=0.01,
   134|         0|            0|            0|  0.00%|        value_coef=0.5,
   135|         0|            0|            0|  0.00%|        max_grad_norm=0.5,
   136|         0|            0|            0|  0.00%|        target_kl=None,
   137|         0|            0|            0|  0.00%|        device='cpu',
   138|         0|            0|            0|  0.00%|        writer=None, # Tensorboard SummaryWriter
   139|         0|            0|            0|  0.00%|        use_wandb=True,
   140|         0|            0|            0|  0.00%|        agent_fn=PPOAtariAgent,
   141|         0|            0|            0|  0.00%|        ):
   142|         0|            0|            0|  0.00%|        super().__init__()
   143|         0|            0|            0|  0.00%|
   144|         0|            0|            0|  0.00%|        if isinstance(agent_fn, str):
   145|         0|            0|            0|  0.00%|            if agent_fn == 'PPOAgent':
   146|         0|            0|            0|  0.00%|                agent_fn = PPOAgent
   147|         0|            0|            0|  0.00%|            else:
   148|         0|            0|            0|  0.00%|                raise ValueError(f"Unknown agent_fn {agent_fn}")
   149|         0|            0|            0|  0.00%|
   150|         0|            0|            0|  0.00%|        self.input_shape = input_shape
   151|         0|            0|            0|  0.00%|        self.num_actions = num_actions
   152|         0|            0|            0|  0.00%|        self.num_players = num_players
   153|         0|            0|            0|  0.00%|        self.player_id = player_id
   154|         0|            0|            0|  0.00%|        self.device = device
   155|         0|            0|            0|  0.00%|
   156|         0|            0|            0|  0.00%|        # Training settings
   157|         0|            0|            0|  0.00%|        self.num_envs = num_envs
   158|         0|            0|            0|  0.00%|        self.steps_per_batch = steps_per_batch
   159|         0|            0|            0|  0.00%|        self.batch_size = self.num_envs * self.steps_per_batch
   160|         0|            0|            0|  0.00%|        self.num_minibatches = num_minibatches
   161|         0|            0|            0|  0.00%|        self.minibatch_size = self.batch_size // self.num_minibatches
   162|         0|            0|            0|  0.00%|        self.update_epochs = update_epochs
   163|         0|            0|            0|  0.00%|        self.learning_rate = learning_rate
   164|         0|            0|            0|  0.00%|        self.num_annealing_updates = num_annealing_updates
   165|         0|            0|            0|  0.00%|
   166|         0|            0|            0|  0.00%|        # Loss function
   167|         0|            0|            0|  0.00%|        self.gae = gae
   168|         0|            0|            0|  0.00%|        self.gamma = gamma
   169|         0|            0|            0|  0.00%|        self.gae_lambda = gae_lambda
   170|         0|            0|            0|  0.00%|        self.normalize_advantages = normalize_advantages
   171|         0|            0|            0|  0.00%|        self.clip_coef = clip_coef
   172|         0|            0|            0|  0.00%|        self.clip_vloss = clip_vloss
   173|         0|            0|            0|  0.00%|        self.entropy_coef = entropy_coef
   174|         0|            0|            0|  0.00%|        self.value_coef = value_coef
   175|         0|            0|            0|  0.00%|        self.max_grad_norm = max_grad_norm
   176|         0|            0|            0|  0.00%|        self.target_kl = target_kl
   177|         0|            0|            0|  0.00%|
   178|         0|            0|            0|  0.00%|        # Logging
   179|         0|            0|            0|  0.00%|        self.writer = writer
   180|         0|            0|            0|  0.00%|        self.use_wandb = use_wandb
   181|         0|            0|            0|  0.00%|        self.watch_output = None
   182|         0|            0|            0|  0.00%|
   183|         0|            0|            0|  0.00%|        # Initialize networks
   184|         0|            0|            0|  0.00%|        self.network = agent_fn(self.num_actions, self.input_shape, device).to(device)
   185|         0|            0|            0|  0.00%|        self.optimizer = optim.Adam(self.parameters(), lr=self.learning_rate, eps=1e-5)
   186|         0|            0|            0|  0.00%|
   187|         0|            0|            0|  0.00%|        # Initialize training buffers
   188|         0|            0|            0|  0.00%|        self.legal_actions_mask = torch.zeros((self.steps_per_batch, self.num_envs, self.num_actions), dtype=torch.bool).to(device)
   189|         0|            0|            0|  0.00%|        self.obs = torch.zeros((self.steps_per_batch, self.num_envs) + self.input_shape).to(device)
   190|         0|            0|            0|  0.00%|        self.actions = torch.zeros((self.steps_per_batch, self.num_envs)).to(device)
   191|         0|            0|            0|  0.00%|        self.probs = torch.zeros((self.steps_per_batch, self.num_envs, self.num_actions)).to(device)
   192|         0|            0|            0|  0.00%|        self.logprobs = torch.zeros((self.steps_per_batch, self.num_envs)).to(device)
   193|         0|            0|            0|  0.00%|        self.rewards = torch.zeros((self.steps_per_batch, self.num_envs)).to(device)
   194|         0|            0|            0|  0.00%|        self.dones = torch.zeros((self.steps_per_batch, self.num_envs)).to(device)
   195|         0|            0|            0|  0.00%|        self.values = torch.zeros((self.steps_per_batch, self.num_envs)).to(device)
   196|         0|            0|            0|  0.00%|
   197|         0|            0|            0|  0.00%|        # Initialize counters
   198|         0|            0|            0|  0.00%|        self.cur_batch_idx = 0
   199|         0|            0|            0|  0.00%|        self.total_steps_done = 0
   200|         0|            0|            0|  0.00%|        self.updates_done = 0
   201|         0|            0|            0|  0.00%|        self.start_time = time.time()
   202|         0|            0|            0|  0.00%|
   203|         0|            0|            0|  0.00%|        self.max_policy_diff = 9999
   204|         0|            0|            0|  0.00%|
   205|         0|            0|            0|  0.00%|        self._savers = [
   206|         0|            0|            0|  0.00%|            ("ppo_network", self.network),
   207|         0|            0|            0|  0.00%|        ]
   208|         0|            0|            0|  0.00%|
   209|        18|  4.52995e-05|  2.51664e-06|  0.00%|    def get_value(self, x):
   210|        18|  0.000247002|  1.37223e-05|  0.00%|        return self.network.get_value(x)
(call)|        18|  0.000424862|  2.36034e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194 __getattr__
(call)|        18|   0.00913978|  0.000507765|  0.01%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:45 get_value
   211|         0|            0|            0|  0.00%|
   212|      2610|   0.00748968|  2.86961e-06|  0.01%|    def get_action_and_value(self, x, legal_actions_mask=None, action=None):
   213|      2610|    0.0456209|  1.74793e-05|  0.04%|        return self.network.get_action_and_value(x, legal_actions_mask, action)
(call)|      2610|    0.0641136|  2.45646e-05|  0.06%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194 __getattr__
(call)|      2610|      4.98615|    0.0019104|  4.78%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:48 get_action_and_value
   214|         0|            0|            0|  0.00%|
   215|      2304|    0.0130637|     5.67e-06|  0.01%|    def step(self, time_step, is_evaluation=False):
   216|      2304|    0.0105643|  4.58521e-06|  0.01%|        if is_evaluation:
   217|         0|            0|            0|  0.00%|            singular_env = False
   218|         0|            0|            0|  0.00%|            if not isinstance(time_step, list):
   219|         0|            0|            0|  0.00%|                time_step = [time_step]
   220|         0|            0|            0|  0.00%|                singular_env = True
   221|         0|            0|            0|  0.00%|
   222|         0|            0|            0|  0.00%|            with torch.no_grad():
   223|         0|            0|            0|  0.00%|                legal_actions_mask = legal_actions_to_mask(
   224|         0|            0|            0|  0.00%|                    [ts.observations['legal_actions'][self.player_id] for ts in time_step], self.num_actions
   225|         0|            0|            0|  0.00%|                ).to(self.device)
   226|         0|            0|            0|  0.00%|                obs = torch.Tensor(np.array([ts.observations['info_state'][self.player_id] for ts in time_step])).to(self.device)
   227|         0|            0|            0|  0.00%|                action, log_prob, entropy, value, probs = self.get_action_and_value(obs, legal_actions_mask=legal_actions_mask)
   228|         0|            0|            0|  0.00%|                probs = probs.cpu().numpy()
   229|         0|            0|            0|  0.00%|                if singular_env:
   230|         0|            0|            0|  0.00%|                    return StepOutput(action=action[0].item(), probs=probs[0])
   231|         0|            0|            0|  0.00%|                else:
   232|         0|            0|            0|  0.00%|                    return [StepOutput(action=a.item(), probs=p) for (a, p) in zip(action, probs)]
   233|         0|            0|            0|  0.00%|        else:
   234|      2304|    0.0390401|  1.69445e-05|  0.04%|            with torch.no_grad():
(call)|      2304|     0.043797|  1.90091e-05|  0.04%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:126 __init__
(call)|      2304|    0.0456982|  1.98343e-05|  0.04%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:131 __enter__
   235|         0|            0|            0|  0.00%|                # act
   236|     25344|     0.186996|  7.37833e-06|  0.18%|                obs = torch.Tensor(np.array([ts.observations['info_state'][self.player_id] for ts in time_step])).to(self.device)
(call)|      2304|    0.0457766|  1.98683e-05|  0.04%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:236 <listcomp>
   237|      6912|    0.0535674|  7.74991e-06|  0.05%|                legal_actions_mask = legal_actions_to_mask(
(call)|      2304|     0.389158|  0.000168906|  0.37%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:98 legal_actions_to_mask
   238|     25344|    0.0675709|  2.66615e-06|  0.06%|                    [ts.observations['legal_actions'][self.player_id] for ts in time_step], self.num_actions
(call)|      2304|    0.0433762|  1.88265e-05|  0.04%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:238 <listcomp>
   239|      2304|   0.00970864|  4.21382e-06|  0.01%|                ).to(self.device)
   240|      2304|    0.0308313|  1.33817e-05|  0.03%|                action, logprob, _, value, probs = self.get_action_and_value(obs, legal_actions_mask=legal_actions_mask)
(call)|      2304|       4.3965|    0.0019082|  4.21%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:212 get_action_and_value
   241|         0|            0|            0|  0.00%|
   242|         0|            0|            0|  0.00%|                # store
   243|      2304|    0.0318398|  1.38194e-05|  0.03%|                self.legal_actions_mask[self.cur_batch_idx] = legal_actions_mask
   244|      2304|     0.022872|  9.92707e-06|  0.02%|                self.obs[self.cur_batch_idx] = obs
   245|      2304|    0.0211844|  9.19464e-06|  0.02%|                self.actions[self.cur_batch_idx] = action
   246|      2304|    0.0193176|  8.38439e-06|  0.02%|                self.probs[self.cur_batch_idx] = probs
   247|      2304|    0.0190518|  8.26901e-06|  0.02%|                self.logprobs[self.cur_batch_idx] = logprob
   248|      2304|    0.0344214|  1.49399e-05|  0.03%|                self.values[self.cur_batch_idx] = value.flatten()
   249|         0|            0|            0|  0.00%|
   250|     25344|     0.223145|  8.80466e-06|  0.21%|                agent_output = [StepOutput(action=a.item(), probs=p) for (a, p) in zip(action, probs)]
(call)|      4608|     0.103196|  2.23949e-05|  0.10%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:713 __iter__
(call)|     18432|    0.0727186|  3.94524e-06|  0.07%|# <string>_0:1 __new__
(call)|      2304|     0.233068|  0.000101158|  0.22%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:250 <listcomp>
   251|      2304|    0.0256238|  1.11214e-05|  0.02%|                return agent_output
(call)|      2304|    0.0471902|  2.04819e-05|  0.05%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:135 __exit__
   252|         0|            0|            0|  0.00%|
   253|         0|            0|            0|  0.00%|
   254|      2304|   0.00524521|  2.27657e-06|  0.01%|    def post_step(self, reward, done):
   255|      2304|    0.0754266|  3.27372e-05|  0.07%|        self.rewards[self.cur_batch_idx] = torch.tensor(reward).to(self.device).view(-1)
   256|      2304|    0.0481501|  2.08985e-05|  0.05%|        self.dones[self.cur_batch_idx] = torch.tensor(done).to(self.device).view(-1)
   257|         0|            0|            0|  0.00%|
   258|      2304|    0.0226221|  9.81862e-06|  0.02%|        self.total_steps_done += self.num_envs
(call)|      2304|     0.106713|  4.63164e-05|  0.10%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1210 __setattr__
   259|      2304|    0.0177774|   7.7159e-06|  0.02%|        self.cur_batch_idx += 1
(call)|      2304|    0.0882816|  3.83167e-05|  0.08%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1210 __setattr__
   260|         0|            0|            0|  0.00%|
   261|         0|            0|            0|  0.00%|
   262|        18|  0.000227213|  1.26229e-05|  0.00%|    def learn(self, time_step):
   263|        18|  0.000182629|   1.0146e-05|  0.00%|        if self.use_wandb and self.watch_output is None:
   264|         0|            0|            0|  0.00%|            pass # Honestly, this hasn't been super useful and takes up a lot of log bandwidth, but uncomment to watch the weights in wandb
   265|         0|            0|            0|  0.00%|            # import wandb
   266|         0|            0|            0|  0.00%|            # wandb.watch(self, log_freq=5)
   267|         0|            0|            0|  0.00%|
   268|       198|   0.00143743|  7.25973e-06|  0.00%|        next_obs = torch.Tensor(np.array([ts.observations['info_state'][self.player_id] for ts in time_step])).to(self.device)
(call)|        18|  0.000366211|  2.03451e-05|  0.00%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:268 <listcomp>
   269|         0|            0|            0|  0.00%|
   270|         0|            0|            0|  0.00%|        # Annealing the rate if instructed to do so.
   271|        18|  0.000189543|  1.05302e-05|  0.00%|        if self.num_annealing_updates is not None:
   272|         0|            0|            0|  0.00%|            frac = 1.0 - (self.updates_done) / self.num_annealing_updates
   273|         0|            0|            0|  0.00%|            lrnow = frac * self.learning_rate
   274|         0|            0|            0|  0.00%|            self.optimizer.param_groups[0]["lr"] = lrnow
   275|         0|            0|            0|  0.00%|
   276|         0|            0|            0|  0.00%|        # bootstrap value if not done
   277|        18|  0.000450373|  2.50207e-05|  0.00%|        with torch.no_grad():
(call)|        18|  0.000373363|  2.07424e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:126 __init__
(call)|        18|  0.000414848|  2.30471e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:131 __enter__
   278|        18|  0.000475883|   2.6438e-05|  0.00%|            next_value = self.get_value(next_obs).reshape(1, -1)
(call)|        18|   0.00985694|  0.000547608|  0.01%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:209 get_value
   279|        18|  0.000210524|  1.16958e-05|  0.00%|            if self.gae:
   280|        18|   0.00044775|   2.4875e-05|  0.00%|                advantages = torch.zeros_like(self.rewards).to(self.device)
   281|        18|  0.000205517|  1.14176e-05|  0.00%|                lastgaelam = 0
   282|      2322|    0.0219121|  9.43673e-06|  0.02%|                for t in reversed(range(self.steps_per_batch)):
   283|      2304|    0.0261877|  1.13662e-05|  0.03%|                    nextvalues = next_value if t == self.steps_per_batch - 1 else self.values[t + 1]
   284|      2304|    0.0402367|  1.74639e-05|  0.04%|                    nextnonterminal = 1.0 - self.dones[t]
(call)|      2304|    0.0562232|  2.44024e-05|  0.05%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:26 wrapped
   285|      2304|    0.0750303|  3.25652e-05|  0.07%|                    delta = self.rewards[t] + self.gamma * nextvalues * nextnonterminal - self.values[t]
   286|      2304|    0.0677412|  2.94015e-05|  0.06%|                    advantages[t] = lastgaelam = delta + self.gamma * self.gae_lambda * nextnonterminal * lastgaelam
   287|        18|   0.00185132|  0.000102851|  0.00%|                returns = advantages + self.values
(call)|        18|  0.000431061|  2.39478e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:135 __exit__
   288|         0|            0|            0|  0.00%|            else:
   289|         0|            0|            0|  0.00%|                returns = torch.zeros_like(self.rewards).to(self.device)
   290|         0|            0|            0|  0.00%|                for t in reversed(range(self.steps_per_batch)):
   291|         0|            0|            0|  0.00%|                    next_return = next_value if t == self.steps_per_batch - 1 else returns[t + 1]
   292|         0|            0|            0|  0.00%|                    nextnonterminal = 1.0 - self.dones[t]
   293|         0|            0|            0|  0.00%|                    returns[t] = self.rewards[t] + self.gamma * nextnonterminal * next_return
   294|         0|            0|            0|  0.00%|                advantages = returns - self.values
   295|         0|            0|            0|  0.00%|
   296|         0|            0|            0|  0.00%|        # flatten the batch
   297|        18|  0.000310659|  1.72589e-05|  0.00%|        b_legal_actions_mask = self.legal_actions_mask.reshape((-1, self.num_actions))
   298|        18|   0.00022459|  1.24772e-05|  0.00%|        b_obs = self.obs.reshape((-1,) + self.input_shape)
   299|        18|  0.000215292|  1.19607e-05|  0.00%|        b_logprobs = self.logprobs.reshape(-1)
   300|        18|  0.000210047|  1.16693e-05|  0.00%|        b_actions = self.actions.reshape(-1)
   301|        18|  0.000211716|   1.1762e-05|  0.00%|        b_probs = self.probs.reshape((-1, self.num_actions))
   302|        18|  0.000203133|  1.12851e-05|  0.00%|        b_advantages = advantages.reshape(-1)
   303|        18|  0.000202417|  1.12454e-05|  0.00%|        b_returns = returns.reshape(-1)
   304|        18|  0.000200033|   1.1113e-05|  0.00%|        b_values = self.values.reshape(-1)
   305|         0|            0|            0|  0.00%|
   306|         0|            0|            0|  0.00%|        # Optimizing the policy and value network
   307|        18|  0.000296116|  1.64509e-05|  0.00%|        b_inds = np.arange(self.batch_size)
   308|        18|  0.000153065|   8.5036e-06|  0.00%|        clipfracs = []
   309|        90|  0.000620127|   6.8903e-06|  0.00%|        for epoch in range(self.update_epochs):
   310|        72|   0.00256133|   3.5574e-05|  0.00%|            np.random.shuffle(b_inds)
   311|       360|   0.00265455|  7.37376e-06|  0.00%|            for start in range(0, self.batch_size, self.minibatch_size):
   312|       288|   0.00192881|  6.69724e-06|  0.00%|                end = start + self.minibatch_size
   313|       288|   0.00222969|  7.74198e-06|  0.00%|                mb_inds = b_inds[start:end]
   314|         0|            0|            0|  0.00%|
   315|       288|     0.039108|  0.000135792|  0.04%|                _, newlogprob, entropy, newvalue, _ = self.get_action_and_value(b_obs[mb_inds], legal_actions_mask=b_legal_actions_mask[mb_inds], action=b_actions.long()[mb_inds])
(call)|       288|     0.650351|   0.00225816|  0.62%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:212 get_action_and_value
   316|       288|    0.0137148|  4.76208e-05|  0.01%|                logratio = newlogprob - b_logprobs[mb_inds]
   317|       288|   0.00565219|  1.96257e-05|  0.01%|                ratio = logratio.exp()
   318|         0|            0|            0|  0.00%|
   319|       288|   0.00656867|  2.28079e-05|  0.01%|                with torch.no_grad():
(call)|       288|   0.00662136|  2.29908e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:126 __init__
(call)|       288|   0.00635409|  2.20628e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:131 __enter__
   320|         0|            0|            0|  0.00%|                    # calculate approx_kl http://joschu.net/blog/kl-approx.html
   321|       288|    0.0107083|  3.71817e-05|  0.01%|                    old_approx_kl = (-logratio).mean()
   322|       288|    0.0105956|  3.67901e-05|  0.01%|                    approx_kl = ((ratio - 1) - logratio).mean()
   323|       288|     0.019428|  6.74584e-05|  0.02%|                    clipfracs += [((ratio - 1.0).abs() > self.clip_coef).float().mean().item()]
(call)|       288|   0.00652242|  2.26473e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:135 __exit__
   324|         0|            0|            0|  0.00%|
   325|       288|   0.00834513|  2.89761e-05|  0.01%|                mb_advantages = b_advantages[mb_inds]
   326|       288|   0.00212145|  7.36614e-06|  0.00%|                if self.normalize_advantages:
   327|       288|    0.0172703|  5.99664e-05|  0.02%|                    mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)
   328|         0|            0|            0|  0.00%|
   329|         0|            0|            0|  0.00%|                # Policy loss
   330|       288|   0.00662589|  2.30066e-05|  0.01%|                pg_loss1 = -mb_advantages * ratio
   331|       288|   0.00820112|  2.84761e-05|  0.01%|                pg_loss2 = -mb_advantages * torch.clamp(ratio, 1 - self.clip_coef, 1 + self.clip_coef)
   332|       288|   0.00909543|  3.15814e-05|  0.01%|                pg_loss = torch.max(pg_loss1, pg_loss2).mean()
   333|         0|            0|            0|  0.00%|
   334|         0|            0|            0|  0.00%|                # Value loss
   335|       288|   0.00408316|  1.41776e-05|  0.00%|                newvalue = newvalue.view(-1)
   336|       288|   0.00191092|  6.63516e-06|  0.00%|                if self.clip_vloss:
   337|       288|    0.0129373|  4.49212e-05|  0.01%|                    v_loss_unclipped = (newvalue - b_returns[mb_inds]) ** 2
(call)|       288|   0.00686049|  2.38212e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:26 wrapped
   338|       576|     0.013238|  2.29826e-05|  0.01%|                    v_clipped = b_values[mb_inds] + torch.clamp(
   339|       288|   0.00747776|  2.59644e-05|  0.01%|                        newvalue - b_values[mb_inds],
   340|       288|   0.00210238|  7.29991e-06|  0.00%|                        -self.clip_coef,
   341|       288|   0.00175428|  6.09126e-06|  0.00%|                        self.clip_coef,
   342|         0|            0|            0|  0.00%|                    )
   343|       288|     0.010601|  3.68092e-05|  0.01%|                    v_loss_clipped = (v_clipped - b_returns[mb_inds]) ** 2
(call)|       288|   0.00585365|  2.03252e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:26 wrapped
   344|       288|   0.00433517|  1.50527e-05|  0.00%|                    v_loss_max = torch.max(v_loss_unclipped, v_loss_clipped)
   345|       288|    0.0107284|  3.72512e-05|  0.01%|                    v_loss = 0.5 * v_loss_max.mean()
   346|         0|            0|            0|  0.00%|                else:
   347|         0|            0|            0|  0.00%|                    v_loss = 0.5 * ((newvalue - b_returns[mb_inds]) ** 2).mean()
   348|         0|            0|            0|  0.00%|
   349|       288|   0.00592446|  2.05711e-05|  0.01%|                entropy_loss = entropy.mean()
   350|       288|    0.0170569|  5.92255e-05|  0.02%|                loss = pg_loss - self.entropy_coef * entropy_loss + v_loss * self.value_coef
   351|         0|            0|            0|  0.00%|
   352|       288|   0.00487685|  1.69335e-05|  0.00%|                self.optimizer.zero_grad()
(call)|       288|     0.216123|  0.000750427|  0.21%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/optim/optimizer.py:216 zero_grad
   353|       288|   0.00618196|  2.14651e-05|  0.01%|                loss.backward()
(call)|       288|     0.343829|   0.00119385|  0.33%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:340 backward
   354|       288|   0.00765228|  2.65704e-05|  0.01%|                nn.utils.clip_grad_norm_(self.parameters(), self.max_grad_norm)
(call)|       288|     0.936374|    0.0032513|  0.90%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py:9 clip_grad_norm_
   355|       288|   0.00545931|  1.89559e-05|  0.01%|                self.optimizer.step()
(call)|       288|     0.772531|    0.0026824|  0.74%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/optim/optimizer.py:108 wrapper
   356|         0|            0|            0|  0.00%|
   357|        72|  0.000466824|  6.48366e-06|  0.00%|            if self.target_kl is not None:
   358|         0|            0|            0|  0.00%|                if approx_kl > self.target_kl:
   359|         0|            0|            0|  0.00%|                    break
   360|         0|            0|            0|  0.00%|
   361|        18|  0.000237465|  1.31925e-05|  0.00%|        y_pred, y_true = b_values.cpu().numpy(), b_returns.cpu().numpy()
   362|        18|  0.000285625|  1.58681e-05|  0.00%|        var_y = np.var(y_true)
(call)|        18|   0.00468826|  0.000260459|  0.00%|# <__array_function__ internals>:177 var
   363|        18|  0.000526667|  2.92593e-05|  0.00%|        explained_var = np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y
(call)|        18|   0.00338054|  0.000187808|  0.00%|# <__array_function__ internals>:177 var
   364|         0|            0|            0|  0.00%|
   365|         0|            0|            0|  0.00%|        # compute L_\infty change in probabilities
   366|         0|            0|            0|  0.00%|        # TODO: split into minibatches?
   367|        18|  0.000824451|  4.58029e-05|  0.00%|        _, _, _, _, new_probs = self.get_action_and_value(b_obs, legal_actions_mask=b_legal_actions_mask, action=b_actions.long())
(call)|        18|    0.0565174|   0.00313985|  0.05%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:212 get_action_and_value
   368|        18|   0.00163794|  9.09964e-05|  0.00%|        self.max_policy_diff = (new_probs - b_probs).abs().max().item()
(call)|        18|   0.00109863|  6.10352e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1210 __setattr__
   369|         0|            0|            0|  0.00%|
   370|         0|            0|            0|  0.00%|        # TRY NOT TO MODIFY: record rewards for plotting purposes
   371|        18|  0.000123978|  6.88765e-06|  0.00%|        if self.writer is not None:
   372|         0|            0|            0|  0.00%|            self.writer.add_scalar("charts/learning_rate", self.optimizer.param_groups[0]["lr"], self.total_steps_done)
   373|         0|            0|            0|  0.00%|            self.writer.add_scalar("losses/value_loss", v_loss.item(), self.total_steps_done)
   374|         0|            0|            0|  0.00%|            self.writer.add_scalar("losses/policy_loss", pg_loss.item(), self.total_steps_done)
   375|         0|            0|            0|  0.00%|            self.writer.add_scalar("losses/entropy", entropy_loss.item(), self.total_steps_done)
   376|         0|            0|            0|  0.00%|            self.writer.add_scalar("losses/old_approx_kl", old_approx_kl.item(), self.total_steps_done)
   377|         0|            0|            0|  0.00%|            self.writer.add_scalar("losses/approx_kl", approx_kl.item(), self.total_steps_done)
   378|         0|            0|            0|  0.00%|            self.writer.add_scalar("losses/clipfrac", np.mean(clipfracs), self.total_steps_done)
   379|         0|            0|            0|  0.00%|            self.writer.add_scalar("losses/explained_variance", explained_var, self.total_steps_done)
   380|         0|            0|            0|  0.00%|            self.writer.add_scalar("charts/SPS", int(self.total_steps_done / (time.time() - self.start_time)), self.total_steps_done)
   381|         0|            0|            0|  0.00%|
   382|        18|   0.00011301|  6.27836e-06|  0.00%|        if self.use_wandb:
   383|         0|            0|            0|  0.00%|            import wandb
   384|         0|            0|            0|  0.00%|            prefix = f'network_{self.player_id}'
   385|         0|            0|            0|  0.00%|            wandb.log({
   386|         0|            0|            0|  0.00%|                f"{prefix}/learning_rate": self.optimizer.param_groups[0]["lr"],
   387|         0|            0|            0|  0.00%|                f"{prefix}/value_loss": v_loss.item(),
   388|         0|            0|            0|  0.00%|                f"{prefix}/policy_loss": pg_loss.item(),
   389|         0|            0|            0|  0.00%|                f"{prefix}/entropy": entropy_loss.item(),
   390|         0|            0|            0|  0.00%|                f"{prefix}/old_approx_kl": old_approx_kl.item(),
   391|         0|            0|            0|  0.00%|                f"{prefix}/approx_kl": approx_kl.item(),
   392|         0|            0|            0|  0.00%|                f"{prefix}/clipfrac": np.mean(clipfracs),
   393|         0|            0|            0|  0.00%|                f"{prefix}/explained_variance": explained_var,
   394|         0|            0|            0|  0.00%|                f"{prefix}/SPS": int(self.total_steps_done / (time.time() - self.start_time)), # TODO: This is a bit silly if you do anything like an inline eval
   395|         0|            0|            0|  0.00%|                f"{prefix}/total_steps_done": self.total_steps_done,
   396|         0|            0|            0|  0.00%|                f"{prefix}/updates_done": self.updates_done,
   397|         0|            0|            0|  0.00%|                f"{prefix}/max_policy_diff": self.max_policy_diff,
   398|         0|            0|            0|  0.00%|            }, commit=False)
   399|         0|            0|            0|  0.00%|
   400|         0|            0|            0|  0.00%|        # Update counters
   401|        18|  0.000254154|  1.41197e-05|  0.00%|        self.updates_done += 1
(call)|        18|  0.000783682|  4.35379e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1210 __setattr__
   402|        18|  0.000241518|  1.34177e-05|  0.00%|        self.cur_batch_idx = 0
(call)|        18|  0.000761032|  4.22796e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1210 __setattr__
   403|         0|            0|            0|  0.00%|
   404|         2|  5.00679e-06|   2.5034e-06|  0.00%|    def save(self):
   405|         2|  7.62939e-06|   3.8147e-06|  0.00%|        restore_dict = dict()
   406|         4|  1.04904e-05|   2.6226e-06|  0.00%|        for name, model in self._savers:
   407|         2|  1.69277e-05|  8.46386e-06|  0.00%|            restore_dict[name] = model.state_dict()
(call)|         2|   0.00168085|  0.000840425|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1316 state_dict
   408|         2|  3.57628e-06|  1.78814e-06|  0.00%|        return restore_dict
   409|         0|            0|            0|  0.00%|
   410|         0|            0|            0|  0.00%|    def restore(self, restore_dict):
   411|         0|            0|            0|  0.00%|        for name, model in self._savers:
   412|         0|            0|            0|  0.00%|            model.load_state_dict(restore_dict[name])
   413|         0|            0|            0|  0.00%|
   414|        18|  5.22137e-05|  2.90076e-06|  0.00%|    def get_max_policy_diff(self):
   415|        18|  4.72069e-05|   2.6226e-06|  0.00%|        return self.max_policy_diff
   416|         0|            0|            0|  0.00%|
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py
File duration: 2.30828s (2.21%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|from collections import OrderedDict, namedtuple
     2|         0|            0|            0|  0.00%|import itertools
     3|         0|            0|            0|  0.00%|import warnings
     4|         0|            0|            0|  0.00%|import functools
     5|         0|            0|            0|  0.00%|
     6|         0|            0|            0|  0.00%|import torch
     7|         0|            0|            0|  0.00%|from ..parameter import Parameter
     8|         0|            0|            0|  0.00%|import torch.utils.hooks as hooks
     9|         0|            0|            0|  0.00%|
    10|         0|            0|            0|  0.00%|from torch import Tensor, device, dtype
    11|         0|            0|            0|  0.00%|from typing import Union, Tuple, Any, Callable, Iterator, Set, Optional, overload, TypeVar, Mapping, Dict, List
    12|         0|            0|            0|  0.00%|from ...utils.hooks import RemovableHandle
    13|         0|            0|            0|  0.00%|
    14|         0|            0|            0|  0.00%|_grad_t = Union[Tuple[Tensor, ...], Tensor]
    15|         0|            0|            0|  0.00%|# See https://mypy.readthedocs.io/en/latest/generics.html#generic-methods-and-generic-self for the use
    16|         0|            0|            0|  0.00%|# of `T` to annotate `self`. Many methods of `Module` return `self` and we want those return values to be
    17|         0|            0|            0|  0.00%|# the type of the subclass, not the looser type of `Module`.
    18|         0|            0|            0|  0.00%|T = TypeVar('T', bound='Module')
    19|         0|            0|            0|  0.00%|
    20|         0|            0|            0|  0.00%|class _IncompatibleKeys(namedtuple('IncompatibleKeys', ['missing_keys', 'unexpected_keys'])):
    21|         0|            0|            0|  0.00%|    def __repr__(self):
    22|         0|            0|            0|  0.00%|        if not self.missing_keys and not self.unexpected_keys:
    23|         0|            0|            0|  0.00%|            return '<All keys matched successfully>'
    24|         0|            0|            0|  0.00%|        return super(_IncompatibleKeys, self).__repr__()
    25|         0|            0|            0|  0.00%|
    26|         0|            0|            0|  0.00%|    __str__ = __repr__
    27|         0|            0|            0|  0.00%|
    28|         0|            0|            0|  0.00%|
    29|         0|            0|            0|  0.00%|def _addindent(s_, numSpaces):
    30|         0|            0|            0|  0.00%|    s = s_.split('\n')
    31|         0|            0|            0|  0.00%|    # don't do anything for single-line stuff
    32|         0|            0|            0|  0.00%|    if len(s) == 1:
    33|         0|            0|            0|  0.00%|        return s_
    34|         0|            0|            0|  0.00%|    first = s.pop(0)
    35|         0|            0|            0|  0.00%|    s = [(numSpaces * ' ') + line for line in s]
    36|         0|            0|            0|  0.00%|    s = '\n'.join(s)
    37|         0|            0|            0|  0.00%|    s = first + '\n' + s
    38|         0|            0|            0|  0.00%|    return s
    39|         0|            0|            0|  0.00%|
    40|         0|            0|            0|  0.00%|
    41|         0|            0|            0|  0.00%|r"""This tracks hooks common to all modules that are executed before/after
    42|         0|            0|            0|  0.00%|calling forward and backward. This is global state used for debugging/profiling
    43|         0|            0|            0|  0.00%|purposes"""
    44|         0|            0|            0|  0.00%|_global_backward_hooks: Dict[int, Callable] = OrderedDict()
    45|         0|            0|            0|  0.00%|_global_is_full_backward_hook: Optional[bool] = None
    46|         0|            0|            0|  0.00%|_global_forward_pre_hooks: Dict[int, Callable] = OrderedDict()
    47|         0|            0|            0|  0.00%|_global_forward_hooks: Dict[int, Callable] = OrderedDict()
    48|         0|            0|            0|  0.00%|
    49|         0|            0|            0|  0.00%|_EXTRA_STATE_KEY_SUFFIX = '_extra_state'
    50|         0|            0|            0|  0.00%|
    51|         0|            0|            0|  0.00%|
    52|         0|            0|            0|  0.00%|def register_module_forward_pre_hook(hook: Callable[..., None]) -> RemovableHandle:
    53|         0|            0|            0|  0.00%|    r"""Registers a forward pre-hook common to all modules.
    54|         0|            0|            0|  0.00%|
    55|         0|            0|            0|  0.00%|    .. warning ::
    56|         0|            0|            0|  0.00%|
    57|         0|            0|            0|  0.00%|        This adds global state to the `nn.module` module
    58|         0|            0|            0|  0.00%|        and it is only intended for debugging/profiling purposes.
    59|         0|            0|            0|  0.00%|
    60|         0|            0|            0|  0.00%|    The hook will be called every time before :func:`forward` is invoked.
    61|         0|            0|            0|  0.00%|    It should have the following signature::
    62|         0|            0|            0|  0.00%|
    63|         0|            0|            0|  0.00%|        hook(module, input) -> None or modified input
    64|         0|            0|            0|  0.00%|
    65|         0|            0|            0|  0.00%|    The input contains only the positional arguments given to the module.
    66|         0|            0|            0|  0.00%|    Keyword arguments won't be passed to the hooks and only to the ``forward``.
    67|         0|            0|            0|  0.00%|    The hook can modify the input. User can either return a tuple or a
    68|         0|            0|            0|  0.00%|    single modified value in the hook. We will wrap the value into a tuple
    69|         0|            0|            0|  0.00%|    if a single value is returned(unless that value is already a tuple).
    70|         0|            0|            0|  0.00%|
    71|         0|            0|            0|  0.00%|    This hook has precedence over the specific module hooks registered with
    72|         0|            0|            0|  0.00%|    ``register_forward_pre_hook``.
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|    Returns:
    75|         0|            0|            0|  0.00%|        :class:`torch.utils.hooks.RemovableHandle`:
    76|         0|            0|            0|  0.00%|            a handle that can be used to remove the added hook by calling
    77|         0|            0|            0|  0.00%|            ``handle.remove()``
    78|         0|            0|            0|  0.00%|    """
    79|         0|            0|            0|  0.00%|    handle = hooks.RemovableHandle(_global_forward_pre_hooks)
    80|         0|            0|            0|  0.00%|    _global_forward_pre_hooks[handle.id] = hook
    81|         0|            0|            0|  0.00%|    return handle
    82|         0|            0|            0|  0.00%|
    83|         0|            0|            0|  0.00%|
    84|         0|            0|            0|  0.00%|def register_module_forward_hook(hook: Callable[..., None]) -> RemovableHandle:
    85|         0|            0|            0|  0.00%|    r"""Registers a global forward hook for all the modules
    86|         0|            0|            0|  0.00%|
    87|         0|            0|            0|  0.00%|    .. warning ::
    88|         0|            0|            0|  0.00%|
    89|         0|            0|            0|  0.00%|        This adds global state to the `nn.module` module
    90|         0|            0|            0|  0.00%|        and it is only intended for debugging/profiling purposes.
    91|         0|            0|            0|  0.00%|
    92|         0|            0|            0|  0.00%|    The hook will be called every time after :func:`forward` has computed an output.
    93|         0|            0|            0|  0.00%|    It should have the following signature::
    94|         0|            0|            0|  0.00%|
    95|         0|            0|            0|  0.00%|        hook(module, input, output) -> None or modified output
    96|         0|            0|            0|  0.00%|
    97|         0|            0|            0|  0.00%|    The input contains only the positional arguments given to the module.
    98|         0|            0|            0|  0.00%|    Keyword arguments won't be passed to the hooks and only to the ``forward``.
    99|         0|            0|            0|  0.00%|    The hook can modify the output. It can modify the input inplace but
   100|         0|            0|            0|  0.00%|    it will not have effect on forward since this is called after
   101|         0|            0|            0|  0.00%|    :func:`forward` is called.
   102|         0|            0|            0|  0.00%|
   103|         0|            0|            0|  0.00%|    Returns:
   104|         0|            0|            0|  0.00%|        :class:`torch.utils.hooks.RemovableHandle`:
   105|         0|            0|            0|  0.00%|            a handle that can be used to remove the added hook by calling
   106|         0|            0|            0|  0.00%|            ``handle.remove()``
   107|         0|            0|            0|  0.00%|
   108|         0|            0|            0|  0.00%|    This hook will be executed before specific module hooks registered with
   109|         0|            0|            0|  0.00%|    ``register_forward_hook``.
   110|         0|            0|            0|  0.00%|    """
   111|         0|            0|            0|  0.00%|    handle = hooks.RemovableHandle(_global_forward_hooks)
   112|         0|            0|            0|  0.00%|    _global_forward_hooks[handle.id] = hook
   113|         0|            0|            0|  0.00%|    return handle
   114|         0|            0|            0|  0.00%|
   115|         0|            0|            0|  0.00%|def register_module_backward_hook(
   116|         0|            0|            0|  0.00%|    hook: Callable[['Module', _grad_t, _grad_t], Union[None, Tensor]]
   117|         0|            0|            0|  0.00%|) -> RemovableHandle:
   118|         0|            0|            0|  0.00%|    r"""Registers a backward hook common to all the modules.
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|    This function is deprecated in favor of
   121|         0|            0|            0|  0.00%|    :func:`torch.nn.modules.module.register_module_full_backward_hook`
   122|         0|            0|            0|  0.00%|    and the behavior of this function will change in future versions.
   123|         0|            0|            0|  0.00%|
   124|         0|            0|            0|  0.00%|    Returns:
   125|         0|            0|            0|  0.00%|        :class:`torch.utils.hooks.RemovableHandle`:
   126|         0|            0|            0|  0.00%|            a handle that can be used to remove the added hook by calling
   127|         0|            0|            0|  0.00%|            ``handle.remove()``
   128|         0|            0|            0|  0.00%|
   129|         0|            0|            0|  0.00%|    """
   130|         0|            0|            0|  0.00%|    global _global_is_full_backward_hook
   131|         0|            0|            0|  0.00%|    if _global_is_full_backward_hook is True:
   132|         0|            0|            0|  0.00%|        raise RuntimeError("Cannot use both regular backward hooks and full backward hooks as a "
   133|         0|            0|            0|  0.00%|                           "global Module hook. Please use only one of them.")
   134|         0|            0|            0|  0.00%|
   135|         0|            0|            0|  0.00%|    _global_is_full_backward_hook = False
   136|         0|            0|            0|  0.00%|
   137|         0|            0|            0|  0.00%|    handle = hooks.RemovableHandle(_global_backward_hooks)
   138|         0|            0|            0|  0.00%|    _global_backward_hooks[handle.id] = hook
   139|         0|            0|            0|  0.00%|    return handle
   140|         0|            0|            0|  0.00%|
   141|         0|            0|            0|  0.00%|def register_module_full_backward_hook(
   142|         0|            0|            0|  0.00%|    hook: Callable[['Module', _grad_t, _grad_t], Union[None, Tensor]]
   143|         0|            0|            0|  0.00%|) -> RemovableHandle:
   144|         0|            0|            0|  0.00%|    r"""Registers a backward hook common to all the modules.
   145|         0|            0|            0|  0.00%|
   146|         0|            0|            0|  0.00%|    .. warning ::
   147|         0|            0|            0|  0.00%|        This adds global state to the `nn.module` module
   148|         0|            0|            0|  0.00%|        and it is only intended for debugging/profiling purposes.
   149|         0|            0|            0|  0.00%|
   150|         0|            0|            0|  0.00%|    The hook will be called every time the gradients with respect to module
   151|         0|            0|            0|  0.00%|    inputs are computed. The hook should have the following signature::
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|        hook(module, grad_input, grad_output) -> Tensor or None
   154|         0|            0|            0|  0.00%|
   155|         0|            0|            0|  0.00%|    The :attr:`grad_input` and :attr:`grad_output` are tuples. The hook should
   156|         0|            0|            0|  0.00%|    not modify its arguments, but it can optionally return a new gradient with
   157|         0|            0|            0|  0.00%|    respect to the input that will be used in place of :attr:`grad_input` in
   158|         0|            0|            0|  0.00%|    subsequent computations. :attr:`grad_input` will only correspond to the inputs given
   159|         0|            0|            0|  0.00%|    as positional arguments and all kwarg arguments will not appear in the hook. Entries
   160|         0|            0|            0|  0.00%|    in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor
   161|         0|            0|            0|  0.00%|    arguments.
   162|         0|            0|            0|  0.00%|
   163|         0|            0|            0|  0.00%|    For technical reasons, when this hook is applied to a Module, its forward function will
   164|         0|            0|            0|  0.00%|    receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
   165|         0|            0|            0|  0.00%|    of each Tensor returned by the Module's forward function.
   166|         0|            0|            0|  0.00%|
   167|         0|            0|            0|  0.00%|    Global hooks are called before hooks registered with `register_backward_hook`
   168|         0|            0|            0|  0.00%|
   169|         0|            0|            0|  0.00%|    Returns:
   170|         0|            0|            0|  0.00%|        :class:`torch.utils.hooks.RemovableHandle`:
   171|         0|            0|            0|  0.00%|            a handle that can be used to remove the added hook by calling
   172|         0|            0|            0|  0.00%|            ``handle.remove()``
   173|         0|            0|            0|  0.00%|
   174|         0|            0|            0|  0.00%|    """
   175|         0|            0|            0|  0.00%|    global _global_is_full_backward_hook
   176|         0|            0|            0|  0.00%|    if _global_is_full_backward_hook is False:
   177|         0|            0|            0|  0.00%|        raise RuntimeError("Cannot use both regular backward hooks and full backward hooks as a "
   178|         0|            0|            0|  0.00%|                           "global Module hook. Please use only one of them.")
   179|         0|            0|            0|  0.00%|
   180|         0|            0|            0|  0.00%|    _global_is_full_backward_hook = True
   181|         0|            0|            0|  0.00%|
   182|         0|            0|            0|  0.00%|    handle = hooks.RemovableHandle(_global_backward_hooks)
   183|         0|            0|            0|  0.00%|    _global_backward_hooks[handle.id] = hook
   184|         0|            0|            0|  0.00%|    return handle
   185|         0|            0|            0|  0.00%|
   186|         0|            0|            0|  0.00%|
   187|         0|            0|            0|  0.00%|# Trick mypy into not applying contravariance rules to inputs by defining
   188|         0|            0|            0|  0.00%|# forward as a value, rather than a function.  See also
   189|         0|            0|            0|  0.00%|# https://github.com/python/mypy/issues/8795
   190|         0|            0|            0|  0.00%|def _forward_unimplemented(self, *input: Any) -> None:
   191|         0|            0|            0|  0.00%|    r"""Defines the computation performed at every call.
   192|         0|            0|            0|  0.00%|
   193|         0|            0|            0|  0.00%|    Should be overridden by all subclasses.
   194|         0|            0|            0|  0.00%|
   195|         0|            0|            0|  0.00%|    .. note::
   196|         0|            0|            0|  0.00%|        Although the recipe for forward pass needs to be defined within
   197|         0|            0|            0|  0.00%|        this function, one should call the :class:`Module` instance afterwards
   198|         0|            0|            0|  0.00%|        instead of this since the former takes care of running the
   199|         0|            0|            0|  0.00%|        registered hooks while the latter silently ignores them.
   200|         0|            0|            0|  0.00%|    """
   201|         0|            0|            0|  0.00%|    raise NotImplementedError(f"Module [{type(self).__name__}] is missing the required \"forward\" function")
   202|         0|            0|            0|  0.00%|
   203|         0|            0|            0|  0.00%|
   204|         0|            0|            0|  0.00%|class Module:
   205|         0|            0|            0|  0.00%|    r"""Base class for all neural network modules.
   206|         0|            0|            0|  0.00%|
   207|         0|            0|            0|  0.00%|    Your models should also subclass this class.
   208|         0|            0|            0|  0.00%|
   209|         0|            0|            0|  0.00%|    Modules can also contain other Modules, allowing to nest them in
   210|         0|            0|            0|  0.00%|    a tree structure. You can assign the submodules as regular attributes::
   211|         0|            0|            0|  0.00%|
   212|         0|            0|            0|  0.00%|        import torch.nn as nn
   213|         0|            0|            0|  0.00%|        import torch.nn.functional as F
   214|         0|            0|            0|  0.00%|
   215|         0|            0|            0|  0.00%|        class Model(nn.Module):
   216|         0|            0|            0|  0.00%|            def __init__(self):
   217|         0|            0|            0|  0.00%|                super().__init__()
   218|         0|            0|            0|  0.00%|                self.conv1 = nn.Conv2d(1, 20, 5)
   219|         0|            0|            0|  0.00%|                self.conv2 = nn.Conv2d(20, 20, 5)
   220|         0|            0|            0|  0.00%|
   221|         0|            0|            0|  0.00%|            def forward(self, x):
   222|         0|            0|            0|  0.00%|                x = F.relu(self.conv1(x))
   223|         0|            0|            0|  0.00%|                return F.relu(self.conv2(x))
   224|         0|            0|            0|  0.00%|
   225|         0|            0|            0|  0.00%|    Submodules assigned in this way will be registered, and will have their
   226|         0|            0|            0|  0.00%|    parameters converted too when you call :meth:`to`, etc.
   227|         0|            0|            0|  0.00%|
   228|         0|            0|            0|  0.00%|    .. note::
   229|         0|            0|            0|  0.00%|        As per the example above, an ``__init__()`` call to the parent class
   230|         0|            0|            0|  0.00%|        must be made before assignment on the child.
   231|         0|            0|            0|  0.00%|
   232|         0|            0|            0|  0.00%|    :ivar training: Boolean represents whether this module is in training or
   233|         0|            0|            0|  0.00%|                    evaluation mode.
   234|         0|            0|            0|  0.00%|    :vartype training: bool
   235|         0|            0|            0|  0.00%|    """
   236|         0|            0|            0|  0.00%|
   237|         0|            0|            0|  0.00%|    dump_patches: bool = False
   238|         0|            0|            0|  0.00%|
   239|         0|            0|            0|  0.00%|    _version: int = 1
   240|         0|            0|            0|  0.00%|    r"""This allows better BC support for :meth:`load_state_dict`. In
   241|         0|            0|            0|  0.00%|    :meth:`state_dict`, the version number will be saved as in the attribute
   242|         0|            0|            0|  0.00%|    `_metadata` of the returned state dict, and thus pickled. `_metadata` is a
   243|         0|            0|            0|  0.00%|    dictionary with keys that follow the naming convention of state dict. See
   244|         0|            0|            0|  0.00%|    ``_load_from_state_dict`` on how to use this information in loading.
   245|         0|            0|            0|  0.00%|
   246|         0|            0|            0|  0.00%|    If new parameters/buffers are added/removed from a module, this number shall
   247|         0|            0|            0|  0.00%|    be bumped, and the module's `_load_from_state_dict` method can compare the
   248|         0|            0|            0|  0.00%|    version number and do appropriate changes if the state dict is from before
   249|         0|            0|            0|  0.00%|    the change."""
   250|         0|            0|            0|  0.00%|
   251|         0|            0|            0|  0.00%|    training: bool
   252|         0|            0|            0|  0.00%|    _is_full_backward_hook: Optional[bool]
   253|         0|            0|            0|  0.00%|
   254|         0|            0|            0|  0.00%|    def __init__(self) -> None:
   255|         0|            0|            0|  0.00%|        """
   256|         0|            0|            0|  0.00%|        Initializes internal Module state, shared by both nn.Module and ScriptModule.
   257|         0|            0|            0|  0.00%|        """
   258|         0|            0|            0|  0.00%|        torch._C._log_api_usage_once("python.nn_module")
   259|         0|            0|            0|  0.00%|
   260|         0|            0|            0|  0.00%|        self.training = True
   261|         0|            0|            0|  0.00%|        self._parameters: Dict[str, Optional[Parameter]] = OrderedDict()
   262|         0|            0|            0|  0.00%|        self._buffers: Dict[str, Optional[Tensor]] = OrderedDict()
   263|         0|            0|            0|  0.00%|        self._non_persistent_buffers_set: Set[str] = set()
   264|         0|            0|            0|  0.00%|        self._backward_hooks: Dict[int, Callable] = OrderedDict()
   265|         0|            0|            0|  0.00%|        self._is_full_backward_hook = None
   266|         0|            0|            0|  0.00%|        self._forward_hooks: Dict[int, Callable] = OrderedDict()
   267|         0|            0|            0|  0.00%|        self._forward_pre_hooks: Dict[int, Callable] = OrderedDict()
   268|         0|            0|            0|  0.00%|        self._state_dict_hooks: Dict[int, Callable] = OrderedDict()
   269|         0|            0|            0|  0.00%|        self._load_state_dict_pre_hooks: Dict[int, Callable] = OrderedDict()
   270|         0|            0|            0|  0.00%|        self._load_state_dict_post_hooks: Dict[int, Callable] = OrderedDict()
   271|         0|            0|            0|  0.00%|        self._modules: Dict[str, Optional['Module']] = OrderedDict()
   272|         0|            0|            0|  0.00%|
   273|         0|            0|            0|  0.00%|    forward: Callable[..., Any] = _forward_unimplemented
   274|         0|            0|            0|  0.00%|
   275|         0|            0|            0|  0.00%|    def register_buffer(self, name: str, tensor: Optional[Tensor], persistent: bool = True) -> None:
   276|         0|            0|            0|  0.00%|        r"""Adds a buffer to the module.
   277|         0|            0|            0|  0.00%|
   278|         0|            0|            0|  0.00%|        This is typically used to register a buffer that should not to be
   279|         0|            0|            0|  0.00%|        considered a model parameter. For example, BatchNorm's ``running_mean``
   280|         0|            0|            0|  0.00%|        is not a parameter, but is part of the module's state. Buffers, by
   281|         0|            0|            0|  0.00%|        default, are persistent and will be saved alongside parameters. This
   282|         0|            0|            0|  0.00%|        behavior can be changed by setting :attr:`persistent` to ``False``. The
   283|         0|            0|            0|  0.00%|        only difference between a persistent buffer and a non-persistent buffer
   284|         0|            0|            0|  0.00%|        is that the latter will not be a part of this module's
   285|         0|            0|            0|  0.00%|        :attr:`state_dict`.
   286|         0|            0|            0|  0.00%|
   287|         0|            0|            0|  0.00%|        Buffers can be accessed as attributes using given names.
   288|         0|            0|            0|  0.00%|
   289|         0|            0|            0|  0.00%|        Args:
   290|         0|            0|            0|  0.00%|            name (string): name of the buffer. The buffer can be accessed
   291|         0|            0|            0|  0.00%|                from this module using the given name
   292|         0|            0|            0|  0.00%|            tensor (Tensor or None): buffer to be registered. If ``None``, then operations
   293|         0|            0|            0|  0.00%|                that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,
   294|         0|            0|            0|  0.00%|                the buffer is **not** included in the module's :attr:`state_dict`.
   295|         0|            0|            0|  0.00%|            persistent (bool): whether the buffer is part of this module's
   296|         0|            0|            0|  0.00%|                :attr:`state_dict`.
   297|         0|            0|            0|  0.00%|
   298|         0|            0|            0|  0.00%|        Example::
   299|         0|            0|            0|  0.00%|
   300|         0|            0|            0|  0.00%|            >>> self.register_buffer('running_mean', torch.zeros(num_features))
   301|         0|            0|            0|  0.00%|
   302|         0|            0|            0|  0.00%|        """
   303|         0|            0|            0|  0.00%|        if persistent is False and isinstance(self, torch.jit.ScriptModule):
   304|         0|            0|            0|  0.00%|            raise RuntimeError("ScriptModule does not support non-persistent buffers")
   305|         0|            0|            0|  0.00%|
   306|         0|            0|            0|  0.00%|        if '_buffers' not in self.__dict__:
   307|         0|            0|            0|  0.00%|            raise AttributeError(
   308|         0|            0|            0|  0.00%|                "cannot assign buffer before Module.__init__() call")
   309|         0|            0|            0|  0.00%|        elif not isinstance(name, torch._six.string_classes):
   310|         0|            0|            0|  0.00%|            raise TypeError("buffer name should be a string. "
   311|         0|            0|            0|  0.00%|                            "Got {}".format(torch.typename(name)))
   312|         0|            0|            0|  0.00%|        elif '.' in name:
   313|         0|            0|            0|  0.00%|            raise KeyError("buffer name can't contain \".\"")
   314|         0|            0|            0|  0.00%|        elif name == '':
   315|         0|            0|            0|  0.00%|            raise KeyError("buffer name can't be empty string \"\"")
   316|         0|            0|            0|  0.00%|        elif hasattr(self, name) and name not in self._buffers:
   317|         0|            0|            0|  0.00%|            raise KeyError("attribute '{}' already exists".format(name))
   318|         0|            0|            0|  0.00%|        elif tensor is not None and not isinstance(tensor, torch.Tensor):
   319|         0|            0|            0|  0.00%|            raise TypeError("cannot assign '{}' object to buffer '{}' "
   320|         0|            0|            0|  0.00%|                            "(torch Tensor or None required)"
   321|         0|            0|            0|  0.00%|                            .format(torch.typename(tensor), name))
   322|         0|            0|            0|  0.00%|        else:
   323|         0|            0|            0|  0.00%|            self._buffers[name] = tensor
   324|         0|            0|            0|  0.00%|            if persistent:
   325|         0|            0|            0|  0.00%|                self._non_persistent_buffers_set.discard(name)
   326|         0|            0|            0|  0.00%|            else:
   327|         0|            0|            0|  0.00%|                self._non_persistent_buffers_set.add(name)
   328|         0|            0|            0|  0.00%|
   329|         0|            0|            0|  0.00%|    def register_parameter(self, name: str, param: Optional[Parameter]) -> None:
   330|         0|            0|            0|  0.00%|        r"""Adds a parameter to the module.
   331|         0|            0|            0|  0.00%|
   332|         0|            0|            0|  0.00%|        The parameter can be accessed as an attribute using given name.
   333|         0|            0|            0|  0.00%|
   334|         0|            0|            0|  0.00%|        Args:
   335|         0|            0|            0|  0.00%|            name (string): name of the parameter. The parameter can be accessed
   336|         0|            0|            0|  0.00%|                from this module using the given name
   337|         0|            0|            0|  0.00%|            param (Parameter or None): parameter to be added to the module. If
   338|         0|            0|            0|  0.00%|                ``None``, then operations that run on parameters, such as :attr:`cuda`,
   339|         0|            0|            0|  0.00%|                are ignored. If ``None``, the parameter is **not** included in the
   340|         0|            0|            0|  0.00%|                module's :attr:`state_dict`.
   341|         0|            0|            0|  0.00%|        """
   342|         0|            0|            0|  0.00%|        if '_parameters' not in self.__dict__:
   343|         0|            0|            0|  0.00%|            raise AttributeError(
   344|         0|            0|            0|  0.00%|                "cannot assign parameter before Module.__init__() call")
   345|         0|            0|            0|  0.00%|
   346|         0|            0|            0|  0.00%|        elif not isinstance(name, torch._six.string_classes):
   347|         0|            0|            0|  0.00%|            raise TypeError("parameter name should be a string. "
   348|         0|            0|            0|  0.00%|                            "Got {}".format(torch.typename(name)))
   349|         0|            0|            0|  0.00%|        elif '.' in name:
   350|         0|            0|            0|  0.00%|            raise KeyError("parameter name can't contain \".\"")
   351|         0|            0|            0|  0.00%|        elif name == '':
   352|         0|            0|            0|  0.00%|            raise KeyError("parameter name can't be empty string \"\"")
   353|         0|            0|            0|  0.00%|        elif hasattr(self, name) and name not in self._parameters:
   354|         0|            0|            0|  0.00%|            raise KeyError("attribute '{}' already exists".format(name))
   355|         0|            0|            0|  0.00%|
   356|         0|            0|            0|  0.00%|        if param is None:
   357|         0|            0|            0|  0.00%|            self._parameters[name] = None
   358|         0|            0|            0|  0.00%|        elif not isinstance(param, Parameter):
   359|         0|            0|            0|  0.00%|            raise TypeError("cannot assign '{}' object to parameter '{}' "
   360|         0|            0|            0|  0.00%|                            "(torch.nn.Parameter or None required)"
   361|         0|            0|            0|  0.00%|                            .format(torch.typename(param), name))
   362|         0|            0|            0|  0.00%|        elif param.grad_fn:
   363|         0|            0|            0|  0.00%|            raise ValueError(
   364|         0|            0|            0|  0.00%|                "Cannot assign non-leaf Tensor to parameter '{0}'. Model "
   365|         0|            0|            0|  0.00%|                "parameters must be created explicitly. To express '{0}' "
   366|         0|            0|            0|  0.00%|                "as a function of another Tensor, compute the value in "
   367|         0|            0|            0|  0.00%|                "the forward() method.".format(name))
   368|         0|            0|            0|  0.00%|        else:
   369|         0|            0|            0|  0.00%|            self._parameters[name] = param
   370|         0|            0|            0|  0.00%|
   371|         0|            0|            0|  0.00%|    def add_module(self, name: str, module: Optional['Module']) -> None:
   372|         0|            0|            0|  0.00%|        r"""Adds a child module to the current module.
   373|         0|            0|            0|  0.00%|
   374|         0|            0|            0|  0.00%|        The module can be accessed as an attribute using the given name.
   375|         0|            0|            0|  0.00%|
   376|         0|            0|            0|  0.00%|        Args:
   377|         0|            0|            0|  0.00%|            name (string): name of the child module. The child module can be
   378|         0|            0|            0|  0.00%|                accessed from this module using the given name
   379|         0|            0|            0|  0.00%|            module (Module): child module to be added to the module.
   380|         0|            0|            0|  0.00%|        """
   381|         0|            0|            0|  0.00%|        if not isinstance(module, Module) and module is not None:
   382|         0|            0|            0|  0.00%|            raise TypeError("{} is not a Module subclass".format(
   383|         0|            0|            0|  0.00%|                torch.typename(module)))
   384|         0|            0|            0|  0.00%|        elif not isinstance(name, torch._six.string_classes):
   385|         0|            0|            0|  0.00%|            raise TypeError("module name should be a string. Got {}".format(
   386|         0|            0|            0|  0.00%|                torch.typename(name)))
   387|         0|            0|            0|  0.00%|        elif hasattr(self, name) and name not in self._modules:
   388|         0|            0|            0|  0.00%|            raise KeyError("attribute '{}' already exists".format(name))
   389|         0|            0|            0|  0.00%|        elif '.' in name:
   390|         0|            0|            0|  0.00%|            raise KeyError("module name can't contain \".\", got: {}".format(name))
   391|         0|            0|            0|  0.00%|        elif name == '':
   392|         0|            0|            0|  0.00%|            raise KeyError("module name can't be empty string \"\"")
   393|         0|            0|            0|  0.00%|        self._modules[name] = module
   394|         0|            0|            0|  0.00%|
   395|         0|            0|            0|  0.00%|    def register_module(self, name: str, module: Optional['Module']) -> None:
   396|         0|            0|            0|  0.00%|        r"""Alias for :func:`add_module`."""
   397|         0|            0|            0|  0.00%|        self.add_module(name, module)
   398|         0|            0|            0|  0.00%|
   399|         0|            0|            0|  0.00%|    def get_submodule(self, target: str) -> "Module":
   400|         0|            0|            0|  0.00%|        """
   401|         0|            0|            0|  0.00%|        Returns the submodule given by ``target`` if it exists,
   402|         0|            0|            0|  0.00%|        otherwise throws an error.
   403|         0|            0|            0|  0.00%|
   404|         0|            0|            0|  0.00%|        For example, let's say you have an ``nn.Module`` ``A`` that
   405|         0|            0|            0|  0.00%|        looks like this:
   406|         0|            0|            0|  0.00%|
   407|         0|            0|            0|  0.00%|        .. code-block:: text
   408|         0|            0|            0|  0.00%|
   409|         0|            0|            0|  0.00%|            A(
   410|         0|            0|            0|  0.00%|                (net_b): Module(
   411|         0|            0|            0|  0.00%|                    (net_c): Module(
   412|         0|            0|            0|  0.00%|                        (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))
   413|         0|            0|            0|  0.00%|                    )
   414|         0|            0|            0|  0.00%|                    (linear): Linear(in_features=100, out_features=200, bias=True)
   415|         0|            0|            0|  0.00%|                )
   416|         0|            0|            0|  0.00%|            )
   417|         0|            0|            0|  0.00%|
   418|         0|            0|            0|  0.00%|        (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested
   419|         0|            0|            0|  0.00%|        submodule ``net_b``, which itself has two submodules ``net_c``
   420|         0|            0|            0|  0.00%|        and ``linear``. ``net_c`` then has a submodule ``conv``.)
   421|         0|            0|            0|  0.00%|
   422|         0|            0|            0|  0.00%|        To check whether or not we have the ``linear`` submodule, we
   423|         0|            0|            0|  0.00%|        would call ``get_submodule("net_b.linear")``. To check whether
   424|         0|            0|            0|  0.00%|        we have the ``conv`` submodule, we would call
   425|         0|            0|            0|  0.00%|        ``get_submodule("net_b.net_c.conv")``.
   426|         0|            0|            0|  0.00%|
   427|         0|            0|            0|  0.00%|        The runtime of ``get_submodule`` is bounded by the degree
   428|         0|            0|            0|  0.00%|        of module nesting in ``target``. A query against
   429|         0|            0|            0|  0.00%|        ``named_modules`` achieves the same result, but it is O(N) in
   430|         0|            0|            0|  0.00%|        the number of transitive modules. So, for a simple check to see
   431|         0|            0|            0|  0.00%|        if some submodule exists, ``get_submodule`` should always be
   432|         0|            0|            0|  0.00%|        used.
   433|         0|            0|            0|  0.00%|
   434|         0|            0|            0|  0.00%|        Args:
   435|         0|            0|            0|  0.00%|            target: The fully-qualified string name of the submodule
   436|         0|            0|            0|  0.00%|                to look for. (See above example for how to specify a
   437|         0|            0|            0|  0.00%|                fully-qualified string.)
   438|         0|            0|            0|  0.00%|
   439|         0|            0|            0|  0.00%|        Returns:
   440|         0|            0|            0|  0.00%|            torch.nn.Module: The submodule referenced by ``target``
   441|         0|            0|            0|  0.00%|
   442|         0|            0|            0|  0.00%|        Raises:
   443|         0|            0|            0|  0.00%|            AttributeError: If the target string references an invalid
   444|         0|            0|            0|  0.00%|                path or resolves to something that is not an
   445|         0|            0|            0|  0.00%|                ``nn.Module``
   446|         0|            0|            0|  0.00%|        """
   447|         0|            0|            0|  0.00%|        if target == "":
   448|         0|            0|            0|  0.00%|            return self
   449|         0|            0|            0|  0.00%|
   450|         0|            0|            0|  0.00%|        atoms: List[str] = target.split(".")
   451|         0|            0|            0|  0.00%|        mod: torch.nn.Module = self
   452|         0|            0|            0|  0.00%|
   453|         0|            0|            0|  0.00%|        for item in atoms:
   454|         0|            0|            0|  0.00%|
   455|         0|            0|            0|  0.00%|            if not hasattr(mod, item):
   456|         0|            0|            0|  0.00%|                raise AttributeError(mod._get_name() + " has no "
   457|         0|            0|            0|  0.00%|                                     "attribute `" + item + "`")
   458|         0|            0|            0|  0.00%|
   459|         0|            0|            0|  0.00%|            mod = getattr(mod, item)
   460|         0|            0|            0|  0.00%|
   461|         0|            0|            0|  0.00%|            if not isinstance(mod, torch.nn.Module):
   462|         0|            0|            0|  0.00%|                raise AttributeError("`" + item + "` is not "
   463|         0|            0|            0|  0.00%|                                     "an nn.Module")
   464|         0|            0|            0|  0.00%|
   465|         0|            0|            0|  0.00%|        return mod
   466|         0|            0|            0|  0.00%|
   467|         0|            0|            0|  0.00%|    def get_parameter(self, target: str) -> "Parameter":
   468|         0|            0|            0|  0.00%|        """
   469|         0|            0|            0|  0.00%|        Returns the parameter given by ``target`` if it exists,
   470|         0|            0|            0|  0.00%|        otherwise throws an error.
   471|         0|            0|            0|  0.00%|
   472|         0|            0|            0|  0.00%|        See the docstring for ``get_submodule`` for a more detailed
   473|         0|            0|            0|  0.00%|        explanation of this method's functionality as well as how to
   474|         0|            0|            0|  0.00%|        correctly specify ``target``.
   475|         0|            0|            0|  0.00%|
   476|         0|            0|            0|  0.00%|        Args:
   477|         0|            0|            0|  0.00%|            target: The fully-qualified string name of the Parameter
   478|         0|            0|            0|  0.00%|                to look for. (See ``get_submodule`` for how to specify a
   479|         0|            0|            0|  0.00%|                fully-qualified string.)
   480|         0|            0|            0|  0.00%|
   481|         0|            0|            0|  0.00%|        Returns:
   482|         0|            0|            0|  0.00%|            torch.nn.Parameter: The Parameter referenced by ``target``
   483|         0|            0|            0|  0.00%|
   484|         0|            0|            0|  0.00%|        Raises:
   485|         0|            0|            0|  0.00%|            AttributeError: If the target string references an invalid
   486|         0|            0|            0|  0.00%|                path or resolves to something that is not an
   487|         0|            0|            0|  0.00%|                ``nn.Parameter``
   488|         0|            0|            0|  0.00%|        """
   489|         0|            0|            0|  0.00%|        module_path, _, param_name = target.rpartition(".")
   490|         0|            0|            0|  0.00%|
   491|         0|            0|            0|  0.00%|        mod: torch.nn.Module = self.get_submodule(module_path)
   492|         0|            0|            0|  0.00%|
   493|         0|            0|            0|  0.00%|        if not hasattr(mod, param_name):
   494|         0|            0|            0|  0.00%|            raise AttributeError(mod._get_name() + " has no attribute `"
   495|         0|            0|            0|  0.00%|                                 + param_name + "`")
   496|         0|            0|            0|  0.00%|
   497|         0|            0|            0|  0.00%|        param: torch.nn.Parameter = getattr(mod, param_name)
   498|         0|            0|            0|  0.00%|
   499|         0|            0|            0|  0.00%|        if not isinstance(param, torch.nn.Parameter):
   500|         0|            0|            0|  0.00%|            raise AttributeError("`" + param_name + "` is not an "
   501|         0|            0|            0|  0.00%|                                 "nn.Parameter")
   502|         0|            0|            0|  0.00%|
   503|         0|            0|            0|  0.00%|        return param
   504|         0|            0|            0|  0.00%|
   505|         0|            0|            0|  0.00%|    def get_buffer(self, target: str) -> "Tensor":
   506|         0|            0|            0|  0.00%|        """
   507|         0|            0|            0|  0.00%|        Returns the buffer given by ``target`` if it exists,
   508|         0|            0|            0|  0.00%|        otherwise throws an error.
   509|         0|            0|            0|  0.00%|
   510|         0|            0|            0|  0.00%|        See the docstring for ``get_submodule`` for a more detailed
   511|         0|            0|            0|  0.00%|        explanation of this method's functionality as well as how to
   512|         0|            0|            0|  0.00%|        correctly specify ``target``.
   513|         0|            0|            0|  0.00%|
   514|         0|            0|            0|  0.00%|        Args:
   515|         0|            0|            0|  0.00%|            target: The fully-qualified string name of the buffer
   516|         0|            0|            0|  0.00%|                to look for. (See ``get_submodule`` for how to specify a
   517|         0|            0|            0|  0.00%|                fully-qualified string.)
   518|         0|            0|            0|  0.00%|
   519|         0|            0|            0|  0.00%|        Returns:
   520|         0|            0|            0|  0.00%|            torch.Tensor: The buffer referenced by ``target``
   521|         0|            0|            0|  0.00%|
   522|         0|            0|            0|  0.00%|        Raises:
   523|         0|            0|            0|  0.00%|            AttributeError: If the target string references an invalid
   524|         0|            0|            0|  0.00%|                path or resolves to something that is not a
   525|         0|            0|            0|  0.00%|                buffer
   526|         0|            0|            0|  0.00%|        """
   527|         0|            0|            0|  0.00%|        module_path, _, buffer_name = target.rpartition(".")
   528|         0|            0|            0|  0.00%|
   529|         0|            0|            0|  0.00%|        mod: torch.nn.Module = self.get_submodule(module_path)
   530|         0|            0|            0|  0.00%|
   531|         0|            0|            0|  0.00%|        if not hasattr(mod, buffer_name):
   532|         0|            0|            0|  0.00%|            raise AttributeError(mod._get_name() + " has no attribute `"
   533|         0|            0|            0|  0.00%|                                 + buffer_name + "`")
   534|         0|            0|            0|  0.00%|
   535|         0|            0|            0|  0.00%|        buffer: torch.Tensor = getattr(mod, buffer_name)
   536|         0|            0|            0|  0.00%|
   537|         0|            0|            0|  0.00%|        if buffer_name not in mod._buffers:
   538|         0|            0|            0|  0.00%|            raise AttributeError("`" + buffer_name + "` is not a buffer")
   539|         0|            0|            0|  0.00%|
   540|         0|            0|            0|  0.00%|        return buffer
   541|         0|            0|            0|  0.00%|
   542|         0|            0|            0|  0.00%|    def get_extra_state(self) -> Any:
   543|         0|            0|            0|  0.00%|        """
   544|         0|            0|            0|  0.00%|        Returns any extra state to include in the module's state_dict.
   545|         0|            0|            0|  0.00%|        Implement this and a corresponding :func:`set_extra_state` for your module
   546|         0|            0|            0|  0.00%|        if you need to store extra state. This function is called when building the
   547|         0|            0|            0|  0.00%|        module's `state_dict()`.
   548|         0|            0|            0|  0.00%|
   549|         0|            0|            0|  0.00%|        Note that extra state should be pickleable to ensure working serialization
   550|         0|            0|            0|  0.00%|        of the state_dict. We only provide provide backwards compatibility guarantees
   551|         0|            0|            0|  0.00%|        for serializing Tensors; other objects may break backwards compatibility if
   552|         0|            0|            0|  0.00%|        their serialized pickled form changes.
   553|         0|            0|            0|  0.00%|
   554|         0|            0|            0|  0.00%|        Returns:
   555|         0|            0|            0|  0.00%|            object: Any extra state to store in the module's state_dict
   556|         0|            0|            0|  0.00%|        """
   557|         0|            0|            0|  0.00%|        raise RuntimeError(
   558|         0|            0|            0|  0.00%|            "Reached a code path in Module.get_extra_state() that should never be called. "
   559|         0|            0|            0|  0.00%|            "Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.yml "
   560|         0|            0|            0|  0.00%|            "to report this bug.")
   561|         0|            0|            0|  0.00%|
   562|         0|            0|            0|  0.00%|    def set_extra_state(self, state: Any):
   563|         0|            0|            0|  0.00%|        """
   564|         0|            0|            0|  0.00%|        This function is called from :func:`load_state_dict` to handle any extra state
   565|         0|            0|            0|  0.00%|        found within the `state_dict`. Implement this function and a corresponding
   566|         0|            0|            0|  0.00%|        :func:`get_extra_state` for your module if you need to store extra state within its
   567|         0|            0|            0|  0.00%|        `state_dict`.
   568|         0|            0|            0|  0.00%|
   569|         0|            0|            0|  0.00%|        Args:
   570|         0|            0|            0|  0.00%|            state (dict): Extra state from the `state_dict`
   571|         0|            0|            0|  0.00%|        """
   572|         0|            0|            0|  0.00%|        raise RuntimeError(
   573|         0|            0|            0|  0.00%|            "Reached a code path in Module.set_extra_state() that should never be called. "
   574|         0|            0|            0|  0.00%|            "Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.yml "
   575|         0|            0|            0|  0.00%|            "to report this bug.")
   576|         0|            0|            0|  0.00%|
   577|         0|            0|            0|  0.00%|    def _apply(self, fn):
   578|         0|            0|            0|  0.00%|        for module in self.children():
   579|         0|            0|            0|  0.00%|            module._apply(fn)
   580|         0|            0|            0|  0.00%|
   581|         0|            0|            0|  0.00%|        def compute_should_use_set_data(tensor, tensor_applied):
   582|         0|            0|            0|  0.00%|            if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):
   583|         0|            0|            0|  0.00%|                # If the new tensor has compatible tensor type as the existing tensor,
   584|         0|            0|            0|  0.00%|                # the current behavior is to change the tensor in-place using `.data =`,
   585|         0|            0|            0|  0.00%|                # and the future behavior is to overwrite the existing tensor. However,
   586|         0|            0|            0|  0.00%|                # changing the current behavior is a BC-breaking change, and we want it
   587|         0|            0|            0|  0.00%|                # to happen in future releases. So for now we introduce the
   588|         0|            0|            0|  0.00%|                # `torch.__future__.get_overwrite_module_params_on_conversion()`
   589|         0|            0|            0|  0.00%|                # global flag to let the user control whether they want the future
   590|         0|            0|            0|  0.00%|                # behavior of overwriting the existing tensor or not.
   591|         0|            0|            0|  0.00%|                return not torch.__future__.get_overwrite_module_params_on_conversion()
   592|         0|            0|            0|  0.00%|            else:
   593|         0|            0|            0|  0.00%|                return False
   594|         0|            0|            0|  0.00%|
   595|         0|            0|            0|  0.00%|        for key, param in self._parameters.items():
   596|         0|            0|            0|  0.00%|            if param is None:
   597|         0|            0|            0|  0.00%|                continue
   598|         0|            0|            0|  0.00%|            # Tensors stored in modules are graph leaves, and we don't want to
   599|         0|            0|            0|  0.00%|            # track autograd history of `param_applied`, so we have to use
   600|         0|            0|            0|  0.00%|            # `with torch.no_grad():`
   601|         0|            0|            0|  0.00%|            with torch.no_grad():
   602|         0|            0|            0|  0.00%|                param_applied = fn(param)
   603|         0|            0|            0|  0.00%|            should_use_set_data = compute_should_use_set_data(param, param_applied)
   604|         0|            0|            0|  0.00%|            if should_use_set_data:
   605|         0|            0|            0|  0.00%|                param.data = param_applied
   606|         0|            0|            0|  0.00%|                out_param = param
   607|         0|            0|            0|  0.00%|            else:
   608|         0|            0|            0|  0.00%|                assert isinstance(param, Parameter)
   609|         0|            0|            0|  0.00%|                assert param.is_leaf
   610|         0|            0|            0|  0.00%|                out_param = Parameter(param_applied, param.requires_grad)
   611|         0|            0|            0|  0.00%|                self._parameters[key] = out_param
   612|         0|            0|            0|  0.00%|
   613|         0|            0|            0|  0.00%|            if param.grad is not None:
   614|         0|            0|            0|  0.00%|                with torch.no_grad():
   615|         0|            0|            0|  0.00%|                    grad_applied = fn(param.grad)
   616|         0|            0|            0|  0.00%|                should_use_set_data = compute_should_use_set_data(param.grad, grad_applied)
   617|         0|            0|            0|  0.00%|                if should_use_set_data:
   618|         0|            0|            0|  0.00%|                    out_param.grad.data = grad_applied
   619|         0|            0|            0|  0.00%|                else:
   620|         0|            0|            0|  0.00%|                    assert param.grad.is_leaf
   621|         0|            0|            0|  0.00%|                    out_param.grad = grad_applied.requires_grad_(param.grad.requires_grad)
   622|         0|            0|            0|  0.00%|
   623|         0|            0|            0|  0.00%|        for key, buf in self._buffers.items():
   624|         0|            0|            0|  0.00%|            if buf is not None:
   625|         0|            0|            0|  0.00%|                self._buffers[key] = fn(buf)
   626|         0|            0|            0|  0.00%|
   627|         0|            0|            0|  0.00%|        return self
   628|         0|            0|            0|  0.00%|
   629|         0|            0|            0|  0.00%|    def apply(self: T, fn: Callable[['Module'], None]) -> T:
   630|         0|            0|            0|  0.00%|        r"""Applies ``fn`` recursively to every submodule (as returned by ``.children()``)
   631|         0|            0|            0|  0.00%|        as well as self. Typical use includes initializing the parameters of a model
   632|         0|            0|            0|  0.00%|        (see also :ref:`nn-init-doc`).
   633|         0|            0|            0|  0.00%|
   634|         0|            0|            0|  0.00%|        Args:
   635|         0|            0|            0|  0.00%|            fn (:class:`Module` -> None): function to be applied to each submodule
   636|         0|            0|            0|  0.00%|
   637|         0|            0|            0|  0.00%|        Returns:
   638|         0|            0|            0|  0.00%|            Module: self
   639|         0|            0|            0|  0.00%|
   640|         0|            0|            0|  0.00%|        Example::
   641|         0|            0|            0|  0.00%|
   642|         0|            0|            0|  0.00%|            >>> @torch.no_grad()
   643|         0|            0|            0|  0.00%|            >>> def init_weights(m):
   644|         0|            0|            0|  0.00%|            >>>     print(m)
   645|         0|            0|            0|  0.00%|            >>>     if type(m) == nn.Linear:
   646|         0|            0|            0|  0.00%|            >>>         m.weight.fill_(1.0)
   647|         0|            0|            0|  0.00%|            >>>         print(m.weight)
   648|         0|            0|            0|  0.00%|            >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))
   649|         0|            0|            0|  0.00%|            >>> net.apply(init_weights)
   650|         0|            0|            0|  0.00%|            Linear(in_features=2, out_features=2, bias=True)
   651|         0|            0|            0|  0.00%|            Parameter containing:
   652|         0|            0|            0|  0.00%|            tensor([[ 1.,  1.],
   653|         0|            0|            0|  0.00%|                    [ 1.,  1.]])
   654|         0|            0|            0|  0.00%|            Linear(in_features=2, out_features=2, bias=True)
   655|         0|            0|            0|  0.00%|            Parameter containing:
   656|         0|            0|            0|  0.00%|            tensor([[ 1.,  1.],
   657|         0|            0|            0|  0.00%|                    [ 1.,  1.]])
   658|         0|            0|            0|  0.00%|            Sequential(
   659|         0|            0|            0|  0.00%|              (0): Linear(in_features=2, out_features=2, bias=True)
   660|         0|            0|            0|  0.00%|              (1): Linear(in_features=2, out_features=2, bias=True)
   661|         0|            0|            0|  0.00%|            )
   662|         0|            0|            0|  0.00%|            Sequential(
   663|         0|            0|            0|  0.00%|              (0): Linear(in_features=2, out_features=2, bias=True)
   664|         0|            0|            0|  0.00%|              (1): Linear(in_features=2, out_features=2, bias=True)
   665|         0|            0|            0|  0.00%|            )
   666|         0|            0|            0|  0.00%|        """
   667|         0|            0|            0|  0.00%|        for module in self.children():
   668|         0|            0|            0|  0.00%|            module.apply(fn)
   669|         0|            0|            0|  0.00%|        fn(self)
   670|         0|            0|            0|  0.00%|        return self
   671|         0|            0|            0|  0.00%|
   672|         0|            0|            0|  0.00%|    def cuda(self: T, device: Optional[Union[int, device]] = None) -> T:
   673|         0|            0|            0|  0.00%|        r"""Moves all model parameters and buffers to the GPU.
   674|         0|            0|            0|  0.00%|
   675|         0|            0|            0|  0.00%|        This also makes associated parameters and buffers different objects. So
   676|         0|            0|            0|  0.00%|        it should be called before constructing optimizer if the module will
   677|         0|            0|            0|  0.00%|        live on GPU while being optimized.
   678|         0|            0|            0|  0.00%|
   679|         0|            0|            0|  0.00%|        .. note::
   680|         0|            0|            0|  0.00%|            This method modifies the module in-place.
   681|         0|            0|            0|  0.00%|
   682|         0|            0|            0|  0.00%|        Args:
   683|         0|            0|            0|  0.00%|            device (int, optional): if specified, all parameters will be
   684|         0|            0|            0|  0.00%|                copied to that device
   685|         0|            0|            0|  0.00%|
   686|         0|            0|            0|  0.00%|        Returns:
   687|         0|            0|            0|  0.00%|            Module: self
   688|         0|            0|            0|  0.00%|        """
   689|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.cuda(device))
   690|         0|            0|            0|  0.00%|
   691|         0|            0|            0|  0.00%|    def ipu(self: T, device: Optional[Union[int, device]] = None) -> T:
   692|         0|            0|            0|  0.00%|        r"""Moves all model parameters and buffers to the IPU.
   693|         0|            0|            0|  0.00%|
   694|         0|            0|            0|  0.00%|        This also makes associated parameters and buffers different objects. So
   695|         0|            0|            0|  0.00%|        it should be called before constructing optimizer if the module will
   696|         0|            0|            0|  0.00%|        live on IPU while being optimized.
   697|         0|            0|            0|  0.00%|
   698|         0|            0|            0|  0.00%|        .. note::
   699|         0|            0|            0|  0.00%|            This method modifies the module in-place.
   700|         0|            0|            0|  0.00%|
   701|         0|            0|            0|  0.00%|        Arguments:
   702|         0|            0|            0|  0.00%|            device (int, optional): if specified, all parameters will be
   703|         0|            0|            0|  0.00%|                copied to that device
   704|         0|            0|            0|  0.00%|
   705|         0|            0|            0|  0.00%|        Returns:
   706|         0|            0|            0|  0.00%|            Module: self
   707|         0|            0|            0|  0.00%|        """
   708|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.ipu(device))
   709|         0|            0|            0|  0.00%|
   710|         0|            0|            0|  0.00%|    def xpu(self: T, device: Optional[Union[int, device]] = None) -> T:
   711|         0|            0|            0|  0.00%|        r"""Moves all model parameters and buffers to the XPU.
   712|         0|            0|            0|  0.00%|
   713|         0|            0|            0|  0.00%|        This also makes associated parameters and buffers different objects. So
   714|         0|            0|            0|  0.00%|        it should be called before constructing optimizer if the module will
   715|         0|            0|            0|  0.00%|        live on XPU while being optimized.
   716|         0|            0|            0|  0.00%|
   717|         0|            0|            0|  0.00%|        .. note::
   718|         0|            0|            0|  0.00%|            This method modifies the module in-place.
   719|         0|            0|            0|  0.00%|
   720|         0|            0|            0|  0.00%|        Arguments:
   721|         0|            0|            0|  0.00%|            device (int, optional): if specified, all parameters will be
   722|         0|            0|            0|  0.00%|                copied to that device
   723|         0|            0|            0|  0.00%|
   724|         0|            0|            0|  0.00%|        Returns:
   725|         0|            0|            0|  0.00%|            Module: self
   726|         0|            0|            0|  0.00%|        """
   727|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.xpu(device))
   728|         0|            0|            0|  0.00%|
   729|         0|            0|            0|  0.00%|    def cpu(self: T) -> T:
   730|         0|            0|            0|  0.00%|        r"""Moves all model parameters and buffers to the CPU.
   731|         0|            0|            0|  0.00%|
   732|         0|            0|            0|  0.00%|        .. note::
   733|         0|            0|            0|  0.00%|            This method modifies the module in-place.
   734|         0|            0|            0|  0.00%|
   735|         0|            0|            0|  0.00%|        Returns:
   736|         0|            0|            0|  0.00%|            Module: self
   737|         0|            0|            0|  0.00%|        """
   738|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.cpu())
   739|         0|            0|            0|  0.00%|
   740|         0|            0|            0|  0.00%|    def type(self: T, dst_type: Union[dtype, str]) -> T:
   741|         0|            0|            0|  0.00%|        r"""Casts all parameters and buffers to :attr:`dst_type`.
   742|         0|            0|            0|  0.00%|
   743|         0|            0|            0|  0.00%|        .. note::
   744|         0|            0|            0|  0.00%|            This method modifies the module in-place.
   745|         0|            0|            0|  0.00%|
   746|         0|            0|            0|  0.00%|        Args:
   747|         0|            0|            0|  0.00%|            dst_type (type or string): the desired type
   748|         0|            0|            0|  0.00%|
   749|         0|            0|            0|  0.00%|        Returns:
   750|         0|            0|            0|  0.00%|            Module: self
   751|         0|            0|            0|  0.00%|        """
   752|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.type(dst_type))
   753|         0|            0|            0|  0.00%|
   754|         0|            0|            0|  0.00%|    def float(self: T) -> T:
   755|         0|            0|            0|  0.00%|        r"""Casts all floating point parameters and buffers to ``float`` datatype.
   756|         0|            0|            0|  0.00%|
   757|         0|            0|            0|  0.00%|        .. note::
   758|         0|            0|            0|  0.00%|            This method modifies the module in-place.
   759|         0|            0|            0|  0.00%|
   760|         0|            0|            0|  0.00%|        Returns:
   761|         0|            0|            0|  0.00%|            Module: self
   762|         0|            0|            0|  0.00%|        """
   763|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.float() if t.is_floating_point() else t)
   764|         0|            0|            0|  0.00%|
   765|         0|            0|            0|  0.00%|    def double(self: T) -> T:
   766|         0|            0|            0|  0.00%|        r"""Casts all floating point parameters and buffers to ``double`` datatype.
   767|         0|            0|            0|  0.00%|
   768|         0|            0|            0|  0.00%|        .. note::
   769|         0|            0|            0|  0.00%|            This method modifies the module in-place.
   770|         0|            0|            0|  0.00%|
   771|         0|            0|            0|  0.00%|        Returns:
   772|         0|            0|            0|  0.00%|            Module: self
   773|         0|            0|            0|  0.00%|        """
   774|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.double() if t.is_floating_point() else t)
   775|         0|            0|            0|  0.00%|
   776|         0|            0|            0|  0.00%|    def half(self: T) -> T:
   777|         0|            0|            0|  0.00%|        r"""Casts all floating point parameters and buffers to ``half`` datatype.
   778|         0|            0|            0|  0.00%|
   779|         0|            0|            0|  0.00%|        .. note::
   780|         0|            0|            0|  0.00%|            This method modifies the module in-place.
   781|         0|            0|            0|  0.00%|
   782|         0|            0|            0|  0.00%|        Returns:
   783|         0|            0|            0|  0.00%|            Module: self
   784|         0|            0|            0|  0.00%|        """
   785|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.half() if t.is_floating_point() else t)
   786|         0|            0|            0|  0.00%|
   787|         0|            0|            0|  0.00%|    def bfloat16(self: T) -> T:
   788|         0|            0|            0|  0.00%|        r"""Casts all floating point parameters and buffers to ``bfloat16`` datatype.
   789|         0|            0|            0|  0.00%|
   790|         0|            0|            0|  0.00%|        .. note::
   791|         0|            0|            0|  0.00%|            This method modifies the module in-place.
   792|         0|            0|            0|  0.00%|
   793|         0|            0|            0|  0.00%|        Returns:
   794|         0|            0|            0|  0.00%|            Module: self
   795|         0|            0|            0|  0.00%|        """
   796|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.bfloat16() if t.is_floating_point() else t)
   797|         0|            0|            0|  0.00%|
   798|         0|            0|            0|  0.00%|    def to_empty(self: T, *, device: Union[str, device]) -> T:
   799|         0|            0|            0|  0.00%|        r"""Moves the parameters and buffers to the specified device without copying storage.
   800|         0|            0|            0|  0.00%|
   801|         0|            0|            0|  0.00%|        Args:
   802|         0|            0|            0|  0.00%|            device (:class:`torch.device`): The desired device of the parameters
   803|         0|            0|            0|  0.00%|                and buffers in this module.
   804|         0|            0|            0|  0.00%|
   805|         0|            0|            0|  0.00%|        Returns:
   806|         0|            0|            0|  0.00%|            Module: self
   807|         0|            0|            0|  0.00%|        """
   808|         0|            0|            0|  0.00%|        return self._apply(lambda t: torch.empty_like(t, device=device))
   809|         0|            0|            0|  0.00%|
   810|         0|            0|            0|  0.00%|    @overload
   811|         0|            0|            0|  0.00%|    def to(self: T, device: Optional[Union[int, device]] = ..., dtype: Optional[Union[dtype, str]] = ...,
   812|         0|            0|            0|  0.00%|           non_blocking: bool = ...) -> T:
   813|         0|            0|            0|  0.00%|        ...
   814|         0|            0|            0|  0.00%|
   815|         0|            0|            0|  0.00%|    @overload
   816|         0|            0|            0|  0.00%|    def to(self: T, dtype: Union[dtype, str], non_blocking: bool = ...) -> T:
   817|         0|            0|            0|  0.00%|        ...
   818|         0|            0|            0|  0.00%|
   819|         0|            0|            0|  0.00%|    @overload
   820|         0|            0|            0|  0.00%|    def to(self: T, tensor: Tensor, non_blocking: bool = ...) -> T:
   821|         0|            0|            0|  0.00%|        ...
   822|         0|            0|            0|  0.00%|
   823|         0|            0|            0|  0.00%|    def to(self, *args, **kwargs):
   824|         0|            0|            0|  0.00%|        r"""Moves and/or casts the parameters and buffers.
   825|         0|            0|            0|  0.00%|
   826|         0|            0|            0|  0.00%|        This can be called as
   827|         0|            0|            0|  0.00%|
   828|         0|            0|            0|  0.00%|        .. function:: to(device=None, dtype=None, non_blocking=False)
   829|         0|            0|            0|  0.00%|           :noindex:
   830|         0|            0|            0|  0.00%|
   831|         0|            0|            0|  0.00%|        .. function:: to(dtype, non_blocking=False)
   832|         0|            0|            0|  0.00%|           :noindex:
   833|         0|            0|            0|  0.00%|
   834|         0|            0|            0|  0.00%|        .. function:: to(tensor, non_blocking=False)
   835|         0|            0|            0|  0.00%|           :noindex:
   836|         0|            0|            0|  0.00%|
   837|         0|            0|            0|  0.00%|        .. function:: to(memory_format=torch.channels_last)
   838|         0|            0|            0|  0.00%|           :noindex:
   839|         0|            0|            0|  0.00%|
   840|         0|            0|            0|  0.00%|        Its signature is similar to :meth:`torch.Tensor.to`, but only accepts
   841|         0|            0|            0|  0.00%|        floating point or complex :attr:`dtype`\ s. In addition, this method will
   842|         0|            0|            0|  0.00%|        only cast the floating point or complex parameters and buffers to :attr:`dtype`
   843|         0|            0|            0|  0.00%|        (if given). The integral parameters and buffers will be moved
   844|         0|            0|            0|  0.00%|        :attr:`device`, if that is given, but with dtypes unchanged. When
   845|         0|            0|            0|  0.00%|        :attr:`non_blocking` is set, it tries to convert/move asynchronously
   846|         0|            0|            0|  0.00%|        with respect to the host if possible, e.g., moving CPU Tensors with
   847|         0|            0|            0|  0.00%|        pinned memory to CUDA devices.
   848|         0|            0|            0|  0.00%|
   849|         0|            0|            0|  0.00%|        See below for examples.
   850|         0|            0|            0|  0.00%|
   851|         0|            0|            0|  0.00%|        .. note::
   852|         0|            0|            0|  0.00%|            This method modifies the module in-place.
   853|         0|            0|            0|  0.00%|
   854|         0|            0|            0|  0.00%|        Args:
   855|         0|            0|            0|  0.00%|            device (:class:`torch.device`): the desired device of the parameters
   856|         0|            0|            0|  0.00%|                and buffers in this module
   857|         0|            0|            0|  0.00%|            dtype (:class:`torch.dtype`): the desired floating point or complex dtype of
   858|         0|            0|            0|  0.00%|                the parameters and buffers in this module
   859|         0|            0|            0|  0.00%|            tensor (torch.Tensor): Tensor whose dtype and device are the desired
   860|         0|            0|            0|  0.00%|                dtype and device for all parameters and buffers in this module
   861|         0|            0|            0|  0.00%|            memory_format (:class:`torch.memory_format`): the desired memory
   862|         0|            0|            0|  0.00%|                format for 4D parameters and buffers in this module (keyword
   863|         0|            0|            0|  0.00%|                only argument)
   864|         0|            0|            0|  0.00%|
   865|         0|            0|            0|  0.00%|        Returns:
   866|         0|            0|            0|  0.00%|            Module: self
   867|         0|            0|            0|  0.00%|
   868|         0|            0|            0|  0.00%|        Examples::
   869|         0|            0|            0|  0.00%|
   870|         0|            0|            0|  0.00%|            >>> linear = nn.Linear(2, 2)
   871|         0|            0|            0|  0.00%|            >>> linear.weight
   872|         0|            0|            0|  0.00%|            Parameter containing:
   873|         0|            0|            0|  0.00%|            tensor([[ 0.1913, -0.3420],
   874|         0|            0|            0|  0.00%|                    [-0.5113, -0.2325]])
   875|         0|            0|            0|  0.00%|            >>> linear.to(torch.double)
   876|         0|            0|            0|  0.00%|            Linear(in_features=2, out_features=2, bias=True)
   877|         0|            0|            0|  0.00%|            >>> linear.weight
   878|         0|            0|            0|  0.00%|            Parameter containing:
   879|         0|            0|            0|  0.00%|            tensor([[ 0.1913, -0.3420],
   880|         0|            0|            0|  0.00%|                    [-0.5113, -0.2325]], dtype=torch.float64)
   881|         0|            0|            0|  0.00%|            >>> gpu1 = torch.device("cuda:1")
   882|         0|            0|            0|  0.00%|            >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)
   883|         0|            0|            0|  0.00%|            Linear(in_features=2, out_features=2, bias=True)
   884|         0|            0|            0|  0.00%|            >>> linear.weight
   885|         0|            0|            0|  0.00%|            Parameter containing:
   886|         0|            0|            0|  0.00%|            tensor([[ 0.1914, -0.3420],
   887|         0|            0|            0|  0.00%|                    [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')
   888|         0|            0|            0|  0.00%|            >>> cpu = torch.device("cpu")
   889|         0|            0|            0|  0.00%|            >>> linear.to(cpu)
   890|         0|            0|            0|  0.00%|            Linear(in_features=2, out_features=2, bias=True)
   891|         0|            0|            0|  0.00%|            >>> linear.weight
   892|         0|            0|            0|  0.00%|            Parameter containing:
   893|         0|            0|            0|  0.00%|            tensor([[ 0.1914, -0.3420],
   894|         0|            0|            0|  0.00%|                    [-0.5112, -0.2324]], dtype=torch.float16)
   895|         0|            0|            0|  0.00%|
   896|         0|            0|            0|  0.00%|            >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)
   897|         0|            0|            0|  0.00%|            >>> linear.weight
   898|         0|            0|            0|  0.00%|            Parameter containing:
   899|         0|            0|            0|  0.00%|            tensor([[ 0.3741+0.j,  0.2382+0.j],
   900|         0|            0|            0|  0.00%|                    [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)
   901|         0|            0|            0|  0.00%|            >>> linear(torch.ones(3, 2, dtype=torch.cdouble))
   902|         0|            0|            0|  0.00%|            tensor([[0.6122+0.j, 0.1150+0.j],
   903|         0|            0|            0|  0.00%|                    [0.6122+0.j, 0.1150+0.j],
   904|         0|            0|            0|  0.00%|                    [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)
   905|         0|            0|            0|  0.00%|
   906|         0|            0|            0|  0.00%|        """
   907|         0|            0|            0|  0.00%|
   908|         0|            0|            0|  0.00%|        device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)
   909|         0|            0|            0|  0.00%|
   910|         0|            0|            0|  0.00%|        if dtype is not None:
   911|         0|            0|            0|  0.00%|            if not (dtype.is_floating_point or dtype.is_complex):
   912|         0|            0|            0|  0.00%|                raise TypeError('nn.Module.to only accepts floating point or complex '
   913|         0|            0|            0|  0.00%|                                'dtypes, but got desired dtype={}'.format(dtype))
   914|         0|            0|            0|  0.00%|            if dtype.is_complex:
   915|         0|            0|            0|  0.00%|                warnings.warn(
   916|         0|            0|            0|  0.00%|                    "Complex modules are a new feature under active development whose design may change, "
   917|         0|            0|            0|  0.00%|                    "and some modules might not work as expected when using complex tensors as parameters or buffers. "
   918|         0|            0|            0|  0.00%|                    "Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.yml "
   919|         0|            0|            0|  0.00%|                    "if a complex module does not work as expected.")
   920|         0|            0|            0|  0.00%|
   921|         0|            0|            0|  0.00%|        def convert(t):
   922|         0|            0|            0|  0.00%|            if convert_to_format is not None and t.dim() in (4, 5):
   923|         0|            0|            0|  0.00%|                return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,
   924|         0|            0|            0|  0.00%|                            non_blocking, memory_format=convert_to_format)
   925|         0|            0|            0|  0.00%|            return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
   926|         0|            0|            0|  0.00%|
   927|         0|            0|            0|  0.00%|        return self._apply(convert)
   928|         0|            0|            0|  0.00%|
   929|         0|            0|            0|  0.00%|    def register_backward_hook(
   930|         0|            0|            0|  0.00%|        self, hook: Callable[['Module', _grad_t, _grad_t], Union[None, Tensor]]
   931|         0|            0|            0|  0.00%|    ) -> RemovableHandle:
   932|         0|            0|            0|  0.00%|        r"""Registers a backward hook on the module.
   933|         0|            0|            0|  0.00%|
   934|         0|            0|            0|  0.00%|        This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and
   935|         0|            0|            0|  0.00%|        the behavior of this function will change in future versions.
   936|         0|            0|            0|  0.00%|
   937|         0|            0|            0|  0.00%|        Returns:
   938|         0|            0|            0|  0.00%|            :class:`torch.utils.hooks.RemovableHandle`:
   939|         0|            0|            0|  0.00%|                a handle that can be used to remove the added hook by calling
   940|         0|            0|            0|  0.00%|                ``handle.remove()``
   941|         0|            0|            0|  0.00%|
   942|         0|            0|            0|  0.00%|        """
   943|         0|            0|            0|  0.00%|        if self._is_full_backward_hook is True:
   944|         0|            0|            0|  0.00%|            raise RuntimeError("Cannot use both regular backward hooks and full backward hooks on a "
   945|         0|            0|            0|  0.00%|                               "single Module. Please use only one of them.")
   946|         0|            0|            0|  0.00%|
   947|         0|            0|            0|  0.00%|        self._is_full_backward_hook = False
   948|         0|            0|            0|  0.00%|
   949|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._backward_hooks)
   950|         0|            0|            0|  0.00%|        self._backward_hooks[handle.id] = hook
   951|         0|            0|            0|  0.00%|        return handle
   952|         0|            0|            0|  0.00%|
   953|         0|            0|            0|  0.00%|    def register_full_backward_hook(
   954|         0|            0|            0|  0.00%|        self, hook: Callable[['Module', _grad_t, _grad_t], Union[None, Tensor]]
   955|         0|            0|            0|  0.00%|    ) -> RemovableHandle:
   956|         0|            0|            0|  0.00%|        r"""Registers a backward hook on the module.
   957|         0|            0|            0|  0.00%|
   958|         0|            0|            0|  0.00%|        The hook will be called every time the gradients with respect to module
   959|         0|            0|            0|  0.00%|        inputs are computed. The hook should have the following signature::
   960|         0|            0|            0|  0.00%|
   961|         0|            0|            0|  0.00%|            hook(module, grad_input, grad_output) -> tuple(Tensor) or None
   962|         0|            0|            0|  0.00%|
   963|         0|            0|            0|  0.00%|        The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients
   964|         0|            0|            0|  0.00%|        with respect to the inputs and outputs respectively. The hook should
   965|         0|            0|            0|  0.00%|        not modify its arguments, but it can optionally return a new gradient with
   966|         0|            0|            0|  0.00%|        respect to the input that will be used in place of :attr:`grad_input` in
   967|         0|            0|            0|  0.00%|        subsequent computations. :attr:`grad_input` will only correspond to the inputs given
   968|         0|            0|            0|  0.00%|        as positional arguments and all kwarg arguments are ignored. Entries
   969|         0|            0|            0|  0.00%|        in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor
   970|         0|            0|            0|  0.00%|        arguments.
   971|         0|            0|            0|  0.00%|
   972|         0|            0|            0|  0.00%|        For technical reasons, when this hook is applied to a Module, its forward function will
   973|         0|            0|            0|  0.00%|        receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
   974|         0|            0|            0|  0.00%|        of each Tensor returned by the Module's forward function.
   975|         0|            0|            0|  0.00%|
   976|         0|            0|            0|  0.00%|        .. warning ::
   977|         0|            0|            0|  0.00%|            Modifying inputs or outputs inplace is not allowed when using backward hooks and
   978|         0|            0|            0|  0.00%|            will raise an error.
   979|         0|            0|            0|  0.00%|
   980|         0|            0|            0|  0.00%|        Returns:
   981|         0|            0|            0|  0.00%|            :class:`torch.utils.hooks.RemovableHandle`:
   982|         0|            0|            0|  0.00%|                a handle that can be used to remove the added hook by calling
   983|         0|            0|            0|  0.00%|                ``handle.remove()``
   984|         0|            0|            0|  0.00%|
   985|         0|            0|            0|  0.00%|        """
   986|         0|            0|            0|  0.00%|        if self._is_full_backward_hook is False:
   987|         0|            0|            0|  0.00%|            raise RuntimeError("Cannot use both regular backward hooks and full backward hooks on a "
   988|         0|            0|            0|  0.00%|                               "single Module. Please use only one of them.")
   989|         0|            0|            0|  0.00%|
   990|         0|            0|            0|  0.00%|        self._is_full_backward_hook = True
   991|         0|            0|            0|  0.00%|
   992|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._backward_hooks)
   993|         0|            0|            0|  0.00%|        self._backward_hooks[handle.id] = hook
   994|         0|            0|            0|  0.00%|        return handle
   995|         0|            0|            0|  0.00%|
   996|         0|            0|            0|  0.00%|    def _get_backward_hooks(self):
   997|         0|            0|            0|  0.00%|        r"""Returns the backward hooks for use in the call function.
   998|         0|            0|            0|  0.00%|        It returns two lists, one with the full backward hooks and one with the non-full
   999|         0|            0|            0|  0.00%|        backward hooks.
  1000|         0|            0|            0|  0.00%|        """
  1001|         0|            0|            0|  0.00%|        full_backward_hooks: List[Callable] = []
  1002|         0|            0|            0|  0.00%|        if (_global_is_full_backward_hook is True):
  1003|         0|            0|            0|  0.00%|            full_backward_hooks += _global_backward_hooks.values()
  1004|         0|            0|            0|  0.00%|        if (self._is_full_backward_hook is True):
  1005|         0|            0|            0|  0.00%|            full_backward_hooks += self._backward_hooks.values()
  1006|         0|            0|            0|  0.00%|
  1007|         0|            0|            0|  0.00%|        non_full_backward_hooks: List[Callable] = []
  1008|         0|            0|            0|  0.00%|        if (_global_is_full_backward_hook is False):
  1009|         0|            0|            0|  0.00%|            non_full_backward_hooks += _global_backward_hooks.values()
  1010|         0|            0|            0|  0.00%|        if (self._is_full_backward_hook is False):
  1011|         0|            0|            0|  0.00%|            non_full_backward_hooks += self._backward_hooks.values()
  1012|         0|            0|            0|  0.00%|
  1013|         0|            0|            0|  0.00%|        return full_backward_hooks, non_full_backward_hooks
  1014|         0|            0|            0|  0.00%|
  1015|         0|            0|            0|  0.00%|    def _maybe_warn_non_full_backward_hook(self, inputs, result, grad_fn):
  1016|         0|            0|            0|  0.00%|        if not isinstance(result, torch.Tensor):
  1017|         0|            0|            0|  0.00%|            if not (isinstance(result, tuple) and all([isinstance(r, torch.Tensor) for r in result])):
  1018|         0|            0|            0|  0.00%|                warnings.warn("Using non-full backward hooks on a Module that does not return a "
  1019|         0|            0|            0|  0.00%|                              "single Tensor or a tuple of Tensors is deprecated and will be removed "
  1020|         0|            0|            0|  0.00%|                              "in future versions. This hook will be missing some of the grad_output. "
  1021|         0|            0|            0|  0.00%|                              "Please use register_full_backward_hook to get the documented behavior.")
  1022|         0|            0|            0|  0.00%|                return
  1023|         0|            0|            0|  0.00%|        else:
  1024|         0|            0|            0|  0.00%|            result = (result,)
  1025|         0|            0|            0|  0.00%|
  1026|         0|            0|            0|  0.00%|        if not isinstance(inputs, torch.Tensor):
  1027|         0|            0|            0|  0.00%|            if not (isinstance(inputs, tuple) and all([isinstance(i, torch.Tensor) for i in inputs])):
  1028|         0|            0|            0|  0.00%|                warnings.warn("Using non-full backward hooks on a Module that does not take as input a "
  1029|         0|            0|            0|  0.00%|                              "single Tensor or a tuple of Tensors is deprecated and will be removed "
  1030|         0|            0|            0|  0.00%|                              "in future versions. This hook will be missing some of the grad_input. "
  1031|         0|            0|            0|  0.00%|                              "Please use register_full_backward_hook to get the documented behavior.")
  1032|         0|            0|            0|  0.00%|                return
  1033|         0|            0|            0|  0.00%|        else:
  1034|         0|            0|            0|  0.00%|            inputs = (inputs,)
  1035|         0|            0|            0|  0.00%|
  1036|         0|            0|            0|  0.00%|        # At this point we are sure that inputs and result are tuple of Tensors
  1037|         0|            0|            0|  0.00%|        out_grad_fn = {r.grad_fn for r in result if r.grad_fn is not None}
  1038|         0|            0|            0|  0.00%|        if len(out_grad_fn) == 0 or (len(out_grad_fn) == 1 and grad_fn not in out_grad_fn):
  1039|         0|            0|            0|  0.00%|            warnings.warn("Using a non-full backward hook when outputs are nested in python data structure "
  1040|         0|            0|            0|  0.00%|                          "is deprecated and will be removed in future versions. This hook will be missing "
  1041|         0|            0|            0|  0.00%|                          "some grad_output.")
  1042|         0|            0|            0|  0.00%|        elif len(out_grad_fn) > 1:
  1043|         0|            0|            0|  0.00%|            warnings.warn("Using a non-full backward hook when outputs are generated by different autograd Nodes "
  1044|         0|            0|            0|  0.00%|                          "is deprecated and will be removed in future versions. This hook will be missing "
  1045|         0|            0|            0|  0.00%|                          "some grad_output. Please use register_full_backward_hook to get the documented behavior.")
  1046|         0|            0|            0|  0.00%|        else:
  1047|         0|            0|            0|  0.00%|            # At this point the grad_ouput part of the hook will most likely be correct
  1048|         0|            0|            0|  0.00%|            inputs_grad_fn = {i.grad_fn for i in inputs if i.grad_fn is not None}
  1049|         0|            0|            0|  0.00%|
  1050|         0|            0|            0|  0.00%|            next_functions = {n[0] for n in grad_fn.next_functions}
  1051|         0|            0|            0|  0.00%|
  1052|         0|            0|            0|  0.00%|            if inputs_grad_fn != next_functions:
  1053|         0|            0|            0|  0.00%|                warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
  1054|         0|            0|            0|  0.00%|                              "is deprecated and will be removed in future versions. This hook will be missing "
  1055|         0|            0|            0|  0.00%|                              "some grad_input. Please use register_full_backward_hook to get the documented "
  1056|         0|            0|            0|  0.00%|                              "behavior.")
  1057|         0|            0|            0|  0.00%|
  1058|         0|            0|            0|  0.00%|    def register_forward_pre_hook(self, hook: Callable[..., None]) -> RemovableHandle:
  1059|         0|            0|            0|  0.00%|        r"""Registers a forward pre-hook on the module.
  1060|         0|            0|            0|  0.00%|
  1061|         0|            0|            0|  0.00%|        The hook will be called every time before :func:`forward` is invoked.
  1062|         0|            0|            0|  0.00%|        It should have the following signature::
  1063|         0|            0|            0|  0.00%|
  1064|         0|            0|            0|  0.00%|            hook(module, input) -> None or modified input
  1065|         0|            0|            0|  0.00%|
  1066|         0|            0|            0|  0.00%|        The input contains only the positional arguments given to the module.
  1067|         0|            0|            0|  0.00%|        Keyword arguments won't be passed to the hooks and only to the ``forward``.
  1068|         0|            0|            0|  0.00%|        The hook can modify the input. User can either return a tuple or a
  1069|         0|            0|            0|  0.00%|        single modified value in the hook. We will wrap the value into a tuple
  1070|         0|            0|            0|  0.00%|        if a single value is returned(unless that value is already a tuple).
  1071|         0|            0|            0|  0.00%|
  1072|         0|            0|            0|  0.00%|        Returns:
  1073|         0|            0|            0|  0.00%|            :class:`torch.utils.hooks.RemovableHandle`:
  1074|         0|            0|            0|  0.00%|                a handle that can be used to remove the added hook by calling
  1075|         0|            0|            0|  0.00%|                ``handle.remove()``
  1076|         0|            0|            0|  0.00%|        """
  1077|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._forward_pre_hooks)
  1078|         0|            0|            0|  0.00%|        self._forward_pre_hooks[handle.id] = hook
  1079|         0|            0|            0|  0.00%|        return handle
  1080|         0|            0|            0|  0.00%|
  1081|         0|            0|            0|  0.00%|    def register_forward_hook(self, hook: Callable[..., None]) -> RemovableHandle:
  1082|         0|            0|            0|  0.00%|        r"""Registers a forward hook on the module.
  1083|         0|            0|            0|  0.00%|
  1084|         0|            0|            0|  0.00%|        The hook will be called every time after :func:`forward` has computed an output.
  1085|         0|            0|            0|  0.00%|        It should have the following signature::
  1086|         0|            0|            0|  0.00%|
  1087|         0|            0|            0|  0.00%|            hook(module, input, output) -> None or modified output
  1088|         0|            0|            0|  0.00%|
  1089|         0|            0|            0|  0.00%|        The input contains only the positional arguments given to the module.
  1090|         0|            0|            0|  0.00%|        Keyword arguments won't be passed to the hooks and only to the ``forward``.
  1091|         0|            0|            0|  0.00%|        The hook can modify the output. It can modify the input inplace but
  1092|         0|            0|            0|  0.00%|        it will not have effect on forward since this is called after
  1093|         0|            0|            0|  0.00%|        :func:`forward` is called.
  1094|         0|            0|            0|  0.00%|
  1095|         0|            0|            0|  0.00%|        Returns:
  1096|         0|            0|            0|  0.00%|            :class:`torch.utils.hooks.RemovableHandle`:
  1097|         0|            0|            0|  0.00%|                a handle that can be used to remove the added hook by calling
  1098|         0|            0|            0|  0.00%|                ``handle.remove()``
  1099|         0|            0|            0|  0.00%|        """
  1100|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._forward_hooks)
  1101|         0|            0|            0|  0.00%|        self._forward_hooks[handle.id] = hook
  1102|         0|            0|            0|  0.00%|        return handle
  1103|         0|            0|            0|  0.00%|
  1104|         0|            0|            0|  0.00%|    def _slow_forward(self, *input, **kwargs):
  1105|         0|            0|            0|  0.00%|        tracing_state = torch._C._get_tracing_state()
  1106|         0|            0|            0|  0.00%|        if not tracing_state or isinstance(self.forward, torch._C.ScriptMethod):
  1107|         0|            0|            0|  0.00%|            return self.forward(*input, **kwargs)
  1108|         0|            0|            0|  0.00%|        recording_scopes = torch.jit._trace._trace_module_map is not None
  1109|         0|            0|            0|  0.00%|        if recording_scopes:
  1110|         0|            0|            0|  0.00%|            # type ignore was added because at this point one knows that
  1111|         0|            0|            0|  0.00%|            # torch.jit._trace._trace_module_map is not Optional and has type Dict[Any, Any]
  1112|         0|            0|            0|  0.00%|            name = torch.jit._trace._trace_module_map[self] if self in torch.jit._trace._trace_module_map else None  # type: ignore[index, operator] # noqa: B950
  1113|         0|            0|            0|  0.00%|            if name:
  1114|         0|            0|            0|  0.00%|                tracing_state.push_scope(name)
  1115|         0|            0|            0|  0.00%|            else:
  1116|         0|            0|            0|  0.00%|                recording_scopes = False
  1117|         0|            0|            0|  0.00%|        try:
  1118|         0|            0|            0|  0.00%|            result = self.forward(*input, **kwargs)
  1119|         0|            0|            0|  0.00%|        finally:
  1120|         0|            0|            0|  0.00%|            if recording_scopes:
  1121|         0|            0|            0|  0.00%|                tracing_state.pop_scope()
  1122|         0|            0|            0|  0.00%|        return result
  1123|         0|            0|            0|  0.00%|
  1124|     31428|     0.114349|  3.63846e-06|  0.11%|    def _call_impl(self, *input, **kwargs):
  1125|     31428|     0.183435|  5.83667e-06|  0.18%|        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
  1126|         0|            0|            0|  0.00%|        # If we don't have any hooks, we want to skip the rest of the logic in
  1127|         0|            0|            0|  0.00%|        # this function, and just call forward.
  1128|     94284|     0.323985|  3.43627e-06|  0.31%|        if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
  1129|     62856|     0.205441|  3.26845e-06|  0.20%|                or _global_forward_hooks or _global_forward_pre_hooks):
  1130|     31428|     0.287243|  9.13971e-06|  0.28%|            return forward_call(*input, **kwargs)
(call)|     15714|     0.951703|   6.0564e-05|  0.91%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:113 forward
(call)|     10476|     0.141984|  1.35533e-05|  0.14%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:353 forward
(call)|      5238|      2.41351|  0.000460768|  2.31%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/container.py:137 forward
  1131|         0|            0|            0|  0.00%|        # Do not call functions when jit is used
  1132|         0|            0|            0|  0.00%|        full_backward_hooks, non_full_backward_hooks = [], []
  1133|         0|            0|            0|  0.00%|        if self._backward_hooks or _global_backward_hooks:
  1134|         0|            0|            0|  0.00%|            full_backward_hooks, non_full_backward_hooks = self._get_backward_hooks()
  1135|         0|            0|            0|  0.00%|        if _global_forward_pre_hooks or self._forward_pre_hooks:
  1136|         0|            0|            0|  0.00%|            for hook in (*_global_forward_pre_hooks.values(), *self._forward_pre_hooks.values()):
  1137|         0|            0|            0|  0.00%|                result = hook(self, input)
  1138|         0|            0|            0|  0.00%|                if result is not None:
  1139|         0|            0|            0|  0.00%|                    if not isinstance(result, tuple):
  1140|         0|            0|            0|  0.00%|                        result = (result,)
  1141|         0|            0|            0|  0.00%|                    input = result
  1142|         0|            0|            0|  0.00%|
  1143|         0|            0|            0|  0.00%|        bw_hook = None
  1144|         0|            0|            0|  0.00%|        if full_backward_hooks:
  1145|         0|            0|            0|  0.00%|            bw_hook = hooks.BackwardHook(self, full_backward_hooks)
  1146|         0|            0|            0|  0.00%|            input = bw_hook.setup_input_hook(input)
  1147|         0|            0|            0|  0.00%|
  1148|         0|            0|            0|  0.00%|        result = forward_call(*input, **kwargs)
  1149|         0|            0|            0|  0.00%|        if _global_forward_hooks or self._forward_hooks:
  1150|         0|            0|            0|  0.00%|            for hook in (*_global_forward_hooks.values(), *self._forward_hooks.values()):
  1151|         0|            0|            0|  0.00%|                hook_result = hook(self, input, result)
  1152|         0|            0|            0|  0.00%|                if hook_result is not None:
  1153|         0|            0|            0|  0.00%|                    result = hook_result
  1154|         0|            0|            0|  0.00%|
  1155|         0|            0|            0|  0.00%|        if bw_hook:
  1156|         0|            0|            0|  0.00%|            result = bw_hook.setup_output_hook(result)
  1157|         0|            0|            0|  0.00%|
  1158|         0|            0|            0|  0.00%|        # Handle the non-full backward hooks
  1159|         0|            0|            0|  0.00%|        if non_full_backward_hooks:
  1160|         0|            0|            0|  0.00%|            var = result
  1161|         0|            0|            0|  0.00%|            while not isinstance(var, torch.Tensor):
  1162|         0|            0|            0|  0.00%|                if isinstance(var, dict):
  1163|         0|            0|            0|  0.00%|                    var = next((v for v in var.values() if isinstance(v, torch.Tensor)))
  1164|         0|            0|            0|  0.00%|                else:
  1165|         0|            0|            0|  0.00%|                    var = var[0]
  1166|         0|            0|            0|  0.00%|            grad_fn = var.grad_fn
  1167|         0|            0|            0|  0.00%|            if grad_fn is not None:
  1168|         0|            0|            0|  0.00%|                for hook in non_full_backward_hooks:
  1169|         0|            0|            0|  0.00%|                    wrapper = functools.partial(hook, self)
  1170|         0|            0|            0|  0.00%|                    functools.update_wrapper(wrapper, hook)
  1171|         0|            0|            0|  0.00%|                    grad_fn.register_hook(wrapper)
  1172|         0|            0|            0|  0.00%|                self._maybe_warn_non_full_backward_hook(input, result, grad_fn)
  1173|         0|            0|            0|  0.00%|
  1174|         0|            0|            0|  0.00%|        return result
  1175|         0|            0|            0|  0.00%|
  1176|         0|            0|            0|  0.00%|    __call__ : Callable[..., Any] = _call_impl
  1177|         0|            0|            0|  0.00%|
  1178|         0|            0|            0|  0.00%|    def __setstate__(self, state):
  1179|         0|            0|            0|  0.00%|        self.__dict__.update(state)
  1180|         0|            0|            0|  0.00%|        # Support loading old checkpoints that don't have the following attrs:
  1181|         0|            0|            0|  0.00%|        if '_forward_pre_hooks' not in self.__dict__:
  1182|         0|            0|            0|  0.00%|            self._forward_pre_hooks = OrderedDict()
  1183|         0|            0|            0|  0.00%|        if '_state_dict_hooks' not in self.__dict__:
  1184|         0|            0|            0|  0.00%|            self._state_dict_hooks = OrderedDict()
  1185|         0|            0|            0|  0.00%|        if '_load_state_dict_pre_hooks' not in self.__dict__:
  1186|         0|            0|            0|  0.00%|            self._load_state_dict_pre_hooks = OrderedDict()
  1187|         0|            0|            0|  0.00%|        if '_load_state_dict_post_hooks' not in self.__dict__:
  1188|         0|            0|            0|  0.00%|            self._load_state_dict_post_hooks = OrderedDict()
  1189|         0|            0|            0|  0.00%|        if '_non_persistent_buffers_set' not in self.__dict__:
  1190|         0|            0|            0|  0.00%|            self._non_persistent_buffers_set = set()
  1191|         0|            0|            0|  0.00%|        if '_is_full_backward_hook' not in self.__dict__:
  1192|         0|            0|            0|  0.00%|            self._is_full_backward_hook = None
  1193|         0|            0|            0|  0.00%|
  1194|     41904|    0.0860107|  2.05257e-06|  0.08%|    def __getattr__(self, name: str) -> Union[Tensor, 'Module']:
  1195|     41904|     0.104805|  2.50107e-06|  0.10%|        if '_parameters' in self.__dict__:
  1196|     41904|    0.0950358|  2.26794e-06|  0.09%|            _parameters = self.__dict__['_parameters']
  1197|     41904|      0.09409|  2.24537e-06|  0.09%|            if name in _parameters:
  1198|     31428|    0.0652802|  2.07714e-06|  0.06%|                return _parameters[name]
  1199|     10476|    0.0305262|  2.91391e-06|  0.03%|        if '_buffers' in self.__dict__:
  1200|     10476|    0.0236425|  2.25683e-06|  0.02%|            _buffers = self.__dict__['_buffers']
  1201|     10476|    0.0222723|  2.12604e-06|  0.02%|            if name in _buffers:
  1202|      2610|   0.00582671|  2.23246e-06|  0.01%|                return _buffers[name]
  1203|      7866|     0.015805|  2.00928e-06|  0.02%|        if '_modules' in self.__dict__:
  1204|      7866|     0.015604|  1.98373e-06|  0.01%|            modules = self.__dict__['_modules']
  1205|      7866|    0.0151753|  1.92923e-06|  0.01%|            if name in modules:
  1206|      7866|    0.0144897|  1.84206e-06|  0.01%|                return modules[name]
  1207|         0|            0|            0|  0.00%|        raise AttributeError("'{}' object has no attribute '{}'".format(
  1208|         0|            0|            0|  0.00%|            type(self).__name__, name))
  1209|         0|            0|            0|  0.00%|
  1210|      4662|    0.0133908|  2.87233e-06|  0.01%|    def __setattr__(self, name: str, value: Union[Tensor, 'Module']) -> None:
  1211|      4662|    0.0140536|   3.0145e-06|  0.01%|        def remove_from(*dicts_or_sets):
  1212|         0|            0|            0|  0.00%|            for d in dicts_or_sets:
  1213|         0|            0|            0|  0.00%|                if name in d:
  1214|         0|            0|            0|  0.00%|                    if isinstance(d, dict):
  1215|         0|            0|            0|  0.00%|                        del d[name]
  1216|         0|            0|            0|  0.00%|                    else:
  1217|         0|            0|            0|  0.00%|                        d.discard(name)
  1218|         0|            0|            0|  0.00%|
  1219|      4662|    0.0135362|  2.90352e-06|  0.01%|        params = self.__dict__.get('_parameters')
  1220|      4662|    0.0355117|  7.61727e-06|  0.03%|        if isinstance(value, Parameter):
(call)|      4662|    0.0396039|  8.49506e-06|  0.04%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/parameter.py:9 __instancecheck__
  1221|         0|            0|            0|  0.00%|            if params is None:
  1222|         0|            0|            0|  0.00%|                raise AttributeError(
  1223|         0|            0|            0|  0.00%|                    "cannot assign parameters before Module.__init__() call")
  1224|         0|            0|            0|  0.00%|            remove_from(self.__dict__, self._buffers, self._modules, self._non_persistent_buffers_set)
  1225|         0|            0|            0|  0.00%|            self.register_parameter(name, value)
  1226|      4662|    0.0126898|  2.72197e-06|  0.01%|        elif params is not None and name in params:
  1227|         0|            0|            0|  0.00%|            if value is not None:
  1228|         0|            0|            0|  0.00%|                raise TypeError("cannot assign '{}' as parameter '{}' "
  1229|         0|            0|            0|  0.00%|                                "(torch.nn.Parameter or None expected)"
  1230|         0|            0|            0|  0.00%|                                .format(torch.typename(value), name))
  1231|         0|            0|            0|  0.00%|            self.register_parameter(name, value)
  1232|         0|            0|            0|  0.00%|        else:
  1233|      4662|    0.0124953|  2.68024e-06|  0.01%|            modules = self.__dict__.get('_modules')
  1234|      4662|    0.0115039|   2.4676e-06|  0.01%|            if isinstance(value, Module):
  1235|         0|            0|            0|  0.00%|                if modules is None:
  1236|         0|            0|            0|  0.00%|                    raise AttributeError(
  1237|         0|            0|            0|  0.00%|                        "cannot assign module before Module.__init__() call")
  1238|         0|            0|            0|  0.00%|                remove_from(self.__dict__, self._parameters, self._buffers, self._non_persistent_buffers_set)
  1239|         0|            0|            0|  0.00%|                modules[name] = value
  1240|      4662|    0.0108228|  2.32149e-06|  0.01%|            elif modules is not None and name in modules:
  1241|         0|            0|            0|  0.00%|                if value is not None:
  1242|         0|            0|            0|  0.00%|                    raise TypeError("cannot assign '{}' as child module '{}' "
  1243|         0|            0|            0|  0.00%|                                    "(torch.nn.Module or None expected)"
  1244|         0|            0|            0|  0.00%|                                    .format(torch.typename(value), name))
  1245|         0|            0|            0|  0.00%|                modules[name] = value
  1246|         0|            0|            0|  0.00%|            else:
  1247|      4662|    0.0106976|  2.29464e-06|  0.01%|                buffers = self.__dict__.get('_buffers')
  1248|      4662|    0.0103052|  2.21046e-06|  0.01%|                if buffers is not None and name in buffers:
  1249|         0|            0|            0|  0.00%|                    if value is not None and not isinstance(value, torch.Tensor):
  1250|         0|            0|            0|  0.00%|                        raise TypeError("cannot assign '{}' as buffer '{}' "
  1251|         0|            0|            0|  0.00%|                                        "(torch.Tensor or None expected)"
  1252|         0|            0|            0|  0.00%|                                        .format(torch.typename(value), name))
  1253|         0|            0|            0|  0.00%|                    buffers[name] = value
  1254|         0|            0|            0|  0.00%|                else:
  1255|      4662|    0.0130272|  2.79434e-06|  0.01%|                    object.__setattr__(self, name, value)
  1256|         0|            0|            0|  0.00%|
  1257|         0|            0|            0|  0.00%|    def __delattr__(self, name):
  1258|         0|            0|            0|  0.00%|        if name in self._parameters:
  1259|         0|            0|            0|  0.00%|            del self._parameters[name]
  1260|         0|            0|            0|  0.00%|        elif name in self._buffers:
  1261|         0|            0|            0|  0.00%|            del self._buffers[name]
  1262|         0|            0|            0|  0.00%|            self._non_persistent_buffers_set.discard(name)
  1263|         0|            0|            0|  0.00%|        elif name in self._modules:
  1264|         0|            0|            0|  0.00%|            del self._modules[name]
  1265|         0|            0|            0|  0.00%|        else:
  1266|         0|            0|            0|  0.00%|            object.__delattr__(self, name)
  1267|         0|            0|            0|  0.00%|
  1268|         0|            0|            0|  0.00%|    def _register_state_dict_hook(self, hook):
  1269|         0|            0|            0|  0.00%|        r"""These hooks will be called with arguments: `self`, `state_dict`,
  1270|         0|            0|            0|  0.00%|        `prefix`, `local_metadata`, after the `state_dict` of `self` is set.
  1271|         0|            0|            0|  0.00%|        Note that only parameters and buffers of `self` or its children are
  1272|         0|            0|            0|  0.00%|        guaranteed to exist in `state_dict`. The hooks may modify `state_dict`
  1273|         0|            0|            0|  0.00%|        inplace or return a new one.
  1274|         0|            0|            0|  0.00%|        """
  1275|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._state_dict_hooks)
  1276|         0|            0|            0|  0.00%|        self._state_dict_hooks[handle.id] = hook
  1277|         0|            0|            0|  0.00%|        return handle
  1278|         0|            0|            0|  0.00%|
  1279|        26|  5.65052e-05|  2.17328e-06|  0.00%|    def _save_to_state_dict(self, destination, prefix, keep_vars):
  1280|         0|            0|            0|  0.00%|        r"""Saves module state to `destination` dictionary, containing a state
  1281|         0|            0|            0|  0.00%|        of the module, but not its descendants. This is called on every
  1282|         0|            0|            0|  0.00%|        submodule in :meth:`~torch.nn.Module.state_dict`.
  1283|         0|            0|            0|  0.00%|
  1284|         0|            0|            0|  0.00%|        In rare cases, subclasses can achieve class-specific behavior by
  1285|         0|            0|            0|  0.00%|        overriding this method with custom logic.
  1286|         0|            0|            0|  0.00%|
  1287|         0|            0|            0|  0.00%|        Args:
  1288|         0|            0|            0|  0.00%|            destination (dict): a dict where state will be stored
  1289|         0|            0|            0|  0.00%|            prefix (str): the prefix for parameters and buffers used in this
  1290|         0|            0|            0|  0.00%|                module
  1291|         0|            0|            0|  0.00%|        """
  1292|        50|  0.000125885|   2.5177e-06|  0.00%|        for name, param in self._parameters.items():
  1293|        24|  4.72069e-05|  1.96695e-06|  0.00%|            if param is not None:
  1294|        24|  0.000111818|   4.6591e-06|  0.00%|                destination[prefix + name] = param if keep_vars else param.detach()
  1295|        28|  6.79493e-05|  2.42676e-06|  0.00%|        for name, buf in self._buffers.items():
  1296|         2|  6.19888e-06|  3.09944e-06|  0.00%|            if buf is not None and name not in self._non_persistent_buffers_set:
  1297|         2|  1.74046e-05|  8.70228e-06|  0.00%|                destination[prefix + name] = buf if keep_vars else buf.detach()
  1298|        26|  5.45979e-05|  2.09992e-06|  0.00%|        extra_state_key = prefix + _EXTRA_STATE_KEY_SUFFIX
  1299|        26|   6.4373e-05|  2.47589e-06|  0.00%|        if getattr(self.__class__, "get_extra_state", Module.get_extra_state) is not Module.get_extra_state:
  1300|         0|            0|            0|  0.00%|            destination[extra_state_key] = self.get_extra_state()
  1301|         0|            0|            0|  0.00%|
  1302|         0|            0|            0|  0.00%|    # The user can pass an optional arbitrary mappable object to `state_dict`, in which case `state_dict` returns
  1303|         0|            0|            0|  0.00%|    # back that same object. But if they pass nothing, an `OrederedDict` is created and returned.
  1304|         0|            0|            0|  0.00%|    T_destination = TypeVar('T_destination', bound=Dict[str, Any])
  1305|         0|            0|            0|  0.00%|
  1306|         0|            0|            0|  0.00%|    @overload
  1307|         0|            0|            0|  0.00%|    def state_dict(self, *, destination: T_destination, prefix: str = ..., keep_vars: bool = ...) -> T_destination:
  1308|         0|            0|            0|  0.00%|        ...
  1309|         0|            0|            0|  0.00%|
  1310|         0|            0|            0|  0.00%|    @overload
  1311|         0|            0|            0|  0.00%|    def state_dict(self, *, prefix: str = ..., keep_vars: bool = ...) -> Dict[str, Any]:
  1312|         0|            0|            0|  0.00%|        ...
  1313|         0|            0|            0|  0.00%|
  1314|         0|            0|            0|  0.00%|    # TODO: Change `*args` to `*` and remove the copprespinding warning in docs when BC allows.
  1315|         0|            0|            0|  0.00%|    # Also remove the logic for arg parsing together.
  1316|        26|  7.12872e-05|  2.74181e-06|  0.00%|    def state_dict(self, *args, destination=None, prefix='', keep_vars=False):
  1317|         0|            0|            0|  0.00%|        r"""Returns a dictionary containing a whole state of the module.
  1318|         0|            0|            0|  0.00%|
  1319|         0|            0|            0|  0.00%|        Both parameters and persistent buffers (e.g. running averages) are
  1320|         0|            0|            0|  0.00%|        included. Keys are corresponding parameter and buffer names.
  1321|         0|            0|            0|  0.00%|        Parameters and buffers set to ``None`` are not included.
  1322|         0|            0|            0|  0.00%|
  1323|         0|            0|            0|  0.00%|        .. warning::
  1324|         0|            0|            0|  0.00%|            Currently ``state_dict()`` also accepts positional arguments for
  1325|         0|            0|            0|  0.00%|            ``destination``, ``prefix`` and ``keep_vars`` in order. However,
  1326|         0|            0|            0|  0.00%|            this is being deprecated and keyword arguments will be enforced in
  1327|         0|            0|            0|  0.00%|            future releases.
  1328|         0|            0|            0|  0.00%|
  1329|         0|            0|            0|  0.00%|        .. warning::
  1330|         0|            0|            0|  0.00%|            Please avoid the use of argument ``destination`` as it is not
  1331|         0|            0|            0|  0.00%|            designed for end-users.
  1332|         0|            0|            0|  0.00%|
  1333|         0|            0|            0|  0.00%|        Args:
  1334|         0|            0|            0|  0.00%|            destination (dict, optional): If provided, the state of module will
  1335|         0|            0|            0|  0.00%|                be updated into the dict and the same object is returned.
  1336|         0|            0|            0|  0.00%|                Otherwise, an ``OrderedDict`` will be created and returned.
  1337|         0|            0|            0|  0.00%|                Default: ``None``.
  1338|         0|            0|            0|  0.00%|            prefix (str, optional): a prefix added to parameter and buffer
  1339|         0|            0|            0|  0.00%|                names to compose the keys in state_dict. Default: ``''``.
  1340|         0|            0|            0|  0.00%|            keep_vars (bool, optional): by default the :class:`~torch.Tensor` s
  1341|         0|            0|            0|  0.00%|                returned in the state dict are detached from autograd. If it's
  1342|         0|            0|            0|  0.00%|                set to ``True``, detaching will not be performed.
  1343|         0|            0|            0|  0.00%|                Default: ``False``.
  1344|         0|            0|            0|  0.00%|
  1345|         0|            0|            0|  0.00%|        Returns:
  1346|         0|            0|            0|  0.00%|            dict:
  1347|         0|            0|            0|  0.00%|                a dictionary containing a whole state of the module
  1348|         0|            0|            0|  0.00%|
  1349|         0|            0|            0|  0.00%|        Example::
  1350|         0|            0|            0|  0.00%|
  1351|         0|            0|            0|  0.00%|            >>> module.state_dict().keys()
  1352|         0|            0|            0|  0.00%|            ['bias', 'weight']
  1353|         0|            0|            0|  0.00%|
  1354|         0|            0|            0|  0.00%|        """
  1355|         0|            0|            0|  0.00%|
  1356|         0|            0|            0|  0.00%|        # TODO: Remove `args` and the parsing logic when BC allows.
  1357|        26|  6.60419e-05|  2.54007e-06|  0.00%|        if len(args) > 0:
  1358|         0|            0|            0|  0.00%|            if destination is None:
  1359|         0|            0|            0|  0.00%|                destination = args[0]
  1360|         0|            0|            0|  0.00%|            if len(args) > 1 and prefix == '':
  1361|         0|            0|            0|  0.00%|                prefix = args[1]
  1362|         0|            0|            0|  0.00%|            if len(args) > 2 and keep_vars is False:
  1363|         0|            0|            0|  0.00%|                keep_vars = args[2]
  1364|         0|            0|            0|  0.00%|            # DeprecationWarning is ignored by default
  1365|         0|            0|            0|  0.00%|            warnings.warn(
  1366|         0|            0|            0|  0.00%|                "Positional args are being deprecated, use kwargs instead. Refer to "
  1367|         0|            0|            0|  0.00%|                "https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict"
  1368|         0|            0|            0|  0.00%|                " for details.")
  1369|         0|            0|            0|  0.00%|
  1370|        26|  6.31809e-05|  2.43004e-06|  0.00%|        if destination is None:
  1371|         2|   6.4373e-06|  3.21865e-06|  0.00%|            destination = OrderedDict()
  1372|         2|  7.86781e-06|  3.93391e-06|  0.00%|            destination._metadata = OrderedDict()
  1373|         0|            0|            0|  0.00%|
  1374|        26|  7.31945e-05|  2.81517e-06|  0.00%|        local_metadata = dict(version=self._version)
  1375|        26|  6.38962e-05|  2.45755e-06|  0.00%|        if hasattr(destination, "_metadata"):
  1376|        26|  7.48634e-05|  2.87936e-06|  0.00%|            destination._metadata[prefix[:-1]] = local_metadata
  1377|         0|            0|            0|  0.00%|
  1378|        26|  0.000201941|  7.76694e-06|  0.00%|        self._save_to_state_dict(destination, prefix, keep_vars)
(call)|        26|  0.000551939|  2.12284e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1279 _save_to_state_dict
  1379|        50|  0.000143528|  2.87056e-06|  0.00%|        for name, module in self._modules.items():
  1380|        24|  5.36442e-05|  2.23517e-06|  0.00%|            if module is not None:
  1381|        24|  0.000181437|  7.55986e-06|  0.00%|                module.state_dict(destination=destination, prefix=prefix + name + '.', keep_vars=keep_vars)
(call)|        24|   0.00146747|  6.11444e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1316 state_dict
  1382|        26|  6.48499e-05|  2.49423e-06|  0.00%|        for hook in self._state_dict_hooks.values():
  1383|         0|            0|            0|  0.00%|            hook_result = hook(self, destination, prefix, local_metadata)
  1384|         0|            0|            0|  0.00%|            if hook_result is not None:
  1385|         0|            0|            0|  0.00%|                destination = hook_result
  1386|        26|  5.67436e-05|  2.18245e-06|  0.00%|        return destination
  1387|         0|            0|            0|  0.00%|
  1388|         0|            0|            0|  0.00%|    def _register_load_state_dict_pre_hook(self, hook, with_module=False):
  1389|         0|            0|            0|  0.00%|        r"""These hooks will be called with arguments: `state_dict`, `prefix`,
  1390|         0|            0|            0|  0.00%|        `local_metadata`, `strict`, `missing_keys`, `unexpected_keys`,
  1391|         0|            0|            0|  0.00%|        `error_msgs`, before loading `state_dict` into `self`. These arguments
  1392|         0|            0|            0|  0.00%|        are exactly the same as those of `_load_from_state_dict`.
  1393|         0|            0|            0|  0.00%|
  1394|         0|            0|            0|  0.00%|        If ``with_module`` is ``True``, then the first argument to the hook is
  1395|         0|            0|            0|  0.00%|        an instance of the module.
  1396|         0|            0|            0|  0.00%|
  1397|         0|            0|            0|  0.00%|        Arguments:
  1398|         0|            0|            0|  0.00%|            hook (Callable): Callable hook that will be invoked before
  1399|         0|            0|            0|  0.00%|                loading the state dict.
  1400|         0|            0|            0|  0.00%|            with_module (bool, optional): Whether or not to pass the module
  1401|         0|            0|            0|  0.00%|                instance to the hook as the first parameter.
  1402|         0|            0|            0|  0.00%|        """
  1403|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._load_state_dict_pre_hooks)
  1404|         0|            0|            0|  0.00%|        if with_module:
  1405|         0|            0|            0|  0.00%|            hook = functools.partial(hook, self)
  1406|         0|            0|            0|  0.00%|        self._load_state_dict_pre_hooks[handle.id] = hook
  1407|         0|            0|            0|  0.00%|        return handle
  1408|         0|            0|            0|  0.00%|
  1409|         0|            0|            0|  0.00%|    def register_load_state_dict_post_hook(self, hook):
  1410|         0|            0|            0|  0.00%|        r"""Registers a post hook to be run after module's ``load_state_dict``
  1411|         0|            0|            0|  0.00%|        is called.
  1412|         0|            0|            0|  0.00%|
  1413|         0|            0|            0|  0.00%|        It should have the following signature::
  1414|         0|            0|            0|  0.00%|            hook(module, incompatible_keys) -> None
  1415|         0|            0|            0|  0.00%|
  1416|         0|            0|            0|  0.00%|        The ``module`` argument is the current module that this hook is registered
  1417|         0|            0|            0|  0.00%|        on, and the ``incompatible_keys`` argument is a ``NamedTuple`` consisting
  1418|         0|            0|            0|  0.00%|        of attributes ``missing_keys`` and ``unexpected_keys``. ``missing_keys``
  1419|         0|            0|            0|  0.00%|        is a ``list`` of ``str`` containing the missing keys and
  1420|         0|            0|            0|  0.00%|        ``unexpected_keys`` is a ``list`` of ``str`` containing the unexpected keys.
  1421|         0|            0|            0|  0.00%|
  1422|         0|            0|            0|  0.00%|        The given incompatible_keys can be modified inplace if needed.
  1423|         0|            0|            0|  0.00%|
  1424|         0|            0|            0|  0.00%|        Note that the checks performed when calling :func:`load_state_dict` with
  1425|         0|            0|            0|  0.00%|        ``strict=True`` are affected by modifications the hook makes to
  1426|         0|            0|            0|  0.00%|        ``missing_keys`` or ``unexpected_keys``, as expected. Additions to either
  1427|         0|            0|            0|  0.00%|        set of keys will result in an error being thrown when ``strict=True``, and
  1428|         0|            0|            0|  0.00%|        clearning out both missing and unexpected keys will avoid an error.
  1429|         0|            0|            0|  0.00%|
  1430|         0|            0|            0|  0.00%|        Returns:
  1431|         0|            0|            0|  0.00%|            :class:`torch.utils.hooks.RemovableHandle`:
  1432|         0|            0|            0|  0.00%|                a handle that can be used to remove the added hook by calling
  1433|         0|            0|            0|  0.00%|                ``handle.remove()``
  1434|         0|            0|            0|  0.00%|        """
  1435|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._load_state_dict_post_hooks)
  1436|         0|            0|            0|  0.00%|        self._load_state_dict_post_hooks[handle.id] = hook
  1437|         0|            0|            0|  0.00%|        return handle
  1438|         0|            0|            0|  0.00%|
  1439|         0|            0|            0|  0.00%|
  1440|         0|            0|            0|  0.00%|    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,
  1441|         0|            0|            0|  0.00%|                              missing_keys, unexpected_keys, error_msgs):
  1442|         0|            0|            0|  0.00%|        r"""Copies parameters and buffers from :attr:`state_dict` into only
  1443|         0|            0|            0|  0.00%|        this module, but not its descendants. This is called on every submodule
  1444|         0|            0|            0|  0.00%|        in :meth:`~torch.nn.Module.load_state_dict`. Metadata saved for this
  1445|         0|            0|            0|  0.00%|        module in input :attr:`state_dict` is provided as :attr:`local_metadata`.
  1446|         0|            0|            0|  0.00%|        For state dicts without metadata, :attr:`local_metadata` is empty.
  1447|         0|            0|            0|  0.00%|        Subclasses can achieve class-specific backward compatible loading using
  1448|         0|            0|            0|  0.00%|        the version number at `local_metadata.get("version", None)`.
  1449|         0|            0|            0|  0.00%|
  1450|         0|            0|            0|  0.00%|        .. note::
  1451|         0|            0|            0|  0.00%|            :attr:`state_dict` is not the same object as the input
  1452|         0|            0|            0|  0.00%|            :attr:`state_dict` to :meth:`~torch.nn.Module.load_state_dict`. So
  1453|         0|            0|            0|  0.00%|            it can be modified.
  1454|         0|            0|            0|  0.00%|
  1455|         0|            0|            0|  0.00%|        Args:
  1456|         0|            0|            0|  0.00%|            state_dict (dict): a dict containing parameters and
  1457|         0|            0|            0|  0.00%|                persistent buffers.
  1458|         0|            0|            0|  0.00%|            prefix (str): the prefix for parameters and buffers used in this
  1459|         0|            0|            0|  0.00%|                module
  1460|         0|            0|            0|  0.00%|            local_metadata (dict): a dict containing the metadata for this module.
  1461|         0|            0|            0|  0.00%|                See
  1462|         0|            0|            0|  0.00%|            strict (bool): whether to strictly enforce that the keys in
  1463|         0|            0|            0|  0.00%|                :attr:`state_dict` with :attr:`prefix` match the names of
  1464|         0|            0|            0|  0.00%|                parameters and buffers in this module
  1465|         0|            0|            0|  0.00%|            missing_keys (list of str): if ``strict=True``, add missing keys to
  1466|         0|            0|            0|  0.00%|                this list
  1467|         0|            0|            0|  0.00%|            unexpected_keys (list of str): if ``strict=True``, add unexpected
  1468|         0|            0|            0|  0.00%|                keys to this list
  1469|         0|            0|            0|  0.00%|            error_msgs (list of str): error messages should be added to this
  1470|         0|            0|            0|  0.00%|                list, and will be reported together in
  1471|         0|            0|            0|  0.00%|                :meth:`~torch.nn.Module.load_state_dict`
  1472|         0|            0|            0|  0.00%|        """
  1473|         0|            0|            0|  0.00%|        for hook in self._load_state_dict_pre_hooks.values():
  1474|         0|            0|            0|  0.00%|            hook(state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)
  1475|         0|            0|            0|  0.00%|
  1476|         0|            0|            0|  0.00%|        persistent_buffers = {k: v for k, v in self._buffers.items() if k not in self._non_persistent_buffers_set}
  1477|         0|            0|            0|  0.00%|        local_name_params = itertools.chain(self._parameters.items(), persistent_buffers.items())
  1478|         0|            0|            0|  0.00%|        local_state = {k: v for k, v in local_name_params if v is not None}
  1479|         0|            0|            0|  0.00%|
  1480|         0|            0|            0|  0.00%|        for name, param in local_state.items():
  1481|         0|            0|            0|  0.00%|            key = prefix + name
  1482|         0|            0|            0|  0.00%|            if key in state_dict:
  1483|         0|            0|            0|  0.00%|                input_param = state_dict[key]
  1484|         0|            0|            0|  0.00%|                if not torch.overrides.is_tensor_like(input_param):
  1485|         0|            0|            0|  0.00%|                    error_msgs.append('While copying the parameter named "{}", '
  1486|         0|            0|            0|  0.00%|                                      'expected torch.Tensor or Tensor-like object from checkpoint but '
  1487|         0|            0|            0|  0.00%|                                      'received {}'
  1488|         0|            0|            0|  0.00%|                                      .format(key, type(input_param)))
  1489|         0|            0|            0|  0.00%|                    continue
  1490|         0|            0|            0|  0.00%|
  1491|         0|            0|            0|  0.00%|                # This is used to avoid copying uninitialized parameters into
  1492|         0|            0|            0|  0.00%|                # non-lazy modules, since they dont have the hook to do the checks
  1493|         0|            0|            0|  0.00%|                # in such case, it will error when accessing the .shape attribute.
  1494|         0|            0|            0|  0.00%|                is_param_lazy = torch.nn.parameter.is_lazy(param)
  1495|         0|            0|            0|  0.00%|                # Backward compatibility: loading 1-dim tensor from 0.3.* to version 0.4+
  1496|         0|            0|            0|  0.00%|                if not is_param_lazy and len(param.shape) == 0 and len(input_param.shape) == 1:
  1497|         0|            0|            0|  0.00%|                    input_param = input_param[0]
  1498|         0|            0|            0|  0.00%|
  1499|         0|            0|            0|  0.00%|                if not is_param_lazy and input_param.shape != param.shape:
  1500|         0|            0|            0|  0.00%|                    # local shape should match the one in checkpoint
  1501|         0|            0|            0|  0.00%|                    error_msgs.append('size mismatch for {}: copying a param with shape {} from checkpoint, '
  1502|         0|            0|            0|  0.00%|                                      'the shape in current model is {}.'
  1503|         0|            0|            0|  0.00%|                                      .format(key, input_param.shape, param.shape))
  1504|         0|            0|            0|  0.00%|                    continue
  1505|         0|            0|            0|  0.00%|                try:
  1506|         0|            0|            0|  0.00%|                    with torch.no_grad():
  1507|         0|            0|            0|  0.00%|                        param.copy_(input_param)
  1508|         0|            0|            0|  0.00%|                except Exception as ex:
  1509|         0|            0|            0|  0.00%|                    error_msgs.append('While copying the parameter named "{}", '
  1510|         0|            0|            0|  0.00%|                                      'whose dimensions in the model are {} and '
  1511|         0|            0|            0|  0.00%|                                      'whose dimensions in the checkpoint are {}, '
  1512|         0|            0|            0|  0.00%|                                      'an exception occurred : {}.'
  1513|         0|            0|            0|  0.00%|                                      .format(key, param.size(), input_param.size(), ex.args))
  1514|         0|            0|            0|  0.00%|            elif strict:
  1515|         0|            0|            0|  0.00%|                missing_keys.append(key)
  1516|         0|            0|            0|  0.00%|
  1517|         0|            0|            0|  0.00%|        extra_state_key = prefix + _EXTRA_STATE_KEY_SUFFIX
  1518|         0|            0|            0|  0.00%|        if getattr(self.__class__, "set_extra_state", Module.set_extra_state) is not Module.set_extra_state:
  1519|         0|            0|            0|  0.00%|            if extra_state_key in state_dict:
  1520|         0|            0|            0|  0.00%|                self.set_extra_state(state_dict[extra_state_key])
  1521|         0|            0|            0|  0.00%|            elif strict:
  1522|         0|            0|            0|  0.00%|                missing_keys.append(extra_state_key)
  1523|         0|            0|            0|  0.00%|        elif strict and (extra_state_key in state_dict):
  1524|         0|            0|            0|  0.00%|            unexpected_keys.append(extra_state_key)
  1525|         0|            0|            0|  0.00%|
  1526|         0|            0|            0|  0.00%|        if strict:
  1527|         0|            0|            0|  0.00%|            for key in state_dict.keys():
  1528|         0|            0|            0|  0.00%|                if key.startswith(prefix) and key != extra_state_key:
  1529|         0|            0|            0|  0.00%|                    input_name = key[len(prefix):]
  1530|         0|            0|            0|  0.00%|                    input_name = input_name.split('.', 1)[0]  # get the name of param/buffer/child
  1531|         0|            0|            0|  0.00%|                    if input_name not in self._modules and input_name not in local_state:
  1532|         0|            0|            0|  0.00%|                        unexpected_keys.append(key)
  1533|         0|            0|            0|  0.00%|
  1534|         0|            0|            0|  0.00%|    def load_state_dict(self, state_dict: Mapping[str, Any],
  1535|         0|            0|            0|  0.00%|                        strict: bool = True):
  1536|         0|            0|            0|  0.00%|        r"""Copies parameters and buffers from :attr:`state_dict` into
  1537|         0|            0|            0|  0.00%|        this module and its descendants. If :attr:`strict` is ``True``, then
  1538|         0|            0|            0|  0.00%|        the keys of :attr:`state_dict` must exactly match the keys returned
  1539|         0|            0|            0|  0.00%|        by this module's :meth:`~torch.nn.Module.state_dict` function.
  1540|         0|            0|            0|  0.00%|
  1541|         0|            0|            0|  0.00%|        Args:
  1542|         0|            0|            0|  0.00%|            state_dict (dict): a dict containing parameters and
  1543|         0|            0|            0|  0.00%|                persistent buffers.
  1544|         0|            0|            0|  0.00%|            strict (bool, optional): whether to strictly enforce that the keys
  1545|         0|            0|            0|  0.00%|                in :attr:`state_dict` match the keys returned by this module's
  1546|         0|            0|            0|  0.00%|                :meth:`~torch.nn.Module.state_dict` function. Default: ``True``
  1547|         0|            0|            0|  0.00%|
  1548|         0|            0|            0|  0.00%|        Returns:
  1549|         0|            0|            0|  0.00%|            ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:
  1550|         0|            0|            0|  0.00%|                * **missing_keys** is a list of str containing the missing keys
  1551|         0|            0|            0|  0.00%|                * **unexpected_keys** is a list of str containing the unexpected keys
  1552|         0|            0|            0|  0.00%|
  1553|         0|            0|            0|  0.00%|        Note:
  1554|         0|            0|            0|  0.00%|            If a parameter or buffer is registered as ``None`` and its corresponding key
  1555|         0|            0|            0|  0.00%|            exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a
  1556|         0|            0|            0|  0.00%|            ``RuntimeError``.
  1557|         0|            0|            0|  0.00%|        """
  1558|         0|            0|            0|  0.00%|        if not isinstance(state_dict, Mapping):
  1559|         0|            0|            0|  0.00%|            raise TypeError("Expected state_dict to be dict-like, got {}.".format(type(state_dict)))
  1560|         0|            0|            0|  0.00%|
  1561|         0|            0|            0|  0.00%|        missing_keys: List[str] = []
  1562|         0|            0|            0|  0.00%|        unexpected_keys: List[str] = []
  1563|         0|            0|            0|  0.00%|        error_msgs: List[str] = []
  1564|         0|            0|            0|  0.00%|
  1565|         0|            0|            0|  0.00%|        # copy state_dict so _load_from_state_dict can modify it
  1566|         0|            0|            0|  0.00%|        metadata = getattr(state_dict, '_metadata', None)
  1567|         0|            0|            0|  0.00%|        state_dict = OrderedDict(state_dict)
  1568|         0|            0|            0|  0.00%|        if metadata is not None:
  1569|         0|            0|            0|  0.00%|            # mypy isn't aware that "_metadata" exists in state_dict
  1570|         0|            0|            0|  0.00%|            state_dict._metadata = metadata  # type: ignore[attr-defined]
  1571|         0|            0|            0|  0.00%|
  1572|         0|            0|            0|  0.00%|        def load(module, prefix=''):
  1573|         0|            0|            0|  0.00%|            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})
  1574|         0|            0|            0|  0.00%|            module._load_from_state_dict(
  1575|         0|            0|            0|  0.00%|                state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)
  1576|         0|            0|            0|  0.00%|            for name, child in module._modules.items():
  1577|         0|            0|            0|  0.00%|                if child is not None:
  1578|         0|            0|            0|  0.00%|                    load(child, prefix + name + '.')
  1579|         0|            0|            0|  0.00%|
  1580|         0|            0|            0|  0.00%|            # Note that the hook can modify missing_keys and unexpected_keys.
  1581|         0|            0|            0|  0.00%|            incompatible_keys = _IncompatibleKeys(missing_keys, unexpected_keys)
  1582|         0|            0|            0|  0.00%|            for hook in module._load_state_dict_post_hooks.values():
  1583|         0|            0|            0|  0.00%|                out = hook(module, incompatible_keys)
  1584|         0|            0|            0|  0.00%|                assert out is None, (
  1585|         0|            0|            0|  0.00%|                    "Hooks registered with ``register_load_state_dict_post_hook`` are not"
  1586|         0|            0|            0|  0.00%|                    "expected to return new values, if incompatible_keys need to be modified,"
  1587|         0|            0|            0|  0.00%|                    "it should be done inplace."
  1588|         0|            0|            0|  0.00%|                )
  1589|         0|            0|            0|  0.00%|
  1590|         0|            0|            0|  0.00%|        load(self)
  1591|         0|            0|            0|  0.00%|        del load
  1592|         0|            0|            0|  0.00%|
  1593|         0|            0|            0|  0.00%|        if strict:
  1594|         0|            0|            0|  0.00%|            if len(unexpected_keys) > 0:
  1595|         0|            0|            0|  0.00%|                error_msgs.insert(
  1596|         0|            0|            0|  0.00%|                    0, 'Unexpected key(s) in state_dict: {}. '.format(
  1597|         0|            0|            0|  0.00%|                        ', '.join('"{}"'.format(k) for k in unexpected_keys)))
  1598|         0|            0|            0|  0.00%|            if len(missing_keys) > 0:
  1599|         0|            0|            0|  0.00%|                error_msgs.insert(
  1600|         0|            0|            0|  0.00%|                    0, 'Missing key(s) in state_dict: {}. '.format(
  1601|         0|            0|            0|  0.00%|                        ', '.join('"{}"'.format(k) for k in missing_keys)))
  1602|         0|            0|            0|  0.00%|
  1603|         0|            0|            0|  0.00%|        if len(error_msgs) > 0:
  1604|         0|            0|            0|  0.00%|            raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
  1605|         0|            0|            0|  0.00%|                               self.__class__.__name__, "\n\t".join(error_msgs)))
  1606|         0|            0|            0|  0.00%|        return _IncompatibleKeys(missing_keys, unexpected_keys)
  1607|         0|            0|            0|  0.00%|
  1608|       288|   0.00100994|  3.50674e-06|  0.00%|    def _named_members(self, get_members_fn, prefix='', recurse=True):
  1609|         0|            0|            0|  0.00%|        r"""Helper method for yielding various names + members of modules."""
  1610|       288|   0.00129962|  4.51257e-06|  0.00%|        memo = set()
  1611|       288|   0.00128698|  4.46869e-06|  0.00%|        modules = self.named_modules(prefix=prefix) if recurse else [(prefix, self)]
  1612|      4320|    0.0277281|  6.41854e-06|  0.03%|        for module_prefix, module in modules:
(call)|      4320|      0.22626|   5.2375e-05|  0.22%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1775 named_modules
  1613|      4032|    0.0244298|  6.05898e-06|  0.02%|            members = get_members_fn(module)
(call)|      4032|    0.0138249|   3.4288e-06|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1666 <lambda>
  1614|      7488|    0.0170858|  2.28176e-06|  0.02%|            for k, v in members:
  1615|      3456|    0.0199728|  5.77917e-06|  0.02%|                if v is None or v in memo:
(call)|      3456|    0.0167089|  4.83474e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:731 __hash__
  1616|         0|            0|            0|  0.00%|                    continue
  1617|      3456|    0.0197518|  5.71522e-06|  0.02%|                memo.add(v)
(call)|      3456|    0.0161324|  4.66793e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:731 __hash__
  1618|      3456|   0.00819612|  2.37156e-06|  0.01%|                name = module_prefix + ('.' if module_prefix else '') + k
  1619|      6912|    0.0129099|  1.86775e-06|  0.01%|                yield name, v
  1620|         0|            0|            0|  0.00%|
  1621|       288|  0.000737429|  2.56052e-06|  0.00%|    def parameters(self, recurse: bool = True) -> Iterator[Parameter]:
  1622|         0|            0|            0|  0.00%|        r"""Returns an iterator over module parameters.
  1623|         0|            0|            0|  0.00%|
  1624|         0|            0|            0|  0.00%|        This is typically passed to an optimizer.
  1625|         0|            0|            0|  0.00%|
  1626|         0|            0|            0|  0.00%|        Args:
  1627|         0|            0|            0|  0.00%|            recurse (bool): if True, then yields parameters of this module
  1628|         0|            0|            0|  0.00%|                and all submodules. Otherwise, yields only parameters that
  1629|         0|            0|            0|  0.00%|                are direct members of this module.
  1630|         0|            0|            0|  0.00%|
  1631|         0|            0|            0|  0.00%|        Yields:
  1632|         0|            0|            0|  0.00%|            Parameter: module parameter
  1633|         0|            0|            0|  0.00%|
  1634|         0|            0|            0|  0.00%|        Example::
  1635|         0|            0|            0|  0.00%|
  1636|         0|            0|            0|  0.00%|            >>> for param in model.parameters():
  1637|         0|            0|            0|  0.00%|            >>>     print(type(param), param.size())
  1638|         0|            0|            0|  0.00%|            <class 'torch.Tensor'> (20L,)
  1639|         0|            0|            0|  0.00%|            <class 'torch.Tensor'> (20L, 1L, 5L, 5L)
  1640|         0|            0|            0|  0.00%|
  1641|         0|            0|            0|  0.00%|        """
  1642|      3744|    0.0213552|  5.70383e-06|  0.02%|        for name, param in self.named_parameters(recurse=recurse):
(call)|      3744|     0.445336|  0.000118947|  0.43%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1645 named_parameters
  1643|      6912|    0.0109596|  1.58559e-06|  0.01%|            yield param
  1644|         0|            0|            0|  0.00%|
  1645|       288|  0.000793934|  2.75671e-06|  0.00%|    def named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, Parameter]]:
  1646|         0|            0|            0|  0.00%|        r"""Returns an iterator over module parameters, yielding both the
  1647|         0|            0|            0|  0.00%|        name of the parameter as well as the parameter itself.
  1648|         0|            0|            0|  0.00%|
  1649|         0|            0|            0|  0.00%|        Args:
  1650|         0|            0|            0|  0.00%|            prefix (str): prefix to prepend to all parameter names.
  1651|         0|            0|            0|  0.00%|            recurse (bool): if True, then yields parameters of this module
  1652|         0|            0|            0|  0.00%|                and all submodules. Otherwise, yields only parameters that
  1653|         0|            0|            0|  0.00%|                are direct members of this module.
  1654|         0|            0|            0|  0.00%|
  1655|         0|            0|            0|  0.00%|        Yields:
  1656|         0|            0|            0|  0.00%|            (string, Parameter): Tuple containing the name and parameter
  1657|         0|            0|            0|  0.00%|
  1658|         0|            0|            0|  0.00%|        Example::
  1659|         0|            0|            0|  0.00%|
  1660|         0|            0|            0|  0.00%|            >>> for name, param in self.named_parameters():
  1661|         0|            0|            0|  0.00%|            >>>    if name in ['bias']:
  1662|         0|            0|            0|  0.00%|            >>>        print(param.size())
  1663|         0|            0|            0|  0.00%|
  1664|         0|            0|            0|  0.00%|        """
  1665|       576|   0.00170279|  2.95622e-06|  0.00%|        gen = self._named_members(
  1666|      8352|    0.0146725|  1.75677e-06|  0.01%|            lambda module: module._parameters.items(),
  1667|       288|  0.000734329|  2.54975e-06|  0.00%|            prefix=prefix, recurse=recurse)
  1668|      3744|    0.0227582|  6.07859e-06|  0.02%|        for elem in gen:
(call)|      3744|     0.406597|    0.0001086|  0.39%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1608 _named_members
  1669|      6912|    0.0119026|  1.72202e-06|  0.01%|            yield elem
  1670|         0|            0|            0|  0.00%|
  1671|         0|            0|            0|  0.00%|    def buffers(self, recurse: bool = True) -> Iterator[Tensor]:
  1672|         0|            0|            0|  0.00%|        r"""Returns an iterator over module buffers.
  1673|         0|            0|            0|  0.00%|
  1674|         0|            0|            0|  0.00%|        Args:
  1675|         0|            0|            0|  0.00%|            recurse (bool): if True, then yields buffers of this module
  1676|         0|            0|            0|  0.00%|                and all submodules. Otherwise, yields only buffers that
  1677|         0|            0|            0|  0.00%|                are direct members of this module.
  1678|         0|            0|            0|  0.00%|
  1679|         0|            0|            0|  0.00%|        Yields:
  1680|         0|            0|            0|  0.00%|            torch.Tensor: module buffer
  1681|         0|            0|            0|  0.00%|
  1682|         0|            0|            0|  0.00%|        Example::
  1683|         0|            0|            0|  0.00%|
  1684|         0|            0|            0|  0.00%|            >>> for buf in model.buffers():
  1685|         0|            0|            0|  0.00%|            >>>     print(type(buf), buf.size())
  1686|         0|            0|            0|  0.00%|            <class 'torch.Tensor'> (20L,)
  1687|         0|            0|            0|  0.00%|            <class 'torch.Tensor'> (20L, 1L, 5L, 5L)
  1688|         0|            0|            0|  0.00%|
  1689|         0|            0|            0|  0.00%|        """
  1690|         0|            0|            0|  0.00%|        for _, buf in self.named_buffers(recurse=recurse):
  1691|         0|            0|            0|  0.00%|            yield buf
  1692|         0|            0|            0|  0.00%|
  1693|         0|            0|            0|  0.00%|    def named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, Tensor]]:
  1694|         0|            0|            0|  0.00%|        r"""Returns an iterator over module buffers, yielding both the
  1695|         0|            0|            0|  0.00%|        name of the buffer as well as the buffer itself.
  1696|         0|            0|            0|  0.00%|
  1697|         0|            0|            0|  0.00%|        Args:
  1698|         0|            0|            0|  0.00%|            prefix (str): prefix to prepend to all buffer names.
  1699|         0|            0|            0|  0.00%|            recurse (bool): if True, then yields buffers of this module
  1700|         0|            0|            0|  0.00%|                and all submodules. Otherwise, yields only buffers that
  1701|         0|            0|            0|  0.00%|                are direct members of this module.
  1702|         0|            0|            0|  0.00%|
  1703|         0|            0|            0|  0.00%|        Yields:
  1704|         0|            0|            0|  0.00%|            (string, torch.Tensor): Tuple containing the name and buffer
  1705|         0|            0|            0|  0.00%|
  1706|         0|            0|            0|  0.00%|        Example::
  1707|         0|            0|            0|  0.00%|
  1708|         0|            0|            0|  0.00%|            >>> for name, buf in self.named_buffers():
  1709|         0|            0|            0|  0.00%|            >>>    if name in ['running_var']:
  1710|         0|            0|            0|  0.00%|            >>>        print(buf.size())
  1711|         0|            0|            0|  0.00%|
  1712|         0|            0|            0|  0.00%|        """
  1713|         0|            0|            0|  0.00%|        gen = self._named_members(
  1714|         0|            0|            0|  0.00%|            lambda module: module._buffers.items(),
  1715|         0|            0|            0|  0.00%|            prefix=prefix, recurse=recurse)
  1716|         0|            0|            0|  0.00%|        for elem in gen:
  1717|         0|            0|            0|  0.00%|            yield elem
  1718|         0|            0|            0|  0.00%|
  1719|         0|            0|            0|  0.00%|    def children(self) -> Iterator['Module']:
  1720|         0|            0|            0|  0.00%|        r"""Returns an iterator over immediate children modules.
  1721|         0|            0|            0|  0.00%|
  1722|         0|            0|            0|  0.00%|        Yields:
  1723|         0|            0|            0|  0.00%|            Module: a child module
  1724|         0|            0|            0|  0.00%|        """
  1725|         0|            0|            0|  0.00%|        for name, module in self.named_children():
  1726|         0|            0|            0|  0.00%|            yield module
  1727|         0|            0|            0|  0.00%|
  1728|         0|            0|            0|  0.00%|    def named_children(self) -> Iterator[Tuple[str, 'Module']]:
  1729|         0|            0|            0|  0.00%|        r"""Returns an iterator over immediate children modules, yielding both
  1730|         0|            0|            0|  0.00%|        the name of the module as well as the module itself.
  1731|         0|            0|            0|  0.00%|
  1732|         0|            0|            0|  0.00%|        Yields:
  1733|         0|            0|            0|  0.00%|            (string, Module): Tuple containing a name and child module
  1734|         0|            0|            0|  0.00%|
  1735|         0|            0|            0|  0.00%|        Example::
  1736|         0|            0|            0|  0.00%|
  1737|         0|            0|            0|  0.00%|            >>> for name, module in model.named_children():
  1738|         0|            0|            0|  0.00%|            >>>     if name in ['conv4', 'conv5']:
  1739|         0|            0|            0|  0.00%|            >>>         print(module)
  1740|         0|            0|            0|  0.00%|
  1741|         0|            0|            0|  0.00%|        """
  1742|         0|            0|            0|  0.00%|        memo = set()
  1743|         0|            0|            0|  0.00%|        for name, module in self._modules.items():
  1744|         0|            0|            0|  0.00%|            if module is not None and module not in memo:
  1745|         0|            0|            0|  0.00%|                memo.add(module)
  1746|         0|            0|            0|  0.00%|                yield name, module
  1747|         0|            0|            0|  0.00%|
  1748|         0|            0|            0|  0.00%|    def modules(self) -> Iterator['Module']:
  1749|         0|            0|            0|  0.00%|        r"""Returns an iterator over all modules in the network.
  1750|         0|            0|            0|  0.00%|
  1751|         0|            0|            0|  0.00%|        Yields:
  1752|         0|            0|            0|  0.00%|            Module: a module in the network
  1753|         0|            0|            0|  0.00%|
  1754|         0|            0|            0|  0.00%|        Note:
  1755|         0|            0|            0|  0.00%|            Duplicate modules are returned only once. In the following
  1756|         0|            0|            0|  0.00%|            example, ``l`` will be returned only once.
  1757|         0|            0|            0|  0.00%|
  1758|         0|            0|            0|  0.00%|        Example::
  1759|         0|            0|            0|  0.00%|
  1760|         0|            0|            0|  0.00%|            >>> l = nn.Linear(2, 2)
  1761|         0|            0|            0|  0.00%|            >>> net = nn.Sequential(l, l)
  1762|         0|            0|            0|  0.00%|            >>> for idx, m in enumerate(net.modules()):
  1763|         0|            0|            0|  0.00%|                    print(idx, '->', m)
  1764|         0|            0|            0|  0.00%|
  1765|         0|            0|            0|  0.00%|            0 -> Sequential(
  1766|         0|            0|            0|  0.00%|              (0): Linear(in_features=2, out_features=2, bias=True)
  1767|         0|            0|            0|  0.00%|              (1): Linear(in_features=2, out_features=2, bias=True)
  1768|         0|            0|            0|  0.00%|            )
  1769|         0|            0|            0|  0.00%|            1 -> Linear(in_features=2, out_features=2, bias=True)
  1770|         0|            0|            0|  0.00%|
  1771|         0|            0|            0|  0.00%|        """
  1772|         0|            0|            0|  0.00%|        for _, module in self.named_modules():
  1773|         0|            0|            0|  0.00%|            yield module
  1774|         0|            0|            0|  0.00%|
  1775|      4032|   0.00871515|   2.1615e-06|  0.01%|    def named_modules(self, memo: Optional[Set['Module']] = None, prefix: str = '', remove_duplicate: bool = True):
  1776|         0|            0|            0|  0.00%|        r"""Returns an iterator over all modules in the network, yielding
  1777|         0|            0|            0|  0.00%|        both the name of the module as well as the module itself.
  1778|         0|            0|            0|  0.00%|
  1779|         0|            0|            0|  0.00%|        Args:
  1780|         0|            0|            0|  0.00%|            memo: a memo to store the set of modules already added to the result
  1781|         0|            0|            0|  0.00%|            prefix: a prefix that will be added to the name of the module
  1782|         0|            0|            0|  0.00%|            remove_duplicate: whether to remove the duplicated module instances in the result
  1783|         0|            0|            0|  0.00%|                or not
  1784|         0|            0|            0|  0.00%|
  1785|         0|            0|            0|  0.00%|        Yields:
  1786|         0|            0|            0|  0.00%|            (string, Module): Tuple of name and module
  1787|         0|            0|            0|  0.00%|
  1788|         0|            0|            0|  0.00%|        Note:
  1789|         0|            0|            0|  0.00%|            Duplicate modules are returned only once. In the following
  1790|         0|            0|            0|  0.00%|            example, ``l`` will be returned only once.
  1791|         0|            0|            0|  0.00%|
  1792|         0|            0|            0|  0.00%|        Example::
  1793|         0|            0|            0|  0.00%|
  1794|         0|            0|            0|  0.00%|            >>> l = nn.Linear(2, 2)
  1795|         0|            0|            0|  0.00%|            >>> net = nn.Sequential(l, l)
  1796|         0|            0|            0|  0.00%|            >>> for idx, m in enumerate(net.named_modules()):
  1797|         0|            0|            0|  0.00%|                    print(idx, '->', m)
  1798|         0|            0|            0|  0.00%|
  1799|         0|            0|            0|  0.00%|            0 -> ('', Sequential(
  1800|         0|            0|            0|  0.00%|              (0): Linear(in_features=2, out_features=2, bias=True)
  1801|         0|            0|            0|  0.00%|              (1): Linear(in_features=2, out_features=2, bias=True)
  1802|         0|            0|            0|  0.00%|            ))
  1803|         0|            0|            0|  0.00%|            1 -> ('0', Linear(in_features=2, out_features=2, bias=True))
  1804|         0|            0|            0|  0.00%|
  1805|         0|            0|            0|  0.00%|        """
  1806|         0|            0|            0|  0.00%|
  1807|      4032|   0.00986052|  2.44556e-06|  0.01%|        if memo is None:
  1808|       288|  0.000908613|  3.15491e-06|  0.00%|            memo = set()
  1809|      4032|   0.00988984|  2.45284e-06|  0.01%|        if self not in memo:
  1810|      4032|   0.00946236|  2.34681e-06|  0.01%|            if remove_duplicate:
  1811|      4032|    0.0101852|   2.5261e-06|  0.01%|                memo.add(self)
  1812|      8064|    0.0181892|   2.2556e-06|  0.02%|            yield prefix, self
  1813|      7776|    0.0194316|  2.49892e-06|  0.02%|            for name, module in self._modules.items():
  1814|      3744|    0.0074892|  2.00032e-06|  0.01%|                if module is None:
  1815|         0|            0|            0|  0.00%|                    continue
  1816|      3744|   0.00864458|  2.30892e-06|  0.01%|                submodule_prefix = prefix + ('.' if prefix else '') + name
  1817|     13824|    0.0885482|   6.4054e-06|  0.08%|                for m in module.named_modules(memo, submodule_prefix, remove_duplicate):
(call)|     13824|     0.179232|  1.29653e-05|  0.17%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1775 named_modules
  1818|     20160|    0.0349355|  1.73291e-06|  0.03%|                    yield m
  1819|         0|            0|            0|  0.00%|
  1820|         0|            0|            0|  0.00%|    def train(self: T, mode: bool = True) -> T:
  1821|         0|            0|            0|  0.00%|        r"""Sets the module in training mode.
  1822|         0|            0|            0|  0.00%|
  1823|         0|            0|            0|  0.00%|        This has any effect only on certain modules. See documentations of
  1824|         0|            0|            0|  0.00%|        particular modules for details of their behaviors in training/evaluation
  1825|         0|            0|            0|  0.00%|        mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,
  1826|         0|            0|            0|  0.00%|        etc.
  1827|         0|            0|            0|  0.00%|
  1828|         0|            0|            0|  0.00%|        Args:
  1829|         0|            0|            0|  0.00%|            mode (bool): whether to set training mode (``True``) or evaluation
  1830|         0|            0|            0|  0.00%|                         mode (``False``). Default: ``True``.
  1831|         0|            0|            0|  0.00%|
  1832|         0|            0|            0|  0.00%|        Returns:
  1833|         0|            0|            0|  0.00%|            Module: self
  1834|         0|            0|            0|  0.00%|        """
  1835|         0|            0|            0|  0.00%|        if not isinstance(mode, bool):
  1836|         0|            0|            0|  0.00%|            raise ValueError("training mode is expected to be boolean")
  1837|         0|            0|            0|  0.00%|        self.training = mode
  1838|         0|            0|            0|  0.00%|        for module in self.children():
  1839|         0|            0|            0|  0.00%|            module.train(mode)
  1840|         0|            0|            0|  0.00%|        return self
  1841|         0|            0|            0|  0.00%|
  1842|         0|            0|            0|  0.00%|    def eval(self: T) -> T:
  1843|         0|            0|            0|  0.00%|        r"""Sets the module in evaluation mode.
  1844|         0|            0|            0|  0.00%|
  1845|         0|            0|            0|  0.00%|        This has any effect only on certain modules. See documentations of
  1846|         0|            0|            0|  0.00%|        particular modules for details of their behaviors in training/evaluation
  1847|         0|            0|            0|  0.00%|        mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,
  1848|         0|            0|            0|  0.00%|        etc.
  1849|         0|            0|            0|  0.00%|
  1850|         0|            0|            0|  0.00%|        This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.
  1851|         0|            0|            0|  0.00%|
  1852|         0|            0|            0|  0.00%|        See :ref:`locally-disable-grad-doc` for a comparison between
  1853|         0|            0|            0|  0.00%|        `.eval()` and several similar mechanisms that may be confused with it.
  1854|         0|            0|            0|  0.00%|
  1855|         0|            0|            0|  0.00%|        Returns:
  1856|         0|            0|            0|  0.00%|            Module: self
  1857|         0|            0|            0|  0.00%|        """
  1858|         0|            0|            0|  0.00%|        return self.train(False)
  1859|         0|            0|            0|  0.00%|
  1860|         0|            0|            0|  0.00%|    def requires_grad_(self: T, requires_grad: bool = True) -> T:
  1861|         0|            0|            0|  0.00%|        r"""Change if autograd should record operations on parameters in this
  1862|         0|            0|            0|  0.00%|        module.
  1863|         0|            0|            0|  0.00%|
  1864|         0|            0|            0|  0.00%|        This method sets the parameters' :attr:`requires_grad` attributes
  1865|         0|            0|            0|  0.00%|        in-place.
  1866|         0|            0|            0|  0.00%|
  1867|         0|            0|            0|  0.00%|        This method is helpful for freezing part of the module for finetuning
  1868|         0|            0|            0|  0.00%|        or training parts of a model individually (e.g., GAN training).
  1869|         0|            0|            0|  0.00%|
  1870|         0|            0|            0|  0.00%|        See :ref:`locally-disable-grad-doc` for a comparison between
  1871|         0|            0|            0|  0.00%|        `.requires_grad_()` and several similar mechanisms that may be confused with it.
  1872|         0|            0|            0|  0.00%|
  1873|         0|            0|            0|  0.00%|        Args:
  1874|         0|            0|            0|  0.00%|            requires_grad (bool): whether autograd should record operations on
  1875|         0|            0|            0|  0.00%|                                  parameters in this module. Default: ``True``.
  1876|         0|            0|            0|  0.00%|
  1877|         0|            0|            0|  0.00%|        Returns:
  1878|         0|            0|            0|  0.00%|            Module: self
  1879|         0|            0|            0|  0.00%|        """
  1880|         0|            0|            0|  0.00%|        for p in self.parameters():
  1881|         0|            0|            0|  0.00%|            p.requires_grad_(requires_grad)
  1882|         0|            0|            0|  0.00%|        return self
  1883|         0|            0|            0|  0.00%|
  1884|         0|            0|            0|  0.00%|    def zero_grad(self, set_to_none: bool = False) -> None:
  1885|         0|            0|            0|  0.00%|        r"""Sets gradients of all model parameters to zero. See similar function
  1886|         0|            0|            0|  0.00%|        under :class:`torch.optim.Optimizer` for more context.
  1887|         0|            0|            0|  0.00%|
  1888|         0|            0|            0|  0.00%|        Args:
  1889|         0|            0|            0|  0.00%|            set_to_none (bool): instead of setting to zero, set the grads to None.
  1890|         0|            0|            0|  0.00%|                See :meth:`torch.optim.Optimizer.zero_grad` for details.
  1891|         0|            0|            0|  0.00%|        """
  1892|         0|            0|            0|  0.00%|        if getattr(self, '_is_replica', False):
  1893|         0|            0|            0|  0.00%|            warnings.warn(
  1894|         0|            0|            0|  0.00%|                "Calling .zero_grad() from a module created with nn.DataParallel() has no effect. "
  1895|         0|            0|            0|  0.00%|                "The parameters are copied (in a differentiable manner) from the original module. "
  1896|         0|            0|            0|  0.00%|                "This means they are not leaf nodes in autograd and so don't accumulate gradients. "
  1897|         0|            0|            0|  0.00%|                "If you need gradients in your forward method, consider using autograd.grad instead.")
  1898|         0|            0|            0|  0.00%|
  1899|         0|            0|            0|  0.00%|        for p in self.parameters():
  1900|         0|            0|            0|  0.00%|            if p.grad is not None:
  1901|         0|            0|            0|  0.00%|                if set_to_none:
  1902|         0|            0|            0|  0.00%|                    p.grad = None
  1903|         0|            0|            0|  0.00%|                else:
  1904|         0|            0|            0|  0.00%|                    if p.grad.grad_fn is not None:
  1905|         0|            0|            0|  0.00%|                        p.grad.detach_()
  1906|         0|            0|            0|  0.00%|                    else:
  1907|         0|            0|            0|  0.00%|                        p.grad.requires_grad_(False)
  1908|         0|            0|            0|  0.00%|                    p.grad.zero_()
  1909|         0|            0|            0|  0.00%|
  1910|         0|            0|            0|  0.00%|    def share_memory(self: T) -> T:
  1911|         0|            0|            0|  0.00%|        r"""See :meth:`torch.Tensor.share_memory_`"""
  1912|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.share_memory_())
  1913|         0|            0|            0|  0.00%|
  1914|         0|            0|            0|  0.00%|    def _get_name(self):
  1915|         0|            0|            0|  0.00%|        return self.__class__.__name__
  1916|         0|            0|            0|  0.00%|
  1917|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
  1918|         0|            0|            0|  0.00%|        r"""Set the extra representation of the module
  1919|         0|            0|            0|  0.00%|
  1920|         0|            0|            0|  0.00%|        To print customized extra information, you should re-implement
  1921|         0|            0|            0|  0.00%|        this method in your own modules. Both single-line and multi-line
  1922|         0|            0|            0|  0.00%|        strings are acceptable.
  1923|         0|            0|            0|  0.00%|        """
  1924|         0|            0|            0|  0.00%|        return ''
  1925|         0|            0|            0|  0.00%|
  1926|         0|            0|            0|  0.00%|    def __repr__(self):
  1927|         0|            0|            0|  0.00%|        # We treat the extra repr like the sub-module, one item per line
  1928|         0|            0|            0|  0.00%|        extra_lines = []
  1929|         0|            0|            0|  0.00%|        extra_repr = self.extra_repr()
  1930|         0|            0|            0|  0.00%|        # empty string will be split into list ['']
  1931|         0|            0|            0|  0.00%|        if extra_repr:
  1932|         0|            0|            0|  0.00%|            extra_lines = extra_repr.split('\n')
  1933|         0|            0|            0|  0.00%|        child_lines = []
  1934|         0|            0|            0|  0.00%|        for key, module in self._modules.items():
  1935|         0|            0|            0|  0.00%|            mod_str = repr(module)
  1936|         0|            0|            0|  0.00%|            mod_str = _addindent(mod_str, 2)
  1937|         0|            0|            0|  0.00%|            child_lines.append('(' + key + '): ' + mod_str)
  1938|         0|            0|            0|  0.00%|        lines = extra_lines + child_lines
  1939|         0|            0|            0|  0.00%|
  1940|         0|            0|            0|  0.00%|        main_str = self._get_name() + '('
  1941|         0|            0|            0|  0.00%|        if lines:
  1942|         0|            0|            0|  0.00%|            # simple one-liner info, which most builtin Modules will use
  1943|         0|            0|            0|  0.00%|            if len(extra_lines) == 1 and not child_lines:
  1944|         0|            0|            0|  0.00%|                main_str += extra_lines[0]
  1945|         0|            0|            0|  0.00%|            else:
  1946|         0|            0|            0|  0.00%|                main_str += '\n  ' + '\n  '.join(lines) + '\n'
  1947|         0|            0|            0|  0.00%|
  1948|         0|            0|            0|  0.00%|        main_str += ')'
  1949|         0|            0|            0|  0.00%|        return main_str
  1950|         0|            0|            0|  0.00%|
  1951|         0|            0|            0|  0.00%|    def __dir__(self):
  1952|         0|            0|            0|  0.00%|        module_attrs = dir(self.__class__)
  1953|         0|            0|            0|  0.00%|        attrs = list(self.__dict__.keys())
  1954|         0|            0|            0|  0.00%|        parameters = list(self._parameters.keys())
  1955|         0|            0|            0|  0.00%|        modules = list(self._modules.keys())
  1956|         0|            0|            0|  0.00%|        buffers = list(self._buffers.keys())
  1957|         0|            0|            0|  0.00%|        keys = module_attrs + attrs + parameters + modules + buffers
  1958|         0|            0|            0|  0.00%|
  1959|         0|            0|            0|  0.00%|        # Eliminate attrs that are not legal Python variable names
  1960|         0|            0|            0|  0.00%|        keys = [key for key in keys if not key[0].isdigit()]
  1961|         0|            0|            0|  0.00%|
  1962|         0|            0|            0|  0.00%|        return sorted(keys)
  1963|         0|            0|            0|  0.00%|
  1964|         0|            0|            0|  0.00%|    def _replicate_for_data_parallel(self):
  1965|         0|            0|            0|  0.00%|        replica = self.__new__(type(self))
  1966|         0|            0|            0|  0.00%|        replica.__dict__ = self.__dict__.copy()
  1967|         0|            0|            0|  0.00%|
  1968|         0|            0|            0|  0.00%|        # replicas do not have parameters themselves, the replicas reference the original
  1969|         0|            0|            0|  0.00%|        # module.
  1970|         0|            0|            0|  0.00%|        replica._parameters = OrderedDict()
  1971|         0|            0|            0|  0.00%|        replica._buffers = replica._buffers.copy()
  1972|         0|            0|            0|  0.00%|        replica._modules = replica._modules.copy()
  1973|         0|            0|            0|  0.00%|        replica._is_replica = True  # type: ignore[assignment]
  1974|         0|            0|            0|  0.00%|
  1975|         0|            0|            0|  0.00%|        return replica
File: <__array_function__ internals>
File duration: 2.06699s (1.98%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|
     2|         0|            0|            0|  0.00%|
     3|         0|            0|            0|  0.00%|
     4|         0|            0|            0|  0.00%|
     5|         0|            0|            0|  0.00%|
     6|         0|            0|            0|  0.00%|
     7|         0|            0|            0|  0.00%|
     8|         0|            0|            0|  0.00%|
     9|         0|            0|            0|  0.00%|
    10|         0|            0|            0|  0.00%|
    11|         0|            0|            0|  0.00%|
    12|         0|            0|            0|  0.00%|
    13|         0|            0|            0|  0.00%|
    14|         0|            0|            0|  0.00%|
    15|         0|            0|            0|  0.00%|
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|
    18|         0|            0|            0|  0.00%|
    19|         0|            0|            0|  0.00%|
    20|         0|            0|            0|  0.00%|
    21|         0|            0|            0|  0.00%|
    22|         0|            0|            0|  0.00%|
    23|         0|            0|            0|  0.00%|
    24|         0|            0|            0|  0.00%|
    25|         0|            0|            0|  0.00%|
    26|         0|            0|            0|  0.00%|
    27|         0|            0|            0|  0.00%|
    28|         0|            0|            0|  0.00%|
    29|         0|            0|            0|  0.00%|
    30|         0|            0|            0|  0.00%|
    31|         0|            0|            0|  0.00%|
    32|         0|            0|            0|  0.00%|
    33|         0|            0|            0|  0.00%|
    34|         0|            0|            0|  0.00%|
    35|         0|            0|            0|  0.00%|
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|
    38|         0|            0|            0|  0.00%|
    39|         0|            0|            0|  0.00%|
    40|         0|            0|            0|  0.00%|
    41|         0|            0|            0|  0.00%|
    42|         0|            0|            0|  0.00%|
    43|         0|            0|            0|  0.00%|
    44|         0|            0|            0|  0.00%|
    45|         0|            0|            0|  0.00%|
    46|         0|            0|            0|  0.00%|
    47|         0|            0|            0|  0.00%|
    48|         0|            0|            0|  0.00%|
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|
    51|         0|            0|            0|  0.00%|
    52|         0|            0|            0|  0.00%|
    53|         0|            0|            0|  0.00%|
    54|         0|            0|            0|  0.00%|
    55|         0|            0|            0|  0.00%|
    56|         0|            0|            0|  0.00%|
    57|         0|            0|            0|  0.00%|
    58|         0|            0|            0|  0.00%|
    59|         0|            0|            0|  0.00%|
    60|         0|            0|            0|  0.00%|
    61|         0|            0|            0|  0.00%|
    62|         0|            0|            0|  0.00%|
    63|         0|            0|            0|  0.00%|
    64|         0|            0|            0|  0.00%|
    65|         0|            0|            0|  0.00%|
    66|         0|            0|            0|  0.00%|
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|
    69|         0|            0|            0|  0.00%|
    70|         0|            0|            0|  0.00%|
    71|         0|            0|            0|  0.00%|
    72|         0|            0|            0|  0.00%|
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|
    75|         0|            0|            0|  0.00%|
    76|         0|            0|            0|  0.00%|
    77|         0|            0|            0|  0.00%|
    78|         0|            0|            0|  0.00%|
    79|         0|            0|            0|  0.00%|
    80|         0|            0|            0|  0.00%|
    81|         0|            0|            0|  0.00%|
    82|         0|            0|            0|  0.00%|
    83|         0|            0|            0|  0.00%|
    84|         0|            0|            0|  0.00%|
    85|         0|            0|            0|  0.00%|
    86|         0|            0|            0|  0.00%|
    87|         0|            0|            0|  0.00%|
    88|         0|            0|            0|  0.00%|
    89|         0|            0|            0|  0.00%|
    90|         0|            0|            0|  0.00%|
    91|         0|            0|            0|  0.00%|
    92|         0|            0|            0|  0.00%|
    93|         0|            0|            0|  0.00%|
    94|         0|            0|            0|  0.00%|
    95|         0|            0|            0|  0.00%|
    96|         0|            0|            0|  0.00%|
    97|         0|            0|            0|  0.00%|
    98|         0|            0|            0|  0.00%|
    99|         0|            0|            0|  0.00%|
   100|         0|            0|            0|  0.00%|
   101|         0|            0|            0|  0.00%|
   102|         0|            0|            0|  0.00%|
   103|         0|            0|            0|  0.00%|
   104|         0|            0|            0|  0.00%|
   105|         0|            0|            0|  0.00%|
   106|         0|            0|            0|  0.00%|
   107|         0|            0|            0|  0.00%|
   108|         0|            0|            0|  0.00%|
   109|         0|            0|            0|  0.00%|
   110|         0|            0|            0|  0.00%|
   111|         0|            0|            0|  0.00%|
   112|         0|            0|            0|  0.00%|
   113|         0|            0|            0|  0.00%|
   114|         0|            0|            0|  0.00%|
   115|         0|            0|            0|  0.00%|
   116|         0|            0|            0|  0.00%|
   117|         0|            0|            0|  0.00%|
   118|         0|            0|            0|  0.00%|
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|
   121|         0|            0|            0|  0.00%|
   122|         0|            0|            0|  0.00%|
   123|         0|            0|            0|  0.00%|
   124|         0|            0|            0|  0.00%|
   125|         0|            0|            0|  0.00%|
   126|         0|            0|            0|  0.00%|
   127|         0|            0|            0|  0.00%|
   128|         0|            0|            0|  0.00%|
   129|         0|            0|            0|  0.00%|
   130|         0|            0|            0|  0.00%|
   131|         0|            0|            0|  0.00%|
   132|         0|            0|            0|  0.00%|
   133|         0|            0|            0|  0.00%|
   134|         0|            0|            0|  0.00%|
   135|         0|            0|            0|  0.00%|
   136|         0|            0|            0|  0.00%|
   137|         0|            0|            0|  0.00%|
   138|         0|            0|            0|  0.00%|
   139|         0|            0|            0|  0.00%|
   140|         0|            0|            0|  0.00%|
   141|         0|            0|            0|  0.00%|
   142|         0|            0|            0|  0.00%|
   143|         0|            0|            0|  0.00%|
   144|         0|            0|            0|  0.00%|
   145|         0|            0|            0|  0.00%|
   146|         0|            0|            0|  0.00%|
   147|         0|            0|            0|  0.00%|
   148|         0|            0|            0|  0.00%|
   149|         0|            0|            0|  0.00%|
   150|         0|            0|            0|  0.00%|
   151|         0|            0|            0|  0.00%|
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|
   154|         0|            0|            0|  0.00%|
   155|         0|            0|            0|  0.00%|
   156|         0|            0|            0|  0.00%|
   157|         0|            0|            0|  0.00%|
   158|         0|            0|            0|  0.00%|
   159|         0|            0|            0|  0.00%|
   160|         0|            0|            0|  0.00%|
   161|         0|            0|            0|  0.00%|
   162|         0|            0|            0|  0.00%|
   163|         0|            0|            0|  0.00%|
   164|         0|            0|            0|  0.00%|
   165|         0|            0|            0|  0.00%|
   166|         0|            0|            0|  0.00%|
   167|         0|            0|            0|  0.00%|
   168|         0|            0|            0|  0.00%|
   169|         0|            0|            0|  0.00%|
   170|         0|            0|            0|  0.00%|
   171|         0|            0|            0|  0.00%|
   172|         0|            0|            0|  0.00%|
   173|         0|            0|            0|  0.00%|
   174|         0|            0|            0|  0.00%|
   175|         0|            0|            0|  0.00%|
   176|         0|            0|            0|  0.00%|
   177|    112042|     0.250854|  2.23893e-06|  0.24%|
   178|         0|            0|            0|  0.00%|
   179|    112042|     0.789017|  7.04215e-06|  0.76%|
(call)|     11906|    0.0468011|  3.93088e-06|  0.04%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/multiarray.py:1071 copyto
(call)|      5892|    0.0221815|  3.76468e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2491 _cumsum_dispatcher
(call)|      5892|     0.021631|  3.67125e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:1315 _searchsorted_dispatcher
(call)|     59335|     0.229606|  3.86965e-06|  0.22%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/multiarray.py:341 where
(call)|     10557|    0.0417132|  3.95124e-06|  0.04%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/numeric.py:72 _zeros_like_dispatcher
(call)|     10557|    0.0397322|  3.76359e-06|  0.04%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/multiarray.py:80 empty_like
(call)|      7867|    0.0343046|  4.36057e-06|  0.03%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2155 _sum_dispatcher
(call)|        36|  0.000171661|  4.76837e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3619 _var_dispatcher
   180|    224084|     0.818026|  3.65053e-06|  0.78%|
(call)|      5892|     0.296761|  5.03667e-05|  0.28%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2495 cumsum
(call)|      5892|     0.128206|  2.17594e-05|  0.12%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:1319 searchsorted
(call)|     10557|     0.667938|  6.32697e-05|  0.64%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/numeric.py:76 zeros_like
(call)|      7867|     0.455611|  5.79142e-05|  0.44%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2160 sum
(call)|        36|   0.00695539|  0.000193205|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3624 var
   181|    112042|     0.209093|   1.8662e-06|  0.20%|
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py
File duration: 0.960029s (0.92%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|"""Module containing non-deprecated functions borrowed from Numeric.
     2|         0|            0|            0|  0.00%|
     3|         0|            0|            0|  0.00%|"""
     4|         0|            0|            0|  0.00%|import functools
     5|         0|            0|            0|  0.00%|import types
     6|         0|            0|            0|  0.00%|import warnings
     7|         0|            0|            0|  0.00%|
     8|         0|            0|            0|  0.00%|import numpy as np
     9|         0|            0|            0|  0.00%|from . import multiarray as mu
    10|         0|            0|            0|  0.00%|from . import overrides
    11|         0|            0|            0|  0.00%|from . import umath as um
    12|         0|            0|            0|  0.00%|from . import numerictypes as nt
    13|         0|            0|            0|  0.00%|from .multiarray import asarray, array, asanyarray, concatenate
    14|         0|            0|            0|  0.00%|from . import _methods
    15|         0|            0|            0|  0.00%|
    16|         0|            0|            0|  0.00%|_dt_ = nt.sctype2char
    17|         0|            0|            0|  0.00%|
    18|         0|            0|            0|  0.00%|# functions that are methods
    19|         0|            0|            0|  0.00%|__all__ = [
    20|         0|            0|            0|  0.00%|    'alen', 'all', 'alltrue', 'amax', 'amin', 'any', 'argmax',
    21|         0|            0|            0|  0.00%|    'argmin', 'argpartition', 'argsort', 'around', 'choose', 'clip',
    22|         0|            0|            0|  0.00%|    'compress', 'cumprod', 'cumproduct', 'cumsum', 'diagonal', 'mean',
    23|         0|            0|            0|  0.00%|    'ndim', 'nonzero', 'partition', 'prod', 'product', 'ptp', 'put',
    24|         0|            0|            0|  0.00%|    'ravel', 'repeat', 'reshape', 'resize', 'round_',
    25|         0|            0|            0|  0.00%|    'searchsorted', 'shape', 'size', 'sometrue', 'sort', 'squeeze',
    26|         0|            0|            0|  0.00%|    'std', 'sum', 'swapaxes', 'take', 'trace', 'transpose', 'var',
    27|         0|            0|            0|  0.00%|]
    28|         0|            0|            0|  0.00%|
    29|         0|            0|            0|  0.00%|_gentype = types.GeneratorType
    30|         0|            0|            0|  0.00%|# save away Python sum
    31|         0|            0|            0|  0.00%|_sum_ = sum
    32|         0|            0|            0|  0.00%|
    33|         0|            0|            0|  0.00%|array_function_dispatch = functools.partial(
    34|         0|            0|            0|  0.00%|    overrides.array_function_dispatch, module='numpy')
    35|         0|            0|            0|  0.00%|
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|# functions that are now methods
    38|      5892|    0.0109129|  1.85215e-06|  0.01%|def _wrapit(obj, method, *args, **kwds):
    39|      5892|    0.0122263|  2.07508e-06|  0.01%|    try:
    40|      5892|    0.0288239|  4.89203e-06|  0.03%|        wrap = obj.__array_wrap__
    41|      5892|    0.0154953|  2.62989e-06|  0.01%|    except AttributeError:
    42|      5892|     0.014626|  2.48235e-06|  0.01%|        wrap = None
    43|      5892|    0.0604117|  1.02532e-05|  0.06%|    result = getattr(asarray(obj), method)(*args, **kwds)
    44|      5892|    0.0127087|  2.15694e-06|  0.01%|    if wrap:
    45|         0|            0|            0|  0.00%|        if not isinstance(result, mu.ndarray):
    46|         0|            0|            0|  0.00%|            result = asarray(result)
    47|         0|            0|            0|  0.00%|        result = wrap(result)
    48|      5892|    0.0106311|  1.80433e-06|  0.01%|    return result
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|
    51|     11784|    0.0231156|  1.96161e-06|  0.02%|def _wrapfunc(obj, method, *args, **kwds):
    52|     11784|       0.0279|  2.36762e-06|  0.03%|    bound = getattr(obj, method, None)
    53|     11784|    0.0219398|  1.86183e-06|  0.02%|    if bound is None:
    54|      5892|    0.0440543|  7.47696e-06|  0.04%|        return _wrapit(obj, method, *args, **kwds)
(call)|      5892|     0.165836|  2.81459e-05|  0.16%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:38 _wrapit
    55|         0|            0|            0|  0.00%|
    56|      5892|   0.00981212|  1.66533e-06|  0.01%|    try:
    57|      5892|    0.0296969|  5.04021e-06|  0.03%|        return bound(*args, **kwds)
    58|         0|            0|            0|  0.00%|    except TypeError:
    59|         0|            0|            0|  0.00%|        # A TypeError occurs if the object does have such a method in its
    60|         0|            0|            0|  0.00%|        # class, but its signature is not identical to that of NumPy's. This
    61|         0|            0|            0|  0.00%|        # situation has occurred in the case of a downstream library like
    62|         0|            0|            0|  0.00%|        # 'pandas'.
    63|         0|            0|            0|  0.00%|        #
    64|         0|            0|            0|  0.00%|        # Call _wrapit from within the except clause to ensure a potential
    65|         0|            0|            0|  0.00%|        # exception has a traceback chain.
    66|         0|            0|            0|  0.00%|        return _wrapit(obj, method, *args, **kwds)
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|
    69|      7867|    0.0220873|  2.80759e-06|  0.02%|def _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs):
    70|     47202|     0.136307|  2.88774e-06|  0.13%|    passkwargs = {k: v for k, v in kwargs.items()
(call)|      7867|     0.112173|  1.42586e-05|  0.11%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:70 <dictcomp>
    71|     23601|    0.0390897|  1.65627e-06|  0.04%|                  if v is not np._NoValue}
    72|         0|            0|            0|  0.00%|
    73|      7867|    0.0238438|  3.03086e-06|  0.02%|    if type(obj) is not mu.ndarray:
    74|         0|            0|            0|  0.00%|        try:
    75|         0|            0|            0|  0.00%|            reduction = getattr(obj, method)
    76|         0|            0|            0|  0.00%|        except AttributeError:
    77|         0|            0|            0|  0.00%|            pass
    78|         0|            0|            0|  0.00%|        else:
    79|         0|            0|            0|  0.00%|            # This branch is needed for reductions like any which don't
    80|         0|            0|            0|  0.00%|            # support a dtype.
    81|         0|            0|            0|  0.00%|            if dtype is not None:
    82|         0|            0|            0|  0.00%|                return reduction(axis=axis, dtype=dtype, out=out, **passkwargs)
    83|         0|            0|            0|  0.00%|            else:
    84|         0|            0|            0|  0.00%|                return reduction(axis=axis, out=out, **passkwargs)
    85|         0|            0|            0|  0.00%|
    86|      7867|    0.0777493|  9.88296e-06|  0.07%|    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
    87|         0|            0|            0|  0.00%|
    88|         0|            0|            0|  0.00%|
    89|         0|            0|            0|  0.00%|def _take_dispatcher(a, indices, axis=None, out=None, mode=None):
    90|         0|            0|            0|  0.00%|    return (a, out)
    91|         0|            0|            0|  0.00%|
    92|         0|            0|            0|  0.00%|
    93|         0|            0|            0|  0.00%|@array_function_dispatch(_take_dispatcher)
    94|         0|            0|            0|  0.00%|def take(a, indices, axis=None, out=None, mode='raise'):
    95|         0|            0|            0|  0.00%|    """
    96|         0|            0|            0|  0.00%|    Take elements from an array along an axis.
    97|         0|            0|            0|  0.00%|
    98|         0|            0|            0|  0.00%|    When axis is not None, this function does the same thing as "fancy"
    99|         0|            0|            0|  0.00%|    indexing (indexing arrays using arrays); however, it can be easier to use
   100|         0|            0|            0|  0.00%|    if you need elements along a given axis. A call such as
   101|         0|            0|            0|  0.00%|    ``np.take(arr, indices, axis=3)`` is equivalent to
   102|         0|            0|            0|  0.00%|    ``arr[:,:,:,indices,...]``.
   103|         0|            0|            0|  0.00%|
   104|         0|            0|            0|  0.00%|    Explained without fancy indexing, this is equivalent to the following use
   105|         0|            0|            0|  0.00%|    of `ndindex`, which sets each of ``ii``, ``jj``, and ``kk`` to a tuple of
   106|         0|            0|            0|  0.00%|    indices::
   107|         0|            0|            0|  0.00%|
   108|         0|            0|            0|  0.00%|        Ni, Nk = a.shape[:axis], a.shape[axis+1:]
   109|         0|            0|            0|  0.00%|        Nj = indices.shape
   110|         0|            0|            0|  0.00%|        for ii in ndindex(Ni):
   111|         0|            0|            0|  0.00%|            for jj in ndindex(Nj):
   112|         0|            0|            0|  0.00%|                for kk in ndindex(Nk):
   113|         0|            0|            0|  0.00%|                    out[ii + jj + kk] = a[ii + (indices[jj],) + kk]
   114|         0|            0|            0|  0.00%|
   115|         0|            0|            0|  0.00%|    Parameters
   116|         0|            0|            0|  0.00%|    ----------
   117|         0|            0|            0|  0.00%|    a : array_like (Ni..., M, Nk...)
   118|         0|            0|            0|  0.00%|        The source array.
   119|         0|            0|            0|  0.00%|    indices : array_like (Nj...)
   120|         0|            0|            0|  0.00%|        The indices of the values to extract.
   121|         0|            0|            0|  0.00%|
   122|         0|            0|            0|  0.00%|        .. versionadded:: 1.8.0
   123|         0|            0|            0|  0.00%|
   124|         0|            0|            0|  0.00%|        Also allow scalars for indices.
   125|         0|            0|            0|  0.00%|    axis : int, optional
   126|         0|            0|            0|  0.00%|        The axis over which to select values. By default, the flattened
   127|         0|            0|            0|  0.00%|        input array is used.
   128|         0|            0|            0|  0.00%|    out : ndarray, optional (Ni..., Nj..., Nk...)
   129|         0|            0|            0|  0.00%|        If provided, the result will be placed in this array. It should
   130|         0|            0|            0|  0.00%|        be of the appropriate shape and dtype. Note that `out` is always
   131|         0|            0|            0|  0.00%|        buffered if `mode='raise'`; use other modes for better performance.
   132|         0|            0|            0|  0.00%|    mode : {'raise', 'wrap', 'clip'}, optional
   133|         0|            0|            0|  0.00%|        Specifies how out-of-bounds indices will behave.
   134|         0|            0|            0|  0.00%|
   135|         0|            0|            0|  0.00%|        * 'raise' -- raise an error (default)
   136|         0|            0|            0|  0.00%|        * 'wrap' -- wrap around
   137|         0|            0|            0|  0.00%|        * 'clip' -- clip to the range
   138|         0|            0|            0|  0.00%|
   139|         0|            0|            0|  0.00%|        'clip' mode means that all indices that are too large are replaced
   140|         0|            0|            0|  0.00%|        by the index that addresses the last element along that axis. Note
   141|         0|            0|            0|  0.00%|        that this disables indexing with negative numbers.
   142|         0|            0|            0|  0.00%|
   143|         0|            0|            0|  0.00%|    Returns
   144|         0|            0|            0|  0.00%|    -------
   145|         0|            0|            0|  0.00%|    out : ndarray (Ni..., Nj..., Nk...)
   146|         0|            0|            0|  0.00%|        The returned array has the same type as `a`.
   147|         0|            0|            0|  0.00%|
   148|         0|            0|            0|  0.00%|    See Also
   149|         0|            0|            0|  0.00%|    --------
   150|         0|            0|            0|  0.00%|    compress : Take elements using a boolean mask
   151|         0|            0|            0|  0.00%|    ndarray.take : equivalent method
   152|         0|            0|            0|  0.00%|    take_along_axis : Take elements by matching the array and the index arrays
   153|         0|            0|            0|  0.00%|
   154|         0|            0|            0|  0.00%|    Notes
   155|         0|            0|            0|  0.00%|    -----
   156|         0|            0|            0|  0.00%|
   157|         0|            0|            0|  0.00%|    By eliminating the inner loop in the description above, and using `s_` to
   158|         0|            0|            0|  0.00%|    build simple slice objects, `take` can be expressed  in terms of applying
   159|         0|            0|            0|  0.00%|    fancy indexing to each 1-d slice::
   160|         0|            0|            0|  0.00%|
   161|         0|            0|            0|  0.00%|        Ni, Nk = a.shape[:axis], a.shape[axis+1:]
   162|         0|            0|            0|  0.00%|        for ii in ndindex(Ni):
   163|         0|            0|            0|  0.00%|            for kk in ndindex(Nj):
   164|         0|            0|            0|  0.00%|                out[ii + s_[...,] + kk] = a[ii + s_[:,] + kk][indices]
   165|         0|            0|            0|  0.00%|
   166|         0|            0|            0|  0.00%|    For this reason, it is equivalent to (but faster than) the following use
   167|         0|            0|            0|  0.00%|    of `apply_along_axis`::
   168|         0|            0|            0|  0.00%|
   169|         0|            0|            0|  0.00%|        out = np.apply_along_axis(lambda a_1d: a_1d[indices], axis, a)
   170|         0|            0|            0|  0.00%|
   171|         0|            0|            0|  0.00%|    Examples
   172|         0|            0|            0|  0.00%|    --------
   173|         0|            0|            0|  0.00%|    >>> a = [4, 3, 5, 7, 6, 8]
   174|         0|            0|            0|  0.00%|    >>> indices = [0, 1, 4]
   175|         0|            0|            0|  0.00%|    >>> np.take(a, indices)
   176|         0|            0|            0|  0.00%|    array([4, 3, 6])
   177|         0|            0|            0|  0.00%|
   178|         0|            0|            0|  0.00%|    In this example if `a` is an ndarray, "fancy" indexing can be used.
   179|         0|            0|            0|  0.00%|
   180|         0|            0|            0|  0.00%|    >>> a = np.array(a)
   181|         0|            0|            0|  0.00%|    >>> a[indices]
   182|         0|            0|            0|  0.00%|    array([4, 3, 6])
   183|         0|            0|            0|  0.00%|
   184|         0|            0|            0|  0.00%|    If `indices` is not one dimensional, the output also has these dimensions.
   185|         0|            0|            0|  0.00%|
   186|         0|            0|            0|  0.00%|    >>> np.take(a, [[0, 1], [2, 3]])
   187|         0|            0|            0|  0.00%|    array([[4, 3],
   188|         0|            0|            0|  0.00%|           [5, 7]])
   189|         0|            0|            0|  0.00%|    """
   190|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'take', indices, axis=axis, out=out, mode=mode)
   191|         0|            0|            0|  0.00%|
   192|         0|            0|            0|  0.00%|
   193|         0|            0|            0|  0.00%|def _reshape_dispatcher(a, newshape, order=None):
   194|         0|            0|            0|  0.00%|    return (a,)
   195|         0|            0|            0|  0.00%|
   196|         0|            0|            0|  0.00%|
   197|         0|            0|            0|  0.00%|# not deprecated --- copy if necessary, view otherwise
   198|         0|            0|            0|  0.00%|@array_function_dispatch(_reshape_dispatcher)
   199|         0|            0|            0|  0.00%|def reshape(a, newshape, order='C'):
   200|         0|            0|            0|  0.00%|    """
   201|         0|            0|            0|  0.00%|    Gives a new shape to an array without changing its data.
   202|         0|            0|            0|  0.00%|
   203|         0|            0|            0|  0.00%|    Parameters
   204|         0|            0|            0|  0.00%|    ----------
   205|         0|            0|            0|  0.00%|    a : array_like
   206|         0|            0|            0|  0.00%|        Array to be reshaped.
   207|         0|            0|            0|  0.00%|    newshape : int or tuple of ints
   208|         0|            0|            0|  0.00%|        The new shape should be compatible with the original shape. If
   209|         0|            0|            0|  0.00%|        an integer, then the result will be a 1-D array of that length.
   210|         0|            0|            0|  0.00%|        One shape dimension can be -1. In this case, the value is
   211|         0|            0|            0|  0.00%|        inferred from the length of the array and remaining dimensions.
   212|         0|            0|            0|  0.00%|    order : {'C', 'F', 'A'}, optional
   213|         0|            0|            0|  0.00%|        Read the elements of `a` using this index order, and place the
   214|         0|            0|            0|  0.00%|        elements into the reshaped array using this index order.  'C'
   215|         0|            0|            0|  0.00%|        means to read / write the elements using C-like index order,
   216|         0|            0|            0|  0.00%|        with the last axis index changing fastest, back to the first
   217|         0|            0|            0|  0.00%|        axis index changing slowest. 'F' means to read / write the
   218|         0|            0|            0|  0.00%|        elements using Fortran-like index order, with the first index
   219|         0|            0|            0|  0.00%|        changing fastest, and the last index changing slowest. Note that
   220|         0|            0|            0|  0.00%|        the 'C' and 'F' options take no account of the memory layout of
   221|         0|            0|            0|  0.00%|        the underlying array, and only refer to the order of indexing.
   222|         0|            0|            0|  0.00%|        'A' means to read / write the elements in Fortran-like index
   223|         0|            0|            0|  0.00%|        order if `a` is Fortran *contiguous* in memory, C-like order
   224|         0|            0|            0|  0.00%|        otherwise.
   225|         0|            0|            0|  0.00%|
   226|         0|            0|            0|  0.00%|    Returns
   227|         0|            0|            0|  0.00%|    -------
   228|         0|            0|            0|  0.00%|    reshaped_array : ndarray
   229|         0|            0|            0|  0.00%|        This will be a new view object if possible; otherwise, it will
   230|         0|            0|            0|  0.00%|        be a copy.  Note there is no guarantee of the *memory layout* (C- or
   231|         0|            0|            0|  0.00%|        Fortran- contiguous) of the returned array.
   232|         0|            0|            0|  0.00%|
   233|         0|            0|            0|  0.00%|    See Also
   234|         0|            0|            0|  0.00%|    --------
   235|         0|            0|            0|  0.00%|    ndarray.reshape : Equivalent method.
   236|         0|            0|            0|  0.00%|
   237|         0|            0|            0|  0.00%|    Notes
   238|         0|            0|            0|  0.00%|    -----
   239|         0|            0|            0|  0.00%|    It is not always possible to change the shape of an array without
   240|         0|            0|            0|  0.00%|    copying the data. If you want an error to be raised when the data is copied,
   241|         0|            0|            0|  0.00%|    you should assign the new shape to the shape attribute of the array::
   242|         0|            0|            0|  0.00%|
   243|         0|            0|            0|  0.00%|     >>> a = np.zeros((10, 2))
   244|         0|            0|            0|  0.00%|
   245|         0|            0|            0|  0.00%|     # A transpose makes the array non-contiguous
   246|         0|            0|            0|  0.00%|     >>> b = a.T
   247|         0|            0|            0|  0.00%|
   248|         0|            0|            0|  0.00%|     # Taking a view makes it possible to modify the shape without modifying
   249|         0|            0|            0|  0.00%|     # the initial object.
   250|         0|            0|            0|  0.00%|     >>> c = b.view()
   251|         0|            0|            0|  0.00%|     >>> c.shape = (20)
   252|         0|            0|            0|  0.00%|     Traceback (most recent call last):
   253|         0|            0|            0|  0.00%|        ...
   254|         0|            0|            0|  0.00%|     AttributeError: Incompatible shape for in-place modification. Use
   255|         0|            0|            0|  0.00%|     `.reshape()` to make a copy with the desired shape.
   256|         0|            0|            0|  0.00%|
   257|         0|            0|            0|  0.00%|    The `order` keyword gives the index ordering both for *fetching* the values
   258|         0|            0|            0|  0.00%|    from `a`, and then *placing* the values into the output array.
   259|         0|            0|            0|  0.00%|    For example, let's say you have an array:
   260|         0|            0|            0|  0.00%|
   261|         0|            0|            0|  0.00%|    >>> a = np.arange(6).reshape((3, 2))
   262|         0|            0|            0|  0.00%|    >>> a
   263|         0|            0|            0|  0.00%|    array([[0, 1],
   264|         0|            0|            0|  0.00%|           [2, 3],
   265|         0|            0|            0|  0.00%|           [4, 5]])
   266|         0|            0|            0|  0.00%|
   267|         0|            0|            0|  0.00%|    You can think of reshaping as first raveling the array (using the given
   268|         0|            0|            0|  0.00%|    index order), then inserting the elements from the raveled array into the
   269|         0|            0|            0|  0.00%|    new array using the same kind of index ordering as was used for the
   270|         0|            0|            0|  0.00%|    raveling.
   271|         0|            0|            0|  0.00%|
   272|         0|            0|            0|  0.00%|    >>> np.reshape(a, (2, 3)) # C-like index ordering
   273|         0|            0|            0|  0.00%|    array([[0, 1, 2],
   274|         0|            0|            0|  0.00%|           [3, 4, 5]])
   275|         0|            0|            0|  0.00%|    >>> np.reshape(np.ravel(a), (2, 3)) # equivalent to C ravel then C reshape
   276|         0|            0|            0|  0.00%|    array([[0, 1, 2],
   277|         0|            0|            0|  0.00%|           [3, 4, 5]])
   278|         0|            0|            0|  0.00%|    >>> np.reshape(a, (2, 3), order='F') # Fortran-like index ordering
   279|         0|            0|            0|  0.00%|    array([[0, 4, 3],
   280|         0|            0|            0|  0.00%|           [2, 1, 5]])
   281|         0|            0|            0|  0.00%|    >>> np.reshape(np.ravel(a, order='F'), (2, 3), order='F')
   282|         0|            0|            0|  0.00%|    array([[0, 4, 3],
   283|         0|            0|            0|  0.00%|           [2, 1, 5]])
   284|         0|            0|            0|  0.00%|
   285|         0|            0|            0|  0.00%|    Examples
   286|         0|            0|            0|  0.00%|    --------
   287|         0|            0|            0|  0.00%|    >>> a = np.array([[1,2,3], [4,5,6]])
   288|         0|            0|            0|  0.00%|    >>> np.reshape(a, 6)
   289|         0|            0|            0|  0.00%|    array([1, 2, 3, 4, 5, 6])
   290|         0|            0|            0|  0.00%|    >>> np.reshape(a, 6, order='F')
   291|         0|            0|            0|  0.00%|    array([1, 4, 2, 5, 3, 6])
   292|         0|            0|            0|  0.00%|
   293|         0|            0|            0|  0.00%|    >>> np.reshape(a, (3,-1))       # the unspecified value is inferred to be 2
   294|         0|            0|            0|  0.00%|    array([[1, 2],
   295|         0|            0|            0|  0.00%|           [3, 4],
   296|         0|            0|            0|  0.00%|           [5, 6]])
   297|         0|            0|            0|  0.00%|    """
   298|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'reshape', newshape, order=order)
   299|         0|            0|            0|  0.00%|
   300|         0|            0|            0|  0.00%|
   301|         0|            0|            0|  0.00%|def _choose_dispatcher(a, choices, out=None, mode=None):
   302|         0|            0|            0|  0.00%|    yield a
   303|         0|            0|            0|  0.00%|    yield from choices
   304|         0|            0|            0|  0.00%|    yield out
   305|         0|            0|            0|  0.00%|
   306|         0|            0|            0|  0.00%|
   307|         0|            0|            0|  0.00%|@array_function_dispatch(_choose_dispatcher)
   308|         0|            0|            0|  0.00%|def choose(a, choices, out=None, mode='raise'):
   309|         0|            0|            0|  0.00%|    """
   310|         0|            0|            0|  0.00%|    Construct an array from an index array and a list of arrays to choose from.
   311|         0|            0|            0|  0.00%|
   312|         0|            0|            0|  0.00%|    First of all, if confused or uncertain, definitely look at the Examples -
   313|         0|            0|            0|  0.00%|    in its full generality, this function is less simple than it might
   314|         0|            0|            0|  0.00%|    seem from the following code description (below ndi =
   315|         0|            0|            0|  0.00%|    `numpy.lib.index_tricks`):
   316|         0|            0|            0|  0.00%|
   317|         0|            0|            0|  0.00%|    ``np.choose(a,c) == np.array([c[a[I]][I] for I in ndi.ndindex(a.shape)])``.
   318|         0|            0|            0|  0.00%|
   319|         0|            0|            0|  0.00%|    But this omits some subtleties.  Here is a fully general summary:
   320|         0|            0|            0|  0.00%|
   321|         0|            0|            0|  0.00%|    Given an "index" array (`a`) of integers and a sequence of ``n`` arrays
   322|         0|            0|            0|  0.00%|    (`choices`), `a` and each choice array are first broadcast, as necessary,
   323|         0|            0|            0|  0.00%|    to arrays of a common shape; calling these *Ba* and *Bchoices[i], i =
   324|         0|            0|            0|  0.00%|    0,...,n-1* we have that, necessarily, ``Ba.shape == Bchoices[i].shape``
   325|         0|            0|            0|  0.00%|    for each ``i``.  Then, a new array with shape ``Ba.shape`` is created as
   326|         0|            0|            0|  0.00%|    follows:
   327|         0|            0|            0|  0.00%|
   328|         0|            0|            0|  0.00%|    * if ``mode='raise'`` (the default), then, first of all, each element of
   329|         0|            0|            0|  0.00%|      ``a`` (and thus ``Ba``) must be in the range ``[0, n-1]``; now, suppose
   330|         0|            0|            0|  0.00%|      that ``i`` (in that range) is the value at the ``(j0, j1, ..., jm)``
   331|         0|            0|            0|  0.00%|      position in ``Ba`` - then the value at the same position in the new array
   332|         0|            0|            0|  0.00%|      is the value in ``Bchoices[i]`` at that same position;
   333|         0|            0|            0|  0.00%|
   334|         0|            0|            0|  0.00%|    * if ``mode='wrap'``, values in `a` (and thus `Ba`) may be any (signed)
   335|         0|            0|            0|  0.00%|      integer; modular arithmetic is used to map integers outside the range
   336|         0|            0|            0|  0.00%|      `[0, n-1]` back into that range; and then the new array is constructed
   337|         0|            0|            0|  0.00%|      as above;
   338|         0|            0|            0|  0.00%|
   339|         0|            0|            0|  0.00%|    * if ``mode='clip'``, values in `a` (and thus ``Ba``) may be any (signed)
   340|         0|            0|            0|  0.00%|      integer; negative integers are mapped to 0; values greater than ``n-1``
   341|         0|            0|            0|  0.00%|      are mapped to ``n-1``; and then the new array is constructed as above.
   342|         0|            0|            0|  0.00%|
   343|         0|            0|            0|  0.00%|    Parameters
   344|         0|            0|            0|  0.00%|    ----------
   345|         0|            0|            0|  0.00%|    a : int array
   346|         0|            0|            0|  0.00%|        This array must contain integers in ``[0, n-1]``, where ``n`` is the
   347|         0|            0|            0|  0.00%|        number of choices, unless ``mode=wrap`` or ``mode=clip``, in which
   348|         0|            0|            0|  0.00%|        cases any integers are permissible.
   349|         0|            0|            0|  0.00%|    choices : sequence of arrays
   350|         0|            0|            0|  0.00%|        Choice arrays. `a` and all of the choices must be broadcastable to the
   351|         0|            0|            0|  0.00%|        same shape.  If `choices` is itself an array (not recommended), then
   352|         0|            0|            0|  0.00%|        its outermost dimension (i.e., the one corresponding to
   353|         0|            0|            0|  0.00%|        ``choices.shape[0]``) is taken as defining the "sequence".
   354|         0|            0|            0|  0.00%|    out : array, optional
   355|         0|            0|            0|  0.00%|        If provided, the result will be inserted into this array. It should
   356|         0|            0|            0|  0.00%|        be of the appropriate shape and dtype. Note that `out` is always
   357|         0|            0|            0|  0.00%|        buffered if ``mode='raise'``; use other modes for better performance.
   358|         0|            0|            0|  0.00%|    mode : {'raise' (default), 'wrap', 'clip'}, optional
   359|         0|            0|            0|  0.00%|        Specifies how indices outside ``[0, n-1]`` will be treated:
   360|         0|            0|            0|  0.00%|
   361|         0|            0|            0|  0.00%|          * 'raise' : an exception is raised
   362|         0|            0|            0|  0.00%|          * 'wrap' : value becomes value mod ``n``
   363|         0|            0|            0|  0.00%|          * 'clip' : values < 0 are mapped to 0, values > n-1 are mapped to n-1
   364|         0|            0|            0|  0.00%|
   365|         0|            0|            0|  0.00%|    Returns
   366|         0|            0|            0|  0.00%|    -------
   367|         0|            0|            0|  0.00%|    merged_array : array
   368|         0|            0|            0|  0.00%|        The merged result.
   369|         0|            0|            0|  0.00%|
   370|         0|            0|            0|  0.00%|    Raises
   371|         0|            0|            0|  0.00%|    ------
   372|         0|            0|            0|  0.00%|    ValueError: shape mismatch
   373|         0|            0|            0|  0.00%|        If `a` and each choice array are not all broadcastable to the same
   374|         0|            0|            0|  0.00%|        shape.
   375|         0|            0|            0|  0.00%|
   376|         0|            0|            0|  0.00%|    See Also
   377|         0|            0|            0|  0.00%|    --------
   378|         0|            0|            0|  0.00%|    ndarray.choose : equivalent method
   379|         0|            0|            0|  0.00%|    numpy.take_along_axis : Preferable if `choices` is an array
   380|         0|            0|            0|  0.00%|
   381|         0|            0|            0|  0.00%|    Notes
   382|         0|            0|            0|  0.00%|    -----
   383|         0|            0|            0|  0.00%|    To reduce the chance of misinterpretation, even though the following
   384|         0|            0|            0|  0.00%|    "abuse" is nominally supported, `choices` should neither be, nor be
   385|         0|            0|            0|  0.00%|    thought of as, a single array, i.e., the outermost sequence-like container
   386|         0|            0|            0|  0.00%|    should be either a list or a tuple.
   387|         0|            0|            0|  0.00%|
   388|         0|            0|            0|  0.00%|    Examples
   389|         0|            0|            0|  0.00%|    --------
   390|         0|            0|            0|  0.00%|
   391|         0|            0|            0|  0.00%|    >>> choices = [[0, 1, 2, 3], [10, 11, 12, 13],
   392|         0|            0|            0|  0.00%|    ...   [20, 21, 22, 23], [30, 31, 32, 33]]
   393|         0|            0|            0|  0.00%|    >>> np.choose([2, 3, 1, 0], choices
   394|         0|            0|            0|  0.00%|    ... # the first element of the result will be the first element of the
   395|         0|            0|            0|  0.00%|    ... # third (2+1) "array" in choices, namely, 20; the second element
   396|         0|            0|            0|  0.00%|    ... # will be the second element of the fourth (3+1) choice array, i.e.,
   397|         0|            0|            0|  0.00%|    ... # 31, etc.
   398|         0|            0|            0|  0.00%|    ... )
   399|         0|            0|            0|  0.00%|    array([20, 31, 12,  3])
   400|         0|            0|            0|  0.00%|    >>> np.choose([2, 4, 1, 0], choices, mode='clip') # 4 goes to 3 (4-1)
   401|         0|            0|            0|  0.00%|    array([20, 31, 12,  3])
   402|         0|            0|            0|  0.00%|    >>> # because there are 4 choice arrays
   403|         0|            0|            0|  0.00%|    >>> np.choose([2, 4, 1, 0], choices, mode='wrap') # 4 goes to (4 mod 4)
   404|         0|            0|            0|  0.00%|    array([20,  1, 12,  3])
   405|         0|            0|            0|  0.00%|    >>> # i.e., 0
   406|         0|            0|            0|  0.00%|
   407|         0|            0|            0|  0.00%|    A couple examples illustrating how choose broadcasts:
   408|         0|            0|            0|  0.00%|
   409|         0|            0|            0|  0.00%|    >>> a = [[1, 0, 1], [0, 1, 0], [1, 0, 1]]
   410|         0|            0|            0|  0.00%|    >>> choices = [-10, 10]
   411|         0|            0|            0|  0.00%|    >>> np.choose(a, choices)
   412|         0|            0|            0|  0.00%|    array([[ 10, -10,  10],
   413|         0|            0|            0|  0.00%|           [-10,  10, -10],
   414|         0|            0|            0|  0.00%|           [ 10, -10,  10]])
   415|         0|            0|            0|  0.00%|
   416|         0|            0|            0|  0.00%|    >>> # With thanks to Anne Archibald
   417|         0|            0|            0|  0.00%|    >>> a = np.array([0, 1]).reshape((2,1,1))
   418|         0|            0|            0|  0.00%|    >>> c1 = np.array([1, 2, 3]).reshape((1,3,1))
   419|         0|            0|            0|  0.00%|    >>> c2 = np.array([-1, -2, -3, -4, -5]).reshape((1,1,5))
   420|         0|            0|            0|  0.00%|    >>> np.choose(a, (c1, c2)) # result is 2x3x5, res[0,:,:]=c1, res[1,:,:]=c2
   421|         0|            0|            0|  0.00%|    array([[[ 1,  1,  1,  1,  1],
   422|         0|            0|            0|  0.00%|            [ 2,  2,  2,  2,  2],
   423|         0|            0|            0|  0.00%|            [ 3,  3,  3,  3,  3]],
   424|         0|            0|            0|  0.00%|           [[-1, -2, -3, -4, -5],
   425|         0|            0|            0|  0.00%|            [-1, -2, -3, -4, -5],
   426|         0|            0|            0|  0.00%|            [-1, -2, -3, -4, -5]]])
   427|         0|            0|            0|  0.00%|
   428|         0|            0|            0|  0.00%|    """
   429|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'choose', choices, out=out, mode=mode)
   430|         0|            0|            0|  0.00%|
   431|         0|            0|            0|  0.00%|
   432|         0|            0|            0|  0.00%|def _repeat_dispatcher(a, repeats, axis=None):
   433|         0|            0|            0|  0.00%|    return (a,)
   434|         0|            0|            0|  0.00%|
   435|         0|            0|            0|  0.00%|
   436|         0|            0|            0|  0.00%|@array_function_dispatch(_repeat_dispatcher)
   437|         0|            0|            0|  0.00%|def repeat(a, repeats, axis=None):
   438|         0|            0|            0|  0.00%|    """
   439|         0|            0|            0|  0.00%|    Repeat elements of an array.
   440|         0|            0|            0|  0.00%|
   441|         0|            0|            0|  0.00%|    Parameters
   442|         0|            0|            0|  0.00%|    ----------
   443|         0|            0|            0|  0.00%|    a : array_like
   444|         0|            0|            0|  0.00%|        Input array.
   445|         0|            0|            0|  0.00%|    repeats : int or array of ints
   446|         0|            0|            0|  0.00%|        The number of repetitions for each element.  `repeats` is broadcasted
   447|         0|            0|            0|  0.00%|        to fit the shape of the given axis.
   448|         0|            0|            0|  0.00%|    axis : int, optional
   449|         0|            0|            0|  0.00%|        The axis along which to repeat values.  By default, use the
   450|         0|            0|            0|  0.00%|        flattened input array, and return a flat output array.
   451|         0|            0|            0|  0.00%|
   452|         0|            0|            0|  0.00%|    Returns
   453|         0|            0|            0|  0.00%|    -------
   454|         0|            0|            0|  0.00%|    repeated_array : ndarray
   455|         0|            0|            0|  0.00%|        Output array which has the same shape as `a`, except along
   456|         0|            0|            0|  0.00%|        the given axis.
   457|         0|            0|            0|  0.00%|
   458|         0|            0|            0|  0.00%|    See Also
   459|         0|            0|            0|  0.00%|    --------
   460|         0|            0|            0|  0.00%|    tile : Tile an array.
   461|         0|            0|            0|  0.00%|    unique : Find the unique elements of an array.
   462|         0|            0|            0|  0.00%|
   463|         0|            0|            0|  0.00%|    Examples
   464|         0|            0|            0|  0.00%|    --------
   465|         0|            0|            0|  0.00%|    >>> np.repeat(3, 4)
   466|         0|            0|            0|  0.00%|    array([3, 3, 3, 3])
   467|         0|            0|            0|  0.00%|    >>> x = np.array([[1,2],[3,4]])
   468|         0|            0|            0|  0.00%|    >>> np.repeat(x, 2)
   469|         0|            0|            0|  0.00%|    array([1, 1, 2, 2, 3, 3, 4, 4])
   470|         0|            0|            0|  0.00%|    >>> np.repeat(x, 3, axis=1)
   471|         0|            0|            0|  0.00%|    array([[1, 1, 1, 2, 2, 2],
   472|         0|            0|            0|  0.00%|           [3, 3, 3, 4, 4, 4]])
   473|         0|            0|            0|  0.00%|    >>> np.repeat(x, [1, 2], axis=0)
   474|         0|            0|            0|  0.00%|    array([[1, 2],
   475|         0|            0|            0|  0.00%|           [3, 4],
   476|         0|            0|            0|  0.00%|           [3, 4]])
   477|         0|            0|            0|  0.00%|
   478|         0|            0|            0|  0.00%|    """
   479|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'repeat', repeats, axis=axis)
   480|         0|            0|            0|  0.00%|
   481|         0|            0|            0|  0.00%|
   482|         0|            0|            0|  0.00%|def _put_dispatcher(a, ind, v, mode=None):
   483|         0|            0|            0|  0.00%|    return (a, ind, v)
   484|         0|            0|            0|  0.00%|
   485|         0|            0|            0|  0.00%|
   486|         0|            0|            0|  0.00%|@array_function_dispatch(_put_dispatcher)
   487|         0|            0|            0|  0.00%|def put(a, ind, v, mode='raise'):
   488|         0|            0|            0|  0.00%|    """
   489|         0|            0|            0|  0.00%|    Replaces specified elements of an array with given values.
   490|         0|            0|            0|  0.00%|
   491|         0|            0|            0|  0.00%|    The indexing works on the flattened target array. `put` is roughly
   492|         0|            0|            0|  0.00%|    equivalent to:
   493|         0|            0|            0|  0.00%|
   494|         0|            0|            0|  0.00%|    ::
   495|         0|            0|            0|  0.00%|
   496|         0|            0|            0|  0.00%|        a.flat[ind] = v
   497|         0|            0|            0|  0.00%|
   498|         0|            0|            0|  0.00%|    Parameters
   499|         0|            0|            0|  0.00%|    ----------
   500|         0|            0|            0|  0.00%|    a : ndarray
   501|         0|            0|            0|  0.00%|        Target array.
   502|         0|            0|            0|  0.00%|    ind : array_like
   503|         0|            0|            0|  0.00%|        Target indices, interpreted as integers.
   504|         0|            0|            0|  0.00%|    v : array_like
   505|         0|            0|            0|  0.00%|        Values to place in `a` at target indices. If `v` is shorter than
   506|         0|            0|            0|  0.00%|        `ind` it will be repeated as necessary.
   507|         0|            0|            0|  0.00%|    mode : {'raise', 'wrap', 'clip'}, optional
   508|         0|            0|            0|  0.00%|        Specifies how out-of-bounds indices will behave.
   509|         0|            0|            0|  0.00%|
   510|         0|            0|            0|  0.00%|        * 'raise' -- raise an error (default)
   511|         0|            0|            0|  0.00%|        * 'wrap' -- wrap around
   512|         0|            0|            0|  0.00%|        * 'clip' -- clip to the range
   513|         0|            0|            0|  0.00%|
   514|         0|            0|            0|  0.00%|        'clip' mode means that all indices that are too large are replaced
   515|         0|            0|            0|  0.00%|        by the index that addresses the last element along that axis. Note
   516|         0|            0|            0|  0.00%|        that this disables indexing with negative numbers. In 'raise' mode,
   517|         0|            0|            0|  0.00%|        if an exception occurs the target array may still be modified.
   518|         0|            0|            0|  0.00%|
   519|         0|            0|            0|  0.00%|    See Also
   520|         0|            0|            0|  0.00%|    --------
   521|         0|            0|            0|  0.00%|    putmask, place
   522|         0|            0|            0|  0.00%|    put_along_axis : Put elements by matching the array and the index arrays
   523|         0|            0|            0|  0.00%|
   524|         0|            0|            0|  0.00%|    Examples
   525|         0|            0|            0|  0.00%|    --------
   526|         0|            0|            0|  0.00%|    >>> a = np.arange(5)
   527|         0|            0|            0|  0.00%|    >>> np.put(a, [0, 2], [-44, -55])
   528|         0|            0|            0|  0.00%|    >>> a
   529|         0|            0|            0|  0.00%|    array([-44,   1, -55,   3,   4])
   530|         0|            0|            0|  0.00%|
   531|         0|            0|            0|  0.00%|    >>> a = np.arange(5)
   532|         0|            0|            0|  0.00%|    >>> np.put(a, 22, -5, mode='clip')
   533|         0|            0|            0|  0.00%|    >>> a
   534|         0|            0|            0|  0.00%|    array([ 0,  1,  2,  3, -5])
   535|         0|            0|            0|  0.00%|
   536|         0|            0|            0|  0.00%|    """
   537|         0|            0|            0|  0.00%|    try:
   538|         0|            0|            0|  0.00%|        put = a.put
   539|         0|            0|            0|  0.00%|    except AttributeError as e:
   540|         0|            0|            0|  0.00%|        raise TypeError("argument 1 must be numpy.ndarray, "
   541|         0|            0|            0|  0.00%|                        "not {name}".format(name=type(a).__name__)) from e
   542|         0|            0|            0|  0.00%|
   543|         0|            0|            0|  0.00%|    return put(ind, v, mode=mode)
   544|         0|            0|            0|  0.00%|
   545|         0|            0|            0|  0.00%|
   546|         0|            0|            0|  0.00%|def _swapaxes_dispatcher(a, axis1, axis2):
   547|         0|            0|            0|  0.00%|    return (a,)
   548|         0|            0|            0|  0.00%|
   549|         0|            0|            0|  0.00%|
   550|         0|            0|            0|  0.00%|@array_function_dispatch(_swapaxes_dispatcher)
   551|         0|            0|            0|  0.00%|def swapaxes(a, axis1, axis2):
   552|         0|            0|            0|  0.00%|    """
   553|         0|            0|            0|  0.00%|    Interchange two axes of an array.
   554|         0|            0|            0|  0.00%|
   555|         0|            0|            0|  0.00%|    Parameters
   556|         0|            0|            0|  0.00%|    ----------
   557|         0|            0|            0|  0.00%|    a : array_like
   558|         0|            0|            0|  0.00%|        Input array.
   559|         0|            0|            0|  0.00%|    axis1 : int
   560|         0|            0|            0|  0.00%|        First axis.
   561|         0|            0|            0|  0.00%|    axis2 : int
   562|         0|            0|            0|  0.00%|        Second axis.
   563|         0|            0|            0|  0.00%|
   564|         0|            0|            0|  0.00%|    Returns
   565|         0|            0|            0|  0.00%|    -------
   566|         0|            0|            0|  0.00%|    a_swapped : ndarray
   567|         0|            0|            0|  0.00%|        For NumPy >= 1.10.0, if `a` is an ndarray, then a view of `a` is
   568|         0|            0|            0|  0.00%|        returned; otherwise a new array is created. For earlier NumPy
   569|         0|            0|            0|  0.00%|        versions a view of `a` is returned only if the order of the
   570|         0|            0|            0|  0.00%|        axes is changed, otherwise the input array is returned.
   571|         0|            0|            0|  0.00%|
   572|         0|            0|            0|  0.00%|    Examples
   573|         0|            0|            0|  0.00%|    --------
   574|         0|            0|            0|  0.00%|    >>> x = np.array([[1,2,3]])
   575|         0|            0|            0|  0.00%|    >>> np.swapaxes(x,0,1)
   576|         0|            0|            0|  0.00%|    array([[1],
   577|         0|            0|            0|  0.00%|           [2],
   578|         0|            0|            0|  0.00%|           [3]])
   579|         0|            0|            0|  0.00%|
   580|         0|            0|            0|  0.00%|    >>> x = np.array([[[0,1],[2,3]],[[4,5],[6,7]]])
   581|         0|            0|            0|  0.00%|    >>> x
   582|         0|            0|            0|  0.00%|    array([[[0, 1],
   583|         0|            0|            0|  0.00%|            [2, 3]],
   584|         0|            0|            0|  0.00%|           [[4, 5],
   585|         0|            0|            0|  0.00%|            [6, 7]]])
   586|         0|            0|            0|  0.00%|
   587|         0|            0|            0|  0.00%|    >>> np.swapaxes(x,0,2)
   588|         0|            0|            0|  0.00%|    array([[[0, 4],
   589|         0|            0|            0|  0.00%|            [2, 6]],
   590|         0|            0|            0|  0.00%|           [[1, 5],
   591|         0|            0|            0|  0.00%|            [3, 7]]])
   592|         0|            0|            0|  0.00%|
   593|         0|            0|            0|  0.00%|    """
   594|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'swapaxes', axis1, axis2)
   595|         0|            0|            0|  0.00%|
   596|         0|            0|            0|  0.00%|
   597|         0|            0|            0|  0.00%|def _transpose_dispatcher(a, axes=None):
   598|         0|            0|            0|  0.00%|    return (a,)
   599|         0|            0|            0|  0.00%|
   600|         0|            0|            0|  0.00%|
   601|         0|            0|            0|  0.00%|@array_function_dispatch(_transpose_dispatcher)
   602|         0|            0|            0|  0.00%|def transpose(a, axes=None):
   603|         0|            0|            0|  0.00%|    """
   604|         0|            0|            0|  0.00%|    Reverse or permute the axes of an array; returns the modified array.
   605|         0|            0|            0|  0.00%|
   606|         0|            0|            0|  0.00%|    For an array a with two axes, transpose(a) gives the matrix transpose.
   607|         0|            0|            0|  0.00%|
   608|         0|            0|            0|  0.00%|    Refer to `numpy.ndarray.transpose` for full documentation.
   609|         0|            0|            0|  0.00%|
   610|         0|            0|            0|  0.00%|    Parameters
   611|         0|            0|            0|  0.00%|    ----------
   612|         0|            0|            0|  0.00%|    a : array_like
   613|         0|            0|            0|  0.00%|        Input array.
   614|         0|            0|            0|  0.00%|    axes : tuple or list of ints, optional
   615|         0|            0|            0|  0.00%|        If specified, it must be a tuple or list which contains a permutation of
   616|         0|            0|            0|  0.00%|        [0,1,..,N-1] where N is the number of axes of a.  The i'th axis of the
   617|         0|            0|            0|  0.00%|        returned array will correspond to the axis numbered ``axes[i]`` of the
   618|         0|            0|            0|  0.00%|        input.  If not specified, defaults to ``range(a.ndim)[::-1]``, which
   619|         0|            0|            0|  0.00%|        reverses the order of the axes.
   620|         0|            0|            0|  0.00%|
   621|         0|            0|            0|  0.00%|    Returns
   622|         0|            0|            0|  0.00%|    -------
   623|         0|            0|            0|  0.00%|    p : ndarray
   624|         0|            0|            0|  0.00%|        `a` with its axes permuted.  A view is returned whenever
   625|         0|            0|            0|  0.00%|        possible.
   626|         0|            0|            0|  0.00%|
   627|         0|            0|            0|  0.00%|    See Also
   628|         0|            0|            0|  0.00%|    --------
   629|         0|            0|            0|  0.00%|    ndarray.transpose : Equivalent method
   630|         0|            0|            0|  0.00%|    moveaxis
   631|         0|            0|            0|  0.00%|    argsort
   632|         0|            0|            0|  0.00%|
   633|         0|            0|            0|  0.00%|    Notes
   634|         0|            0|            0|  0.00%|    -----
   635|         0|            0|            0|  0.00%|    Use `transpose(a, argsort(axes))` to invert the transposition of tensors
   636|         0|            0|            0|  0.00%|    when using the `axes` keyword argument.
   637|         0|            0|            0|  0.00%|
   638|         0|            0|            0|  0.00%|    Transposing a 1-D array returns an unchanged view of the original array.
   639|         0|            0|            0|  0.00%|
   640|         0|            0|            0|  0.00%|    Examples
   641|         0|            0|            0|  0.00%|    --------
   642|         0|            0|            0|  0.00%|    >>> x = np.arange(4).reshape((2,2))
   643|         0|            0|            0|  0.00%|    >>> x
   644|         0|            0|            0|  0.00%|    array([[0, 1],
   645|         0|            0|            0|  0.00%|           [2, 3]])
   646|         0|            0|            0|  0.00%|
   647|         0|            0|            0|  0.00%|    >>> np.transpose(x)
   648|         0|            0|            0|  0.00%|    array([[0, 2],
   649|         0|            0|            0|  0.00%|           [1, 3]])
   650|         0|            0|            0|  0.00%|
   651|         0|            0|            0|  0.00%|    >>> x = np.ones((1, 2, 3))
   652|         0|            0|            0|  0.00%|    >>> np.transpose(x, (1, 0, 2)).shape
   653|         0|            0|            0|  0.00%|    (2, 1, 3)
   654|         0|            0|            0|  0.00%|
   655|         0|            0|            0|  0.00%|    >>> x = np.ones((2, 3, 4, 5))
   656|         0|            0|            0|  0.00%|    >>> np.transpose(x).shape
   657|         0|            0|            0|  0.00%|    (5, 4, 3, 2)
   658|         0|            0|            0|  0.00%|
   659|         0|            0|            0|  0.00%|    """
   660|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'transpose', axes)
   661|         0|            0|            0|  0.00%|
   662|         0|            0|            0|  0.00%|
   663|         0|            0|            0|  0.00%|def _partition_dispatcher(a, kth, axis=None, kind=None, order=None):
   664|         0|            0|            0|  0.00%|    return (a,)
   665|         0|            0|            0|  0.00%|
   666|         0|            0|            0|  0.00%|
   667|         0|            0|            0|  0.00%|@array_function_dispatch(_partition_dispatcher)
   668|         0|            0|            0|  0.00%|def partition(a, kth, axis=-1, kind='introselect', order=None):
   669|         0|            0|            0|  0.00%|    """
   670|         0|            0|            0|  0.00%|    Return a partitioned copy of an array.
   671|         0|            0|            0|  0.00%|
   672|         0|            0|            0|  0.00%|    Creates a copy of the array with its elements rearranged in such a
   673|         0|            0|            0|  0.00%|    way that the value of the element in k-th position is in the
   674|         0|            0|            0|  0.00%|    position it would be in a sorted array. All elements smaller than
   675|         0|            0|            0|  0.00%|    the k-th element are moved before this element and all equal or
   676|         0|            0|            0|  0.00%|    greater are moved behind it. The ordering of the elements in the two
   677|         0|            0|            0|  0.00%|    partitions is undefined.
   678|         0|            0|            0|  0.00%|
   679|         0|            0|            0|  0.00%|    .. versionadded:: 1.8.0
   680|         0|            0|            0|  0.00%|
   681|         0|            0|            0|  0.00%|    Parameters
   682|         0|            0|            0|  0.00%|    ----------
   683|         0|            0|            0|  0.00%|    a : array_like
   684|         0|            0|            0|  0.00%|        Array to be sorted.
   685|         0|            0|            0|  0.00%|    kth : int or sequence of ints
   686|         0|            0|            0|  0.00%|        Element index to partition by. The k-th value of the element
   687|         0|            0|            0|  0.00%|        will be in its final sorted position and all smaller elements
   688|         0|            0|            0|  0.00%|        will be moved before it and all equal or greater elements behind
   689|         0|            0|            0|  0.00%|        it. The order of all elements in the partitions is undefined. If
   690|         0|            0|            0|  0.00%|        provided with a sequence of k-th it will partition all elements
   691|         0|            0|            0|  0.00%|        indexed by k-th  of them into their sorted position at once.
   692|         0|            0|            0|  0.00%|
   693|         0|            0|            0|  0.00%|        .. deprecated:: 1.22.0
   694|         0|            0|            0|  0.00%|            Passing booleans as index is deprecated.
   695|         0|            0|            0|  0.00%|    axis : int or None, optional
   696|         0|            0|            0|  0.00%|        Axis along which to sort. If None, the array is flattened before
   697|         0|            0|            0|  0.00%|        sorting. The default is -1, which sorts along the last axis.
   698|         0|            0|            0|  0.00%|    kind : {'introselect'}, optional
   699|         0|            0|            0|  0.00%|        Selection algorithm. Default is 'introselect'.
   700|         0|            0|            0|  0.00%|    order : str or list of str, optional
   701|         0|            0|            0|  0.00%|        When `a` is an array with fields defined, this argument
   702|         0|            0|            0|  0.00%|        specifies which fields to compare first, second, etc.  A single
   703|         0|            0|            0|  0.00%|        field can be specified as a string.  Not all fields need be
   704|         0|            0|            0|  0.00%|        specified, but unspecified fields will still be used, in the
   705|         0|            0|            0|  0.00%|        order in which they come up in the dtype, to break ties.
   706|         0|            0|            0|  0.00%|
   707|         0|            0|            0|  0.00%|    Returns
   708|         0|            0|            0|  0.00%|    -------
   709|         0|            0|            0|  0.00%|    partitioned_array : ndarray
   710|         0|            0|            0|  0.00%|        Array of the same type and shape as `a`.
   711|         0|            0|            0|  0.00%|
   712|         0|            0|            0|  0.00%|    See Also
   713|         0|            0|            0|  0.00%|    --------
   714|         0|            0|            0|  0.00%|    ndarray.partition : Method to sort an array in-place.
   715|         0|            0|            0|  0.00%|    argpartition : Indirect partition.
   716|         0|            0|            0|  0.00%|    sort : Full sorting
   717|         0|            0|            0|  0.00%|
   718|         0|            0|            0|  0.00%|    Notes
   719|         0|            0|            0|  0.00%|    -----
   720|         0|            0|            0|  0.00%|    The various selection algorithms are characterized by their average
   721|         0|            0|            0|  0.00%|    speed, worst case performance, work space size, and whether they are
   722|         0|            0|            0|  0.00%|    stable. A stable sort keeps items with the same key in the same
   723|         0|            0|            0|  0.00%|    relative order. The available algorithms have the following
   724|         0|            0|            0|  0.00%|    properties:
   725|         0|            0|            0|  0.00%|
   726|         0|            0|            0|  0.00%|    ================= ======= ============= ============ =======
   727|         0|            0|            0|  0.00%|       kind            speed   worst case    work space  stable
   728|         0|            0|            0|  0.00%|    ================= ======= ============= ============ =======
   729|         0|            0|            0|  0.00%|    'introselect'        1        O(n)           0         no
   730|         0|            0|            0|  0.00%|    ================= ======= ============= ============ =======
   731|         0|            0|            0|  0.00%|
   732|         0|            0|            0|  0.00%|    All the partition algorithms make temporary copies of the data when
   733|         0|            0|            0|  0.00%|    partitioning along any but the last axis.  Consequently,
   734|         0|            0|            0|  0.00%|    partitioning along the last axis is faster and uses less space than
   735|         0|            0|            0|  0.00%|    partitioning along any other axis.
   736|         0|            0|            0|  0.00%|
   737|         0|            0|            0|  0.00%|    The sort order for complex numbers is lexicographic. If both the
   738|         0|            0|            0|  0.00%|    real and imaginary parts are non-nan then the order is determined by
   739|         0|            0|            0|  0.00%|    the real parts except when they are equal, in which case the order
   740|         0|            0|            0|  0.00%|    is determined by the imaginary parts.
   741|         0|            0|            0|  0.00%|
   742|         0|            0|            0|  0.00%|    Examples
   743|         0|            0|            0|  0.00%|    --------
   744|         0|            0|            0|  0.00%|    >>> a = np.array([3, 4, 2, 1])
   745|         0|            0|            0|  0.00%|    >>> np.partition(a, 3)
   746|         0|            0|            0|  0.00%|    array([2, 1, 3, 4])
   747|         0|            0|            0|  0.00%|
   748|         0|            0|            0|  0.00%|    >>> np.partition(a, (1, 3))
   749|         0|            0|            0|  0.00%|    array([1, 2, 3, 4])
   750|         0|            0|            0|  0.00%|
   751|         0|            0|            0|  0.00%|    """
   752|         0|            0|            0|  0.00%|    if axis is None:
   753|         0|            0|            0|  0.00%|        # flatten returns (1, N) for np.matrix, so always use the last axis
   754|         0|            0|            0|  0.00%|        a = asanyarray(a).flatten()
   755|         0|            0|            0|  0.00%|        axis = -1
   756|         0|            0|            0|  0.00%|    else:
   757|         0|            0|            0|  0.00%|        a = asanyarray(a).copy(order="K")
   758|         0|            0|            0|  0.00%|    a.partition(kth, axis=axis, kind=kind, order=order)
   759|         0|            0|            0|  0.00%|    return a
   760|         0|            0|            0|  0.00%|
   761|         0|            0|            0|  0.00%|
   762|         0|            0|            0|  0.00%|def _argpartition_dispatcher(a, kth, axis=None, kind=None, order=None):
   763|         0|            0|            0|  0.00%|    return (a,)
   764|         0|            0|            0|  0.00%|
   765|         0|            0|            0|  0.00%|
   766|         0|            0|            0|  0.00%|@array_function_dispatch(_argpartition_dispatcher)
   767|         0|            0|            0|  0.00%|def argpartition(a, kth, axis=-1, kind='introselect', order=None):
   768|         0|            0|            0|  0.00%|    """
   769|         0|            0|            0|  0.00%|    Perform an indirect partition along the given axis using the
   770|         0|            0|            0|  0.00%|    algorithm specified by the `kind` keyword. It returns an array of
   771|         0|            0|            0|  0.00%|    indices of the same shape as `a` that index data along the given
   772|         0|            0|            0|  0.00%|    axis in partitioned order.
   773|         0|            0|            0|  0.00%|
   774|         0|            0|            0|  0.00%|    .. versionadded:: 1.8.0
   775|         0|            0|            0|  0.00%|
   776|         0|            0|            0|  0.00%|    Parameters
   777|         0|            0|            0|  0.00%|    ----------
   778|         0|            0|            0|  0.00%|    a : array_like
   779|         0|            0|            0|  0.00%|        Array to sort.
   780|         0|            0|            0|  0.00%|    kth : int or sequence of ints
   781|         0|            0|            0|  0.00%|        Element index to partition by. The k-th element will be in its
   782|         0|            0|            0|  0.00%|        final sorted position and all smaller elements will be moved
   783|         0|            0|            0|  0.00%|        before it and all larger elements behind it. The order all
   784|         0|            0|            0|  0.00%|        elements in the partitions is undefined. If provided with a
   785|         0|            0|            0|  0.00%|        sequence of k-th it will partition all of them into their sorted
   786|         0|            0|            0|  0.00%|        position at once.
   787|         0|            0|            0|  0.00%|
   788|         0|            0|            0|  0.00%|        .. deprecated:: 1.22.0
   789|         0|            0|            0|  0.00%|            Passing booleans as index is deprecated.
   790|         0|            0|            0|  0.00%|    axis : int or None, optional
   791|         0|            0|            0|  0.00%|        Axis along which to sort. The default is -1 (the last axis). If
   792|         0|            0|            0|  0.00%|        None, the flattened array is used.
   793|         0|            0|            0|  0.00%|    kind : {'introselect'}, optional
   794|         0|            0|            0|  0.00%|        Selection algorithm. Default is 'introselect'
   795|         0|            0|            0|  0.00%|    order : str or list of str, optional
   796|         0|            0|            0|  0.00%|        When `a` is an array with fields defined, this argument
   797|         0|            0|            0|  0.00%|        specifies which fields to compare first, second, etc. A single
   798|         0|            0|            0|  0.00%|        field can be specified as a string, and not all fields need be
   799|         0|            0|            0|  0.00%|        specified, but unspecified fields will still be used, in the
   800|         0|            0|            0|  0.00%|        order in which they come up in the dtype, to break ties.
   801|         0|            0|            0|  0.00%|
   802|         0|            0|            0|  0.00%|    Returns
   803|         0|            0|            0|  0.00%|    -------
   804|         0|            0|            0|  0.00%|    index_array : ndarray, int
   805|         0|            0|            0|  0.00%|        Array of indices that partition `a` along the specified axis.
   806|         0|            0|            0|  0.00%|        If `a` is one-dimensional, ``a[index_array]`` yields a partitioned `a`.
   807|         0|            0|            0|  0.00%|        More generally, ``np.take_along_axis(a, index_array, axis=a)`` always
   808|         0|            0|            0|  0.00%|        yields the partitioned `a`, irrespective of dimensionality.
   809|         0|            0|            0|  0.00%|
   810|         0|            0|            0|  0.00%|    See Also
   811|         0|            0|            0|  0.00%|    --------
   812|         0|            0|            0|  0.00%|    partition : Describes partition algorithms used.
   813|         0|            0|            0|  0.00%|    ndarray.partition : Inplace partition.
   814|         0|            0|            0|  0.00%|    argsort : Full indirect sort.
   815|         0|            0|            0|  0.00%|    take_along_axis : Apply ``index_array`` from argpartition
   816|         0|            0|            0|  0.00%|                      to an array as if by calling partition.
   817|         0|            0|            0|  0.00%|
   818|         0|            0|            0|  0.00%|    Notes
   819|         0|            0|            0|  0.00%|    -----
   820|         0|            0|            0|  0.00%|    See `partition` for notes on the different selection algorithms.
   821|         0|            0|            0|  0.00%|
   822|         0|            0|            0|  0.00%|    Examples
   823|         0|            0|            0|  0.00%|    --------
   824|         0|            0|            0|  0.00%|    One dimensional array:
   825|         0|            0|            0|  0.00%|
   826|         0|            0|            0|  0.00%|    >>> x = np.array([3, 4, 2, 1])
   827|         0|            0|            0|  0.00%|    >>> x[np.argpartition(x, 3)]
   828|         0|            0|            0|  0.00%|    array([2, 1, 3, 4])
   829|         0|            0|            0|  0.00%|    >>> x[np.argpartition(x, (1, 3))]
   830|         0|            0|            0|  0.00%|    array([1, 2, 3, 4])
   831|         0|            0|            0|  0.00%|
   832|         0|            0|            0|  0.00%|    >>> x = [3, 4, 2, 1]
   833|         0|            0|            0|  0.00%|    >>> np.array(x)[np.argpartition(x, 3)]
   834|         0|            0|            0|  0.00%|    array([2, 1, 3, 4])
   835|         0|            0|            0|  0.00%|
   836|         0|            0|            0|  0.00%|    Multi-dimensional array:
   837|         0|            0|            0|  0.00%|
   838|         0|            0|            0|  0.00%|    >>> x = np.array([[3, 4, 2], [1, 3, 1]])
   839|         0|            0|            0|  0.00%|    >>> index_array = np.argpartition(x, kth=1, axis=-1)
   840|         0|            0|            0|  0.00%|    >>> np.take_along_axis(x, index_array, axis=-1)  # same as np.partition(x, kth=1)
   841|         0|            0|            0|  0.00%|    array([[2, 3, 4],
   842|         0|            0|            0|  0.00%|           [1, 1, 3]])
   843|         0|            0|            0|  0.00%|
   844|         0|            0|            0|  0.00%|    """
   845|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)
   846|         0|            0|            0|  0.00%|
   847|         0|            0|            0|  0.00%|
   848|         0|            0|            0|  0.00%|def _sort_dispatcher(a, axis=None, kind=None, order=None):
   849|         0|            0|            0|  0.00%|    return (a,)
   850|         0|            0|            0|  0.00%|
   851|         0|            0|            0|  0.00%|
   852|         0|            0|            0|  0.00%|@array_function_dispatch(_sort_dispatcher)
   853|         0|            0|            0|  0.00%|def sort(a, axis=-1, kind=None, order=None):
   854|         0|            0|            0|  0.00%|    """
   855|         0|            0|            0|  0.00%|    Return a sorted copy of an array.
   856|         0|            0|            0|  0.00%|
   857|         0|            0|            0|  0.00%|    Parameters
   858|         0|            0|            0|  0.00%|    ----------
   859|         0|            0|            0|  0.00%|    a : array_like
   860|         0|            0|            0|  0.00%|        Array to be sorted.
   861|         0|            0|            0|  0.00%|    axis : int or None, optional
   862|         0|            0|            0|  0.00%|        Axis along which to sort. If None, the array is flattened before
   863|         0|            0|            0|  0.00%|        sorting. The default is -1, which sorts along the last axis.
   864|         0|            0|            0|  0.00%|    kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional
   865|         0|            0|            0|  0.00%|        Sorting algorithm. The default is 'quicksort'. Note that both 'stable'
   866|         0|            0|            0|  0.00%|        and 'mergesort' use timsort or radix sort under the covers and, in general,
   867|         0|            0|            0|  0.00%|        the actual implementation will vary with data type. The 'mergesort' option
   868|         0|            0|            0|  0.00%|        is retained for backwards compatibility.
   869|         0|            0|            0|  0.00%|
   870|         0|            0|            0|  0.00%|        .. versionchanged:: 1.15.0.
   871|         0|            0|            0|  0.00%|           The 'stable' option was added.
   872|         0|            0|            0|  0.00%|
   873|         0|            0|            0|  0.00%|    order : str or list of str, optional
   874|         0|            0|            0|  0.00%|        When `a` is an array with fields defined, this argument specifies
   875|         0|            0|            0|  0.00%|        which fields to compare first, second, etc.  A single field can
   876|         0|            0|            0|  0.00%|        be specified as a string, and not all fields need be specified,
   877|         0|            0|            0|  0.00%|        but unspecified fields will still be used, in the order in which
   878|         0|            0|            0|  0.00%|        they come up in the dtype, to break ties.
   879|         0|            0|            0|  0.00%|
   880|         0|            0|            0|  0.00%|    Returns
   881|         0|            0|            0|  0.00%|    -------
   882|         0|            0|            0|  0.00%|    sorted_array : ndarray
   883|         0|            0|            0|  0.00%|        Array of the same type and shape as `a`.
   884|         0|            0|            0|  0.00%|
   885|         0|            0|            0|  0.00%|    See Also
   886|         0|            0|            0|  0.00%|    --------
   887|         0|            0|            0|  0.00%|    ndarray.sort : Method to sort an array in-place.
   888|         0|            0|            0|  0.00%|    argsort : Indirect sort.
   889|         0|            0|            0|  0.00%|    lexsort : Indirect stable sort on multiple keys.
   890|         0|            0|            0|  0.00%|    searchsorted : Find elements in a sorted array.
   891|         0|            0|            0|  0.00%|    partition : Partial sort.
   892|         0|            0|            0|  0.00%|
   893|         0|            0|            0|  0.00%|    Notes
   894|         0|            0|            0|  0.00%|    -----
   895|         0|            0|            0|  0.00%|    The various sorting algorithms are characterized by their average speed,
   896|         0|            0|            0|  0.00%|    worst case performance, work space size, and whether they are stable. A
   897|         0|            0|            0|  0.00%|    stable sort keeps items with the same key in the same relative
   898|         0|            0|            0|  0.00%|    order. The four algorithms implemented in NumPy have the following
   899|         0|            0|            0|  0.00%|    properties:
   900|         0|            0|            0|  0.00%|
   901|         0|            0|            0|  0.00%|    =========== ======= ============= ============ ========
   902|         0|            0|            0|  0.00%|       kind      speed   worst case    work space   stable
   903|         0|            0|            0|  0.00%|    =========== ======= ============= ============ ========
   904|         0|            0|            0|  0.00%|    'quicksort'    1     O(n^2)            0          no
   905|         0|            0|            0|  0.00%|    'heapsort'     3     O(n*log(n))       0          no
   906|         0|            0|            0|  0.00%|    'mergesort'    2     O(n*log(n))      ~n/2        yes
   907|         0|            0|            0|  0.00%|    'timsort'      2     O(n*log(n))      ~n/2        yes
   908|         0|            0|            0|  0.00%|    =========== ======= ============= ============ ========
   909|         0|            0|            0|  0.00%|
   910|         0|            0|            0|  0.00%|    .. note:: The datatype determines which of 'mergesort' or 'timsort'
   911|         0|            0|            0|  0.00%|       is actually used, even if 'mergesort' is specified. User selection
   912|         0|            0|            0|  0.00%|       at a finer scale is not currently available.
   913|         0|            0|            0|  0.00%|
   914|         0|            0|            0|  0.00%|    All the sort algorithms make temporary copies of the data when
   915|         0|            0|            0|  0.00%|    sorting along any but the last axis.  Consequently, sorting along
   916|         0|            0|            0|  0.00%|    the last axis is faster and uses less space than sorting along
   917|         0|            0|            0|  0.00%|    any other axis.
   918|         0|            0|            0|  0.00%|
   919|         0|            0|            0|  0.00%|    The sort order for complex numbers is lexicographic. If both the real
   920|         0|            0|            0|  0.00%|    and imaginary parts are non-nan then the order is determined by the
   921|         0|            0|            0|  0.00%|    real parts except when they are equal, in which case the order is
   922|         0|            0|            0|  0.00%|    determined by the imaginary parts.
   923|         0|            0|            0|  0.00%|
   924|         0|            0|            0|  0.00%|    Previous to numpy 1.4.0 sorting real and complex arrays containing nan
   925|         0|            0|            0|  0.00%|    values led to undefined behaviour. In numpy versions >= 1.4.0 nan
   926|         0|            0|            0|  0.00%|    values are sorted to the end. The extended sort order is:
   927|         0|            0|            0|  0.00%|
   928|         0|            0|            0|  0.00%|      * Real: [R, nan]
   929|         0|            0|            0|  0.00%|      * Complex: [R + Rj, R + nanj, nan + Rj, nan + nanj]
   930|         0|            0|            0|  0.00%|
   931|         0|            0|            0|  0.00%|    where R is a non-nan real value. Complex values with the same nan
   932|         0|            0|            0|  0.00%|    placements are sorted according to the non-nan part if it exists.
   933|         0|            0|            0|  0.00%|    Non-nan values are sorted as before.
   934|         0|            0|            0|  0.00%|
   935|         0|            0|            0|  0.00%|    .. versionadded:: 1.12.0
   936|         0|            0|            0|  0.00%|
   937|         0|            0|            0|  0.00%|    quicksort has been changed to `introsort <https://en.wikipedia.org/wiki/Introsort>`_.
   938|         0|            0|            0|  0.00%|    When sorting does not make enough progress it switches to
   939|         0|            0|            0|  0.00%|    `heapsort <https://en.wikipedia.org/wiki/Heapsort>`_.
   940|         0|            0|            0|  0.00%|    This implementation makes quicksort O(n*log(n)) in the worst case.
   941|         0|            0|            0|  0.00%|
   942|         0|            0|            0|  0.00%|    'stable' automatically chooses the best stable sorting algorithm
   943|         0|            0|            0|  0.00%|    for the data type being sorted.
   944|         0|            0|            0|  0.00%|    It, along with 'mergesort' is currently mapped to
   945|         0|            0|            0|  0.00%|    `timsort <https://en.wikipedia.org/wiki/Timsort>`_
   946|         0|            0|            0|  0.00%|    or `radix sort <https://en.wikipedia.org/wiki/Radix_sort>`_
   947|         0|            0|            0|  0.00%|    depending on the data type.
   948|         0|            0|            0|  0.00%|    API forward compatibility currently limits the
   949|         0|            0|            0|  0.00%|    ability to select the implementation and it is hardwired for the different
   950|         0|            0|            0|  0.00%|    data types.
   951|         0|            0|            0|  0.00%|
   952|         0|            0|            0|  0.00%|    .. versionadded:: 1.17.0
   953|         0|            0|            0|  0.00%|
   954|         0|            0|            0|  0.00%|    Timsort is added for better performance on already or nearly
   955|         0|            0|            0|  0.00%|    sorted data. On random data timsort is almost identical to
   956|         0|            0|            0|  0.00%|    mergesort. It is now used for stable sort while quicksort is still the
   957|         0|            0|            0|  0.00%|    default sort if none is chosen. For timsort details, refer to
   958|         0|            0|            0|  0.00%|    `CPython listsort.txt <https://github.com/python/cpython/blob/3.7/Objects/listsort.txt>`_.
   959|         0|            0|            0|  0.00%|    'mergesort' and 'stable' are mapped to radix sort for integer data types. Radix sort is an
   960|         0|            0|            0|  0.00%|    O(n) sort instead of O(n log n).
   961|         0|            0|            0|  0.00%|
   962|         0|            0|            0|  0.00%|    .. versionchanged:: 1.18.0
   963|         0|            0|            0|  0.00%|
   964|         0|            0|            0|  0.00%|    NaT now sorts to the end of arrays for consistency with NaN.
   965|         0|            0|            0|  0.00%|
   966|         0|            0|            0|  0.00%|    Examples
   967|         0|            0|            0|  0.00%|    --------
   968|         0|            0|            0|  0.00%|    >>> a = np.array([[1,4],[3,1]])
   969|         0|            0|            0|  0.00%|    >>> np.sort(a)                # sort along the last axis
   970|         0|            0|            0|  0.00%|    array([[1, 4],
   971|         0|            0|            0|  0.00%|           [1, 3]])
   972|         0|            0|            0|  0.00%|    >>> np.sort(a, axis=None)     # sort the flattened array
   973|         0|            0|            0|  0.00%|    array([1, 1, 3, 4])
   974|         0|            0|            0|  0.00%|    >>> np.sort(a, axis=0)        # sort along the first axis
   975|         0|            0|            0|  0.00%|    array([[1, 1],
   976|         0|            0|            0|  0.00%|           [3, 4]])
   977|         0|            0|            0|  0.00%|
   978|         0|            0|            0|  0.00%|    Use the `order` keyword to specify a field to use when sorting a
   979|         0|            0|            0|  0.00%|    structured array:
   980|         0|            0|            0|  0.00%|
   981|         0|            0|            0|  0.00%|    >>> dtype = [('name', 'S10'), ('height', float), ('age', int)]
   982|         0|            0|            0|  0.00%|    >>> values = [('Arthur', 1.8, 41), ('Lancelot', 1.9, 38),
   983|         0|            0|            0|  0.00%|    ...           ('Galahad', 1.7, 38)]
   984|         0|            0|            0|  0.00%|    >>> a = np.array(values, dtype=dtype)       # create a structured array
   985|         0|            0|            0|  0.00%|    >>> np.sort(a, order='height')                        # doctest: +SKIP
   986|         0|            0|            0|  0.00%|    array([('Galahad', 1.7, 38), ('Arthur', 1.8, 41),
   987|         0|            0|            0|  0.00%|           ('Lancelot', 1.8999999999999999, 38)],
   988|         0|            0|            0|  0.00%|          dtype=[('name', '|S10'), ('height', '<f8'), ('age', '<i4')])
   989|         0|            0|            0|  0.00%|
   990|         0|            0|            0|  0.00%|    Sort by age, then height if ages are equal:
   991|         0|            0|            0|  0.00%|
   992|         0|            0|            0|  0.00%|    >>> np.sort(a, order=['age', 'height'])               # doctest: +SKIP
   993|         0|            0|            0|  0.00%|    array([('Galahad', 1.7, 38), ('Lancelot', 1.8999999999999999, 38),
   994|         0|            0|            0|  0.00%|           ('Arthur', 1.8, 41)],
   995|         0|            0|            0|  0.00%|          dtype=[('name', '|S10'), ('height', '<f8'), ('age', '<i4')])
   996|         0|            0|            0|  0.00%|
   997|         0|            0|            0|  0.00%|    """
   998|         0|            0|            0|  0.00%|    if axis is None:
   999|         0|            0|            0|  0.00%|        # flatten returns (1, N) for np.matrix, so always use the last axis
  1000|         0|            0|            0|  0.00%|        a = asanyarray(a).flatten()
  1001|         0|            0|            0|  0.00%|        axis = -1
  1002|         0|            0|            0|  0.00%|    else:
  1003|         0|            0|            0|  0.00%|        a = asanyarray(a).copy(order="K")
  1004|         0|            0|            0|  0.00%|    a.sort(axis=axis, kind=kind, order=order)
  1005|         0|            0|            0|  0.00%|    return a
  1006|         0|            0|            0|  0.00%|
  1007|         0|            0|            0|  0.00%|
  1008|         0|            0|            0|  0.00%|def _argsort_dispatcher(a, axis=None, kind=None, order=None):
  1009|         0|            0|            0|  0.00%|    return (a,)
  1010|         0|            0|            0|  0.00%|
  1011|         0|            0|            0|  0.00%|
  1012|         0|            0|            0|  0.00%|@array_function_dispatch(_argsort_dispatcher)
  1013|         0|            0|            0|  0.00%|def argsort(a, axis=-1, kind=None, order=None):
  1014|         0|            0|            0|  0.00%|    """
  1015|         0|            0|            0|  0.00%|    Returns the indices that would sort an array.
  1016|         0|            0|            0|  0.00%|
  1017|         0|            0|            0|  0.00%|    Perform an indirect sort along the given axis using the algorithm specified
  1018|         0|            0|            0|  0.00%|    by the `kind` keyword. It returns an array of indices of the same shape as
  1019|         0|            0|            0|  0.00%|    `a` that index data along the given axis in sorted order.
  1020|         0|            0|            0|  0.00%|
  1021|         0|            0|            0|  0.00%|    Parameters
  1022|         0|            0|            0|  0.00%|    ----------
  1023|         0|            0|            0|  0.00%|    a : array_like
  1024|         0|            0|            0|  0.00%|        Array to sort.
  1025|         0|            0|            0|  0.00%|    axis : int or None, optional
  1026|         0|            0|            0|  0.00%|        Axis along which to sort.  The default is -1 (the last axis). If None,
  1027|         0|            0|            0|  0.00%|        the flattened array is used.
  1028|         0|            0|            0|  0.00%|    kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional
  1029|         0|            0|            0|  0.00%|        Sorting algorithm. The default is 'quicksort'. Note that both 'stable'
  1030|         0|            0|            0|  0.00%|        and 'mergesort' use timsort under the covers and, in general, the
  1031|         0|            0|            0|  0.00%|        actual implementation will vary with data type. The 'mergesort' option
  1032|         0|            0|            0|  0.00%|        is retained for backwards compatibility.
  1033|         0|            0|            0|  0.00%|
  1034|         0|            0|            0|  0.00%|        .. versionchanged:: 1.15.0.
  1035|         0|            0|            0|  0.00%|           The 'stable' option was added.
  1036|         0|            0|            0|  0.00%|    order : str or list of str, optional
  1037|         0|            0|            0|  0.00%|        When `a` is an array with fields defined, this argument specifies
  1038|         0|            0|            0|  0.00%|        which fields to compare first, second, etc.  A single field can
  1039|         0|            0|            0|  0.00%|        be specified as a string, and not all fields need be specified,
  1040|         0|            0|            0|  0.00%|        but unspecified fields will still be used, in the order in which
  1041|         0|            0|            0|  0.00%|        they come up in the dtype, to break ties.
  1042|         0|            0|            0|  0.00%|
  1043|         0|            0|            0|  0.00%|    Returns
  1044|         0|            0|            0|  0.00%|    -------
  1045|         0|            0|            0|  0.00%|    index_array : ndarray, int
  1046|         0|            0|            0|  0.00%|        Array of indices that sort `a` along the specified `axis`.
  1047|         0|            0|            0|  0.00%|        If `a` is one-dimensional, ``a[index_array]`` yields a sorted `a`.
  1048|         0|            0|            0|  0.00%|        More generally, ``np.take_along_axis(a, index_array, axis=axis)``
  1049|         0|            0|            0|  0.00%|        always yields the sorted `a`, irrespective of dimensionality.
  1050|         0|            0|            0|  0.00%|
  1051|         0|            0|            0|  0.00%|    See Also
  1052|         0|            0|            0|  0.00%|    --------
  1053|         0|            0|            0|  0.00%|    sort : Describes sorting algorithms used.
  1054|         0|            0|            0|  0.00%|    lexsort : Indirect stable sort with multiple keys.
  1055|         0|            0|            0|  0.00%|    ndarray.sort : Inplace sort.
  1056|         0|            0|            0|  0.00%|    argpartition : Indirect partial sort.
  1057|         0|            0|            0|  0.00%|    take_along_axis : Apply ``index_array`` from argsort
  1058|         0|            0|            0|  0.00%|                      to an array as if by calling sort.
  1059|         0|            0|            0|  0.00%|
  1060|         0|            0|            0|  0.00%|    Notes
  1061|         0|            0|            0|  0.00%|    -----
  1062|         0|            0|            0|  0.00%|    See `sort` for notes on the different sorting algorithms.
  1063|         0|            0|            0|  0.00%|
  1064|         0|            0|            0|  0.00%|    As of NumPy 1.4.0 `argsort` works with real/complex arrays containing
  1065|         0|            0|            0|  0.00%|    nan values. The enhanced sort order is documented in `sort`.
  1066|         0|            0|            0|  0.00%|
  1067|         0|            0|            0|  0.00%|    Examples
  1068|         0|            0|            0|  0.00%|    --------
  1069|         0|            0|            0|  0.00%|    One dimensional array:
  1070|         0|            0|            0|  0.00%|
  1071|         0|            0|            0|  0.00%|    >>> x = np.array([3, 1, 2])
  1072|         0|            0|            0|  0.00%|    >>> np.argsort(x)
  1073|         0|            0|            0|  0.00%|    array([1, 2, 0])
  1074|         0|            0|            0|  0.00%|
  1075|         0|            0|            0|  0.00%|    Two-dimensional array:
  1076|         0|            0|            0|  0.00%|
  1077|         0|            0|            0|  0.00%|    >>> x = np.array([[0, 3], [2, 2]])
  1078|         0|            0|            0|  0.00%|    >>> x
  1079|         0|            0|            0|  0.00%|    array([[0, 3],
  1080|         0|            0|            0|  0.00%|           [2, 2]])
  1081|         0|            0|            0|  0.00%|
  1082|         0|            0|            0|  0.00%|    >>> ind = np.argsort(x, axis=0)  # sorts along first axis (down)
  1083|         0|            0|            0|  0.00%|    >>> ind
  1084|         0|            0|            0|  0.00%|    array([[0, 1],
  1085|         0|            0|            0|  0.00%|           [1, 0]])
  1086|         0|            0|            0|  0.00%|    >>> np.take_along_axis(x, ind, axis=0)  # same as np.sort(x, axis=0)
  1087|         0|            0|            0|  0.00%|    array([[0, 2],
  1088|         0|            0|            0|  0.00%|           [2, 3]])
  1089|         0|            0|            0|  0.00%|
  1090|         0|            0|            0|  0.00%|    >>> ind = np.argsort(x, axis=1)  # sorts along last axis (across)
  1091|         0|            0|            0|  0.00%|    >>> ind
  1092|         0|            0|            0|  0.00%|    array([[0, 1],
  1093|         0|            0|            0|  0.00%|           [0, 1]])
  1094|         0|            0|            0|  0.00%|    >>> np.take_along_axis(x, ind, axis=1)  # same as np.sort(x, axis=1)
  1095|         0|            0|            0|  0.00%|    array([[0, 3],
  1096|         0|            0|            0|  0.00%|           [2, 2]])
  1097|         0|            0|            0|  0.00%|
  1098|         0|            0|            0|  0.00%|    Indices of the sorted elements of a N-dimensional array:
  1099|         0|            0|            0|  0.00%|
  1100|         0|            0|            0|  0.00%|    >>> ind = np.unravel_index(np.argsort(x, axis=None), x.shape)
  1101|         0|            0|            0|  0.00%|    >>> ind
  1102|         0|            0|            0|  0.00%|    (array([0, 1, 1, 0]), array([0, 0, 1, 1]))
  1103|         0|            0|            0|  0.00%|    >>> x[ind]  # same as np.sort(x, axis=None)
  1104|         0|            0|            0|  0.00%|    array([0, 2, 2, 3])
  1105|         0|            0|            0|  0.00%|
  1106|         0|            0|            0|  0.00%|    Sorting with keys:
  1107|         0|            0|            0|  0.00%|
  1108|         0|            0|            0|  0.00%|    >>> x = np.array([(1, 0), (0, 1)], dtype=[('x', '<i4'), ('y', '<i4')])
  1109|         0|            0|            0|  0.00%|    >>> x
  1110|         0|            0|            0|  0.00%|    array([(1, 0), (0, 1)],
  1111|         0|            0|            0|  0.00%|          dtype=[('x', '<i4'), ('y', '<i4')])
  1112|         0|            0|            0|  0.00%|
  1113|         0|            0|            0|  0.00%|    >>> np.argsort(x, order=('x','y'))
  1114|         0|            0|            0|  0.00%|    array([1, 0])
  1115|         0|            0|            0|  0.00%|
  1116|         0|            0|            0|  0.00%|    >>> np.argsort(x, order=('y','x'))
  1117|         0|            0|            0|  0.00%|    array([0, 1])
  1118|         0|            0|            0|  0.00%|
  1119|         0|            0|            0|  0.00%|    """
  1120|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'argsort', axis=axis, kind=kind, order=order)
  1121|         0|            0|            0|  0.00%|
  1122|         0|            0|            0|  0.00%|
  1123|         0|            0|            0|  0.00%|def _argmax_dispatcher(a, axis=None, out=None, *, keepdims=np._NoValue):
  1124|         0|            0|            0|  0.00%|    return (a, out)
  1125|         0|            0|            0|  0.00%|
  1126|         0|            0|            0|  0.00%|
  1127|         0|            0|            0|  0.00%|@array_function_dispatch(_argmax_dispatcher)
  1128|         0|            0|            0|  0.00%|def argmax(a, axis=None, out=None, *, keepdims=np._NoValue):
  1129|         0|            0|            0|  0.00%|    """
  1130|         0|            0|            0|  0.00%|    Returns the indices of the maximum values along an axis.
  1131|         0|            0|            0|  0.00%|
  1132|         0|            0|            0|  0.00%|    Parameters
  1133|         0|            0|            0|  0.00%|    ----------
  1134|         0|            0|            0|  0.00%|    a : array_like
  1135|         0|            0|            0|  0.00%|        Input array.
  1136|         0|            0|            0|  0.00%|    axis : int, optional
  1137|         0|            0|            0|  0.00%|        By default, the index is into the flattened array, otherwise
  1138|         0|            0|            0|  0.00%|        along the specified axis.
  1139|         0|            0|            0|  0.00%|    out : array, optional
  1140|         0|            0|            0|  0.00%|        If provided, the result will be inserted into this array. It should
  1141|         0|            0|            0|  0.00%|        be of the appropriate shape and dtype.
  1142|         0|            0|            0|  0.00%|    keepdims : bool, optional
  1143|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  1144|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  1145|         0|            0|            0|  0.00%|        the result will broadcast correctly against the array.
  1146|         0|            0|            0|  0.00%|
  1147|         0|            0|            0|  0.00%|        .. versionadded:: 1.22.0
  1148|         0|            0|            0|  0.00%|
  1149|         0|            0|            0|  0.00%|    Returns
  1150|         0|            0|            0|  0.00%|    -------
  1151|         0|            0|            0|  0.00%|    index_array : ndarray of ints
  1152|         0|            0|            0|  0.00%|        Array of indices into the array. It has the same shape as `a.shape`
  1153|         0|            0|            0|  0.00%|        with the dimension along `axis` removed. If `keepdims` is set to True,
  1154|         0|            0|            0|  0.00%|        then the size of `axis` will be 1 with the resulting array having same
  1155|         0|            0|            0|  0.00%|        shape as `a.shape`.
  1156|         0|            0|            0|  0.00%|
  1157|         0|            0|            0|  0.00%|    See Also
  1158|         0|            0|            0|  0.00%|    --------
  1159|         0|            0|            0|  0.00%|    ndarray.argmax, argmin
  1160|         0|            0|            0|  0.00%|    amax : The maximum value along a given axis.
  1161|         0|            0|            0|  0.00%|    unravel_index : Convert a flat index into an index tuple.
  1162|         0|            0|            0|  0.00%|    take_along_axis : Apply ``np.expand_dims(index_array, axis)``
  1163|         0|            0|            0|  0.00%|                      from argmax to an array as if by calling max.
  1164|         0|            0|            0|  0.00%|
  1165|         0|            0|            0|  0.00%|    Notes
  1166|         0|            0|            0|  0.00%|    -----
  1167|         0|            0|            0|  0.00%|    In case of multiple occurrences of the maximum values, the indices
  1168|         0|            0|            0|  0.00%|    corresponding to the first occurrence are returned.
  1169|         0|            0|            0|  0.00%|
  1170|         0|            0|            0|  0.00%|    Examples
  1171|         0|            0|            0|  0.00%|    --------
  1172|         0|            0|            0|  0.00%|    >>> a = np.arange(6).reshape(2,3) + 10
  1173|         0|            0|            0|  0.00%|    >>> a
  1174|         0|            0|            0|  0.00%|    array([[10, 11, 12],
  1175|         0|            0|            0|  0.00%|           [13, 14, 15]])
  1176|         0|            0|            0|  0.00%|    >>> np.argmax(a)
  1177|         0|            0|            0|  0.00%|    5
  1178|         0|            0|            0|  0.00%|    >>> np.argmax(a, axis=0)
  1179|         0|            0|            0|  0.00%|    array([1, 1, 1])
  1180|         0|            0|            0|  0.00%|    >>> np.argmax(a, axis=1)
  1181|         0|            0|            0|  0.00%|    array([2, 2])
  1182|         0|            0|            0|  0.00%|
  1183|         0|            0|            0|  0.00%|    Indexes of the maximal elements of a N-dimensional array:
  1184|         0|            0|            0|  0.00%|
  1185|         0|            0|            0|  0.00%|    >>> ind = np.unravel_index(np.argmax(a, axis=None), a.shape)
  1186|         0|            0|            0|  0.00%|    >>> ind
  1187|         0|            0|            0|  0.00%|    (1, 2)
  1188|         0|            0|            0|  0.00%|    >>> a[ind]
  1189|         0|            0|            0|  0.00%|    15
  1190|         0|            0|            0|  0.00%|
  1191|         0|            0|            0|  0.00%|    >>> b = np.arange(6)
  1192|         0|            0|            0|  0.00%|    >>> b[1] = 5
  1193|         0|            0|            0|  0.00%|    >>> b
  1194|         0|            0|            0|  0.00%|    array([0, 5, 2, 3, 4, 5])
  1195|         0|            0|            0|  0.00%|    >>> np.argmax(b)  # Only the first occurrence is returned.
  1196|         0|            0|            0|  0.00%|    1
  1197|         0|            0|            0|  0.00%|
  1198|         0|            0|            0|  0.00%|    >>> x = np.array([[4,2,3], [1,0,3]])
  1199|         0|            0|            0|  0.00%|    >>> index_array = np.argmax(x, axis=-1)
  1200|         0|            0|            0|  0.00%|    >>> # Same as np.amax(x, axis=-1, keepdims=True)
  1201|         0|            0|            0|  0.00%|    >>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1)
  1202|         0|            0|            0|  0.00%|    array([[4],
  1203|         0|            0|            0|  0.00%|           [3]])
  1204|         0|            0|            0|  0.00%|    >>> # Same as np.amax(x, axis=-1)
  1205|         0|            0|            0|  0.00%|    >>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1).squeeze(axis=-1)
  1206|         0|            0|            0|  0.00%|    array([4, 3])
  1207|         0|            0|            0|  0.00%|
  1208|         0|            0|            0|  0.00%|    Setting `keepdims` to `True`,
  1209|         0|            0|            0|  0.00%|
  1210|         0|            0|            0|  0.00%|    >>> x = np.arange(24).reshape((2, 3, 4))
  1211|         0|            0|            0|  0.00%|    >>> res = np.argmax(x, axis=1, keepdims=True)
  1212|         0|            0|            0|  0.00%|    >>> res.shape
  1213|         0|            0|            0|  0.00%|    (2, 1, 4)
  1214|         0|            0|            0|  0.00%|    """
  1215|         0|            0|            0|  0.00%|    kwds = {'keepdims': keepdims} if keepdims is not np._NoValue else {}
  1216|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'argmax', axis=axis, out=out, **kwds)
  1217|         0|            0|            0|  0.00%|
  1218|         0|            0|            0|  0.00%|
  1219|         0|            0|            0|  0.00%|def _argmin_dispatcher(a, axis=None, out=None, *, keepdims=np._NoValue):
  1220|         0|            0|            0|  0.00%|    return (a, out)
  1221|         0|            0|            0|  0.00%|
  1222|         0|            0|            0|  0.00%|
  1223|         0|            0|            0|  0.00%|@array_function_dispatch(_argmin_dispatcher)
  1224|         0|            0|            0|  0.00%|def argmin(a, axis=None, out=None, *, keepdims=np._NoValue):
  1225|         0|            0|            0|  0.00%|    """
  1226|         0|            0|            0|  0.00%|    Returns the indices of the minimum values along an axis.
  1227|         0|            0|            0|  0.00%|
  1228|         0|            0|            0|  0.00%|    Parameters
  1229|         0|            0|            0|  0.00%|    ----------
  1230|         0|            0|            0|  0.00%|    a : array_like
  1231|         0|            0|            0|  0.00%|        Input array.
  1232|         0|            0|            0|  0.00%|    axis : int, optional
  1233|         0|            0|            0|  0.00%|        By default, the index is into the flattened array, otherwise
  1234|         0|            0|            0|  0.00%|        along the specified axis.
  1235|         0|            0|            0|  0.00%|    out : array, optional
  1236|         0|            0|            0|  0.00%|        If provided, the result will be inserted into this array. It should
  1237|         0|            0|            0|  0.00%|        be of the appropriate shape and dtype.
  1238|         0|            0|            0|  0.00%|    keepdims : bool, optional
  1239|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  1240|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  1241|         0|            0|            0|  0.00%|        the result will broadcast correctly against the array.
  1242|         0|            0|            0|  0.00%|
  1243|         0|            0|            0|  0.00%|        .. versionadded:: 1.22.0
  1244|         0|            0|            0|  0.00%|
  1245|         0|            0|            0|  0.00%|    Returns
  1246|         0|            0|            0|  0.00%|    -------
  1247|         0|            0|            0|  0.00%|    index_array : ndarray of ints
  1248|         0|            0|            0|  0.00%|        Array of indices into the array. It has the same shape as `a.shape`
  1249|         0|            0|            0|  0.00%|        with the dimension along `axis` removed. If `keepdims` is set to True,
  1250|         0|            0|            0|  0.00%|        then the size of `axis` will be 1 with the resulting array having same
  1251|         0|            0|            0|  0.00%|        shape as `a.shape`.
  1252|         0|            0|            0|  0.00%|
  1253|         0|            0|            0|  0.00%|    See Also
  1254|         0|            0|            0|  0.00%|    --------
  1255|         0|            0|            0|  0.00%|    ndarray.argmin, argmax
  1256|         0|            0|            0|  0.00%|    amin : The minimum value along a given axis.
  1257|         0|            0|            0|  0.00%|    unravel_index : Convert a flat index into an index tuple.
  1258|         0|            0|            0|  0.00%|    take_along_axis : Apply ``np.expand_dims(index_array, axis)``
  1259|         0|            0|            0|  0.00%|                      from argmin to an array as if by calling min.
  1260|         0|            0|            0|  0.00%|
  1261|         0|            0|            0|  0.00%|    Notes
  1262|         0|            0|            0|  0.00%|    -----
  1263|         0|            0|            0|  0.00%|    In case of multiple occurrences of the minimum values, the indices
  1264|         0|            0|            0|  0.00%|    corresponding to the first occurrence are returned.
  1265|         0|            0|            0|  0.00%|
  1266|         0|            0|            0|  0.00%|    Examples
  1267|         0|            0|            0|  0.00%|    --------
  1268|         0|            0|            0|  0.00%|    >>> a = np.arange(6).reshape(2,3) + 10
  1269|         0|            0|            0|  0.00%|    >>> a
  1270|         0|            0|            0|  0.00%|    array([[10, 11, 12],
  1271|         0|            0|            0|  0.00%|           [13, 14, 15]])
  1272|         0|            0|            0|  0.00%|    >>> np.argmin(a)
  1273|         0|            0|            0|  0.00%|    0
  1274|         0|            0|            0|  0.00%|    >>> np.argmin(a, axis=0)
  1275|         0|            0|            0|  0.00%|    array([0, 0, 0])
  1276|         0|            0|            0|  0.00%|    >>> np.argmin(a, axis=1)
  1277|         0|            0|            0|  0.00%|    array([0, 0])
  1278|         0|            0|            0|  0.00%|
  1279|         0|            0|            0|  0.00%|    Indices of the minimum elements of a N-dimensional array:
  1280|         0|            0|            0|  0.00%|
  1281|         0|            0|            0|  0.00%|    >>> ind = np.unravel_index(np.argmin(a, axis=None), a.shape)
  1282|         0|            0|            0|  0.00%|    >>> ind
  1283|         0|            0|            0|  0.00%|    (0, 0)
  1284|         0|            0|            0|  0.00%|    >>> a[ind]
  1285|         0|            0|            0|  0.00%|    10
  1286|         0|            0|            0|  0.00%|
  1287|         0|            0|            0|  0.00%|    >>> b = np.arange(6) + 10
  1288|         0|            0|            0|  0.00%|    >>> b[4] = 10
  1289|         0|            0|            0|  0.00%|    >>> b
  1290|         0|            0|            0|  0.00%|    array([10, 11, 12, 13, 10, 15])
  1291|         0|            0|            0|  0.00%|    >>> np.argmin(b)  # Only the first occurrence is returned.
  1292|         0|            0|            0|  0.00%|    0
  1293|         0|            0|            0|  0.00%|
  1294|         0|            0|            0|  0.00%|    >>> x = np.array([[4,2,3], [1,0,3]])
  1295|         0|            0|            0|  0.00%|    >>> index_array = np.argmin(x, axis=-1)
  1296|         0|            0|            0|  0.00%|    >>> # Same as np.amin(x, axis=-1, keepdims=True)
  1297|         0|            0|            0|  0.00%|    >>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1)
  1298|         0|            0|            0|  0.00%|    array([[2],
  1299|         0|            0|            0|  0.00%|           [0]])
  1300|         0|            0|            0|  0.00%|    >>> # Same as np.amax(x, axis=-1)
  1301|         0|            0|            0|  0.00%|    >>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1).squeeze(axis=-1)
  1302|         0|            0|            0|  0.00%|    array([2, 0])
  1303|         0|            0|            0|  0.00%|
  1304|         0|            0|            0|  0.00%|    Setting `keepdims` to `True`,
  1305|         0|            0|            0|  0.00%|
  1306|         0|            0|            0|  0.00%|    >>> x = np.arange(24).reshape((2, 3, 4))
  1307|         0|            0|            0|  0.00%|    >>> res = np.argmin(x, axis=1, keepdims=True)
  1308|         0|            0|            0|  0.00%|    >>> res.shape
  1309|         0|            0|            0|  0.00%|    (2, 1, 4)
  1310|         0|            0|            0|  0.00%|    """
  1311|         0|            0|            0|  0.00%|    kwds = {'keepdims': keepdims} if keepdims is not np._NoValue else {}
  1312|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'argmin', axis=axis, out=out, **kwds)
  1313|         0|            0|            0|  0.00%|
  1314|         0|            0|            0|  0.00%|
  1315|      5892|   0.00938082|  1.59213e-06|  0.01%|def _searchsorted_dispatcher(a, v, side=None, sorter=None):
  1316|      5892|    0.0122502|  2.07912e-06|  0.01%|    return (a, v, sorter)
  1317|         0|            0|            0|  0.00%|
  1318|         0|            0|            0|  0.00%|
  1319|      5892|   0.00966954|  1.64113e-06|  0.01%|@array_function_dispatch(_searchsorted_dispatcher)
  1320|         0|            0|            0|  0.00%|def searchsorted(a, v, side='left', sorter=None):
  1321|         0|            0|            0|  0.00%|    """
  1322|         0|            0|            0|  0.00%|    Find indices where elements should be inserted to maintain order.
  1323|         0|            0|            0|  0.00%|
  1324|         0|            0|            0|  0.00%|    Find the indices into a sorted array `a` such that, if the
  1325|         0|            0|            0|  0.00%|    corresponding elements in `v` were inserted before the indices, the
  1326|         0|            0|            0|  0.00%|    order of `a` would be preserved.
  1327|         0|            0|            0|  0.00%|
  1328|         0|            0|            0|  0.00%|    Assuming that `a` is sorted:
  1329|         0|            0|            0|  0.00%|
  1330|         0|            0|            0|  0.00%|    ======  ============================
  1331|         0|            0|            0|  0.00%|    `side`  returned index `i` satisfies
  1332|         0|            0|            0|  0.00%|    ======  ============================
  1333|         0|            0|            0|  0.00%|    left    ``a[i-1] < v <= a[i]``
  1334|         0|            0|            0|  0.00%|    right   ``a[i-1] <= v < a[i]``
  1335|         0|            0|            0|  0.00%|    ======  ============================
  1336|         0|            0|            0|  0.00%|
  1337|         0|            0|            0|  0.00%|    Parameters
  1338|         0|            0|            0|  0.00%|    ----------
  1339|         0|            0|            0|  0.00%|    a : 1-D array_like
  1340|         0|            0|            0|  0.00%|        Input array. If `sorter` is None, then it must be sorted in
  1341|         0|            0|            0|  0.00%|        ascending order, otherwise `sorter` must be an array of indices
  1342|         0|            0|            0|  0.00%|        that sort it.
  1343|         0|            0|            0|  0.00%|    v : array_like
  1344|         0|            0|            0|  0.00%|        Values to insert into `a`.
  1345|         0|            0|            0|  0.00%|    side : {'left', 'right'}, optional
  1346|         0|            0|            0|  0.00%|        If 'left', the index of the first suitable location found is given.
  1347|         0|            0|            0|  0.00%|        If 'right', return the last such index.  If there is no suitable
  1348|         0|            0|            0|  0.00%|        index, return either 0 or N (where N is the length of `a`).
  1349|         0|            0|            0|  0.00%|    sorter : 1-D array_like, optional
  1350|         0|            0|            0|  0.00%|        Optional array of integer indices that sort array a into ascending
  1351|         0|            0|            0|  0.00%|        order. They are typically the result of argsort.
  1352|         0|            0|            0|  0.00%|
  1353|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  1354|         0|            0|            0|  0.00%|
  1355|         0|            0|            0|  0.00%|    Returns
  1356|         0|            0|            0|  0.00%|    -------
  1357|         0|            0|            0|  0.00%|    indices : int or array of ints
  1358|         0|            0|            0|  0.00%|        Array of insertion points with the same shape as `v`,
  1359|         0|            0|            0|  0.00%|        or an integer if `v` is a scalar.
  1360|         0|            0|            0|  0.00%|
  1361|         0|            0|            0|  0.00%|    See Also
  1362|         0|            0|            0|  0.00%|    --------
  1363|         0|            0|            0|  0.00%|    sort : Return a sorted copy of an array.
  1364|         0|            0|            0|  0.00%|    histogram : Produce histogram from 1-D data.
  1365|         0|            0|            0|  0.00%|
  1366|         0|            0|            0|  0.00%|    Notes
  1367|         0|            0|            0|  0.00%|    -----
  1368|         0|            0|            0|  0.00%|    Binary search is used to find the required insertion points.
  1369|         0|            0|            0|  0.00%|
  1370|         0|            0|            0|  0.00%|    As of NumPy 1.4.0 `searchsorted` works with real/complex arrays containing
  1371|         0|            0|            0|  0.00%|    `nan` values. The enhanced sort order is documented in `sort`.
  1372|         0|            0|            0|  0.00%|
  1373|         0|            0|            0|  0.00%|    This function uses the same algorithm as the builtin python `bisect.bisect_left`
  1374|         0|            0|            0|  0.00%|    (``side='left'``) and `bisect.bisect_right` (``side='right'``) functions,
  1375|         0|            0|            0|  0.00%|    which is also vectorized in the `v` argument.
  1376|         0|            0|            0|  0.00%|
  1377|         0|            0|            0|  0.00%|    Examples
  1378|         0|            0|            0|  0.00%|    --------
  1379|         0|            0|            0|  0.00%|    >>> np.searchsorted([1,2,3,4,5], 3)
  1380|         0|            0|            0|  0.00%|    2
  1381|         0|            0|            0|  0.00%|    >>> np.searchsorted([1,2,3,4,5], 3, side='right')
  1382|         0|            0|            0|  0.00%|    3
  1383|         0|            0|            0|  0.00%|    >>> np.searchsorted([1,2,3,4,5], [-10, 10, 2, 3])
  1384|         0|            0|            0|  0.00%|    array([0, 5, 1, 2])
  1385|         0|            0|            0|  0.00%|
  1386|         0|            0|            0|  0.00%|    """
  1387|      5892|    0.0412495|  7.00094e-06|  0.04%|    return _wrapfunc(a, 'searchsorted', v, side=side, sorter=sorter)
(call)|      5892|    0.0772874|  1.31174e-05|  0.07%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:51 _wrapfunc
  1388|         0|            0|            0|  0.00%|
  1389|         0|            0|            0|  0.00%|
  1390|         0|            0|            0|  0.00%|def _resize_dispatcher(a, new_shape):
  1391|         0|            0|            0|  0.00%|    return (a,)
  1392|         0|            0|            0|  0.00%|
  1393|         0|            0|            0|  0.00%|
  1394|         0|            0|            0|  0.00%|@array_function_dispatch(_resize_dispatcher)
  1395|         0|            0|            0|  0.00%|def resize(a, new_shape):
  1396|         0|            0|            0|  0.00%|    """
  1397|         0|            0|            0|  0.00%|    Return a new array with the specified shape.
  1398|         0|            0|            0|  0.00%|
  1399|         0|            0|            0|  0.00%|    If the new array is larger than the original array, then the new
  1400|         0|            0|            0|  0.00%|    array is filled with repeated copies of `a`.  Note that this behavior
  1401|         0|            0|            0|  0.00%|    is different from a.resize(new_shape) which fills with zeros instead
  1402|         0|            0|            0|  0.00%|    of repeated copies of `a`.
  1403|         0|            0|            0|  0.00%|
  1404|         0|            0|            0|  0.00%|    Parameters
  1405|         0|            0|            0|  0.00%|    ----------
  1406|         0|            0|            0|  0.00%|    a : array_like
  1407|         0|            0|            0|  0.00%|        Array to be resized.
  1408|         0|            0|            0|  0.00%|
  1409|         0|            0|            0|  0.00%|    new_shape : int or tuple of int
  1410|         0|            0|            0|  0.00%|        Shape of resized array.
  1411|         0|            0|            0|  0.00%|
  1412|         0|            0|            0|  0.00%|    Returns
  1413|         0|            0|            0|  0.00%|    -------
  1414|         0|            0|            0|  0.00%|    reshaped_array : ndarray
  1415|         0|            0|            0|  0.00%|        The new array is formed from the data in the old array, repeated
  1416|         0|            0|            0|  0.00%|        if necessary to fill out the required number of elements.  The
  1417|         0|            0|            0|  0.00%|        data are repeated iterating over the array in C-order.
  1418|         0|            0|            0|  0.00%|
  1419|         0|            0|            0|  0.00%|    See Also
  1420|         0|            0|            0|  0.00%|    --------
  1421|         0|            0|            0|  0.00%|    numpy.reshape : Reshape an array without changing the total size.
  1422|         0|            0|            0|  0.00%|    numpy.pad : Enlarge and pad an array.
  1423|         0|            0|            0|  0.00%|    numpy.repeat : Repeat elements of an array.
  1424|         0|            0|            0|  0.00%|    ndarray.resize : resize an array in-place.
  1425|         0|            0|            0|  0.00%|
  1426|         0|            0|            0|  0.00%|    Notes
  1427|         0|            0|            0|  0.00%|    -----
  1428|         0|            0|            0|  0.00%|    When the total size of the array does not change `~numpy.reshape` should
  1429|         0|            0|            0|  0.00%|    be used.  In most other cases either indexing (to reduce the size)
  1430|         0|            0|            0|  0.00%|    or padding (to increase the size) may be a more appropriate solution.
  1431|         0|            0|            0|  0.00%|
  1432|         0|            0|            0|  0.00%|    Warning: This functionality does **not** consider axes separately,
  1433|         0|            0|            0|  0.00%|    i.e. it does not apply interpolation/extrapolation.
  1434|         0|            0|            0|  0.00%|    It fills the return array with the required number of elements, iterating
  1435|         0|            0|            0|  0.00%|    over `a` in C-order, disregarding axes (and cycling back from the start if
  1436|         0|            0|            0|  0.00%|    the new shape is larger).  This functionality is therefore not suitable to
  1437|         0|            0|            0|  0.00%|    resize images, or data where each axis represents a separate and distinct
  1438|         0|            0|            0|  0.00%|    entity.
  1439|         0|            0|            0|  0.00%|
  1440|         0|            0|            0|  0.00%|    Examples
  1441|         0|            0|            0|  0.00%|    --------
  1442|         0|            0|            0|  0.00%|    >>> a=np.array([[0,1],[2,3]])
  1443|         0|            0|            0|  0.00%|    >>> np.resize(a,(2,3))
  1444|         0|            0|            0|  0.00%|    array([[0, 1, 2],
  1445|         0|            0|            0|  0.00%|           [3, 0, 1]])
  1446|         0|            0|            0|  0.00%|    >>> np.resize(a,(1,4))
  1447|         0|            0|            0|  0.00%|    array([[0, 1, 2, 3]])
  1448|         0|            0|            0|  0.00%|    >>> np.resize(a,(2,4))
  1449|         0|            0|            0|  0.00%|    array([[0, 1, 2, 3],
  1450|         0|            0|            0|  0.00%|           [0, 1, 2, 3]])
  1451|         0|            0|            0|  0.00%|
  1452|         0|            0|            0|  0.00%|    """
  1453|         0|            0|            0|  0.00%|    if isinstance(new_shape, (int, nt.integer)):
  1454|         0|            0|            0|  0.00%|        new_shape = (new_shape,)
  1455|         0|            0|            0|  0.00%|
  1456|         0|            0|            0|  0.00%|    a = ravel(a)
  1457|         0|            0|            0|  0.00%|
  1458|         0|            0|            0|  0.00%|    new_size = 1
  1459|         0|            0|            0|  0.00%|    for dim_length in new_shape:
  1460|         0|            0|            0|  0.00%|        new_size *= dim_length
  1461|         0|            0|            0|  0.00%|        if dim_length < 0:
  1462|         0|            0|            0|  0.00%|            raise ValueError('all elements of `new_shape` must be non-negative')
  1463|         0|            0|            0|  0.00%|
  1464|         0|            0|            0|  0.00%|    if a.size == 0 or new_size == 0:
  1465|         0|            0|            0|  0.00%|        # First case must zero fill. The second would have repeats == 0.
  1466|         0|            0|            0|  0.00%|        return np.zeros_like(a, shape=new_shape)
  1467|         0|            0|            0|  0.00%|
  1468|         0|            0|            0|  0.00%|    repeats = -(-new_size // a.size)  # ceil division
  1469|         0|            0|            0|  0.00%|    a = concatenate((a,) * repeats)[:new_size]
  1470|         0|            0|            0|  0.00%|
  1471|         0|            0|            0|  0.00%|    return reshape(a, new_shape)
  1472|         0|            0|            0|  0.00%|
  1473|         0|            0|            0|  0.00%|
  1474|         0|            0|            0|  0.00%|def _squeeze_dispatcher(a, axis=None):
  1475|         0|            0|            0|  0.00%|    return (a,)
  1476|         0|            0|            0|  0.00%|
  1477|         0|            0|            0|  0.00%|
  1478|         0|            0|            0|  0.00%|@array_function_dispatch(_squeeze_dispatcher)
  1479|         0|            0|            0|  0.00%|def squeeze(a, axis=None):
  1480|         0|            0|            0|  0.00%|    """
  1481|         0|            0|            0|  0.00%|    Remove axes of length one from `a`.
  1482|         0|            0|            0|  0.00%|
  1483|         0|            0|            0|  0.00%|    Parameters
  1484|         0|            0|            0|  0.00%|    ----------
  1485|         0|            0|            0|  0.00%|    a : array_like
  1486|         0|            0|            0|  0.00%|        Input data.
  1487|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  1488|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  1489|         0|            0|            0|  0.00%|
  1490|         0|            0|            0|  0.00%|        Selects a subset of the entries of length one in the
  1491|         0|            0|            0|  0.00%|        shape. If an axis is selected with shape entry greater than
  1492|         0|            0|            0|  0.00%|        one, an error is raised.
  1493|         0|            0|            0|  0.00%|
  1494|         0|            0|            0|  0.00%|    Returns
  1495|         0|            0|            0|  0.00%|    -------
  1496|         0|            0|            0|  0.00%|    squeezed : ndarray
  1497|         0|            0|            0|  0.00%|        The input array, but with all or a subset of the
  1498|         0|            0|            0|  0.00%|        dimensions of length 1 removed. This is always `a` itself
  1499|         0|            0|            0|  0.00%|        or a view into `a`. Note that if all axes are squeezed,
  1500|         0|            0|            0|  0.00%|        the result is a 0d array and not a scalar.
  1501|         0|            0|            0|  0.00%|
  1502|         0|            0|            0|  0.00%|    Raises
  1503|         0|            0|            0|  0.00%|    ------
  1504|         0|            0|            0|  0.00%|    ValueError
  1505|         0|            0|            0|  0.00%|        If `axis` is not None, and an axis being squeezed is not of length 1
  1506|         0|            0|            0|  0.00%|
  1507|         0|            0|            0|  0.00%|    See Also
  1508|         0|            0|            0|  0.00%|    --------
  1509|         0|            0|            0|  0.00%|    expand_dims : The inverse operation, adding entries of length one
  1510|         0|            0|            0|  0.00%|    reshape : Insert, remove, and combine dimensions, and resize existing ones
  1511|         0|            0|            0|  0.00%|
  1512|         0|            0|            0|  0.00%|    Examples
  1513|         0|            0|            0|  0.00%|    --------
  1514|         0|            0|            0|  0.00%|    >>> x = np.array([[[0], [1], [2]]])
  1515|         0|            0|            0|  0.00%|    >>> x.shape
  1516|         0|            0|            0|  0.00%|    (1, 3, 1)
  1517|         0|            0|            0|  0.00%|    >>> np.squeeze(x).shape
  1518|         0|            0|            0|  0.00%|    (3,)
  1519|         0|            0|            0|  0.00%|    >>> np.squeeze(x, axis=0).shape
  1520|         0|            0|            0|  0.00%|    (3, 1)
  1521|         0|            0|            0|  0.00%|    >>> np.squeeze(x, axis=1).shape
  1522|         0|            0|            0|  0.00%|    Traceback (most recent call last):
  1523|         0|            0|            0|  0.00%|    ...
  1524|         0|            0|            0|  0.00%|    ValueError: cannot select an axis to squeeze out which has size not equal to one
  1525|         0|            0|            0|  0.00%|    >>> np.squeeze(x, axis=2).shape
  1526|         0|            0|            0|  0.00%|    (1, 3)
  1527|         0|            0|            0|  0.00%|    >>> x = np.array([[1234]])
  1528|         0|            0|            0|  0.00%|    >>> x.shape
  1529|         0|            0|            0|  0.00%|    (1, 1)
  1530|         0|            0|            0|  0.00%|    >>> np.squeeze(x)
  1531|         0|            0|            0|  0.00%|    array(1234)  # 0d array
  1532|         0|            0|            0|  0.00%|    >>> np.squeeze(x).shape
  1533|         0|            0|            0|  0.00%|    ()
  1534|         0|            0|            0|  0.00%|    >>> np.squeeze(x)[()]
  1535|         0|            0|            0|  0.00%|    1234
  1536|         0|            0|            0|  0.00%|
  1537|         0|            0|            0|  0.00%|    """
  1538|         0|            0|            0|  0.00%|    try:
  1539|         0|            0|            0|  0.00%|        squeeze = a.squeeze
  1540|         0|            0|            0|  0.00%|    except AttributeError:
  1541|         0|            0|            0|  0.00%|        return _wrapit(a, 'squeeze', axis=axis)
  1542|         0|            0|            0|  0.00%|    if axis is None:
  1543|         0|            0|            0|  0.00%|        return squeeze()
  1544|         0|            0|            0|  0.00%|    else:
  1545|         0|            0|            0|  0.00%|        return squeeze(axis=axis)
  1546|         0|            0|            0|  0.00%|
  1547|         0|            0|            0|  0.00%|
  1548|         0|            0|            0|  0.00%|def _diagonal_dispatcher(a, offset=None, axis1=None, axis2=None):
  1549|         0|            0|            0|  0.00%|    return (a,)
  1550|         0|            0|            0|  0.00%|
  1551|         0|            0|            0|  0.00%|
  1552|         0|            0|            0|  0.00%|@array_function_dispatch(_diagonal_dispatcher)
  1553|         0|            0|            0|  0.00%|def diagonal(a, offset=0, axis1=0, axis2=1):
  1554|         0|            0|            0|  0.00%|    """
  1555|         0|            0|            0|  0.00%|    Return specified diagonals.
  1556|         0|            0|            0|  0.00%|
  1557|         0|            0|            0|  0.00%|    If `a` is 2-D, returns the diagonal of `a` with the given offset,
  1558|         0|            0|            0|  0.00%|    i.e., the collection of elements of the form ``a[i, i+offset]``.  If
  1559|         0|            0|            0|  0.00%|    `a` has more than two dimensions, then the axes specified by `axis1`
  1560|         0|            0|            0|  0.00%|    and `axis2` are used to determine the 2-D sub-array whose diagonal is
  1561|         0|            0|            0|  0.00%|    returned.  The shape of the resulting array can be determined by
  1562|         0|            0|            0|  0.00%|    removing `axis1` and `axis2` and appending an index to the right equal
  1563|         0|            0|            0|  0.00%|    to the size of the resulting diagonals.
  1564|         0|            0|            0|  0.00%|
  1565|         0|            0|            0|  0.00%|    In versions of NumPy prior to 1.7, this function always returned a new,
  1566|         0|            0|            0|  0.00%|    independent array containing a copy of the values in the diagonal.
  1567|         0|            0|            0|  0.00%|
  1568|         0|            0|            0|  0.00%|    In NumPy 1.7 and 1.8, it continues to return a copy of the diagonal,
  1569|         0|            0|            0|  0.00%|    but depending on this fact is deprecated. Writing to the resulting
  1570|         0|            0|            0|  0.00%|    array continues to work as it used to, but a FutureWarning is issued.
  1571|         0|            0|            0|  0.00%|
  1572|         0|            0|            0|  0.00%|    Starting in NumPy 1.9 it returns a read-only view on the original array.
  1573|         0|            0|            0|  0.00%|    Attempting to write to the resulting array will produce an error.
  1574|         0|            0|            0|  0.00%|
  1575|         0|            0|            0|  0.00%|    In some future release, it will return a read/write view and writing to
  1576|         0|            0|            0|  0.00%|    the returned array will alter your original array.  The returned array
  1577|         0|            0|            0|  0.00%|    will have the same type as the input array.
  1578|         0|            0|            0|  0.00%|
  1579|         0|            0|            0|  0.00%|    If you don't write to the array returned by this function, then you can
  1580|         0|            0|            0|  0.00%|    just ignore all of the above.
  1581|         0|            0|            0|  0.00%|
  1582|         0|            0|            0|  0.00%|    If you depend on the current behavior, then we suggest copying the
  1583|         0|            0|            0|  0.00%|    returned array explicitly, i.e., use ``np.diagonal(a).copy()`` instead
  1584|         0|            0|            0|  0.00%|    of just ``np.diagonal(a)``. This will work with both past and future
  1585|         0|            0|            0|  0.00%|    versions of NumPy.
  1586|         0|            0|            0|  0.00%|
  1587|         0|            0|            0|  0.00%|    Parameters
  1588|         0|            0|            0|  0.00%|    ----------
  1589|         0|            0|            0|  0.00%|    a : array_like
  1590|         0|            0|            0|  0.00%|        Array from which the diagonals are taken.
  1591|         0|            0|            0|  0.00%|    offset : int, optional
  1592|         0|            0|            0|  0.00%|        Offset of the diagonal from the main diagonal.  Can be positive or
  1593|         0|            0|            0|  0.00%|        negative.  Defaults to main diagonal (0).
  1594|         0|            0|            0|  0.00%|    axis1 : int, optional
  1595|         0|            0|            0|  0.00%|        Axis to be used as the first axis of the 2-D sub-arrays from which
  1596|         0|            0|            0|  0.00%|        the diagonals should be taken.  Defaults to first axis (0).
  1597|         0|            0|            0|  0.00%|    axis2 : int, optional
  1598|         0|            0|            0|  0.00%|        Axis to be used as the second axis of the 2-D sub-arrays from
  1599|         0|            0|            0|  0.00%|        which the diagonals should be taken. Defaults to second axis (1).
  1600|         0|            0|            0|  0.00%|
  1601|         0|            0|            0|  0.00%|    Returns
  1602|         0|            0|            0|  0.00%|    -------
  1603|         0|            0|            0|  0.00%|    array_of_diagonals : ndarray
  1604|         0|            0|            0|  0.00%|        If `a` is 2-D, then a 1-D array containing the diagonal and of the
  1605|         0|            0|            0|  0.00%|        same type as `a` is returned unless `a` is a `matrix`, in which case
  1606|         0|            0|            0|  0.00%|        a 1-D array rather than a (2-D) `matrix` is returned in order to
  1607|         0|            0|            0|  0.00%|        maintain backward compatibility.
  1608|         0|            0|            0|  0.00%|
  1609|         0|            0|            0|  0.00%|        If ``a.ndim > 2``, then the dimensions specified by `axis1` and `axis2`
  1610|         0|            0|            0|  0.00%|        are removed, and a new axis inserted at the end corresponding to the
  1611|         0|            0|            0|  0.00%|        diagonal.
  1612|         0|            0|            0|  0.00%|
  1613|         0|            0|            0|  0.00%|    Raises
  1614|         0|            0|            0|  0.00%|    ------
  1615|         0|            0|            0|  0.00%|    ValueError
  1616|         0|            0|            0|  0.00%|        If the dimension of `a` is less than 2.
  1617|         0|            0|            0|  0.00%|
  1618|         0|            0|            0|  0.00%|    See Also
  1619|         0|            0|            0|  0.00%|    --------
  1620|         0|            0|            0|  0.00%|    diag : MATLAB work-a-like for 1-D and 2-D arrays.
  1621|         0|            0|            0|  0.00%|    diagflat : Create diagonal arrays.
  1622|         0|            0|            0|  0.00%|    trace : Sum along diagonals.
  1623|         0|            0|            0|  0.00%|
  1624|         0|            0|            0|  0.00%|    Examples
  1625|         0|            0|            0|  0.00%|    --------
  1626|         0|            0|            0|  0.00%|    >>> a = np.arange(4).reshape(2,2)
  1627|         0|            0|            0|  0.00%|    >>> a
  1628|         0|            0|            0|  0.00%|    array([[0, 1],
  1629|         0|            0|            0|  0.00%|           [2, 3]])
  1630|         0|            0|            0|  0.00%|    >>> a.diagonal()
  1631|         0|            0|            0|  0.00%|    array([0, 3])
  1632|         0|            0|            0|  0.00%|    >>> a.diagonal(1)
  1633|         0|            0|            0|  0.00%|    array([1])
  1634|         0|            0|            0|  0.00%|
  1635|         0|            0|            0|  0.00%|    A 3-D example:
  1636|         0|            0|            0|  0.00%|
  1637|         0|            0|            0|  0.00%|    >>> a = np.arange(8).reshape(2,2,2); a
  1638|         0|            0|            0|  0.00%|    array([[[0, 1],
  1639|         0|            0|            0|  0.00%|            [2, 3]],
  1640|         0|            0|            0|  0.00%|           [[4, 5],
  1641|         0|            0|            0|  0.00%|            [6, 7]]])
  1642|         0|            0|            0|  0.00%|    >>> a.diagonal(0,  # Main diagonals of two arrays created by skipping
  1643|         0|            0|            0|  0.00%|    ...            0,  # across the outer(left)-most axis last and
  1644|         0|            0|            0|  0.00%|    ...            1)  # the "middle" (row) axis first.
  1645|         0|            0|            0|  0.00%|    array([[0, 6],
  1646|         0|            0|            0|  0.00%|           [1, 7]])
  1647|         0|            0|            0|  0.00%|
  1648|         0|            0|            0|  0.00%|    The sub-arrays whose main diagonals we just obtained; note that each
  1649|         0|            0|            0|  0.00%|    corresponds to fixing the right-most (column) axis, and that the
  1650|         0|            0|            0|  0.00%|    diagonals are "packed" in rows.
  1651|         0|            0|            0|  0.00%|
  1652|         0|            0|            0|  0.00%|    >>> a[:,:,0]  # main diagonal is [0 6]
  1653|         0|            0|            0|  0.00%|    array([[0, 2],
  1654|         0|            0|            0|  0.00%|           [4, 6]])
  1655|         0|            0|            0|  0.00%|    >>> a[:,:,1]  # main diagonal is [1 7]
  1656|         0|            0|            0|  0.00%|    array([[1, 3],
  1657|         0|            0|            0|  0.00%|           [5, 7]])
  1658|         0|            0|            0|  0.00%|
  1659|         0|            0|            0|  0.00%|    The anti-diagonal can be obtained by reversing the order of elements
  1660|         0|            0|            0|  0.00%|    using either `numpy.flipud` or `numpy.fliplr`.
  1661|         0|            0|            0|  0.00%|
  1662|         0|            0|            0|  0.00%|    >>> a = np.arange(9).reshape(3, 3)
  1663|         0|            0|            0|  0.00%|    >>> a
  1664|         0|            0|            0|  0.00%|    array([[0, 1, 2],
  1665|         0|            0|            0|  0.00%|           [3, 4, 5],
  1666|         0|            0|            0|  0.00%|           [6, 7, 8]])
  1667|         0|            0|            0|  0.00%|    >>> np.fliplr(a).diagonal()  # Horizontal flip
  1668|         0|            0|            0|  0.00%|    array([2, 4, 6])
  1669|         0|            0|            0|  0.00%|    >>> np.flipud(a).diagonal()  # Vertical flip
  1670|         0|            0|            0|  0.00%|    array([6, 4, 2])
  1671|         0|            0|            0|  0.00%|
  1672|         0|            0|            0|  0.00%|    Note that the order in which the diagonal is retrieved varies depending
  1673|         0|            0|            0|  0.00%|    on the flip function.
  1674|         0|            0|            0|  0.00%|    """
  1675|         0|            0|            0|  0.00%|    if isinstance(a, np.matrix):
  1676|         0|            0|            0|  0.00%|        # Make diagonal of matrix 1-D to preserve backward compatibility.
  1677|         0|            0|            0|  0.00%|        return asarray(a).diagonal(offset=offset, axis1=axis1, axis2=axis2)
  1678|         0|            0|            0|  0.00%|    else:
  1679|         0|            0|            0|  0.00%|        return asanyarray(a).diagonal(offset=offset, axis1=axis1, axis2=axis2)
  1680|         0|            0|            0|  0.00%|
  1681|         0|            0|            0|  0.00%|
  1682|         0|            0|            0|  0.00%|def _trace_dispatcher(
  1683|         0|            0|            0|  0.00%|        a, offset=None, axis1=None, axis2=None, dtype=None, out=None):
  1684|         0|            0|            0|  0.00%|    return (a, out)
  1685|         0|            0|            0|  0.00%|
  1686|         0|            0|            0|  0.00%|
  1687|         0|            0|            0|  0.00%|@array_function_dispatch(_trace_dispatcher)
  1688|         0|            0|            0|  0.00%|def trace(a, offset=0, axis1=0, axis2=1, dtype=None, out=None):
  1689|         0|            0|            0|  0.00%|    """
  1690|         0|            0|            0|  0.00%|    Return the sum along diagonals of the array.
  1691|         0|            0|            0|  0.00%|
  1692|         0|            0|            0|  0.00%|    If `a` is 2-D, the sum along its diagonal with the given offset
  1693|         0|            0|            0|  0.00%|    is returned, i.e., the sum of elements ``a[i,i+offset]`` for all i.
  1694|         0|            0|            0|  0.00%|
  1695|         0|            0|            0|  0.00%|    If `a` has more than two dimensions, then the axes specified by axis1 and
  1696|         0|            0|            0|  0.00%|    axis2 are used to determine the 2-D sub-arrays whose traces are returned.
  1697|         0|            0|            0|  0.00%|    The shape of the resulting array is the same as that of `a` with `axis1`
  1698|         0|            0|            0|  0.00%|    and `axis2` removed.
  1699|         0|            0|            0|  0.00%|
  1700|         0|            0|            0|  0.00%|    Parameters
  1701|         0|            0|            0|  0.00%|    ----------
  1702|         0|            0|            0|  0.00%|    a : array_like
  1703|         0|            0|            0|  0.00%|        Input array, from which the diagonals are taken.
  1704|         0|            0|            0|  0.00%|    offset : int, optional
  1705|         0|            0|            0|  0.00%|        Offset of the diagonal from the main diagonal. Can be both positive
  1706|         0|            0|            0|  0.00%|        and negative. Defaults to 0.
  1707|         0|            0|            0|  0.00%|    axis1, axis2 : int, optional
  1708|         0|            0|            0|  0.00%|        Axes to be used as the first and second axis of the 2-D sub-arrays
  1709|         0|            0|            0|  0.00%|        from which the diagonals should be taken. Defaults are the first two
  1710|         0|            0|            0|  0.00%|        axes of `a`.
  1711|         0|            0|            0|  0.00%|    dtype : dtype, optional
  1712|         0|            0|            0|  0.00%|        Determines the data-type of the returned array and of the accumulator
  1713|         0|            0|            0|  0.00%|        where the elements are summed. If dtype has the value None and `a` is
  1714|         0|            0|            0|  0.00%|        of integer type of precision less than the default integer
  1715|         0|            0|            0|  0.00%|        precision, then the default integer precision is used. Otherwise,
  1716|         0|            0|            0|  0.00%|        the precision is the same as that of `a`.
  1717|         0|            0|            0|  0.00%|    out : ndarray, optional
  1718|         0|            0|            0|  0.00%|        Array into which the output is placed. Its type is preserved and
  1719|         0|            0|            0|  0.00%|        it must be of the right shape to hold the output.
  1720|         0|            0|            0|  0.00%|
  1721|         0|            0|            0|  0.00%|    Returns
  1722|         0|            0|            0|  0.00%|    -------
  1723|         0|            0|            0|  0.00%|    sum_along_diagonals : ndarray
  1724|         0|            0|            0|  0.00%|        If `a` is 2-D, the sum along the diagonal is returned.  If `a` has
  1725|         0|            0|            0|  0.00%|        larger dimensions, then an array of sums along diagonals is returned.
  1726|         0|            0|            0|  0.00%|
  1727|         0|            0|            0|  0.00%|    See Also
  1728|         0|            0|            0|  0.00%|    --------
  1729|         0|            0|            0|  0.00%|    diag, diagonal, diagflat
  1730|         0|            0|            0|  0.00%|
  1731|         0|            0|            0|  0.00%|    Examples
  1732|         0|            0|            0|  0.00%|    --------
  1733|         0|            0|            0|  0.00%|    >>> np.trace(np.eye(3))
  1734|         0|            0|            0|  0.00%|    3.0
  1735|         0|            0|            0|  0.00%|    >>> a = np.arange(8).reshape((2,2,2))
  1736|         0|            0|            0|  0.00%|    >>> np.trace(a)
  1737|         0|            0|            0|  0.00%|    array([6, 8])
  1738|         0|            0|            0|  0.00%|
  1739|         0|            0|            0|  0.00%|    >>> a = np.arange(24).reshape((2,2,2,3))
  1740|         0|            0|            0|  0.00%|    >>> np.trace(a).shape
  1741|         0|            0|            0|  0.00%|    (2, 3)
  1742|         0|            0|            0|  0.00%|
  1743|         0|            0|            0|  0.00%|    """
  1744|         0|            0|            0|  0.00%|    if isinstance(a, np.matrix):
  1745|         0|            0|            0|  0.00%|        # Get trace of matrix via an array to preserve backward compatibility.
  1746|         0|            0|            0|  0.00%|        return asarray(a).trace(offset=offset, axis1=axis1, axis2=axis2, dtype=dtype, out=out)
  1747|         0|            0|            0|  0.00%|    else:
  1748|         0|            0|            0|  0.00%|        return asanyarray(a).trace(offset=offset, axis1=axis1, axis2=axis2, dtype=dtype, out=out)
  1749|         0|            0|            0|  0.00%|
  1750|         0|            0|            0|  0.00%|
  1751|         0|            0|            0|  0.00%|def _ravel_dispatcher(a, order=None):
  1752|         0|            0|            0|  0.00%|    return (a,)
  1753|         0|            0|            0|  0.00%|
  1754|         0|            0|            0|  0.00%|
  1755|         0|            0|            0|  0.00%|@array_function_dispatch(_ravel_dispatcher)
  1756|         0|            0|            0|  0.00%|def ravel(a, order='C'):
  1757|         0|            0|            0|  0.00%|    """Return a contiguous flattened array.
  1758|         0|            0|            0|  0.00%|
  1759|         0|            0|            0|  0.00%|    A 1-D array, containing the elements of the input, is returned.  A copy is
  1760|         0|            0|            0|  0.00%|    made only if needed.
  1761|         0|            0|            0|  0.00%|
  1762|         0|            0|            0|  0.00%|    As of NumPy 1.10, the returned array will have the same type as the input
  1763|         0|            0|            0|  0.00%|    array. (for example, a masked array will be returned for a masked array
  1764|         0|            0|            0|  0.00%|    input)
  1765|         0|            0|            0|  0.00%|
  1766|         0|            0|            0|  0.00%|    Parameters
  1767|         0|            0|            0|  0.00%|    ----------
  1768|         0|            0|            0|  0.00%|    a : array_like
  1769|         0|            0|            0|  0.00%|        Input array.  The elements in `a` are read in the order specified by
  1770|         0|            0|            0|  0.00%|        `order`, and packed as a 1-D array.
  1771|         0|            0|            0|  0.00%|    order : {'C','F', 'A', 'K'}, optional
  1772|         0|            0|            0|  0.00%|
  1773|         0|            0|            0|  0.00%|        The elements of `a` are read using this index order. 'C' means
  1774|         0|            0|            0|  0.00%|        to index the elements in row-major, C-style order,
  1775|         0|            0|            0|  0.00%|        with the last axis index changing fastest, back to the first
  1776|         0|            0|            0|  0.00%|        axis index changing slowest.  'F' means to index the elements
  1777|         0|            0|            0|  0.00%|        in column-major, Fortran-style order, with the
  1778|         0|            0|            0|  0.00%|        first index changing fastest, and the last index changing
  1779|         0|            0|            0|  0.00%|        slowest. Note that the 'C' and 'F' options take no account of
  1780|         0|            0|            0|  0.00%|        the memory layout of the underlying array, and only refer to
  1781|         0|            0|            0|  0.00%|        the order of axis indexing.  'A' means to read the elements in
  1782|         0|            0|            0|  0.00%|        Fortran-like index order if `a` is Fortran *contiguous* in
  1783|         0|            0|            0|  0.00%|        memory, C-like order otherwise.  'K' means to read the
  1784|         0|            0|            0|  0.00%|        elements in the order they occur in memory, except for
  1785|         0|            0|            0|  0.00%|        reversing the data when strides are negative.  By default, 'C'
  1786|         0|            0|            0|  0.00%|        index order is used.
  1787|         0|            0|            0|  0.00%|
  1788|         0|            0|            0|  0.00%|    Returns
  1789|         0|            0|            0|  0.00%|    -------
  1790|         0|            0|            0|  0.00%|    y : array_like
  1791|         0|            0|            0|  0.00%|        y is an array of the same subtype as `a`, with shape ``(a.size,)``.
  1792|         0|            0|            0|  0.00%|        Note that matrices are special cased for backward compatibility, if `a`
  1793|         0|            0|            0|  0.00%|        is a matrix, then y is a 1-D ndarray.
  1794|         0|            0|            0|  0.00%|
  1795|         0|            0|            0|  0.00%|    See Also
  1796|         0|            0|            0|  0.00%|    --------
  1797|         0|            0|            0|  0.00%|    ndarray.flat : 1-D iterator over an array.
  1798|         0|            0|            0|  0.00%|    ndarray.flatten : 1-D array copy of the elements of an array
  1799|         0|            0|            0|  0.00%|                      in row-major order.
  1800|         0|            0|            0|  0.00%|    ndarray.reshape : Change the shape of an array without changing its data.
  1801|         0|            0|            0|  0.00%|
  1802|         0|            0|            0|  0.00%|    Notes
  1803|         0|            0|            0|  0.00%|    -----
  1804|         0|            0|            0|  0.00%|    In row-major, C-style order, in two dimensions, the row index
  1805|         0|            0|            0|  0.00%|    varies the slowest, and the column index the quickest.  This can
  1806|         0|            0|            0|  0.00%|    be generalized to multiple dimensions, where row-major order
  1807|         0|            0|            0|  0.00%|    implies that the index along the first axis varies slowest, and
  1808|         0|            0|            0|  0.00%|    the index along the last quickest.  The opposite holds for
  1809|         0|            0|            0|  0.00%|    column-major, Fortran-style index ordering.
  1810|         0|            0|            0|  0.00%|
  1811|         0|            0|            0|  0.00%|    When a view is desired in as many cases as possible, ``arr.reshape(-1)``
  1812|         0|            0|            0|  0.00%|    may be preferable.
  1813|         0|            0|            0|  0.00%|
  1814|         0|            0|            0|  0.00%|    Examples
  1815|         0|            0|            0|  0.00%|    --------
  1816|         0|            0|            0|  0.00%|    It is equivalent to ``reshape(-1, order=order)``.
  1817|         0|            0|            0|  0.00%|
  1818|         0|            0|            0|  0.00%|    >>> x = np.array([[1, 2, 3], [4, 5, 6]])
  1819|         0|            0|            0|  0.00%|    >>> np.ravel(x)
  1820|         0|            0|            0|  0.00%|    array([1, 2, 3, 4, 5, 6])
  1821|         0|            0|            0|  0.00%|
  1822|         0|            0|            0|  0.00%|    >>> x.reshape(-1)
  1823|         0|            0|            0|  0.00%|    array([1, 2, 3, 4, 5, 6])
  1824|         0|            0|            0|  0.00%|
  1825|         0|            0|            0|  0.00%|    >>> np.ravel(x, order='F')
  1826|         0|            0|            0|  0.00%|    array([1, 4, 2, 5, 3, 6])
  1827|         0|            0|            0|  0.00%|
  1828|         0|            0|            0|  0.00%|    When ``order`` is 'A', it will preserve the array's 'C' or 'F' ordering:
  1829|         0|            0|            0|  0.00%|
  1830|         0|            0|            0|  0.00%|    >>> np.ravel(x.T)
  1831|         0|            0|            0|  0.00%|    array([1, 4, 2, 5, 3, 6])
  1832|         0|            0|            0|  0.00%|    >>> np.ravel(x.T, order='A')
  1833|         0|            0|            0|  0.00%|    array([1, 2, 3, 4, 5, 6])
  1834|         0|            0|            0|  0.00%|
  1835|         0|            0|            0|  0.00%|    When ``order`` is 'K', it will preserve orderings that are neither 'C'
  1836|         0|            0|            0|  0.00%|    nor 'F', but won't reverse axes:
  1837|         0|            0|            0|  0.00%|
  1838|         0|            0|            0|  0.00%|    >>> a = np.arange(3)[::-1]; a
  1839|         0|            0|            0|  0.00%|    array([2, 1, 0])
  1840|         0|            0|            0|  0.00%|    >>> a.ravel(order='C')
  1841|         0|            0|            0|  0.00%|    array([2, 1, 0])
  1842|         0|            0|            0|  0.00%|    >>> a.ravel(order='K')
  1843|         0|            0|            0|  0.00%|    array([2, 1, 0])
  1844|         0|            0|            0|  0.00%|
  1845|         0|            0|            0|  0.00%|    >>> a = np.arange(12).reshape(2,3,2).swapaxes(1,2); a
  1846|         0|            0|            0|  0.00%|    array([[[ 0,  2,  4],
  1847|         0|            0|            0|  0.00%|            [ 1,  3,  5]],
  1848|         0|            0|            0|  0.00%|           [[ 6,  8, 10],
  1849|         0|            0|            0|  0.00%|            [ 7,  9, 11]]])
  1850|         0|            0|            0|  0.00%|    >>> a.ravel(order='C')
  1851|         0|            0|            0|  0.00%|    array([ 0,  2,  4,  1,  3,  5,  6,  8, 10,  7,  9, 11])
  1852|         0|            0|            0|  0.00%|    >>> a.ravel(order='K')
  1853|         0|            0|            0|  0.00%|    array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
  1854|         0|            0|            0|  0.00%|
  1855|         0|            0|            0|  0.00%|    """
  1856|         0|            0|            0|  0.00%|    if isinstance(a, np.matrix):
  1857|         0|            0|            0|  0.00%|        return asarray(a).ravel(order=order)
  1858|         0|            0|            0|  0.00%|    else:
  1859|         0|            0|            0|  0.00%|        return asanyarray(a).ravel(order=order)
  1860|         0|            0|            0|  0.00%|
  1861|         0|            0|            0|  0.00%|
  1862|         0|            0|            0|  0.00%|def _nonzero_dispatcher(a):
  1863|         0|            0|            0|  0.00%|    return (a,)
  1864|         0|            0|            0|  0.00%|
  1865|         0|            0|            0|  0.00%|
  1866|         0|            0|            0|  0.00%|@array_function_dispatch(_nonzero_dispatcher)
  1867|         0|            0|            0|  0.00%|def nonzero(a):
  1868|         0|            0|            0|  0.00%|    """
  1869|         0|            0|            0|  0.00%|    Return the indices of the elements that are non-zero.
  1870|         0|            0|            0|  0.00%|
  1871|         0|            0|            0|  0.00%|    Returns a tuple of arrays, one for each dimension of `a`,
  1872|         0|            0|            0|  0.00%|    containing the indices of the non-zero elements in that
  1873|         0|            0|            0|  0.00%|    dimension. The values in `a` are always tested and returned in
  1874|         0|            0|            0|  0.00%|    row-major, C-style order.
  1875|         0|            0|            0|  0.00%|
  1876|         0|            0|            0|  0.00%|    To group the indices by element, rather than dimension, use `argwhere`,
  1877|         0|            0|            0|  0.00%|    which returns a row for each non-zero element.
  1878|         0|            0|            0|  0.00%|
  1879|         0|            0|            0|  0.00%|    .. note::
  1880|         0|            0|            0|  0.00%|
  1881|         0|            0|            0|  0.00%|       When called on a zero-d array or scalar, ``nonzero(a)`` is treated
  1882|         0|            0|            0|  0.00%|       as ``nonzero(atleast_1d(a))``.
  1883|         0|            0|            0|  0.00%|
  1884|         0|            0|            0|  0.00%|       .. deprecated:: 1.17.0
  1885|         0|            0|            0|  0.00%|
  1886|         0|            0|            0|  0.00%|          Use `atleast_1d` explicitly if this behavior is deliberate.
  1887|         0|            0|            0|  0.00%|
  1888|         0|            0|            0|  0.00%|    Parameters
  1889|         0|            0|            0|  0.00%|    ----------
  1890|         0|            0|            0|  0.00%|    a : array_like
  1891|         0|            0|            0|  0.00%|        Input array.
  1892|         0|            0|            0|  0.00%|
  1893|         0|            0|            0|  0.00%|    Returns
  1894|         0|            0|            0|  0.00%|    -------
  1895|         0|            0|            0|  0.00%|    tuple_of_arrays : tuple
  1896|         0|            0|            0|  0.00%|        Indices of elements that are non-zero.
  1897|         0|            0|            0|  0.00%|
  1898|         0|            0|            0|  0.00%|    See Also
  1899|         0|            0|            0|  0.00%|    --------
  1900|         0|            0|            0|  0.00%|    flatnonzero :
  1901|         0|            0|            0|  0.00%|        Return indices that are non-zero in the flattened version of the input
  1902|         0|            0|            0|  0.00%|        array.
  1903|         0|            0|            0|  0.00%|    ndarray.nonzero :
  1904|         0|            0|            0|  0.00%|        Equivalent ndarray method.
  1905|         0|            0|            0|  0.00%|    count_nonzero :
  1906|         0|            0|            0|  0.00%|        Counts the number of non-zero elements in the input array.
  1907|         0|            0|            0|  0.00%|
  1908|         0|            0|            0|  0.00%|    Notes
  1909|         0|            0|            0|  0.00%|    -----
  1910|         0|            0|            0|  0.00%|    While the nonzero values can be obtained with ``a[nonzero(a)]``, it is
  1911|         0|            0|            0|  0.00%|    recommended to use ``x[x.astype(bool)]`` or ``x[x != 0]`` instead, which
  1912|         0|            0|            0|  0.00%|    will correctly handle 0-d arrays.
  1913|         0|            0|            0|  0.00%|
  1914|         0|            0|            0|  0.00%|    Examples
  1915|         0|            0|            0|  0.00%|    --------
  1916|         0|            0|            0|  0.00%|    >>> x = np.array([[3, 0, 0], [0, 4, 0], [5, 6, 0]])
  1917|         0|            0|            0|  0.00%|    >>> x
  1918|         0|            0|            0|  0.00%|    array([[3, 0, 0],
  1919|         0|            0|            0|  0.00%|           [0, 4, 0],
  1920|         0|            0|            0|  0.00%|           [5, 6, 0]])
  1921|         0|            0|            0|  0.00%|    >>> np.nonzero(x)
  1922|         0|            0|            0|  0.00%|    (array([0, 1, 2, 2]), array([0, 1, 0, 1]))
  1923|         0|            0|            0|  0.00%|
  1924|         0|            0|            0|  0.00%|    >>> x[np.nonzero(x)]
  1925|         0|            0|            0|  0.00%|    array([3, 4, 5, 6])
  1926|         0|            0|            0|  0.00%|    >>> np.transpose(np.nonzero(x))
  1927|         0|            0|            0|  0.00%|    array([[0, 0],
  1928|         0|            0|            0|  0.00%|           [1, 1],
  1929|         0|            0|            0|  0.00%|           [2, 0],
  1930|         0|            0|            0|  0.00%|           [2, 1]])
  1931|         0|            0|            0|  0.00%|
  1932|         0|            0|            0|  0.00%|    A common use for ``nonzero`` is to find the indices of an array, where
  1933|         0|            0|            0|  0.00%|    a condition is True.  Given an array `a`, the condition `a` > 3 is a
  1934|         0|            0|            0|  0.00%|    boolean array and since False is interpreted as 0, np.nonzero(a > 3)
  1935|         0|            0|            0|  0.00%|    yields the indices of the `a` where the condition is true.
  1936|         0|            0|            0|  0.00%|
  1937|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
  1938|         0|            0|            0|  0.00%|    >>> a > 3
  1939|         0|            0|            0|  0.00%|    array([[False, False, False],
  1940|         0|            0|            0|  0.00%|           [ True,  True,  True],
  1941|         0|            0|            0|  0.00%|           [ True,  True,  True]])
  1942|         0|            0|            0|  0.00%|    >>> np.nonzero(a > 3)
  1943|         0|            0|            0|  0.00%|    (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))
  1944|         0|            0|            0|  0.00%|
  1945|         0|            0|            0|  0.00%|    Using this result to index `a` is equivalent to using the mask directly:
  1946|         0|            0|            0|  0.00%|
  1947|         0|            0|            0|  0.00%|    >>> a[np.nonzero(a > 3)]
  1948|         0|            0|            0|  0.00%|    array([4, 5, 6, 7, 8, 9])
  1949|         0|            0|            0|  0.00%|    >>> a[a > 3]  # prefer this spelling
  1950|         0|            0|            0|  0.00%|    array([4, 5, 6, 7, 8, 9])
  1951|         0|            0|            0|  0.00%|
  1952|         0|            0|            0|  0.00%|    ``nonzero`` can also be called as a method of the array.
  1953|         0|            0|            0|  0.00%|
  1954|         0|            0|            0|  0.00%|    >>> (a > 3).nonzero()
  1955|         0|            0|            0|  0.00%|    (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))
  1956|         0|            0|            0|  0.00%|
  1957|         0|            0|            0|  0.00%|    """
  1958|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'nonzero')
  1959|         0|            0|            0|  0.00%|
  1960|         0|            0|            0|  0.00%|
  1961|         0|            0|            0|  0.00%|def _shape_dispatcher(a):
  1962|         0|            0|            0|  0.00%|    return (a,)
  1963|         0|            0|            0|  0.00%|
  1964|         0|            0|            0|  0.00%|
  1965|         0|            0|            0|  0.00%|@array_function_dispatch(_shape_dispatcher)
  1966|         0|            0|            0|  0.00%|def shape(a):
  1967|         0|            0|            0|  0.00%|    """
  1968|         0|            0|            0|  0.00%|    Return the shape of an array.
  1969|         0|            0|            0|  0.00%|
  1970|         0|            0|            0|  0.00%|    Parameters
  1971|         0|            0|            0|  0.00%|    ----------
  1972|         0|            0|            0|  0.00%|    a : array_like
  1973|         0|            0|            0|  0.00%|        Input array.
  1974|         0|            0|            0|  0.00%|
  1975|         0|            0|            0|  0.00%|    Returns
  1976|         0|            0|            0|  0.00%|    -------
  1977|         0|            0|            0|  0.00%|    shape : tuple of ints
  1978|         0|            0|            0|  0.00%|        The elements of the shape tuple give the lengths of the
  1979|         0|            0|            0|  0.00%|        corresponding array dimensions.
  1980|         0|            0|            0|  0.00%|
  1981|         0|            0|            0|  0.00%|    See Also
  1982|         0|            0|            0|  0.00%|    --------
  1983|         0|            0|            0|  0.00%|    len
  1984|         0|            0|            0|  0.00%|    ndarray.shape : Equivalent array method.
  1985|         0|            0|            0|  0.00%|
  1986|         0|            0|            0|  0.00%|    Examples
  1987|         0|            0|            0|  0.00%|    --------
  1988|         0|            0|            0|  0.00%|    >>> np.shape(np.eye(3))
  1989|         0|            0|            0|  0.00%|    (3, 3)
  1990|         0|            0|            0|  0.00%|    >>> np.shape([[1, 2]])
  1991|         0|            0|            0|  0.00%|    (1, 2)
  1992|         0|            0|            0|  0.00%|    >>> np.shape([0])
  1993|         0|            0|            0|  0.00%|    (1,)
  1994|         0|            0|            0|  0.00%|    >>> np.shape(0)
  1995|         0|            0|            0|  0.00%|    ()
  1996|         0|            0|            0|  0.00%|
  1997|         0|            0|            0|  0.00%|    >>> a = np.array([(1, 2), (3, 4)], dtype=[('x', 'i4'), ('y', 'i4')])
  1998|         0|            0|            0|  0.00%|    >>> np.shape(a)
  1999|         0|            0|            0|  0.00%|    (2,)
  2000|         0|            0|            0|  0.00%|    >>> a.shape
  2001|         0|            0|            0|  0.00%|    (2,)
  2002|         0|            0|            0|  0.00%|
  2003|         0|            0|            0|  0.00%|    """
  2004|         0|            0|            0|  0.00%|    try:
  2005|         0|            0|            0|  0.00%|        result = a.shape
  2006|         0|            0|            0|  0.00%|    except AttributeError:
  2007|         0|            0|            0|  0.00%|        result = asarray(a).shape
  2008|         0|            0|            0|  0.00%|    return result
  2009|         0|            0|            0|  0.00%|
  2010|         0|            0|            0|  0.00%|
  2011|         0|            0|            0|  0.00%|def _compress_dispatcher(condition, a, axis=None, out=None):
  2012|         0|            0|            0|  0.00%|    return (condition, a, out)
  2013|         0|            0|            0|  0.00%|
  2014|         0|            0|            0|  0.00%|
  2015|         0|            0|            0|  0.00%|@array_function_dispatch(_compress_dispatcher)
  2016|         0|            0|            0|  0.00%|def compress(condition, a, axis=None, out=None):
  2017|         0|            0|            0|  0.00%|    """
  2018|         0|            0|            0|  0.00%|    Return selected slices of an array along given axis.
  2019|         0|            0|            0|  0.00%|
  2020|         0|            0|            0|  0.00%|    When working along a given axis, a slice along that axis is returned in
  2021|         0|            0|            0|  0.00%|    `output` for each index where `condition` evaluates to True. When
  2022|         0|            0|            0|  0.00%|    working on a 1-D array, `compress` is equivalent to `extract`.
  2023|         0|            0|            0|  0.00%|
  2024|         0|            0|            0|  0.00%|    Parameters
  2025|         0|            0|            0|  0.00%|    ----------
  2026|         0|            0|            0|  0.00%|    condition : 1-D array of bools
  2027|         0|            0|            0|  0.00%|        Array that selects which entries to return. If len(condition)
  2028|         0|            0|            0|  0.00%|        is less than the size of `a` along the given axis, then output is
  2029|         0|            0|            0|  0.00%|        truncated to the length of the condition array.
  2030|         0|            0|            0|  0.00%|    a : array_like
  2031|         0|            0|            0|  0.00%|        Array from which to extract a part.
  2032|         0|            0|            0|  0.00%|    axis : int, optional
  2033|         0|            0|            0|  0.00%|        Axis along which to take slices. If None (default), work on the
  2034|         0|            0|            0|  0.00%|        flattened array.
  2035|         0|            0|            0|  0.00%|    out : ndarray, optional
  2036|         0|            0|            0|  0.00%|        Output array.  Its type is preserved and it must be of the right
  2037|         0|            0|            0|  0.00%|        shape to hold the output.
  2038|         0|            0|            0|  0.00%|
  2039|         0|            0|            0|  0.00%|    Returns
  2040|         0|            0|            0|  0.00%|    -------
  2041|         0|            0|            0|  0.00%|    compressed_array : ndarray
  2042|         0|            0|            0|  0.00%|        A copy of `a` without the slices along axis for which `condition`
  2043|         0|            0|            0|  0.00%|        is false.
  2044|         0|            0|            0|  0.00%|
  2045|         0|            0|            0|  0.00%|    See Also
  2046|         0|            0|            0|  0.00%|    --------
  2047|         0|            0|            0|  0.00%|    take, choose, diag, diagonal, select
  2048|         0|            0|            0|  0.00%|    ndarray.compress : Equivalent method in ndarray
  2049|         0|            0|            0|  0.00%|    extract : Equivalent method when working on 1-D arrays
  2050|         0|            0|            0|  0.00%|    :ref:`ufuncs-output-type`
  2051|         0|            0|            0|  0.00%|
  2052|         0|            0|            0|  0.00%|    Examples
  2053|         0|            0|            0|  0.00%|    --------
  2054|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2], [3, 4], [5, 6]])
  2055|         0|            0|            0|  0.00%|    >>> a
  2056|         0|            0|            0|  0.00%|    array([[1, 2],
  2057|         0|            0|            0|  0.00%|           [3, 4],
  2058|         0|            0|            0|  0.00%|           [5, 6]])
  2059|         0|            0|            0|  0.00%|    >>> np.compress([0, 1], a, axis=0)
  2060|         0|            0|            0|  0.00%|    array([[3, 4]])
  2061|         0|            0|            0|  0.00%|    >>> np.compress([False, True, True], a, axis=0)
  2062|         0|            0|            0|  0.00%|    array([[3, 4],
  2063|         0|            0|            0|  0.00%|           [5, 6]])
  2064|         0|            0|            0|  0.00%|    >>> np.compress([False, True], a, axis=1)
  2065|         0|            0|            0|  0.00%|    array([[2],
  2066|         0|            0|            0|  0.00%|           [4],
  2067|         0|            0|            0|  0.00%|           [6]])
  2068|         0|            0|            0|  0.00%|
  2069|         0|            0|            0|  0.00%|    Working on the flattened array does not return slices along an axis but
  2070|         0|            0|            0|  0.00%|    selects elements.
  2071|         0|            0|            0|  0.00%|
  2072|         0|            0|            0|  0.00%|    >>> np.compress([False, True], a)
  2073|         0|            0|            0|  0.00%|    array([2])
  2074|         0|            0|            0|  0.00%|
  2075|         0|            0|            0|  0.00%|    """
  2076|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'compress', condition, axis=axis, out=out)
  2077|         0|            0|            0|  0.00%|
  2078|         0|            0|            0|  0.00%|
  2079|         0|            0|            0|  0.00%|def _clip_dispatcher(a, a_min, a_max, out=None, **kwargs):
  2080|         0|            0|            0|  0.00%|    return (a, a_min, a_max)
  2081|         0|            0|            0|  0.00%|
  2082|         0|            0|            0|  0.00%|
  2083|         0|            0|            0|  0.00%|@array_function_dispatch(_clip_dispatcher)
  2084|         0|            0|            0|  0.00%|def clip(a, a_min, a_max, out=None, **kwargs):
  2085|         0|            0|            0|  0.00%|    """
  2086|         0|            0|            0|  0.00%|    Clip (limit) the values in an array.
  2087|         0|            0|            0|  0.00%|
  2088|         0|            0|            0|  0.00%|    Given an interval, values outside the interval are clipped to
  2089|         0|            0|            0|  0.00%|    the interval edges.  For example, if an interval of ``[0, 1]``
  2090|         0|            0|            0|  0.00%|    is specified, values smaller than 0 become 0, and values larger
  2091|         0|            0|            0|  0.00%|    than 1 become 1.
  2092|         0|            0|            0|  0.00%|
  2093|         0|            0|            0|  0.00%|    Equivalent to but faster than ``np.minimum(a_max, np.maximum(a, a_min))``.
  2094|         0|            0|            0|  0.00%|
  2095|         0|            0|            0|  0.00%|    No check is performed to ensure ``a_min < a_max``.
  2096|         0|            0|            0|  0.00%|
  2097|         0|            0|            0|  0.00%|    Parameters
  2098|         0|            0|            0|  0.00%|    ----------
  2099|         0|            0|            0|  0.00%|    a : array_like
  2100|         0|            0|            0|  0.00%|        Array containing elements to clip.
  2101|         0|            0|            0|  0.00%|    a_min, a_max : array_like or None
  2102|         0|            0|            0|  0.00%|        Minimum and maximum value. If ``None``, clipping is not performed on
  2103|         0|            0|            0|  0.00%|        the corresponding edge. Only one of `a_min` and `a_max` may be
  2104|         0|            0|            0|  0.00%|        ``None``. Both are broadcast against `a`.
  2105|         0|            0|            0|  0.00%|    out : ndarray, optional
  2106|         0|            0|            0|  0.00%|        The results will be placed in this array. It may be the input
  2107|         0|            0|            0|  0.00%|        array for in-place clipping.  `out` must be of the right shape
  2108|         0|            0|            0|  0.00%|        to hold the output.  Its type is preserved.
  2109|         0|            0|            0|  0.00%|    **kwargs
  2110|         0|            0|            0|  0.00%|        For other keyword-only arguments, see the
  2111|         0|            0|            0|  0.00%|        :ref:`ufunc docs <ufuncs.kwargs>`.
  2112|         0|            0|            0|  0.00%|
  2113|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
  2114|         0|            0|            0|  0.00%|
  2115|         0|            0|            0|  0.00%|    Returns
  2116|         0|            0|            0|  0.00%|    -------
  2117|         0|            0|            0|  0.00%|    clipped_array : ndarray
  2118|         0|            0|            0|  0.00%|        An array with the elements of `a`, but where values
  2119|         0|            0|            0|  0.00%|        < `a_min` are replaced with `a_min`, and those > `a_max`
  2120|         0|            0|            0|  0.00%|        with `a_max`.
  2121|         0|            0|            0|  0.00%|
  2122|         0|            0|            0|  0.00%|    See Also
  2123|         0|            0|            0|  0.00%|    --------
  2124|         0|            0|            0|  0.00%|    :ref:`ufuncs-output-type`
  2125|         0|            0|            0|  0.00%|
  2126|         0|            0|            0|  0.00%|    Notes
  2127|         0|            0|            0|  0.00%|    -----
  2128|         0|            0|            0|  0.00%|    When `a_min` is greater than `a_max`, `clip` returns an
  2129|         0|            0|            0|  0.00%|    array in which all values are equal to `a_max`,
  2130|         0|            0|            0|  0.00%|    as shown in the second example.
  2131|         0|            0|            0|  0.00%|
  2132|         0|            0|            0|  0.00%|    Examples
  2133|         0|            0|            0|  0.00%|    --------
  2134|         0|            0|            0|  0.00%|    >>> a = np.arange(10)
  2135|         0|            0|            0|  0.00%|    >>> a
  2136|         0|            0|            0|  0.00%|    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
  2137|         0|            0|            0|  0.00%|    >>> np.clip(a, 1, 8)
  2138|         0|            0|            0|  0.00%|    array([1, 1, 2, 3, 4, 5, 6, 7, 8, 8])
  2139|         0|            0|            0|  0.00%|    >>> np.clip(a, 8, 1)
  2140|         0|            0|            0|  0.00%|    array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
  2141|         0|            0|            0|  0.00%|    >>> np.clip(a, 3, 6, out=a)
  2142|         0|            0|            0|  0.00%|    array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])
  2143|         0|            0|            0|  0.00%|    >>> a
  2144|         0|            0|            0|  0.00%|    array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])
  2145|         0|            0|            0|  0.00%|    >>> a = np.arange(10)
  2146|         0|            0|            0|  0.00%|    >>> a
  2147|         0|            0|            0|  0.00%|    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
  2148|         0|            0|            0|  0.00%|    >>> np.clip(a, [3, 4, 1, 1, 1, 4, 4, 4, 4, 4], 8)
  2149|         0|            0|            0|  0.00%|    array([3, 4, 2, 3, 4, 5, 6, 7, 8, 8])
  2150|         0|            0|            0|  0.00%|
  2151|         0|            0|            0|  0.00%|    """
  2152|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'clip', a_min, a_max, out=out, **kwargs)
  2153|         0|            0|            0|  0.00%|
  2154|         0|            0|            0|  0.00%|
  2155|      7867|    0.0152199|  1.93465e-06|  0.01%|def _sum_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None,
  2156|         0|            0|            0|  0.00%|                    initial=None, where=None):
  2157|      7867|    0.0190847|  2.42592e-06|  0.02%|    return (a, out)
  2158|         0|            0|            0|  0.00%|
  2159|         0|            0|            0|  0.00%|
  2160|      7867|    0.0190399|  2.42022e-06|  0.02%|@array_function_dispatch(_sum_dispatcher)
  2161|         0|            0|            0|  0.00%|def sum(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,
  2162|         0|            0|            0|  0.00%|        initial=np._NoValue, where=np._NoValue):
  2163|         0|            0|            0|  0.00%|    """
  2164|         0|            0|            0|  0.00%|    Sum of array elements over a given axis.
  2165|         0|            0|            0|  0.00%|
  2166|         0|            0|            0|  0.00%|    Parameters
  2167|         0|            0|            0|  0.00%|    ----------
  2168|         0|            0|            0|  0.00%|    a : array_like
  2169|         0|            0|            0|  0.00%|        Elements to sum.
  2170|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  2171|         0|            0|            0|  0.00%|        Axis or axes along which a sum is performed.  The default,
  2172|         0|            0|            0|  0.00%|        axis=None, will sum all of the elements of the input array.  If
  2173|         0|            0|            0|  0.00%|        axis is negative it counts from the last to the first axis.
  2174|         0|            0|            0|  0.00%|
  2175|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  2176|         0|            0|            0|  0.00%|
  2177|         0|            0|            0|  0.00%|        If axis is a tuple of ints, a sum is performed on all of the axes
  2178|         0|            0|            0|  0.00%|        specified in the tuple instead of a single axis or all the axes as
  2179|         0|            0|            0|  0.00%|        before.
  2180|         0|            0|            0|  0.00%|    dtype : dtype, optional
  2181|         0|            0|            0|  0.00%|        The type of the returned array and of the accumulator in which the
  2182|         0|            0|            0|  0.00%|        elements are summed.  The dtype of `a` is used by default unless `a`
  2183|         0|            0|            0|  0.00%|        has an integer dtype of less precision than the default platform
  2184|         0|            0|            0|  0.00%|        integer.  In that case, if `a` is signed then the platform integer
  2185|         0|            0|            0|  0.00%|        is used while if `a` is unsigned then an unsigned integer of the
  2186|         0|            0|            0|  0.00%|        same precision as the platform integer is used.
  2187|         0|            0|            0|  0.00%|    out : ndarray, optional
  2188|         0|            0|            0|  0.00%|        Alternative output array in which to place the result. It must have
  2189|         0|            0|            0|  0.00%|        the same shape as the expected output, but the type of the output
  2190|         0|            0|            0|  0.00%|        values will be cast if necessary.
  2191|         0|            0|            0|  0.00%|    keepdims : bool, optional
  2192|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  2193|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  2194|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  2195|         0|            0|            0|  0.00%|
  2196|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  2197|         0|            0|            0|  0.00%|        passed through to the `sum` method of sub-classes of
  2198|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  2199|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  2200|         0|            0|            0|  0.00%|        exceptions will be raised.
  2201|         0|            0|            0|  0.00%|    initial : scalar, optional
  2202|         0|            0|            0|  0.00%|        Starting value for the sum. See `~numpy.ufunc.reduce` for details.
  2203|         0|            0|            0|  0.00%|
  2204|         0|            0|            0|  0.00%|        .. versionadded:: 1.15.0
  2205|         0|            0|            0|  0.00%|
  2206|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  2207|         0|            0|            0|  0.00%|        Elements to include in the sum. See `~numpy.ufunc.reduce` for details.
  2208|         0|            0|            0|  0.00%|
  2209|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
  2210|         0|            0|            0|  0.00%|
  2211|         0|            0|            0|  0.00%|    Returns
  2212|         0|            0|            0|  0.00%|    -------
  2213|         0|            0|            0|  0.00%|    sum_along_axis : ndarray
  2214|         0|            0|            0|  0.00%|        An array with the same shape as `a`, with the specified
  2215|         0|            0|            0|  0.00%|        axis removed.   If `a` is a 0-d array, or if `axis` is None, a scalar
  2216|         0|            0|            0|  0.00%|        is returned.  If an output array is specified, a reference to
  2217|         0|            0|            0|  0.00%|        `out` is returned.
  2218|         0|            0|            0|  0.00%|
  2219|         0|            0|            0|  0.00%|    See Also
  2220|         0|            0|            0|  0.00%|    --------
  2221|         0|            0|            0|  0.00%|    ndarray.sum : Equivalent method.
  2222|         0|            0|            0|  0.00%|
  2223|         0|            0|            0|  0.00%|    add.reduce : Equivalent functionality of `add`.
  2224|         0|            0|            0|  0.00%|
  2225|         0|            0|            0|  0.00%|    cumsum : Cumulative sum of array elements.
  2226|         0|            0|            0|  0.00%|
  2227|         0|            0|            0|  0.00%|    trapz : Integration of array values using the composite trapezoidal rule.
  2228|         0|            0|            0|  0.00%|
  2229|         0|            0|            0|  0.00%|    mean, average
  2230|         0|            0|            0|  0.00%|
  2231|         0|            0|            0|  0.00%|    Notes
  2232|         0|            0|            0|  0.00%|    -----
  2233|         0|            0|            0|  0.00%|    Arithmetic is modular when using integer types, and no error is
  2234|         0|            0|            0|  0.00%|    raised on overflow.
  2235|         0|            0|            0|  0.00%|
  2236|         0|            0|            0|  0.00%|    The sum of an empty array is the neutral element 0:
  2237|         0|            0|            0|  0.00%|
  2238|         0|            0|            0|  0.00%|    >>> np.sum([])
  2239|         0|            0|            0|  0.00%|    0.0
  2240|         0|            0|            0|  0.00%|
  2241|         0|            0|            0|  0.00%|    For floating point numbers the numerical precision of sum (and
  2242|         0|            0|            0|  0.00%|    ``np.add.reduce``) is in general limited by directly adding each number
  2243|         0|            0|            0|  0.00%|    individually to the result causing rounding errors in every step.
  2244|         0|            0|            0|  0.00%|    However, often numpy will use a  numerically better approach (partial
  2245|         0|            0|            0|  0.00%|    pairwise summation) leading to improved precision in many use-cases.
  2246|         0|            0|            0|  0.00%|    This improved precision is always provided when no ``axis`` is given.
  2247|         0|            0|            0|  0.00%|    When ``axis`` is given, it will depend on which axis is summed.
  2248|         0|            0|            0|  0.00%|    Technically, to provide the best speed possible, the improved precision
  2249|         0|            0|            0|  0.00%|    is only used when the summation is along the fast axis in memory.
  2250|         0|            0|            0|  0.00%|    Note that the exact precision may vary depending on other parameters.
  2251|         0|            0|            0|  0.00%|    In contrast to NumPy, Python's ``math.fsum`` function uses a slower but
  2252|         0|            0|            0|  0.00%|    more precise approach to summation.
  2253|         0|            0|            0|  0.00%|    Especially when summing a large number of lower precision floating point
  2254|         0|            0|            0|  0.00%|    numbers, such as ``float32``, numerical errors can become significant.
  2255|         0|            0|            0|  0.00%|    In such cases it can be advisable to use `dtype="float64"` to use a higher
  2256|         0|            0|            0|  0.00%|    precision for the output.
  2257|         0|            0|            0|  0.00%|
  2258|         0|            0|            0|  0.00%|    Examples
  2259|         0|            0|            0|  0.00%|    --------
  2260|         0|            0|            0|  0.00%|    >>> np.sum([0.5, 1.5])
  2261|         0|            0|            0|  0.00%|    2.0
  2262|         0|            0|            0|  0.00%|    >>> np.sum([0.5, 0.7, 0.2, 1.5], dtype=np.int32)
  2263|         0|            0|            0|  0.00%|    1
  2264|         0|            0|            0|  0.00%|    >>> np.sum([[0, 1], [0, 5]])
  2265|         0|            0|            0|  0.00%|    6
  2266|         0|            0|            0|  0.00%|    >>> np.sum([[0, 1], [0, 5]], axis=0)
  2267|         0|            0|            0|  0.00%|    array([0, 6])
  2268|         0|            0|            0|  0.00%|    >>> np.sum([[0, 1], [0, 5]], axis=1)
  2269|         0|            0|            0|  0.00%|    array([1, 5])
  2270|         0|            0|            0|  0.00%|    >>> np.sum([[0, 1], [np.nan, 5]], where=[False, True], axis=1)
  2271|         0|            0|            0|  0.00%|    array([1., 5.])
  2272|         0|            0|            0|  0.00%|
  2273|         0|            0|            0|  0.00%|    If the accumulator is too small, overflow occurs:
  2274|         0|            0|            0|  0.00%|
  2275|         0|            0|            0|  0.00%|    >>> np.ones(128, dtype=np.int8).sum(dtype=np.int8)
  2276|         0|            0|            0|  0.00%|    -128
  2277|         0|            0|            0|  0.00%|
  2278|         0|            0|            0|  0.00%|    You can also start the sum with a value other than zero:
  2279|         0|            0|            0|  0.00%|
  2280|         0|            0|            0|  0.00%|    >>> np.sum([10], initial=5)
  2281|         0|            0|            0|  0.00%|    15
  2282|         0|            0|            0|  0.00%|    """
  2283|      7867|     0.024986|  3.17606e-06|  0.02%|    if isinstance(a, _gentype):
  2284|         0|            0|            0|  0.00%|        # 2018-02-25, 1.15.0
  2285|         0|            0|            0|  0.00%|        warnings.warn(
  2286|         0|            0|            0|  0.00%|            "Calling np.sum(generator) is deprecated, and in the future will give a different result. "
  2287|         0|            0|            0|  0.00%|            "Use np.sum(np.fromiter(generator)) or the python sum builtin instead.",
  2288|         0|            0|            0|  0.00%|            DeprecationWarning, stacklevel=3)
  2289|         0|            0|            0|  0.00%|
  2290|         0|            0|            0|  0.00%|        res = _sum_(a)
  2291|         0|            0|            0|  0.00%|        if out is not None:
  2292|         0|            0|            0|  0.00%|            out[...] = res
  2293|         0|            0|            0|  0.00%|            return out
  2294|         0|            0|            0|  0.00%|        return res
  2295|         0|            0|            0|  0.00%|
  2296|     15734|    0.0952706|  6.05508e-06|  0.09%|    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,
(call)|      7867|     0.299077|  3.80167e-05|  0.29%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:69 _wrapreduction
  2297|      7867|    0.0172372|  2.19107e-06|  0.02%|                          initial=initial, where=where)
  2298|         0|            0|            0|  0.00%|
  2299|         0|            0|            0|  0.00%|
  2300|         0|            0|            0|  0.00%|def _any_dispatcher(a, axis=None, out=None, keepdims=None, *,
  2301|         0|            0|            0|  0.00%|                    where=np._NoValue):
  2302|         0|            0|            0|  0.00%|    return (a, where, out)
  2303|         0|            0|            0|  0.00%|
  2304|         0|            0|            0|  0.00%|
  2305|         0|            0|            0|  0.00%|@array_function_dispatch(_any_dispatcher)
  2306|         0|            0|            0|  0.00%|def any(a, axis=None, out=None, keepdims=np._NoValue, *, where=np._NoValue):
  2307|         0|            0|            0|  0.00%|    """
  2308|         0|            0|            0|  0.00%|    Test whether any array element along a given axis evaluates to True.
  2309|         0|            0|            0|  0.00%|
  2310|         0|            0|            0|  0.00%|    Returns single boolean unless `axis` is not ``None``
  2311|         0|            0|            0|  0.00%|
  2312|         0|            0|            0|  0.00%|    Parameters
  2313|         0|            0|            0|  0.00%|    ----------
  2314|         0|            0|            0|  0.00%|    a : array_like
  2315|         0|            0|            0|  0.00%|        Input array or object that can be converted to an array.
  2316|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  2317|         0|            0|            0|  0.00%|        Axis or axes along which a logical OR reduction is performed.
  2318|         0|            0|            0|  0.00%|        The default (``axis=None``) is to perform a logical OR over all
  2319|         0|            0|            0|  0.00%|        the dimensions of the input array. `axis` may be negative, in
  2320|         0|            0|            0|  0.00%|        which case it counts from the last to the first axis.
  2321|         0|            0|            0|  0.00%|
  2322|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  2323|         0|            0|            0|  0.00%|
  2324|         0|            0|            0|  0.00%|        If this is a tuple of ints, a reduction is performed on multiple
  2325|         0|            0|            0|  0.00%|        axes, instead of a single axis or all the axes as before.
  2326|         0|            0|            0|  0.00%|    out : ndarray, optional
  2327|         0|            0|            0|  0.00%|        Alternate output array in which to place the result.  It must have
  2328|         0|            0|            0|  0.00%|        the same shape as the expected output and its type is preserved
  2329|         0|            0|            0|  0.00%|        (e.g., if it is of type float, then it will remain so, returning
  2330|         0|            0|            0|  0.00%|        1.0 for True and 0.0 for False, regardless of the type of `a`).
  2331|         0|            0|            0|  0.00%|        See :ref:`ufuncs-output-type` for more details.
  2332|         0|            0|            0|  0.00%|
  2333|         0|            0|            0|  0.00%|    keepdims : bool, optional
  2334|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  2335|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  2336|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  2337|         0|            0|            0|  0.00%|
  2338|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  2339|         0|            0|            0|  0.00%|        passed through to the `any` method of sub-classes of
  2340|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  2341|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  2342|         0|            0|            0|  0.00%|        exceptions will be raised.
  2343|         0|            0|            0|  0.00%|
  2344|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  2345|         0|            0|            0|  0.00%|        Elements to include in checking for any `True` values.
  2346|         0|            0|            0|  0.00%|        See `~numpy.ufunc.reduce` for details.
  2347|         0|            0|            0|  0.00%|
  2348|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
  2349|         0|            0|            0|  0.00%|
  2350|         0|            0|            0|  0.00%|    Returns
  2351|         0|            0|            0|  0.00%|    -------
  2352|         0|            0|            0|  0.00%|    any : bool or ndarray
  2353|         0|            0|            0|  0.00%|        A new boolean or `ndarray` is returned unless `out` is specified,
  2354|         0|            0|            0|  0.00%|        in which case a reference to `out` is returned.
  2355|         0|            0|            0|  0.00%|
  2356|         0|            0|            0|  0.00%|    See Also
  2357|         0|            0|            0|  0.00%|    --------
  2358|         0|            0|            0|  0.00%|    ndarray.any : equivalent method
  2359|         0|            0|            0|  0.00%|
  2360|         0|            0|            0|  0.00%|    all : Test whether all elements along a given axis evaluate to True.
  2361|         0|            0|            0|  0.00%|
  2362|         0|            0|            0|  0.00%|    Notes
  2363|         0|            0|            0|  0.00%|    -----
  2364|         0|            0|            0|  0.00%|    Not a Number (NaN), positive infinity and negative infinity evaluate
  2365|         0|            0|            0|  0.00%|    to `True` because these are not equal to zero.
  2366|         0|            0|            0|  0.00%|
  2367|         0|            0|            0|  0.00%|    Examples
  2368|         0|            0|            0|  0.00%|    --------
  2369|         0|            0|            0|  0.00%|    >>> np.any([[True, False], [True, True]])
  2370|         0|            0|            0|  0.00%|    True
  2371|         0|            0|            0|  0.00%|
  2372|         0|            0|            0|  0.00%|    >>> np.any([[True, False], [False, False]], axis=0)
  2373|         0|            0|            0|  0.00%|    array([ True, False])
  2374|         0|            0|            0|  0.00%|
  2375|         0|            0|            0|  0.00%|    >>> np.any([-1, 0, 5])
  2376|         0|            0|            0|  0.00%|    True
  2377|         0|            0|            0|  0.00%|
  2378|         0|            0|            0|  0.00%|    >>> np.any(np.nan)
  2379|         0|            0|            0|  0.00%|    True
  2380|         0|            0|            0|  0.00%|
  2381|         0|            0|            0|  0.00%|    >>> np.any([[True, False], [False, False]], where=[[False], [True]])
  2382|         0|            0|            0|  0.00%|    False
  2383|         0|            0|            0|  0.00%|
  2384|         0|            0|            0|  0.00%|    >>> o=np.array(False)
  2385|         0|            0|            0|  0.00%|    >>> z=np.any([-1, 4, 5], out=o)
  2386|         0|            0|            0|  0.00%|    >>> z, o
  2387|         0|            0|            0|  0.00%|    (array(True), array(True))
  2388|         0|            0|            0|  0.00%|    >>> # Check now that z is a reference to o
  2389|         0|            0|            0|  0.00%|    >>> z is o
  2390|         0|            0|            0|  0.00%|    True
  2391|         0|            0|            0|  0.00%|    >>> id(z), id(o) # identity of z and o              # doctest: +SKIP
  2392|         0|            0|            0|  0.00%|    (191614240, 191614240)
  2393|         0|            0|            0|  0.00%|
  2394|         0|            0|            0|  0.00%|    """
  2395|         0|            0|            0|  0.00%|    return _wrapreduction(a, np.logical_or, 'any', axis, None, out,
  2396|         0|            0|            0|  0.00%|                          keepdims=keepdims, where=where)
  2397|         0|            0|            0|  0.00%|
  2398|         0|            0|            0|  0.00%|
  2399|         0|            0|            0|  0.00%|def _all_dispatcher(a, axis=None, out=None, keepdims=None, *,
  2400|         0|            0|            0|  0.00%|                    where=None):
  2401|         0|            0|            0|  0.00%|    return (a, where, out)
  2402|         0|            0|            0|  0.00%|
  2403|         0|            0|            0|  0.00%|
  2404|         0|            0|            0|  0.00%|@array_function_dispatch(_all_dispatcher)
  2405|         0|            0|            0|  0.00%|def all(a, axis=None, out=None, keepdims=np._NoValue, *, where=np._NoValue):
  2406|         0|            0|            0|  0.00%|    """
  2407|         0|            0|            0|  0.00%|    Test whether all array elements along a given axis evaluate to True.
  2408|         0|            0|            0|  0.00%|
  2409|         0|            0|            0|  0.00%|    Parameters
  2410|         0|            0|            0|  0.00%|    ----------
  2411|         0|            0|            0|  0.00%|    a : array_like
  2412|         0|            0|            0|  0.00%|        Input array or object that can be converted to an array.
  2413|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  2414|         0|            0|            0|  0.00%|        Axis or axes along which a logical AND reduction is performed.
  2415|         0|            0|            0|  0.00%|        The default (``axis=None``) is to perform a logical AND over all
  2416|         0|            0|            0|  0.00%|        the dimensions of the input array. `axis` may be negative, in
  2417|         0|            0|            0|  0.00%|        which case it counts from the last to the first axis.
  2418|         0|            0|            0|  0.00%|
  2419|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  2420|         0|            0|            0|  0.00%|
  2421|         0|            0|            0|  0.00%|        If this is a tuple of ints, a reduction is performed on multiple
  2422|         0|            0|            0|  0.00%|        axes, instead of a single axis or all the axes as before.
  2423|         0|            0|            0|  0.00%|    out : ndarray, optional
  2424|         0|            0|            0|  0.00%|        Alternate output array in which to place the result.
  2425|         0|            0|            0|  0.00%|        It must have the same shape as the expected output and its
  2426|         0|            0|            0|  0.00%|        type is preserved (e.g., if ``dtype(out)`` is float, the result
  2427|         0|            0|            0|  0.00%|        will consist of 0.0's and 1.0's). See :ref:`ufuncs-output-type` for more
  2428|         0|            0|            0|  0.00%|        details.
  2429|         0|            0|            0|  0.00%|
  2430|         0|            0|            0|  0.00%|    keepdims : bool, optional
  2431|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  2432|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  2433|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  2434|         0|            0|            0|  0.00%|
  2435|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  2436|         0|            0|            0|  0.00%|        passed through to the `all` method of sub-classes of
  2437|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  2438|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  2439|         0|            0|            0|  0.00%|        exceptions will be raised.
  2440|         0|            0|            0|  0.00%|
  2441|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  2442|         0|            0|            0|  0.00%|        Elements to include in checking for all `True` values.
  2443|         0|            0|            0|  0.00%|        See `~numpy.ufunc.reduce` for details.
  2444|         0|            0|            0|  0.00%|
  2445|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
  2446|         0|            0|            0|  0.00%|
  2447|         0|            0|            0|  0.00%|    Returns
  2448|         0|            0|            0|  0.00%|    -------
  2449|         0|            0|            0|  0.00%|    all : ndarray, bool
  2450|         0|            0|            0|  0.00%|        A new boolean or array is returned unless `out` is specified,
  2451|         0|            0|            0|  0.00%|        in which case a reference to `out` is returned.
  2452|         0|            0|            0|  0.00%|
  2453|         0|            0|            0|  0.00%|    See Also
  2454|         0|            0|            0|  0.00%|    --------
  2455|         0|            0|            0|  0.00%|    ndarray.all : equivalent method
  2456|         0|            0|            0|  0.00%|
  2457|         0|            0|            0|  0.00%|    any : Test whether any element along a given axis evaluates to True.
  2458|         0|            0|            0|  0.00%|
  2459|         0|            0|            0|  0.00%|    Notes
  2460|         0|            0|            0|  0.00%|    -----
  2461|         0|            0|            0|  0.00%|    Not a Number (NaN), positive infinity and negative infinity
  2462|         0|            0|            0|  0.00%|    evaluate to `True` because these are not equal to zero.
  2463|         0|            0|            0|  0.00%|
  2464|         0|            0|            0|  0.00%|    Examples
  2465|         0|            0|            0|  0.00%|    --------
  2466|         0|            0|            0|  0.00%|    >>> np.all([[True,False],[True,True]])
  2467|         0|            0|            0|  0.00%|    False
  2468|         0|            0|            0|  0.00%|
  2469|         0|            0|            0|  0.00%|    >>> np.all([[True,False],[True,True]], axis=0)
  2470|         0|            0|            0|  0.00%|    array([ True, False])
  2471|         0|            0|            0|  0.00%|
  2472|         0|            0|            0|  0.00%|    >>> np.all([-1, 4, 5])
  2473|         0|            0|            0|  0.00%|    True
  2474|         0|            0|            0|  0.00%|
  2475|         0|            0|            0|  0.00%|    >>> np.all([1.0, np.nan])
  2476|         0|            0|            0|  0.00%|    True
  2477|         0|            0|            0|  0.00%|
  2478|         0|            0|            0|  0.00%|    >>> np.all([[True, True], [False, True]], where=[[True], [False]])
  2479|         0|            0|            0|  0.00%|    True
  2480|         0|            0|            0|  0.00%|
  2481|         0|            0|            0|  0.00%|    >>> o=np.array(False)
  2482|         0|            0|            0|  0.00%|    >>> z=np.all([-1, 4, 5], out=o)
  2483|         0|            0|            0|  0.00%|    >>> id(z), id(o), z
  2484|         0|            0|            0|  0.00%|    (28293632, 28293632, array(True)) # may vary
  2485|         0|            0|            0|  0.00%|
  2486|         0|            0|            0|  0.00%|    """
  2487|         0|            0|            0|  0.00%|    return _wrapreduction(a, np.logical_and, 'all', axis, None, out,
  2488|         0|            0|            0|  0.00%|                          keepdims=keepdims, where=where)
  2489|         0|            0|            0|  0.00%|
  2490|         0|            0|            0|  0.00%|
  2491|      5892|   0.00974679|  1.65424e-06|  0.01%|def _cumsum_dispatcher(a, axis=None, dtype=None, out=None):
  2492|      5892|    0.0124347|  2.11044e-06|  0.01%|    return (a, out)
  2493|         0|            0|            0|  0.00%|
  2494|         0|            0|            0|  0.00%|
  2495|      5892|     0.010149|  1.72251e-06|  0.01%|@array_function_dispatch(_cumsum_dispatcher)
  2496|         0|            0|            0|  0.00%|def cumsum(a, axis=None, dtype=None, out=None):
  2497|         0|            0|            0|  0.00%|    """
  2498|         0|            0|            0|  0.00%|    Return the cumulative sum of the elements along a given axis.
  2499|         0|            0|            0|  0.00%|
  2500|         0|            0|            0|  0.00%|    Parameters
  2501|         0|            0|            0|  0.00%|    ----------
  2502|         0|            0|            0|  0.00%|    a : array_like
  2503|         0|            0|            0|  0.00%|        Input array.
  2504|         0|            0|            0|  0.00%|    axis : int, optional
  2505|         0|            0|            0|  0.00%|        Axis along which the cumulative sum is computed. The default
  2506|         0|            0|            0|  0.00%|        (None) is to compute the cumsum over the flattened array.
  2507|         0|            0|            0|  0.00%|    dtype : dtype, optional
  2508|         0|            0|            0|  0.00%|        Type of the returned array and of the accumulator in which the
  2509|         0|            0|            0|  0.00%|        elements are summed.  If `dtype` is not specified, it defaults
  2510|         0|            0|            0|  0.00%|        to the dtype of `a`, unless `a` has an integer dtype with a
  2511|         0|            0|            0|  0.00%|        precision less than that of the default platform integer.  In
  2512|         0|            0|            0|  0.00%|        that case, the default platform integer is used.
  2513|         0|            0|            0|  0.00%|    out : ndarray, optional
  2514|         0|            0|            0|  0.00%|        Alternative output array in which to place the result. It must
  2515|         0|            0|            0|  0.00%|        have the same shape and buffer length as the expected output
  2516|         0|            0|            0|  0.00%|        but the type will be cast if necessary. See :ref:`ufuncs-output-type` for
  2517|         0|            0|            0|  0.00%|        more details.
  2518|         0|            0|            0|  0.00%|
  2519|         0|            0|            0|  0.00%|    Returns
  2520|         0|            0|            0|  0.00%|    -------
  2521|         0|            0|            0|  0.00%|    cumsum_along_axis : ndarray.
  2522|         0|            0|            0|  0.00%|        A new array holding the result is returned unless `out` is
  2523|         0|            0|            0|  0.00%|        specified, in which case a reference to `out` is returned. The
  2524|         0|            0|            0|  0.00%|        result has the same size as `a`, and the same shape as `a` if
  2525|         0|            0|            0|  0.00%|        `axis` is not None or `a` is a 1-d array.
  2526|         0|            0|            0|  0.00%|
  2527|         0|            0|            0|  0.00%|    See Also
  2528|         0|            0|            0|  0.00%|    --------
  2529|         0|            0|            0|  0.00%|    sum : Sum array elements.
  2530|         0|            0|            0|  0.00%|    trapz : Integration of array values using the composite trapezoidal rule.
  2531|         0|            0|            0|  0.00%|    diff : Calculate the n-th discrete difference along given axis.
  2532|         0|            0|            0|  0.00%|
  2533|         0|            0|            0|  0.00%|    Notes
  2534|         0|            0|            0|  0.00%|    -----
  2535|         0|            0|            0|  0.00%|    Arithmetic is modular when using integer types, and no error is
  2536|         0|            0|            0|  0.00%|    raised on overflow.
  2537|         0|            0|            0|  0.00%|
  2538|         0|            0|            0|  0.00%|    ``cumsum(a)[-1]`` may not be equal to ``sum(a)`` for floating-point
  2539|         0|            0|            0|  0.00%|    values since ``sum`` may use a pairwise summation routine, reducing
  2540|         0|            0|            0|  0.00%|    the roundoff-error. See `sum` for more information.
  2541|         0|            0|            0|  0.00%|
  2542|         0|            0|            0|  0.00%|    Examples
  2543|         0|            0|            0|  0.00%|    --------
  2544|         0|            0|            0|  0.00%|    >>> a = np.array([[1,2,3], [4,5,6]])
  2545|         0|            0|            0|  0.00%|    >>> a
  2546|         0|            0|            0|  0.00%|    array([[1, 2, 3],
  2547|         0|            0|            0|  0.00%|           [4, 5, 6]])
  2548|         0|            0|            0|  0.00%|    >>> np.cumsum(a)
  2549|         0|            0|            0|  0.00%|    array([ 1,  3,  6, 10, 15, 21])
  2550|         0|            0|            0|  0.00%|    >>> np.cumsum(a, dtype=float)     # specifies type of output value(s)
  2551|         0|            0|            0|  0.00%|    array([  1.,   3.,   6.,  10.,  15.,  21.])
  2552|         0|            0|            0|  0.00%|
  2553|         0|            0|            0|  0.00%|    >>> np.cumsum(a,axis=0)      # sum over rows for each of the 3 columns
  2554|         0|            0|            0|  0.00%|    array([[1, 2, 3],
  2555|         0|            0|            0|  0.00%|           [5, 7, 9]])
  2556|         0|            0|            0|  0.00%|    >>> np.cumsum(a,axis=1)      # sum over columns for each of the 2 rows
  2557|         0|            0|            0|  0.00%|    array([[ 1,  3,  6],
  2558|         0|            0|            0|  0.00%|           [ 4,  9, 15]])
  2559|         0|            0|            0|  0.00%|
  2560|         0|            0|            0|  0.00%|    ``cumsum(b)[-1]`` may not be equal to ``sum(b)``
  2561|         0|            0|            0|  0.00%|
  2562|         0|            0|            0|  0.00%|    >>> b = np.array([1, 2e-9, 3e-9] * 1000000)
  2563|         0|            0|            0|  0.00%|    >>> b.cumsum()[-1]
  2564|         0|            0|            0|  0.00%|    1000000.0050045159
  2565|         0|            0|            0|  0.00%|    >>> b.sum()
  2566|         0|            0|            0|  0.00%|    1000000.0050000029
  2567|         0|            0|            0|  0.00%|
  2568|         0|            0|            0|  0.00%|    """
  2569|      5892|    0.0415444|  7.05099e-06|  0.04%|    return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out)
(call)|      5892|     0.245067|  4.15932e-05|  0.23%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:51 _wrapfunc
  2570|         0|            0|            0|  0.00%|
  2571|         0|            0|            0|  0.00%|
  2572|         0|            0|            0|  0.00%|def _ptp_dispatcher(a, axis=None, out=None, keepdims=None):
  2573|         0|            0|            0|  0.00%|    return (a, out)
  2574|         0|            0|            0|  0.00%|
  2575|         0|            0|            0|  0.00%|
  2576|         0|            0|            0|  0.00%|@array_function_dispatch(_ptp_dispatcher)
  2577|         0|            0|            0|  0.00%|def ptp(a, axis=None, out=None, keepdims=np._NoValue):
  2578|         0|            0|            0|  0.00%|    """
  2579|         0|            0|            0|  0.00%|    Range of values (maximum - minimum) along an axis.
  2580|         0|            0|            0|  0.00%|
  2581|         0|            0|            0|  0.00%|    The name of the function comes from the acronym for 'peak to peak'.
  2582|         0|            0|            0|  0.00%|
  2583|         0|            0|            0|  0.00%|    .. warning::
  2584|         0|            0|            0|  0.00%|        `ptp` preserves the data type of the array. This means the
  2585|         0|            0|            0|  0.00%|        return value for an input of signed integers with n bits
  2586|         0|            0|            0|  0.00%|        (e.g. `np.int8`, `np.int16`, etc) is also a signed integer
  2587|         0|            0|            0|  0.00%|        with n bits.  In that case, peak-to-peak values greater than
  2588|         0|            0|            0|  0.00%|        ``2**(n-1)-1`` will be returned as negative values. An example
  2589|         0|            0|            0|  0.00%|        with a work-around is shown below.
  2590|         0|            0|            0|  0.00%|
  2591|         0|            0|            0|  0.00%|    Parameters
  2592|         0|            0|            0|  0.00%|    ----------
  2593|         0|            0|            0|  0.00%|    a : array_like
  2594|         0|            0|            0|  0.00%|        Input values.
  2595|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  2596|         0|            0|            0|  0.00%|        Axis along which to find the peaks.  By default, flatten the
  2597|         0|            0|            0|  0.00%|        array.  `axis` may be negative, in
  2598|         0|            0|            0|  0.00%|        which case it counts from the last to the first axis.
  2599|         0|            0|            0|  0.00%|
  2600|         0|            0|            0|  0.00%|        .. versionadded:: 1.15.0
  2601|         0|            0|            0|  0.00%|
  2602|         0|            0|            0|  0.00%|        If this is a tuple of ints, a reduction is performed on multiple
  2603|         0|            0|            0|  0.00%|        axes, instead of a single axis or all the axes as before.
  2604|         0|            0|            0|  0.00%|    out : array_like
  2605|         0|            0|            0|  0.00%|        Alternative output array in which to place the result. It must
  2606|         0|            0|            0|  0.00%|        have the same shape and buffer length as the expected output,
  2607|         0|            0|            0|  0.00%|        but the type of the output values will be cast if necessary.
  2608|         0|            0|            0|  0.00%|
  2609|         0|            0|            0|  0.00%|    keepdims : bool, optional
  2610|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  2611|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  2612|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  2613|         0|            0|            0|  0.00%|
  2614|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  2615|         0|            0|            0|  0.00%|        passed through to the `ptp` method of sub-classes of
  2616|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  2617|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  2618|         0|            0|            0|  0.00%|        exceptions will be raised.
  2619|         0|            0|            0|  0.00%|
  2620|         0|            0|            0|  0.00%|    Returns
  2621|         0|            0|            0|  0.00%|    -------
  2622|         0|            0|            0|  0.00%|    ptp : ndarray
  2623|         0|            0|            0|  0.00%|        A new array holding the result, unless `out` was
  2624|         0|            0|            0|  0.00%|        specified, in which case a reference to `out` is returned.
  2625|         0|            0|            0|  0.00%|
  2626|         0|            0|            0|  0.00%|    Examples
  2627|         0|            0|            0|  0.00%|    --------
  2628|         0|            0|            0|  0.00%|    >>> x = np.array([[4, 9, 2, 10],
  2629|         0|            0|            0|  0.00%|    ...               [6, 9, 7, 12]])
  2630|         0|            0|            0|  0.00%|
  2631|         0|            0|            0|  0.00%|    >>> np.ptp(x, axis=1)
  2632|         0|            0|            0|  0.00%|    array([8, 6])
  2633|         0|            0|            0|  0.00%|
  2634|         0|            0|            0|  0.00%|    >>> np.ptp(x, axis=0)
  2635|         0|            0|            0|  0.00%|    array([2, 0, 5, 2])
  2636|         0|            0|            0|  0.00%|
  2637|         0|            0|            0|  0.00%|    >>> np.ptp(x)
  2638|         0|            0|            0|  0.00%|    10
  2639|         0|            0|            0|  0.00%|
  2640|         0|            0|            0|  0.00%|    This example shows that a negative value can be returned when
  2641|         0|            0|            0|  0.00%|    the input is an array of signed integers.
  2642|         0|            0|            0|  0.00%|
  2643|         0|            0|            0|  0.00%|    >>> y = np.array([[1, 127],
  2644|         0|            0|            0|  0.00%|    ...               [0, 127],
  2645|         0|            0|            0|  0.00%|    ...               [-1, 127],
  2646|         0|            0|            0|  0.00%|    ...               [-2, 127]], dtype=np.int8)
  2647|         0|            0|            0|  0.00%|    >>> np.ptp(y, axis=1)
  2648|         0|            0|            0|  0.00%|    array([ 126,  127, -128, -127], dtype=int8)
  2649|         0|            0|            0|  0.00%|
  2650|         0|            0|            0|  0.00%|    A work-around is to use the `view()` method to view the result as
  2651|         0|            0|            0|  0.00%|    unsigned integers with the same bit width:
  2652|         0|            0|            0|  0.00%|
  2653|         0|            0|            0|  0.00%|    >>> np.ptp(y, axis=1).view(np.uint8)
  2654|         0|            0|            0|  0.00%|    array([126, 127, 128, 129], dtype=uint8)
  2655|         0|            0|            0|  0.00%|
  2656|         0|            0|            0|  0.00%|    """
  2657|         0|            0|            0|  0.00%|    kwargs = {}
  2658|         0|            0|            0|  0.00%|    if keepdims is not np._NoValue:
  2659|         0|            0|            0|  0.00%|        kwargs['keepdims'] = keepdims
  2660|         0|            0|            0|  0.00%|    if type(a) is not mu.ndarray:
  2661|         0|            0|            0|  0.00%|        try:
  2662|         0|            0|            0|  0.00%|            ptp = a.ptp
  2663|         0|            0|            0|  0.00%|        except AttributeError:
  2664|         0|            0|            0|  0.00%|            pass
  2665|         0|            0|            0|  0.00%|        else:
  2666|         0|            0|            0|  0.00%|            return ptp(axis=axis, out=out, **kwargs)
  2667|         0|            0|            0|  0.00%|    return _methods._ptp(a, axis=axis, out=out, **kwargs)
  2668|         0|            0|            0|  0.00%|
  2669|         0|            0|            0|  0.00%|
  2670|         0|            0|            0|  0.00%|def _amax_dispatcher(a, axis=None, out=None, keepdims=None, initial=None,
  2671|         0|            0|            0|  0.00%|                     where=None):
  2672|         0|            0|            0|  0.00%|    return (a, out)
  2673|         0|            0|            0|  0.00%|
  2674|         0|            0|            0|  0.00%|
  2675|         0|            0|            0|  0.00%|@array_function_dispatch(_amax_dispatcher)
  2676|         0|            0|            0|  0.00%|def amax(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,
  2677|         0|            0|            0|  0.00%|         where=np._NoValue):
  2678|         0|            0|            0|  0.00%|    """
  2679|         0|            0|            0|  0.00%|    Return the maximum of an array or maximum along an axis.
  2680|         0|            0|            0|  0.00%|
  2681|         0|            0|            0|  0.00%|    Parameters
  2682|         0|            0|            0|  0.00%|    ----------
  2683|         0|            0|            0|  0.00%|    a : array_like
  2684|         0|            0|            0|  0.00%|        Input data.
  2685|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  2686|         0|            0|            0|  0.00%|        Axis or axes along which to operate.  By default, flattened input is
  2687|         0|            0|            0|  0.00%|        used.
  2688|         0|            0|            0|  0.00%|
  2689|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  2690|         0|            0|            0|  0.00%|
  2691|         0|            0|            0|  0.00%|        If this is a tuple of ints, the maximum is selected over multiple axes,
  2692|         0|            0|            0|  0.00%|        instead of a single axis or all the axes as before.
  2693|         0|            0|            0|  0.00%|    out : ndarray, optional
  2694|         0|            0|            0|  0.00%|        Alternative output array in which to place the result.  Must
  2695|         0|            0|            0|  0.00%|        be of the same shape and buffer length as the expected output.
  2696|         0|            0|            0|  0.00%|        See :ref:`ufuncs-output-type` for more details.
  2697|         0|            0|            0|  0.00%|
  2698|         0|            0|            0|  0.00%|    keepdims : bool, optional
  2699|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  2700|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  2701|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  2702|         0|            0|            0|  0.00%|
  2703|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  2704|         0|            0|            0|  0.00%|        passed through to the `amax` method of sub-classes of
  2705|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  2706|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  2707|         0|            0|            0|  0.00%|        exceptions will be raised.
  2708|         0|            0|            0|  0.00%|
  2709|         0|            0|            0|  0.00%|    initial : scalar, optional
  2710|         0|            0|            0|  0.00%|        The minimum value of an output element. Must be present to allow
  2711|         0|            0|            0|  0.00%|        computation on empty slice. See `~numpy.ufunc.reduce` for details.
  2712|         0|            0|            0|  0.00%|
  2713|         0|            0|            0|  0.00%|        .. versionadded:: 1.15.0
  2714|         0|            0|            0|  0.00%|
  2715|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  2716|         0|            0|            0|  0.00%|        Elements to compare for the maximum. See `~numpy.ufunc.reduce`
  2717|         0|            0|            0|  0.00%|        for details.
  2718|         0|            0|            0|  0.00%|
  2719|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
  2720|         0|            0|            0|  0.00%|
  2721|         0|            0|            0|  0.00%|    Returns
  2722|         0|            0|            0|  0.00%|    -------
  2723|         0|            0|            0|  0.00%|    amax : ndarray or scalar
  2724|         0|            0|            0|  0.00%|        Maximum of `a`. If `axis` is None, the result is a scalar value.
  2725|         0|            0|            0|  0.00%|        If `axis` is given, the result is an array of dimension
  2726|         0|            0|            0|  0.00%|        ``a.ndim - 1``.
  2727|         0|            0|            0|  0.00%|
  2728|         0|            0|            0|  0.00%|    See Also
  2729|         0|            0|            0|  0.00%|    --------
  2730|         0|            0|            0|  0.00%|    amin :
  2731|         0|            0|            0|  0.00%|        The minimum value of an array along a given axis, propagating any NaNs.
  2732|         0|            0|            0|  0.00%|    nanmax :
  2733|         0|            0|            0|  0.00%|        The maximum value of an array along a given axis, ignoring any NaNs.
  2734|         0|            0|            0|  0.00%|    maximum :
  2735|         0|            0|            0|  0.00%|        Element-wise maximum of two arrays, propagating any NaNs.
  2736|         0|            0|            0|  0.00%|    fmax :
  2737|         0|            0|            0|  0.00%|        Element-wise maximum of two arrays, ignoring any NaNs.
  2738|         0|            0|            0|  0.00%|    argmax :
  2739|         0|            0|            0|  0.00%|        Return the indices of the maximum values.
  2740|         0|            0|            0|  0.00%|
  2741|         0|            0|            0|  0.00%|    nanmin, minimum, fmin
  2742|         0|            0|            0|  0.00%|
  2743|         0|            0|            0|  0.00%|    Notes
  2744|         0|            0|            0|  0.00%|    -----
  2745|         0|            0|            0|  0.00%|    NaN values are propagated, that is if at least one item is NaN, the
  2746|         0|            0|            0|  0.00%|    corresponding max value will be NaN as well. To ignore NaN values
  2747|         0|            0|            0|  0.00%|    (MATLAB behavior), please use nanmax.
  2748|         0|            0|            0|  0.00%|
  2749|         0|            0|            0|  0.00%|    Don't use `amax` for element-wise comparison of 2 arrays; when
  2750|         0|            0|            0|  0.00%|    ``a.shape[0]`` is 2, ``maximum(a[0], a[1])`` is faster than
  2751|         0|            0|            0|  0.00%|    ``amax(a, axis=0)``.
  2752|         0|            0|            0|  0.00%|
  2753|         0|            0|            0|  0.00%|    Examples
  2754|         0|            0|            0|  0.00%|    --------
  2755|         0|            0|            0|  0.00%|    >>> a = np.arange(4).reshape((2,2))
  2756|         0|            0|            0|  0.00%|    >>> a
  2757|         0|            0|            0|  0.00%|    array([[0, 1],
  2758|         0|            0|            0|  0.00%|           [2, 3]])
  2759|         0|            0|            0|  0.00%|    >>> np.amax(a)           # Maximum of the flattened array
  2760|         0|            0|            0|  0.00%|    3
  2761|         0|            0|            0|  0.00%|    >>> np.amax(a, axis=0)   # Maxima along the first axis
  2762|         0|            0|            0|  0.00%|    array([2, 3])
  2763|         0|            0|            0|  0.00%|    >>> np.amax(a, axis=1)   # Maxima along the second axis
  2764|         0|            0|            0|  0.00%|    array([1, 3])
  2765|         0|            0|            0|  0.00%|    >>> np.amax(a, where=[False, True], initial=-1, axis=0)
  2766|         0|            0|            0|  0.00%|    array([-1,  3])
  2767|         0|            0|            0|  0.00%|    >>> b = np.arange(5, dtype=float)
  2768|         0|            0|            0|  0.00%|    >>> b[2] = np.NaN
  2769|         0|            0|            0|  0.00%|    >>> np.amax(b)
  2770|         0|            0|            0|  0.00%|    nan
  2771|         0|            0|            0|  0.00%|    >>> np.amax(b, where=~np.isnan(b), initial=-1)
  2772|         0|            0|            0|  0.00%|    4.0
  2773|         0|            0|            0|  0.00%|    >>> np.nanmax(b)
  2774|         0|            0|            0|  0.00%|    4.0
  2775|         0|            0|            0|  0.00%|
  2776|         0|            0|            0|  0.00%|    You can use an initial value to compute the maximum of an empty slice, or
  2777|         0|            0|            0|  0.00%|    to initialize it to a different value:
  2778|         0|            0|            0|  0.00%|
  2779|         0|            0|            0|  0.00%|    >>> np.amax([[-50], [10]], axis=-1, initial=0)
  2780|         0|            0|            0|  0.00%|    array([ 0, 10])
  2781|         0|            0|            0|  0.00%|
  2782|         0|            0|            0|  0.00%|    Notice that the initial value is used as one of the elements for which the
  2783|         0|            0|            0|  0.00%|    maximum is determined, unlike for the default argument Python's max
  2784|         0|            0|            0|  0.00%|    function, which is only used for empty iterables.
  2785|         0|            0|            0|  0.00%|
  2786|         0|            0|            0|  0.00%|    >>> np.amax([5], initial=6)
  2787|         0|            0|            0|  0.00%|    6
  2788|         0|            0|            0|  0.00%|    >>> max([5], default=6)
  2789|         0|            0|            0|  0.00%|    5
  2790|         0|            0|            0|  0.00%|    """
  2791|         0|            0|            0|  0.00%|    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  2792|         0|            0|            0|  0.00%|                          keepdims=keepdims, initial=initial, where=where)
  2793|         0|            0|            0|  0.00%|
  2794|         0|            0|            0|  0.00%|
  2795|         0|            0|            0|  0.00%|def _amin_dispatcher(a, axis=None, out=None, keepdims=None, initial=None,
  2796|         0|            0|            0|  0.00%|                     where=None):
  2797|         0|            0|            0|  0.00%|    return (a, out)
  2798|         0|            0|            0|  0.00%|
  2799|         0|            0|            0|  0.00%|
  2800|         0|            0|            0|  0.00%|@array_function_dispatch(_amin_dispatcher)
  2801|         0|            0|            0|  0.00%|def amin(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,
  2802|         0|            0|            0|  0.00%|         where=np._NoValue):
  2803|         0|            0|            0|  0.00%|    """
  2804|         0|            0|            0|  0.00%|    Return the minimum of an array or minimum along an axis.
  2805|         0|            0|            0|  0.00%|
  2806|         0|            0|            0|  0.00%|    Parameters
  2807|         0|            0|            0|  0.00%|    ----------
  2808|         0|            0|            0|  0.00%|    a : array_like
  2809|         0|            0|            0|  0.00%|        Input data.
  2810|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  2811|         0|            0|            0|  0.00%|        Axis or axes along which to operate.  By default, flattened input is
  2812|         0|            0|            0|  0.00%|        used.
  2813|         0|            0|            0|  0.00%|
  2814|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  2815|         0|            0|            0|  0.00%|
  2816|         0|            0|            0|  0.00%|        If this is a tuple of ints, the minimum is selected over multiple axes,
  2817|         0|            0|            0|  0.00%|        instead of a single axis or all the axes as before.
  2818|         0|            0|            0|  0.00%|    out : ndarray, optional
  2819|         0|            0|            0|  0.00%|        Alternative output array in which to place the result.  Must
  2820|         0|            0|            0|  0.00%|        be of the same shape and buffer length as the expected output.
  2821|         0|            0|            0|  0.00%|        See :ref:`ufuncs-output-type` for more details.
  2822|         0|            0|            0|  0.00%|
  2823|         0|            0|            0|  0.00%|    keepdims : bool, optional
  2824|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  2825|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  2826|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  2827|         0|            0|            0|  0.00%|
  2828|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  2829|         0|            0|            0|  0.00%|        passed through to the `amin` method of sub-classes of
  2830|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  2831|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  2832|         0|            0|            0|  0.00%|        exceptions will be raised.
  2833|         0|            0|            0|  0.00%|
  2834|         0|            0|            0|  0.00%|    initial : scalar, optional
  2835|         0|            0|            0|  0.00%|        The maximum value of an output element. Must be present to allow
  2836|         0|            0|            0|  0.00%|        computation on empty slice. See `~numpy.ufunc.reduce` for details.
  2837|         0|            0|            0|  0.00%|
  2838|         0|            0|            0|  0.00%|        .. versionadded:: 1.15.0
  2839|         0|            0|            0|  0.00%|
  2840|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  2841|         0|            0|            0|  0.00%|        Elements to compare for the minimum. See `~numpy.ufunc.reduce`
  2842|         0|            0|            0|  0.00%|        for details.
  2843|         0|            0|            0|  0.00%|
  2844|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
  2845|         0|            0|            0|  0.00%|
  2846|         0|            0|            0|  0.00%|    Returns
  2847|         0|            0|            0|  0.00%|    -------
  2848|         0|            0|            0|  0.00%|    amin : ndarray or scalar
  2849|         0|            0|            0|  0.00%|        Minimum of `a`. If `axis` is None, the result is a scalar value.
  2850|         0|            0|            0|  0.00%|        If `axis` is given, the result is an array of dimension
  2851|         0|            0|            0|  0.00%|        ``a.ndim - 1``.
  2852|         0|            0|            0|  0.00%|
  2853|         0|            0|            0|  0.00%|    See Also
  2854|         0|            0|            0|  0.00%|    --------
  2855|         0|            0|            0|  0.00%|    amax :
  2856|         0|            0|            0|  0.00%|        The maximum value of an array along a given axis, propagating any NaNs.
  2857|         0|            0|            0|  0.00%|    nanmin :
  2858|         0|            0|            0|  0.00%|        The minimum value of an array along a given axis, ignoring any NaNs.
  2859|         0|            0|            0|  0.00%|    minimum :
  2860|         0|            0|            0|  0.00%|        Element-wise minimum of two arrays, propagating any NaNs.
  2861|         0|            0|            0|  0.00%|    fmin :
  2862|         0|            0|            0|  0.00%|        Element-wise minimum of two arrays, ignoring any NaNs.
  2863|         0|            0|            0|  0.00%|    argmin :
  2864|         0|            0|            0|  0.00%|        Return the indices of the minimum values.
  2865|         0|            0|            0|  0.00%|
  2866|         0|            0|            0|  0.00%|    nanmax, maximum, fmax
  2867|         0|            0|            0|  0.00%|
  2868|         0|            0|            0|  0.00%|    Notes
  2869|         0|            0|            0|  0.00%|    -----
  2870|         0|            0|            0|  0.00%|    NaN values are propagated, that is if at least one item is NaN, the
  2871|         0|            0|            0|  0.00%|    corresponding min value will be NaN as well. To ignore NaN values
  2872|         0|            0|            0|  0.00%|    (MATLAB behavior), please use nanmin.
  2873|         0|            0|            0|  0.00%|
  2874|         0|            0|            0|  0.00%|    Don't use `amin` for element-wise comparison of 2 arrays; when
  2875|         0|            0|            0|  0.00%|    ``a.shape[0]`` is 2, ``minimum(a[0], a[1])`` is faster than
  2876|         0|            0|            0|  0.00%|    ``amin(a, axis=0)``.
  2877|         0|            0|            0|  0.00%|
  2878|         0|            0|            0|  0.00%|    Examples
  2879|         0|            0|            0|  0.00%|    --------
  2880|         0|            0|            0|  0.00%|    >>> a = np.arange(4).reshape((2,2))
  2881|         0|            0|            0|  0.00%|    >>> a
  2882|         0|            0|            0|  0.00%|    array([[0, 1],
  2883|         0|            0|            0|  0.00%|           [2, 3]])
  2884|         0|            0|            0|  0.00%|    >>> np.amin(a)           # Minimum of the flattened array
  2885|         0|            0|            0|  0.00%|    0
  2886|         0|            0|            0|  0.00%|    >>> np.amin(a, axis=0)   # Minima along the first axis
  2887|         0|            0|            0|  0.00%|    array([0, 1])
  2888|         0|            0|            0|  0.00%|    >>> np.amin(a, axis=1)   # Minima along the second axis
  2889|         0|            0|            0|  0.00%|    array([0, 2])
  2890|         0|            0|            0|  0.00%|    >>> np.amin(a, where=[False, True], initial=10, axis=0)
  2891|         0|            0|            0|  0.00%|    array([10,  1])
  2892|         0|            0|            0|  0.00%|
  2893|         0|            0|            0|  0.00%|    >>> b = np.arange(5, dtype=float)
  2894|         0|            0|            0|  0.00%|    >>> b[2] = np.NaN
  2895|         0|            0|            0|  0.00%|    >>> np.amin(b)
  2896|         0|            0|            0|  0.00%|    nan
  2897|         0|            0|            0|  0.00%|    >>> np.amin(b, where=~np.isnan(b), initial=10)
  2898|         0|            0|            0|  0.00%|    0.0
  2899|         0|            0|            0|  0.00%|    >>> np.nanmin(b)
  2900|         0|            0|            0|  0.00%|    0.0
  2901|         0|            0|            0|  0.00%|
  2902|         0|            0|            0|  0.00%|    >>> np.amin([[-50], [10]], axis=-1, initial=0)
  2903|         0|            0|            0|  0.00%|    array([-50,   0])
  2904|         0|            0|            0|  0.00%|
  2905|         0|            0|            0|  0.00%|    Notice that the initial value is used as one of the elements for which the
  2906|         0|            0|            0|  0.00%|    minimum is determined, unlike for the default argument Python's max
  2907|         0|            0|            0|  0.00%|    function, which is only used for empty iterables.
  2908|         0|            0|            0|  0.00%|
  2909|         0|            0|            0|  0.00%|    Notice that this isn't the same as Python's ``default`` argument.
  2910|         0|            0|            0|  0.00%|
  2911|         0|            0|            0|  0.00%|    >>> np.amin([6], initial=5)
  2912|         0|            0|            0|  0.00%|    5
  2913|         0|            0|            0|  0.00%|    >>> min([6], default=5)
  2914|         0|            0|            0|  0.00%|    6
  2915|         0|            0|            0|  0.00%|    """
  2916|         0|            0|            0|  0.00%|    return _wrapreduction(a, np.minimum, 'min', axis, None, out,
  2917|         0|            0|            0|  0.00%|                          keepdims=keepdims, initial=initial, where=where)
  2918|         0|            0|            0|  0.00%|
  2919|         0|            0|            0|  0.00%|
  2920|         0|            0|            0|  0.00%|def _alen_dispathcer(a):
  2921|         0|            0|            0|  0.00%|    return (a,)
  2922|         0|            0|            0|  0.00%|
  2923|         0|            0|            0|  0.00%|
  2924|         0|            0|            0|  0.00%|@array_function_dispatch(_alen_dispathcer)
  2925|         0|            0|            0|  0.00%|def alen(a):
  2926|         0|            0|            0|  0.00%|    """
  2927|         0|            0|            0|  0.00%|    Return the length of the first dimension of the input array.
  2928|         0|            0|            0|  0.00%|
  2929|         0|            0|            0|  0.00%|    .. deprecated:: 1.18
  2930|         0|            0|            0|  0.00%|       `numpy.alen` is deprecated, use `len` instead.
  2931|         0|            0|            0|  0.00%|
  2932|         0|            0|            0|  0.00%|    Parameters
  2933|         0|            0|            0|  0.00%|    ----------
  2934|         0|            0|            0|  0.00%|    a : array_like
  2935|         0|            0|            0|  0.00%|       Input array.
  2936|         0|            0|            0|  0.00%|
  2937|         0|            0|            0|  0.00%|    Returns
  2938|         0|            0|            0|  0.00%|    -------
  2939|         0|            0|            0|  0.00%|    alen : int
  2940|         0|            0|            0|  0.00%|       Length of the first dimension of `a`.
  2941|         0|            0|            0|  0.00%|
  2942|         0|            0|            0|  0.00%|    See Also
  2943|         0|            0|            0|  0.00%|    --------
  2944|         0|            0|            0|  0.00%|    shape, size
  2945|         0|            0|            0|  0.00%|
  2946|         0|            0|            0|  0.00%|    Examples
  2947|         0|            0|            0|  0.00%|    --------
  2948|         0|            0|            0|  0.00%|    >>> a = np.zeros((7,4,5))
  2949|         0|            0|            0|  0.00%|    >>> a.shape[0]
  2950|         0|            0|            0|  0.00%|    7
  2951|         0|            0|            0|  0.00%|    >>> np.alen(a)
  2952|         0|            0|            0|  0.00%|    7
  2953|         0|            0|            0|  0.00%|
  2954|         0|            0|            0|  0.00%|    """
  2955|         0|            0|            0|  0.00%|    # NumPy 1.18.0, 2019-08-02
  2956|         0|            0|            0|  0.00%|    warnings.warn(
  2957|         0|            0|            0|  0.00%|        "`np.alen` is deprecated, use `len` instead",
  2958|         0|            0|            0|  0.00%|        DeprecationWarning, stacklevel=2)
  2959|         0|            0|            0|  0.00%|    try:
  2960|         0|            0|            0|  0.00%|        return len(a)
  2961|         0|            0|            0|  0.00%|    except TypeError:
  2962|         0|            0|            0|  0.00%|        return len(array(a, ndmin=1))
  2963|         0|            0|            0|  0.00%|
  2964|         0|            0|            0|  0.00%|
  2965|         0|            0|            0|  0.00%|def _prod_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None,
  2966|         0|            0|            0|  0.00%|                     initial=None, where=None):
  2967|         0|            0|            0|  0.00%|    return (a, out)
  2968|         0|            0|            0|  0.00%|
  2969|         0|            0|            0|  0.00%|
  2970|         0|            0|            0|  0.00%|@array_function_dispatch(_prod_dispatcher)
  2971|         0|            0|            0|  0.00%|def prod(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,
  2972|         0|            0|            0|  0.00%|         initial=np._NoValue, where=np._NoValue):
  2973|         0|            0|            0|  0.00%|    """
  2974|         0|            0|            0|  0.00%|    Return the product of array elements over a given axis.
  2975|         0|            0|            0|  0.00%|
  2976|         0|            0|            0|  0.00%|    Parameters
  2977|         0|            0|            0|  0.00%|    ----------
  2978|         0|            0|            0|  0.00%|    a : array_like
  2979|         0|            0|            0|  0.00%|        Input data.
  2980|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  2981|         0|            0|            0|  0.00%|        Axis or axes along which a product is performed.  The default,
  2982|         0|            0|            0|  0.00%|        axis=None, will calculate the product of all the elements in the
  2983|         0|            0|            0|  0.00%|        input array. If axis is negative it counts from the last to the
  2984|         0|            0|            0|  0.00%|        first axis.
  2985|         0|            0|            0|  0.00%|
  2986|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  2987|         0|            0|            0|  0.00%|
  2988|         0|            0|            0|  0.00%|        If axis is a tuple of ints, a product is performed on all of the
  2989|         0|            0|            0|  0.00%|        axes specified in the tuple instead of a single axis or all the
  2990|         0|            0|            0|  0.00%|        axes as before.
  2991|         0|            0|            0|  0.00%|    dtype : dtype, optional
  2992|         0|            0|            0|  0.00%|        The type of the returned array, as well as of the accumulator in
  2993|         0|            0|            0|  0.00%|        which the elements are multiplied.  The dtype of `a` is used by
  2994|         0|            0|            0|  0.00%|        default unless `a` has an integer dtype of less precision than the
  2995|         0|            0|            0|  0.00%|        default platform integer.  In that case, if `a` is signed then the
  2996|         0|            0|            0|  0.00%|        platform integer is used while if `a` is unsigned then an unsigned
  2997|         0|            0|            0|  0.00%|        integer of the same precision as the platform integer is used.
  2998|         0|            0|            0|  0.00%|    out : ndarray, optional
  2999|         0|            0|            0|  0.00%|        Alternative output array in which to place the result. It must have
  3000|         0|            0|            0|  0.00%|        the same shape as the expected output, but the type of the output
  3001|         0|            0|            0|  0.00%|        values will be cast if necessary.
  3002|         0|            0|            0|  0.00%|    keepdims : bool, optional
  3003|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left in the
  3004|         0|            0|            0|  0.00%|        result as dimensions with size one. With this option, the result
  3005|         0|            0|            0|  0.00%|        will broadcast correctly against the input array.
  3006|         0|            0|            0|  0.00%|
  3007|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  3008|         0|            0|            0|  0.00%|        passed through to the `prod` method of sub-classes of
  3009|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  3010|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  3011|         0|            0|            0|  0.00%|        exceptions will be raised.
  3012|         0|            0|            0|  0.00%|    initial : scalar, optional
  3013|         0|            0|            0|  0.00%|        The starting value for this product. See `~numpy.ufunc.reduce` for details.
  3014|         0|            0|            0|  0.00%|
  3015|         0|            0|            0|  0.00%|        .. versionadded:: 1.15.0
  3016|         0|            0|            0|  0.00%|
  3017|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  3018|         0|            0|            0|  0.00%|        Elements to include in the product. See `~numpy.ufunc.reduce` for details.
  3019|         0|            0|            0|  0.00%|
  3020|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
  3021|         0|            0|            0|  0.00%|
  3022|         0|            0|            0|  0.00%|    Returns
  3023|         0|            0|            0|  0.00%|    -------
  3024|         0|            0|            0|  0.00%|    product_along_axis : ndarray, see `dtype` parameter above.
  3025|         0|            0|            0|  0.00%|        An array shaped as `a` but with the specified axis removed.
  3026|         0|            0|            0|  0.00%|        Returns a reference to `out` if specified.
  3027|         0|            0|            0|  0.00%|
  3028|         0|            0|            0|  0.00%|    See Also
  3029|         0|            0|            0|  0.00%|    --------
  3030|         0|            0|            0|  0.00%|    ndarray.prod : equivalent method
  3031|         0|            0|            0|  0.00%|    :ref:`ufuncs-output-type`
  3032|         0|            0|            0|  0.00%|
  3033|         0|            0|            0|  0.00%|    Notes
  3034|         0|            0|            0|  0.00%|    -----
  3035|         0|            0|            0|  0.00%|    Arithmetic is modular when using integer types, and no error is
  3036|         0|            0|            0|  0.00%|    raised on overflow.  That means that, on a 32-bit platform:
  3037|         0|            0|            0|  0.00%|
  3038|         0|            0|            0|  0.00%|    >>> x = np.array([536870910, 536870910, 536870910, 536870910])
  3039|         0|            0|            0|  0.00%|    >>> np.prod(x)
  3040|         0|            0|            0|  0.00%|    16 # may vary
  3041|         0|            0|            0|  0.00%|
  3042|         0|            0|            0|  0.00%|    The product of an empty array is the neutral element 1:
  3043|         0|            0|            0|  0.00%|
  3044|         0|            0|            0|  0.00%|    >>> np.prod([])
  3045|         0|            0|            0|  0.00%|    1.0
  3046|         0|            0|            0|  0.00%|
  3047|         0|            0|            0|  0.00%|    Examples
  3048|         0|            0|            0|  0.00%|    --------
  3049|         0|            0|            0|  0.00%|    By default, calculate the product of all elements:
  3050|         0|            0|            0|  0.00%|
  3051|         0|            0|            0|  0.00%|    >>> np.prod([1.,2.])
  3052|         0|            0|            0|  0.00%|    2.0
  3053|         0|            0|            0|  0.00%|
  3054|         0|            0|            0|  0.00%|    Even when the input array is two-dimensional:
  3055|         0|            0|            0|  0.00%|
  3056|         0|            0|            0|  0.00%|    >>> np.prod([[1.,2.],[3.,4.]])
  3057|         0|            0|            0|  0.00%|    24.0
  3058|         0|            0|            0|  0.00%|
  3059|         0|            0|            0|  0.00%|    But we can also specify the axis over which to multiply:
  3060|         0|            0|            0|  0.00%|
  3061|         0|            0|            0|  0.00%|    >>> np.prod([[1.,2.],[3.,4.]], axis=1)
  3062|         0|            0|            0|  0.00%|    array([  2.,  12.])
  3063|         0|            0|            0|  0.00%|
  3064|         0|            0|            0|  0.00%|    Or select specific elements to include:
  3065|         0|            0|            0|  0.00%|
  3066|         0|            0|            0|  0.00%|    >>> np.prod([1., np.nan, 3.], where=[True, False, True])
  3067|         0|            0|            0|  0.00%|    3.0
  3068|         0|            0|            0|  0.00%|
  3069|         0|            0|            0|  0.00%|    If the type of `x` is unsigned, then the output type is
  3070|         0|            0|            0|  0.00%|    the unsigned platform integer:
  3071|         0|            0|            0|  0.00%|
  3072|         0|            0|            0|  0.00%|    >>> x = np.array([1, 2, 3], dtype=np.uint8)
  3073|         0|            0|            0|  0.00%|    >>> np.prod(x).dtype == np.uint
  3074|         0|            0|            0|  0.00%|    True
  3075|         0|            0|            0|  0.00%|
  3076|         0|            0|            0|  0.00%|    If `x` is of a signed integer type, then the output type
  3077|         0|            0|            0|  0.00%|    is the default platform integer:
  3078|         0|            0|            0|  0.00%|
  3079|         0|            0|            0|  0.00%|    >>> x = np.array([1, 2, 3], dtype=np.int8)
  3080|         0|            0|            0|  0.00%|    >>> np.prod(x).dtype == int
  3081|         0|            0|            0|  0.00%|    True
  3082|         0|            0|            0|  0.00%|
  3083|         0|            0|            0|  0.00%|    You can also start the product with a value other than one:
  3084|         0|            0|            0|  0.00%|
  3085|         0|            0|            0|  0.00%|    >>> np.prod([1, 2], initial=5)
  3086|         0|            0|            0|  0.00%|    10
  3087|         0|            0|            0|  0.00%|    """
  3088|         0|            0|            0|  0.00%|    return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,
  3089|         0|            0|            0|  0.00%|                          keepdims=keepdims, initial=initial, where=where)
  3090|         0|            0|            0|  0.00%|
  3091|         0|            0|            0|  0.00%|
  3092|         0|            0|            0|  0.00%|def _cumprod_dispatcher(a, axis=None, dtype=None, out=None):
  3093|         0|            0|            0|  0.00%|    return (a, out)
  3094|         0|            0|            0|  0.00%|
  3095|         0|            0|            0|  0.00%|
  3096|         0|            0|            0|  0.00%|@array_function_dispatch(_cumprod_dispatcher)
  3097|         0|            0|            0|  0.00%|def cumprod(a, axis=None, dtype=None, out=None):
  3098|         0|            0|            0|  0.00%|    """
  3099|         0|            0|            0|  0.00%|    Return the cumulative product of elements along a given axis.
  3100|         0|            0|            0|  0.00%|
  3101|         0|            0|            0|  0.00%|    Parameters
  3102|         0|            0|            0|  0.00%|    ----------
  3103|         0|            0|            0|  0.00%|    a : array_like
  3104|         0|            0|            0|  0.00%|        Input array.
  3105|         0|            0|            0|  0.00%|    axis : int, optional
  3106|         0|            0|            0|  0.00%|        Axis along which the cumulative product is computed.  By default
  3107|         0|            0|            0|  0.00%|        the input is flattened.
  3108|         0|            0|            0|  0.00%|    dtype : dtype, optional
  3109|         0|            0|            0|  0.00%|        Type of the returned array, as well as of the accumulator in which
  3110|         0|            0|            0|  0.00%|        the elements are multiplied.  If *dtype* is not specified, it
  3111|         0|            0|            0|  0.00%|        defaults to the dtype of `a`, unless `a` has an integer dtype with
  3112|         0|            0|            0|  0.00%|        a precision less than that of the default platform integer.  In
  3113|         0|            0|            0|  0.00%|        that case, the default platform integer is used instead.
  3114|         0|            0|            0|  0.00%|    out : ndarray, optional
  3115|         0|            0|            0|  0.00%|        Alternative output array in which to place the result. It must
  3116|         0|            0|            0|  0.00%|        have the same shape and buffer length as the expected output
  3117|         0|            0|            0|  0.00%|        but the type of the resulting values will be cast if necessary.
  3118|         0|            0|            0|  0.00%|
  3119|         0|            0|            0|  0.00%|    Returns
  3120|         0|            0|            0|  0.00%|    -------
  3121|         0|            0|            0|  0.00%|    cumprod : ndarray
  3122|         0|            0|            0|  0.00%|        A new array holding the result is returned unless `out` is
  3123|         0|            0|            0|  0.00%|        specified, in which case a reference to out is returned.
  3124|         0|            0|            0|  0.00%|
  3125|         0|            0|            0|  0.00%|    See Also
  3126|         0|            0|            0|  0.00%|    --------
  3127|         0|            0|            0|  0.00%|    :ref:`ufuncs-output-type`
  3128|         0|            0|            0|  0.00%|
  3129|         0|            0|            0|  0.00%|    Notes
  3130|         0|            0|            0|  0.00%|    -----
  3131|         0|            0|            0|  0.00%|    Arithmetic is modular when using integer types, and no error is
  3132|         0|            0|            0|  0.00%|    raised on overflow.
  3133|         0|            0|            0|  0.00%|
  3134|         0|            0|            0|  0.00%|    Examples
  3135|         0|            0|            0|  0.00%|    --------
  3136|         0|            0|            0|  0.00%|    >>> a = np.array([1,2,3])
  3137|         0|            0|            0|  0.00%|    >>> np.cumprod(a) # intermediate results 1, 1*2
  3138|         0|            0|            0|  0.00%|    ...               # total product 1*2*3 = 6
  3139|         0|            0|            0|  0.00%|    array([1, 2, 6])
  3140|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2, 3], [4, 5, 6]])
  3141|         0|            0|            0|  0.00%|    >>> np.cumprod(a, dtype=float) # specify type of output
  3142|         0|            0|            0|  0.00%|    array([   1.,    2.,    6.,   24.,  120.,  720.])
  3143|         0|            0|            0|  0.00%|
  3144|         0|            0|            0|  0.00%|    The cumulative product for each column (i.e., over the rows) of `a`:
  3145|         0|            0|            0|  0.00%|
  3146|         0|            0|            0|  0.00%|    >>> np.cumprod(a, axis=0)
  3147|         0|            0|            0|  0.00%|    array([[ 1,  2,  3],
  3148|         0|            0|            0|  0.00%|           [ 4, 10, 18]])
  3149|         0|            0|            0|  0.00%|
  3150|         0|            0|            0|  0.00%|    The cumulative product for each row (i.e. over the columns) of `a`:
  3151|         0|            0|            0|  0.00%|
  3152|         0|            0|            0|  0.00%|    >>> np.cumprod(a,axis=1)
  3153|         0|            0|            0|  0.00%|    array([[  1,   2,   6],
  3154|         0|            0|            0|  0.00%|           [  4,  20, 120]])
  3155|         0|            0|            0|  0.00%|
  3156|         0|            0|            0|  0.00%|    """
  3157|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'cumprod', axis=axis, dtype=dtype, out=out)
  3158|         0|            0|            0|  0.00%|
  3159|         0|            0|            0|  0.00%|
  3160|         0|            0|            0|  0.00%|def _ndim_dispatcher(a):
  3161|         0|            0|            0|  0.00%|    return (a,)
  3162|         0|            0|            0|  0.00%|
  3163|         0|            0|            0|  0.00%|
  3164|         0|            0|            0|  0.00%|@array_function_dispatch(_ndim_dispatcher)
  3165|         0|            0|            0|  0.00%|def ndim(a):
  3166|         0|            0|            0|  0.00%|    """
  3167|         0|            0|            0|  0.00%|    Return the number of dimensions of an array.
  3168|         0|            0|            0|  0.00%|
  3169|         0|            0|            0|  0.00%|    Parameters
  3170|         0|            0|            0|  0.00%|    ----------
  3171|         0|            0|            0|  0.00%|    a : array_like
  3172|         0|            0|            0|  0.00%|        Input array.  If it is not already an ndarray, a conversion is
  3173|         0|            0|            0|  0.00%|        attempted.
  3174|         0|            0|            0|  0.00%|
  3175|         0|            0|            0|  0.00%|    Returns
  3176|         0|            0|            0|  0.00%|    -------
  3177|         0|            0|            0|  0.00%|    number_of_dimensions : int
  3178|         0|            0|            0|  0.00%|        The number of dimensions in `a`.  Scalars are zero-dimensional.
  3179|         0|            0|            0|  0.00%|
  3180|         0|            0|            0|  0.00%|    See Also
  3181|         0|            0|            0|  0.00%|    --------
  3182|         0|            0|            0|  0.00%|    ndarray.ndim : equivalent method
  3183|         0|            0|            0|  0.00%|    shape : dimensions of array
  3184|         0|            0|            0|  0.00%|    ndarray.shape : dimensions of array
  3185|         0|            0|            0|  0.00%|
  3186|         0|            0|            0|  0.00%|    Examples
  3187|         0|            0|            0|  0.00%|    --------
  3188|         0|            0|            0|  0.00%|    >>> np.ndim([[1,2,3],[4,5,6]])
  3189|         0|            0|            0|  0.00%|    2
  3190|         0|            0|            0|  0.00%|    >>> np.ndim(np.array([[1,2,3],[4,5,6]]))
  3191|         0|            0|            0|  0.00%|    2
  3192|         0|            0|            0|  0.00%|    >>> np.ndim(1)
  3193|         0|            0|            0|  0.00%|    0
  3194|         0|            0|            0|  0.00%|
  3195|         0|            0|            0|  0.00%|    """
  3196|         0|            0|            0|  0.00%|    try:
  3197|         0|            0|            0|  0.00%|        return a.ndim
  3198|         0|            0|            0|  0.00%|    except AttributeError:
  3199|         0|            0|            0|  0.00%|        return asarray(a).ndim
  3200|         0|            0|            0|  0.00%|
  3201|         0|            0|            0|  0.00%|
  3202|         0|            0|            0|  0.00%|def _size_dispatcher(a, axis=None):
  3203|         0|            0|            0|  0.00%|    return (a,)
  3204|         0|            0|            0|  0.00%|
  3205|         0|            0|            0|  0.00%|
  3206|         0|            0|            0|  0.00%|@array_function_dispatch(_size_dispatcher)
  3207|         0|            0|            0|  0.00%|def size(a, axis=None):
  3208|         0|            0|            0|  0.00%|    """
  3209|         0|            0|            0|  0.00%|    Return the number of elements along a given axis.
  3210|         0|            0|            0|  0.00%|
  3211|         0|            0|            0|  0.00%|    Parameters
  3212|         0|            0|            0|  0.00%|    ----------
  3213|         0|            0|            0|  0.00%|    a : array_like
  3214|         0|            0|            0|  0.00%|        Input data.
  3215|         0|            0|            0|  0.00%|    axis : int, optional
  3216|         0|            0|            0|  0.00%|        Axis along which the elements are counted.  By default, give
  3217|         0|            0|            0|  0.00%|        the total number of elements.
  3218|         0|            0|            0|  0.00%|
  3219|         0|            0|            0|  0.00%|    Returns
  3220|         0|            0|            0|  0.00%|    -------
  3221|         0|            0|            0|  0.00%|    element_count : int
  3222|         0|            0|            0|  0.00%|        Number of elements along the specified axis.
  3223|         0|            0|            0|  0.00%|
  3224|         0|            0|            0|  0.00%|    See Also
  3225|         0|            0|            0|  0.00%|    --------
  3226|         0|            0|            0|  0.00%|    shape : dimensions of array
  3227|         0|            0|            0|  0.00%|    ndarray.shape : dimensions of array
  3228|         0|            0|            0|  0.00%|    ndarray.size : number of elements in array
  3229|         0|            0|            0|  0.00%|
  3230|         0|            0|            0|  0.00%|    Examples
  3231|         0|            0|            0|  0.00%|    --------
  3232|         0|            0|            0|  0.00%|    >>> a = np.array([[1,2,3],[4,5,6]])
  3233|         0|            0|            0|  0.00%|    >>> np.size(a)
  3234|         0|            0|            0|  0.00%|    6
  3235|         0|            0|            0|  0.00%|    >>> np.size(a,1)
  3236|         0|            0|            0|  0.00%|    3
  3237|         0|            0|            0|  0.00%|    >>> np.size(a,0)
  3238|         0|            0|            0|  0.00%|    2
  3239|         0|            0|            0|  0.00%|
  3240|         0|            0|            0|  0.00%|    """
  3241|         0|            0|            0|  0.00%|    if axis is None:
  3242|         0|            0|            0|  0.00%|        try:
  3243|         0|            0|            0|  0.00%|            return a.size
  3244|         0|            0|            0|  0.00%|        except AttributeError:
  3245|         0|            0|            0|  0.00%|            return asarray(a).size
  3246|         0|            0|            0|  0.00%|    else:
  3247|         0|            0|            0|  0.00%|        try:
  3248|         0|            0|            0|  0.00%|            return a.shape[axis]
  3249|         0|            0|            0|  0.00%|        except AttributeError:
  3250|         0|            0|            0|  0.00%|            return asarray(a).shape[axis]
  3251|         0|            0|            0|  0.00%|
  3252|         0|            0|            0|  0.00%|
  3253|         0|            0|            0|  0.00%|def _around_dispatcher(a, decimals=None, out=None):
  3254|         0|            0|            0|  0.00%|    return (a, out)
  3255|         0|            0|            0|  0.00%|
  3256|         0|            0|            0|  0.00%|
  3257|         0|            0|            0|  0.00%|@array_function_dispatch(_around_dispatcher)
  3258|         0|            0|            0|  0.00%|def around(a, decimals=0, out=None):
  3259|         0|            0|            0|  0.00%|    """
  3260|         0|            0|            0|  0.00%|    Evenly round to the given number of decimals.
  3261|         0|            0|            0|  0.00%|
  3262|         0|            0|            0|  0.00%|    Parameters
  3263|         0|            0|            0|  0.00%|    ----------
  3264|         0|            0|            0|  0.00%|    a : array_like
  3265|         0|            0|            0|  0.00%|        Input data.
  3266|         0|            0|            0|  0.00%|    decimals : int, optional
  3267|         0|            0|            0|  0.00%|        Number of decimal places to round to (default: 0).  If
  3268|         0|            0|            0|  0.00%|        decimals is negative, it specifies the number of positions to
  3269|         0|            0|            0|  0.00%|        the left of the decimal point.
  3270|         0|            0|            0|  0.00%|    out : ndarray, optional
  3271|         0|            0|            0|  0.00%|        Alternative output array in which to place the result. It must have
  3272|         0|            0|            0|  0.00%|        the same shape as the expected output, but the type of the output
  3273|         0|            0|            0|  0.00%|        values will be cast if necessary. See :ref:`ufuncs-output-type` for more
  3274|         0|            0|            0|  0.00%|        details.
  3275|         0|            0|            0|  0.00%|
  3276|         0|            0|            0|  0.00%|    Returns
  3277|         0|            0|            0|  0.00%|    -------
  3278|         0|            0|            0|  0.00%|    rounded_array : ndarray
  3279|         0|            0|            0|  0.00%|        An array of the same type as `a`, containing the rounded values.
  3280|         0|            0|            0|  0.00%|        Unless `out` was specified, a new array is created.  A reference to
  3281|         0|            0|            0|  0.00%|        the result is returned.
  3282|         0|            0|            0|  0.00%|
  3283|         0|            0|            0|  0.00%|        The real and imaginary parts of complex numbers are rounded
  3284|         0|            0|            0|  0.00%|        separately.  The result of rounding a float is a float.
  3285|         0|            0|            0|  0.00%|
  3286|         0|            0|            0|  0.00%|    See Also
  3287|         0|            0|            0|  0.00%|    --------
  3288|         0|            0|            0|  0.00%|    ndarray.round : equivalent method
  3289|         0|            0|            0|  0.00%|
  3290|         0|            0|            0|  0.00%|    ceil, fix, floor, rint, trunc
  3291|         0|            0|            0|  0.00%|
  3292|         0|            0|            0|  0.00%|
  3293|         0|            0|            0|  0.00%|    Notes
  3294|         0|            0|            0|  0.00%|    -----
  3295|         0|            0|            0|  0.00%|    For values exactly halfway between rounded decimal values, NumPy
  3296|         0|            0|            0|  0.00%|    rounds to the nearest even value. Thus 1.5 and 2.5 round to 2.0,
  3297|         0|            0|            0|  0.00%|    -0.5 and 0.5 round to 0.0, etc.
  3298|         0|            0|            0|  0.00%|
  3299|         0|            0|            0|  0.00%|    ``np.around`` uses a fast but sometimes inexact algorithm to round
  3300|         0|            0|            0|  0.00%|    floating-point datatypes. For positive `decimals` it is equivalent to
  3301|         0|            0|            0|  0.00%|    ``np.true_divide(np.rint(a * 10**decimals), 10**decimals)``, which has
  3302|         0|            0|            0|  0.00%|    error due to the inexact representation of decimal fractions in the IEEE
  3303|         0|            0|            0|  0.00%|    floating point standard [1]_ and errors introduced when scaling by powers
  3304|         0|            0|            0|  0.00%|    of ten. For instance, note the extra "1" in the following:
  3305|         0|            0|            0|  0.00%|
  3306|         0|            0|            0|  0.00%|        >>> np.round(56294995342131.5, 3)
  3307|         0|            0|            0|  0.00%|        56294995342131.51
  3308|         0|            0|            0|  0.00%|
  3309|         0|            0|            0|  0.00%|    If your goal is to print such values with a fixed number of decimals, it is
  3310|         0|            0|            0|  0.00%|    preferable to use numpy's float printing routines to limit the number of
  3311|         0|            0|            0|  0.00%|    printed decimals:
  3312|         0|            0|            0|  0.00%|
  3313|         0|            0|            0|  0.00%|        >>> np.format_float_positional(56294995342131.5, precision=3)
  3314|         0|            0|            0|  0.00%|        '56294995342131.5'
  3315|         0|            0|            0|  0.00%|
  3316|         0|            0|            0|  0.00%|    The float printing routines use an accurate but much more computationally
  3317|         0|            0|            0|  0.00%|    demanding algorithm to compute the number of digits after the decimal
  3318|         0|            0|            0|  0.00%|    point.
  3319|         0|            0|            0|  0.00%|
  3320|         0|            0|            0|  0.00%|    Alternatively, Python's builtin `round` function uses a more accurate
  3321|         0|            0|            0|  0.00%|    but slower algorithm for 64-bit floating point values:
  3322|         0|            0|            0|  0.00%|
  3323|         0|            0|            0|  0.00%|        >>> round(56294995342131.5, 3)
  3324|         0|            0|            0|  0.00%|        56294995342131.5
  3325|         0|            0|            0|  0.00%|        >>> np.round(16.055, 2), round(16.055, 2)  # equals 16.0549999999999997
  3326|         0|            0|            0|  0.00%|        (16.06, 16.05)
  3327|         0|            0|            0|  0.00%|
  3328|         0|            0|            0|  0.00%|
  3329|         0|            0|            0|  0.00%|    References
  3330|         0|            0|            0|  0.00%|    ----------
  3331|         0|            0|            0|  0.00%|    .. [1] "Lecture Notes on the Status of IEEE 754", William Kahan,
  3332|         0|            0|            0|  0.00%|           https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF
  3333|         0|            0|            0|  0.00%|
  3334|         0|            0|            0|  0.00%|    Examples
  3335|         0|            0|            0|  0.00%|    --------
  3336|         0|            0|            0|  0.00%|    >>> np.around([0.37, 1.64])
  3337|         0|            0|            0|  0.00%|    array([0., 2.])
  3338|         0|            0|            0|  0.00%|    >>> np.around([0.37, 1.64], decimals=1)
  3339|         0|            0|            0|  0.00%|    array([0.4, 1.6])
  3340|         0|            0|            0|  0.00%|    >>> np.around([.5, 1.5, 2.5, 3.5, 4.5]) # rounds to nearest even value
  3341|         0|            0|            0|  0.00%|    array([0., 2., 2., 4., 4.])
  3342|         0|            0|            0|  0.00%|    >>> np.around([1,2,3,11], decimals=1) # ndarray of ints is returned
  3343|         0|            0|            0|  0.00%|    array([ 1,  2,  3, 11])
  3344|         0|            0|            0|  0.00%|    >>> np.around([1,2,3,11], decimals=-1)
  3345|         0|            0|            0|  0.00%|    array([ 0,  0,  0, 10])
  3346|         0|            0|            0|  0.00%|
  3347|         0|            0|            0|  0.00%|    """
  3348|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'round', decimals=decimals, out=out)
  3349|         0|            0|            0|  0.00%|
  3350|         0|            0|            0|  0.00%|
  3351|         0|            0|            0|  0.00%|def _mean_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None, *,
  3352|         0|            0|            0|  0.00%|                     where=None):
  3353|         0|            0|            0|  0.00%|    return (a, where, out)
  3354|         0|            0|            0|  0.00%|
  3355|         0|            0|            0|  0.00%|
  3356|         0|            0|            0|  0.00%|@array_function_dispatch(_mean_dispatcher)
  3357|         0|            0|            0|  0.00%|def mean(a, axis=None, dtype=None, out=None, keepdims=np._NoValue, *,
  3358|         0|            0|            0|  0.00%|         where=np._NoValue):
  3359|         0|            0|            0|  0.00%|    """
  3360|         0|            0|            0|  0.00%|    Compute the arithmetic mean along the specified axis.
  3361|         0|            0|            0|  0.00%|
  3362|         0|            0|            0|  0.00%|    Returns the average of the array elements.  The average is taken over
  3363|         0|            0|            0|  0.00%|    the flattened array by default, otherwise over the specified axis.
  3364|         0|            0|            0|  0.00%|    `float64` intermediate and return values are used for integer inputs.
  3365|         0|            0|            0|  0.00%|
  3366|         0|            0|            0|  0.00%|    Parameters
  3367|         0|            0|            0|  0.00%|    ----------
  3368|         0|            0|            0|  0.00%|    a : array_like
  3369|         0|            0|            0|  0.00%|        Array containing numbers whose mean is desired. If `a` is not an
  3370|         0|            0|            0|  0.00%|        array, a conversion is attempted.
  3371|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  3372|         0|            0|            0|  0.00%|        Axis or axes along which the means are computed. The default is to
  3373|         0|            0|            0|  0.00%|        compute the mean of the flattened array.
  3374|         0|            0|            0|  0.00%|
  3375|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  3376|         0|            0|            0|  0.00%|
  3377|         0|            0|            0|  0.00%|        If this is a tuple of ints, a mean is performed over multiple axes,
  3378|         0|            0|            0|  0.00%|        instead of a single axis or all the axes as before.
  3379|         0|            0|            0|  0.00%|    dtype : data-type, optional
  3380|         0|            0|            0|  0.00%|        Type to use in computing the mean.  For integer inputs, the default
  3381|         0|            0|            0|  0.00%|        is `float64`; for floating point inputs, it is the same as the
  3382|         0|            0|            0|  0.00%|        input dtype.
  3383|         0|            0|            0|  0.00%|    out : ndarray, optional
  3384|         0|            0|            0|  0.00%|        Alternate output array in which to place the result.  The default
  3385|         0|            0|            0|  0.00%|        is ``None``; if provided, it must have the same shape as the
  3386|         0|            0|            0|  0.00%|        expected output, but the type will be cast if necessary.
  3387|         0|            0|            0|  0.00%|        See :ref:`ufuncs-output-type` for more details.
  3388|         0|            0|            0|  0.00%|
  3389|         0|            0|            0|  0.00%|    keepdims : bool, optional
  3390|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  3391|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  3392|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  3393|         0|            0|            0|  0.00%|
  3394|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  3395|         0|            0|            0|  0.00%|        passed through to the `mean` method of sub-classes of
  3396|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  3397|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  3398|         0|            0|            0|  0.00%|        exceptions will be raised.
  3399|         0|            0|            0|  0.00%|
  3400|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  3401|         0|            0|            0|  0.00%|        Elements to include in the mean. See `~numpy.ufunc.reduce` for details.
  3402|         0|            0|            0|  0.00%|
  3403|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
  3404|         0|            0|            0|  0.00%|
  3405|         0|            0|            0|  0.00%|    Returns
  3406|         0|            0|            0|  0.00%|    -------
  3407|         0|            0|            0|  0.00%|    m : ndarray, see dtype parameter above
  3408|         0|            0|            0|  0.00%|        If `out=None`, returns a new array containing the mean values,
  3409|         0|            0|            0|  0.00%|        otherwise a reference to the output array is returned.
  3410|         0|            0|            0|  0.00%|
  3411|         0|            0|            0|  0.00%|    See Also
  3412|         0|            0|            0|  0.00%|    --------
  3413|         0|            0|            0|  0.00%|    average : Weighted average
  3414|         0|            0|            0|  0.00%|    std, var, nanmean, nanstd, nanvar
  3415|         0|            0|            0|  0.00%|
  3416|         0|            0|            0|  0.00%|    Notes
  3417|         0|            0|            0|  0.00%|    -----
  3418|         0|            0|            0|  0.00%|    The arithmetic mean is the sum of the elements along the axis divided
  3419|         0|            0|            0|  0.00%|    by the number of elements.
  3420|         0|            0|            0|  0.00%|
  3421|         0|            0|            0|  0.00%|    Note that for floating-point input, the mean is computed using the
  3422|         0|            0|            0|  0.00%|    same precision the input has.  Depending on the input data, this can
  3423|         0|            0|            0|  0.00%|    cause the results to be inaccurate, especially for `float32` (see
  3424|         0|            0|            0|  0.00%|    example below).  Specifying a higher-precision accumulator using the
  3425|         0|            0|            0|  0.00%|    `dtype` keyword can alleviate this issue.
  3426|         0|            0|            0|  0.00%|
  3427|         0|            0|            0|  0.00%|    By default, `float16` results are computed using `float32` intermediates
  3428|         0|            0|            0|  0.00%|    for extra precision.
  3429|         0|            0|            0|  0.00%|
  3430|         0|            0|            0|  0.00%|    Examples
  3431|         0|            0|            0|  0.00%|    --------
  3432|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2], [3, 4]])
  3433|         0|            0|            0|  0.00%|    >>> np.mean(a)
  3434|         0|            0|            0|  0.00%|    2.5
  3435|         0|            0|            0|  0.00%|    >>> np.mean(a, axis=0)
  3436|         0|            0|            0|  0.00%|    array([2., 3.])
  3437|         0|            0|            0|  0.00%|    >>> np.mean(a, axis=1)
  3438|         0|            0|            0|  0.00%|    array([1.5, 3.5])
  3439|         0|            0|            0|  0.00%|
  3440|         0|            0|            0|  0.00%|    In single precision, `mean` can be inaccurate:
  3441|         0|            0|            0|  0.00%|
  3442|         0|            0|            0|  0.00%|    >>> a = np.zeros((2, 512*512), dtype=np.float32)
  3443|         0|            0|            0|  0.00%|    >>> a[0, :] = 1.0
  3444|         0|            0|            0|  0.00%|    >>> a[1, :] = 0.1
  3445|         0|            0|            0|  0.00%|    >>> np.mean(a)
  3446|         0|            0|            0|  0.00%|    0.54999924
  3447|         0|            0|            0|  0.00%|
  3448|         0|            0|            0|  0.00%|    Computing the mean in float64 is more accurate:
  3449|         0|            0|            0|  0.00%|
  3450|         0|            0|            0|  0.00%|    >>> np.mean(a, dtype=np.float64)
  3451|         0|            0|            0|  0.00%|    0.55000000074505806 # may vary
  3452|         0|            0|            0|  0.00%|
  3453|         0|            0|            0|  0.00%|    Specifying a where argument:
  3454|         0|            0|            0|  0.00%|    >>> a = np.array([[5, 9, 13], [14, 10, 12], [11, 15, 19]])
  3455|         0|            0|            0|  0.00%|    >>> np.mean(a)
  3456|         0|            0|            0|  0.00%|    12.0
  3457|         0|            0|            0|  0.00%|    >>> np.mean(a, where=[[True], [False], [False]])
  3458|         0|            0|            0|  0.00%|    9.0
  3459|         0|            0|            0|  0.00%|
  3460|         0|            0|            0|  0.00%|    """
  3461|         0|            0|            0|  0.00%|    kwargs = {}
  3462|         0|            0|            0|  0.00%|    if keepdims is not np._NoValue:
  3463|         0|            0|            0|  0.00%|        kwargs['keepdims'] = keepdims
  3464|         0|            0|            0|  0.00%|    if where is not np._NoValue:
  3465|         0|            0|            0|  0.00%|        kwargs['where'] = where
  3466|         0|            0|            0|  0.00%|    if type(a) is not mu.ndarray:
  3467|         0|            0|            0|  0.00%|        try:
  3468|         0|            0|            0|  0.00%|            mean = a.mean
  3469|         0|            0|            0|  0.00%|        except AttributeError:
  3470|         0|            0|            0|  0.00%|            pass
  3471|         0|            0|            0|  0.00%|        else:
  3472|         0|            0|            0|  0.00%|            return mean(axis=axis, dtype=dtype, out=out, **kwargs)
  3473|         0|            0|            0|  0.00%|
  3474|         0|            0|            0|  0.00%|    return _methods._mean(a, axis=axis, dtype=dtype,
  3475|         0|            0|            0|  0.00%|                          out=out, **kwargs)
  3476|         0|            0|            0|  0.00%|
  3477|         0|            0|            0|  0.00%|
  3478|         0|            0|            0|  0.00%|def _std_dispatcher(a, axis=None, dtype=None, out=None, ddof=None,
  3479|         0|            0|            0|  0.00%|                    keepdims=None, *, where=None):
  3480|         0|            0|            0|  0.00%|    return (a, where, out)
  3481|         0|            0|            0|  0.00%|
  3482|         0|            0|            0|  0.00%|
  3483|         0|            0|            0|  0.00%|@array_function_dispatch(_std_dispatcher)
  3484|         0|            0|            0|  0.00%|def std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue, *,
  3485|         0|            0|            0|  0.00%|        where=np._NoValue):
  3486|         0|            0|            0|  0.00%|    """
  3487|         0|            0|            0|  0.00%|    Compute the standard deviation along the specified axis.
  3488|         0|            0|            0|  0.00%|
  3489|         0|            0|            0|  0.00%|    Returns the standard deviation, a measure of the spread of a distribution,
  3490|         0|            0|            0|  0.00%|    of the array elements. The standard deviation is computed for the
  3491|         0|            0|            0|  0.00%|    flattened array by default, otherwise over the specified axis.
  3492|         0|            0|            0|  0.00%|
  3493|         0|            0|            0|  0.00%|    Parameters
  3494|         0|            0|            0|  0.00%|    ----------
  3495|         0|            0|            0|  0.00%|    a : array_like
  3496|         0|            0|            0|  0.00%|        Calculate the standard deviation of these values.
  3497|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  3498|         0|            0|            0|  0.00%|        Axis or axes along which the standard deviation is computed. The
  3499|         0|            0|            0|  0.00%|        default is to compute the standard deviation of the flattened array.
  3500|         0|            0|            0|  0.00%|
  3501|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  3502|         0|            0|            0|  0.00%|
  3503|         0|            0|            0|  0.00%|        If this is a tuple of ints, a standard deviation is performed over
  3504|         0|            0|            0|  0.00%|        multiple axes, instead of a single axis or all the axes as before.
  3505|         0|            0|            0|  0.00%|    dtype : dtype, optional
  3506|         0|            0|            0|  0.00%|        Type to use in computing the standard deviation. For arrays of
  3507|         0|            0|            0|  0.00%|        integer type the default is float64, for arrays of float types it is
  3508|         0|            0|            0|  0.00%|        the same as the array type.
  3509|         0|            0|            0|  0.00%|    out : ndarray, optional
  3510|         0|            0|            0|  0.00%|        Alternative output array in which to place the result. It must have
  3511|         0|            0|            0|  0.00%|        the same shape as the expected output but the type (of the calculated
  3512|         0|            0|            0|  0.00%|        values) will be cast if necessary.
  3513|         0|            0|            0|  0.00%|    ddof : int, optional
  3514|         0|            0|            0|  0.00%|        Means Delta Degrees of Freedom.  The divisor used in calculations
  3515|         0|            0|            0|  0.00%|        is ``N - ddof``, where ``N`` represents the number of elements.
  3516|         0|            0|            0|  0.00%|        By default `ddof` is zero.
  3517|         0|            0|            0|  0.00%|    keepdims : bool, optional
  3518|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  3519|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  3520|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  3521|         0|            0|            0|  0.00%|
  3522|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  3523|         0|            0|            0|  0.00%|        passed through to the `std` method of sub-classes of
  3524|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  3525|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  3526|         0|            0|            0|  0.00%|        exceptions will be raised.
  3527|         0|            0|            0|  0.00%|
  3528|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  3529|         0|            0|            0|  0.00%|        Elements to include in the standard deviation.
  3530|         0|            0|            0|  0.00%|        See `~numpy.ufunc.reduce` for details.
  3531|         0|            0|            0|  0.00%|
  3532|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
  3533|         0|            0|            0|  0.00%|
  3534|         0|            0|            0|  0.00%|    Returns
  3535|         0|            0|            0|  0.00%|    -------
  3536|         0|            0|            0|  0.00%|    standard_deviation : ndarray, see dtype parameter above.
  3537|         0|            0|            0|  0.00%|        If `out` is None, return a new array containing the standard deviation,
  3538|         0|            0|            0|  0.00%|        otherwise return a reference to the output array.
  3539|         0|            0|            0|  0.00%|
  3540|         0|            0|            0|  0.00%|    See Also
  3541|         0|            0|            0|  0.00%|    --------
  3542|         0|            0|            0|  0.00%|    var, mean, nanmean, nanstd, nanvar
  3543|         0|            0|            0|  0.00%|    :ref:`ufuncs-output-type`
  3544|         0|            0|            0|  0.00%|
  3545|         0|            0|            0|  0.00%|    Notes
  3546|         0|            0|            0|  0.00%|    -----
  3547|         0|            0|            0|  0.00%|    The standard deviation is the square root of the average of the squared
  3548|         0|            0|            0|  0.00%|    deviations from the mean, i.e., ``std = sqrt(mean(x))``, where
  3549|         0|            0|            0|  0.00%|    ``x = abs(a - a.mean())**2``.
  3550|         0|            0|            0|  0.00%|
  3551|         0|            0|            0|  0.00%|    The average squared deviation is typically calculated as ``x.sum() / N``,
  3552|         0|            0|            0|  0.00%|    where ``N = len(x)``. If, however, `ddof` is specified, the divisor
  3553|         0|            0|            0|  0.00%|    ``N - ddof`` is used instead. In standard statistical practice, ``ddof=1``
  3554|         0|            0|            0|  0.00%|    provides an unbiased estimator of the variance of the infinite population.
  3555|         0|            0|            0|  0.00%|    ``ddof=0`` provides a maximum likelihood estimate of the variance for
  3556|         0|            0|            0|  0.00%|    normally distributed variables. The standard deviation computed in this
  3557|         0|            0|            0|  0.00%|    function is the square root of the estimated variance, so even with
  3558|         0|            0|            0|  0.00%|    ``ddof=1``, it will not be an unbiased estimate of the standard deviation
  3559|         0|            0|            0|  0.00%|    per se.
  3560|         0|            0|            0|  0.00%|
  3561|         0|            0|            0|  0.00%|    Note that, for complex numbers, `std` takes the absolute
  3562|         0|            0|            0|  0.00%|    value before squaring, so that the result is always real and nonnegative.
  3563|         0|            0|            0|  0.00%|
  3564|         0|            0|            0|  0.00%|    For floating-point input, the *std* is computed using the same
  3565|         0|            0|            0|  0.00%|    precision the input has. Depending on the input data, this can cause
  3566|         0|            0|            0|  0.00%|    the results to be inaccurate, especially for float32 (see example below).
  3567|         0|            0|            0|  0.00%|    Specifying a higher-accuracy accumulator using the `dtype` keyword can
  3568|         0|            0|            0|  0.00%|    alleviate this issue.
  3569|         0|            0|            0|  0.00%|
  3570|         0|            0|            0|  0.00%|    Examples
  3571|         0|            0|            0|  0.00%|    --------
  3572|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2], [3, 4]])
  3573|         0|            0|            0|  0.00%|    >>> np.std(a)
  3574|         0|            0|            0|  0.00%|    1.1180339887498949 # may vary
  3575|         0|            0|            0|  0.00%|    >>> np.std(a, axis=0)
  3576|         0|            0|            0|  0.00%|    array([1.,  1.])
  3577|         0|            0|            0|  0.00%|    >>> np.std(a, axis=1)
  3578|         0|            0|            0|  0.00%|    array([0.5,  0.5])
  3579|         0|            0|            0|  0.00%|
  3580|         0|            0|            0|  0.00%|    In single precision, std() can be inaccurate:
  3581|         0|            0|            0|  0.00%|
  3582|         0|            0|            0|  0.00%|    >>> a = np.zeros((2, 512*512), dtype=np.float32)
  3583|         0|            0|            0|  0.00%|    >>> a[0, :] = 1.0
  3584|         0|            0|            0|  0.00%|    >>> a[1, :] = 0.1
  3585|         0|            0|            0|  0.00%|    >>> np.std(a)
  3586|         0|            0|            0|  0.00%|    0.45000005
  3587|         0|            0|            0|  0.00%|
  3588|         0|            0|            0|  0.00%|    Computing the standard deviation in float64 is more accurate:
  3589|         0|            0|            0|  0.00%|
  3590|         0|            0|            0|  0.00%|    >>> np.std(a, dtype=np.float64)
  3591|         0|            0|            0|  0.00%|    0.44999999925494177 # may vary
  3592|         0|            0|            0|  0.00%|
  3593|         0|            0|            0|  0.00%|    Specifying a where argument:
  3594|         0|            0|            0|  0.00%|
  3595|         0|            0|            0|  0.00%|    >>> a = np.array([[14, 8, 11, 10], [7, 9, 10, 11], [10, 15, 5, 10]])
  3596|         0|            0|            0|  0.00%|    >>> np.std(a)
  3597|         0|            0|            0|  0.00%|    2.614064523559687 # may vary
  3598|         0|            0|            0|  0.00%|    >>> np.std(a, where=[[True], [True], [False]])
  3599|         0|            0|            0|  0.00%|    2.0
  3600|         0|            0|            0|  0.00%|
  3601|         0|            0|            0|  0.00%|    """
  3602|         0|            0|            0|  0.00%|    kwargs = {}
  3603|         0|            0|            0|  0.00%|    if keepdims is not np._NoValue:
  3604|         0|            0|            0|  0.00%|        kwargs['keepdims'] = keepdims
  3605|         0|            0|            0|  0.00%|    if where is not np._NoValue:
  3606|         0|            0|            0|  0.00%|        kwargs['where'] = where
  3607|         0|            0|            0|  0.00%|    if type(a) is not mu.ndarray:
  3608|         0|            0|            0|  0.00%|        try:
  3609|         0|            0|            0|  0.00%|            std = a.std
  3610|         0|            0|            0|  0.00%|        except AttributeError:
  3611|         0|            0|            0|  0.00%|            pass
  3612|         0|            0|            0|  0.00%|        else:
  3613|         0|            0|            0|  0.00%|            return std(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)
  3614|         0|            0|            0|  0.00%|
  3615|         0|            0|            0|  0.00%|    return _methods._std(a, axis=axis, dtype=dtype, out=out, ddof=ddof,
  3616|         0|            0|            0|  0.00%|                         **kwargs)
  3617|         0|            0|            0|  0.00%|
  3618|         0|            0|            0|  0.00%|
  3619|        36|  8.01086e-05|  2.22524e-06|  0.00%|def _var_dispatcher(a, axis=None, dtype=None, out=None, ddof=None,
  3620|         0|            0|            0|  0.00%|                    keepdims=None, *, where=None):
  3621|        36|  9.15527e-05|  2.54313e-06|  0.00%|    return (a, where, out)
  3622|         0|            0|            0|  0.00%|
  3623|         0|            0|            0|  0.00%|
  3624|        36|  0.000102997|  2.86102e-06|  0.00%|@array_function_dispatch(_var_dispatcher)
  3625|         0|            0|            0|  0.00%|def var(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue, *,
  3626|         0|            0|            0|  0.00%|        where=np._NoValue):
  3627|         0|            0|            0|  0.00%|    """
  3628|         0|            0|            0|  0.00%|    Compute the variance along the specified axis.
  3629|         0|            0|            0|  0.00%|
  3630|         0|            0|            0|  0.00%|    Returns the variance of the array elements, a measure of the spread of a
  3631|         0|            0|            0|  0.00%|    distribution.  The variance is computed for the flattened array by
  3632|         0|            0|            0|  0.00%|    default, otherwise over the specified axis.
  3633|         0|            0|            0|  0.00%|
  3634|         0|            0|            0|  0.00%|    Parameters
  3635|         0|            0|            0|  0.00%|    ----------
  3636|         0|            0|            0|  0.00%|    a : array_like
  3637|         0|            0|            0|  0.00%|        Array containing numbers whose variance is desired.  If `a` is not an
  3638|         0|            0|            0|  0.00%|        array, a conversion is attempted.
  3639|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  3640|         0|            0|            0|  0.00%|        Axis or axes along which the variance is computed.  The default is to
  3641|         0|            0|            0|  0.00%|        compute the variance of the flattened array.
  3642|         0|            0|            0|  0.00%|
  3643|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  3644|         0|            0|            0|  0.00%|
  3645|         0|            0|            0|  0.00%|        If this is a tuple of ints, a variance is performed over multiple axes,
  3646|         0|            0|            0|  0.00%|        instead of a single axis or all the axes as before.
  3647|         0|            0|            0|  0.00%|    dtype : data-type, optional
  3648|         0|            0|            0|  0.00%|        Type to use in computing the variance.  For arrays of integer type
  3649|         0|            0|            0|  0.00%|        the default is `float64`; for arrays of float types it is the same as
  3650|         0|            0|            0|  0.00%|        the array type.
  3651|         0|            0|            0|  0.00%|    out : ndarray, optional
  3652|         0|            0|            0|  0.00%|        Alternate output array in which to place the result.  It must have
  3653|         0|            0|            0|  0.00%|        the same shape as the expected output, but the type is cast if
  3654|         0|            0|            0|  0.00%|        necessary.
  3655|         0|            0|            0|  0.00%|    ddof : int, optional
  3656|         0|            0|            0|  0.00%|        "Delta Degrees of Freedom": the divisor used in the calculation is
  3657|         0|            0|            0|  0.00%|        ``N - ddof``, where ``N`` represents the number of elements. By
  3658|         0|            0|            0|  0.00%|        default `ddof` is zero.
  3659|         0|            0|            0|  0.00%|    keepdims : bool, optional
  3660|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  3661|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  3662|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  3663|         0|            0|            0|  0.00%|
  3664|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  3665|         0|            0|            0|  0.00%|        passed through to the `var` method of sub-classes of
  3666|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  3667|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  3668|         0|            0|            0|  0.00%|        exceptions will be raised.
  3669|         0|            0|            0|  0.00%|
  3670|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  3671|         0|            0|            0|  0.00%|        Elements to include in the variance. See `~numpy.ufunc.reduce` for
  3672|         0|            0|            0|  0.00%|        details.
  3673|         0|            0|            0|  0.00%|
  3674|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
  3675|         0|            0|            0|  0.00%|
  3676|         0|            0|            0|  0.00%|    Returns
  3677|         0|            0|            0|  0.00%|    -------
  3678|         0|            0|            0|  0.00%|    variance : ndarray, see dtype parameter above
  3679|         0|            0|            0|  0.00%|        If ``out=None``, returns a new array containing the variance;
  3680|         0|            0|            0|  0.00%|        otherwise, a reference to the output array is returned.
  3681|         0|            0|            0|  0.00%|
  3682|         0|            0|            0|  0.00%|    See Also
  3683|         0|            0|            0|  0.00%|    --------
  3684|         0|            0|            0|  0.00%|    std, mean, nanmean, nanstd, nanvar
  3685|         0|            0|            0|  0.00%|    :ref:`ufuncs-output-type`
  3686|         0|            0|            0|  0.00%|
  3687|         0|            0|            0|  0.00%|    Notes
  3688|         0|            0|            0|  0.00%|    -----
  3689|         0|            0|            0|  0.00%|    The variance is the average of the squared deviations from the mean,
  3690|         0|            0|            0|  0.00%|    i.e.,  ``var = mean(x)``, where ``x = abs(a - a.mean())**2``.
  3691|         0|            0|            0|  0.00%|
  3692|         0|            0|            0|  0.00%|    The mean is typically calculated as ``x.sum() / N``, where ``N = len(x)``.
  3693|         0|            0|            0|  0.00%|    If, however, `ddof` is specified, the divisor ``N - ddof`` is used
  3694|         0|            0|            0|  0.00%|    instead.  In standard statistical practice, ``ddof=1`` provides an
  3695|         0|            0|            0|  0.00%|    unbiased estimator of the variance of a hypothetical infinite population.
  3696|         0|            0|            0|  0.00%|    ``ddof=0`` provides a maximum likelihood estimate of the variance for
  3697|         0|            0|            0|  0.00%|    normally distributed variables.
  3698|         0|            0|            0|  0.00%|
  3699|         0|            0|            0|  0.00%|    Note that for complex numbers, the absolute value is taken before
  3700|         0|            0|            0|  0.00%|    squaring, so that the result is always real and nonnegative.
  3701|         0|            0|            0|  0.00%|
  3702|         0|            0|            0|  0.00%|    For floating-point input, the variance is computed using the same
  3703|         0|            0|            0|  0.00%|    precision the input has.  Depending on the input data, this can cause
  3704|         0|            0|            0|  0.00%|    the results to be inaccurate, especially for `float32` (see example
  3705|         0|            0|            0|  0.00%|    below).  Specifying a higher-accuracy accumulator using the ``dtype``
  3706|         0|            0|            0|  0.00%|    keyword can alleviate this issue.
  3707|         0|            0|            0|  0.00%|
  3708|         0|            0|            0|  0.00%|    Examples
  3709|         0|            0|            0|  0.00%|    --------
  3710|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2], [3, 4]])
  3711|         0|            0|            0|  0.00%|    >>> np.var(a)
  3712|         0|            0|            0|  0.00%|    1.25
  3713|         0|            0|            0|  0.00%|    >>> np.var(a, axis=0)
  3714|         0|            0|            0|  0.00%|    array([1.,  1.])
  3715|         0|            0|            0|  0.00%|    >>> np.var(a, axis=1)
  3716|         0|            0|            0|  0.00%|    array([0.25,  0.25])
  3717|         0|            0|            0|  0.00%|
  3718|         0|            0|            0|  0.00%|    In single precision, var() can be inaccurate:
  3719|         0|            0|            0|  0.00%|
  3720|         0|            0|            0|  0.00%|    >>> a = np.zeros((2, 512*512), dtype=np.float32)
  3721|         0|            0|            0|  0.00%|    >>> a[0, :] = 1.0
  3722|         0|            0|            0|  0.00%|    >>> a[1, :] = 0.1
  3723|         0|            0|            0|  0.00%|    >>> np.var(a)
  3724|         0|            0|            0|  0.00%|    0.20250003
  3725|         0|            0|            0|  0.00%|
  3726|         0|            0|            0|  0.00%|    Computing the variance in float64 is more accurate:
  3727|         0|            0|            0|  0.00%|
  3728|         0|            0|            0|  0.00%|    >>> np.var(a, dtype=np.float64)
  3729|         0|            0|            0|  0.00%|    0.20249999932944759 # may vary
  3730|         0|            0|            0|  0.00%|    >>> ((1-0.55)**2 + (0.1-0.55)**2)/2
  3731|         0|            0|            0|  0.00%|    0.2025
  3732|         0|            0|            0|  0.00%|
  3733|         0|            0|            0|  0.00%|    Specifying a where argument:
  3734|         0|            0|            0|  0.00%|
  3735|         0|            0|            0|  0.00%|    >>> a = np.array([[14, 8, 11, 10], [7, 9, 10, 11], [10, 15, 5, 10]])
  3736|         0|            0|            0|  0.00%|    >>> np.var(a)
  3737|         0|            0|            0|  0.00%|    6.833333333333333 # may vary
  3738|         0|            0|            0|  0.00%|    >>> np.var(a, where=[[True], [True], [False]])
  3739|         0|            0|            0|  0.00%|    4.0
  3740|         0|            0|            0|  0.00%|
  3741|         0|            0|            0|  0.00%|    """
  3742|        36|  9.65595e-05|  2.68221e-06|  0.00%|    kwargs = {}
  3743|        36|  9.91821e-05|  2.75506e-06|  0.00%|    if keepdims is not np._NoValue:
  3744|         0|            0|            0|  0.00%|        kwargs['keepdims'] = keepdims
  3745|        36|  8.41618e-05|  2.33783e-06|  0.00%|    if where is not np._NoValue:
  3746|         0|            0|            0|  0.00%|        kwargs['where'] = where
  3747|         0|            0|            0|  0.00%|
  3748|        36|  0.000123501|  3.43058e-06|  0.00%|    if type(a) is not mu.ndarray:
  3749|         0|            0|            0|  0.00%|        try:
  3750|         0|            0|            0|  0.00%|            var = a.var
  3751|         0|            0|            0|  0.00%|
  3752|         0|            0|            0|  0.00%|        except AttributeError:
  3753|         0|            0|            0|  0.00%|            pass
  3754|         0|            0|            0|  0.00%|        else:
  3755|         0|            0|            0|  0.00%|            return var(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)
  3756|         0|            0|            0|  0.00%|
  3757|        72|  0.000576735|   8.0102e-06|  0.00%|    return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,
(call)|        36|   0.00579286|  0.000160913|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/_methods.py:195 _var
  3758|        36|  7.93934e-05|  2.20537e-06|  0.00%|                         **kwargs)
  3759|         0|            0|            0|  0.00%|
  3760|         0|            0|            0|  0.00%|
  3761|         0|            0|            0|  0.00%|# Aliases of other functions. These have their own definitions only so that
  3762|         0|            0|            0|  0.00%|# they can have unique docstrings.
  3763|         0|            0|            0|  0.00%|
  3764|         0|            0|            0|  0.00%|@array_function_dispatch(_around_dispatcher)
  3765|         0|            0|            0|  0.00%|def round_(a, decimals=0, out=None):
  3766|         0|            0|            0|  0.00%|    """
  3767|         0|            0|            0|  0.00%|    Round an array to the given number of decimals.
  3768|         0|            0|            0|  0.00%|
  3769|         0|            0|            0|  0.00%|    See Also
  3770|         0|            0|            0|  0.00%|    --------
  3771|         0|            0|            0|  0.00%|    around : equivalent function; see for details.
  3772|         0|            0|            0|  0.00%|    """
  3773|         0|            0|            0|  0.00%|    return around(a, decimals=decimals, out=out)
  3774|         0|            0|            0|  0.00%|
  3775|         0|            0|            0|  0.00%|
  3776|         0|            0|            0|  0.00%|@array_function_dispatch(_prod_dispatcher, verify=False)
  3777|         0|            0|            0|  0.00%|def product(*args, **kwargs):
  3778|         0|            0|            0|  0.00%|    """
  3779|         0|            0|            0|  0.00%|    Return the product of array elements over a given axis.
  3780|         0|            0|            0|  0.00%|
  3781|         0|            0|            0|  0.00%|    See Also
  3782|         0|            0|            0|  0.00%|    --------
  3783|         0|            0|            0|  0.00%|    prod : equivalent function; see for details.
  3784|         0|            0|            0|  0.00%|    """
  3785|         0|            0|            0|  0.00%|    return prod(*args, **kwargs)
  3786|         0|            0|            0|  0.00%|
  3787|         0|            0|            0|  0.00%|
  3788|         0|            0|            0|  0.00%|@array_function_dispatch(_cumprod_dispatcher, verify=False)
  3789|         0|            0|            0|  0.00%|def cumproduct(*args, **kwargs):
  3790|         0|            0|            0|  0.00%|    """
  3791|         0|            0|            0|  0.00%|    Return the cumulative product over the given axis.
  3792|         0|            0|            0|  0.00%|
  3793|         0|            0|            0|  0.00%|    See Also
  3794|         0|            0|            0|  0.00%|    --------
  3795|         0|            0|            0|  0.00%|    cumprod : equivalent function; see for details.
  3796|         0|            0|            0|  0.00%|    """
  3797|         0|            0|            0|  0.00%|    return cumprod(*args, **kwargs)
  3798|         0|            0|            0|  0.00%|
  3799|         0|            0|            0|  0.00%|
  3800|         0|            0|            0|  0.00%|@array_function_dispatch(_any_dispatcher, verify=False)
  3801|         0|            0|            0|  0.00%|def sometrue(*args, **kwargs):
  3802|         0|            0|            0|  0.00%|    """
  3803|         0|            0|            0|  0.00%|    Check whether some values are true.
  3804|         0|            0|            0|  0.00%|
  3805|         0|            0|            0|  0.00%|    Refer to `any` for full documentation.
  3806|         0|            0|            0|  0.00%|
  3807|         0|            0|            0|  0.00%|    See Also
  3808|         0|            0|            0|  0.00%|    --------
  3809|         0|            0|            0|  0.00%|    any : equivalent function; see for details.
  3810|         0|            0|            0|  0.00%|    """
  3811|         0|            0|            0|  0.00%|    return any(*args, **kwargs)
  3812|         0|            0|            0|  0.00%|
  3813|         0|            0|            0|  0.00%|
  3814|         0|            0|            0|  0.00%|@array_function_dispatch(_all_dispatcher, verify=False)
  3815|         0|            0|            0|  0.00%|def alltrue(*args, **kwargs):
  3816|         0|            0|            0|  0.00%|    """
  3817|         0|            0|            0|  0.00%|    Check if all elements of input array are true.
  3818|         0|            0|            0|  0.00%|
  3819|         0|            0|            0|  0.00%|    See Also
  3820|         0|            0|            0|  0.00%|    --------
  3821|         0|            0|            0|  0.00%|    numpy.all : Equivalent function; see for details.
  3822|         0|            0|            0|  0.00%|    """
  3823|         0|            0|            0|  0.00%|    return all(*args, **kwargs)
File: /apps/open_spiel/open_spiel/python/vector_env.py
File duration: 0.754794s (0.72%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|class SyncVectorEnv(object):
     2|         0|            0|            0|  0.00%|    """
     3|         0|            0|            0|  0.00%|    A vectorized RL Environment. This environment is synchronized - games do not execute in parallel. Speedups are realized by calling models on many game states simultaneously.
     4|         0|            0|            0|  0.00%|    """
     5|         0|            0|            0|  0.00%|    def __init__(self, envs):
     6|         0|            0|            0|  0.00%|        if not isinstance(envs, list):
     7|         0|            0|            0|  0.00%|            raise ValueError("Need to call this with a list of rl_environment.Environment objects")
     8|         0|            0|            0|  0.00%|        self.envs = envs
     9|         0|            0|            0|  0.00%|
    10|         1|  4.52995e-06|  4.52995e-06|  0.00%|    def __len__(self):
    11|         1|  7.86781e-06|  7.86781e-06|  0.00%|        return len(self.envs)
    12|         0|            0|            0|  0.00%|
    13|         0|            0|            0|  0.00%|    def observation_spec(self):
    14|         0|            0|            0|  0.00%|        return self.envs[0].observation_spec()
    15|         0|            0|            0|  0.00%|
    16|         0|            0|            0|  0.00%|    @property
    17|         0|            0|            0|  0.00%|    def num_players(self):
    18|         0|            0|            0|  0.00%|        return self.envs[0].num_players
    19|         0|            0|            0|  0.00%|
    20|      2304|    0.0104892|  4.55262e-06|  0.01%|    def step(self, step_outputs, reset_if_done=False):
    21|         0|            0|            0|  0.00%|        '''
    22|         0|            0|            0|  0.00%|        reset_if_done: if True, automatically reset the environment when the epsiode ends
    23|         0|            0|            0|  0.00%|        '''
    24|      2304|   0.00935078|   4.0585e-06|  0.01%|        if not isinstance(step_outputs, list):
    25|         0|            0|            0|  0.00%|            step_outputs = [step_outputs]
    26|         0|            0|            0|  0.00%|
    27|     25344|     0.302278|   1.1927e-05|  0.29%|        time_steps = [self.envs[i].step([step_outputs[i].action]) for i in range(len(self.envs))]
(call)|     18432|      64.4167|   0.00349483| 61.72%|# /apps/open_spiel/open_spiel/python/env_decorator.py:29 step
(call)|      2304|      64.6912|    0.0280778| 61.98%|# /apps/open_spiel/open_spiel/python/vector_env.py:27 <listcomp>
    28|     25344|    0.0565958|   2.2331e-06|  0.05%|        reward = [step.rewards for step in time_steps]
(call)|      2304|    0.0381575|  1.65614e-05|  0.04%|# /apps/open_spiel/open_spiel/python/vector_env.py:28 <listcomp>
    29|     25344|     0.115081|  4.54076e-06|  0.11%|        done = [step.last() for step in time_steps]
(call)|     18432|    0.0575778|   3.1238e-06|  0.06%|# /apps/open_spiel/open_spiel/python/rl_environment.py:94 last
(call)|      2304|     0.155912|  6.76703e-05|  0.15%|# /apps/open_spiel/open_spiel/python/vector_env.py:29 <listcomp>
    30|      2304|   0.00592136|  2.57004e-06|  0.01%|        unreset_time_steps = time_steps # Copy these because you may want to look at the unreset versions to extract information from them
    31|         0|            0|            0|  0.00%|
    32|      2304|   0.00549388|   2.3845e-06|  0.01%|        if reset_if_done:
    33|      2304|    0.0233631|  1.01402e-05|  0.02%|            time_steps = self.reset(envs_to_reset=done)
(call)|      2304|      29.0818|    0.0126223| 27.86%|# /apps/open_spiel/open_spiel/python/vector_env.py:37 reset
    34|         0|            0|            0|  0.00%|
    35|      2304|   0.00624824|  2.71191e-06|  0.01%|        return time_steps, reward, done, unreset_time_steps
    36|         0|            0|            0|  0.00%|
    37|      2305|   0.00589514|  2.55754e-06|  0.01%|    def reset(self, envs_to_reset=None):
    38|      2305|   0.00569201|  2.46942e-06|  0.01%|        if envs_to_reset is None:
    39|        11|  2.76566e-05|  2.51423e-06|  0.00%|            envs_to_reset = [True for _ in range(len(self.envs))]
(call)|         1|  1.71661e-05|  1.71661e-05|  0.00%|# /apps/open_spiel/open_spiel/python/vector_env.py:39 <listcomp>
    40|         0|            0|            0|  0.00%|
    41|     25355|      0.20287|  8.00119e-06|  0.19%|        time_steps = [self.envs[i].reset() if envs_to_reset[i] else self.envs[i].get_time_step() for i in range(len(self.envs))]
(call)|      1349|      4.49834|   0.00333458|  4.31%|# /apps/open_spiel/open_spiel/python/env_decorator.py:33 reset
(call)|      2305|      29.0705|    0.0126119| 27.85%|# /apps/open_spiel/open_spiel/python/vector_env.py:41 <listcomp>
(call)|     17091|      24.3917|   0.00142717| 23.37%|# /apps/open_spiel/open_spiel/python/env_decorator.py:48 get_time_step
    42|      2305|   0.00547576|   2.3756e-06|  0.01%|        return time_steps
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/categorical.py
File duration: 0.733382s (0.70%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import torch
     2|         0|            0|            0|  0.00%|from torch._six import nan
     3|         0|            0|            0|  0.00%|from torch.distributions import constraints
     4|         0|            0|            0|  0.00%|from torch.distributions.distribution import Distribution
     5|         0|            0|            0|  0.00%|from torch.distributions.utils import probs_to_logits, logits_to_probs, lazy_property
     6|         0|            0|            0|  0.00%|
     7|         0|            0|            0|  0.00%|
     8|         0|            0|            0|  0.00%|class Categorical(Distribution):
     9|         0|            0|            0|  0.00%|    r"""
    10|         0|            0|            0|  0.00%|    Creates a categorical distribution parameterized by either :attr:`probs` or
    11|         0|            0|            0|  0.00%|    :attr:`logits` (but not both).
    12|         0|            0|            0|  0.00%|
    13|         0|            0|            0|  0.00%|    .. note::
    14|         0|            0|            0|  0.00%|        It is equivalent to the distribution that :func:`torch.multinomial`
    15|         0|            0|            0|  0.00%|        samples from.
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|    Samples are integers from :math:`\{0, \ldots, K-1\}` where `K` is ``probs.size(-1)``.
    18|         0|            0|            0|  0.00%|
    19|         0|            0|            0|  0.00%|    If `probs` is 1-dimensional with length-`K`, each element is the relative probability
    20|         0|            0|            0|  0.00%|    of sampling the class at that index.
    21|         0|            0|            0|  0.00%|
    22|         0|            0|            0|  0.00%|    If `probs` is N-dimensional, the first N-1 dimensions are treated as a batch of
    23|         0|            0|            0|  0.00%|    relative probability vectors.
    24|         0|            0|            0|  0.00%|
    25|         0|            0|            0|  0.00%|    .. note:: The `probs` argument must be non-negative, finite and have a non-zero sum,
    26|         0|            0|            0|  0.00%|              and it will be normalized to sum to 1 along the last dimension. :attr:`probs`
    27|         0|            0|            0|  0.00%|              will return this normalized value.
    28|         0|            0|            0|  0.00%|              The `logits` argument will be interpreted as unnormalized log probabilities
    29|         0|            0|            0|  0.00%|              and can therefore be any real number. It will likewise be normalized so that
    30|         0|            0|            0|  0.00%|              the resulting probabilities sum to 1 along the last dimension. :attr:`logits`
    31|         0|            0|            0|  0.00%|              will return this normalized value.
    32|         0|            0|            0|  0.00%|
    33|         0|            0|            0|  0.00%|    See also: :func:`torch.multinomial`
    34|         0|            0|            0|  0.00%|
    35|         0|            0|            0|  0.00%|    Example::
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|        >>> m = Categorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))
    38|         0|            0|            0|  0.00%|        >>> m.sample()  # equal probability of 0, 1, 2, 3
    39|         0|            0|            0|  0.00%|        tensor(3)
    40|         0|            0|            0|  0.00%|
    41|         0|            0|            0|  0.00%|    Args:
    42|         0|            0|            0|  0.00%|        probs (Tensor): event probabilities
    43|         0|            0|            0|  0.00%|        logits (Tensor): event log probabilities (unnormalized)
    44|         0|            0|            0|  0.00%|    """
    45|         0|            0|            0|  0.00%|    arg_constraints = {'probs': constraints.simplex,
    46|         0|            0|            0|  0.00%|                       'logits': constraints.real_vector}
    47|         0|            0|            0|  0.00%|    has_enumerate_support = True
    48|         0|            0|            0|  0.00%|
    49|      2610|   0.00801635|   3.0714e-06|  0.01%|    def __init__(self, probs=None, logits=None, validate_args=None):
    50|      2610|   0.00836396|  3.20458e-06|  0.01%|        if (probs is None) == (logits is None):
    51|         0|            0|            0|  0.00%|            raise ValueError("Either `probs` or `logits` must be specified, but not both.")
    52|      2610|   0.00683236|  2.61776e-06|  0.01%|        if probs is not None:
    53|         0|            0|            0|  0.00%|            if probs.dim() < 1:
    54|         0|            0|            0|  0.00%|                raise ValueError("`probs` parameter must be at least one-dimensional.")
    55|         0|            0|            0|  0.00%|            self.probs = probs / probs.sum(-1, keepdim=True)
    56|         0|            0|            0|  0.00%|        else:
    57|      2610|   0.00818205|  3.13488e-06|  0.01%|            if logits.dim() < 1:
    58|         0|            0|            0|  0.00%|                raise ValueError("`logits` parameter must be at least one-dimensional.")
    59|         0|            0|            0|  0.00%|            # Normalize
    60|      2610|     0.199004|  7.62467e-05|  0.19%|            self.logits = logits - logits.logsumexp(dim=-1, keepdim=True)
    61|      2610|    0.0128241|  4.91343e-06|  0.01%|        self._param = self.probs if probs is not None else self.logits
    62|      2610|    0.0122368|  4.68844e-06|  0.01%|        self._num_events = self._param.size()[-1]
    63|      2610|    0.0149937|   5.7447e-06|  0.01%|        batch_shape = self._param.size()[:-1] if self._param.ndimension() > 1 else torch.Size()
    64|      2610|    0.0305796|  1.17163e-05|  0.03%|        super(Categorical, self).__init__(batch_shape, validate_args=validate_args)
(call)|      2610|     0.453619|    0.0001738|  0.43%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/distribution.py:34 __init__
    65|         0|            0|            0|  0.00%|
    66|         0|            0|            0|  0.00%|    def expand(self, batch_shape, _instance=None):
    67|         0|            0|            0|  0.00%|        new = self._get_checked_instance(Categorical, _instance)
    68|         0|            0|            0|  0.00%|        batch_shape = torch.Size(batch_shape)
    69|         0|            0|            0|  0.00%|        param_shape = batch_shape + torch.Size((self._num_events,))
    70|         0|            0|            0|  0.00%|        if 'probs' in self.__dict__:
    71|         0|            0|            0|  0.00%|            new.probs = self.probs.expand(param_shape)
    72|         0|            0|            0|  0.00%|            new._param = new.probs
    73|         0|            0|            0|  0.00%|        if 'logits' in self.__dict__:
    74|         0|            0|            0|  0.00%|            new.logits = self.logits.expand(param_shape)
    75|         0|            0|            0|  0.00%|            new._param = new.logits
    76|         0|            0|            0|  0.00%|        new._num_events = self._num_events
    77|         0|            0|            0|  0.00%|        super(Categorical, new).__init__(batch_shape, validate_args=False)
    78|         0|            0|            0|  0.00%|        new._validate_args = self._validate_args
    79|         0|            0|            0|  0.00%|        return new
    80|         0|            0|            0|  0.00%|
    81|         0|            0|            0|  0.00%|    def _new(self, *args, **kwargs):
    82|         0|            0|            0|  0.00%|        return self._param.new(*args, **kwargs)
    83|         0|            0|            0|  0.00%|
    84|      2610|   0.00488043|   1.8699e-06|  0.00%|    @constraints.dependent_property(is_discrete=True, event_dim=0)
    85|         0|            0|            0|  0.00%|    def support(self):
    86|      2610|    0.0207031|  7.93221e-06|  0.02%|        return constraints.integer_interval(0, self._num_events - 1)
(call)|      2610|    0.0255868|  9.80339e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/constraints.py:251 __init__
    87|         0|            0|            0|  0.00%|
    88|         0|            0|            0|  0.00%|    @lazy_property
    89|         0|            0|            0|  0.00%|    def logits(self):
    90|         0|            0|            0|  0.00%|        return probs_to_logits(self.probs)
    91|         0|            0|            0|  0.00%|
    92|      2610|   0.00416327|  1.59512e-06|  0.00%|    @lazy_property
    93|         0|            0|            0|  0.00%|    def probs(self):
    94|      2610|    0.0174286|  6.67764e-06|  0.02%|        return logits_to_probs(self.logits)
(call)|      2610|     0.100044|   3.8331e-05|  0.10%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/utils.py:65 logits_to_probs
    95|         0|            0|            0|  0.00%|
    96|         0|            0|            0|  0.00%|    @property
    97|         0|            0|            0|  0.00%|    def param_shape(self):
    98|         0|            0|            0|  0.00%|        return self._param.size()
    99|         0|            0|            0|  0.00%|
   100|         0|            0|            0|  0.00%|    @property
   101|         0|            0|            0|  0.00%|    def mean(self):
   102|         0|            0|            0|  0.00%|        return torch.full(self._extended_shape(), nan, dtype=self.probs.dtype, device=self.probs.device)
   103|         0|            0|            0|  0.00%|
   104|         0|            0|            0|  0.00%|    @property
   105|         0|            0|            0|  0.00%|    def mode(self):
   106|         0|            0|            0|  0.00%|        return self.probs.argmax(axis=-1)
   107|         0|            0|            0|  0.00%|
   108|         0|            0|            0|  0.00%|    @property
   109|         0|            0|            0|  0.00%|    def variance(self):
   110|         0|            0|            0|  0.00%|        return torch.full(self._extended_shape(), nan, dtype=self.probs.dtype, device=self.probs.device)
   111|         0|            0|            0|  0.00%|
   112|      2304|   0.00594616|   2.5808e-06|  0.01%|    def sample(self, sample_shape=torch.Size()):
   113|      2304|   0.00710225|  3.08257e-06|  0.01%|        if not isinstance(sample_shape, torch.Size):
   114|         0|            0|            0|  0.00%|            sample_shape = torch.Size(sample_shape)
   115|      2304|    0.0290496|  1.26083e-05|  0.03%|        probs_2d = self.probs.reshape(-1, self._num_events)
(call)|      2304|      0.19608|  8.51042e-05|  0.19%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/utils.py:106 __get__
   116|      2304|    0.0397081|  1.72344e-05|  0.04%|        samples_2d = torch.multinomial(probs_2d, sample_shape.numel(), True).T
   117|      2304|    0.0275686|  1.19655e-05|  0.03%|        return samples_2d.reshape(self._extended_shape(sample_shape))
(call)|      2304|    0.0182559|  7.92359e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/distribution.py:241 _extended_shape
   118|         0|            0|            0|  0.00%|
   119|      2610|   0.00622964|  2.38683e-06|  0.01%|    def log_prob(self, value):
   120|      2610|   0.00629735|  2.41278e-06|  0.01%|        if self._validate_args:
   121|      2610|    0.0266044|  1.01933e-05|  0.03%|            self._validate_sample(value)
(call)|      2610|     0.369444|  0.000141549|  0.35%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/distribution.py:255 _validate_sample
   122|      2610|    0.0236487|  9.06082e-06|  0.02%|        value = value.long().unsqueeze(-1)
   123|      2610|    0.0227497|  8.71635e-06|  0.02%|        value, log_pmf = torch.broadcast_tensors(value, self.logits)
(call)|      2610|    0.0822089|  3.14977e-05|  0.08%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/functional.py:44 broadcast_tensors
   124|      2610|     0.021065|  8.07088e-06|  0.02%|        value = value[..., :1]
   125|      2610|    0.0398228|  1.52578e-05|  0.04%|        return log_pmf.gather(-1, value).squeeze(-1)
   126|         0|            0|            0|  0.00%|
   127|      2610|   0.00646639|  2.47754e-06|  0.01%|    def entropy(self):
   128|      2610|    0.0125375|  4.80363e-06|  0.01%|        min_real = torch.finfo(self.logits.dtype).min
   129|      2610|    0.0305016|  1.16864e-05|  0.03%|        logits = torch.clamp(self.logits, min=min_real)
   130|      2610|     0.025995|  9.95978e-06|  0.02%|        p_log_p = logits * self.probs
(call)|       306|    0.0335727|  0.000109715|  0.03%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/utils.py:106 __get__
   131|      2610|    0.0538809|   2.0644e-05|  0.05%|        return -p_log_p.sum(-1)
   132|         0|            0|            0|  0.00%|
   133|         0|            0|            0|  0.00%|    def enumerate_support(self, expand=True):
   134|         0|            0|            0|  0.00%|        num_events = self._num_events
   135|         0|            0|            0|  0.00%|        values = torch.arange(num_events, dtype=torch.long, device=self._param.device)
   136|         0|            0|            0|  0.00%|        values = values.view((-1,) + (1,) * len(self._batch_shape))
   137|         0|            0|            0|  0.00%|        if expand:
   138|         0|            0|            0|  0.00%|            values = values.expand((-1,) + self._batch_shape)
   139|         0|            0|            0|  0.00%|        return values
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/optim/adam.py
File duration: 0.635546s (0.61%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import math
     2|         0|            0|            0|  0.00%|import torch
     3|         0|            0|            0|  0.00%|from torch import Tensor
     4|         0|            0|            0|  0.00%|from .optimizer import Optimizer
     5|         0|            0|            0|  0.00%|from typing import List, Optional
     6|         0|            0|            0|  0.00%|
     7|         0|            0|            0|  0.00%|
     8|         0|            0|            0|  0.00%|class Adam(Optimizer):
     9|         0|            0|            0|  0.00%|    r"""Implements Adam algorithm.
    10|         0|            0|            0|  0.00%|
    11|         0|            0|            0|  0.00%|    .. math::
    12|         0|            0|            0|  0.00%|       \begin{aligned}
    13|         0|            0|            0|  0.00%|            &\rule{110mm}{0.4pt}                                                                 \\
    14|         0|            0|            0|  0.00%|            &\textbf{input}      : \gamma \text{ (lr)}, \beta_1, \beta_2
    15|         0|            0|            0|  0.00%|                \text{ (betas)},\theta_0 \text{ (params)},f(\theta) \text{ (objective)}          \\
    16|         0|            0|            0|  0.00%|            &\hspace{13mm}      \lambda \text{ (weight decay)},  \: \textit{amsgrad},
    17|         0|            0|            0|  0.00%|                \:\textit{maximize}                                                              \\
    18|         0|            0|            0|  0.00%|            &\textbf{initialize} :  m_0 \leftarrow 0 \text{ ( first moment)},
    19|         0|            0|            0|  0.00%|                v_0\leftarrow 0 \text{ (second moment)},\: \widehat{v_0}^{max}\leftarrow 0\\[-1.ex]
    20|         0|            0|            0|  0.00%|            &\rule{110mm}{0.4pt}                                                                 \\
    21|         0|            0|            0|  0.00%|            &\textbf{for} \: t=1 \: \textbf{to} \: \ldots \: \textbf{do}                         \\
    22|         0|            0|            0|  0.00%|
    23|         0|            0|            0|  0.00%|            &\hspace{5mm}\textbf{if} \: \textit{maximize}:                                       \\
    24|         0|            0|            0|  0.00%|            &\hspace{10mm}g_t           \leftarrow   -\nabla_{\theta} f_t (\theta_{t-1})         \\
    25|         0|            0|            0|  0.00%|            &\hspace{5mm}\textbf{else}                                                           \\
    26|         0|            0|            0|  0.00%|            &\hspace{10mm}g_t           \leftarrow   \nabla_{\theta} f_t (\theta_{t-1})          \\
    27|         0|            0|            0|  0.00%|            &\hspace{5mm}\textbf{if} \: \lambda \neq 0                                           \\
    28|         0|            0|            0|  0.00%|            &\hspace{10mm} g_t \leftarrow g_t + \lambda  \theta_{t-1}                            \\
    29|         0|            0|            0|  0.00%|            &\hspace{5mm}m_t           \leftarrow   \beta_1 m_{t-1} + (1 - \beta_1) g_t          \\
    30|         0|            0|            0|  0.00%|            &\hspace{5mm}v_t           \leftarrow   \beta_2 v_{t-1} + (1-\beta_2) g^2_t          \\
    31|         0|            0|            0|  0.00%|            &\hspace{5mm}\widehat{m_t} \leftarrow   m_t/\big(1-\beta_1^t \big)                   \\
    32|         0|            0|            0|  0.00%|            &\hspace{5mm}\widehat{v_t} \leftarrow   v_t/\big(1-\beta_2^t \big)                   \\
    33|         0|            0|            0|  0.00%|            &\hspace{5mm}\textbf{if} \: amsgrad                                                  \\
    34|         0|            0|            0|  0.00%|            &\hspace{10mm}\widehat{v_t}^{max} \leftarrow \mathrm{max}(\widehat{v_t}^{max},
    35|         0|            0|            0|  0.00%|                \widehat{v_t})                                                                   \\
    36|         0|            0|            0|  0.00%|            &\hspace{10mm}\theta_t \leftarrow \theta_{t-1} - \gamma \widehat{m_t}/
    37|         0|            0|            0|  0.00%|                \big(\sqrt{\widehat{v_t}^{max}} + \epsilon \big)                                 \\
    38|         0|            0|            0|  0.00%|            &\hspace{5mm}\textbf{else}                                                           \\
    39|         0|            0|            0|  0.00%|            &\hspace{10mm}\theta_t \leftarrow \theta_{t-1} - \gamma \widehat{m_t}/
    40|         0|            0|            0|  0.00%|                \big(\sqrt{\widehat{v_t}} + \epsilon \big)                                       \\
    41|         0|            0|            0|  0.00%|            &\rule{110mm}{0.4pt}                                                          \\[-1.ex]
    42|         0|            0|            0|  0.00%|            &\bf{return} \:  \theta_t                                                     \\[-1.ex]
    43|         0|            0|            0|  0.00%|            &\rule{110mm}{0.4pt}                                                          \\[-1.ex]
    44|         0|            0|            0|  0.00%|       \end{aligned}
    45|         0|            0|            0|  0.00%|
    46|         0|            0|            0|  0.00%|    For further details regarding the algorithm we refer to `Adam: A Method for Stochastic Optimization`_.
    47|         0|            0|            0|  0.00%|
    48|         0|            0|            0|  0.00%|    Args:
    49|         0|            0|            0|  0.00%|        params (iterable): iterable of parameters to optimize or dicts defining
    50|         0|            0|            0|  0.00%|            parameter groups
    51|         0|            0|            0|  0.00%|        lr (float, optional): learning rate (default: 1e-3)
    52|         0|            0|            0|  0.00%|        betas (Tuple[float, float], optional): coefficients used for computing
    53|         0|            0|            0|  0.00%|            running averages of gradient and its square (default: (0.9, 0.999))
    54|         0|            0|            0|  0.00%|        eps (float, optional): term added to the denominator to improve
    55|         0|            0|            0|  0.00%|            numerical stability (default: 1e-8)
    56|         0|            0|            0|  0.00%|        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)
    57|         0|            0|            0|  0.00%|        amsgrad (boolean, optional): whether to use the AMSGrad variant of this
    58|         0|            0|            0|  0.00%|            algorithm from the paper `On the Convergence of Adam and Beyond`_
    59|         0|            0|            0|  0.00%|            (default: False)
    60|         0|            0|            0|  0.00%|        foreach (bool, optional): whether foreach implementation of optimizer
    61|         0|            0|            0|  0.00%|            is used (default: None)
    62|         0|            0|            0|  0.00%|        maximize (bool, optional): maximize the params based on the objective, instead of
    63|         0|            0|            0|  0.00%|            minimizing (default: False)
    64|         0|            0|            0|  0.00%|        capturable (bool, optional): whether this instance is safe to capture in a CUDA graph.
    65|         0|            0|            0|  0.00%|            Passing True can impair ungraphed performance, so if you don't intend to
    66|         0|            0|            0|  0.00%|            graph capture this instance, leave it False (default: False)
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|    .. _Adam\: A Method for Stochastic Optimization:
    69|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1412.6980
    70|         0|            0|            0|  0.00%|    .. _On the Convergence of Adam and Beyond:
    71|         0|            0|            0|  0.00%|        https://openreview.net/forum?id=ryQu7f-RZ
    72|         0|            0|            0|  0.00%|    """
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,
    75|         0|            0|            0|  0.00%|                 weight_decay=0, amsgrad=False, *, foreach: Optional[bool] = None,
    76|         0|            0|            0|  0.00%|                 maximize: bool = False, capturable: bool = False):
    77|         0|            0|            0|  0.00%|        if not 0.0 <= lr:
    78|         0|            0|            0|  0.00%|            raise ValueError("Invalid learning rate: {}".format(lr))
    79|         0|            0|            0|  0.00%|        if not 0.0 <= eps:
    80|         0|            0|            0|  0.00%|            raise ValueError("Invalid epsilon value: {}".format(eps))
    81|         0|            0|            0|  0.00%|        if not 0.0 <= betas[0] < 1.0:
    82|         0|            0|            0|  0.00%|            raise ValueError("Invalid beta parameter at index 0: {}".format(betas[0]))
    83|         0|            0|            0|  0.00%|        if not 0.0 <= betas[1] < 1.0:
    84|         0|            0|            0|  0.00%|            raise ValueError("Invalid beta parameter at index 1: {}".format(betas[1]))
    85|         0|            0|            0|  0.00%|        if not 0.0 <= weight_decay:
    86|         0|            0|            0|  0.00%|            raise ValueError("Invalid weight_decay value: {}".format(weight_decay))
    87|         0|            0|            0|  0.00%|        defaults = dict(lr=lr, betas=betas, eps=eps,
    88|         0|            0|            0|  0.00%|                        weight_decay=weight_decay, amsgrad=amsgrad,
    89|         0|            0|            0|  0.00%|                        maximize=maximize, foreach=foreach, capturable=capturable)
    90|         0|            0|            0|  0.00%|        super(Adam, self).__init__(params, defaults)
    91|         0|            0|            0|  0.00%|
    92|         0|            0|            0|  0.00%|    def __setstate__(self, state):
    93|         0|            0|            0|  0.00%|        super().__setstate__(state)
    94|         0|            0|            0|  0.00%|        for group in self.param_groups:
    95|         0|            0|            0|  0.00%|            group.setdefault('amsgrad', False)
    96|         0|            0|            0|  0.00%|            group.setdefault('maximize', False)
    97|         0|            0|            0|  0.00%|            group.setdefault('foreach', None)
    98|         0|            0|            0|  0.00%|            group.setdefault('capturable', False)
    99|         0|            0|            0|  0.00%|        state_values = list(self.state.values())
   100|         0|            0|            0|  0.00%|        step_is_tensor = (len(state_values) != 0) and torch.is_tensor(state_values[0]['step'])
   101|         0|            0|            0|  0.00%|        if not step_is_tensor:
   102|         0|            0|            0|  0.00%|            for s in state_values:
   103|         0|            0|            0|  0.00%|                s['step'] = torch.tensor(float(s['step']))
   104|         0|            0|            0|  0.00%|
   105|       288|   0.00124574|  4.32548e-06|  0.00%|    @torch.no_grad()
   106|         0|            0|            0|  0.00%|    def step(self, closure=None):
   107|         0|            0|            0|  0.00%|        """Performs a single optimization step.
   108|         0|            0|            0|  0.00%|
   109|         0|            0|            0|  0.00%|        Args:
   110|         0|            0|            0|  0.00%|            closure (callable, optional): A closure that reevaluates the model
   111|         0|            0|            0|  0.00%|                and returns the loss.
   112|         0|            0|            0|  0.00%|        """
   113|       288|   0.00264788|  9.19402e-06|  0.00%|        self._cuda_graph_capture_health_check()
(call)|       288|   0.00918674|  3.18984e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/optim/optimizer.py:84 _cuda_graph_capture_health_check
   114|         0|            0|            0|  0.00%|
   115|       288|   0.00111389|  3.86768e-06|  0.00%|        loss = None
   116|       288|   0.00107503|  3.73274e-06|  0.00%|        if closure is not None:
   117|         0|            0|            0|  0.00%|            with torch.enable_grad():
   118|         0|            0|            0|  0.00%|                loss = closure()
   119|         0|            0|            0|  0.00%|
   120|       576|   0.00199199|  3.45831e-06|  0.00%|        for group in self.param_groups:
   121|       288|   0.00101995|  3.54151e-06|  0.00%|            params_with_grad = []
   122|       288|  0.000984907|  3.41982e-06|  0.00%|            grads = []
   123|       288|  0.000917673|  3.18636e-06|  0.00%|            exp_avgs = []
   124|       288|  0.000879049|  3.05225e-06|  0.00%|            exp_avg_sqs = []
   125|       288|  0.000842333|  2.92477e-06|  0.00%|            max_exp_avg_sqs = []
   126|       288|  0.000865221|  3.00424e-06|  0.00%|            state_steps = []
   127|       288|  0.000941277|  3.26832e-06|  0.00%|            beta1, beta2 = group['betas']
   128|         0|            0|            0|  0.00%|
   129|      3744|   0.00851178|  2.27345e-06|  0.01%|            for p in group['params']:
   130|      3456|    0.0223866|  6.47759e-06|  0.02%|                if p.grad is not None:
(call)|      3456|    0.0180469|  5.22189e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:1071 grad
   131|      3456|   0.00841975|  2.43627e-06|  0.01%|                    params_with_grad.append(p)
   132|      3456|    0.0221708|  6.41516e-06|  0.02%|                    if p.grad.is_sparse:
(call)|      3456|    0.0169652|   4.9089e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:1071 grad
   133|         0|            0|            0|  0.00%|                        raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')
   134|      3456|    0.0220616|  6.38356e-06|  0.02%|                    grads.append(p.grad)
(call)|      3456|    0.0166557|  4.81935e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:1071 grad
   135|         0|            0|            0|  0.00%|
   136|      3456|     0.022434|  6.49132e-06|  0.02%|                    state = self.state[p]
(call)|      3456|     0.017112|  4.95139e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:731 __hash__
   137|         0|            0|            0|  0.00%|                    # Lazy state initialization
   138|      3456|   0.00863957|  2.49988e-06|  0.01%|                    if len(state) == 0:
   139|         0|            0|            0|  0.00%|                        state['step'] = torch.zeros((1,), dtype=torch.float, device=p.device) \
   140|         0|            0|            0|  0.00%|                            if self.defaults['capturable'] else torch.tensor(0.)
   141|         0|            0|            0|  0.00%|                        # Exponential moving average of gradient values
   142|         0|            0|            0|  0.00%|                        state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
   143|         0|            0|            0|  0.00%|                        # Exponential moving average of squared gradient values
   144|         0|            0|            0|  0.00%|                        state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
   145|         0|            0|            0|  0.00%|                        if group['amsgrad']:
   146|         0|            0|            0|  0.00%|                            # Maintains max of all exp. moving avg. of sq. grad. values
   147|         0|            0|            0|  0.00%|                            state['max_exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
   148|         0|            0|            0|  0.00%|
   149|      3456|   0.00845933|  2.44772e-06|  0.01%|                    exp_avgs.append(state['exp_avg'])
   150|      3456|   0.00807762|  2.33727e-06|  0.01%|                    exp_avg_sqs.append(state['exp_avg_sq'])
   151|         0|            0|            0|  0.00%|
   152|      3456|   0.00778508|  2.25263e-06|  0.01%|                    if group['amsgrad']:
   153|         0|            0|            0|  0.00%|                        max_exp_avg_sqs.append(state['max_exp_avg_sq'])
   154|         0|            0|            0|  0.00%|
   155|      3456|   0.00791812|  2.29112e-06|  0.01%|                    state_steps.append(state['step'])
   156|         0|            0|            0|  0.00%|
   157|       576|   0.00389957|  6.77009e-06|  0.00%|            adam(params_with_grad,
(call)|       288|     0.460862|   0.00160022|  0.44%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/optim/adam.py:176 adam
   158|       288|  0.000612974|  2.12838e-06|  0.00%|                 grads,
   159|       288|  0.000627041|  2.17723e-06|  0.00%|                 exp_avgs,
   160|       288|   0.00062108|  2.15653e-06|  0.00%|                 exp_avg_sqs,
   161|       288|  0.000595808|  2.06878e-06|  0.00%|                 max_exp_avg_sqs,
   162|       288|  0.000601768|  2.08947e-06|  0.00%|                 state_steps,
   163|       288|  0.000609159|  2.11514e-06|  0.00%|                 amsgrad=group['amsgrad'],
   164|       288|  0.000614405|  2.13335e-06|  0.00%|                 beta1=beta1,
   165|       288|   0.00059557|  2.06795e-06|  0.00%|                 beta2=beta2,
   166|       288|  0.000622272|  2.16067e-06|  0.00%|                 lr=group['lr'],
   167|       288|  0.000618696|  2.14825e-06|  0.00%|                 weight_decay=group['weight_decay'],
   168|       288|  0.000633955|  2.20123e-06|  0.00%|                 eps=group['eps'],
   169|       288|  0.000642061|  2.22938e-06|  0.00%|                 maximize=group['maximize'],
   170|       288|  0.000627756|  2.17971e-06|  0.00%|                 foreach=group['foreach'],
   171|       288|  0.000611782|  2.12424e-06|  0.00%|                 capturable=group['capturable'])
   172|         0|            0|            0|  0.00%|
   173|       288|  0.000761032|  2.64247e-06|  0.00%|        return loss
   174|         0|            0|            0|  0.00%|
   175|         0|            0|            0|  0.00%|
   176|       288|  0.000832558|  2.89083e-06|  0.00%|def adam(params: List[Tensor],
   177|         0|            0|            0|  0.00%|         grads: List[Tensor],
   178|         0|            0|            0|  0.00%|         exp_avgs: List[Tensor],
   179|         0|            0|            0|  0.00%|         exp_avg_sqs: List[Tensor],
   180|         0|            0|            0|  0.00%|         max_exp_avg_sqs: List[Tensor],
   181|         0|            0|            0|  0.00%|         state_steps: List[Tensor],
   182|         0|            0|            0|  0.00%|         # kwonly args with defaults are not supported by functions compiled with torchscript issue #70627
   183|         0|            0|            0|  0.00%|         # setting this as kwarg for now as functional API is compiled by torch/distributed/optim
   184|         0|            0|            0|  0.00%|         foreach: bool = None,
   185|         0|            0|            0|  0.00%|         capturable: bool = False,
   186|         0|            0|            0|  0.00%|         *,
   187|         0|            0|            0|  0.00%|         amsgrad: bool,
   188|         0|            0|            0|  0.00%|         beta1: float,
   189|         0|            0|            0|  0.00%|         beta2: float,
   190|         0|            0|            0|  0.00%|         lr: float,
   191|         0|            0|            0|  0.00%|         weight_decay: float,
   192|         0|            0|            0|  0.00%|         eps: float,
   193|         0|            0|            0|  0.00%|         maximize: bool):
   194|         0|            0|            0|  0.00%|    r"""Functional API that performs Adam algorithm computation.
   195|         0|            0|            0|  0.00%|    See :class:`~torch.optim.Adam` for details.
   196|         0|            0|            0|  0.00%|    """
   197|         0|            0|            0|  0.00%|
   198|      4320|    0.0088048|  2.03815e-06|  0.01%|    if not all([isinstance(t, torch.Tensor) for t in state_steps]):
(call)|       288|   0.00656247|  2.27864e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/optim/adam.py:198 <listcomp>
   199|         0|            0|            0|  0.00%|        raise RuntimeError("API has changed, `state_steps` argument must contain a list of singleton tensors")
   200|         0|            0|            0|  0.00%|
   201|       288|  0.000695944|  2.41647e-06|  0.00%|    if foreach is None:
   202|         0|            0|            0|  0.00%|        # Placeholder for more complex foreach logic to be added when value is not set
   203|       288|   0.00067091|  2.32955e-06|  0.00%|        foreach = False
   204|         0|            0|            0|  0.00%|
   205|       288|  0.000650883|  2.26001e-06|  0.00%|    if foreach and torch.jit.is_scripting():
   206|         0|            0|            0|  0.00%|        raise RuntimeError('torch.jit.script not supported with foreach optimizers')
   207|         0|            0|            0|  0.00%|
   208|       288|   0.00062561|  2.17226e-06|  0.00%|    if foreach and not torch.jit.is_scripting():
   209|         0|            0|            0|  0.00%|        func = _multi_tensor_adam
   210|         0|            0|            0|  0.00%|    else:
   211|       288|  0.000643253|  2.23352e-06|  0.00%|        func = _single_tensor_adam
   212|         0|            0|            0|  0.00%|
   213|       576|   0.00466895|  8.10582e-06|  0.00%|    func(params,
(call)|       288|     0.435632|   0.00151261|  0.42%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/optim/adam.py:229 _single_tensor_adam
   214|       288|  0.000586271|  2.03566e-06|  0.00%|         grads,
   215|       288|  0.000602007|   2.0903e-06|  0.00%|         exp_avgs,
   216|       288|  0.000598192|  2.07706e-06|  0.00%|         exp_avg_sqs,
   217|       288|  0.000604391|  2.09858e-06|  0.00%|         max_exp_avg_sqs,
   218|       288|  0.000564575|  1.96033e-06|  0.00%|         state_steps,
   219|       288|  0.000590324|  2.04974e-06|  0.00%|         amsgrad=amsgrad,
   220|       288|  0.000582457|  2.02242e-06|  0.00%|         beta1=beta1,
   221|       288|  0.000622034|  2.15984e-06|  0.00%|         beta2=beta2,
   222|       288|  0.000577211|  2.00421e-06|  0.00%|         lr=lr,
   223|       288|  0.000567198|  1.96944e-06|  0.00%|         weight_decay=weight_decay,
   224|       288|  0.000575542|  1.99841e-06|  0.00%|         eps=eps,
   225|       288|  0.000582695|  2.02325e-06|  0.00%|         maximize=maximize,
   226|       288|  0.000584364|  2.02904e-06|  0.00%|         capturable=capturable)
   227|         0|            0|            0|  0.00%|
   228|         0|            0|            0|  0.00%|
   229|       288|    0.0013504|   4.6889e-06|  0.00%|def _single_tensor_adam(params: List[Tensor],
   230|         0|            0|            0|  0.00%|                        grads: List[Tensor],
   231|         0|            0|            0|  0.00%|                        exp_avgs: List[Tensor],
   232|         0|            0|            0|  0.00%|                        exp_avg_sqs: List[Tensor],
   233|         0|            0|            0|  0.00%|                        max_exp_avg_sqs: List[Tensor],
   234|         0|            0|            0|  0.00%|                        state_steps: List[Tensor],
   235|         0|            0|            0|  0.00%|                        *,
   236|         0|            0|            0|  0.00%|                        amsgrad: bool,
   237|         0|            0|            0|  0.00%|                        beta1: float,
   238|         0|            0|            0|  0.00%|                        beta2: float,
   239|         0|            0|            0|  0.00%|                        lr: float,
   240|         0|            0|            0|  0.00%|                        weight_decay: float,
   241|         0|            0|            0|  0.00%|                        eps: float,
   242|         0|            0|            0|  0.00%|                        maximize: bool,
   243|         0|            0|            0|  0.00%|                        capturable: bool):
   244|         0|            0|            0|  0.00%|
   245|      3744|    0.0128679|  3.43695e-06|  0.01%|    for i, param in enumerate(params):
   246|         0|            0|            0|  0.00%|
   247|      3456|    0.0104887|  3.03494e-06|  0.01%|        grad = grads[i] if not maximize else -grads[i]
   248|      3456|    0.0100641|  2.91207e-06|  0.01%|        exp_avg = exp_avgs[i]
   249|      3456|   0.00985384|  2.85123e-06|  0.01%|        exp_avg_sq = exp_avg_sqs[i]
   250|      3456|   0.00964761|  2.79155e-06|  0.01%|        step_t = state_steps[i]
   251|         0|            0|            0|  0.00%|
   252|      3456|   0.00950837|  2.75126e-06|  0.01%|        if capturable:
   253|         0|            0|            0|  0.00%|            assert param.is_cuda and step_t.is_cuda, "If capturable=True, params and state_steps must be CUDA tensors."
   254|         0|            0|            0|  0.00%|
   255|         0|            0|            0|  0.00%|        # update step
   256|      3456|    0.0363245|  1.05106e-05|  0.03%|        step_t += 1
   257|         0|            0|            0|  0.00%|
   258|      3456|    0.0113194|  3.27529e-06|  0.01%|        if weight_decay != 0:
   259|         0|            0|            0|  0.00%|            grad = grad.add(param, alpha=weight_decay)
   260|         0|            0|            0|  0.00%|
   261|         0|            0|            0|  0.00%|        # Decay the first and second moment running average coefficient
   262|      3456|    0.0476282|  1.37813e-05|  0.05%|        exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)
   263|      3456|    0.0536416|  1.55213e-05|  0.05%|        exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)
   264|         0|            0|            0|  0.00%|
   265|      3456|    0.0118551|   3.4303e-06|  0.01%|        if capturable:
   266|         0|            0|            0|  0.00%|            step = step_t
   267|         0|            0|            0|  0.00%|
   268|         0|            0|            0|  0.00%|            # 1 - beta1 ** step can't be captured in a CUDA graph, even if step is a CUDA tensor
   269|         0|            0|            0|  0.00%|            # (incurs "RuntimeError: CUDA error: operation not permitted when stream is capturing")
   270|         0|            0|            0|  0.00%|            bias_correction1 = 1 - torch.pow(beta1, step)
   271|         0|            0|            0|  0.00%|            bias_correction2 = 1 - torch.pow(beta2, step)
   272|         0|            0|            0|  0.00%|
   273|         0|            0|            0|  0.00%|            step_size = lr / bias_correction1
   274|         0|            0|            0|  0.00%|            step_size_neg = step_size.neg()
   275|         0|            0|            0|  0.00%|
   276|         0|            0|            0|  0.00%|            bias_correction2_sqrt = bias_correction2.sqrt()
   277|         0|            0|            0|  0.00%|
   278|         0|            0|            0|  0.00%|            if amsgrad:
   279|         0|            0|            0|  0.00%|                # Maintains the maximum of all 2nd moment running avg. till now
   280|         0|            0|            0|  0.00%|                torch.maximum(max_exp_avg_sqs[i], exp_avg_sq, out=max_exp_avg_sqs[i])
   281|         0|            0|            0|  0.00%|                # Uses the max. for normalizing running avg. of gradient
   282|         0|            0|            0|  0.00%|                # Folds in (admittedly ugly) 1-elem step_size math here to avoid extra param-set-sized read+write
   283|         0|            0|            0|  0.00%|                # (can't fold it into addcdiv_ below because addcdiv_ requires value is a Number, not a Tensor)
   284|         0|            0|            0|  0.00%|                denom = (max_exp_avg_sqs[i].sqrt() / (bias_correction2_sqrt * step_size_neg)).add_(eps / step_size_neg)
   285|         0|            0|            0|  0.00%|            else:
   286|         0|            0|            0|  0.00%|                denom = (exp_avg_sq.sqrt() / (bias_correction2_sqrt * step_size_neg)).add_(eps / step_size_neg)
   287|         0|            0|            0|  0.00%|
   288|         0|            0|            0|  0.00%|            param.addcdiv_(exp_avg, denom)
   289|         0|            0|            0|  0.00%|        else:
   290|      3456|     0.015188|  4.39467e-06|  0.01%|            step = step_t.item()
   291|         0|            0|            0|  0.00%|
   292|      3456|     0.013907|    4.024e-06|  0.01%|            bias_correction1 = 1 - beta1 ** step
   293|      3456|    0.0109112|  3.15718e-06|  0.01%|            bias_correction2 = 1 - beta2 ** step
   294|         0|            0|            0|  0.00%|
   295|      3456|    0.0102937|  2.97851e-06|  0.01%|            step_size = lr / bias_correction1
   296|         0|            0|            0|  0.00%|
   297|      3456|    0.0115669|   3.3469e-06|  0.01%|            bias_correction2_sqrt = math.sqrt(bias_correction2)
   298|         0|            0|            0|  0.00%|
   299|      3456|   0.00987864|   2.8584e-06|  0.01%|            if amsgrad:
   300|         0|            0|            0|  0.00%|                # Maintains the maximum of all 2nd moment running avg. till now
   301|         0|            0|            0|  0.00%|                torch.maximum(max_exp_avg_sqs[i], exp_avg_sq, out=max_exp_avg_sqs[i])
   302|         0|            0|            0|  0.00%|                # Use the max. for normalizing running avg. of gradient
   303|         0|            0|            0|  0.00%|                denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)
   304|         0|            0|            0|  0.00%|            else:
   305|      3456|     0.109892|  3.17976e-05|  0.11%|                denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)
   306|         0|            0|            0|  0.00%|
   307|      3456|    0.0294447|  8.51988e-06|  0.03%|            param.addcdiv_(exp_avg, denom, value=-step_size)
   308|         0|            0|            0|  0.00%|
   309|         0|            0|            0|  0.00%|
   310|         0|            0|            0|  0.00%|def _multi_tensor_adam(params: List[Tensor],
   311|         0|            0|            0|  0.00%|                       grads: List[Tensor],
   312|         0|            0|            0|  0.00%|                       exp_avgs: List[Tensor],
   313|         0|            0|            0|  0.00%|                       exp_avg_sqs: List[Tensor],
   314|         0|            0|            0|  0.00%|                       max_exp_avg_sqs: List[Tensor],
   315|         0|            0|            0|  0.00%|                       state_steps: List[Tensor],
   316|         0|            0|            0|  0.00%|                       *,
   317|         0|            0|            0|  0.00%|                       amsgrad: bool,
   318|         0|            0|            0|  0.00%|                       beta1: float,
   319|         0|            0|            0|  0.00%|                       beta2: float,
   320|         0|            0|            0|  0.00%|                       lr: float,
   321|         0|            0|            0|  0.00%|                       weight_decay: float,
   322|         0|            0|            0|  0.00%|                       eps: float,
   323|         0|            0|            0|  0.00%|                       maximize: bool,
   324|         0|            0|            0|  0.00%|                       capturable: bool):
   325|         0|            0|            0|  0.00%|    if len(params) == 0:
   326|         0|            0|            0|  0.00%|        return
   327|         0|            0|            0|  0.00%|
   328|         0|            0|            0|  0.00%|    if capturable:
   329|         0|            0|            0|  0.00%|        assert all(p.is_cuda and step.is_cuda for p, step in zip(params, state_steps)), \
   330|         0|            0|            0|  0.00%|            "If capturable=True, params and state_steps must be CUDA tensors."
   331|         0|            0|            0|  0.00%|
   332|         0|            0|            0|  0.00%|    if maximize:
   333|         0|            0|            0|  0.00%|        grads = torch._foreach_neg(tuple(grads))  # type: ignore[assignment]
   334|         0|            0|            0|  0.00%|
   335|         0|            0|            0|  0.00%|    # update steps
   336|         0|            0|            0|  0.00%|    torch._foreach_add_(state_steps, 1)
   337|         0|            0|            0|  0.00%|
   338|         0|            0|            0|  0.00%|    if weight_decay != 0:
   339|         0|            0|            0|  0.00%|        torch._foreach_add_(grads, params, alpha=weight_decay)
   340|         0|            0|            0|  0.00%|
   341|         0|            0|            0|  0.00%|    # Decay the first and second moment running average coefficient
   342|         0|            0|            0|  0.00%|    torch._foreach_mul_(exp_avgs, beta1)
   343|         0|            0|            0|  0.00%|    torch._foreach_add_(exp_avgs, grads, alpha=1 - beta1)
   344|         0|            0|            0|  0.00%|
   345|         0|            0|            0|  0.00%|    torch._foreach_mul_(exp_avg_sqs, beta2)
   346|         0|            0|            0|  0.00%|    torch._foreach_addcmul_(exp_avg_sqs, grads, grads, 1 - beta2)
   347|         0|            0|            0|  0.00%|
   348|         0|            0|            0|  0.00%|    if capturable:
   349|         0|            0|            0|  0.00%|        # TODO: use foreach_pow if/when foreach_pow is added
   350|         0|            0|            0|  0.00%|        bias_correction1 = [torch.pow(beta1, step) for step in state_steps]
   351|         0|            0|            0|  0.00%|        bias_correction2 = [torch.pow(beta2, step) for step in state_steps]
   352|         0|            0|            0|  0.00%|        # foreach_sub doesn't allow a scalar as the first arg
   353|         0|            0|            0|  0.00%|        torch._foreach_sub_(bias_correction1, 1)
   354|         0|            0|            0|  0.00%|        torch._foreach_sub_(bias_correction2, 1)
   355|         0|            0|            0|  0.00%|        torch._foreach_neg_(bias_correction1)
   356|         0|            0|            0|  0.00%|        torch._foreach_neg_(bias_correction2)
   357|         0|            0|            0|  0.00%|
   358|         0|            0|            0|  0.00%|        # foreach_div doesn't allow a scalar as the first arg
   359|         0|            0|            0|  0.00%|        step_size = torch._foreach_div(bias_correction1, lr)
   360|         0|            0|            0|  0.00%|        torch._foreach_reciprocal_(step_size)
   361|         0|            0|            0|  0.00%|        torch._foreach_neg_(step_size)
   362|         0|            0|            0|  0.00%|
   363|         0|            0|            0|  0.00%|        bias_correction2_sqrt = torch._foreach_sqrt(bias_correction2)
   364|         0|            0|            0|  0.00%|
   365|         0|            0|            0|  0.00%|        if amsgrad:
   366|         0|            0|            0|  0.00%|            # Maintains the maximum of all 2nd moment running avg. till now
   367|         0|            0|            0|  0.00%|            max_exp_avg_sqs = torch._foreach_maximum(max_exp_avg_sqs, exp_avg_sqs)  # type: ignore[assignment]
   368|         0|            0|            0|  0.00%|
   369|         0|            0|            0|  0.00%|            # Use the max. for normalizing running avg. of gradient
   370|         0|            0|            0|  0.00%|            max_exp_avg_sq_sqrt = torch._foreach_sqrt(max_exp_avg_sqs)
   371|         0|            0|            0|  0.00%|            # Folds in (admittedly ugly) 1-elem step_size math here to avoid extra param-set-sized read+write
   372|         0|            0|            0|  0.00%|            # (can't fold it into addcdiv_ below because addcdiv_ requires value is a Number, not a Tensor)
   373|         0|            0|            0|  0.00%|            torch._foreach_div_(max_exp_avg_sq_sqrt, torch._foreach_mul(bias_correction2_sqrt, step_size))
   374|         0|            0|            0|  0.00%|            eps_over_step_size = torch._foreach_div(step_size, eps)
   375|         0|            0|            0|  0.00%|            torch._foreach_reciprocal_(eps_over_step_size)
   376|         0|            0|            0|  0.00%|            denom = torch._foreach_add(max_exp_avg_sq_sqrt, eps_over_step_size)
   377|         0|            0|            0|  0.00%|        else:
   378|         0|            0|            0|  0.00%|            exp_avg_sq_sqrt = torch._foreach_sqrt(exp_avg_sqs)
   379|         0|            0|            0|  0.00%|            torch._foreach_div_(exp_avg_sq_sqrt, torch._foreach_mul(bias_correction2_sqrt, step_size))
   380|         0|            0|            0|  0.00%|            eps_over_step_size = torch._foreach_div(step_size, eps)
   381|         0|            0|            0|  0.00%|            torch._foreach_reciprocal_(eps_over_step_size)
   382|         0|            0|            0|  0.00%|            denom = torch._foreach_add(exp_avg_sq_sqrt, eps_over_step_size)
   383|         0|            0|            0|  0.00%|
   384|         0|            0|            0|  0.00%|        torch._foreach_addcdiv_(params, exp_avgs, denom)
   385|         0|            0|            0|  0.00%|    else:
   386|         0|            0|            0|  0.00%|        bias_correction1 = [1 - beta1 ** step.item() for step in state_steps]
   387|         0|            0|            0|  0.00%|        bias_correction2 = [1 - beta2 ** step.item() for step in state_steps]
   388|         0|            0|            0|  0.00%|
   389|         0|            0|            0|  0.00%|        step_size = [(lr / bc) * -1 for bc in bias_correction1]
   390|         0|            0|            0|  0.00%|
   391|         0|            0|            0|  0.00%|        bias_correction2_sqrt = [math.sqrt(bc) for bc in bias_correction2]
   392|         0|            0|            0|  0.00%|
   393|         0|            0|            0|  0.00%|        if amsgrad:
   394|         0|            0|            0|  0.00%|            # Maintains the maximum of all 2nd moment running avg. till now
   395|         0|            0|            0|  0.00%|            max_exp_avg_sqs = torch._foreach_maximum(max_exp_avg_sqs, exp_avg_sqs)  # type: ignore[assignment]
   396|         0|            0|            0|  0.00%|
   397|         0|            0|            0|  0.00%|            # Use the max. for normalizing running avg. of gradient
   398|         0|            0|            0|  0.00%|            max_exp_avg_sq_sqrt = torch._foreach_sqrt(max_exp_avg_sqs)
   399|         0|            0|            0|  0.00%|            torch._foreach_div_(max_exp_avg_sq_sqrt, bias_correction2_sqrt)
   400|         0|            0|            0|  0.00%|            denom = torch._foreach_add(max_exp_avg_sq_sqrt, eps)
   401|         0|            0|            0|  0.00%|        else:
   402|         0|            0|            0|  0.00%|            exp_avg_sq_sqrt = torch._foreach_sqrt(exp_avg_sqs)
   403|         0|            0|            0|  0.00%|            torch._foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)
   404|         0|            0|            0|  0.00%|            denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
   405|         0|            0|            0|  0.00%|
   406|         0|            0|            0|  0.00%|        torch._foreach_addcdiv_(params, exp_avgs, denom, step_size)
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py
File duration: 0.615916s (0.59%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import math
     2|         0|            0|            0|  0.00%|from typing import Any
     3|         0|            0|            0|  0.00%|
     4|         0|            0|            0|  0.00%|import torch
     5|         0|            0|            0|  0.00%|from torch import Tensor
     6|         0|            0|            0|  0.00%|from torch.nn.parameter import Parameter, UninitializedParameter
     7|         0|            0|            0|  0.00%|from .. import functional as F
     8|         0|            0|            0|  0.00%|from .. import init
     9|         0|            0|            0|  0.00%|from .module import Module
    10|         0|            0|            0|  0.00%|from .lazy import LazyModuleMixin
    11|         0|            0|            0|  0.00%|
    12|         0|            0|            0|  0.00%|
    13|         0|            0|            0|  0.00%|__all__ = [
    14|         0|            0|            0|  0.00%|    'Bilinear',
    15|         0|            0|            0|  0.00%|    'Identity',
    16|         0|            0|            0|  0.00%|    'LazyLinear',
    17|         0|            0|            0|  0.00%|    'Linear',
    18|         0|            0|            0|  0.00%|]
    19|         0|            0|            0|  0.00%|
    20|         0|            0|            0|  0.00%|
    21|         0|            0|            0|  0.00%|class Identity(Module):
    22|         0|            0|            0|  0.00%|    r"""A placeholder identity operator that is argument-insensitive.
    23|         0|            0|            0|  0.00%|
    24|         0|            0|            0|  0.00%|    Args:
    25|         0|            0|            0|  0.00%|        args: any argument (unused)
    26|         0|            0|            0|  0.00%|        kwargs: any keyword argument (unused)
    27|         0|            0|            0|  0.00%|
    28|         0|            0|            0|  0.00%|    Shape:
    29|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
    30|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
    31|         0|            0|            0|  0.00%|
    32|         0|            0|            0|  0.00%|    Examples::
    33|         0|            0|            0|  0.00%|
    34|         0|            0|            0|  0.00%|        >>> m = nn.Identity(54, unused_argument1=0.1, unused_argument2=False)
    35|         0|            0|            0|  0.00%|        >>> input = torch.randn(128, 20)
    36|         0|            0|            0|  0.00%|        >>> output = m(input)
    37|         0|            0|            0|  0.00%|        >>> print(output.size())
    38|         0|            0|            0|  0.00%|        torch.Size([128, 20])
    39|         0|            0|            0|  0.00%|
    40|         0|            0|            0|  0.00%|    """
    41|         0|            0|            0|  0.00%|    def __init__(self, *args: Any, **kwargs: Any) -> None:
    42|         0|            0|            0|  0.00%|        super(Identity, self).__init__()
    43|         0|            0|            0|  0.00%|
    44|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
    45|         0|            0|            0|  0.00%|        return input
    46|         0|            0|            0|  0.00%|
    47|         0|            0|            0|  0.00%|
    48|         0|            0|            0|  0.00%|class Linear(Module):
    49|         0|            0|            0|  0.00%|    r"""Applies a linear transformation to the incoming data: :math:`y = xA^T + b`
    50|         0|            0|            0|  0.00%|
    51|         0|            0|            0|  0.00%|    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.
    52|         0|            0|            0|  0.00%|
    53|         0|            0|            0|  0.00%|    On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.
    54|         0|            0|            0|  0.00%|
    55|         0|            0|            0|  0.00%|    Args:
    56|         0|            0|            0|  0.00%|        in_features: size of each input sample
    57|         0|            0|            0|  0.00%|        out_features: size of each output sample
    58|         0|            0|            0|  0.00%|        bias: If set to ``False``, the layer will not learn an additive bias.
    59|         0|            0|            0|  0.00%|            Default: ``True``
    60|         0|            0|            0|  0.00%|
    61|         0|            0|            0|  0.00%|    Shape:
    62|         0|            0|            0|  0.00%|        - Input: :math:`(*, H_{in})` where :math:`*` means any number of
    63|         0|            0|            0|  0.00%|          dimensions including none and :math:`H_{in} = \text{in\_features}`.
    64|         0|            0|            0|  0.00%|        - Output: :math:`(*, H_{out})` where all but the last dimension
    65|         0|            0|            0|  0.00%|          are the same shape as the input and :math:`H_{out} = \text{out\_features}`.
    66|         0|            0|            0|  0.00%|
    67|         0|            0|            0|  0.00%|    Attributes:
    68|         0|            0|            0|  0.00%|        weight: the learnable weights of the module of shape
    69|         0|            0|            0|  0.00%|            :math:`(\text{out\_features}, \text{in\_features})`. The values are
    70|         0|            0|            0|  0.00%|            initialized from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})`, where
    71|         0|            0|            0|  0.00%|            :math:`k = \frac{1}{\text{in\_features}}`
    72|         0|            0|            0|  0.00%|        bias:   the learnable bias of the module of shape :math:`(\text{out\_features})`.
    73|         0|            0|            0|  0.00%|                If :attr:`bias` is ``True``, the values are initialized from
    74|         0|            0|            0|  0.00%|                :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
    75|         0|            0|            0|  0.00%|                :math:`k = \frac{1}{\text{in\_features}}`
    76|         0|            0|            0|  0.00%|
    77|         0|            0|            0|  0.00%|    Examples::
    78|         0|            0|            0|  0.00%|
    79|         0|            0|            0|  0.00%|        >>> m = nn.Linear(20, 30)
    80|         0|            0|            0|  0.00%|        >>> input = torch.randn(128, 20)
    81|         0|            0|            0|  0.00%|        >>> output = m(input)
    82|         0|            0|            0|  0.00%|        >>> print(output.size())
    83|         0|            0|            0|  0.00%|        torch.Size([128, 30])
    84|         0|            0|            0|  0.00%|    """
    85|         0|            0|            0|  0.00%|    __constants__ = ['in_features', 'out_features']
    86|         0|            0|            0|  0.00%|    in_features: int
    87|         0|            0|            0|  0.00%|    out_features: int
    88|         0|            0|            0|  0.00%|    weight: Tensor
    89|         0|            0|            0|  0.00%|
    90|         0|            0|            0|  0.00%|    def __init__(self, in_features: int, out_features: int, bias: bool = True,
    91|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:
    92|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}
    93|         0|            0|            0|  0.00%|        super(Linear, self).__init__()
    94|         0|            0|            0|  0.00%|        self.in_features = in_features
    95|         0|            0|            0|  0.00%|        self.out_features = out_features
    96|         0|            0|            0|  0.00%|        self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
    97|         0|            0|            0|  0.00%|        if bias:
    98|         0|            0|            0|  0.00%|            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))
    99|         0|            0|            0|  0.00%|        else:
   100|         0|            0|            0|  0.00%|            self.register_parameter('bias', None)
   101|         0|            0|            0|  0.00%|        self.reset_parameters()
   102|         0|            0|            0|  0.00%|
   103|         0|            0|            0|  0.00%|    def reset_parameters(self) -> None:
   104|         0|            0|            0|  0.00%|        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with
   105|         0|            0|            0|  0.00%|        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see
   106|         0|            0|            0|  0.00%|        # https://github.com/pytorch/pytorch/issues/57109
   107|         0|            0|            0|  0.00%|        init.kaiming_uniform_(self.weight, a=math.sqrt(5))
   108|         0|            0|            0|  0.00%|        if self.bias is not None:
   109|         0|            0|            0|  0.00%|            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)
   110|         0|            0|            0|  0.00%|            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0
   111|         0|            0|            0|  0.00%|            init.uniform_(self.bias, -bound, bound)
   112|         0|            0|            0|  0.00%|
   113|     15714|    0.0275567|  1.75364e-06|  0.03%|    def forward(self, input: Tensor) -> Tensor:
   114|     15714|      0.58836|  3.74417e-05|  0.56%|        return F.linear(input, self.weight, self.bias)
(call)|     31428|     0.335786|  1.06843e-05|  0.32%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194 __getattr__
   115|         0|            0|            0|  0.00%|
   116|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   117|         0|            0|            0|  0.00%|        return 'in_features={}, out_features={}, bias={}'.format(
   118|         0|            0|            0|  0.00%|            self.in_features, self.out_features, self.bias is not None
   119|         0|            0|            0|  0.00%|        )
   120|         0|            0|            0|  0.00%|
   121|         0|            0|            0|  0.00%|
   122|         0|            0|            0|  0.00%|# This class exists solely to avoid triggering an obscure error when scripting
   123|         0|            0|            0|  0.00%|# an improperly quantized attention layer. See this issue for details:
   124|         0|            0|            0|  0.00%|# https://github.com/pytorch/pytorch/issues/58969
   125|         0|            0|            0|  0.00%|# TODO: fail fast on quantization API usage error, then remove this class
   126|         0|            0|            0|  0.00%|# and replace uses of it with plain Linear
   127|         0|            0|            0|  0.00%|class NonDynamicallyQuantizableLinear(Linear):
   128|         0|            0|            0|  0.00%|    def __init__(self, in_features: int, out_features: int, bias: bool = True,
   129|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:
   130|         0|            0|            0|  0.00%|        super().__init__(in_features, out_features, bias=bias,
   131|         0|            0|            0|  0.00%|                         device=device, dtype=dtype)
   132|         0|            0|            0|  0.00%|
   133|         0|            0|            0|  0.00%|
   134|         0|            0|            0|  0.00%|class Bilinear(Module):
   135|         0|            0|            0|  0.00%|    r"""Applies a bilinear transformation to the incoming data:
   136|         0|            0|            0|  0.00%|    :math:`y = x_1^T A x_2 + b`
   137|         0|            0|            0|  0.00%|
   138|         0|            0|            0|  0.00%|    Args:
   139|         0|            0|            0|  0.00%|        in1_features: size of each first input sample
   140|         0|            0|            0|  0.00%|        in2_features: size of each second input sample
   141|         0|            0|            0|  0.00%|        out_features: size of each output sample
   142|         0|            0|            0|  0.00%|        bias: If set to False, the layer will not learn an additive bias.
   143|         0|            0|            0|  0.00%|            Default: ``True``
   144|         0|            0|            0|  0.00%|
   145|         0|            0|            0|  0.00%|    Shape:
   146|         0|            0|            0|  0.00%|        - Input1: :math:`(*, H_{in1})` where :math:`H_{in1}=\text{in1\_features}` and
   147|         0|            0|            0|  0.00%|          :math:`*` means any number of additional dimensions including none. All but the last dimension
   148|         0|            0|            0|  0.00%|          of the inputs should be the same.
   149|         0|            0|            0|  0.00%|        - Input2: :math:`(*, H_{in2})` where :math:`H_{in2}=\text{in2\_features}`.
   150|         0|            0|            0|  0.00%|        - Output: :math:`(*, H_{out})` where :math:`H_{out}=\text{out\_features}`
   151|         0|            0|            0|  0.00%|          and all but the last dimension are the same shape as the input.
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|    Attributes:
   154|         0|            0|            0|  0.00%|        weight: the learnable weights of the module of shape
   155|         0|            0|            0|  0.00%|            :math:`(\text{out\_features}, \text{in1\_features}, \text{in2\_features})`.
   156|         0|            0|            0|  0.00%|            The values are initialized from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})`, where
   157|         0|            0|            0|  0.00%|            :math:`k = \frac{1}{\text{in1\_features}}`
   158|         0|            0|            0|  0.00%|        bias:   the learnable bias of the module of shape :math:`(\text{out\_features})`.
   159|         0|            0|            0|  0.00%|                If :attr:`bias` is ``True``, the values are initialized from
   160|         0|            0|            0|  0.00%|                :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})`, where
   161|         0|            0|            0|  0.00%|                :math:`k = \frac{1}{\text{in1\_features}}`
   162|         0|            0|            0|  0.00%|
   163|         0|            0|            0|  0.00%|    Examples::
   164|         0|            0|            0|  0.00%|
   165|         0|            0|            0|  0.00%|        >>> m = nn.Bilinear(20, 30, 40)
   166|         0|            0|            0|  0.00%|        >>> input1 = torch.randn(128, 20)
   167|         0|            0|            0|  0.00%|        >>> input2 = torch.randn(128, 30)
   168|         0|            0|            0|  0.00%|        >>> output = m(input1, input2)
   169|         0|            0|            0|  0.00%|        >>> print(output.size())
   170|         0|            0|            0|  0.00%|        torch.Size([128, 40])
   171|         0|            0|            0|  0.00%|    """
   172|         0|            0|            0|  0.00%|    __constants__ = ['in1_features', 'in2_features', 'out_features']
   173|         0|            0|            0|  0.00%|    in1_features: int
   174|         0|            0|            0|  0.00%|    in2_features: int
   175|         0|            0|            0|  0.00%|    out_features: int
   176|         0|            0|            0|  0.00%|    weight: Tensor
   177|         0|            0|            0|  0.00%|
   178|         0|            0|            0|  0.00%|    def __init__(self, in1_features: int, in2_features: int, out_features: int, bias: bool = True,
   179|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:
   180|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}
   181|         0|            0|            0|  0.00%|        super(Bilinear, self).__init__()
   182|         0|            0|            0|  0.00%|        self.in1_features = in1_features
   183|         0|            0|            0|  0.00%|        self.in2_features = in2_features
   184|         0|            0|            0|  0.00%|        self.out_features = out_features
   185|         0|            0|            0|  0.00%|        self.weight = Parameter(torch.empty((out_features, in1_features, in2_features), **factory_kwargs))
   186|         0|            0|            0|  0.00%|
   187|         0|            0|            0|  0.00%|        if bias:
   188|         0|            0|            0|  0.00%|            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))
   189|         0|            0|            0|  0.00%|        else:
   190|         0|            0|            0|  0.00%|            self.register_parameter('bias', None)
   191|         0|            0|            0|  0.00%|        self.reset_parameters()
   192|         0|            0|            0|  0.00%|
   193|         0|            0|            0|  0.00%|    def reset_parameters(self) -> None:
   194|         0|            0|            0|  0.00%|        bound = 1 / math.sqrt(self.weight.size(1))
   195|         0|            0|            0|  0.00%|        init.uniform_(self.weight, -bound, bound)
   196|         0|            0|            0|  0.00%|        if self.bias is not None:
   197|         0|            0|            0|  0.00%|            init.uniform_(self.bias, -bound, bound)
   198|         0|            0|            0|  0.00%|
   199|         0|            0|            0|  0.00%|    def forward(self, input1: Tensor, input2: Tensor) -> Tensor:
   200|         0|            0|            0|  0.00%|        return F.bilinear(input1, input2, self.weight, self.bias)
   201|         0|            0|            0|  0.00%|
   202|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   203|         0|            0|            0|  0.00%|        return 'in1_features={}, in2_features={}, out_features={}, bias={}'.format(
   204|         0|            0|            0|  0.00%|            self.in1_features, self.in2_features, self.out_features, self.bias is not None
   205|         0|            0|            0|  0.00%|        )
   206|         0|            0|            0|  0.00%|
   207|         0|            0|            0|  0.00%|
   208|         0|            0|            0|  0.00%|class LazyLinear(LazyModuleMixin, Linear):
   209|         0|            0|            0|  0.00%|    r"""A :class:`torch.nn.Linear` module where `in_features` is inferred.
   210|         0|            0|            0|  0.00%|
   211|         0|            0|            0|  0.00%|    In this module, the `weight` and `bias` are of :class:`torch.nn.UninitializedParameter`
   212|         0|            0|            0|  0.00%|    class. They will be initialized after the first call to ``forward`` is done and the
   213|         0|            0|            0|  0.00%|    module will become a regular :class:`torch.nn.Linear` module. The ``in_features`` argument
   214|         0|            0|            0|  0.00%|    of the :class:`Linear` is inferred from the ``input.shape[-1]``.
   215|         0|            0|            0|  0.00%|
   216|         0|            0|            0|  0.00%|    Check the :class:`torch.nn.modules.lazy.LazyModuleMixin` for further documentation
   217|         0|            0|            0|  0.00%|    on lazy modules and their limitations.
   218|         0|            0|            0|  0.00%|
   219|         0|            0|            0|  0.00%|    Args:
   220|         0|            0|            0|  0.00%|        out_features: size of each output sample
   221|         0|            0|            0|  0.00%|        bias: If set to ``False``, the layer will not learn an additive bias.
   222|         0|            0|            0|  0.00%|            Default: ``True``
   223|         0|            0|            0|  0.00%|
   224|         0|            0|            0|  0.00%|    Attributes:
   225|         0|            0|            0|  0.00%|        weight: the learnable weights of the module of shape
   226|         0|            0|            0|  0.00%|            :math:`(\text{out\_features}, \text{in\_features})`. The values are
   227|         0|            0|            0|  0.00%|            initialized from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})`, where
   228|         0|            0|            0|  0.00%|            :math:`k = \frac{1}{\text{in\_features}}`
   229|         0|            0|            0|  0.00%|        bias:   the learnable bias of the module of shape :math:`(\text{out\_features})`.
   230|         0|            0|            0|  0.00%|                If :attr:`bias` is ``True``, the values are initialized from
   231|         0|            0|            0|  0.00%|                :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
   232|         0|            0|            0|  0.00%|                :math:`k = \frac{1}{\text{in\_features}}`
   233|         0|            0|            0|  0.00%|
   234|         0|            0|            0|  0.00%|
   235|         0|            0|            0|  0.00%|    """
   236|         0|            0|            0|  0.00%|
   237|         0|            0|            0|  0.00%|    cls_to_become = Linear  # type: ignore[assignment]
   238|         0|            0|            0|  0.00%|    weight: UninitializedParameter
   239|         0|            0|            0|  0.00%|    bias: UninitializedParameter  # type: ignore[assignment]
   240|         0|            0|            0|  0.00%|
   241|         0|            0|            0|  0.00%|    def __init__(self, out_features: int, bias: bool = True,
   242|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:
   243|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}
   244|         0|            0|            0|  0.00%|        # bias is hardcoded to False to avoid creating tensor
   245|         0|            0|            0|  0.00%|        # that will soon be overwritten.
   246|         0|            0|            0|  0.00%|        super().__init__(0, 0, False)
   247|         0|            0|            0|  0.00%|        self.weight = UninitializedParameter(**factory_kwargs)
   248|         0|            0|            0|  0.00%|        self.out_features = out_features
   249|         0|            0|            0|  0.00%|        if bias:
   250|         0|            0|            0|  0.00%|            self.bias = UninitializedParameter(**factory_kwargs)
   251|         0|            0|            0|  0.00%|
   252|         0|            0|            0|  0.00%|    def reset_parameters(self) -> None:
   253|         0|            0|            0|  0.00%|        if not self.has_uninitialized_params() and self.in_features != 0:
   254|         0|            0|            0|  0.00%|            super().reset_parameters()
   255|         0|            0|            0|  0.00%|
   256|         0|            0|            0|  0.00%|    def initialize_parameters(self, input) -> None:  # type: ignore[override]
   257|         0|            0|            0|  0.00%|        if self.has_uninitialized_params():
   258|         0|            0|            0|  0.00%|            with torch.no_grad():
   259|         0|            0|            0|  0.00%|                self.in_features = input.shape[-1]
   260|         0|            0|            0|  0.00%|                self.weight.materialize((self.out_features, self.in_features))
   261|         0|            0|            0|  0.00%|                if self.bias is not None:
   262|         0|            0|            0|  0.00%|                    self.bias.materialize((self.out_features,))
   263|         0|            0|            0|  0.00%|                self.reset_parameters()
   264|         0|            0|            0|  0.00%|# TODO: PartialLinear - maybe in sparse?
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/distribution.py
File duration: 0.441989s (0.42%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import torch
     2|         0|            0|            0|  0.00%|import warnings
     3|         0|            0|            0|  0.00%|from torch.distributions import constraints
     4|         0|            0|            0|  0.00%|from torch.distributions.utils import lazy_property
     5|         0|            0|            0|  0.00%|from typing import Dict, Optional, Any
     6|         0|            0|            0|  0.00%|
     7|         0|            0|            0|  0.00%|
     8|         0|            0|            0|  0.00%|class Distribution(object):
     9|         0|            0|            0|  0.00%|    r"""
    10|         0|            0|            0|  0.00%|    Distribution is the abstract base class for probability distributions.
    11|         0|            0|            0|  0.00%|    """
    12|         0|            0|            0|  0.00%|
    13|         0|            0|            0|  0.00%|    has_rsample = False
    14|         0|            0|            0|  0.00%|    has_enumerate_support = False
    15|         0|            0|            0|  0.00%|    _validate_args = __debug__
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|    @staticmethod
    18|         0|            0|            0|  0.00%|    def set_default_validate_args(value):
    19|         0|            0|            0|  0.00%|        """
    20|         0|            0|            0|  0.00%|        Sets whether validation is enabled or disabled.
    21|         0|            0|            0|  0.00%|
    22|         0|            0|            0|  0.00%|        The default behavior mimics Python's ``assert`` statement: validation
    23|         0|            0|            0|  0.00%|        is on by default, but is disabled if Python is run in optimized mode
    24|         0|            0|            0|  0.00%|        (via ``python -O``). Validation may be expensive, so you may want to
    25|         0|            0|            0|  0.00%|        disable it once a model is working.
    26|         0|            0|            0|  0.00%|
    27|         0|            0|            0|  0.00%|        Args:
    28|         0|            0|            0|  0.00%|            value (bool): Whether to enable validation.
    29|         0|            0|            0|  0.00%|        """
    30|         0|            0|            0|  0.00%|        if value not in [True, False]:
    31|         0|            0|            0|  0.00%|            raise ValueError
    32|         0|            0|            0|  0.00%|        Distribution._validate_args = value
    33|         0|            0|            0|  0.00%|
    34|      2610|   0.00963068|  3.68992e-06|  0.01%|    def __init__(self, batch_shape=torch.Size(), event_shape=torch.Size(), validate_args=None):
    35|      2610|   0.00920725|  3.52768e-06|  0.01%|        self._batch_shape = batch_shape
    36|      2610|   0.00815463|  3.12438e-06|  0.01%|        self._event_shape = event_shape
    37|      2610|   0.00794816|  3.04527e-06|  0.01%|        if validate_args is not None:
    38|         0|            0|            0|  0.00%|            self._validate_args = validate_args
    39|      2610|   0.00800705|  3.06784e-06|  0.01%|        if self._validate_args:
    40|      2610|   0.00768542|  2.94461e-06|  0.01%|            try:
    41|      2610|   0.00845194|  3.23829e-06|  0.01%|                arg_constraints = self.arg_constraints
    42|         0|            0|            0|  0.00%|            except NotImplementedError:
    43|         0|            0|            0|  0.00%|                arg_constraints = {}
    44|         0|            0|            0|  0.00%|                warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +
    45|         0|            0|            0|  0.00%|                              'Please set `arg_constraints = {}` or initialize the distribution ' +
    46|         0|            0|            0|  0.00%|                              'with `validate_args=False` to turn off validation.')
    47|      7830|    0.0248675|  3.17593e-06|  0.02%|            for param, constraint in arg_constraints.items():
    48|      5220|    0.0413558|  7.92258e-06|  0.04%|                if constraints.is_dependent(constraint):
(call)|      5220|    0.0229087|  4.38864e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/constraints.py:142 is_dependent
    49|         0|            0|            0|  0.00%|                    continue  # skip constraints that cannot be checked
    50|      5220|    0.0348542|  6.67704e-06|  0.03%|                if param not in self.__dict__ and isinstance(getattr(type(self), param), lazy_property):
(call)|      2610|    0.0475075|  1.82021e-05|  0.05%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/utils.py:106 __get__
    51|      2610|   0.00755024|  2.89281e-06|  0.01%|                    continue  # skip checking lazily-constructed args
    52|      2610|   0.00725675|  2.78036e-06|  0.01%|                value = getattr(self, param)
    53|      2610|    0.0223053|  8.54607e-06|  0.02%|                valid = constraint.check(value)
(call)|      2610|     0.144912|   5.5522e-05|  0.14%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/constraints.py:208 check
    54|      2610|    0.0310524|  1.18975e-05|  0.03%|                if not valid.all():
    55|         0|            0|            0|  0.00%|                    raise ValueError(
    56|         0|            0|            0|  0.00%|                        f"Expected parameter {param} "
    57|         0|            0|            0|  0.00%|                        f"({type(value).__name__} of shape {tuple(value.shape)}) "
    58|         0|            0|            0|  0.00%|                        f"of distribution {repr(self)} "
    59|         0|            0|            0|  0.00%|                        f"to satisfy the constraint {repr(constraint)}, "
    60|         0|            0|            0|  0.00%|                        f"but found invalid values:\n{value}"
    61|         0|            0|            0|  0.00%|                    )
    62|      2610|    0.0099628|  3.81716e-06|  0.01%|        super(Distribution, self).__init__()
    63|         0|            0|            0|  0.00%|
    64|         0|            0|            0|  0.00%|    def expand(self, batch_shape, _instance=None):
    65|         0|            0|            0|  0.00%|        """
    66|         0|            0|            0|  0.00%|        Returns a new distribution instance (or populates an existing instance
    67|         0|            0|            0|  0.00%|        provided by a derived class) with batch dimensions expanded to
    68|         0|            0|            0|  0.00%|        `batch_shape`. This method calls :class:`~torch.Tensor.expand` on
    69|         0|            0|            0|  0.00%|        the distribution's parameters. As such, this does not allocate new
    70|         0|            0|            0|  0.00%|        memory for the expanded distribution instance. Additionally,
    71|         0|            0|            0|  0.00%|        this does not repeat any args checking or parameter broadcasting in
    72|         0|            0|            0|  0.00%|        `__init__.py`, when an instance is first created.
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|        Args:
    75|         0|            0|            0|  0.00%|            batch_shape (torch.Size): the desired expanded size.
    76|         0|            0|            0|  0.00%|            _instance: new instance provided by subclasses that
    77|         0|            0|            0|  0.00%|                need to override `.expand`.
    78|         0|            0|            0|  0.00%|
    79|         0|            0|            0|  0.00%|        Returns:
    80|         0|            0|            0|  0.00%|            New distribution instance with batch dimensions expanded to
    81|         0|            0|            0|  0.00%|            `batch_size`.
    82|         0|            0|            0|  0.00%|        """
    83|         0|            0|            0|  0.00%|        raise NotImplementedError
    84|         0|            0|            0|  0.00%|
    85|         0|            0|            0|  0.00%|    @property
    86|         0|            0|            0|  0.00%|    def batch_shape(self):
    87|         0|            0|            0|  0.00%|        """
    88|         0|            0|            0|  0.00%|        Returns the shape over which parameters are batched.
    89|         0|            0|            0|  0.00%|        """
    90|         0|            0|            0|  0.00%|        return self._batch_shape
    91|         0|            0|            0|  0.00%|
    92|         0|            0|            0|  0.00%|    @property
    93|         0|            0|            0|  0.00%|    def event_shape(self):
    94|         0|            0|            0|  0.00%|        """
    95|         0|            0|            0|  0.00%|        Returns the shape of a single sample (without batching).
    96|         0|            0|            0|  0.00%|        """
    97|         0|            0|            0|  0.00%|        return self._event_shape
    98|         0|            0|            0|  0.00%|
    99|         0|            0|            0|  0.00%|    @property
   100|         0|            0|            0|  0.00%|    def arg_constraints(self) -> Dict[str, constraints.Constraint]:
   101|         0|            0|            0|  0.00%|        """
   102|         0|            0|            0|  0.00%|        Returns a dictionary from argument names to
   103|         0|            0|            0|  0.00%|        :class:`~torch.distributions.constraints.Constraint` objects that
   104|         0|            0|            0|  0.00%|        should be satisfied by each argument of this distribution. Args that
   105|         0|            0|            0|  0.00%|        are not tensors need not appear in this dict.
   106|         0|            0|            0|  0.00%|        """
   107|         0|            0|            0|  0.00%|        raise NotImplementedError
   108|         0|            0|            0|  0.00%|
   109|         0|            0|            0|  0.00%|    @property
   110|         0|            0|            0|  0.00%|    def support(self) -> Optional[Any]:
   111|         0|            0|            0|  0.00%|        """
   112|         0|            0|            0|  0.00%|        Returns a :class:`~torch.distributions.constraints.Constraint` object
   113|         0|            0|            0|  0.00%|        representing this distribution's support.
   114|         0|            0|            0|  0.00%|        """
   115|         0|            0|            0|  0.00%|        raise NotImplementedError
   116|         0|            0|            0|  0.00%|
   117|         0|            0|            0|  0.00%|    @property
   118|         0|            0|            0|  0.00%|    def mean(self):
   119|         0|            0|            0|  0.00%|        """
   120|         0|            0|            0|  0.00%|        Returns the mean of the distribution.
   121|         0|            0|            0|  0.00%|        """
   122|         0|            0|            0|  0.00%|        raise NotImplementedError
   123|         0|            0|            0|  0.00%|
   124|         0|            0|            0|  0.00%|    @property
   125|         0|            0|            0|  0.00%|    def mode(self):
   126|         0|            0|            0|  0.00%|        """
   127|         0|            0|            0|  0.00%|        Returns the mode of the distribution.
   128|         0|            0|            0|  0.00%|        """
   129|         0|            0|            0|  0.00%|        raise NotImplementedError(f"{self.__class__} does not implement mode")
   130|         0|            0|            0|  0.00%|
   131|         0|            0|            0|  0.00%|    @property
   132|         0|            0|            0|  0.00%|    def variance(self):
   133|         0|            0|            0|  0.00%|        """
   134|         0|            0|            0|  0.00%|        Returns the variance of the distribution.
   135|         0|            0|            0|  0.00%|        """
   136|         0|            0|            0|  0.00%|        raise NotImplementedError
   137|         0|            0|            0|  0.00%|
   138|         0|            0|            0|  0.00%|    @property
   139|         0|            0|            0|  0.00%|    def stddev(self):
   140|         0|            0|            0|  0.00%|        """
   141|         0|            0|            0|  0.00%|        Returns the standard deviation of the distribution.
   142|         0|            0|            0|  0.00%|        """
   143|         0|            0|            0|  0.00%|        return self.variance.sqrt()
   144|         0|            0|            0|  0.00%|
   145|         0|            0|            0|  0.00%|    def sample(self, sample_shape=torch.Size()):
   146|         0|            0|            0|  0.00%|        """
   147|         0|            0|            0|  0.00%|        Generates a sample_shape shaped sample or sample_shape shaped batch of
   148|         0|            0|            0|  0.00%|        samples if the distribution parameters are batched.
   149|         0|            0|            0|  0.00%|        """
   150|         0|            0|            0|  0.00%|        with torch.no_grad():
   151|         0|            0|            0|  0.00%|            return self.rsample(sample_shape)
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|    def rsample(self, sample_shape=torch.Size()):
   154|         0|            0|            0|  0.00%|        """
   155|         0|            0|            0|  0.00%|        Generates a sample_shape shaped reparameterized sample or sample_shape
   156|         0|            0|            0|  0.00%|        shaped batch of reparameterized samples if the distribution parameters
   157|         0|            0|            0|  0.00%|        are batched.
   158|         0|            0|            0|  0.00%|        """
   159|         0|            0|            0|  0.00%|        raise NotImplementedError
   160|         0|            0|            0|  0.00%|
   161|         0|            0|            0|  0.00%|    def sample_n(self, n):
   162|         0|            0|            0|  0.00%|        """
   163|         0|            0|            0|  0.00%|        Generates n samples or n batches of samples if the distribution
   164|         0|            0|            0|  0.00%|        parameters are batched.
   165|         0|            0|            0|  0.00%|        """
   166|         0|            0|            0|  0.00%|        warnings.warn('sample_n will be deprecated. Use .sample((n,)) instead', UserWarning)
   167|         0|            0|            0|  0.00%|        return self.sample(torch.Size((n,)))
   168|         0|            0|            0|  0.00%|
   169|         0|            0|            0|  0.00%|    def log_prob(self, value):
   170|         0|            0|            0|  0.00%|        """
   171|         0|            0|            0|  0.00%|        Returns the log of the probability density/mass function evaluated at
   172|         0|            0|            0|  0.00%|        `value`.
   173|         0|            0|            0|  0.00%|
   174|         0|            0|            0|  0.00%|        Args:
   175|         0|            0|            0|  0.00%|            value (Tensor):
   176|         0|            0|            0|  0.00%|        """
   177|         0|            0|            0|  0.00%|        raise NotImplementedError
   178|         0|            0|            0|  0.00%|
   179|         0|            0|            0|  0.00%|    def cdf(self, value):
   180|         0|            0|            0|  0.00%|        """
   181|         0|            0|            0|  0.00%|        Returns the cumulative density/mass function evaluated at
   182|         0|            0|            0|  0.00%|        `value`.
   183|         0|            0|            0|  0.00%|
   184|         0|            0|            0|  0.00%|        Args:
   185|         0|            0|            0|  0.00%|            value (Tensor):
   186|         0|            0|            0|  0.00%|        """
   187|         0|            0|            0|  0.00%|        raise NotImplementedError
   188|         0|            0|            0|  0.00%|
   189|         0|            0|            0|  0.00%|    def icdf(self, value):
   190|         0|            0|            0|  0.00%|        """
   191|         0|            0|            0|  0.00%|        Returns the inverse cumulative density/mass function evaluated at
   192|         0|            0|            0|  0.00%|        `value`.
   193|         0|            0|            0|  0.00%|
   194|         0|            0|            0|  0.00%|        Args:
   195|         0|            0|            0|  0.00%|            value (Tensor):
   196|         0|            0|            0|  0.00%|        """
   197|         0|            0|            0|  0.00%|        raise NotImplementedError
   198|         0|            0|            0|  0.00%|
   199|         0|            0|            0|  0.00%|    def enumerate_support(self, expand=True):
   200|         0|            0|            0|  0.00%|        """
   201|         0|            0|            0|  0.00%|        Returns tensor containing all values supported by a discrete
   202|         0|            0|            0|  0.00%|        distribution. The result will enumerate over dimension 0, so the shape
   203|         0|            0|            0|  0.00%|        of the result will be `(cardinality,) + batch_shape + event_shape`
   204|         0|            0|            0|  0.00%|        (where `event_shape = ()` for univariate distributions).
   205|         0|            0|            0|  0.00%|
   206|         0|            0|            0|  0.00%|        Note that this enumerates over all batched tensors in lock-step
   207|         0|            0|            0|  0.00%|        `[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens
   208|         0|            0|            0|  0.00%|        along dim 0, but with the remaining batch dimensions being
   209|         0|            0|            0|  0.00%|        singleton dimensions, `[[0], [1], ..`.
   210|         0|            0|            0|  0.00%|
   211|         0|            0|            0|  0.00%|        To iterate over the full Cartesian product use
   212|         0|            0|            0|  0.00%|        `itertools.product(m.enumerate_support())`.
   213|         0|            0|            0|  0.00%|
   214|         0|            0|            0|  0.00%|        Args:
   215|         0|            0|            0|  0.00%|            expand (bool): whether to expand the support over the
   216|         0|            0|            0|  0.00%|                batch dims to match the distribution's `batch_shape`.
   217|         0|            0|            0|  0.00%|
   218|         0|            0|            0|  0.00%|        Returns:
   219|         0|            0|            0|  0.00%|            Tensor iterating over dimension 0.
   220|         0|            0|            0|  0.00%|        """
   221|         0|            0|            0|  0.00%|        raise NotImplementedError
   222|         0|            0|            0|  0.00%|
   223|         0|            0|            0|  0.00%|    def entropy(self):
   224|         0|            0|            0|  0.00%|        """
   225|         0|            0|            0|  0.00%|        Returns entropy of distribution, batched over batch_shape.
   226|         0|            0|            0|  0.00%|
   227|         0|            0|            0|  0.00%|        Returns:
   228|         0|            0|            0|  0.00%|            Tensor of shape batch_shape.
   229|         0|            0|            0|  0.00%|        """
   230|         0|            0|            0|  0.00%|        raise NotImplementedError
   231|         0|            0|            0|  0.00%|
   232|         0|            0|            0|  0.00%|    def perplexity(self):
   233|         0|            0|            0|  0.00%|        """
   234|         0|            0|            0|  0.00%|        Returns perplexity of distribution, batched over batch_shape.
   235|         0|            0|            0|  0.00%|
   236|         0|            0|            0|  0.00%|        Returns:
   237|         0|            0|            0|  0.00%|            Tensor of shape batch_shape.
   238|         0|            0|            0|  0.00%|        """
   239|         0|            0|            0|  0.00%|        return torch.exp(self.entropy())
   240|         0|            0|            0|  0.00%|
   241|      2304|   0.00456834|  1.98279e-06|  0.00%|    def _extended_shape(self, sample_shape=torch.Size()):
   242|         0|            0|            0|  0.00%|        """
   243|         0|            0|            0|  0.00%|        Returns the size of the sample returned by the distribution, given
   244|         0|            0|            0|  0.00%|        a `sample_shape`. Note, that the batch and event shapes of a distribution
   245|         0|            0|            0|  0.00%|        instance are fixed at the time of construction. If this is empty, the
   246|         0|            0|            0|  0.00%|        returned shape is upcast to (1,).
   247|         0|            0|            0|  0.00%|
   248|         0|            0|            0|  0.00%|        Args:
   249|         0|            0|            0|  0.00%|            sample_shape (torch.Size): the size of the sample to be drawn.
   250|         0|            0|            0|  0.00%|        """
   251|      2304|   0.00541377|  2.34973e-06|  0.01%|        if not isinstance(sample_shape, torch.Size):
   252|         0|            0|            0|  0.00%|            sample_shape = torch.Size(sample_shape)
   253|      2304|   0.00827384|  3.59108e-06|  0.01%|        return sample_shape + self._batch_shape + self._event_shape
   254|         0|            0|            0|  0.00%|
   255|      2610|   0.00848556|  3.25117e-06|  0.01%|    def _validate_sample(self, value):
   256|         0|            0|            0|  0.00%|        """
   257|         0|            0|            0|  0.00%|        Argument validation for distribution methods such as `log_prob`,
   258|         0|            0|            0|  0.00%|        `cdf` and `icdf`. The rightmost dimensions of a value to be
   259|         0|            0|            0|  0.00%|        scored via these methods must agree with the distribution's batch
   260|         0|            0|            0|  0.00%|        and event shapes.
   261|         0|            0|            0|  0.00%|
   262|         0|            0|            0|  0.00%|        Args:
   263|         0|            0|            0|  0.00%|            value (Tensor): the tensor whose log probability is to be
   264|         0|            0|            0|  0.00%|                computed by the `log_prob` method.
   265|         0|            0|            0|  0.00%|        Raises
   266|         0|            0|            0|  0.00%|            ValueError: when the rightmost dimensions of `value` do not match the
   267|         0|            0|            0|  0.00%|                distribution's batch and event shapes.
   268|         0|            0|            0|  0.00%|        """
   269|      2610|   0.00996637|  3.81853e-06|  0.01%|        if not isinstance(value, torch.Tensor):
   270|         0|            0|            0|  0.00%|            raise ValueError('The value argument to log_prob must be a Tensor')
   271|         0|            0|            0|  0.00%|
   272|      2610|    0.0131278|  5.02981e-06|  0.01%|        event_dim_start = len(value.size()) - len(self._event_shape)
   273|      2610|    0.0128701|  4.93106e-06|  0.01%|        if value.size()[event_dim_start:] != self._event_shape:
   274|         0|            0|            0|  0.00%|            raise ValueError('The right-most size of value must match event_shape: {} vs {}.'.
   275|         0|            0|            0|  0.00%|                             format(value.size(), self._event_shape))
   276|         0|            0|            0|  0.00%|
   277|      2610|   0.00936317|  3.58742e-06|  0.01%|        actual_shape = value.size()
   278|      2610|   0.00974607|  3.73413e-06|  0.01%|        expected_shape = self._batch_shape + self._event_shape
   279|      5220|    0.0206566|   3.9572e-06|  0.02%|        for i, j in zip(reversed(actual_shape), reversed(expected_shape)):
   280|      2610|   0.00837994|   3.2107e-06|  0.01%|            if i != 1 and j != 1 and i != j:
   281|         0|            0|            0|  0.00%|                raise ValueError('Value is not broadcastable with batch_shape+event_shape: {} vs {}.'.
   282|         0|            0|            0|  0.00%|                                 format(actual_shape, expected_shape))
   283|      2610|   0.00658727|  2.52386e-06|  0.01%|        try:
   284|      2610|    0.0215819|  8.26892e-06|  0.02%|            support = self.support
(call)|      2610|    0.0511703|  1.96055e-05|  0.05%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/categorical.py:84 support
   285|         0|            0|            0|  0.00%|        except NotImplementedError:
   286|         0|            0|            0|  0.00%|            warnings.warn(f'{self.__class__} does not define `support` to enable ' +
   287|         0|            0|            0|  0.00%|                          'sample validation. Please initialize the distribution with ' +
   288|         0|            0|            0|  0.00%|                          '`validate_args=False` to turn off validation.')
   289|         0|            0|            0|  0.00%|            return
   290|      2610|   0.00851941|  3.26414e-06|  0.01%|        assert support is not None
   291|      2610|    0.0251491|  9.63567e-06|  0.02%|        valid = support.check(value)
(call)|      2610|     0.132831|   5.0893e-05|  0.13%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/constraints.py:256 check
   292|      2610|    0.0310099|  1.18812e-05|  0.03%|        if not valid.all():
   293|         0|            0|            0|  0.00%|            raise ValueError(
   294|         0|            0|            0|  0.00%|                "Expected value argument "
   295|         0|            0|            0|  0.00%|                f"({type(value).__name__} of shape {tuple(value.shape)}) "
   296|         0|            0|            0|  0.00%|                f"to be within the support ({repr(support)}) "
   297|         0|            0|            0|  0.00%|                f"of the distribution {repr(self)}, "
   298|         0|            0|            0|  0.00%|                f"but found invalid values:\n{value}"
   299|         0|            0|            0|  0.00%|            )
   300|         0|            0|            0|  0.00%|
   301|         0|            0|            0|  0.00%|    def _get_checked_instance(self, cls, _instance=None):
   302|         0|            0|            0|  0.00%|        if _instance is None and type(self).__init__ != cls.__init__:
   303|         0|            0|            0|  0.00%|            raise NotImplementedError("Subclass {} of {} that defines a custom __init__ method "
   304|         0|            0|            0|  0.00%|                                      "must also define a custom .expand() method.".
   305|         0|            0|            0|  0.00%|                                      format(self.__class__.__name__, cls.__name__))
   306|         0|            0|            0|  0.00%|        return self.__new__(type(self)) if _instance is None else _instance
   307|         0|            0|            0|  0.00%|
   308|         0|            0|            0|  0.00%|    def __repr__(self):
   309|         0|            0|            0|  0.00%|        param_names = [k for k, _ in self.arg_constraints.items() if k in self.__dict__]
   310|         0|            0|            0|  0.00%|        args_string = ', '.join(['{}: {}'.format(p, self.__dict__[p]
   311|         0|            0|            0|  0.00%|                                if self.__dict__[p].numel() == 1
   312|         0|            0|            0|  0.00%|                                else self.__dict__[p].size()) for p in param_names])
   313|         0|            0|            0|  0.00%|        return self.__class__.__name__ + '(' + args_string + ')'
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py
File duration: 0.431961s (0.41%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|from collections import OrderedDict
     2|         0|            0|            0|  0.00%|import enum
     3|         0|            0|            0|  0.00%|import functools
     4|         0|            0|            0|  0.00%|from numbers import Number
     5|         0|            0|            0|  0.00%|from typing import Any, Dict, Optional, Tuple, Union
     6|         0|            0|            0|  0.00%|import warnings
     7|         0|            0|            0|  0.00%|import copyreg
     8|         0|            0|            0|  0.00%|from copy import deepcopy
     9|         0|            0|            0|  0.00%|
    10|         0|            0|            0|  0.00%|import torch
    11|         0|            0|            0|  0.00%|import torch._C as _C
    12|         0|            0|            0|  0.00%|from torch._namedtensor_internals import (
    13|         0|            0|            0|  0.00%|    update_names, check_serializing_named_tensor, resolve_ellipsis,
    14|         0|            0|            0|  0.00%|    unzip_namedshape, single_ellipsis_index, is_ellipsis)
    15|         0|            0|            0|  0.00%|from torch.overrides import (
    16|         0|            0|            0|  0.00%|    has_torch_function, has_torch_function_unary, has_torch_function_variadic,
    17|         0|            0|            0|  0.00%|    handle_torch_function, get_default_nowrap_functions)
    18|         0|            0|            0|  0.00%|import torch.utils.hooks as hooks
    19|         0|            0|            0|  0.00%|
    20|         0|            0|            0|  0.00%|
    21|         0|            0|            0|  0.00%|def _handle_torch_function_and_wrap_type_error_to_not_implemented(f):
    22|         0|            0|            0|  0.00%|    # functools.wraps doesn't work well with methods in python 2
    23|         0|            0|            0|  0.00%|    method_assignments = ('__name__', '__doc__')
    24|         0|            0|            0|  0.00%|    assigned = functools.WRAPPER_ASSIGNMENTS
    25|         0|            0|            0|  0.00%|
    26|      3168|   0.00931716|  2.94102e-06|  0.01%|    @functools.wraps(f, assigned=assigned)
    27|         0|            0|            0|  0.00%|    def wrapped(*args, **kwargs):
    28|      3168|   0.00631785|  1.99427e-06|  0.01%|        try:
    29|         0|            0|            0|  0.00%|            # See https://github.com/pytorch/pytorch/issues/75462
    30|      3168|   0.00621843|  1.96289e-06|  0.01%|            if has_torch_function(args):
    31|         0|            0|            0|  0.00%|                return handle_torch_function(wrapped, args, *args, **kwargs)
    32|      3168|    0.0233195|  7.36095e-06|  0.02%|            return f(*args, **kwargs)
(call)|      2304|    0.0277846|  1.20593e-05|  0.03%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:637 __rsub__
(call)|       288|   0.00544024|  1.88897e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:641 __rdiv__
    33|         0|            0|            0|  0.00%|        except TypeError:
    34|         0|            0|            0|  0.00%|            return NotImplemented
    35|         0|            0|            0|  0.00%|    return wrapped
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|# Should not be used, this is kept only for BC of loading old serialized Tensor subclasses
    38|         0|            0|            0|  0.00%|def _rebuild_from_type(func, type, args, dict):
    39|         0|            0|            0|  0.00%|    if type is Tensor:
    40|         0|            0|            0|  0.00%|        return func(*args)
    41|         0|            0|            0|  0.00%|
    42|         0|            0|            0|  0.00%|    ret = func(*args).as_subclass(type)
    43|         0|            0|            0|  0.00%|    ret.__dict__ = dict
    44|         0|            0|            0|  0.00%|    return ret
    45|         0|            0|            0|  0.00%|
    46|         0|            0|            0|  0.00%|def _rebuild_from_type_v2(func, new_type, args, state):
    47|         0|            0|            0|  0.00%|    if new_type is Tensor:
    48|         0|            0|            0|  0.00%|        return func(*args)
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|    ret = func(*args)
    51|         0|            0|            0|  0.00%|    if type(ret) is not new_type:
    52|         0|            0|            0|  0.00%|        ret = ret.as_subclass(new_type)
    53|         0|            0|            0|  0.00%|    # Tensor does define __setstate__ even though it doesn't define
    54|         0|            0|            0|  0.00%|    # __getstate__. So only use __setstate__ if it is NOT the one defined
    55|         0|            0|            0|  0.00%|    # on Tensor
    56|         0|            0|            0|  0.00%|    if getattr(ret.__class__, "__setstate__", Tensor.__setstate__) is not Tensor.__setstate__:
    57|         0|            0|            0|  0.00%|        ret.__setstate__(state)
    58|         0|            0|            0|  0.00%|    else:
    59|         0|            0|            0|  0.00%|        if isinstance(state, tuple):
    60|         0|            0|            0|  0.00%|            if not len(state) == 2:
    61|         0|            0|            0|  0.00%|                raise RuntimeError(f"Invalid serialized state: {state}")
    62|         0|            0|            0|  0.00%|            dict_state = state[0]
    63|         0|            0|            0|  0.00%|            slots_state = state[1]
    64|         0|            0|            0|  0.00%|        else:
    65|         0|            0|            0|  0.00%|            dict_state = state
    66|         0|            0|            0|  0.00%|            slots_state = None
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|        for k, v in dict_state.items():
    69|         0|            0|            0|  0.00%|            setattr(ret, k, v)
    70|         0|            0|            0|  0.00%|
    71|         0|            0|            0|  0.00%|        if slots_state:
    72|         0|            0|            0|  0.00%|            for k, v in slots_state.items():
    73|         0|            0|            0|  0.00%|                setattr(ret, k, v)
    74|         0|            0|            0|  0.00%|    return ret
    75|         0|            0|            0|  0.00%|
    76|         0|            0|            0|  0.00%|
    77|         0|            0|            0|  0.00%|# NB: If you subclass Tensor, and want to share the subclassed class
    78|         0|            0|            0|  0.00%|# across processes, you must also update torch/multiprocessing/reductions.py
    79|         0|            0|            0|  0.00%|# to define a ForkingPickler serialization mode for the class.
    80|         0|            0|            0|  0.00%|#
    81|         0|            0|            0|  0.00%|# NB: If you add a new method to Tensor, you must update
    82|         0|            0|            0|  0.00%|# torch/__init__.py.in to add a type annotation for your method;
    83|         0|            0|            0|  0.00%|# otherwise, it will not show up in autocomplete.
    84|         0|            0|            0|  0.00%|class Tensor(torch._C._TensorBase):
    85|         0|            0|            0|  0.00%|    def __deepcopy__(self, memo):
    86|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
    87|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__deepcopy__, (self,), self, memo)
    88|         0|            0|            0|  0.00%|        if not self.is_leaf:
    89|         0|            0|            0|  0.00%|            raise RuntimeError("Only Tensors created explicitly by the user "
    90|         0|            0|            0|  0.00%|                               "(graph leaves) support the deepcopy protocol at the moment")
    91|         0|            0|            0|  0.00%|        if id(self) in memo:
    92|         0|            0|            0|  0.00%|            return memo[id(self)]
    93|         0|            0|            0|  0.00%|        with torch.no_grad():
    94|         0|            0|            0|  0.00%|            # TODO: skipping storage copy is wrong for meta, as meta
    95|         0|            0|            0|  0.00%|            # does accurate alias tracking; however, the code below
    96|         0|            0|            0|  0.00%|            # doesn't work because of
    97|         0|            0|            0|  0.00%|            # https://github.com/pytorch/pytorch/issues/47442
    98|         0|            0|            0|  0.00%|            # Update the test in test_serialization if you remove 'meta' from here
    99|         0|            0|            0|  0.00%|            if self.is_sparse or self.device.type in ['lazy', 'xla', 'mps', 'ort', 'meta', 'hpu'] or \
   100|         0|            0|            0|  0.00%|                    (type(self) is not Tensor and self.data_ptr() == 0):
   101|         0|            0|            0|  0.00%|                new_tensor = self.clone()
   102|         0|            0|            0|  0.00%|                if type(new_tensor) is not type(self):
   103|         0|            0|            0|  0.00%|                    raise RuntimeError("The default implementation of __deepcopy__() for wrapper subclasses "
   104|         0|            0|            0|  0.00%|                                       "only works for subclass types that implement clone() and for which "
   105|         0|            0|            0|  0.00%|                                       "cloning returns another instance of the same subclass. You should either "
   106|         0|            0|            0|  0.00%|                                       "properly implement clone() for your subclass or override __deepcopy__() "
   107|         0|            0|            0|  0.00%|                                       "if it is intended behavior for clone() to return an instance of a "
   108|         0|            0|            0|  0.00%|                                       "different type.")
   109|         0|            0|            0|  0.00%|            else:
   110|         0|            0|            0|  0.00%|                new_storage = self.storage().__deepcopy__(memo)
   111|         0|            0|            0|  0.00%|                if self.is_quantized:
   112|         0|            0|            0|  0.00%|                    # quantizer_params can be different type based on torch attribute
   113|         0|            0|            0|  0.00%|                    quantizer_params: Union[Tuple[torch.qscheme, float, int], Tuple[torch.qscheme, Tensor, Tensor, int]]
   114|         0|            0|            0|  0.00%|                    if self.qscheme() == torch.per_tensor_affine:
   115|         0|            0|            0|  0.00%|                        quantizer_params = self.qscheme(), self.q_scale(), self.q_zero_point()
   116|         0|            0|            0|  0.00%|                    elif self.qscheme() in (torch.per_channel_affine, torch.per_channel_affine_float_qparams):
   117|         0|            0|            0|  0.00%|                        quantizer_params = self.qscheme(), \
   118|         0|            0|            0|  0.00%|                            self.q_per_channel_scales(), \
   119|         0|            0|            0|  0.00%|                            self.q_per_channel_zero_points(), \
   120|         0|            0|            0|  0.00%|                            self.q_per_channel_axis()
   121|         0|            0|            0|  0.00%|                    else:
   122|         0|            0|            0|  0.00%|                        raise RuntimeError(f"Unsupported qscheme {self.qscheme()} in deepcopy")
   123|         0|            0|            0|  0.00%|                    # TODO: Once we decide to break serialization FC, no longer
   124|         0|            0|            0|  0.00%|                    # need to wrap with _TypedStorage
   125|         0|            0|            0|  0.00%|                    new_tensor = torch._utils._rebuild_qtensor(
   126|         0|            0|            0|  0.00%|                        torch.storage._TypedStorage(
   127|         0|            0|            0|  0.00%|                            wrap_storage=new_storage._untyped(),
   128|         0|            0|            0|  0.00%|                            dtype=self.dtype),
   129|         0|            0|            0|  0.00%|                        self.storage_offset(),
   130|         0|            0|            0|  0.00%|                        self.size(),
   131|         0|            0|            0|  0.00%|                        self.stride(),
   132|         0|            0|            0|  0.00%|                        quantizer_params,
   133|         0|            0|            0|  0.00%|                        self.requires_grad,
   134|         0|            0|            0|  0.00%|                        self._backward_hooks)
   135|         0|            0|            0|  0.00%|                    if type(new_tensor) is not type(self):
   136|         0|            0|            0|  0.00%|                        raise RuntimeError("The default implementation of __deepcopy__() for quantized tensors "
   137|         0|            0|            0|  0.00%|                                           "expects the tensor returned by torch._utils._rebuild_qtensor() to "
   138|         0|            0|            0|  0.00%|                                           "match the type of the instance being copied. If you encounter this, "
   139|         0|            0|            0|  0.00%|                                           "please open an issue on PyTorch's GitHub.")
   140|         0|            0|            0|  0.00%|                else:
   141|         0|            0|            0|  0.00%|                    new_tensor = self.new_empty([])
   142|         0|            0|            0|  0.00%|                    if type(new_tensor) is not type(self):
   143|         0|            0|            0|  0.00%|                        raise RuntimeError("The default implementation of __deepcopy__() for non-wrapper subclasses "
   144|         0|            0|            0|  0.00%|                                           "only works for subclass types that implement new_empty() and for which "
   145|         0|            0|            0|  0.00%|                                           "that function returns another instance of the same subclass. You should "
   146|         0|            0|            0|  0.00%|                                           "either properly implement new_empty() for your subclass or override "
   147|         0|            0|            0|  0.00%|                                           "__deepcopy__() if it is intended behavior for new_empty() to return "
   148|         0|            0|            0|  0.00%|                                           "an instance of a different type.")
   149|         0|            0|            0|  0.00%|                    new_tensor.set_(new_storage, self.storage_offset(), self.size(), self.stride())
   150|         0|            0|            0|  0.00%|                    if self.is_conj():
   151|         0|            0|            0|  0.00%|                        new_tensor = new_tensor.conj_physical()
   152|         0|            0|            0|  0.00%|                    if self.is_neg():
   153|         0|            0|            0|  0.00%|                        new_tensor = new_tensor.neg()
   154|         0|            0|            0|  0.00%|            if self.requires_grad:
   155|         0|            0|            0|  0.00%|                new_tensor.requires_grad_()
   156|         0|            0|            0|  0.00%|            if self.grad is not None:
   157|         0|            0|            0|  0.00%|                new_tensor.grad = self.grad.__deepcopy__(memo)
   158|         0|            0|            0|  0.00%|
   159|         0|            0|            0|  0.00%|            if not type(self) is Tensor:
   160|         0|            0|            0|  0.00%|                if type(new_tensor) is not type(self):
   161|         0|            0|            0|  0.00%|                    raise RuntimeError("Type of deepcopy result does not match the type of the source tensor. "
   162|         0|            0|            0|  0.00%|                                       "If you encounter this, please open an issue on PyTorch's GitHub.")
   163|         0|            0|            0|  0.00%|
   164|         0|            0|            0|  0.00%|                # Plain Tensors don't have slots
   165|         0|            0|            0|  0.00%|                slots_to_save = copyreg._slotnames(self.__class__)  # type: ignore[attr-defined]
   166|         0|            0|            0|  0.00%|                for slot in slots_to_save:
   167|         0|            0|            0|  0.00%|                    if hasattr(self, slot):
   168|         0|            0|            0|  0.00%|                        setattr(new_tensor, slot, deepcopy(getattr(self, slot), memo))
   169|         0|            0|            0|  0.00%|
   170|         0|            0|            0|  0.00%|            new_tensor.__dict__ = deepcopy(self.__dict__, memo)
   171|         0|            0|            0|  0.00%|
   172|         0|            0|            0|  0.00%|            memo[id(self)] = new_tensor
   173|         0|            0|            0|  0.00%|            return new_tensor
   174|         0|            0|            0|  0.00%|
   175|         0|            0|            0|  0.00%|    def __reduce_ex__(self, proto):
   176|         0|            0|            0|  0.00%|        if type(self) is Tensor:
   177|         0|            0|            0|  0.00%|            return self._reduce_ex_internal(proto)
   178|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   179|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__reduce_ex__, (self,), self, proto)
   180|         0|            0|            0|  0.00%|        func, args = self._reduce_ex_internal(proto)
   181|         0|            0|            0|  0.00%|        # Get the state of the python subclass
   182|         0|            0|            0|  0.00%|        # This loosely mimicks the function on the object class but since Tensor do not inherit
   183|         0|            0|            0|  0.00%|        # from it, we cannot call that function directly
   184|         0|            0|            0|  0.00%|        # https://github.com/python/cpython/blob/c83919bd635f4433f1c6ae8504996a9fe3c215e5/Objects/typeobject.c#L4891
   185|         0|            0|            0|  0.00%|        getstate_fn = getattr(self, "__getstate__", None)
   186|         0|            0|            0|  0.00%|        if getstate_fn:
   187|         0|            0|            0|  0.00%|            state = getstate_fn()
   188|         0|            0|            0|  0.00%|        else:
   189|         0|            0|            0|  0.00%|            slots_to_save = copyreg._slotnames(self.__class__)  # type: ignore[attr-defined]
   190|         0|            0|            0|  0.00%|            if slots_to_save:
   191|         0|            0|            0|  0.00%|                state = (self.__dict__, {name: getattr(self, name) for name in slots_to_save if hasattr(self, name)})
   192|         0|            0|            0|  0.00%|            else:
   193|         0|            0|            0|  0.00%|                state = self.__dict__
   194|         0|            0|            0|  0.00%|        return (_rebuild_from_type_v2, (func, type(self), args, state))
   195|         0|            0|            0|  0.00%|
   196|         0|            0|            0|  0.00%|    def storage(self):
   197|         0|            0|            0|  0.00%|        r"""
   198|         0|            0|            0|  0.00%|        storage() -> torch.Storage
   199|         0|            0|            0|  0.00%|
   200|         0|            0|            0|  0.00%|        Returns the underlying storage.
   201|         0|            0|            0|  0.00%|        """
   202|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   203|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.storage, (self,), self)
   204|         0|            0|            0|  0.00%|
   205|         0|            0|            0|  0.00%|        return torch._TypedStorage(wrap_storage=self._storage(), dtype=self.dtype)
   206|         0|            0|            0|  0.00%|
   207|         0|            0|            0|  0.00%|    def _reduce_ex_internal(self, proto):
   208|         0|            0|            0|  0.00%|        check_serializing_named_tensor(self)
   209|         0|            0|            0|  0.00%|        # See Note [Don't serialize hooks]
   210|         0|            0|            0|  0.00%|        torch.utils.hooks.warn_if_has_hooks(self)
   211|         0|            0|            0|  0.00%|        backward_hooks: Dict[Any, Any] = OrderedDict()
   212|         0|            0|            0|  0.00%|        # Note: Numpy array is chosen to be the rebuild component for XLA, ORT Tensors.
   213|         0|            0|            0|  0.00%|        # We considered a few options:
   214|         0|            0|            0|  0.00%|        # 1. CPU tensor can't be used here.
   215|         0|            0|            0|  0.00%|        #    Otherwise in torch.load CPU storage is reconstructed with randomly
   216|         0|            0|            0|  0.00%|        #    initialized data, moved onto backend device, and then storage is updated
   217|         0|            0|            0|  0.00%|        #    to the serialized content. This works perfectly for CPU/CUDA but not these backends;
   218|         0|            0|            0|  0.00%|        #    their tensors are disconnected with storage so they don't get the update.
   219|         0|            0|            0|  0.00%|        # 2. Python list is not a good fit due to performance reason.
   220|         0|            0|            0|  0.00%|        #    `tolist()` converts every single element in the tensor into python objects
   221|         0|            0|            0|  0.00%|        #    and serialize them one by one.
   222|         0|            0|            0|  0.00%|        if self.device.type in ['xla', 'ort', 'mps', 'hpu']:
   223|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_device_tensor_from_numpy, (self.cpu().numpy(),
   224|         0|            0|            0|  0.00%|                                                                     self.dtype,
   225|         0|            0|            0|  0.00%|                                                                     str(self.device),
   226|         0|            0|            0|  0.00%|                                                                     self.requires_grad))
   227|         0|            0|            0|  0.00%|        if self.device.type == 'meta':
   228|         0|            0|            0|  0.00%|            # NB: This implementation BREAKS storage sharing.  Current
   229|         0|            0|            0|  0.00%|            # hypothesis is that no one cares for meta tensors.
   230|         0|            0|            0|  0.00%|            arg_meta = (
   231|         0|            0|            0|  0.00%|                self.dtype,
   232|         0|            0|            0|  0.00%|                tuple(self.size()),
   233|         0|            0|            0|  0.00%|                self.stride(),
   234|         0|            0|            0|  0.00%|                self.requires_grad,
   235|         0|            0|            0|  0.00%|            )
   236|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_meta_tensor_no_storage, arg_meta)
   237|         0|            0|            0|  0.00%|        if self.is_quantized:
   238|         0|            0|            0|  0.00%|            # quantizer_params can be different type based on torch attribute
   239|         0|            0|            0|  0.00%|            quantizer_params: Union[Tuple[torch.qscheme, float, int], Tuple[Any, Tensor, Tensor, int]]
   240|         0|            0|            0|  0.00%|            if self.qscheme() == torch.per_tensor_affine:
   241|         0|            0|            0|  0.00%|                quantizer_params = (torch.per_tensor_affine,
   242|         0|            0|            0|  0.00%|                                    self.q_scale(),
   243|         0|            0|            0|  0.00%|                                    self.q_zero_point())
   244|         0|            0|            0|  0.00%|            elif self.qscheme() in (torch.per_channel_affine, torch.per_channel_affine_float_qparams):
   245|         0|            0|            0|  0.00%|                # convert scales and zero points to tuple to avoid recursive calls
   246|         0|            0|            0|  0.00%|                # when/if we get multi-axis quantized tensors in the future, the shape
   247|         0|            0|            0|  0.00%|                # is recoverable from the main tensor shape
   248|         0|            0|            0|  0.00%|                quantizer_params = (torch.per_channel_affine,
   249|         0|            0|            0|  0.00%|                                    self.q_per_channel_scales(),
   250|         0|            0|            0|  0.00%|                                    self.q_per_channel_zero_points(),
   251|         0|            0|            0|  0.00%|                                    self.q_per_channel_axis())
   252|         0|            0|            0|  0.00%|            else:
   253|         0|            0|            0|  0.00%|                raise RuntimeError(f"Serialization is not supported for tensors of type {self.qscheme()}")
   254|         0|            0|            0|  0.00%|            # TODO: Once we decide to break serialization FC, no longer
   255|         0|            0|            0|  0.00%|            # need to wrap with _TypedStorage
   256|         0|            0|            0|  0.00%|            args_qtensor = (
   257|         0|            0|            0|  0.00%|                torch.storage._TypedStorage(
   258|         0|            0|            0|  0.00%|                    wrap_storage=self.storage()._untyped(),
   259|         0|            0|            0|  0.00%|                    dtype=self.dtype),
   260|         0|            0|            0|  0.00%|                self.storage_offset(),
   261|         0|            0|            0|  0.00%|                tuple(self.size()),
   262|         0|            0|            0|  0.00%|                self.stride(),
   263|         0|            0|            0|  0.00%|                quantizer_params,
   264|         0|            0|            0|  0.00%|                self.requires_grad,
   265|         0|            0|            0|  0.00%|                backward_hooks)
   266|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_qtensor, args_qtensor)
   267|         0|            0|            0|  0.00%|        elif self.is_sparse:
   268|         0|            0|            0|  0.00%|            if self.layout == torch.sparse_coo:
   269|         0|            0|            0|  0.00%|                args_sparse = (self.layout,
   270|         0|            0|            0|  0.00%|                               (self._indices(),
   271|         0|            0|            0|  0.00%|                                self._values(),
   272|         0|            0|            0|  0.00%|                                self.size()))
   273|         0|            0|            0|  0.00%|            else:
   274|         0|            0|            0|  0.00%|                raise NotImplementedError(
   275|         0|            0|            0|  0.00%|                    'sparse tensor __reduce_ex__ for layout `%s`' % (self.layout))
   276|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_sparse_tensor, args_sparse)
   277|         0|            0|            0|  0.00%|        elif self.is_sparse_csr:
   278|         0|            0|            0|  0.00%|            if self.layout == torch.sparse_csr:
   279|         0|            0|            0|  0.00%|                args_sparse_csr = (self.layout,
   280|         0|            0|            0|  0.00%|                                   (self.crow_indices(),
   281|         0|            0|            0|  0.00%|                                    self.col_indices(),
   282|         0|            0|            0|  0.00%|                                    self.values(),
   283|         0|            0|            0|  0.00%|                                    self.size()))
   284|         0|            0|            0|  0.00%|            else:
   285|         0|            0|            0|  0.00%|                raise NotImplementedError(
   286|         0|            0|            0|  0.00%|                    'sparse csr tensor __reduce_ex__ for layout `%s`' % (self.layout))
   287|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_sparse_csr_tensor, args_sparse_csr)
   288|         0|            0|            0|  0.00%|        elif self.data_ptr() == 0 and type(self) is not torch.Tensor:
   289|         0|            0|            0|  0.00%|            arg_wrapper_subclass = (
   290|         0|            0|            0|  0.00%|                type(self),
   291|         0|            0|            0|  0.00%|                self.dtype,
   292|         0|            0|            0|  0.00%|                tuple(self.size()),
   293|         0|            0|            0|  0.00%|                self.stride(),
   294|         0|            0|            0|  0.00%|                self.storage_offset(),
   295|         0|            0|            0|  0.00%|                self.layout,
   296|         0|            0|            0|  0.00%|                self.device,
   297|         0|            0|            0|  0.00%|                self.requires_grad
   298|         0|            0|            0|  0.00%|            )
   299|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_wrapper_subclass, arg_wrapper_subclass)
   300|         0|            0|            0|  0.00%|        else:
   301|         0|            0|            0|  0.00%|            # TODO: Once we decide to break serialization FC, no longer
   302|         0|            0|            0|  0.00%|            # need to wrap with _TypedStorage
   303|         0|            0|            0|  0.00%|            args = (
   304|         0|            0|            0|  0.00%|                torch.storage._TypedStorage(
   305|         0|            0|            0|  0.00%|                    wrap_storage=self.storage()._untyped(),
   306|         0|            0|            0|  0.00%|                    dtype=self.dtype),
   307|         0|            0|            0|  0.00%|                self.storage_offset(),
   308|         0|            0|            0|  0.00%|                tuple(self.size()),
   309|         0|            0|            0|  0.00%|                self.stride(),
   310|         0|            0|            0|  0.00%|                self.requires_grad,
   311|         0|            0|            0|  0.00%|                backward_hooks)  # previously was self._backward_hooks
   312|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_tensor_v2, args)
   313|         0|            0|            0|  0.00%|
   314|         0|            0|            0|  0.00%|    def __setstate__(self, state):
   315|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   316|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__setstate__, (self,), self, state)
   317|         0|            0|            0|  0.00%|        # Warning: this method is NOT called when you torch.load() a tensor;
   318|         0|            0|            0|  0.00%|        # that is managed by _rebuild_tensor_v2
   319|         0|            0|            0|  0.00%|        if not self.is_leaf:
   320|         0|            0|            0|  0.00%|            raise RuntimeError('__setstate__ can be only called on leaf Tensors')
   321|         0|            0|            0|  0.00%|        if len(state) == 4:
   322|         0|            0|            0|  0.00%|            # legacy serialization of Tensor
   323|         0|            0|            0|  0.00%|            self.set_(*state)
   324|         0|            0|            0|  0.00%|            return
   325|         0|            0|            0|  0.00%|        elif len(state) == 5:
   326|         0|            0|            0|  0.00%|            # legacy serialization of Variable
   327|         0|            0|            0|  0.00%|            self.data = state[0]
   328|         0|            0|            0|  0.00%|            state = (state[3], state[4], state[2])
   329|         0|            0|            0|  0.00%|        # The setting of _backward_hooks is expected to be a no-op.
   330|         0|            0|            0|  0.00%|        # See Note [Don't serialize hooks]
   331|         0|            0|            0|  0.00%|        self.requires_grad, _, self._backward_hooks = state
   332|         0|            0|            0|  0.00%|
   333|         0|            0|            0|  0.00%|    def __repr__(self, *, tensor_contents=None):
   334|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   335|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__repr__, (self,), self,
   336|         0|            0|            0|  0.00%|                                         tensor_contents=tensor_contents)
   337|         0|            0|            0|  0.00%|        # All strings are unicode in Python 3.
   338|         0|            0|            0|  0.00%|        return torch._tensor_str._str(self, tensor_contents=tensor_contents)
   339|         0|            0|            0|  0.00%|
   340|       288|   0.00079751|  2.76913e-06|  0.00%|    def backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None):
   341|         0|            0|            0|  0.00%|        r"""Computes the gradient of current tensor w.r.t. graph leaves.
   342|         0|            0|            0|  0.00%|
   343|         0|            0|            0|  0.00%|        The graph is differentiated using the chain rule. If the tensor is
   344|         0|            0|            0|  0.00%|        non-scalar (i.e. its data has more than one element) and requires
   345|         0|            0|            0|  0.00%|        gradient, the function additionally requires specifying ``gradient``.
   346|         0|            0|            0|  0.00%|        It should be a tensor of matching type and location, that contains
   347|         0|            0|            0|  0.00%|        the gradient of the differentiated function w.r.t. ``self``.
   348|         0|            0|            0|  0.00%|
   349|         0|            0|            0|  0.00%|        This function accumulates gradients in the leaves - you might need to zero
   350|         0|            0|            0|  0.00%|        ``.grad`` attributes or set them to ``None`` before calling it.
   351|         0|            0|            0|  0.00%|        See :ref:`Default gradient layouts<default-grad-layouts>`
   352|         0|            0|            0|  0.00%|        for details on the memory layout of accumulated gradients.
   353|         0|            0|            0|  0.00%|
   354|         0|            0|            0|  0.00%|        .. note::
   355|         0|            0|            0|  0.00%|
   356|         0|            0|            0|  0.00%|            If you run any forward ops, create ``gradient``, and/or call ``backward``
   357|         0|            0|            0|  0.00%|            in a user-specified CUDA stream context, see
   358|         0|            0|            0|  0.00%|            :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.
   359|         0|            0|            0|  0.00%|
   360|         0|            0|            0|  0.00%|        .. note::
   361|         0|            0|            0|  0.00%|
   362|         0|            0|            0|  0.00%|            When ``inputs`` are provided and a given input is not a leaf,
   363|         0|            0|            0|  0.00%|            the current implementation will call its grad_fn (though it is not strictly needed to get this gradients).
   364|         0|            0|            0|  0.00%|            It is an implementation detail on which the user should not rely.
   365|         0|            0|            0|  0.00%|            See https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780 for more details.
   366|         0|            0|            0|  0.00%|
   367|         0|            0|            0|  0.00%|        Args:
   368|         0|            0|            0|  0.00%|            gradient (Tensor or None): Gradient w.r.t. the
   369|         0|            0|            0|  0.00%|                tensor. If it is a tensor, it will be automatically converted
   370|         0|            0|            0|  0.00%|                to a Tensor that does not require grad unless ``create_graph`` is True.
   371|         0|            0|            0|  0.00%|                None values can be specified for scalar Tensors or ones that
   372|         0|            0|            0|  0.00%|                don't require grad. If a None value would be acceptable then
   373|         0|            0|            0|  0.00%|                this argument is optional.
   374|         0|            0|            0|  0.00%|            retain_graph (bool, optional): If ``False``, the graph used to compute
   375|         0|            0|            0|  0.00%|                the grads will be freed. Note that in nearly all cases setting
   376|         0|            0|            0|  0.00%|                this option to True is not needed and often can be worked around
   377|         0|            0|            0|  0.00%|                in a much more efficient way. Defaults to the value of
   378|         0|            0|            0|  0.00%|                ``create_graph``.
   379|         0|            0|            0|  0.00%|            create_graph (bool, optional): If ``True``, graph of the derivative will
   380|         0|            0|            0|  0.00%|                be constructed, allowing to compute higher order derivative
   381|         0|            0|            0|  0.00%|                products. Defaults to ``False``.
   382|         0|            0|            0|  0.00%|            inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be
   383|         0|            0|            0|  0.00%|                accumulated into ``.grad``. All other Tensors will be ignored. If not
   384|         0|            0|            0|  0.00%|                provided, the gradient is accumulated into all the leaf Tensors that were
   385|         0|            0|            0|  0.00%|                used to compute the attr::tensors.
   386|         0|            0|            0|  0.00%|        """
   387|       288|   0.00070858|  2.46035e-06|  0.00%|        if has_torch_function_unary(self):
   388|         0|            0|            0|  0.00%|            return handle_torch_function(
   389|         0|            0|            0|  0.00%|                Tensor.backward,
   390|         0|            0|            0|  0.00%|                (self,),
   391|         0|            0|            0|  0.00%|                self,
   392|         0|            0|            0|  0.00%|                gradient=gradient,
   393|         0|            0|            0|  0.00%|                retain_graph=retain_graph,
   394|         0|            0|            0|  0.00%|                create_graph=create_graph,
   395|         0|            0|            0|  0.00%|                inputs=inputs)
   396|       288|   0.00645733|  2.24213e-05|  0.01%|        torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
(call)|       288|     0.335865|    0.0011662|  0.32%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/__init__.py:85 backward
   397|         0|            0|            0|  0.00%|
   398|         0|            0|            0|  0.00%|    def register_hook(self, hook):
   399|         0|            0|            0|  0.00%|        r"""Registers a backward hook.
   400|         0|            0|            0|  0.00%|
   401|         0|            0|            0|  0.00%|        The hook will be called every time a gradient with respect to the
   402|         0|            0|            0|  0.00%|        Tensor is computed. The hook should have the following signature::
   403|         0|            0|            0|  0.00%|
   404|         0|            0|            0|  0.00%|            hook(grad) -> Tensor or None
   405|         0|            0|            0|  0.00%|
   406|         0|            0|            0|  0.00%|
   407|         0|            0|            0|  0.00%|        The hook should not modify its argument, but it can optionally return
   408|         0|            0|            0|  0.00%|        a new gradient which will be used in place of :attr:`grad`.
   409|         0|            0|            0|  0.00%|
   410|         0|            0|            0|  0.00%|        This function returns a handle with a method ``handle.remove()``
   411|         0|            0|            0|  0.00%|        that removes the hook from the module.
   412|         0|            0|            0|  0.00%|
   413|         0|            0|            0|  0.00%|        Example::
   414|         0|            0|            0|  0.00%|
   415|         0|            0|            0|  0.00%|            >>> v = torch.tensor([0., 0., 0.], requires_grad=True)
   416|         0|            0|            0|  0.00%|            >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient
   417|         0|            0|            0|  0.00%|            >>> v.backward(torch.tensor([1., 2., 3.]))
   418|         0|            0|            0|  0.00%|            >>> v.grad
   419|         0|            0|            0|  0.00%|
   420|         0|            0|            0|  0.00%|             2
   421|         0|            0|            0|  0.00%|             4
   422|         0|            0|            0|  0.00%|             6
   423|         0|            0|            0|  0.00%|            [torch.FloatTensor of size (3,)]
   424|         0|            0|            0|  0.00%|
   425|         0|            0|            0|  0.00%|            >>> h.remove()  # removes the hook
   426|         0|            0|            0|  0.00%|        """
   427|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   428|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.register_hook, (self,), self, hook)
   429|         0|            0|            0|  0.00%|        if not self.requires_grad:
   430|         0|            0|            0|  0.00%|            raise RuntimeError("cannot register a hook on a tensor that "
   431|         0|            0|            0|  0.00%|                               "doesn't require gradient")
   432|         0|            0|            0|  0.00%|        if self._backward_hooks is None:
   433|         0|            0|            0|  0.00%|            self._backward_hooks = OrderedDict()
   434|         0|            0|            0|  0.00%|            if self.grad_fn is not None:
   435|         0|            0|            0|  0.00%|                self.grad_fn._register_hook_dict(self)
   436|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._backward_hooks)
   437|         0|            0|            0|  0.00%|        self._backward_hooks[handle.id] = hook
   438|         0|            0|            0|  0.00%|        return handle
   439|         0|            0|            0|  0.00%|
   440|         0|            0|            0|  0.00%|    def reinforce(self, reward):
   441|         0|            0|            0|  0.00%|        def trim(str):
   442|         0|            0|            0|  0.00%|            return '\n'.join([line.strip() for line in str.split('\n')])
   443|         0|            0|            0|  0.00%|
   444|         0|            0|            0|  0.00%|        raise RuntimeError(trim(r"""reinforce() was removed.
   445|         0|            0|            0|  0.00%|            Use torch.distributions instead.
   446|         0|            0|            0|  0.00%|            See https://pytorch.org/docs/master/distributions.html
   447|         0|            0|            0|  0.00%|
   448|         0|            0|            0|  0.00%|            Instead of:
   449|         0|            0|            0|  0.00%|
   450|         0|            0|            0|  0.00%|            probs = policy_network(state)
   451|         0|            0|            0|  0.00%|            action = probs.multinomial()
   452|         0|            0|            0|  0.00%|            next_state, reward = env.step(action)
   453|         0|            0|            0|  0.00%|            action.reinforce(reward)
   454|         0|            0|            0|  0.00%|            action.backward()
   455|         0|            0|            0|  0.00%|
   456|         0|            0|            0|  0.00%|            Use:
   457|         0|            0|            0|  0.00%|
   458|         0|            0|            0|  0.00%|            probs = policy_network(state)
   459|         0|            0|            0|  0.00%|            # NOTE: categorical is equivalent to what used to be called multinomial
   460|         0|            0|            0|  0.00%|            m = torch.distributions.Categorical(probs)
   461|         0|            0|            0|  0.00%|            action = m.sample()
   462|         0|            0|            0|  0.00%|            next_state, reward = env.step(action)
   463|         0|            0|            0|  0.00%|            loss = -m.log_prob(action) * reward
   464|         0|            0|            0|  0.00%|            loss.backward()
   465|         0|            0|            0|  0.00%|        """))
   466|         0|            0|            0|  0.00%|
   467|         0|            0|            0|  0.00%|    detach = _C._add_docstr(_C._TensorBase.detach, r"""
   468|         0|            0|            0|  0.00%|    Returns a new Tensor, detached from the current graph.
   469|         0|            0|            0|  0.00%|
   470|         0|            0|            0|  0.00%|    The result will never require gradient.
   471|         0|            0|            0|  0.00%|
   472|         0|            0|            0|  0.00%|    This method also affects forward mode AD gradients and the result will never
   473|         0|            0|            0|  0.00%|    have forward mode AD gradients.
   474|         0|            0|            0|  0.00%|
   475|         0|            0|            0|  0.00%|    .. note::
   476|         0|            0|            0|  0.00%|
   477|         0|            0|            0|  0.00%|      Returned Tensor shares the same storage with the original one.
   478|         0|            0|            0|  0.00%|      In-place modifications on either of them will be seen, and may trigger
   479|         0|            0|            0|  0.00%|      errors in correctness checks.
   480|         0|            0|            0|  0.00%|      IMPORTANT NOTE: Previously, in-place size / stride / storage changes
   481|         0|            0|            0|  0.00%|      (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor
   482|         0|            0|            0|  0.00%|      also update the original tensor. Now, these in-place changes will not update the
   483|         0|            0|            0|  0.00%|      original tensor anymore, and will instead trigger an error.
   484|         0|            0|            0|  0.00%|      For sparse tensors:
   485|         0|            0|            0|  0.00%|      In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the
   486|         0|            0|            0|  0.00%|      returned tensor will not update the original tensor anymore, and will instead
   487|         0|            0|            0|  0.00%|      trigger an error.
   488|         0|            0|            0|  0.00%|    """)
   489|         0|            0|            0|  0.00%|
   490|         0|            0|            0|  0.00%|    detach_ = _C._add_docstr(_C._TensorBase.detach_, r"""
   491|         0|            0|            0|  0.00%|    Detaches the Tensor from the graph that created it, making it a leaf.
   492|         0|            0|            0|  0.00%|    Views cannot be detached in-place.
   493|         0|            0|            0|  0.00%|
   494|         0|            0|            0|  0.00%|    This method also affects forward mode AD gradients and the result will never
   495|         0|            0|            0|  0.00%|    have forward mode AD gradients.
   496|         0|            0|            0|  0.00%|    """)
   497|         0|            0|            0|  0.00%|
   498|         0|            0|            0|  0.00%|    def is_shared(self):
   499|         0|            0|            0|  0.00%|        r"""Checks if tensor is in shared memory.
   500|         0|            0|            0|  0.00%|
   501|         0|            0|            0|  0.00%|        This is always ``True`` for CUDA tensors.
   502|         0|            0|            0|  0.00%|        """
   503|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   504|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.is_shared, (self,), self)
   505|         0|            0|            0|  0.00%|        return self.storage().is_shared()
   506|         0|            0|            0|  0.00%|
   507|         0|            0|            0|  0.00%|    def share_memory_(self):
   508|         0|            0|            0|  0.00%|        r"""Moves the underlying storage to shared memory.
   509|         0|            0|            0|  0.00%|
   510|         0|            0|            0|  0.00%|        This is a no-op if the underlying storage is already in shared memory
   511|         0|            0|            0|  0.00%|        and for CUDA tensors. Tensors in shared memory cannot be resized.
   512|         0|            0|            0|  0.00%|        """
   513|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   514|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.share_memory_, (self,), self)
   515|         0|            0|            0|  0.00%|        self.storage().share_memory_()
   516|         0|            0|            0|  0.00%|        return self
   517|         0|            0|            0|  0.00%|
   518|         0|            0|            0|  0.00%|    def __reversed__(self):
   519|         0|            0|            0|  0.00%|        r"""Reverses the tensor along dimension 0."""
   520|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   521|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__reversed__, (self,), self)
   522|         0|            0|            0|  0.00%|        if self.dim() == 0:
   523|         0|            0|            0|  0.00%|            return self
   524|         0|            0|            0|  0.00%|        else:
   525|         0|            0|            0|  0.00%|            return self.flip(0)
   526|         0|            0|            0|  0.00%|
   527|         0|            0|            0|  0.00%|    def norm(self, p="fro", dim=None, keepdim=False, dtype=None):
   528|         0|            0|            0|  0.00%|        r"""See :func:`torch.norm`"""
   529|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   530|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.norm, (self,), self, p=p, dim=dim, keepdim=keepdim, dtype=dtype)
   531|         0|            0|            0|  0.00%|        return torch.norm(self, p, dim, keepdim, dtype=dtype)
   532|         0|            0|            0|  0.00%|
   533|         0|            0|            0|  0.00%|    def solve(self, other):
   534|         0|            0|            0|  0.00%|        from ._linalg_utils import solve
   535|         0|            0|            0|  0.00%|        return solve(self, other)
   536|         0|            0|            0|  0.00%|
   537|         0|            0|            0|  0.00%|    def lu(self, pivot=True, get_infos=False):
   538|         0|            0|            0|  0.00%|        r"""See :func:`torch.lu`"""
   539|         0|            0|            0|  0.00%|        # If get_infos is True, then we don't need to check for errors and vice versa
   540|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   541|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.lu, (self,), self, pivot=pivot, get_infos=get_infos)
   542|         0|            0|            0|  0.00%|
   543|         0|            0|            0|  0.00%|        LU, pivots, infos = torch._lu_with_info(self, pivot=pivot, check_errors=(not get_infos))
   544|         0|            0|            0|  0.00%|        if get_infos:
   545|         0|            0|            0|  0.00%|            return LU, pivots, infos
   546|         0|            0|            0|  0.00%|        else:
   547|         0|            0|            0|  0.00%|            return LU, pivots
   548|         0|            0|            0|  0.00%|
   549|         0|            0|            0|  0.00%|    def stft(self, n_fft: int, hop_length: Optional[int] = None,
   550|         0|            0|            0|  0.00%|             win_length: Optional[int] = None, window: 'Optional[Tensor]' = None,
   551|         0|            0|            0|  0.00%|             center: bool = True, pad_mode: str = 'reflect', normalized: bool = False,
   552|         0|            0|            0|  0.00%|             onesided: Optional[bool] = None, return_complex: Optional[bool] = None):
   553|         0|            0|            0|  0.00%|        r"""See :func:`torch.stft`
   554|         0|            0|            0|  0.00%|
   555|         0|            0|            0|  0.00%|        .. warning::
   556|         0|            0|            0|  0.00%|          This function changed signature at version 0.4.1. Calling with
   557|         0|            0|            0|  0.00%|          the previous signature may cause error or return incorrect result.
   558|         0|            0|            0|  0.00%|        """
   559|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   560|         0|            0|            0|  0.00%|            return handle_torch_function(
   561|         0|            0|            0|  0.00%|                Tensor.stft, (self,), self, n_fft, hop_length=hop_length,
   562|         0|            0|            0|  0.00%|                win_length=win_length, window=window, center=center, pad_mode=pad_mode, normalized=normalized,
   563|         0|            0|            0|  0.00%|                onesided=onesided, return_complex=return_complex
   564|         0|            0|            0|  0.00%|            )
   565|         0|            0|            0|  0.00%|        return torch.stft(self, n_fft, hop_length, win_length, window, center,
   566|         0|            0|            0|  0.00%|                          pad_mode, normalized, onesided, return_complex=return_complex)
   567|         0|            0|            0|  0.00%|
   568|         0|            0|            0|  0.00%|    def istft(self, n_fft: int, hop_length: Optional[int] = None,
   569|         0|            0|            0|  0.00%|              win_length: Optional[int] = None, window: 'Optional[Tensor]' = None,
   570|         0|            0|            0|  0.00%|              center: bool = True, normalized: bool = False,
   571|         0|            0|            0|  0.00%|              onesided: Optional[bool] = None, length: Optional[int] = None,
   572|         0|            0|            0|  0.00%|              return_complex: bool = False):
   573|         0|            0|            0|  0.00%|        r"""See :func:`torch.istft`"""
   574|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   575|         0|            0|            0|  0.00%|            return handle_torch_function(
   576|         0|            0|            0|  0.00%|                Tensor.istft, (self,), self, n_fft, hop_length=hop_length, win_length=win_length,
   577|         0|            0|            0|  0.00%|                window=window, center=center, normalized=normalized, onesided=onesided, length=length,
   578|         0|            0|            0|  0.00%|                return_complex=return_complex
   579|         0|            0|            0|  0.00%|            )
   580|         0|            0|            0|  0.00%|        return torch.istft(self, n_fft, hop_length, win_length, window, center,
   581|         0|            0|            0|  0.00%|                           normalized, onesided, length, return_complex=return_complex)
   582|         0|            0|            0|  0.00%|
   583|         0|            0|            0|  0.00%|    def resize(self, *sizes):
   584|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   585|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.resize, (self,), self, *sizes)
   586|         0|            0|            0|  0.00%|        warnings.warn("non-inplace resize is deprecated")
   587|         0|            0|            0|  0.00%|        from torch.autograd._functions import Resize
   588|         0|            0|            0|  0.00%|        return Resize.apply(self, sizes)
   589|         0|            0|            0|  0.00%|
   590|         0|            0|            0|  0.00%|    def resize_as(self, tensor):
   591|         0|            0|            0|  0.00%|        if has_torch_function_variadic(self, tensor):
   592|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.resize_as, (self, tensor), self, tensor)
   593|         0|            0|            0|  0.00%|        warnings.warn("non-inplace resize_as is deprecated")
   594|         0|            0|            0|  0.00%|        from torch.autograd._functions import Resize
   595|         0|            0|            0|  0.00%|        return Resize.apply(self, tensor.size())
   596|         0|            0|            0|  0.00%|
   597|         0|            0|            0|  0.00%|    def split(self, split_size, dim=0):
   598|         0|            0|            0|  0.00%|        r"""See :func:`torch.split`
   599|         0|            0|            0|  0.00%|        """
   600|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   601|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.split, (self,), self, split_size, dim=dim)
   602|         0|            0|            0|  0.00%|        if isinstance(split_size, int):
   603|         0|            0|            0|  0.00%|            return super(Tensor, self).split(split_size, dim)
   604|         0|            0|            0|  0.00%|        elif isinstance(split_size, Tensor):
   605|         0|            0|            0|  0.00%|            try:
   606|         0|            0|            0|  0.00%|                split_size = int(split_size)
   607|         0|            0|            0|  0.00%|                return super(Tensor, self).split(split_size, dim)
   608|         0|            0|            0|  0.00%|            except ValueError:
   609|         0|            0|            0|  0.00%|                return super(Tensor, self).split_with_sizes(split_size, dim)
   610|         0|            0|            0|  0.00%|        else:
   611|         0|            0|            0|  0.00%|            return super(Tensor, self).split_with_sizes(split_size, dim)
   612|         0|            0|            0|  0.00%|
   613|         0|            0|            0|  0.00%|    def unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None):
   614|         0|            0|            0|  0.00%|        r"""Returns the unique elements of the input tensor.
   615|         0|            0|            0|  0.00%|
   616|         0|            0|            0|  0.00%|        See :func:`torch.unique`
   617|         0|            0|            0|  0.00%|        """
   618|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   619|         0|            0|            0|  0.00%|            return handle_torch_function(
   620|         0|            0|            0|  0.00%|                Tensor.unique, (self,), self, sorted=sorted, return_inverse=return_inverse,
   621|         0|            0|            0|  0.00%|                return_counts=return_counts, dim=dim
   622|         0|            0|            0|  0.00%|            )
   623|         0|            0|            0|  0.00%|        return torch.unique(self, sorted=sorted, return_inverse=return_inverse, return_counts=return_counts, dim=dim)
   624|         0|            0|            0|  0.00%|
   625|         0|            0|            0|  0.00%|    def unique_consecutive(self, return_inverse=False, return_counts=False, dim=None):
   626|         0|            0|            0|  0.00%|        r"""Eliminates all but the first element from every consecutive group of equivalent elements.
   627|         0|            0|            0|  0.00%|
   628|         0|            0|            0|  0.00%|        See :func:`torch.unique_consecutive`
   629|         0|            0|            0|  0.00%|        """
   630|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   631|         0|            0|            0|  0.00%|            return handle_torch_function(
   632|         0|            0|            0|  0.00%|                Tensor.unique_consecutive, (self,), self, return_inverse=return_inverse,
   633|         0|            0|            0|  0.00%|                return_counts=return_counts, dim=dim
   634|         0|            0|            0|  0.00%|            )
   635|         0|            0|            0|  0.00%|        return torch.unique_consecutive(self, return_inverse=return_inverse, return_counts=return_counts, dim=dim)
   636|         0|            0|            0|  0.00%|
   637|      2304|   0.00317407|  1.37763e-06|  0.00%|    @_handle_torch_function_and_wrap_type_error_to_not_implemented
   638|         0|            0|            0|  0.00%|    def __rsub__(self, other):
   639|      2304|    0.0246105|  1.06816e-05|  0.02%|        return _C._VariableFunctions.rsub(self, other)
   640|         0|            0|            0|  0.00%|
   641|       288|  0.000465393|  1.61595e-06|  0.00%|    @_handle_torch_function_and_wrap_type_error_to_not_implemented
   642|         0|            0|            0|  0.00%|    def __rdiv__(self, other):
   643|       288|   0.00497484|  1.72738e-05|  0.00%|        return self.reciprocal() * other
   644|         0|            0|            0|  0.00%|
   645|         0|            0|            0|  0.00%|    __rtruediv__ = __rdiv__
   646|         0|            0|            0|  0.00%|    __itruediv__ = _C._TensorBase.__idiv__
   647|         0|            0|            0|  0.00%|
   648|         0|            0|            0|  0.00%|    __pow__ = _handle_torch_function_and_wrap_type_error_to_not_implemented(_C._TensorBase.pow)
   649|         0|            0|            0|  0.00%|    __ipow__ = _handle_torch_function_and_wrap_type_error_to_not_implemented(_C._TensorBase.pow_)
   650|         0|            0|            0|  0.00%|
   651|         0|            0|            0|  0.00%|    @_handle_torch_function_and_wrap_type_error_to_not_implemented
   652|         0|            0|            0|  0.00%|    def __rmod__(self, other):
   653|         0|            0|            0|  0.00%|        return torch.remainder(other, self)
   654|         0|            0|            0|  0.00%|
   655|         0|            0|            0|  0.00%|    def __format__(self, format_spec):
   656|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   657|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__format__, (self,), self, format_spec)
   658|         0|            0|            0|  0.00%|        if self.dim() == 0 and not self.is_meta:
   659|         0|            0|            0|  0.00%|            return self.item().__format__(format_spec)
   660|         0|            0|            0|  0.00%|        return object.__format__(self, format_spec)
   661|         0|            0|            0|  0.00%|
   662|         0|            0|            0|  0.00%|    @_handle_torch_function_and_wrap_type_error_to_not_implemented
   663|         0|            0|            0|  0.00%|    def __rpow__(self, other):
   664|         0|            0|            0|  0.00%|        dtype = torch.result_type(other, self)
   665|         0|            0|            0|  0.00%|        return torch.tensor(other, dtype=dtype, device=self.device) ** self
   666|         0|            0|            0|  0.00%|
   667|         0|            0|            0|  0.00%|    @_handle_torch_function_and_wrap_type_error_to_not_implemented
   668|         0|            0|            0|  0.00%|    def __floordiv__(self, other):
   669|         0|            0|            0|  0.00%|        warnings.warn("__floordiv__ is deprecated, and its behavior will change in a future version of pytorch. "
   670|         0|            0|            0|  0.00%|                      "It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). "
   671|         0|            0|            0|  0.00%|                      "This results in incorrect rounding for negative values. "
   672|         0|            0|            0|  0.00%|                      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), "
   673|         0|            0|            0|  0.00%|                      "or for actual floor division, use torch.div(a, b, rounding_mode='floor').", stacklevel=3)
   674|         0|            0|            0|  0.00%|        return torch.div(self, other, rounding_mode='trunc')
   675|         0|            0|            0|  0.00%|
   676|         0|            0|            0|  0.00%|    @_handle_torch_function_and_wrap_type_error_to_not_implemented
   677|         0|            0|            0|  0.00%|    def __rfloordiv__(self, other):
   678|         0|            0|            0|  0.00%|        warnings.warn("__rfloordiv__ is deprecated, and its behavior will change in a future version of pytorch. "
   679|         0|            0|            0|  0.00%|                      "It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). "
   680|         0|            0|            0|  0.00%|                      "This results in incorrect rounding for negative values. "
   681|         0|            0|            0|  0.00%|                      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), "
   682|         0|            0|            0|  0.00%|                      "or for actual floor division, use torch.div(a, b, rounding_mode='floor').", stacklevel=3)
   683|         0|            0|            0|  0.00%|        return torch.div(other, self, rounding_mode='trunc')
   684|         0|            0|            0|  0.00%|
   685|         0|            0|            0|  0.00%|    @_handle_torch_function_and_wrap_type_error_to_not_implemented
   686|         0|            0|            0|  0.00%|    def __rlshift__(self, other):
   687|         0|            0|            0|  0.00%|        return torch.bitwise_left_shift(other, self)
   688|         0|            0|            0|  0.00%|
   689|         0|            0|            0|  0.00%|    @_handle_torch_function_and_wrap_type_error_to_not_implemented
   690|         0|            0|            0|  0.00%|    def __rrshift__(self, other):
   691|         0|            0|            0|  0.00%|        return torch.bitwise_right_shift(other, self)
   692|         0|            0|            0|  0.00%|
   693|         0|            0|            0|  0.00%|    @_handle_torch_function_and_wrap_type_error_to_not_implemented
   694|         0|            0|            0|  0.00%|    def __rmatmul__(self, other):
   695|         0|            0|            0|  0.00%|        return torch.matmul(other, self)
   696|         0|            0|            0|  0.00%|
   697|         0|            0|            0|  0.00%|    __pos__ = _C._TensorBase.positive
   698|         0|            0|            0|  0.00%|    __neg__ = _C._TensorBase.neg
   699|         0|            0|            0|  0.00%|    __abs__ = _C._TensorBase.abs
   700|         0|            0|            0|  0.00%|
   701|         0|            0|            0|  0.00%|    def __len__(self):
   702|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   703|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__len__, (self,), self)
   704|         0|            0|            0|  0.00%|        if self.dim() == 0:
   705|         0|            0|            0|  0.00%|            raise TypeError("len() of a 0-d tensor")
   706|         0|            0|            0|  0.00%|        if torch._C._get_tracing_state():
   707|         0|            0|            0|  0.00%|            warnings.warn('Using len to get tensor shape might cause the trace to be incorrect. '
   708|         0|            0|            0|  0.00%|                          'Recommended usage would be tensor.shape[0]. '
   709|         0|            0|            0|  0.00%|                          'Passing a tensor of different shape might lead to errors or silently give '
   710|         0|            0|            0|  0.00%|                          'incorrect results.', category=torch.jit.TracerWarning, stacklevel=2)
   711|         0|            0|            0|  0.00%|        return self.shape[0]
   712|         0|            0|            0|  0.00%|
   713|      4608|    0.0132401|  2.87329e-06|  0.01%|    def __iter__(self):
   714|         0|            0|            0|  0.00%|        # NB: we use 'imap' and not 'map' here, so that in Python 2 we get a
   715|         0|            0|            0|  0.00%|        # generator and don't eagerly perform all the indexes.  This could
   716|         0|            0|            0|  0.00%|        # save us work, and also helps keep trace ordering deterministic
   717|         0|            0|            0|  0.00%|        # (e.g., if you zip(*hiddens), the eager map will force all the
   718|         0|            0|            0|  0.00%|        # indexes of hiddens[0] before hiddens[1], while the generator
   719|         0|            0|            0|  0.00%|        # map will interleave them.)
   720|         0|            0|            0|  0.00%|        # NB: We have intentionally skipped __torch_function__ dispatch here.
   721|         0|            0|            0|  0.00%|        # See gh-54457
   722|      4608|    0.0126297|  2.74083e-06|  0.01%|        if self.dim() == 0:
   723|         0|            0|            0|  0.00%|            raise TypeError('iteration over a 0-d tensor')
   724|      4608|    0.0132079|   2.8663e-06|  0.01%|        if torch._C._get_tracing_state():
   725|         0|            0|            0|  0.00%|            warnings.warn('Iterating over a tensor might cause the trace to be incorrect. '
   726|         0|            0|            0|  0.00%|                          'Passing a tensor of different shape won\'t change the number of '
   727|         0|            0|            0|  0.00%|                          'iterations executed (and might lead to errors or silently give '
   728|         0|            0|            0|  0.00%|                          'incorrect results).', category=torch.jit.TracerWarning, stacklevel=2)
   729|      4608|    0.0641181|  1.39145e-05|  0.06%|        return iter(self.unbind(0))
   730|         0|            0|            0|  0.00%|
   731|     10368|     0.014298|  1.37905e-06|  0.01%|    def __hash__(self):
   732|     10368|    0.0184219|   1.7768e-06|  0.02%|        if has_torch_function_unary(self):
   733|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__hash__, (self,), self)
   734|     10368|    0.0172334|  1.66217e-06|  0.02%|        return id(self)
   735|         0|            0|            0|  0.00%|
   736|         0|            0|            0|  0.00%|    def __dir__(self):
   737|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   738|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__dir__, (self,), self)
   739|         0|            0|            0|  0.00%|        tensor_methods = dir(self.__class__)
   740|         0|            0|            0|  0.00%|        tensor_methods.remove('volatile')  # deprecated
   741|         0|            0|            0|  0.00%|        attrs = list(self.__dict__.keys())
   742|         0|            0|            0|  0.00%|        keys = tensor_methods + attrs
   743|         0|            0|            0|  0.00%|
   744|         0|            0|            0|  0.00%|        # property only available dense, cuda tensors
   745|         0|            0|            0|  0.00%|        if (not self.is_cuda) or self.is_sparse:
   746|         0|            0|            0|  0.00%|            keys.remove("__cuda_array_interface__")
   747|         0|            0|            0|  0.00%|
   748|         0|            0|            0|  0.00%|        return sorted(keys)
   749|         0|            0|            0|  0.00%|
   750|         0|            0|            0|  0.00%|    # Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`
   751|         0|            0|            0|  0.00%|    __array_priority__ = 1000    # prefer Tensor ops over numpy ones
   752|         0|            0|            0|  0.00%|
   753|         0|            0|            0|  0.00%|    def __array__(self, dtype=None):
   754|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   755|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__array__, (self,), self, dtype=dtype)
   756|         0|            0|            0|  0.00%|        if dtype is None:
   757|         0|            0|            0|  0.00%|            return self.numpy()
   758|         0|            0|            0|  0.00%|        else:
   759|         0|            0|            0|  0.00%|            return self.numpy().astype(dtype, copy=False)
   760|         0|            0|            0|  0.00%|
   761|         0|            0|            0|  0.00%|    # Wrap Numpy array again in a suitable tensor when done, to support e.g.
   762|         0|            0|            0|  0.00%|    # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`
   763|         0|            0|            0|  0.00%|    def __array_wrap__(self, array):
   764|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   765|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__array_wrap__, (self,), self, array=array)
   766|         0|            0|            0|  0.00%|        if array.dtype == bool:
   767|         0|            0|            0|  0.00%|            # Workaround, torch has no built-in bool tensor
   768|         0|            0|            0|  0.00%|            array = array.astype('uint8')
   769|         0|            0|            0|  0.00%|        return torch.from_numpy(array)
   770|         0|            0|            0|  0.00%|
   771|         0|            0|            0|  0.00%|    def __contains__(self, element):
   772|         0|            0|            0|  0.00%|        r"""Check if `element` is present in tensor
   773|         0|            0|            0|  0.00%|
   774|         0|            0|            0|  0.00%|        Args:
   775|         0|            0|            0|  0.00%|            element (Tensor or scalar): element to be checked
   776|         0|            0|            0|  0.00%|                for presence in current tensor"
   777|         0|            0|            0|  0.00%|        """
   778|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   779|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__contains__, (self,), self, element)
   780|         0|            0|            0|  0.00%|        if isinstance(element, (torch.Tensor, Number)):
   781|         0|            0|            0|  0.00%|            # type hint doesn't understand the __contains__ result array
   782|         0|            0|            0|  0.00%|            return (element == self).any().item()  # type: ignore[union-attr]
   783|         0|            0|            0|  0.00%|
   784|         0|            0|            0|  0.00%|        raise RuntimeError(
   785|         0|            0|            0|  0.00%|            "Tensor.__contains__ only supports Tensor or scalar, but you passed in a %s." %
   786|         0|            0|            0|  0.00%|            type(element)
   787|         0|            0|            0|  0.00%|        )
   788|         0|            0|            0|  0.00%|
   789|         0|            0|            0|  0.00%|    @property
   790|         0|            0|            0|  0.00%|    def __cuda_array_interface__(self):
   791|         0|            0|            0|  0.00%|        """Array view description for cuda tensors.
   792|         0|            0|            0|  0.00%|
   793|         0|            0|            0|  0.00%|        See:
   794|         0|            0|            0|  0.00%|        https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html
   795|         0|            0|            0|  0.00%|        """
   796|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   797|         0|            0|            0|  0.00%|            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185
   798|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__cuda_array_interface__.__get__, (self,), self)  # type: ignore[attr-defined]
   799|         0|            0|            0|  0.00%|
   800|         0|            0|            0|  0.00%|        # raise AttributeError for unsupported tensors, so that
   801|         0|            0|            0|  0.00%|        # hasattr(cpu_tensor, "__cuda_array_interface__") is False.
   802|         0|            0|            0|  0.00%|        if not self.is_cuda:
   803|         0|            0|            0|  0.00%|            raise AttributeError(
   804|         0|            0|            0|  0.00%|                "Can't get __cuda_array_interface__ on non-CUDA tensor type: %s "
   805|         0|            0|            0|  0.00%|                "If CUDA data is required use tensor.cuda() to copy tensor to device memory." %
   806|         0|            0|            0|  0.00%|                self.type()
   807|         0|            0|            0|  0.00%|            )
   808|         0|            0|            0|  0.00%|
   809|         0|            0|            0|  0.00%|        if self.is_sparse:
   810|         0|            0|            0|  0.00%|            raise AttributeError(
   811|         0|            0|            0|  0.00%|                "Can't get __cuda_array_interface__ on sparse type: %s "
   812|         0|            0|            0|  0.00%|                "Use Tensor.to_dense() to convert to a dense tensor first." %
   813|         0|            0|            0|  0.00%|                self.type()
   814|         0|            0|            0|  0.00%|            )
   815|         0|            0|            0|  0.00%|
   816|         0|            0|            0|  0.00%|        # RuntimeError, matching tensor.__array__() behavior.
   817|         0|            0|            0|  0.00%|        if self.requires_grad:
   818|         0|            0|            0|  0.00%|            raise RuntimeError(
   819|         0|            0|            0|  0.00%|                "Can't get __cuda_array_interface__ on Variable that requires grad. "
   820|         0|            0|            0|  0.00%|                "If gradients aren't required, use var.detach() to get Variable that doesn't require grad."
   821|         0|            0|            0|  0.00%|            )
   822|         0|            0|            0|  0.00%|
   823|         0|            0|            0|  0.00%|        # CUDA devices are little-endian and tensors are stored in native byte
   824|         0|            0|            0|  0.00%|        # order. 1-byte entries are endian-agnostic.
   825|         0|            0|            0|  0.00%|        typestr = {
   826|         0|            0|            0|  0.00%|            torch.complex64: "<c8",
   827|         0|            0|            0|  0.00%|            torch.complex128: "<c16",
   828|         0|            0|            0|  0.00%|            torch.float16: "<f2",
   829|         0|            0|            0|  0.00%|            torch.float32: "<f4",
   830|         0|            0|            0|  0.00%|            torch.float64: "<f8",
   831|         0|            0|            0|  0.00%|            torch.uint8: "|u1",
   832|         0|            0|            0|  0.00%|            torch.int8: "|i1",
   833|         0|            0|            0|  0.00%|            torch.int16: "<i2",
   834|         0|            0|            0|  0.00%|            torch.int32: "<i4",
   835|         0|            0|            0|  0.00%|            torch.int64: "<i8",
   836|         0|            0|            0|  0.00%|        }[self.dtype]
   837|         0|            0|            0|  0.00%|
   838|         0|            0|            0|  0.00%|        itemsize = self.storage().element_size()
   839|         0|            0|            0|  0.00%|
   840|         0|            0|            0|  0.00%|        shape = tuple(self.shape)
   841|         0|            0|            0|  0.00%|        if self.is_contiguous():
   842|         0|            0|            0|  0.00%|            # __cuda_array_interface__ v2 requires the strides to be omitted
   843|         0|            0|            0|  0.00%|            # (either not set or set to None) for C-contiguous arrays.
   844|         0|            0|            0|  0.00%|            strides = None
   845|         0|            0|            0|  0.00%|        else:
   846|         0|            0|            0|  0.00%|            strides = tuple(s * itemsize for s in self.stride())
   847|         0|            0|            0|  0.00%|        data_ptr = self.data_ptr() if self.numel() > 0 else 0
   848|         0|            0|            0|  0.00%|        data = (data_ptr, False)  # read-only is false
   849|         0|            0|            0|  0.00%|
   850|         0|            0|            0|  0.00%|        return dict(typestr=typestr, shape=shape, strides=strides, data=data, version=2)
   851|         0|            0|            0|  0.00%|
   852|         0|            0|            0|  0.00%|    def storage_type(self):
   853|         0|            0|            0|  0.00%|        r"""storage_type() -> type
   854|         0|            0|            0|  0.00%|
   855|         0|            0|            0|  0.00%|        Returns the type of the underlying storage.
   856|         0|            0|            0|  0.00%|
   857|         0|            0|            0|  0.00%|        """
   858|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   859|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.storage_type, (self,), self)
   860|         0|            0|            0|  0.00%|
   861|         0|            0|            0|  0.00%|        return self.storage()._get_legacy_storage_class()
   862|         0|            0|            0|  0.00%|
   863|         0|            0|            0|  0.00%|    def refine_names(self, *names):
   864|         0|            0|            0|  0.00%|        r"""Refines the dimension names of :attr:`self` according to :attr:`names`.
   865|         0|            0|            0|  0.00%|
   866|         0|            0|            0|  0.00%|        Refining is a special case of renaming that "lifts" unnamed dimensions.
   867|         0|            0|            0|  0.00%|        A ``None`` dim can be refined to have any name; a named dim can only be
   868|         0|            0|            0|  0.00%|        refined to have the same name.
   869|         0|            0|            0|  0.00%|
   870|         0|            0|            0|  0.00%|        Because named tensors can coexist with unnamed tensors, refining names
   871|         0|            0|            0|  0.00%|        gives a nice way to write named-tensor-aware code that works with both
   872|         0|            0|            0|  0.00%|        named and unnamed tensors.
   873|         0|            0|            0|  0.00%|
   874|         0|            0|            0|  0.00%|        :attr:`names` may contain up to one Ellipsis (``...``).
   875|         0|            0|            0|  0.00%|        The Ellipsis is expanded greedily; it is expanded in-place to fill
   876|         0|            0|            0|  0.00%|        :attr:`names` to the same length as ``self.dim()`` using names from the
   877|         0|            0|            0|  0.00%|        corresponding indices of ``self.names``.
   878|         0|            0|            0|  0.00%|
   879|         0|            0|            0|  0.00%|        Python 2 does not support Ellipsis but one may use a string literal
   880|         0|            0|            0|  0.00%|        instead (``'...'``).
   881|         0|            0|            0|  0.00%|
   882|         0|            0|            0|  0.00%|        Args:
   883|         0|            0|            0|  0.00%|            names (iterable of str): The desired names of the output tensor. May
   884|         0|            0|            0|  0.00%|                contain up to one Ellipsis.
   885|         0|            0|            0|  0.00%|
   886|         0|            0|            0|  0.00%|        Examples::
   887|         0|            0|            0|  0.00%|
   888|         0|            0|            0|  0.00%|            >>> imgs = torch.randn(32, 3, 128, 128)
   889|         0|            0|            0|  0.00%|            >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')
   890|         0|            0|            0|  0.00%|            >>> named_imgs.names
   891|         0|            0|            0|  0.00%|            ('N', 'C', 'H', 'W')
   892|         0|            0|            0|  0.00%|
   893|         0|            0|            0|  0.00%|            >>> tensor = torch.randn(2, 3, 5, 7, 11)
   894|         0|            0|            0|  0.00%|            >>> tensor = tensor.refine_names('A', ..., 'B', 'C')
   895|         0|            0|            0|  0.00%|            >>> tensor.names
   896|         0|            0|            0|  0.00%|            ('A', None, None, 'B', 'C')
   897|         0|            0|            0|  0.00%|
   898|         0|            0|            0|  0.00%|        .. warning::
   899|         0|            0|            0|  0.00%|            The named tensor API is experimental and subject to change.
   900|         0|            0|            0|  0.00%|
   901|         0|            0|            0|  0.00%|        """
   902|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   903|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.refine_names, (self,), self, *names)
   904|         0|            0|            0|  0.00%|        names = resolve_ellipsis(names, self.names, 'refine_names')
   905|         0|            0|            0|  0.00%|        return super(Tensor, self).refine_names(names)
   906|         0|            0|            0|  0.00%|
   907|         0|            0|            0|  0.00%|    def align_to(self, *names):
   908|         0|            0|            0|  0.00%|        r"""Permutes the dimensions of the :attr:`self` tensor to match the order
   909|         0|            0|            0|  0.00%|        specified in :attr:`names`, adding size-one dims for any new names.
   910|         0|            0|            0|  0.00%|
   911|         0|            0|            0|  0.00%|        All of the dims of :attr:`self` must be named in order to use this method.
   912|         0|            0|            0|  0.00%|        The resulting tensor is a view on the original tensor.
   913|         0|            0|            0|  0.00%|
   914|         0|            0|            0|  0.00%|        All dimension names of :attr:`self` must be present in :attr:`names`.
   915|         0|            0|            0|  0.00%|        :attr:`names` may contain additional names that are not in ``self.names``;
   916|         0|            0|            0|  0.00%|        the output tensor has a size-one dimension for each of those new names.
   917|         0|            0|            0|  0.00%|
   918|         0|            0|            0|  0.00%|        :attr:`names` may contain up to one Ellipsis (``...``).
   919|         0|            0|            0|  0.00%|        The Ellipsis is expanded to be equal to all dimension names of :attr:`self`
   920|         0|            0|            0|  0.00%|        that are not mentioned in :attr:`names`, in the order that they appear
   921|         0|            0|            0|  0.00%|        in :attr:`self`.
   922|         0|            0|            0|  0.00%|
   923|         0|            0|            0|  0.00%|        Python 2 does not support Ellipsis but one may use a string literal
   924|         0|            0|            0|  0.00%|        instead (``'...'``).
   925|         0|            0|            0|  0.00%|
   926|         0|            0|            0|  0.00%|        Args:
   927|         0|            0|            0|  0.00%|            names (iterable of str): The desired dimension ordering of the
   928|         0|            0|            0|  0.00%|                output tensor. May contain up to one Ellipsis that is expanded
   929|         0|            0|            0|  0.00%|                to all unmentioned dim names of :attr:`self`.
   930|         0|            0|            0|  0.00%|
   931|         0|            0|            0|  0.00%|        Examples::
   932|         0|            0|            0|  0.00%|
   933|         0|            0|            0|  0.00%|            >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)
   934|         0|            0|            0|  0.00%|            >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')
   935|         0|            0|            0|  0.00%|
   936|         0|            0|            0|  0.00%|            # Move the F and E dims to the front while keeping the rest in order
   937|         0|            0|            0|  0.00%|            >>> named_tensor.align_to('F', 'E', ...)
   938|         0|            0|            0|  0.00%|
   939|         0|            0|            0|  0.00%|        .. warning::
   940|         0|            0|            0|  0.00%|            The named tensor API is experimental and subject to change.
   941|         0|            0|            0|  0.00%|
   942|         0|            0|            0|  0.00%|        """
   943|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   944|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.align_to, (self,), self, *names)
   945|         0|            0|            0|  0.00%|        ellipsis_idx = single_ellipsis_index(names, 'align_to')
   946|         0|            0|            0|  0.00%|        if ellipsis_idx is None:
   947|         0|            0|            0|  0.00%|            return super(Tensor, self).align_to(names)
   948|         0|            0|            0|  0.00%|        return super(Tensor, self).align_to(
   949|         0|            0|            0|  0.00%|            [name for name in names if not is_ellipsis(name)],
   950|         0|            0|            0|  0.00%|            ellipsis_idx)
   951|         0|            0|            0|  0.00%|
   952|         0|            0|            0|  0.00%|    def unflatten(self, dim, sizes):
   953|         0|            0|            0|  0.00%|        r"""Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions
   954|         0|            0|            0|  0.00%|        of sizes given by :attr:`sizes`.
   955|         0|            0|            0|  0.00%|
   956|         0|            0|            0|  0.00%|        * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well
   957|         0|            0|            0|  0.00%|          as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])
   958|         0|            0|            0|  0.00%|          if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number
   959|         0|            0|            0|  0.00%|          of elements in the original dim being unflattened.
   960|         0|            0|            0|  0.00%|
   961|         0|            0|            0|  0.00%|        Args:
   962|         0|            0|            0|  0.00%|            dim (Union[int, str]): Dimension to unflatten
   963|         0|            0|            0|  0.00%|            sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension
   964|         0|            0|            0|  0.00%|
   965|         0|            0|            0|  0.00%|        Examples:
   966|         0|            0|            0|  0.00%|            >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape
   967|         0|            0|            0|  0.00%|            torch.Size([3, 2, 2, 1])
   968|         0|            0|            0|  0.00%|            >>> torch.randn(3, 4, 1).unflatten(1, (-1, 2)).shape # the size -1 is inferred from the size of dimension 1
   969|         0|            0|            0|  0.00%|            torch.Size([3, 2, 2, 1])
   970|         0|            0|            0|  0.00%|            >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))
   971|         0|            0|            0|  0.00%|            tensor([[[-1.1772,  0.0180],
   972|         0|            0|            0|  0.00%|                    [ 0.2412,  0.1431]],
   973|         0|            0|            0|  0.00%|                    [[-1.1819, -0.8899],
   974|         0|            0|            0|  0.00%|                    [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))
   975|         0|            0|            0|  0.00%|            >>> torch.randn(2, names=('A',)).unflatten('A', (('B1', -1), ('B2', 1)))
   976|         0|            0|            0|  0.00%|            tensor([[-0.8591],
   977|         0|            0|            0|  0.00%|                    [ 0.3100]], names=('B1', 'B2'))
   978|         0|            0|            0|  0.00%|
   979|         0|            0|            0|  0.00%|        .. warning::
   980|         0|            0|            0|  0.00%|            The named tensor API is experimental and subject to change.
   981|         0|            0|            0|  0.00%|
   982|         0|            0|            0|  0.00%|        """
   983|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   984|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.unflatten, (self,), self, dim, sizes)
   985|         0|            0|            0|  0.00%|
   986|         0|            0|            0|  0.00%|        if not sizes:
   987|         0|            0|            0|  0.00%|            raise RuntimeError("unflatten: sizes must be non-empty")
   988|         0|            0|            0|  0.00%|
   989|         0|            0|            0|  0.00%|        names = None
   990|         0|            0|            0|  0.00%|        if isinstance(sizes, OrderedDict) or (isinstance(sizes, (tuple, list)) and isinstance(sizes[0], (tuple, list))):
   991|         0|            0|            0|  0.00%|            names, sizes = unzip_namedshape(sizes)
   992|         0|            0|            0|  0.00%|        return super(Tensor, self).unflatten(dim, sizes, names)
   993|         0|            0|            0|  0.00%|
   994|         0|            0|            0|  0.00%|
   995|         0|            0|            0|  0.00%|    def rename_(self, *names, **rename_map):
   996|         0|            0|            0|  0.00%|        """In-place version of :meth:`~Tensor.rename`."""
   997|         0|            0|            0|  0.00%|
   998|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
   999|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.rename_, (self,), self, *names, **rename_map)
  1000|         0|            0|            0|  0.00%|
  1001|         0|            0|            0|  0.00%|        # Note [rename_ / rename API]
  1002|         0|            0|            0|  0.00%|        # The Python API for these is different from the C++ API. In Python:
  1003|         0|            0|            0|  0.00%|        # 1) tensor.rename(*names) takes a vararglist of names
  1004|         0|            0|            0|  0.00%|        # 2) tensor.rename(**rename_map) takes a map of names to rename.
  1005|         0|            0|            0|  0.00%|        # C++ is static, making it difficult to implement similar behavior.
  1006|         0|            0|            0|  0.00%|        return update_names(self, names, rename_map, inplace=True)
  1007|         0|            0|            0|  0.00%|
  1008|         0|            0|            0|  0.00%|    def rename(self, *names, **rename_map):
  1009|         0|            0|            0|  0.00%|        """Renames dimension names of :attr:`self`.
  1010|         0|            0|            0|  0.00%|
  1011|         0|            0|            0|  0.00%|        There are two main usages:
  1012|         0|            0|            0|  0.00%|
  1013|         0|            0|            0|  0.00%|        ``self.rename(**rename_map)`` returns a view on tensor that has dims
  1014|         0|            0|            0|  0.00%|        renamed as specified in the mapping :attr:`rename_map`.
  1015|         0|            0|            0|  0.00%|
  1016|         0|            0|            0|  0.00%|        ``self.rename(*names)`` returns a view on tensor, renaming all
  1017|         0|            0|            0|  0.00%|        dimensions positionally using :attr:`names`.
  1018|         0|            0|            0|  0.00%|        Use ``self.rename(None)`` to drop names on a tensor.
  1019|         0|            0|            0|  0.00%|
  1020|         0|            0|            0|  0.00%|        One cannot specify both positional args :attr:`names` and keyword args
  1021|         0|            0|            0|  0.00%|        :attr:`rename_map`.
  1022|         0|            0|            0|  0.00%|
  1023|         0|            0|            0|  0.00%|        Examples::
  1024|         0|            0|            0|  0.00%|
  1025|         0|            0|            0|  0.00%|            >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))
  1026|         0|            0|            0|  0.00%|            >>> renamed_imgs = imgs.rename(N='batch', C='channels')
  1027|         0|            0|            0|  0.00%|            >>> renamed_imgs.names
  1028|         0|            0|            0|  0.00%|            ('batch', 'channels', 'H', 'W')
  1029|         0|            0|            0|  0.00%|
  1030|         0|            0|            0|  0.00%|            >>> renamed_imgs = imgs.rename(None)
  1031|         0|            0|            0|  0.00%|            >>> renamed_imgs.names
  1032|         0|            0|            0|  0.00%|            (None,)
  1033|         0|            0|            0|  0.00%|
  1034|         0|            0|            0|  0.00%|            >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')
  1035|         0|            0|            0|  0.00%|            >>> renamed_imgs.names
  1036|         0|            0|            0|  0.00%|            ('batch', 'channel', 'height', 'width')
  1037|         0|            0|            0|  0.00%|
  1038|         0|            0|            0|  0.00%|        .. warning::
  1039|         0|            0|            0|  0.00%|            The named tensor API is experimental and subject to change.
  1040|         0|            0|            0|  0.00%|
  1041|         0|            0|            0|  0.00%|        """
  1042|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
  1043|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.rename, (self,), self, *names, **rename_map)
  1044|         0|            0|            0|  0.00%|
  1045|         0|            0|            0|  0.00%|        # See Note [rename_ / rename API]
  1046|         0|            0|            0|  0.00%|        return update_names(self, names, rename_map, inplace=False)
  1047|         0|            0|            0|  0.00%|
  1048|         0|            0|            0|  0.00%|    def to_sparse_coo(self):
  1049|         0|            0|            0|  0.00%|        """ Convert a tensor to :ref:`coordinate format <sparse-coo-docs>`.
  1050|         0|            0|            0|  0.00%|
  1051|         0|            0|            0|  0.00%|       Examples::
  1052|         0|            0|            0|  0.00%|
  1053|         0|            0|            0|  0.00%|            >>> dense = torch.randn(5, 5)
  1054|         0|            0|            0|  0.00%|            >>> sparse = dense.to_sparse_coo()
  1055|         0|            0|            0|  0.00%|            >>> sparse._nnz()
  1056|         0|            0|            0|  0.00%|            25
  1057|         0|            0|            0|  0.00%|
  1058|         0|            0|            0|  0.00%|       """
  1059|         0|            0|            0|  0.00%|        return self.to_sparse()
  1060|         0|            0|            0|  0.00%|
  1061|         0|            0|            0|  0.00%|    def _update_names(self, names, inplace):
  1062|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
  1063|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor._update_names, (self,), self, names, inplace)
  1064|         0|            0|            0|  0.00%|
  1065|         0|            0|            0|  0.00%|        # See Note [rename_ / rename API]
  1066|         0|            0|            0|  0.00%|        if inplace:
  1067|         0|            0|            0|  0.00%|            return super(Tensor, self).rename_(names)
  1068|         0|            0|            0|  0.00%|        else:
  1069|         0|            0|            0|  0.00%|            return super(Tensor, self).rename(names)
  1070|         0|            0|            0|  0.00%|
  1071|     38304|    0.0564671|  1.47418e-06|  0.05%|    @property
  1072|         0|            0|            0|  0.00%|    def grad(self):
  1073|         0|            0|            0|  0.00%|        """
  1074|         0|            0|            0|  0.00%|        This attribute is ``None`` by default and becomes a Tensor the first time a call to
  1075|         0|            0|            0|  0.00%|        :func:`backward` computes gradients for ``self``.
  1076|         0|            0|            0|  0.00%|        The attribute will then contain the gradients computed and future calls to
  1077|         0|            0|            0|  0.00%|        :func:`backward` will accumulate (add) gradients into it.
  1078|         0|            0|            0|  0.00%|        """
  1079|     38304|    0.0646989|  1.68909e-06|  0.06%|        if has_torch_function_unary(self):
  1080|         0|            0|            0|  0.00%|            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185
  1081|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.grad.__get__, (self,), self)  # type: ignore[attr-defined]
  1082|         0|            0|            0|  0.00%|
  1083|     38304|    0.0712845|  1.86102e-06|  0.07%|        return self._grad
  1084|         0|            0|            0|  0.00%|
  1085|         0|            0|            0|  0.00%|    @grad.setter
  1086|         0|            0|            0|  0.00%|    def grad(self, new_grad):
  1087|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
  1088|         0|            0|            0|  0.00%|            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185
  1089|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.grad.__set__, (self,), self, new_grad)  # type: ignore[attr-defined]
  1090|         0|            0|            0|  0.00%|        self._grad = new_grad
  1091|         0|            0|            0|  0.00%|
  1092|         0|            0|            0|  0.00%|    @grad.deleter
  1093|         0|            0|            0|  0.00%|    def grad(self):
  1094|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
  1095|         0|            0|            0|  0.00%|            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185
  1096|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.grad.__delete__, (self,), self)  # type: ignore[attr-defined]
  1097|         0|            0|            0|  0.00%|        del self._grad
  1098|         0|            0|            0|  0.00%|
  1099|         0|            0|            0|  0.00%|    @classmethod
  1100|         0|            0|            0|  0.00%|    def __torch_function__(cls, func, types, args=(), kwargs=None):
  1101|         0|            0|            0|  0.00%|        """
  1102|         0|            0|            0|  0.00%|        This __torch_function__ implementation wraps subclasses such that
  1103|         0|            0|            0|  0.00%|        methods called on subclasses return a subclass instance instead of
  1104|         0|            0|            0|  0.00%|        a ``torch.Tensor`` instance.
  1105|         0|            0|            0|  0.00%|
  1106|         0|            0|            0|  0.00%|        One corollary to this is that you need coverage for torch.Tensor
  1107|         0|            0|            0|  0.00%|        methods if implementing __torch_function__ for subclasses.
  1108|         0|            0|            0|  0.00%|
  1109|         0|            0|            0|  0.00%|        We recommend always calling ``super().__torch_function__`` as the base
  1110|         0|            0|            0|  0.00%|        case when doing the above.
  1111|         0|            0|            0|  0.00%|
  1112|         0|            0|            0|  0.00%|        While not mandatory, we recommend making `__torch_function__` a classmethod.
  1113|         0|            0|            0|  0.00%|        """
  1114|         0|            0|            0|  0.00%|        if kwargs is None:
  1115|         0|            0|            0|  0.00%|            kwargs = {}
  1116|         0|            0|            0|  0.00%|
  1117|         0|            0|            0|  0.00%|        if not all(issubclass(cls, t) for t in types):
  1118|         0|            0|            0|  0.00%|            return NotImplemented
  1119|         0|            0|            0|  0.00%|
  1120|         0|            0|            0|  0.00%|        with _C.DisableTorchFunction():
  1121|         0|            0|            0|  0.00%|            ret = func(*args, **kwargs)
  1122|         0|            0|            0|  0.00%|            if func in get_default_nowrap_functions():
  1123|         0|            0|            0|  0.00%|                return ret
  1124|         0|            0|            0|  0.00%|            else:
  1125|         0|            0|            0|  0.00%|                return _convert(ret, cls)
  1126|         0|            0|            0|  0.00%|
  1127|         0|            0|            0|  0.00%|    __torch_dispatch__ = _C._disabled_torch_dispatch_impl
  1128|         0|            0|            0|  0.00%|
  1129|         0|            0|            0|  0.00%|    def __dlpack__(self, stream=None):
  1130|         0|            0|            0|  0.00%|        """
  1131|         0|            0|            0|  0.00%|        Creates a DLpack `capsule https://data-apis.org/array-api/latest/design_topics/data_interchange.html#data-interchange`_
  1132|         0|            0|            0|  0.00%|        of the current tensor to be exported to other libraries.
  1133|         0|            0|            0|  0.00%|
  1134|         0|            0|            0|  0.00%|        This function will be called from the `from_dlpack` method
  1135|         0|            0|            0|  0.00%|        of the library that will consume the capsule. `from_dlpack` passes the current
  1136|         0|            0|            0|  0.00%|        stream to this method as part of the specification.
  1137|         0|            0|            0|  0.00%|
  1138|         0|            0|            0|  0.00%|        Args:
  1139|         0|            0|            0|  0.00%|            stream (integer or None): An optional Python integer representing a
  1140|         0|            0|            0|  0.00%|            pointer to a CUDA stream. The current stream is synchronized with
  1141|         0|            0|            0|  0.00%|            this stream before the capsule is created, and since the capsule
  1142|         0|            0|            0|  0.00%|            shares its storage with the tensor this make it safe to access from
  1143|         0|            0|            0|  0.00%|            both streams.  If None or -1 is passed then no synchronization is performed.
  1144|         0|            0|            0|  0.00%|        """
  1145|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
  1146|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__dlpack__, (self,), self, stream)
  1147|         0|            0|            0|  0.00%|
  1148|         0|            0|            0|  0.00%|        # DLPack capsules can't capture all of PyTorch's semantics,
  1149|         0|            0|            0|  0.00%|        # so we prohibit exporting tensors that would lose their properties like
  1150|         0|            0|            0|  0.00%|        # requires_grad and having the conjugate bit set.
  1151|         0|            0|            0|  0.00%|        if self.requires_grad:
  1152|         0|            0|            0|  0.00%|            raise RuntimeError('Can\'t export tensors that require gradient, use tensor.detach()')
  1153|         0|            0|            0|  0.00%|        if self.is_conj():
  1154|         0|            0|            0|  0.00%|            raise RuntimeError('Can\'t export tensors with the conjugate bit set')
  1155|         0|            0|            0|  0.00%|        if self.layout != torch.strided:
  1156|         0|            0|            0|  0.00%|            raise RuntimeError('Can\'t export tensors with layout other than torch.strided')
  1157|         0|            0|            0|  0.00%|
  1158|         0|            0|            0|  0.00%|        if stream is not None and type(stream) is not int:
  1159|         0|            0|            0|  0.00%|            # Stream pointers in CUDA/ROCm are uniquely numbered and can
  1160|         0|            0|            0|  0.00%|            # be retrieved from their integer value.
  1161|         0|            0|            0|  0.00%|            raise TypeError('stream must be ``int`` or ``none``')
  1162|         0|            0|            0|  0.00%|        elif stream is not None and stream != -1:
  1163|         0|            0|            0|  0.00%|            if self.device.type == 'cuda':
  1164|         0|            0|            0|  0.00%|                stream = torch.cuda.ExternalStream(stream)
  1165|         0|            0|            0|  0.00%|                # Only synchronize on different streams
  1166|         0|            0|            0|  0.00%|                if stream != torch.cuda.current_stream:
  1167|         0|            0|            0|  0.00%|                    event = torch.cuda.Event()
  1168|         0|            0|            0|  0.00%|                    event.record(torch.cuda.current_stream())
  1169|         0|            0|            0|  0.00%|                    stream.wait_event(event)
  1170|         0|            0|            0|  0.00%|        return torch.to_dlpack(self)
  1171|         0|            0|            0|  0.00%|
  1172|         0|            0|            0|  0.00%|    def __dlpack_device__(self) -> Tuple[enum.IntEnum, int]:
  1173|         0|            0|            0|  0.00%|        # Avoid circular import
  1174|         0|            0|            0|  0.00%|        from torch.utils.dlpack import DLDeviceType
  1175|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):
  1176|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__dlpack_device__, (self,), self)
  1177|         0|            0|            0|  0.00%|        idx = self.device.index if self.device.index is not None else 0
  1178|         0|            0|            0|  0.00%|        if self.device.type == 'cuda' and torch.version.hip is not None:
  1179|         0|            0|            0|  0.00%|            device_type = DLDeviceType.kDLROCM
  1180|         0|            0|            0|  0.00%|        elif self.device.type == 'cpu' and self.is_pinned():
  1181|         0|            0|            0|  0.00%|            device_type = DLDeviceType.kDLCPUPinned
  1182|         0|            0|            0|  0.00%|        elif self.device.type == 'cuda':
  1183|         0|            0|            0|  0.00%|            device_type = DLDeviceType.kDLGPU
  1184|         0|            0|            0|  0.00%|        elif self.device.type == 'cpu':
  1185|         0|            0|            0|  0.00%|            device_type = DLDeviceType.kDLCPU
  1186|         0|            0|            0|  0.00%|        else:
  1187|         0|            0|            0|  0.00%|            raise ValueError('Unknown device type {} for Dlpack'.format(self.device.type))
  1188|         0|            0|            0|  0.00%|        return (device_type, idx)
  1189|         0|            0|            0|  0.00%|
  1190|         0|            0|            0|  0.00%|    __module__ = 'torch'
  1191|         0|            0|            0|  0.00%|
  1192|         0|            0|            0|  0.00%|def _convert(ret, cls):
  1193|         0|            0|            0|  0.00%|    if cls is Tensor:
  1194|         0|            0|            0|  0.00%|        return ret
  1195|         0|            0|            0|  0.00%|
  1196|         0|            0|            0|  0.00%|    if isinstance(ret, Tensor) and not isinstance(ret, cls):
  1197|         0|            0|            0|  0.00%|        ret = ret.as_subclass(cls)
  1198|         0|            0|            0|  0.00%|
  1199|         0|            0|            0|  0.00%|    if isinstance(ret, (tuple, list)):
  1200|         0|            0|            0|  0.00%|        # Also handles things like namedtuples
  1201|         0|            0|            0|  0.00%|        ret = type(ret)(_convert(r, cls) for r in ret)
  1202|         0|            0|            0|  0.00%|
  1203|         0|            0|            0|  0.00%|    return ret
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/container.py
File duration: 0.392966s (0.38%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import warnings
     2|         0|            0|            0|  0.00%|from collections import OrderedDict, abc as container_abcs
     3|         0|            0|            0|  0.00%|from itertools import chain, islice
     4|         0|            0|            0|  0.00%|import operator
     5|         0|            0|            0|  0.00%|
     6|         0|            0|            0|  0.00%|import torch
     7|         0|            0|            0|  0.00%|from .module import Module
     8|         0|            0|            0|  0.00%|from ..parameter import Parameter
     9|         0|            0|            0|  0.00%|from torch._jit_internal import _copy_to_script_wrapper
    10|         0|            0|            0|  0.00%|
    11|         0|            0|            0|  0.00%|from typing import Any, Dict, Iterable, Iterator, Mapping, Optional, overload, Tuple, TypeVar, Union
    12|         0|            0|            0|  0.00%|
    13|         0|            0|            0|  0.00%|T = TypeVar('T', bound=Module)
    14|         0|            0|            0|  0.00%|
    15|         0|            0|            0|  0.00%|
    16|         0|            0|            0|  0.00%|class Container(Module):
    17|         0|            0|            0|  0.00%|
    18|         0|            0|            0|  0.00%|    def __init__(self, **kwargs: Any) -> None:
    19|         0|            0|            0|  0.00%|        super(Container, self).__init__()
    20|         0|            0|            0|  0.00%|        # DeprecationWarning is ignored by default <sigh>
    21|         0|            0|            0|  0.00%|        warnings.warn("nn.Container is deprecated. All of it's functionality "
    22|         0|            0|            0|  0.00%|                      "is now implemented in nn.Module. Subclass that instead.")
    23|         0|            0|            0|  0.00%|        for key, value in kwargs.items():
    24|         0|            0|            0|  0.00%|            self.add_module(key, value)
    25|         0|            0|            0|  0.00%|
    26|         0|            0|            0|  0.00%|
    27|         0|            0|            0|  0.00%|class Sequential(Module):
    28|         0|            0|            0|  0.00%|    r"""A sequential container.
    29|         0|            0|            0|  0.00%|    Modules will be added to it in the order they are passed in the
    30|         0|            0|            0|  0.00%|    constructor. Alternatively, an ``OrderedDict`` of modules can be
    31|         0|            0|            0|  0.00%|    passed in. The ``forward()`` method of ``Sequential`` accepts any
    32|         0|            0|            0|  0.00%|    input and forwards it to the first module it contains. It then
    33|         0|            0|            0|  0.00%|    "chains" outputs to inputs sequentially for each subsequent module,
    34|         0|            0|            0|  0.00%|    finally returning the output of the last module.
    35|         0|            0|            0|  0.00%|
    36|         0|            0|            0|  0.00%|    The value a ``Sequential`` provides over manually calling a sequence
    37|         0|            0|            0|  0.00%|    of modules is that it allows treating the whole container as a
    38|         0|            0|            0|  0.00%|    single module, such that performing a transformation on the
    39|         0|            0|            0|  0.00%|    ``Sequential`` applies to each of the modules it stores (which are
    40|         0|            0|            0|  0.00%|    each a registered submodule of the ``Sequential``).
    41|         0|            0|            0|  0.00%|
    42|         0|            0|            0|  0.00%|    What's the difference between a ``Sequential`` and a
    43|         0|            0|            0|  0.00%|    :class:`torch.nn.ModuleList`? A ``ModuleList`` is exactly what it
    44|         0|            0|            0|  0.00%|    sounds like--a list for storing ``Module`` s! On the other hand,
    45|         0|            0|            0|  0.00%|    the layers in a ``Sequential`` are connected in a cascading way.
    46|         0|            0|            0|  0.00%|
    47|         0|            0|            0|  0.00%|    Example::
    48|         0|            0|            0|  0.00%|
    49|         0|            0|            0|  0.00%|        # Using Sequential to create a small model. When `model` is run,
    50|         0|            0|            0|  0.00%|        # input will first be passed to `Conv2d(1,20,5)`. The output of
    51|         0|            0|            0|  0.00%|        # `Conv2d(1,20,5)` will be used as the input to the first
    52|         0|            0|            0|  0.00%|        # `ReLU`; the output of the first `ReLU` will become the input
    53|         0|            0|            0|  0.00%|        # for `Conv2d(20,64,5)`. Finally, the output of
    54|         0|            0|            0|  0.00%|        # `Conv2d(20,64,5)` will be used as input to the second `ReLU`
    55|         0|            0|            0|  0.00%|        model = nn.Sequential(
    56|         0|            0|            0|  0.00%|                  nn.Conv2d(1,20,5),
    57|         0|            0|            0|  0.00%|                  nn.ReLU(),
    58|         0|            0|            0|  0.00%|                  nn.Conv2d(20,64,5),
    59|         0|            0|            0|  0.00%|                  nn.ReLU()
    60|         0|            0|            0|  0.00%|                )
    61|         0|            0|            0|  0.00%|
    62|         0|            0|            0|  0.00%|        # Using Sequential with OrderedDict. This is functionally the
    63|         0|            0|            0|  0.00%|        # same as the above code
    64|         0|            0|            0|  0.00%|        model = nn.Sequential(OrderedDict([
    65|         0|            0|            0|  0.00%|                  ('conv1', nn.Conv2d(1,20,5)),
    66|         0|            0|            0|  0.00%|                  ('relu1', nn.ReLU()),
    67|         0|            0|            0|  0.00%|                  ('conv2', nn.Conv2d(20,64,5)),
    68|         0|            0|            0|  0.00%|                  ('relu2', nn.ReLU())
    69|         0|            0|            0|  0.00%|                ]))
    70|         0|            0|            0|  0.00%|    """
    71|         0|            0|            0|  0.00%|
    72|         0|            0|            0|  0.00%|    _modules: Dict[str, Module]  # type: ignore[assignment]
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|    @overload
    75|         0|            0|            0|  0.00%|    def __init__(self, *args: Module) -> None:
    76|         0|            0|            0|  0.00%|        ...
    77|         0|            0|            0|  0.00%|
    78|         0|            0|            0|  0.00%|    @overload
    79|         0|            0|            0|  0.00%|    def __init__(self, arg: 'OrderedDict[str, Module]') -> None:
    80|         0|            0|            0|  0.00%|        ...
    81|         0|            0|            0|  0.00%|
    82|         0|            0|            0|  0.00%|    def __init__(self, *args):
    83|         0|            0|            0|  0.00%|        super(Sequential, self).__init__()
    84|         0|            0|            0|  0.00%|        if len(args) == 1 and isinstance(args[0], OrderedDict):
    85|         0|            0|            0|  0.00%|            for key, module in args[0].items():
    86|         0|            0|            0|  0.00%|                self.add_module(key, module)
    87|         0|            0|            0|  0.00%|        else:
    88|         0|            0|            0|  0.00%|            for idx, module in enumerate(args):
    89|         0|            0|            0|  0.00%|                self.add_module(str(idx), module)
    90|         0|            0|            0|  0.00%|
    91|         0|            0|            0|  0.00%|    def _get_item_by_idx(self, iterator, idx) -> T:
    92|         0|            0|            0|  0.00%|        """Get the idx-th item of the iterator"""
    93|         0|            0|            0|  0.00%|        size = len(self)
    94|         0|            0|            0|  0.00%|        idx = operator.index(idx)
    95|         0|            0|            0|  0.00%|        if not -size <= idx < size:
    96|         0|            0|            0|  0.00%|            raise IndexError('index {} is out of range'.format(idx))
    97|         0|            0|            0|  0.00%|        idx %= size
    98|         0|            0|            0|  0.00%|        return next(islice(iterator, idx, None))
    99|         0|            0|            0|  0.00%|
   100|         0|            0|            0|  0.00%|    @_copy_to_script_wrapper
   101|         0|            0|            0|  0.00%|    def __getitem__(self, idx) -> Union['Sequential', T]:
   102|         0|            0|            0|  0.00%|        if isinstance(idx, slice):
   103|         0|            0|            0|  0.00%|            return self.__class__(OrderedDict(list(self._modules.items())[idx]))
   104|         0|            0|            0|  0.00%|        else:
   105|         0|            0|            0|  0.00%|            return self._get_item_by_idx(self._modules.values(), idx)
   106|         0|            0|            0|  0.00%|
   107|         0|            0|            0|  0.00%|    def __setitem__(self, idx: int, module: Module) -> None:
   108|         0|            0|            0|  0.00%|        key: str = self._get_item_by_idx(self._modules.keys(), idx)
   109|         0|            0|            0|  0.00%|        return setattr(self, key, module)
   110|         0|            0|            0|  0.00%|
   111|         0|            0|            0|  0.00%|    def __delitem__(self, idx: Union[slice, int]) -> None:
   112|         0|            0|            0|  0.00%|        if isinstance(idx, slice):
   113|         0|            0|            0|  0.00%|            for key in list(self._modules.keys())[idx]:
   114|         0|            0|            0|  0.00%|                delattr(self, key)
   115|         0|            0|            0|  0.00%|        else:
   116|         0|            0|            0|  0.00%|            key = self._get_item_by_idx(self._modules.keys(), idx)
   117|         0|            0|            0|  0.00%|            delattr(self, key)
   118|         0|            0|            0|  0.00%|
   119|         0|            0|            0|  0.00%|    @_copy_to_script_wrapper
   120|         0|            0|            0|  0.00%|    def __len__(self) -> int:
   121|         0|            0|            0|  0.00%|        return len(self._modules)
   122|         0|            0|            0|  0.00%|
   123|         0|            0|            0|  0.00%|    @_copy_to_script_wrapper
   124|         0|            0|            0|  0.00%|    def __dir__(self):
   125|         0|            0|            0|  0.00%|        keys = super(Sequential, self).__dir__()
   126|         0|            0|            0|  0.00%|        keys = [key for key in keys if not key.isdigit()]
   127|         0|            0|            0|  0.00%|        return keys
   128|         0|            0|            0|  0.00%|
   129|      5238|   0.00768209|  1.46661e-06|  0.01%|    @_copy_to_script_wrapper
   130|         0|            0|            0|  0.00%|    def __iter__(self) -> Iterator[Module]:
   131|      5238|    0.0148816|  2.84109e-06|  0.01%|        return iter(self._modules.values())
   132|         0|            0|            0|  0.00%|
   133|         0|            0|            0|  0.00%|    # NB: We can't really type check this function as the type of input
   134|         0|            0|            0|  0.00%|    # may change dynamically (as is tested in
   135|         0|            0|            0|  0.00%|    # TestScript.test_sequential_intermediary_types).  Cannot annotate
   136|         0|            0|            0|  0.00%|    # with Any as TorchScript expects a more precise type
   137|      5238|    0.0104182|  1.98896e-06|  0.01%|    def forward(self, input):
   138|     31428|    0.0923388|  2.93811e-06|  0.09%|        for module in self:
(call)|      5238|    0.0225637|  4.30769e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/container.py:129 __iter__
   139|     26190|     0.258168|  9.85749e-06|  0.25%|            input = module(input)
(call)|     26190|      2.02054|  7.71493e-05|  1.94%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1124 _call_impl
   140|      5238|   0.00947738|  1.80935e-06|  0.01%|        return input
   141|         0|            0|            0|  0.00%|
   142|         0|            0|            0|  0.00%|    def append(self, module: Module) -> 'Sequential':
   143|         0|            0|            0|  0.00%|        r"""Appends a given module to the end.
   144|         0|            0|            0|  0.00%|
   145|         0|            0|            0|  0.00%|        Args:
   146|         0|            0|            0|  0.00%|            module (nn.Module): module to append
   147|         0|            0|            0|  0.00%|        """
   148|         0|            0|            0|  0.00%|        self.add_module(str(len(self)), module)
   149|         0|            0|            0|  0.00%|        return self
   150|         0|            0|            0|  0.00%|
   151|         0|            0|            0|  0.00%|
   152|         0|            0|            0|  0.00%|class ModuleList(Module):
   153|         0|            0|            0|  0.00%|    r"""Holds submodules in a list.
   154|         0|            0|            0|  0.00%|
   155|         0|            0|            0|  0.00%|    :class:`~torch.nn.ModuleList` can be indexed like a regular Python list, but
   156|         0|            0|            0|  0.00%|    modules it contains are properly registered, and will be visible by all
   157|         0|            0|            0|  0.00%|    :class:`~torch.nn.Module` methods.
   158|         0|            0|            0|  0.00%|
   159|         0|            0|            0|  0.00%|    Args:
   160|         0|            0|            0|  0.00%|        modules (iterable, optional): an iterable of modules to add
   161|         0|            0|            0|  0.00%|
   162|         0|            0|            0|  0.00%|    Example::
   163|         0|            0|            0|  0.00%|
   164|         0|            0|            0|  0.00%|        class MyModule(nn.Module):
   165|         0|            0|            0|  0.00%|            def __init__(self):
   166|         0|            0|            0|  0.00%|                super(MyModule, self).__init__()
   167|         0|            0|            0|  0.00%|                self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])
   168|         0|            0|            0|  0.00%|
   169|         0|            0|            0|  0.00%|            def forward(self, x):
   170|         0|            0|            0|  0.00%|                # ModuleList can act as an iterable, or be indexed using ints
   171|         0|            0|            0|  0.00%|                for i, l in enumerate(self.linears):
   172|         0|            0|            0|  0.00%|                    x = self.linears[i // 2](x) + l(x)
   173|         0|            0|            0|  0.00%|                return x
   174|         0|            0|            0|  0.00%|    """
   175|         0|            0|            0|  0.00%|
   176|         0|            0|            0|  0.00%|    _modules: Dict[str, Module]  # type: ignore[assignment]
   177|         0|            0|            0|  0.00%|
   178|         0|            0|            0|  0.00%|    def __init__(self, modules: Optional[Iterable[Module]] = None) -> None:
   179|         0|            0|            0|  0.00%|        super(ModuleList, self).__init__()
   180|         0|            0|            0|  0.00%|        if modules is not None:
   181|         0|            0|            0|  0.00%|            self += modules
   182|         0|            0|            0|  0.00%|
   183|         0|            0|            0|  0.00%|    def _get_abs_string_index(self, idx):
   184|         0|            0|            0|  0.00%|        """Get the absolute index for the list of modules"""
   185|         0|            0|            0|  0.00%|        idx = operator.index(idx)
   186|         0|            0|            0|  0.00%|        if not (-len(self) <= idx < len(self)):
   187|         0|            0|            0|  0.00%|            raise IndexError('index {} is out of range'.format(idx))
   188|         0|            0|            0|  0.00%|        if idx < 0:
   189|         0|            0|            0|  0.00%|            idx += len(self)
   190|         0|            0|            0|  0.00%|        return str(idx)
   191|         0|            0|            0|  0.00%|
   192|         0|            0|            0|  0.00%|    @_copy_to_script_wrapper
   193|         0|            0|            0|  0.00%|    def __getitem__(self, idx: int) -> Union[Module, 'ModuleList']:
   194|         0|            0|            0|  0.00%|        if isinstance(idx, slice):
   195|         0|            0|            0|  0.00%|            return self.__class__(list(self._modules.values())[idx])
   196|         0|            0|            0|  0.00%|        else:
   197|         0|            0|            0|  0.00%|            return self._modules[self._get_abs_string_index(idx)]
   198|         0|            0|            0|  0.00%|
   199|         0|            0|            0|  0.00%|    def __setitem__(self, idx: int, module: Module) -> None:
   200|         0|            0|            0|  0.00%|        idx = self._get_abs_string_index(idx)
   201|         0|            0|            0|  0.00%|        return setattr(self, str(idx), module)
   202|         0|            0|            0|  0.00%|
   203|         0|            0|            0|  0.00%|    def __delitem__(self, idx: Union[int, slice]) -> None:
   204|         0|            0|            0|  0.00%|        if isinstance(idx, slice):
   205|         0|            0|            0|  0.00%|            for k in range(len(self._modules))[idx]:
   206|         0|            0|            0|  0.00%|                delattr(self, str(k))
   207|         0|            0|            0|  0.00%|        else:
   208|         0|            0|            0|  0.00%|            delattr(self, self._get_abs_string_index(idx))
   209|         0|            0|            0|  0.00%|        # To preserve numbering, self._modules is being reconstructed with modules after deletion
   210|         0|            0|            0|  0.00%|        str_indices = [str(i) for i in range(len(self._modules))]
   211|         0|            0|            0|  0.00%|        self._modules = OrderedDict(list(zip(str_indices, self._modules.values())))
   212|         0|            0|            0|  0.00%|
   213|         0|            0|            0|  0.00%|    @_copy_to_script_wrapper
   214|         0|            0|            0|  0.00%|    def __len__(self) -> int:
   215|         0|            0|            0|  0.00%|        return len(self._modules)
   216|         0|            0|            0|  0.00%|
   217|         0|            0|            0|  0.00%|    @_copy_to_script_wrapper
   218|         0|            0|            0|  0.00%|    def __iter__(self) -> Iterator[Module]:
   219|         0|            0|            0|  0.00%|        return iter(self._modules.values())
   220|         0|            0|            0|  0.00%|
   221|         0|            0|            0|  0.00%|    def __iadd__(self, modules: Iterable[Module]) -> 'ModuleList':
   222|         0|            0|            0|  0.00%|        return self.extend(modules)
   223|         0|            0|            0|  0.00%|
   224|         0|            0|            0|  0.00%|    def __add__(self, other: Iterable[Module]) -> 'ModuleList':
   225|         0|            0|            0|  0.00%|        combined = ModuleList()
   226|         0|            0|            0|  0.00%|        for i, module in enumerate(chain(self, other)):
   227|         0|            0|            0|  0.00%|            combined.add_module(str(i), module)
   228|         0|            0|            0|  0.00%|        return combined
   229|         0|            0|            0|  0.00%|
   230|         0|            0|            0|  0.00%|    @_copy_to_script_wrapper
   231|         0|            0|            0|  0.00%|    def __dir__(self):
   232|         0|            0|            0|  0.00%|        keys = super(ModuleList, self).__dir__()
   233|         0|            0|            0|  0.00%|        keys = [key for key in keys if not key.isdigit()]
   234|         0|            0|            0|  0.00%|        return keys
   235|         0|            0|            0|  0.00%|
   236|         0|            0|            0|  0.00%|    def insert(self, index: int, module: Module) -> None:
   237|         0|            0|            0|  0.00%|        r"""Insert a given module before a given index in the list.
   238|         0|            0|            0|  0.00%|
   239|         0|            0|            0|  0.00%|        Args:
   240|         0|            0|            0|  0.00%|            index (int): index to insert.
   241|         0|            0|            0|  0.00%|            module (nn.Module): module to insert
   242|         0|            0|            0|  0.00%|        """
   243|         0|            0|            0|  0.00%|        for i in range(len(self._modules), index, -1):
   244|         0|            0|            0|  0.00%|            self._modules[str(i)] = self._modules[str(i - 1)]
   245|         0|            0|            0|  0.00%|        self._modules[str(index)] = module
   246|         0|            0|            0|  0.00%|
   247|         0|            0|            0|  0.00%|    def append(self, module: Module) -> 'ModuleList':
   248|         0|            0|            0|  0.00%|        r"""Appends a given module to the end of the list.
   249|         0|            0|            0|  0.00%|
   250|         0|            0|            0|  0.00%|        Args:
   251|         0|            0|            0|  0.00%|            module (nn.Module): module to append
   252|         0|            0|            0|  0.00%|        """
   253|         0|            0|            0|  0.00%|        self.add_module(str(len(self)), module)
   254|         0|            0|            0|  0.00%|        return self
   255|         0|            0|            0|  0.00%|
   256|         0|            0|            0|  0.00%|    def extend(self, modules: Iterable[Module]) -> 'ModuleList':
   257|         0|            0|            0|  0.00%|        r"""Appends modules from a Python iterable to the end of the list.
   258|         0|            0|            0|  0.00%|
   259|         0|            0|            0|  0.00%|        Args:
   260|         0|            0|            0|  0.00%|            modules (iterable): iterable of modules to append
   261|         0|            0|            0|  0.00%|        """
   262|         0|            0|            0|  0.00%|        if not isinstance(modules, container_abcs.Iterable):
   263|         0|            0|            0|  0.00%|            raise TypeError("ModuleList.extend should be called with an "
   264|         0|            0|            0|  0.00%|                            "iterable, but got " + type(modules).__name__)
   265|         0|            0|            0|  0.00%|        offset = len(self)
   266|         0|            0|            0|  0.00%|        for i, module in enumerate(modules):
   267|         0|            0|            0|  0.00%|            self.add_module(str(offset + i), module)
   268|         0|            0|            0|  0.00%|        return self
   269|         0|            0|            0|  0.00%|
   270|         0|            0|            0|  0.00%|    # remove forward alltogether to fallback on Module's _forward_unimplemented
   271|         0|            0|            0|  0.00%|
   272|         0|            0|            0|  0.00%|
   273|         0|            0|            0|  0.00%|class ModuleDict(Module):
   274|         0|            0|            0|  0.00%|    r"""Holds submodules in a dictionary.
   275|         0|            0|            0|  0.00%|
   276|         0|            0|            0|  0.00%|    :class:`~torch.nn.ModuleDict` can be indexed like a regular Python dictionary,
   277|         0|            0|            0|  0.00%|    but modules it contains are properly registered, and will be visible by all
   278|         0|            0|            0|  0.00%|    :class:`~torch.nn.Module` methods.
   279|         0|            0|            0|  0.00%|
   280|         0|            0|            0|  0.00%|    :class:`~torch.nn.ModuleDict` is an **ordered** dictionary that respects
   281|         0|            0|            0|  0.00%|
   282|         0|            0|            0|  0.00%|    * the order of insertion, and
   283|         0|            0|            0|  0.00%|
   284|         0|            0|            0|  0.00%|    * in :meth:`~torch.nn.ModuleDict.update`, the order of the merged
   285|         0|            0|            0|  0.00%|      ``OrderedDict``, ``dict`` (started from Python 3.6) or another
   286|         0|            0|            0|  0.00%|      :class:`~torch.nn.ModuleDict` (the argument to
   287|         0|            0|            0|  0.00%|      :meth:`~torch.nn.ModuleDict.update`).
   288|         0|            0|            0|  0.00%|
   289|         0|            0|            0|  0.00%|    Note that :meth:`~torch.nn.ModuleDict.update` with other unordered mapping
   290|         0|            0|            0|  0.00%|    types (e.g., Python's plain ``dict`` before Python version 3.6) does not
   291|         0|            0|            0|  0.00%|    preserve the order of the merged mapping.
   292|         0|            0|            0|  0.00%|
   293|         0|            0|            0|  0.00%|    Args:
   294|         0|            0|            0|  0.00%|        modules (iterable, optional): a mapping (dictionary) of (string: module)
   295|         0|            0|            0|  0.00%|            or an iterable of key-value pairs of type (string, module)
   296|         0|            0|            0|  0.00%|
   297|         0|            0|            0|  0.00%|    Example::
   298|         0|            0|            0|  0.00%|
   299|         0|            0|            0|  0.00%|        class MyModule(nn.Module):
   300|         0|            0|            0|  0.00%|            def __init__(self):
   301|         0|            0|            0|  0.00%|                super(MyModule, self).__init__()
   302|         0|            0|            0|  0.00%|                self.choices = nn.ModuleDict({
   303|         0|            0|            0|  0.00%|                        'conv': nn.Conv2d(10, 10, 3),
   304|         0|            0|            0|  0.00%|                        'pool': nn.MaxPool2d(3)
   305|         0|            0|            0|  0.00%|                })
   306|         0|            0|            0|  0.00%|                self.activations = nn.ModuleDict([
   307|         0|            0|            0|  0.00%|                        ['lrelu', nn.LeakyReLU()],
   308|         0|            0|            0|  0.00%|                        ['prelu', nn.PReLU()]
   309|         0|            0|            0|  0.00%|                ])
   310|         0|            0|            0|  0.00%|
   311|         0|            0|            0|  0.00%|            def forward(self, x, choice, act):
   312|         0|            0|            0|  0.00%|                x = self.choices[choice](x)
   313|         0|            0|            0|  0.00%|                x = self.activations[act](x)
   314|         0|            0|            0|  0.00%|                return x
   315|         0|            0|            0|  0.00%|    """
   316|         0|            0|            0|  0.00%|
   317|         0|            0|            0|  0.00%|    _modules: Dict[str, Module]  # type: ignore[assignment]
   318|         0|            0|            0|  0.00%|
   319|         0|            0|            0|  0.00%|    def __init__(self, modules: Optional[Mapping[str, Module]] = None) -> None:
   320|         0|            0|            0|  0.00%|        super(ModuleDict, self).__init__()
   321|         0|            0|            0|  0.00%|        if modules is not None:
   322|         0|            0|            0|  0.00%|            self.update(modules)
   323|         0|            0|            0|  0.00%|
   324|         0|            0|            0|  0.00%|    @_copy_to_script_wrapper
   325|         0|            0|            0|  0.00%|    def __getitem__(self, key: str) -> Module:
   326|         0|            0|            0|  0.00%|        return self._modules[key]
   327|         0|            0|            0|  0.00%|
   328|         0|            0|            0|  0.00%|    def __setitem__(self, key: str, module: Module) -> None:
   329|         0|            0|            0|  0.00%|        self.add_module(key, module)
   330|         0|            0|            0|  0.00%|
   331|         0|            0|            0|  0.00%|    def __delitem__(self, key: str) -> None:
   332|         0|            0|            0|  0.00%|        del self._modules[key]
   333|         0|            0|            0|  0.00%|
   334|         0|            0|            0|  0.00%|    @_copy_to_script_wrapper
   335|         0|            0|            0|  0.00%|    def __len__(self) -> int:
   336|         0|            0|            0|  0.00%|        return len(self._modules)
   337|         0|            0|            0|  0.00%|
   338|         0|            0|            0|  0.00%|    @_copy_to_script_wrapper
   339|         0|            0|            0|  0.00%|    def __iter__(self) -> Iterator[str]:
   340|         0|            0|            0|  0.00%|        return iter(self._modules)
   341|         0|            0|            0|  0.00%|
   342|         0|            0|            0|  0.00%|    @_copy_to_script_wrapper
   343|         0|            0|            0|  0.00%|    def __contains__(self, key: str) -> bool:
   344|         0|            0|            0|  0.00%|        return key in self._modules
   345|         0|            0|            0|  0.00%|
   346|         0|            0|            0|  0.00%|    def clear(self) -> None:
   347|         0|            0|            0|  0.00%|        """Remove all items from the ModuleDict.
   348|         0|            0|            0|  0.00%|        """
   349|         0|            0|            0|  0.00%|        self._modules.clear()
   350|         0|            0|            0|  0.00%|
   351|         0|            0|            0|  0.00%|    def pop(self, key: str) -> Module:
   352|         0|            0|            0|  0.00%|        r"""Remove key from the ModuleDict and return its module.
   353|         0|            0|            0|  0.00%|
   354|         0|            0|            0|  0.00%|        Args:
   355|         0|            0|            0|  0.00%|            key (string): key to pop from the ModuleDict
   356|         0|            0|            0|  0.00%|        """
   357|         0|            0|            0|  0.00%|        v = self[key]
   358|         0|            0|            0|  0.00%|        del self[key]
   359|         0|            0|            0|  0.00%|        return v
   360|         0|            0|            0|  0.00%|
   361|         0|            0|            0|  0.00%|    @_copy_to_script_wrapper
   362|         0|            0|            0|  0.00%|    def keys(self) -> Iterable[str]:
   363|         0|            0|            0|  0.00%|        r"""Return an iterable of the ModuleDict keys.
   364|         0|            0|            0|  0.00%|        """
   365|         0|            0|            0|  0.00%|        return self._modules.keys()
   366|         0|            0|            0|  0.00%|
   367|         0|            0|            0|  0.00%|    @_copy_to_script_wrapper
   368|         0|            0|            0|  0.00%|    def items(self) -> Iterable[Tuple[str, Module]]:
   369|         0|            0|            0|  0.00%|        r"""Return an iterable of the ModuleDict key/value pairs.
   370|         0|            0|            0|  0.00%|        """
   371|         0|            0|            0|  0.00%|        return self._modules.items()
   372|         0|            0|            0|  0.00%|
   373|         0|            0|            0|  0.00%|    @_copy_to_script_wrapper
   374|         0|            0|            0|  0.00%|    def values(self) -> Iterable[Module]:
   375|         0|            0|            0|  0.00%|        r"""Return an iterable of the ModuleDict values.
   376|         0|            0|            0|  0.00%|        """
   377|         0|            0|            0|  0.00%|        return self._modules.values()
   378|         0|            0|            0|  0.00%|
   379|         0|            0|            0|  0.00%|    def update(self, modules: Mapping[str, Module]) -> None:
   380|         0|            0|            0|  0.00%|        r"""Update the :class:`~torch.nn.ModuleDict` with the key-value pairs from a
   381|         0|            0|            0|  0.00%|        mapping or an iterable, overwriting existing keys.
   382|         0|            0|            0|  0.00%|
   383|         0|            0|            0|  0.00%|        .. note::
   384|         0|            0|            0|  0.00%|            If :attr:`modules` is an ``OrderedDict``, a :class:`~torch.nn.ModuleDict`, or
   385|         0|            0|            0|  0.00%|            an iterable of key-value pairs, the order of new elements in it is preserved.
   386|         0|            0|            0|  0.00%|
   387|         0|            0|            0|  0.00%|        Args:
   388|         0|            0|            0|  0.00%|            modules (iterable): a mapping (dictionary) from string to :class:`~torch.nn.Module`,
   389|         0|            0|            0|  0.00%|                or an iterable of key-value pairs of type (string, :class:`~torch.nn.Module`)
   390|         0|            0|            0|  0.00%|        """
   391|         0|            0|            0|  0.00%|        if not isinstance(modules, container_abcs.Iterable):
   392|         0|            0|            0|  0.00%|            raise TypeError("ModuleDict.update should be called with an "
   393|         0|            0|            0|  0.00%|                            "iterable of key/value pairs, but got " +
   394|         0|            0|            0|  0.00%|                            type(modules).__name__)
   395|         0|            0|            0|  0.00%|
   396|         0|            0|            0|  0.00%|        if isinstance(modules, (OrderedDict, ModuleDict, container_abcs.Mapping)):
   397|         0|            0|            0|  0.00%|            for key, module in modules.items():
   398|         0|            0|            0|  0.00%|                self[key] = module
   399|         0|            0|            0|  0.00%|        else:
   400|         0|            0|            0|  0.00%|            # modules here can be a list with two items
   401|         0|            0|            0|  0.00%|            for j, m in enumerate(modules):
   402|         0|            0|            0|  0.00%|                if not isinstance(m, container_abcs.Iterable):
   403|         0|            0|            0|  0.00%|                    raise TypeError("ModuleDict update sequence element "
   404|         0|            0|            0|  0.00%|                                    "#" + str(j) + " should be Iterable; is" +
   405|         0|            0|            0|  0.00%|                                    type(m).__name__)
   406|         0|            0|            0|  0.00%|                if not len(m) == 2:
   407|         0|            0|            0|  0.00%|                    raise ValueError("ModuleDict update sequence element "
   408|         0|            0|            0|  0.00%|                                     "#" + str(j) + " has length " + str(len(m)) +
   409|         0|            0|            0|  0.00%|                                     "; 2 is required")
   410|         0|            0|            0|  0.00%|                # modules can be Mapping (what it's typed at), or a list: [(name1, module1), (name2, module2)]
   411|         0|            0|            0|  0.00%|                # that's too cumbersome to type correctly with overloads, so we add an ignore here
   412|         0|            0|            0|  0.00%|                self[m[0]] = m[1]  # type: ignore[assignment]
   413|         0|            0|            0|  0.00%|
   414|         0|            0|            0|  0.00%|    # remove forward alltogether to fallback on Module's _forward_unimplemented
   415|         0|            0|            0|  0.00%|
   416|         0|            0|            0|  0.00%|
   417|         0|            0|            0|  0.00%|class ParameterList(Module):
   418|         0|            0|            0|  0.00%|    r"""Holds parameters in a list.
   419|         0|            0|            0|  0.00%|
   420|         0|            0|            0|  0.00%|    :class:`~torch.nn.ParameterList` can be used like a regular Python
   421|         0|            0|            0|  0.00%|    list, but Tensors that are :class:`~torch.nn.Parameter` are properly registered,
   422|         0|            0|            0|  0.00%|    and will be visible by all :class:`~torch.nn.Module` methods.
   423|         0|            0|            0|  0.00%|
   424|         0|            0|            0|  0.00%|    Note that the constructor, assigning an element of the list, the
   425|         0|            0|            0|  0.00%|    :meth:`~torch.nn.ParameterDict.append` method and the :meth:`~torch.nn.ParameterDict.extend`
   426|         0|            0|            0|  0.00%|    method will convert any :class:`~torch.Tensor` into :class:`~torch.nn.Parameter`.
   427|         0|            0|            0|  0.00%|
   428|         0|            0|            0|  0.00%|    Args:
   429|         0|            0|            0|  0.00%|        parameters (iterable, optional): an iterable of elements to add to the list.
   430|         0|            0|            0|  0.00%|
   431|         0|            0|            0|  0.00%|    Example::
   432|         0|            0|            0|  0.00%|
   433|         0|            0|            0|  0.00%|        class MyModule(nn.Module):
   434|         0|            0|            0|  0.00%|            def __init__(self):
   435|         0|            0|            0|  0.00%|                super(MyModule, self).__init__()
   436|         0|            0|            0|  0.00%|                self.params = nn.ParameterList([nn.Parameter(torch.randn(10, 10)) for i in range(10)])
   437|         0|            0|            0|  0.00%|
   438|         0|            0|            0|  0.00%|            def forward(self, x):
   439|         0|            0|            0|  0.00%|                # ParameterList can act as an iterable, or be indexed using ints
   440|         0|            0|            0|  0.00%|                for i, p in enumerate(self.params):
   441|         0|            0|            0|  0.00%|                    x = self.params[i // 2].mm(x) + p.mm(x)
   442|         0|            0|            0|  0.00%|                return x
   443|         0|            0|            0|  0.00%|    """
   444|         0|            0|            0|  0.00%|
   445|         0|            0|            0|  0.00%|    def __init__(self, values: Optional[Iterable[Any]] = None) -> None:
   446|         0|            0|            0|  0.00%|        super(ParameterList, self).__init__()
   447|         0|            0|            0|  0.00%|        self._size = 0
   448|         0|            0|            0|  0.00%|        if values is not None:
   449|         0|            0|            0|  0.00%|            self += values
   450|         0|            0|            0|  0.00%|
   451|         0|            0|            0|  0.00%|    def _get_abs_string_index(self, idx):
   452|         0|            0|            0|  0.00%|        """Get the absolute index for the list of modules"""
   453|         0|            0|            0|  0.00%|        idx = operator.index(idx)
   454|         0|            0|            0|  0.00%|        if not (-len(self) <= idx < len(self)):
   455|         0|            0|            0|  0.00%|            raise IndexError('index {} is out of range'.format(idx))
   456|         0|            0|            0|  0.00%|        if idx < 0:
   457|         0|            0|            0|  0.00%|            idx += len(self)
   458|         0|            0|            0|  0.00%|        return str(idx)
   459|         0|            0|            0|  0.00%|
   460|         0|            0|            0|  0.00%|    @overload
   461|         0|            0|            0|  0.00%|    def __getitem__(self, idx: int) -> Any:
   462|         0|            0|            0|  0.00%|        ...
   463|         0|            0|            0|  0.00%|
   464|         0|            0|            0|  0.00%|    @overload
   465|         0|            0|            0|  0.00%|    def __getitem__(self: T, idx: slice) -> T:
   466|         0|            0|            0|  0.00%|        ...
   467|         0|            0|            0|  0.00%|
   468|         0|            0|            0|  0.00%|    def __getitem__(self, idx):
   469|         0|            0|            0|  0.00%|        if isinstance(idx, slice):
   470|         0|            0|            0|  0.00%|            start, stop, step = idx.indices(len(self))
   471|         0|            0|            0|  0.00%|            out = self.__class__()
   472|         0|            0|            0|  0.00%|            for i in range(start, stop, step):
   473|         0|            0|            0|  0.00%|                out.append(self[i])
   474|         0|            0|            0|  0.00%|            return out
   475|         0|            0|            0|  0.00%|        else:
   476|         0|            0|            0|  0.00%|            idx = self._get_abs_string_index(idx)
   477|         0|            0|            0|  0.00%|            return getattr(self, str(idx))
   478|         0|            0|            0|  0.00%|
   479|         0|            0|            0|  0.00%|    def __setitem__(self, idx: int, param: Any) -> None:
   480|         0|            0|            0|  0.00%|        # Note that all other function that add an entry to the list part of
   481|         0|            0|            0|  0.00%|        # the ParameterList end up here. So this is the only place where we need
   482|         0|            0|            0|  0.00%|        # to wrap things into Parameter if needed.
   483|         0|            0|            0|  0.00%|        # Objects added via setattr() are not in the list part and thus won't
   484|         0|            0|            0|  0.00%|        # call into this function.
   485|         0|            0|            0|  0.00%|        idx = self._get_abs_string_index(idx)
   486|         0|            0|            0|  0.00%|        if isinstance(param, torch.Tensor) and not isinstance(param, Parameter):
   487|         0|            0|            0|  0.00%|            param = Parameter(param)
   488|         0|            0|            0|  0.00%|        return setattr(self, str(idx), param)
   489|         0|            0|            0|  0.00%|
   490|         0|            0|            0|  0.00%|    def __len__(self) -> int:
   491|         0|            0|            0|  0.00%|        return self._size
   492|         0|            0|            0|  0.00%|
   493|         0|            0|            0|  0.00%|    def __iter__(self) -> Iterator[Any]:
   494|         0|            0|            0|  0.00%|        return iter(self[i] for i in range(len(self)))
   495|         0|            0|            0|  0.00%|
   496|         0|            0|            0|  0.00%|    def __iadd__(self, parameters: Iterable[Any]) -> 'ParameterList':
   497|         0|            0|            0|  0.00%|        return self.extend(parameters)
   498|         0|            0|            0|  0.00%|
   499|         0|            0|            0|  0.00%|    def __dir__(self):
   500|         0|            0|            0|  0.00%|        keys = super(ParameterList, self).__dir__()
   501|         0|            0|            0|  0.00%|        keys = [key for key in keys if not key.isdigit()]
   502|         0|            0|            0|  0.00%|        return keys
   503|         0|            0|            0|  0.00%|
   504|         0|            0|            0|  0.00%|    def append(self, value: Any) -> 'ParameterList':
   505|         0|            0|            0|  0.00%|        """Appends a given value at the end of the list.
   506|         0|            0|            0|  0.00%|
   507|         0|            0|            0|  0.00%|        Args:
   508|         0|            0|            0|  0.00%|            value (Any): value to append
   509|         0|            0|            0|  0.00%|        """
   510|         0|            0|            0|  0.00%|        new_idx = len(self)
   511|         0|            0|            0|  0.00%|        self._size += 1
   512|         0|            0|            0|  0.00%|        self[new_idx] = value
   513|         0|            0|            0|  0.00%|        return self
   514|         0|            0|            0|  0.00%|
   515|         0|            0|            0|  0.00%|    def extend(self, values: Iterable[Any]) -> 'ParameterList':
   516|         0|            0|            0|  0.00%|        """Appends values from a Python iterable to the end of the list.
   517|         0|            0|            0|  0.00%|
   518|         0|            0|            0|  0.00%|        Args:
   519|         0|            0|            0|  0.00%|            values (iterable): iterable of values to append
   520|         0|            0|            0|  0.00%|        """
   521|         0|            0|            0|  0.00%|        # Tensor is an iterable but we never want to unpack it here
   522|         0|            0|            0|  0.00%|        if not isinstance(values, container_abcs.Iterable) or isinstance(values, torch.Tensor):
   523|         0|            0|            0|  0.00%|            raise TypeError("ParameterList.extend should be called with an "
   524|         0|            0|            0|  0.00%|                            "iterable, but got " + type(values).__name__)
   525|         0|            0|            0|  0.00%|        for value in values:
   526|         0|            0|            0|  0.00%|            self.append(value)
   527|         0|            0|            0|  0.00%|        return self
   528|         0|            0|            0|  0.00%|
   529|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   530|         0|            0|            0|  0.00%|        child_lines = []
   531|         0|            0|            0|  0.00%|        for k, p in enumerate(self):
   532|         0|            0|            0|  0.00%|            if isinstance(p, torch.Tensor):
   533|         0|            0|            0|  0.00%|                size_str = 'x'.join(str(size) for size in p.size())
   534|         0|            0|            0|  0.00%|                device_str = '' if not p.is_cuda else ' (GPU {})'.format(p.get_device())
   535|         0|            0|            0|  0.00%|                parastr = '{} containing: [{} of size {}{}]'.format(
   536|         0|            0|            0|  0.00%|                    "Parameter" if isinstance(p, Parameter) else "Tensor",
   537|         0|            0|            0|  0.00%|                    torch.typename(p), size_str, device_str)
   538|         0|            0|            0|  0.00%|                child_lines.append('  (' + str(k) + '): ' + parastr)
   539|         0|            0|            0|  0.00%|            else:
   540|         0|            0|            0|  0.00%|                child_lines.append('  (' + str(k) + '): Object of type: ' + type(p).__name__)
   541|         0|            0|            0|  0.00%|
   542|         0|            0|            0|  0.00%|        tmpstr = '\n'.join(child_lines)
   543|         0|            0|            0|  0.00%|        return tmpstr
   544|         0|            0|            0|  0.00%|
   545|         0|            0|            0|  0.00%|    def __call__(self, *args, **kwargs):
   546|         0|            0|            0|  0.00%|        raise RuntimeError('ParameterList should not be called.')
   547|         0|            0|            0|  0.00%|
   548|         0|            0|            0|  0.00%|
   549|         0|            0|            0|  0.00%|class ParameterDict(Module):
   550|         0|            0|            0|  0.00%|    r"""Holds parameters in a dictionary.
   551|         0|            0|            0|  0.00%|
   552|         0|            0|            0|  0.00%|    ParameterDict can be indexed like a regular Python dictionary, but Parameters it
   553|         0|            0|            0|  0.00%|    contains are properly registered, and will be visible by all Module methods.
   554|         0|            0|            0|  0.00%|    Other objects are treated as would be done by a regular Python dictionary
   555|         0|            0|            0|  0.00%|
   556|         0|            0|            0|  0.00%|    :class:`~torch.nn.ParameterDict` is an **ordered** dictionary.
   557|         0|            0|            0|  0.00%|    :meth:`~torch.nn.ParameterDict.update` with other unordered mapping
   558|         0|            0|            0|  0.00%|    types (e.g., Python's plain ``dict``) does not preserve the order of the
   559|         0|            0|            0|  0.00%|    merged mapping. On the other hand, ``OrderedDict`` or another :class:`~torch.nn.ParameterDict`
   560|         0|            0|            0|  0.00%|    will preserve their ordering.
   561|         0|            0|            0|  0.00%|
   562|         0|            0|            0|  0.00%|    Note that the constructor, assigning an element of the dictionary and the
   563|         0|            0|            0|  0.00%|    :meth:`~torch.nn.ParameterDict.update` method will convert any :class:`~torch.Tensor` into
   564|         0|            0|            0|  0.00%|    :class:`~torch.nn.Parameter`.
   565|         0|            0|            0|  0.00%|
   566|         0|            0|            0|  0.00%|    Args:
   567|         0|            0|            0|  0.00%|        values (iterable, optional): a mapping (dictionary) of
   568|         0|            0|            0|  0.00%|            (string : Any) or an iterable of key-value pairs
   569|         0|            0|            0|  0.00%|            of type (string, Any)
   570|         0|            0|            0|  0.00%|
   571|         0|            0|            0|  0.00%|    Example::
   572|         0|            0|            0|  0.00%|
   573|         0|            0|            0|  0.00%|        class MyModule(nn.Module):
   574|         0|            0|            0|  0.00%|            def __init__(self):
   575|         0|            0|            0|  0.00%|                super(MyModule, self).__init__()
   576|         0|            0|            0|  0.00%|                self.params = nn.ParameterDict({
   577|         0|            0|            0|  0.00%|                        'left': nn.Parameter(torch.randn(5, 10)),
   578|         0|            0|            0|  0.00%|                        'right': nn.Parameter(torch.randn(5, 10))
   579|         0|            0|            0|  0.00%|                })
   580|         0|            0|            0|  0.00%|
   581|         0|            0|            0|  0.00%|            def forward(self, x, choice):
   582|         0|            0|            0|  0.00%|                x = self.params[choice].mm(x)
   583|         0|            0|            0|  0.00%|                return x
   584|         0|            0|            0|  0.00%|    """
   585|         0|            0|            0|  0.00%|
   586|         0|            0|            0|  0.00%|    def __init__(self, parameters: Any = None) -> None:
   587|         0|            0|            0|  0.00%|        super(ParameterDict, self).__init__()
   588|         0|            0|            0|  0.00%|        self._keys: Dict[str, None] = {}
   589|         0|            0|            0|  0.00%|        if parameters is not None:
   590|         0|            0|            0|  0.00%|            self.update(parameters)
   591|         0|            0|            0|  0.00%|
   592|         0|            0|            0|  0.00%|    def _key_to_attr(self, key: str) -> str:
   593|         0|            0|            0|  0.00%|        if not isinstance(key, str):
   594|         0|            0|            0|  0.00%|            raise TypeError("Index given to ParameterDict cannot be used as a key as it is "
   595|         0|            0|            0|  0.00%|                            f"not a string (type is '{type(key).__name__}'). Open an issue on "
   596|         0|            0|            0|  0.00%|                            "github if you need non-string keys.")
   597|         0|            0|            0|  0.00%|        else:
   598|         0|            0|            0|  0.00%|            # Use the key as-is so that `.named_parameters()` returns the right thing
   599|         0|            0|            0|  0.00%|            return key
   600|         0|            0|            0|  0.00%|
   601|         0|            0|            0|  0.00%|    def __getitem__(self, key: str) -> Any:
   602|         0|            0|            0|  0.00%|        attr = self._key_to_attr(key)
   603|         0|            0|            0|  0.00%|        return getattr(self, attr)
   604|         0|            0|            0|  0.00%|
   605|         0|            0|            0|  0.00%|    def __setitem__(self, key: str, value: Any) -> None:
   606|         0|            0|            0|  0.00%|        # Note that all other function that add an entry to the dictionary part of
   607|         0|            0|            0|  0.00%|        # the ParameterDict end up here. So this is the only place where we need
   608|         0|            0|            0|  0.00%|        # to wrap things into Parameter if needed.
   609|         0|            0|            0|  0.00%|        # Objects added via setattr() are not in the dictionary part and thus won't
   610|         0|            0|            0|  0.00%|        # call into this function.
   611|         0|            0|            0|  0.00%|        self._keys[key] = None
   612|         0|            0|            0|  0.00%|        attr = self._key_to_attr(key)
   613|         0|            0|            0|  0.00%|        if isinstance(value, torch.Tensor) and not isinstance(value, Parameter):
   614|         0|            0|            0|  0.00%|            value = Parameter(value)
   615|         0|            0|            0|  0.00%|        setattr(self, attr, value)
   616|         0|            0|            0|  0.00%|
   617|         0|            0|            0|  0.00%|    def __delitem__(self, key: str) -> None:
   618|         0|            0|            0|  0.00%|        del self._keys[key]
   619|         0|            0|            0|  0.00%|        attr = self._key_to_attr(key)
   620|         0|            0|            0|  0.00%|        delattr(self, attr)
   621|         0|            0|            0|  0.00%|
   622|         0|            0|            0|  0.00%|    def __len__(self) -> int:
   623|         0|            0|            0|  0.00%|        return len(self._keys)
   624|         0|            0|            0|  0.00%|
   625|         0|            0|            0|  0.00%|    def __iter__(self) -> Iterator[str]:
   626|         0|            0|            0|  0.00%|        return iter(self._keys)
   627|         0|            0|            0|  0.00%|
   628|         0|            0|            0|  0.00%|    def __reversed__(self) -> Iterator[str]:
   629|         0|            0|            0|  0.00%|        return reversed(list(self._keys))
   630|         0|            0|            0|  0.00%|
   631|         0|            0|            0|  0.00%|    def copy(self) -> 'ParameterDict':
   632|         0|            0|            0|  0.00%|        """Returns a copy of this :class:`~torch.nn.ParameterDict` instance.
   633|         0|            0|            0|  0.00%|        """
   634|         0|            0|            0|  0.00%|        # We have to use an OrderedDict because the ParameterDict constructor
   635|         0|            0|            0|  0.00%|        # behaves differently on plain dict vs OrderedDict
   636|         0|            0|            0|  0.00%|        return ParameterDict(OrderedDict((k, self[k]) for k in self._keys))
   637|         0|            0|            0|  0.00%|
   638|         0|            0|            0|  0.00%|    def __contains__(self, key: str) -> bool:
   639|         0|            0|            0|  0.00%|        return key in self._keys
   640|         0|            0|            0|  0.00%|
   641|         0|            0|            0|  0.00%|    def setdefault(self, key: str, default: Optional[Any] = None) -> Any:
   642|         0|            0|            0|  0.00%|        """If key is in the ParameterDict, return its value.
   643|         0|            0|            0|  0.00%|        If not, insert `key` with a parameter `default` and return `default`.
   644|         0|            0|            0|  0.00%|        `default` defaults to `None`.
   645|         0|            0|            0|  0.00%|
   646|         0|            0|            0|  0.00%|        Args:
   647|         0|            0|            0|  0.00%|            key (string): key to set default for
   648|         0|            0|            0|  0.00%|            default (Any): the parameter set to the key
   649|         0|            0|            0|  0.00%|        """
   650|         0|            0|            0|  0.00%|
   651|         0|            0|            0|  0.00%|        if key not in self:
   652|         0|            0|            0|  0.00%|            self[key] = default
   653|         0|            0|            0|  0.00%|        return self[key]
   654|         0|            0|            0|  0.00%|
   655|         0|            0|            0|  0.00%|    def clear(self) -> None:
   656|         0|            0|            0|  0.00%|        """Remove all items from the ParameterDict.
   657|         0|            0|            0|  0.00%|        """
   658|         0|            0|            0|  0.00%|        for k in self._keys.copy():
   659|         0|            0|            0|  0.00%|            del self[k]
   660|         0|            0|            0|  0.00%|
   661|         0|            0|            0|  0.00%|    def pop(self, key: str) -> Any:
   662|         0|            0|            0|  0.00%|        r"""Remove key from the ParameterDict and return its parameter.
   663|         0|            0|            0|  0.00%|
   664|         0|            0|            0|  0.00%|        Args:
   665|         0|            0|            0|  0.00%|            key (string): key to pop from the ParameterDict
   666|         0|            0|            0|  0.00%|        """
   667|         0|            0|            0|  0.00%|        v = self[key]
   668|         0|            0|            0|  0.00%|        del self[key]
   669|         0|            0|            0|  0.00%|        return v
   670|         0|            0|            0|  0.00%|
   671|         0|            0|            0|  0.00%|    def popitem(self) -> Tuple[str, Any]:
   672|         0|            0|            0|  0.00%|        """Remove and return the last inserted `(key, parameter)` pair
   673|         0|            0|            0|  0.00%|        from the ParameterDict
   674|         0|            0|            0|  0.00%|        """
   675|         0|            0|            0|  0.00%|        k, _ = self._keys.popitem()
   676|         0|            0|            0|  0.00%|        # We need the key in the _keys to be able to access/del
   677|         0|            0|            0|  0.00%|        self._keys[k] = None
   678|         0|            0|            0|  0.00%|        val = self[k]
   679|         0|            0|            0|  0.00%|        del self[k]
   680|         0|            0|            0|  0.00%|        return k, val
   681|         0|            0|            0|  0.00%|
   682|         0|            0|            0|  0.00%|    def get(self, key: str, default: Optional[Any] = None) -> Any:
   683|         0|            0|            0|  0.00%|        r"""Return the parameter associated with key if present.
   684|         0|            0|            0|  0.00%|        Otherwise return default if provided, None if not.
   685|         0|            0|            0|  0.00%|
   686|         0|            0|            0|  0.00%|        Args:
   687|         0|            0|            0|  0.00%|            key (string): key to get from the ParameterDict
   688|         0|            0|            0|  0.00%|            default (Parameter, optional): value to return if key not present
   689|         0|            0|            0|  0.00%|        """
   690|         0|            0|            0|  0.00%|        return self[key] if key in self else default
   691|         0|            0|            0|  0.00%|
   692|         0|            0|            0|  0.00%|    def fromkeys(self, keys: Iterable[str], default: Optional[Any] = None) -> 'ParameterDict':
   693|         0|            0|            0|  0.00%|        r"""Return a new ParameterDict with the keys provided
   694|         0|            0|            0|  0.00%|
   695|         0|            0|            0|  0.00%|        Args:
   696|         0|            0|            0|  0.00%|            keys (iterable, string): keys to make the new ParameterDict from
   697|         0|            0|            0|  0.00%|            default (Parameter, optional): value to set for all keys
   698|         0|            0|            0|  0.00%|        """
   699|         0|            0|            0|  0.00%|        return ParameterDict(((k, default) for k in keys))
   700|         0|            0|            0|  0.00%|
   701|         0|            0|            0|  0.00%|    def keys(self) -> Iterable[str]:
   702|         0|            0|            0|  0.00%|        r"""Return an iterable of the ParameterDict keys.
   703|         0|            0|            0|  0.00%|        """
   704|         0|            0|            0|  0.00%|        return self._keys.keys()
   705|         0|            0|            0|  0.00%|
   706|         0|            0|            0|  0.00%|    def items(self) -> Iterable[Tuple[str, Any]]:
   707|         0|            0|            0|  0.00%|        r"""Return an iterable of the ParameterDict key/value pairs.
   708|         0|            0|            0|  0.00%|        """
   709|         0|            0|            0|  0.00%|        return ((k, self[k]) for k in self._keys)
   710|         0|            0|            0|  0.00%|
   711|         0|            0|            0|  0.00%|    def values(self) -> Iterable[Any]:
   712|         0|            0|            0|  0.00%|        r"""Return an iterable of the ParameterDict values.
   713|         0|            0|            0|  0.00%|        """
   714|         0|            0|            0|  0.00%|        return (self[k] for k in self._keys)
   715|         0|            0|            0|  0.00%|
   716|         0|            0|            0|  0.00%|    def update(self, parameters: Union[Mapping[str, Any], 'ParameterDict']) -> None:
   717|         0|            0|            0|  0.00%|        r"""Update the :class:`~torch.nn.ParameterDict` with the key-value pairs from a
   718|         0|            0|            0|  0.00%|        mapping or an iterable, overwriting existing keys.
   719|         0|            0|            0|  0.00%|
   720|         0|            0|            0|  0.00%|        .. note::
   721|         0|            0|            0|  0.00%|            If :attr:`parameters` is an ``OrderedDict``, a :class:`~torch.nn.ParameterDict`, or
   722|         0|            0|            0|  0.00%|            an iterable of key-value pairs, the order of new elements in it is preserved.
   723|         0|            0|            0|  0.00%|
   724|         0|            0|            0|  0.00%|        Args:
   725|         0|            0|            0|  0.00%|            parameters (iterable): a mapping (dictionary) from string to
   726|         0|            0|            0|  0.00%|                :class:`~torch.nn.Parameter`, or an iterable of
   727|         0|            0|            0|  0.00%|                key-value pairs of type (string, :class:`~torch.nn.Parameter`)
   728|         0|            0|            0|  0.00%|        """
   729|         0|            0|            0|  0.00%|        if not isinstance(parameters, container_abcs.Iterable):
   730|         0|            0|            0|  0.00%|            raise TypeError("ParametersDict.update should be called with an "
   731|         0|            0|            0|  0.00%|                            "iterable of key/value pairs, but got " +
   732|         0|            0|            0|  0.00%|                            type(parameters).__name__)
   733|         0|            0|            0|  0.00%|
   734|         0|            0|            0|  0.00%|        if isinstance(parameters, (OrderedDict, ParameterDict)):
   735|         0|            0|            0|  0.00%|            for key, parameter in parameters.items():
   736|         0|            0|            0|  0.00%|                self[key] = parameter
   737|         0|            0|            0|  0.00%|        elif isinstance(parameters, container_abcs.Mapping):
   738|         0|            0|            0|  0.00%|            for key, parameter in sorted(parameters.items()):
   739|         0|            0|            0|  0.00%|                self[key] = parameter
   740|         0|            0|            0|  0.00%|        else:
   741|         0|            0|            0|  0.00%|            for j, p in enumerate(parameters):
   742|         0|            0|            0|  0.00%|                if not isinstance(p, container_abcs.Iterable):
   743|         0|            0|            0|  0.00%|                    raise TypeError("ParameterDict update sequence element "
   744|         0|            0|            0|  0.00%|                                    "#" + str(j) + " should be Iterable; is" +
   745|         0|            0|            0|  0.00%|                                    type(p).__name__)
   746|         0|            0|            0|  0.00%|                if not len(p) == 2:
   747|         0|            0|            0|  0.00%|                    raise ValueError("ParameterDict update sequence element "
   748|         0|            0|            0|  0.00%|                                     "#" + str(j) + " has length " + str(len(p)) +
   749|         0|            0|            0|  0.00%|                                     "; 2 is required")
   750|         0|            0|            0|  0.00%|                # parameters as length-2 list too cumbersome to type, see ModuleDict.update comment
   751|         0|            0|            0|  0.00%|                self[p[0]] = p[1]  # type: ignore[assignment]
   752|         0|            0|            0|  0.00%|
   753|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   754|         0|            0|            0|  0.00%|        child_lines = []
   755|         0|            0|            0|  0.00%|        for k, p in self.items():
   756|         0|            0|            0|  0.00%|            if isinstance(p, torch.Tensor):
   757|         0|            0|            0|  0.00%|                size_str = 'x'.join(str(size) for size in p.size())
   758|         0|            0|            0|  0.00%|                device_str = '' if not p.is_cuda else ' (GPU {})'.format(p.get_device())
   759|         0|            0|            0|  0.00%|                parastr = '{} containing: [{} of size {}{}]'.format(
   760|         0|            0|            0|  0.00%|                    "Parameter" if isinstance(p, Parameter) else "Tensor",
   761|         0|            0|            0|  0.00%|                    torch.typename(p), size_str, device_str)
   762|         0|            0|            0|  0.00%|                child_lines.append('  (' + str(k) + '): ' + parastr)
   763|         0|            0|            0|  0.00%|            else:
   764|         0|            0|            0|  0.00%|                child_lines.append('  (' + str(k) + '): Object of type: ' + type(p).__name__)
   765|         0|            0|            0|  0.00%|        tmpstr = '\n'.join(child_lines)
   766|         0|            0|            0|  0.00%|        return tmpstr
   767|         0|            0|            0|  0.00%|
   768|         0|            0|            0|  0.00%|    def __call__(self, input):
   769|         0|            0|            0|  0.00%|        raise RuntimeError('ParameterDict should not be called.')
   770|         0|            0|            0|  0.00%|
   771|         0|            0|            0|  0.00%|    def __or__(self, other: 'ParameterDict') -> 'ParameterDict':
   772|         0|            0|            0|  0.00%|        copy = self.copy()
   773|         0|            0|            0|  0.00%|        copy.update(other)
   774|         0|            0|            0|  0.00%|        return copy
   775|         0|            0|            0|  0.00%|
   776|         0|            0|            0|  0.00%|    def __ror__(self, other: 'ParameterDict') -> 'ParameterDict':
   777|         0|            0|            0|  0.00%|        copy = other.copy()
   778|         0|            0|            0|  0.00%|        copy.update(self)
   779|         0|            0|            0|  0.00%|        return copy
   780|         0|            0|            0|  0.00%|
   781|         0|            0|            0|  0.00%|    def __ior__(self, other : 'ParameterDict') -> 'ParameterDict':
   782|         0|            0|            0|  0.00%|        self.update(other)
   783|         0|            0|            0|  0.00%|        return self
File: /apps/open_spiel/open_spiel/python/examples/ppo_utils.py
File duration: 0.367531s (0.35%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|from dataclasses import dataclass, field
     2|         0|            0|            0|  0.00%|from open_spiel.python import rl_environment
     3|         0|            0|            0|  0.00%|from open_spiel.python.examples.env_and_policy import EnvAndPolicy
     4|         0|            0|            0|  0.00%|from open_spiel.python.examples.ubc_utils import *
     5|         0|            0|            0|  0.00%|import numpy as np
     6|         0|            0|            0|  0.00%|import pandas as pd
     7|         0|            0|            0|  0.00%|from open_spiel.python.pytorch.ppo import PPO
     8|         0|            0|            0|  0.00%|import time
     9|         0|            0|            0|  0.00%|import logging
    10|         0|            0|            0|  0.00%|from open_spiel.python.algorithms.exploitability import nash_conv
    11|         0|            0|            0|  0.00%|from open_spiel.python.vector_env import SyncVectorEnv
    12|         0|            0|            0|  0.00%|from open_spiel.python.env_decorator import NormalizingEnvDecorator, AuctionStatTrackingDecorator, RewardShapingEnvDecorator, StateSavingEnvDecorator, PotentialShapingEnvDecorator
    13|         0|            0|            0|  0.00%|from typing import Callable, List
    14|         0|            0|            0|  0.00%|from dataclasses import asdict
    15|         0|            0|            0|  0.00%|
    16|         0|            0|            0|  0.00%|logger = logging.getLogger(__name__)
    17|         0|            0|            0|  0.00%|
    18|         0|            0|            0|  0.00%|PPO_DEFAULTS = {
    19|         0|            0|            0|  0.00%|  'num_envs': 8,
    20|         0|            0|            0|  0.00%|  'steps_per_batch': 128,
    21|         0|            0|            0|  0.00%|  'num_minibatches': 4,
    22|         0|            0|            0|  0.00%|  'update_epochs': 4,
    23|         0|            0|            0|  0.00%|  'learning_rate': 2.5e-4,
    24|         0|            0|            0|  0.00%|  'num_annealing_updates': None,
    25|         0|            0|            0|  0.00%|  'gae': True,
    26|         0|            0|            0|  0.00%|  'gamma': 0.99,
    27|         0|            0|            0|  0.00%|  'gae_lambda': 0.95,
    28|         0|            0|            0|  0.00%|  'normalize_advantages': True,
    29|         0|            0|            0|  0.00%|  'clip_coef': 0.2,
    30|         0|            0|            0|  0.00%|  'clip_vloss': True,
    31|         0|            0|            0|  0.00%|  'agent_fn': 'PPOAgent',
    32|         0|            0|            0|  0.00%|  'entropy_coef': 0.01,
    33|         0|            0|            0|  0.00%|  'value_coef': 0.5,
    34|         0|            0|            0|  0.00%|  'max_grad_norm': 0.5,
    35|         0|            0|            0|  0.00%|  'target_kl': None,
    36|         0|            0|            0|  0.00%|  'device': default_device(),
    37|         0|            0|            0|  0.00%|  'use_wandb': False,
    38|         0|            0|            0|  0.00%|}
    39|         0|            0|            0|  0.00%|
    40|         0|            0|            0|  0.00%|def read_ppo_config(config_name):
    41|         0|            0|            0|  0.00%|    config_file = config_path_from_config_name(config_name)
    42|         0|            0|            0|  0.00%|    logging.info(f"Reading config from {config_file}")
    43|         0|            0|            0|  0.00%|    with open(config_file, 'rb') as fh:
    44|         0|            0|            0|  0.00%|        config = yaml.load(fh, Loader=yaml.FullLoader)
    45|         0|            0|            0|  0.00%|
    46|         0|            0|            0|  0.00%|    config = {**PPO_DEFAULTS, **config}  # priority from right to left
    47|         0|            0|            0|  0.00%|
    48|         0|            0|            0|  0.00%|    return config
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|# def make_schedule_function(func_name, max_t, initial_frac = 0.5):
    51|         0|            0|            0|  0.00%|#   if func_name == 'linear':
    52|         0|            0|            0|  0.00%|#     return lambda t: initial_frac * (1- (t/max_t))
    53|         0|            0|            0|  0.00%|#   elif func_name == 'constant':
    54|         0|            0|            0|  0.00%|#     return lambda t: initial_frac
    55|         0|            0|            0|  0.00%|#   else:
    56|         0|            0|            0|  0.00%|#     raise NotImplementedError()
    57|         0|            0|            0|  0.00%|
    58|         0|            0|            0|  0.00%|# def make_reward_function(func_name):
    59|         0|            0|            0|  0.00%|#   if func_name.startswith('neg_'):
    60|         0|            0|            0|  0.00%|#     reward_function = make_reward_function(func_name[4:])
    61|         0|            0|            0|  0.00%|#     return lambda state: -reward_function(state)
    62|         0|            0|            0|  0.00%|#   else:
    63|         0|            0|            0|  0.00%|#     def generic_reward(state):
    64|         0|            0|            0|  0.00%|#       attr = getattr(state, func_name)
    65|         0|            0|            0|  0.00%|#       if isinstance(attr, Callable):
    66|         0|            0|            0|  0.00%|#         return attr()
    67|         0|            0|            0|  0.00%|#       else:
    68|         0|            0|            0|  0.00%|#         return attr
    69|         0|            0|            0|  0.00%|#     return generic_reward
    70|         0|            0|            0|  0.00%|
    71|         0|            0|            0|  0.00%|
    72|         0|            0|            0|  0.00%|def make_potential_function(func_name):
    73|         0|            0|            0|  0.00%|  if '_potential_normalized' not in func_name:
    74|         0|            0|            0|  0.00%|    func_name += '_potential_normalized'
    75|         0|            0|            0|  0.00%|  if func_name.startswith('neg_'):
    76|         0|            0|            0|  0.00%|    reward_function = make_potential_function(func_name[4:])
    77|         0|            0|            0|  0.00%|    return lambda state: -reward_function(state)
    78|         0|            0|            0|  0.00%|  else:
    79|         0|            0|            0|  0.00%|    def generic_reward(state):
    80|         0|            0|            0|  0.00%|      return getattr(state, func_name)
    81|         0|            0|            0|  0.00%|      # attr = getattr(state, func_name)
    82|         0|            0|            0|  0.00%|      # if isinstance(attr, Callable):
    83|         0|            0|            0|  0.00%|      #   return attr()
    84|         0|            0|            0|  0.00%|      # else:
    85|         0|            0|            0|  0.00%|      #   return attr
    86|         0|            0|            0|  0.00%|    return generic_reward
    87|         0|            0|            0|  0.00%|
    88|         0|            0|            0|  0.00%|@dataclass
    89|         0|            0|            0|  0.00%|class EnvParams:
    90|         0|            0|            0|  0.00%|
    91|         0|            0|            0|  0.00%|  num_envs: int = 8
    92|         0|            0|            0|  0.00%|  normalize_rewards: bool = True
    93|         0|            0|            0|  0.00%|  seed: int = 1234
    94|         0|            0|            0|  0.00%|  track_stats: bool = False
    95|         0|            0|            0|  0.00%|  sync: bool = True
    96|         0|            0|            0|  0.00%|  history_prefix: List = field(default_factory=lambda: [])
    97|         0|            0|            0|  0.00%|  num_states_to_save: int = 0
    98|         0|            0|            0|  0.00%|
    99|         0|            0|            0|  0.00%|  # Stuff related to reward shaping
   100|         0|            0|            0|  0.00%|  # reward_function: str = None
   101|         0|            0|            0|  0.00%|  # schedule_function: str = None
   102|         0|            0|            0|  0.00%|  # initial_frac: float = 0.5
   103|         0|            0|            0|  0.00%|  # total_timesteps: int = None
   104|         0|            0|            0|  0.00%|
   105|         0|            0|            0|  0.00%|  potential_function: str =  None
   106|         0|            0|            0|  0.00%|
   107|         0|            0|            0|  0.00%|  use_wandb: bool = False
   108|         0|            0|            0|  0.00%|  clear_on_report: bool = False
   109|         0|            0|            0|  0.00%|  observer_params: dict = None
   110|         0|            0|            0|  0.00%|
   111|         0|            0|            0|  0.00%|  def make_env(self, game):
   112|         0|            0|            0|  0.00%|    if not self.sync and self.num_envs > 1:
   113|         0|            0|            0|  0.00%|      raise ValueError("Sync must be True if num_envs > 1")
   114|         0|            0|            0|  0.00%|
   115|         0|            0|            0|  0.00%|    def gen_env(seed, env_id=0):
   116|         0|            0|            0|  0.00%|        # Only track env_id == 0 so we don't have multi-valued metrics
   117|         0|            0|            0|  0.00%|
   118|         0|            0|            0|  0.00%|        env = rl_environment.Environment(game, chance_event_sampler=UBCChanceEventSampler(seed=seed), use_observer_api=True, history_prefix=self.history_prefix, observer_params=self.observer_params)
   119|         0|            0|            0|  0.00%|        if self.num_states_to_save:
   120|         0|            0|            0|  0.00%|          env = StateSavingEnvDecorator(env, self.num_states_to_save)
   121|         0|            0|            0|  0.00%|        if self.track_stats:
   122|         0|            0|            0|  0.00%|          env = AuctionStatTrackingDecorator(env, self.clear_on_report)
   123|         0|            0|            0|  0.00%|        if self.normalize_rewards:
   124|         0|            0|            0|  0.00%|          env = NormalizingEnvDecorator(env, reward_normalizer=torch.tensor(np.maximum(game.upper_bounds, game.lower_bounds)))
   125|         0|            0|            0|  0.00%|        if self.potential_function:
   126|         0|            0|            0|  0.00%|          potential_function = make_potential_function(self.potential_function)
   127|         0|            0|            0|  0.00%|          logger.info("Shaping potential with function: {}".format(self.potential_function))
   128|         0|            0|            0|  0.00%|          env = PotentialShapingEnvDecorator(env, potential_function, game.num_players())
   129|         0|            0|            0|  0.00%|        return env
   130|         0|            0|            0|  0.00%|
   131|         0|            0|            0|  0.00%|    if self.sync:
   132|         0|            0|            0|  0.00%|      env = SyncVectorEnv(
   133|         0|            0|            0|  0.00%|          [gen_env(self.seed + i, env_id=i) for i in range(self.num_envs)]
   134|         0|            0|            0|  0.00%|      )
   135|         0|            0|            0|  0.00%|    else:
   136|         0|            0|            0|  0.00%|      env = gen_env(self.seed)
   137|         0|            0|            0|  0.00%|    return env
   138|         0|            0|            0|  0.00%|
   139|         0|            0|            0|  0.00%|  @staticmethod
   140|         0|            0|            0|  0.00%|  def from_config(config):
   141|         0|            0|            0|  0.00%|    ## Config is a dict of params you want to override
   142|         0|            0|            0|  0.00%|    defaults = asdict(EnvParams())
   143|         0|            0|            0|  0.00%|    env_config = {k:v for k,v in config.items() if k in defaults}
   144|         0|            0|            0|  0.00%|    return EnvParams(**{**defaults, **env_config})
   145|         0|            0|            0|  0.00%|
   146|         0|            0|            0|  0.00%|class EpisodeTimer:
   147|         0|            0|            0|  0.00%|
   148|         0|            0|            0|  0.00%|  def __init__(self, frequency, early_frequency=None, fixed_episodes=None, eval_zero=False):
   149|         0|            0|            0|  0.00%|    if fixed_episodes is None:
   150|         0|            0|            0|  0.00%|      fixed_episodes = []
   151|         0|            0|            0|  0.00%|    self.fixed_episodes = fixed_episodes
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|    self.frequency = frequency
   154|         0|            0|            0|  0.00%|    self.early_frequency = early_frequency
   155|         0|            0|            0|  0.00%|    self.cur_frequency = self.frequency if self.early_frequency is None else self.early_frequency
   156|         0|            0|            0|  0.00%|    self.eval_zero = eval_zero
   157|         0|            0|            0|  0.00%|    self.last_known_ep = -1
   158|         0|            0|            0|  0.00%|
   159|         0|            0|            0|  0.00%|  def should_trigger(self, ep):
   160|         0|            0|            0|  0.00%|    if ep > self.frequency: # Move on from early frequency if needed
   161|         0|            0|            0|  0.00%|      self.cur_frequency = self.frequency
   162|         0|            0|            0|  0.00%|
   163|         0|            0|            0|  0.00%|    while ep > self.last_known_ep:
   164|         0|            0|            0|  0.00%|      self.last_known_ep += 1
   165|         0|            0|            0|  0.00%|      if self._should_trigger(self.last_known_ep):
   166|         0|            0|            0|  0.00%|        # Note in the reports you might see unround numbers because of how we do it (e.g., logs for episode 10_007)
   167|         0|            0|            0|  0.00%|        self.last_known_ep = ep
   168|         0|            0|            0|  0.00%|        return True
   169|         0|            0|            0|  0.00%|
   170|         0|            0|            0|  0.00%|    return False
   171|         0|            0|            0|  0.00%|
   172|         0|            0|            0|  0.00%|  def _should_trigger(self, ep):
   173|         0|            0|            0|  0.00%|    return (ep > 0 and ep % self.cur_frequency == 0) or \
   174|         0|            0|            0|  0.00%|      ep in self.fixed_episodes or\
   175|         0|            0|            0|  0.00%|      ep == 0 and self.eval_zero
   176|         0|            0|            0|  0.00%|
   177|         0|            0|            0|  0.00%|
   178|         0|            0|            0|  0.00%|def make_ppo_kwargs_from_config(config):
   179|         0|            0|            0|  0.00%|  ppo_kwargs = {**PPO_DEFAULTS, **config}  # priority from right to left
   180|         0|            0|            0|  0.00%|  ppo_kwargs = {k:v for k,v in ppo_kwargs.items() if k in PPO_DEFAULTS.keys()}
   181|         0|            0|            0|  0.00%|  return ppo_kwargs
   182|         0|            0|            0|  0.00%|
   183|         0|            0|            0|  0.00%|def make_ppo_agent(player_id, config, game):
   184|         0|            0|            0|  0.00%|    num_players, num_actions, num_products = game.num_players(), game.num_distinct_actions(), game.auction_params.num_products
   185|         0|            0|            0|  0.00%|
   186|         0|            0|            0|  0.00%|    state_size = rl_environment.Environment(game).observation_spec()["info_state"]
   187|         0|            0|            0|  0.00%|
   188|         0|            0|            0|  0.00%|    # TODO: Do you want to parameterize NN size/architecture?
   189|         0|            0|            0|  0.00%|    ppo_kwargs = make_ppo_kwargs_from_config(config)
   190|         0|            0|            0|  0.00%|
   191|         0|            0|            0|  0.00%|    return PPO(
   192|         0|            0|            0|  0.00%|        input_shape=state_size,
   193|         0|            0|            0|  0.00%|        num_actions=num_actions,
   194|         0|            0|            0|  0.00%|        num_players=num_players,
   195|         0|            0|            0|  0.00%|        player_id=player_id,
   196|         0|            0|            0|  0.00%|        **ppo_kwargs
   197|         0|            0|            0|  0.00%|    )
   198|         0|            0|            0|  0.00%|
   199|         0|            0|            0|  0.00%|def make_env_and_policy(game, config, env_params=None):
   200|         0|            0|            0|  0.00%|  if env_params is None:
   201|         0|            0|            0|  0.00%|    env_params = EnvParams(num_envs=config['num_envs'], seed=config['seed'])
   202|         0|            0|            0|  0.00%|  env = env_params.make_env(game)
   203|         0|            0|            0|  0.00%|  agents = [make_ppo_agent(player_id, config, game) for player_id in range(game.num_players())]
   204|         0|            0|            0|  0.00%|  return EnvAndPolicy(env=env, agents=agents, game=game)
   205|         0|            0|            0|  0.00%|
   206|         0|            0|            0|  0.00%|class PPOTrainingLoop:
   207|         0|            0|            0|  0.00%|
   208|         1|  4.05312e-06|  4.05312e-06|  0.00%|  def __init__(self, game, env, agents, total_timesteps, players_to_train=None, report_timer=None, eval_timer=None, policy_diff_threshold=1e-3, max_policy_diff_count=5, use_wandb=False):
   209|         1|   3.8147e-06|   3.8147e-06|  0.00%|    self.game = game
   210|         1|  4.52995e-06|  4.52995e-06|  0.00%|    self.env = env
   211|         1|   2.6226e-06|   2.6226e-06|  0.00%|    self.agents = agents
   212|         1|  3.33786e-06|  3.33786e-06|  0.00%|    self.total_timesteps = total_timesteps
   213|         1|   2.5034e-05|   2.5034e-05|  0.00%|    self.players_to_train = players_to_train if players_to_train is not None else list(range(game.num_players()))
   214|         1|  8.10623e-06|  8.10623e-06|  0.00%|    self.fixed_agents = set(range(game.num_players())) - set(self.players_to_train)
   215|         1|  3.57628e-06|  3.57628e-06|  0.00%|    self.report_timer = report_timer
   216|         1|  3.33786e-06|  3.33786e-06|  0.00%|    self.report_hooks = []
   217|         1|  3.09944e-06|  3.09944e-06|  0.00%|    self.eval_timer = eval_timer
   218|         1|  3.57628e-06|  3.57628e-06|  0.00%|    self.eval_hooks = []
   219|         1|  3.33786e-06|  3.33786e-06|  0.00%|    self.policy_diff_threshold = policy_diff_threshold
   220|         1|  3.09944e-06|  3.09944e-06|  0.00%|    self.max_policy_diff_count = max_policy_diff_count
   221|         1|  3.09944e-06|  3.09944e-06|  0.00%|    self.policy_diff_count = 0
   222|         1|  2.86102e-06|  2.86102e-06|  0.00%|    self.use_wandb = use_wandb
   223|         0|            0|            0|  0.00%|
   224|         1|  3.09944e-06|  3.09944e-06|  0.00%|  def add_report_hook(self, hook):
   225|         1|  3.09944e-06|  3.09944e-06|  0.00%|    self.report_hooks.append(hook)
   226|         0|            0|            0|  0.00%|
   227|         1|  3.09944e-06|  3.09944e-06|  0.00%|  def add_eval_hook(self, hook):
   228|         1|  3.57628e-06|  3.57628e-06|  0.00%|    self.eval_hooks.append(hook)
   229|         0|            0|            0|  0.00%|
   230|         1|  8.10623e-06|  8.10623e-06|  0.00%|  def training_loop(self):
   231|         1|  7.62939e-06|  7.62939e-06|  0.00%|    num_steps = self.agents[self.players_to_train[0]].steps_per_batch # Assuming it's all the same across agents...
   232|         1|   1.5974e-05|   1.5974e-05|  0.00%|    batch_size = int(len(self.env) * num_steps)
(call)|         1|  1.23978e-05|  1.23978e-05|  0.00%|# /apps/open_spiel/open_spiel/python/vector_env.py:10 __len__
   233|         1|  6.19888e-06|  6.19888e-06|  0.00%|    num_updates = self.total_timesteps // batch_size
   234|         0|            0|            0|  0.00%|
   235|         1|  1.54972e-05|  1.54972e-05|  0.00%|    logging.info(f"Training for {num_updates} updates")
(call)|         1|  4.57764e-05|  4.57764e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/logging/__init__.py:2062 info
   236|         1|  4.12464e-05|  4.12464e-05|  0.00%|    logging.info(f"Fixed agents are {self.fixed_agents}. Learning agents are {self.players_to_train}")
(call)|         1|  2.47955e-05|  2.47955e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/logging/__init__.py:2062 info
   237|         1|  2.31266e-05|  2.31266e-05|  0.00%|    time_step = self.env.reset()
(call)|         1|    0.0282204|    0.0282204|  0.03%|# /apps/open_spiel/open_spiel/python/vector_env.py:37 reset
   238|         0|            0|            0|  0.00%|
   239|        10|  4.31538e-05|  4.31538e-06|  0.00%|    for update in range(1, num_updates + 1):
   240|         9|  5.22137e-05|  5.80152e-06|  0.00%|      if self.report_timer is not None and self.report_timer.should_trigger(update):
   241|         0|            0|            0|  0.00%|        for hook in self.report_hooks:
   242|         0|            0|            0|  0.00%|          hook(update, update * batch_size)
   243|         9|   3.6478e-05|  4.05312e-06|  0.00%|      if self.eval_timer is not None and self.eval_timer.should_trigger(update):
   244|         0|            0|            0|  0.00%|        for hook in self.eval_hooks:
   245|         0|            0|            0|  0.00%|          hook(update, update * batch_size)
   246|         0|            0|            0|  0.00%|
   247|      1161|    0.0041728|  3.59414e-06|  0.00%|      for _ in range(num_steps):
   248|      3456|     0.017242|  4.98899e-06|  0.02%|          for player_id, agent in enumerate(self.agents):
   249|      2304|    0.0635369|  2.75768e-05|  0.06%|              agent_output = agent.step(time_step, is_evaluation=player_id in self.fixed_agents)
(call)|      2304|      5.90706|   0.00256383|  5.66%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:215 step
   250|      2304|     0.179135|  7.77494e-05|  0.17%|              time_step, reward, done, unreset_time_steps = self.env.step(agent_output, reset_if_done=True)
(call)|      2304|      94.0909|     0.040838| 90.15%|# /apps/open_spiel/open_spiel/python/vector_env.py:20 step
   251|         0|            0|            0|  0.00%|
   252|      3456|    0.0155416|  4.49698e-06|  0.01%|          for player_id, agent in enumerate(self.agents):
   253|      2304|   0.00890303|  3.86416e-06|  0.01%|            if player_id in self.players_to_train:
   254|     25344|    0.0757747|  2.98985e-06|  0.07%|              agent.post_step([r[player_id] for r in reward], done)
(call)|      2304|    0.0399079|  1.73212e-05|  0.04%|# /apps/open_spiel/open_spiel/python/examples/ppo_utils.py:254 <listcomp>
(call)|      2304|     0.364216|   0.00015808|  0.35%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:254 post_step
   255|         0|            0|            0|  0.00%|
   256|         9|  3.02792e-05|  3.36435e-06|  0.00%|      policy_changed = False
   257|        27|   0.00013423|  4.97147e-06|  0.00%|      for player_id, agent in enumerate(self.agents):
   258|        18|  7.65324e-05|   4.2518e-06|  0.00%|        if player_id in self.players_to_train:
   259|        18|   0.00154209|  8.56717e-05|  0.00%|          agent.learn(time_step)
(call)|        18|      3.61342|     0.200746|  3.46%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:262 learn
   260|        18|   0.00026083|  1.44906e-05|  0.00%|        if agent.get_max_policy_diff() >= self.policy_diff_threshold:
(call)|        18|  9.94205e-05|  5.52336e-06|  0.00%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:414 get_max_policy_diff
   261|        18|  9.05991e-05|  5.03328e-06|  0.00%|          policy_changed = True
   262|         0|            0|            0|  0.00%|
   263|         0|            0|            0|  0.00%|      # Commit wandb
   264|         9|  4.05312e-05|  4.50346e-06|  0.00%|      if self.use_wandb:
   265|         0|            0|            0|  0.00%|        # TODO: Make this way less specific to our game/abstract it more
   266|         0|            0|            0|  0.00%|        import wandb
   267|         0|            0|            0|  0.00%|        from open_spiel.python.env_decorator import AuctionStatTrackingDecorator
   268|         0|            0|            0|  0.00%|        stats_dict = AuctionStatTrackingDecorator.merge_stats(self.env)
   269|         0|            0|            0|  0.00%|        log_stats_dict = dict()
   270|         0|            0|            0|  0.00%|        prefix = 'metrics'
   271|         0|            0|            0|  0.00%|        if 'revenues' in stats_dict:
   272|         0|            0|            0|  0.00%|            log_stats_dict[f'{prefix}/mean_revenue'] = np.mean(stats_dict['revenues'])
   273|         0|            0|            0|  0.00%|        if 'auction_lengths' in stats_dict:
   274|         0|            0|            0|  0.00%|            log_stats_dict[f'{prefix}/mean_auction_length'] = np.mean(stats_dict['auction_lengths'])
   275|         0|            0|            0|  0.00%|        if 'welfares' in stats_dict:
   276|         0|            0|            0|  0.00%|            log_stats_dict[f'{prefix}/mean_welfare'] = np.mean(stats_dict['welfares'])
   277|         0|            0|            0|  0.00%|
   278|         0|            0|            0|  0.00%|        for player_id in range(len(self.agents)):
   279|         0|            0|            0|  0.00%|          if 'raw_rewards' in stats_dict:
   280|         0|            0|            0|  0.00%|            log_stats_dict[f'{prefix}/player_{player_id}_mean_reward'] = np.mean(stats_dict['raw_rewards'][player_id])
   281|         0|            0|            0|  0.00%|          if 'payments' in stats_dict:
   282|         0|            0|            0|  0.00%|            log_stats_dict[f'{prefix}/player_{player_id}_payment'] = np.mean(stats_dict['payments'][player_id])
   283|         0|            0|            0|  0.00%|            # f'player_{player_id}_allocation': self.allocations[player_id][-1], # TODO? Probably needs to be per product
   284|         0|            0|            0|  0.00%|
   285|         0|            0|            0|  0.00%|        # TODO:
   286|         0|            0|            0|  0.00%|        # for player_id in range(self.n_players):
   287|         0|            0|            0|  0.00%|        #     metrics[f'metrics/player_{player_id}_unshaped_reward'] = time_step.rewards[player_id]
   288|         0|            0|            0|  0.00%|        #     metrics[f'metrics/player_{player_id}_shaped_reward'] = new_rewards[player_id] - time_step.rewards[player_id]
   289|         0|            0|            0|  0.00%|
   290|         0|            0|            0|  0.00%|        # This should be the ONLY commit=True. Step sizes will now be in terms of updates
   291|         0|            0|            0|  0.00%|        wandb.log(log_stats_dict, commit=True)
   292|         0|            0|            0|  0.00%|
   293|         9|  3.74317e-05|  4.15908e-06|  0.00%|      if not policy_changed:
   294|         0|            0|            0|  0.00%|        self.policy_diff_count += 1
   295|         0|            0|            0|  0.00%|        if self.policy_diff_count >= self.max_policy_diff_count:
   296|         0|            0|            0|  0.00%|          logging.info("Policy has not changed for {} updates. Stopping training".format(self.max_policy_diff_count))
   297|         0|            0|            0|  0.00%|          break
   298|         0|            0|            0|  0.00%|      else:
   299|         9|  3.45707e-05|  3.84119e-06|  0.00%|        self.policy_diff_count = 0
   300|         0|            0|            0|  0.00%|
   301|         0|            0|            0|  0.00%|
   302|         1|  1.83582e-05|  1.83582e-05|  0.00%|    logging.info(f"Terminating PPO training after {update} updates")
(call)|         1|  4.07696e-05|  4.07696e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/logging/__init__.py:2062 info
   303|         0|            0|            0|  0.00%|
   304|         0|            0|            0|  0.00%|    # Lastly, call all hooks
   305|         2|  1.45435e-05|  7.27177e-06|  0.00%|    for hook in self.report_hooks:
   306|         1|  1.45435e-05|  1.45435e-05|  0.00%|      hook(update, update * num_steps)
(call)|         1|  4.00543e-05|  4.00543e-05|  0.00%|# /apps/open_spiel/open_spiel/python/examples/ppo_utils.py:349 report_hook
   307|         2|  9.53674e-06|  4.76837e-06|  0.00%|    for hook in self.eval_hooks:
   308|         1|  2.55108e-05|  2.55108e-05|  0.00%|      hook(update, update * num_steps)
(call)|         1|   0.00202775|   0.00202775|  0.00%|# /apps/open_spiel/open_spiel/python/examples/ppo_utils.py:342 eval_hook
   309|         0|            0|            0|  0.00%|
   310|         0|            0|            0|  0.00%|
   311|         1|  4.76837e-06|  4.76837e-06|  0.00%|def ppo_checkpoint(env_and_model, step, alg_start_time, compute_nash_conv=False, update=None):
   312|         1|  4.76837e-06|  4.76837e-06|  0.00%|    msg = f"EVALUATION AFTER {step} steps"
   313|         1|  4.05312e-06|  4.05312e-06|  0.00%|    if update is not None:
   314|         1|  4.52995e-06|  4.52995e-06|  0.00%|      msg += f" (update {update})"
   315|         1|  9.77516e-06|  9.77516e-06|  0.00%|    logger.info(msg)
(call)|         1|  1.74046e-05|  1.74046e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/logging/__init__.py:1424 info
   316|         0|            0|            0|  0.00%|
   317|         1|   2.5034e-05|   2.5034e-05|  0.00%|    policy = env_and_model.make_policy()
(call)|         1|  0.000143766|  0.000143766|  0.00%|# /apps/open_spiel/open_spiel/python/examples/env_and_policy.py:13 make_policy
   318|         1|  3.33786e-06|  3.33786e-06|  0.00%|    if compute_nash_conv:
   319|         0|            0|            0|  0.00%|        logging.info('Computing nash conv...')
   320|         0|            0|            0|  0.00%|        n_conv = nash_conv(env_and_model.game, policy, use_cpp_br=True)
   321|         0|            0|            0|  0.00%|        logging.info(f"{n_conv}")
   322|         0|            0|            0|  0.00%|        logging.info("_____________________________________________")
   323|         0|            0|            0|  0.00%|    else:
   324|         1|  3.09944e-06|  3.09944e-06|  0.00%|        n_conv = None
   325|         0|            0|            0|  0.00%|
   326|         1|  3.33786e-06|  3.33786e-06|  0.00%|    checkpoint = {
   327|         1|  4.05312e-06|  4.05312e-06|  0.00%|        'walltime': time.time() - alg_start_time,
   328|         1|  1.19209e-05|  1.19209e-05|  0.00%|        'policy': policy.save(),
(call)|         1|   0.00175691|   0.00175691|  0.00%|# /apps/open_spiel/open_spiel/python/rl_agent_policy.py:82 save
   329|         1|  3.57628e-06|  3.57628e-06|  0.00%|        'nash_conv_history': [],
   330|         1|  2.86102e-06|  2.86102e-06|  0.00%|        'episode': step,
   331|         0|            0|            0|  0.00%|    }
   332|         1|  3.09944e-06|  3.09944e-06|  0.00%|    return checkpoint
   333|         0|            0|            0|  0.00%|
   334|         1|  7.62939e-06|  7.62939e-06|  0.00%|def run_ppo(env_and_policy, total_steps, result_saver=None, seed=1234, compute_nash_conv=False, dispatcher=None, report_timer=None, eval_timer=None, use_wandb=False):
   335|         0|            0|            0|  0.00%|  # This may have already been done, but do it again. Required to do it outside to ensure that networks get initilized the same way, which usually happens elsewhere
   336|         1|  1.66893e-05|  1.66893e-05|  0.00%|  fix_seeds(seed)
(call)|         1|  0.000353813|  0.000353813|  0.00%|# /apps/open_spiel/open_spiel/python/examples/ubc_utils.py:43 fix_seeds
   337|         1|  7.15256e-06|  7.15256e-06|  0.00%|  game, env, agents = env_and_policy.game, env_and_policy.env, env_and_policy.agents
   338|         0|            0|            0|  0.00%|
   339|         1|  5.00679e-06|  5.00679e-06|  0.00%|  alg_start_time = time.time()
   340|         1|  1.54972e-05|  1.54972e-05|  0.00%|  trainer = PPOTrainingLoop(game, env, agents, total_steps, report_timer=report_timer, eval_timer=eval_timer, use_wandb=use_wandb)
(call)|         1|   7.7486e-05|   7.7486e-05|  0.00%|# /apps/open_spiel/open_spiel/python/examples/ppo_utils.py:208 __init__
   341|         0|            0|            0|  0.00%|
   342|         2|  8.34465e-06|  4.17233e-06|  0.00%|  def eval_hook(update, total_steps):
   343|         1|  1.35899e-05|  1.35899e-05|  0.00%|    checkpoint = ppo_checkpoint(env_and_policy, total_steps, alg_start_time, compute_nash_conv=compute_nash_conv, update=update)
(call)|         1|   0.00200629|   0.00200629|  0.00%|# /apps/open_spiel/open_spiel/python/examples/ppo_utils.py:311 ppo_checkpoint
   344|         1|  3.57628e-06|  3.57628e-06|  0.00%|    if result_saver is not None:
   345|         0|            0|            0|  0.00%|      checkpoint_name = result_saver.save(checkpoint)
   346|         0|            0|            0|  0.00%|      if dispatcher is not None:
   347|         0|            0|            0|  0.00%|        dispatcher.dispatch(checkpoint_name)
   348|         0|            0|            0|  0.00%|
   349|         2|  8.10623e-06|  4.05312e-06|  0.00%|  def report_hook(update, total_steps):
   350|         1|  9.77516e-06|  9.77516e-06|  0.00%|    logging.info(f"Update {update}")
(call)|         1|   2.6226e-05|   2.6226e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/logging/__init__.py:2062 info
   351|         0|            0|            0|  0.00%|
   352|         1|  0.000190973|  0.000190973|  0.00%|  trainer.add_report_hook(report_hook)
(call)|         1|  6.19888e-06|  6.19888e-06|  0.00%|# /apps/open_spiel/open_spiel/python/examples/ppo_utils.py:224 add_report_hook
   353|         1|  1.26362e-05|  1.26362e-05|  0.00%|  trainer.add_eval_hook(eval_hook)
(call)|         1|  6.67572e-06|  6.67572e-06|  0.00%|# /apps/open_spiel/open_spiel/python/examples/ppo_utils.py:227 add_eval_hook
   354|         1|   0.00013566|   0.00013566|  0.00%|  trainer.training_loop()
(call)|         1|      104.373|      104.373|100.00%|# /apps/open_spiel/open_spiel/python/examples/ppo_utils.py:230 training_loop
   355|         0|            0|            0|  0.00%|
   356|         1|  2.31266e-05|  2.31266e-05|  0.00%|  logging.info(f"Walltime: {pretty_time(time.time() - alg_start_time)}")
(call)|         1|   0.00131726|   0.00131726|  0.00%|# /apps/open_spiel/open_spiel/python/examples/ubc_utils.py:116 pretty_time
(call)|         1|  3.14713e-05|  3.14713e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/logging/__init__.py:2062 info
   357|         1|  9.53674e-06|  9.53674e-06|  0.00%|  logging.info('All done. Goodbye!')
(call)|         1|  2.19345e-05|  2.19345e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/logging/__init__.py:2062 info
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/__init__.py
File duration: 0.335865s (0.32%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|"""
     2|         0|            0|            0|  0.00%|``torch.autograd`` provides classes and functions implementing automatic
     3|         0|            0|            0|  0.00%|differentiation of arbitrary scalar valued functions. It requires minimal
     4|         0|            0|            0|  0.00%|changes to the existing code - you only need to declare :class:`Tensor` s
     5|         0|            0|            0|  0.00%|for which gradients should be computed with the ``requires_grad=True`` keyword.
     6|         0|            0|            0|  0.00%|As of now, we only support autograd for floating point :class:`Tensor` types (
     7|         0|            0|            0|  0.00%|half, float, double and bfloat16) and complex :class:`Tensor` types (cfloat, cdouble).
     8|         0|            0|            0|  0.00%|"""
     9|         0|            0|            0|  0.00%|import torch
    10|         0|            0|            0|  0.00%|import warnings
    11|         0|            0|            0|  0.00%|
    12|         0|            0|            0|  0.00%|from torch.types import _TensorOrTensors
    13|         0|            0|            0|  0.00%|from typing import Any, Callable, List, Optional, Sequence, Tuple, Union, cast
    14|         0|            0|            0|  0.00%|
    15|         0|            0|            0|  0.00%|from .variable import Variable
    16|         0|            0|            0|  0.00%|from .function import Function, NestedIOFunction
    17|         0|            0|            0|  0.00%|from .gradcheck import gradcheck, gradgradcheck
    18|         0|            0|            0|  0.00%|from .grad_mode import no_grad, enable_grad, set_grad_enabled, inference_mode
    19|         0|            0|            0|  0.00%|from .anomaly_mode import detect_anomaly, set_detect_anomaly
    20|         0|            0|            0|  0.00%|from ..overrides import has_torch_function, handle_torch_function, is_tensor_like
    21|         0|            0|            0|  0.00%|from . import functional
    22|         0|            0|            0|  0.00%|from . import forward_ad
    23|         0|            0|            0|  0.00%|from . import graph
    24|         0|            0|            0|  0.00%|from .. import _vmap_internals
    25|         0|            0|            0|  0.00%|
    26|         0|            0|            0|  0.00%|__all__ = ['Variable', 'Function', 'backward', 'grad_mode']
    27|         0|            0|            0|  0.00%|
    28|         0|            0|            0|  0.00%|_OptionalTensor = Optional[torch.Tensor]
    29|         0|            0|            0|  0.00%|
    30|       288|  0.000726938|  2.52409e-06|  0.00%|def _make_grads(outputs: Sequence[torch.Tensor], grads: Sequence[_OptionalTensor],
    31|         0|            0|            0|  0.00%|                is_grads_batched: bool) -> Tuple[_OptionalTensor, ...]:
    32|       288|  0.000706434|   2.4529e-06|  0.00%|    new_grads: List[_OptionalTensor] = []
    33|       576|    0.0017581|  3.05225e-06|  0.00%|    for out, grad in zip(outputs, grads):
    34|       288|  0.000767708|  2.66565e-06|  0.00%|        if isinstance(grad, torch.Tensor):
    35|         0|            0|            0|  0.00%|            grad_shape = grad.shape if not is_grads_batched else grad.shape[1:]
    36|         0|            0|            0|  0.00%|            if not out.shape == grad_shape:
    37|         0|            0|            0|  0.00%|                if is_grads_batched:
    38|         0|            0|            0|  0.00%|                    raise RuntimeError("If `is_grads_batched=True`, we interpret the first "
    39|         0|            0|            0|  0.00%|                                       "dimension of each grad_output as the batch dimension. "
    40|         0|            0|            0|  0.00%|                                       "The sizes of the remaining dimensions are expected to match "
    41|         0|            0|            0|  0.00%|                                       "the shape of corresponding output, but a mismatch "
    42|         0|            0|            0|  0.00%|                                       "was detected: grad_output["
    43|         0|            0|            0|  0.00%|                                       + str(grads.index(grad)) + "] has a shape of "
    44|         0|            0|            0|  0.00%|                                       + str(grad.shape) + " and output["
    45|         0|            0|            0|  0.00%|                                       + str(outputs.index(out)) + "] has a shape of "
    46|         0|            0|            0|  0.00%|                                       + str(out.shape) + ". "
    47|         0|            0|            0|  0.00%|                                       "If you only want some tensors in `grad_output` to be considered "
    48|         0|            0|            0|  0.00%|                                       "batched, consider using vmap.")
    49|         0|            0|            0|  0.00%|                else:
    50|         0|            0|            0|  0.00%|                    raise RuntimeError("Mismatch in shape: grad_output["
    51|         0|            0|            0|  0.00%|                                       + str(grads.index(grad)) + "] has a shape of "
    52|         0|            0|            0|  0.00%|                                       + str(grad.shape) + " and output["
    53|         0|            0|            0|  0.00%|                                       + str(outputs.index(out)) + "] has a shape of "
    54|         0|            0|            0|  0.00%|                                       + str(out.shape) + ".")
    55|         0|            0|            0|  0.00%|            if out.dtype.is_complex != grad.dtype.is_complex:
    56|         0|            0|            0|  0.00%|                raise RuntimeError("For complex Tensors, both grad_output and output"
    57|         0|            0|            0|  0.00%|                                   " are required to have the same dtype."
    58|         0|            0|            0|  0.00%|                                   " Mismatch in dtype: grad_output["
    59|         0|            0|            0|  0.00%|                                   + str(grads.index(grad)) + "] has a dtype of "
    60|         0|            0|            0|  0.00%|                                   + str(grad.dtype) + " and output["
    61|         0|            0|            0|  0.00%|                                   + str(outputs.index(out)) + "] has a dtype of "
    62|         0|            0|            0|  0.00%|                                   + str(out.dtype) + ".")
    63|         0|            0|            0|  0.00%|            new_grads.append(grad)
    64|       288|  0.000620365|  2.15405e-06|  0.00%|        elif grad is None:
    65|       288|  0.000766277|  2.66069e-06|  0.00%|            if out.requires_grad:
    66|       288|  0.000780106|   2.7087e-06|  0.00%|                if out.numel() != 1:
    67|         0|            0|            0|  0.00%|                    raise RuntimeError("grad can be implicitly created only for scalar outputs")
    68|       288|   0.00310016|  1.07644e-05|  0.00%|                new_grads.append(torch.ones_like(out, memory_format=torch.preserve_format))
    69|         0|            0|            0|  0.00%|            else:
    70|         0|            0|            0|  0.00%|                new_grads.append(None)
    71|         0|            0|            0|  0.00%|        else:
    72|         0|            0|            0|  0.00%|            raise TypeError("gradients can be either Tensors or None, but got " +
    73|         0|            0|            0|  0.00%|                            type(grad).__name__)
    74|       288|  0.000679731|  2.36018e-06|  0.00%|    return tuple(new_grads)
    75|         0|            0|            0|  0.00%|
    76|         0|            0|            0|  0.00%|
    77|       288|  0.000477076|  1.65651e-06|  0.00%|def _tensor_or_tensors_to_tuple(tensors: Optional[_TensorOrTensors], length: int) -> Tuple[_OptionalTensor, ...]:
    78|       288|  0.000494957|   1.7186e-06|  0.00%|    if tensors is None:
    79|       288|  0.000535727|  1.86016e-06|  0.00%|        return (None, ) * length
    80|         0|            0|            0|  0.00%|    if isinstance(tensors, torch.Tensor):
    81|         0|            0|            0|  0.00%|        return (tensors, )
    82|         0|            0|            0|  0.00%|    return tuple(tensors)
    83|         0|            0|            0|  0.00%|
    84|         0|            0|            0|  0.00%|
    85|       288|  0.000747442|  2.59529e-06|  0.00%|def backward(
    86|         0|            0|            0|  0.00%|    tensors: _TensorOrTensors,
    87|         0|            0|            0|  0.00%|    grad_tensors: Optional[_TensorOrTensors] = None,
    88|         0|            0|            0|  0.00%|    retain_graph: Optional[bool] = None,
    89|         0|            0|            0|  0.00%|    create_graph: bool = False,
    90|         0|            0|            0|  0.00%|    grad_variables: Optional[_TensorOrTensors] = None,
    91|         0|            0|            0|  0.00%|    inputs: Optional[_TensorOrTensors] = None,
    92|         0|            0|            0|  0.00%|) -> None:
    93|         0|            0|            0|  0.00%|    r"""Computes the sum of gradients of given tensors with respect to graph
    94|         0|            0|            0|  0.00%|    leaves.
    95|         0|            0|            0|  0.00%|
    96|         0|            0|            0|  0.00%|    The graph is differentiated using the chain rule. If any of ``tensors``
    97|         0|            0|            0|  0.00%|    are non-scalar (i.e. their data has more than one element) and require
    98|         0|            0|            0|  0.00%|    gradient, then the Jacobian-vector product would be computed, in this
    99|         0|            0|            0|  0.00%|    case the function additionally requires specifying ``grad_tensors``.
   100|         0|            0|            0|  0.00%|    It should be a sequence of matching length, that contains the "vector"
   101|         0|            0|            0|  0.00%|    in the Jacobian-vector product, usually the gradient of the differentiated
   102|         0|            0|            0|  0.00%|    function w.r.t. corresponding tensors (``None`` is an acceptable value for
   103|         0|            0|            0|  0.00%|    all tensors that don't need gradient tensors).
   104|         0|            0|            0|  0.00%|
   105|         0|            0|            0|  0.00%|    This function accumulates gradients in the leaves - you might need to zero
   106|         0|            0|            0|  0.00%|    ``.grad`` attributes or set them to ``None`` before calling it.
   107|         0|            0|            0|  0.00%|    See :ref:`Default gradient layouts<default-grad-layouts>`
   108|         0|            0|            0|  0.00%|    for details on the memory layout of accumulated gradients.
   109|         0|            0|            0|  0.00%|
   110|         0|            0|            0|  0.00%|    .. note::
   111|         0|            0|            0|  0.00%|        Using this method with ``create_graph=True`` will create a reference cycle
   112|         0|            0|            0|  0.00%|        between the parameter and its gradient which can cause a memory leak.
   113|         0|            0|            0|  0.00%|        We recommend using ``autograd.grad`` when creating the graph to avoid this.
   114|         0|            0|            0|  0.00%|        If you have to use this function, make sure to reset the ``.grad`` fields of your
   115|         0|            0|            0|  0.00%|        parameters to ``None`` after use to break the cycle and avoid the leak.
   116|         0|            0|            0|  0.00%|
   117|         0|            0|            0|  0.00%|    .. note::
   118|         0|            0|            0|  0.00%|
   119|         0|            0|            0|  0.00%|        If you run any forward ops, create ``grad_tensors``, and/or call ``backward``
   120|         0|            0|            0|  0.00%|        in a user-specified CUDA stream context, see
   121|         0|            0|            0|  0.00%|        :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.
   122|         0|            0|            0|  0.00%|
   123|         0|            0|            0|  0.00%|    .. note::
   124|         0|            0|            0|  0.00%|
   125|         0|            0|            0|  0.00%|        When ``inputs`` are provided and a given input is not a leaf,
   126|         0|            0|            0|  0.00%|        the current implementation will call its grad_fn (even though it is not strictly needed to get this gradients).
   127|         0|            0|            0|  0.00%|        It is an implementation detail on which the user should not rely.
   128|         0|            0|            0|  0.00%|        See https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780 for more details.
   129|         0|            0|            0|  0.00%|
   130|         0|            0|            0|  0.00%|    Args:
   131|         0|            0|            0|  0.00%|        tensors (Sequence[Tensor] or Tensor): Tensors of which the derivative will be
   132|         0|            0|            0|  0.00%|            computed.
   133|         0|            0|            0|  0.00%|        grad_tensors (Sequence[Tensor or None] or Tensor, optional): The "vector" in
   134|         0|            0|            0|  0.00%|            the Jacobian-vector product, usually gradients w.r.t. each element of
   135|         0|            0|            0|  0.00%|            corresponding tensors. None values can be specified for scalar Tensors or
   136|         0|            0|            0|  0.00%|            ones that don't require grad. If a None value would be acceptable for all
   137|         0|            0|            0|  0.00%|            grad_tensors, then this argument is optional.
   138|         0|            0|            0|  0.00%|        retain_graph (bool, optional): If ``False``, the graph used to compute the grad
   139|         0|            0|            0|  0.00%|            will be freed. Note that in nearly all cases setting this option to ``True``
   140|         0|            0|            0|  0.00%|            is not needed and often can be worked around in a much more efficient
   141|         0|            0|            0|  0.00%|            way. Defaults to the value of ``create_graph``.
   142|         0|            0|            0|  0.00%|        create_graph (bool, optional): If ``True``, graph of the derivative will
   143|         0|            0|            0|  0.00%|            be constructed, allowing to compute higher order derivative products.
   144|         0|            0|            0|  0.00%|            Defaults to ``False``.
   145|         0|            0|            0|  0.00%|        inputs (Sequence[Tensor] or Tensor, optional): Inputs w.r.t. which the gradient
   146|         0|            0|            0|  0.00%|            be will accumulated into ``.grad``. All other Tensors will be ignored. If
   147|         0|            0|            0|  0.00%|            not provided, the gradient is accumulated into all the leaf Tensors that
   148|         0|            0|            0|  0.00%|            were used to compute the attr::tensors.
   149|         0|            0|            0|  0.00%|    """
   150|       288|  0.000745535|  2.58866e-06|  0.00%|    if grad_variables is not None:
   151|         0|            0|            0|  0.00%|        warnings.warn("'grad_variables' is deprecated. Use 'grad_tensors' instead.")
   152|         0|            0|            0|  0.00%|        if grad_tensors is None:
   153|         0|            0|            0|  0.00%|            grad_tensors = grad_variables
   154|         0|            0|            0|  0.00%|        else:
   155|         0|            0|            0|  0.00%|            raise RuntimeError("'grad_tensors' and 'grad_variables' (deprecated) "
   156|         0|            0|            0|  0.00%|                               "arguments both passed to backward(). Please only "
   157|         0|            0|            0|  0.00%|                               "use 'grad_tensors'.")
   158|       288|  0.000637531|  2.21365e-06|  0.00%|    if inputs is not None and len(inputs) == 0:
   159|         0|            0|            0|  0.00%|        raise RuntimeError("'inputs' argument to backward() cannot be empty.")
   160|         0|            0|            0|  0.00%|
   161|       288|  0.000787973|  2.73602e-06|  0.00%|    tensors = (tensors,) if isinstance(tensors, torch.Tensor) else tuple(tensors)
   162|       576|   0.00127625|  2.21572e-06|  0.00%|    inputs = (inputs,) if isinstance(inputs, torch.Tensor) else \
   163|       288|  0.000671864|  2.33286e-06|  0.00%|        tuple(inputs) if inputs is not None else tuple()
   164|         0|            0|            0|  0.00%|
   165|       288|   0.00186944|  6.49111e-06|  0.00%|    grad_tensors_ = _tensor_or_tensors_to_tuple(grad_tensors, len(tensors))
(call)|       288|   0.00150776|  5.23527e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/__init__.py:77 _tensor_or_tensors_to_tuple
   166|       288|   0.00214338|   7.4423e-06|  0.00%|    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
(call)|       288|   0.00990582|  3.43952e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/__init__.py:30 _make_grads
   167|       288|  0.000618696|  2.14825e-06|  0.00%|    if retain_graph is None:
   168|       288|  0.000572443|  1.98765e-06|  0.00%|        retain_graph = create_graph
   169|         0|            0|            0|  0.00%|
   170|         0|            0|            0|  0.00%|    # The reason we repeat same the comment below is that
   171|         0|            0|            0|  0.00%|    # some Python versions print out the first line of a multi-line function
   172|         0|            0|            0|  0.00%|    # calls in the traceback and some print out the last line
   173|       576|     0.313289|  0.000543905|  0.30%|    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
   174|       288|  0.000565052|  1.96199e-06|  0.00%|        tensors, grad_tensors_, retain_graph, create_graph, inputs,
   175|       288|  0.000526905|  1.82953e-06|  0.00%|        allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
   176|         0|            0|            0|  0.00%|
   177|         0|            0|            0|  0.00%|def grad(
   178|         0|            0|            0|  0.00%|    outputs: _TensorOrTensors,
   179|         0|            0|            0|  0.00%|    inputs: _TensorOrTensors,
   180|         0|            0|            0|  0.00%|    grad_outputs: Optional[_TensorOrTensors] = None,
   181|         0|            0|            0|  0.00%|    retain_graph: Optional[bool] = None,
   182|         0|            0|            0|  0.00%|    create_graph: bool = False,
   183|         0|            0|            0|  0.00%|    only_inputs: bool = True,
   184|         0|            0|            0|  0.00%|    allow_unused: bool = False,
   185|         0|            0|            0|  0.00%|    is_grads_batched: bool = False
   186|         0|            0|            0|  0.00%|) -> Tuple[torch.Tensor, ...]:
   187|         0|            0|            0|  0.00%|    r"""Computes and returns the sum of gradients of outputs with respect to
   188|         0|            0|            0|  0.00%|    the inputs.
   189|         0|            0|            0|  0.00%|
   190|         0|            0|            0|  0.00%|    ``grad_outputs`` should be a sequence of length matching ``output``
   191|         0|            0|            0|  0.00%|    containing the "vector" in vector-Jacobian product, usually the pre-computed
   192|         0|            0|            0|  0.00%|    gradients w.r.t. each of the outputs. If an output doesn't require_grad,
   193|         0|            0|            0|  0.00%|    then the gradient can be ``None``).
   194|         0|            0|            0|  0.00%|
   195|         0|            0|            0|  0.00%|    .. note::
   196|         0|            0|            0|  0.00%|
   197|         0|            0|            0|  0.00%|        If you run any forward ops, create ``grad_outputs``, and/or call ``grad``
   198|         0|            0|            0|  0.00%|        in a user-specified CUDA stream context, see
   199|         0|            0|            0|  0.00%|        :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.
   200|         0|            0|            0|  0.00%|
   201|         0|            0|            0|  0.00%|    .. note::
   202|         0|            0|            0|  0.00%|
   203|         0|            0|            0|  0.00%|        ``only_inputs`` argument is deprecated and is ignored now (defaults to ``True``).
   204|         0|            0|            0|  0.00%|        To accumulate gradient for other parts of the graph, please use
   205|         0|            0|            0|  0.00%|        ``torch.autograd.backward``.
   206|         0|            0|            0|  0.00%|
   207|         0|            0|            0|  0.00%|    Args:
   208|         0|            0|            0|  0.00%|        outputs (sequence of Tensor): outputs of the differentiated function.
   209|         0|            0|            0|  0.00%|        inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be
   210|         0|            0|            0|  0.00%|            returned (and not accumulated into ``.grad``).
   211|         0|            0|            0|  0.00%|        grad_outputs (sequence of Tensor): The "vector" in the vector-Jacobian product.
   212|         0|            0|            0|  0.00%|            Usually gradients w.r.t. each output. None values can be specified for scalar
   213|         0|            0|            0|  0.00%|            Tensors or ones that don't require grad. If a None value would be acceptable
   214|         0|            0|            0|  0.00%|            for all grad_tensors, then this argument is optional. Default: None.
   215|         0|            0|            0|  0.00%|        retain_graph (bool, optional): If ``False``, the graph used to compute the grad
   216|         0|            0|            0|  0.00%|            will be freed. Note that in nearly all cases setting this option to ``True``
   217|         0|            0|            0|  0.00%|            is not needed and often can be worked around in a much more efficient
   218|         0|            0|            0|  0.00%|            way. Defaults to the value of ``create_graph``.
   219|         0|            0|            0|  0.00%|        create_graph (bool, optional): If ``True``, graph of the derivative will
   220|         0|            0|            0|  0.00%|            be constructed, allowing to compute higher order derivative products.
   221|         0|            0|            0|  0.00%|            Default: ``False``.
   222|         0|            0|            0|  0.00%|        allow_unused (bool, optional): If ``False``, specifying inputs that were not
   223|         0|            0|            0|  0.00%|            used when computing outputs (and therefore their grad is always zero)
   224|         0|            0|            0|  0.00%|            is an error. Defaults to ``False``.
   225|         0|            0|            0|  0.00%|        is_grads_batched (bool, optional): If ``True``, the first dimension of each
   226|         0|            0|            0|  0.00%|            tensor in ``grad_outputs`` will be interpreted as the batch dimension.
   227|         0|            0|            0|  0.00%|            Instead of computing a single vector-Jacobian product, we compute a
   228|         0|            0|            0|  0.00%|            batch of vector-Jacobian products for each "vector" in the batch.
   229|         0|            0|            0|  0.00%|            We use the vmap prototype feature as the backend to vectorize calls
   230|         0|            0|            0|  0.00%|            to the autograd engine so that this computation can be performed in a
   231|         0|            0|            0|  0.00%|            single call. This should lead to performance improvements when compared
   232|         0|            0|            0|  0.00%|            to manually looping and performing backward multiple times. Note that
   233|         0|            0|            0|  0.00%|            due to this feature being experimental, there may be performance
   234|         0|            0|            0|  0.00%|            cliffs. Please use ``torch._C._debug_only_display_vmap_fallback_warnings(True)``
   235|         0|            0|            0|  0.00%|            to show any performance warnings and file an issue on github if warnings exist
   236|         0|            0|            0|  0.00%|            for your use case. Defaults to ``False``.
   237|         0|            0|            0|  0.00%|    """
   238|         0|            0|            0|  0.00%|    t_outputs = cast(Tuple[torch.Tensor, ...], (outputs,) if is_tensor_like(outputs) else tuple(outputs))
   239|         0|            0|            0|  0.00%|    t_inputs = cast(Tuple[torch.Tensor, ...], (inputs,) if is_tensor_like(inputs) else tuple(inputs))
   240|         0|            0|            0|  0.00%|    overridable_args = t_outputs + t_inputs
   241|         0|            0|            0|  0.00%|    if has_torch_function(overridable_args):
   242|         0|            0|            0|  0.00%|        return handle_torch_function(
   243|         0|            0|            0|  0.00%|            grad,
   244|         0|            0|            0|  0.00%|            overridable_args,
   245|         0|            0|            0|  0.00%|            t_outputs,
   246|         0|            0|            0|  0.00%|            t_inputs,
   247|         0|            0|            0|  0.00%|            grad_outputs=grad_outputs,
   248|         0|            0|            0|  0.00%|            retain_graph=retain_graph,
   249|         0|            0|            0|  0.00%|            create_graph=create_graph,
   250|         0|            0|            0|  0.00%|            only_inputs=only_inputs,
   251|         0|            0|            0|  0.00%|            allow_unused=allow_unused,
   252|         0|            0|            0|  0.00%|            is_grads_batched=is_grads_batched,
   253|         0|            0|            0|  0.00%|        )
   254|         0|            0|            0|  0.00%|
   255|         0|            0|            0|  0.00%|    if not only_inputs:
   256|         0|            0|            0|  0.00%|        warnings.warn("only_inputs argument is deprecated and is ignored now "
   257|         0|            0|            0|  0.00%|                      "(defaults to True). To accumulate gradient for other "
   258|         0|            0|            0|  0.00%|                      "parts of the graph, please use torch.autograd.backward.")
   259|         0|            0|            0|  0.00%|
   260|         0|            0|            0|  0.00%|    grad_outputs_ = _tensor_or_tensors_to_tuple(grad_outputs, len(t_outputs))
   261|         0|            0|            0|  0.00%|    grad_outputs_ = _make_grads(t_outputs, grad_outputs_, is_grads_batched=is_grads_batched)
   262|         0|            0|            0|  0.00%|
   263|         0|            0|            0|  0.00%|    if retain_graph is None:
   264|         0|            0|            0|  0.00%|        retain_graph = create_graph
   265|         0|            0|            0|  0.00%|
   266|         0|            0|            0|  0.00%|    # The reason we repeat same the comment several times below is because
   267|         0|            0|            0|  0.00%|    # some Python versions print out the first line of multi-line function
   268|         0|            0|            0|  0.00%|    # calls in the traceback and some print out the last line
   269|         0|            0|            0|  0.00%|    if is_grads_batched:
   270|         0|            0|            0|  0.00%|        def vjp(gO):
   271|         0|            0|            0|  0.00%|            return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
   272|         0|            0|            0|  0.00%|                t_outputs, gO, retain_graph, create_graph, t_inputs,
   273|         0|            0|            0|  0.00%|                allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass
   274|         0|            0|            0|  0.00%|        return _vmap_internals._vmap(vjp, 0, 0, allow_none_pass_through=True)(grad_outputs_)
   275|         0|            0|            0|  0.00%|    else:
   276|         0|            0|            0|  0.00%|        return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
   277|         0|            0|            0|  0.00%|            t_outputs, grad_outputs_, retain_graph, create_graph, t_inputs,
   278|         0|            0|            0|  0.00%|            allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass
   279|         0|            0|            0|  0.00%|
   280|         0|            0|            0|  0.00%|
   281|         0|            0|            0|  0.00%|# This function applies in case of gradient checkpointing for memory
   282|         0|            0|            0|  0.00%|# optimization. Currently, gradient checkpointing is supported only if the
   283|         0|            0|            0|  0.00%|# execution engine is invoked through torch.autograd.backward() and its
   284|         0|            0|            0|  0.00%|# inputs argument is not passed. It is not supported for torch.autograd.grad().
   285|         0|            0|            0|  0.00%|# This is because if inputs are specified, the gradient won't be calculated for
   286|         0|            0|            0|  0.00%|# anything else e.g. model parameters like weights, bias etc.
   287|         0|            0|            0|  0.00%|#
   288|         0|            0|            0|  0.00%|# This function returns whether the checkpointing is valid i.e. torch.autograd.backward
   289|         0|            0|            0|  0.00%|# or not i.e. torch.autograd.grad. The implementation works by maintaining a thread
   290|         0|            0|            0|  0.00%|# local variable in torch/csrc/autograd/engine.cpp which looks at the NodeTask
   291|         0|            0|            0|  0.00%|# in the stack and before a NodeTask is executed in evaluate_function, it
   292|         0|            0|            0|  0.00%|# checks for whether reentrant backwards is imperative or not.
   293|         0|            0|            0|  0.00%|# See https://github.com/pytorch/pytorch/pull/4594 for more discussion/context
   294|         0|            0|            0|  0.00%|def _is_checkpoint_valid():
   295|         0|            0|            0|  0.00%|    return Variable._execution_engine.is_checkpoint_valid()
   296|         0|            0|            0|  0.00%|
   297|         0|            0|            0|  0.00%|
   298|         0|            0|            0|  0.00%|def variable(*args, **kwargs):
   299|         0|            0|            0|  0.00%|    raise RuntimeError("torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead")
   300|         0|            0|            0|  0.00%|
   301|         0|            0|            0|  0.00%|# Monkey patching variable.Variable to fix FX codegen. FX generates a call by roughly doing
   302|         0|            0|            0|  0.00%|# f"{fn.__module__}.{fn.__name__}(...). This yields torch.autograd.variable.Variable(...) in the
   303|         0|            0|            0|  0.00%|# output of an FX graph.  Unfortunately the module name torch.autograd.variable is shadowed by the
   304|         0|            0|            0|  0.00%|# deprecated function - variable(...).
   305|         0|            0|            0|  0.00%|variable.Variable = Variable  # type: ignore[attr-defined]
   306|         0|            0|            0|  0.00%|
   307|         0|            0|            0|  0.00%|if not torch._C._autograd_init():
   308|         0|            0|            0|  0.00%|    raise RuntimeError("autograd initialization failed")
   309|         0|            0|            0|  0.00%|
   310|         0|            0|            0|  0.00%|# Import all native method/classes
   311|         0|            0|            0|  0.00%|from torch._C._autograd import (DeviceType, ProfilerActivity, ProfilerState, ProfilerConfig, ProfilerEvent,
   312|         0|            0|            0|  0.00%|                                _enable_profiler_legacy, _disable_profiler_legacy, _profiler_enabled,
   313|         0|            0|            0|  0.00%|                                _enable_record_function, _set_empty_test_observer, kineto_available,
   314|         0|            0|            0|  0.00%|                                _record_function_with_args_enter, _record_function_with_args_exit,
   315|         0|            0|            0|  0.00%|                                _supported_activities, _add_metadata_json, SavedTensor,
   316|         0|            0|            0|  0.00%|                                _push_saved_tensors_default_hooks, _pop_saved_tensors_default_hooks)
   317|         0|            0|            0|  0.00%|
   318|         0|            0|            0|  0.00%|from torch._C._autograd import (_ProfilerResult, _KinetoEvent, _kineto_step,
   319|         0|            0|            0|  0.00%|                                _prepare_profiler, _enable_profiler, _disable_profiler)
   320|         0|            0|            0|  0.00%|
   321|         0|            0|            0|  0.00%|from . import profiler
   322|         0|            0|            0|  0.00%|
   323|         0|            0|            0|  0.00%|def _register_py_tensor_class_for_device(device, cls):
   324|         0|            0|            0|  0.00%|    if not isinstance(cls, type):
   325|         0|            0|            0|  0.00%|        raise RuntimeError("cls isn't a typeinfo object")
   326|         0|            0|            0|  0.00%|    torch._C._register_py_class_for_device(device, cls)
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/constraints.py
File duration: 0.326239s (0.31%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|r"""
     2|         0|            0|            0|  0.00%|The following constraints are implemented:
     3|         0|            0|            0|  0.00%|
     4|         0|            0|            0|  0.00%|- ``constraints.boolean``
     5|         0|            0|            0|  0.00%|- ``constraints.cat``
     6|         0|            0|            0|  0.00%|- ``constraints.corr_cholesky``
     7|         0|            0|            0|  0.00%|- ``constraints.dependent``
     8|         0|            0|            0|  0.00%|- ``constraints.greater_than(lower_bound)``
     9|         0|            0|            0|  0.00%|- ``constraints.greater_than_eq(lower_bound)``
    10|         0|            0|            0|  0.00%|- ``constraints.independent(constraint, reinterpreted_batch_ndims)``
    11|         0|            0|            0|  0.00%|- ``constraints.integer_interval(lower_bound, upper_bound)``
    12|         0|            0|            0|  0.00%|- ``constraints.interval(lower_bound, upper_bound)``
    13|         0|            0|            0|  0.00%|- ``constraints.less_than(upper_bound)``
    14|         0|            0|            0|  0.00%|- ``constraints.lower_cholesky``
    15|         0|            0|            0|  0.00%|- ``constraints.lower_triangular``
    16|         0|            0|            0|  0.00%|- ``constraints.multinomial``
    17|         0|            0|            0|  0.00%|- ``constraints.nonnegative_integer``
    18|         0|            0|            0|  0.00%|- ``constraints.one_hot``
    19|         0|            0|            0|  0.00%|- ``constraints.positive_integer``
    20|         0|            0|            0|  0.00%|- ``constraints.positive``
    21|         0|            0|            0|  0.00%|- ``constraints.positive_semidefinite``
    22|         0|            0|            0|  0.00%|- ``constraints.positive_definite``
    23|         0|            0|            0|  0.00%|- ``constraints.real_vector``
    24|         0|            0|            0|  0.00%|- ``constraints.real``
    25|         0|            0|            0|  0.00%|- ``constraints.simplex``
    26|         0|            0|            0|  0.00%|- ``constraints.symmetric``
    27|         0|            0|            0|  0.00%|- ``constraints.stack``
    28|         0|            0|            0|  0.00%|- ``constraints.square``
    29|         0|            0|            0|  0.00%|- ``constraints.symmetric``
    30|         0|            0|            0|  0.00%|- ``constraints.unit_interval``
    31|         0|            0|            0|  0.00%|"""
    32|         0|            0|            0|  0.00%|
    33|         0|            0|            0|  0.00%|import torch
    34|         0|            0|            0|  0.00%|
    35|         0|            0|            0|  0.00%|__all__ = [
    36|         0|            0|            0|  0.00%|    'Constraint',
    37|         0|            0|            0|  0.00%|    'boolean',
    38|         0|            0|            0|  0.00%|    'cat',
    39|         0|            0|            0|  0.00%|    'corr_cholesky',
    40|         0|            0|            0|  0.00%|    'dependent',
    41|         0|            0|            0|  0.00%|    'dependent_property',
    42|         0|            0|            0|  0.00%|    'greater_than',
    43|         0|            0|            0|  0.00%|    'greater_than_eq',
    44|         0|            0|            0|  0.00%|    'independent',
    45|         0|            0|            0|  0.00%|    'integer_interval',
    46|         0|            0|            0|  0.00%|    'interval',
    47|         0|            0|            0|  0.00%|    'half_open_interval',
    48|         0|            0|            0|  0.00%|    'is_dependent',
    49|         0|            0|            0|  0.00%|    'less_than',
    50|         0|            0|            0|  0.00%|    'lower_cholesky',
    51|         0|            0|            0|  0.00%|    'lower_triangular',
    52|         0|            0|            0|  0.00%|    'multinomial',
    53|         0|            0|            0|  0.00%|    'nonnegative_integer',
    54|         0|            0|            0|  0.00%|    'positive',
    55|         0|            0|            0|  0.00%|    'positive_semidefinite',
    56|         0|            0|            0|  0.00%|    'positive_definite',
    57|         0|            0|            0|  0.00%|    'positive_integer',
    58|         0|            0|            0|  0.00%|    'real',
    59|         0|            0|            0|  0.00%|    'real_vector',
    60|         0|            0|            0|  0.00%|    'simplex',
    61|         0|            0|            0|  0.00%|    'square',
    62|         0|            0|            0|  0.00%|    'stack',
    63|         0|            0|            0|  0.00%|    'symmetric',
    64|         0|            0|            0|  0.00%|    'unit_interval',
    65|         0|            0|            0|  0.00%|]
    66|         0|            0|            0|  0.00%|
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|class Constraint(object):
    69|         0|            0|            0|  0.00%|    """
    70|         0|            0|            0|  0.00%|    Abstract base class for constraints.
    71|         0|            0|            0|  0.00%|
    72|         0|            0|            0|  0.00%|    A constraint object represents a region over which a variable is valid,
    73|         0|            0|            0|  0.00%|    e.g. within which a variable can be optimized.
    74|         0|            0|            0|  0.00%|
    75|         0|            0|            0|  0.00%|    Attributes:
    76|         0|            0|            0|  0.00%|        is_discrete (bool): Whether constrained space is discrete.
    77|         0|            0|            0|  0.00%|            Defaults to False.
    78|         0|            0|            0|  0.00%|        event_dim (int): Number of rightmost dimensions that together define
    79|         0|            0|            0|  0.00%|            an event. The :meth:`check` method will remove this many dimensions
    80|         0|            0|            0|  0.00%|            when computing validity.
    81|         0|            0|            0|  0.00%|    """
    82|         0|            0|            0|  0.00%|    is_discrete = False  # Default to continuous.
    83|         0|            0|            0|  0.00%|    event_dim = 0  # Default to univariate.
    84|         0|            0|            0|  0.00%|
    85|         0|            0|            0|  0.00%|    def check(self, value):
    86|         0|            0|            0|  0.00%|        """
    87|         0|            0|            0|  0.00%|        Returns a byte tensor of ``sample_shape + batch_shape`` indicating
    88|         0|            0|            0|  0.00%|        whether each event in value satisfies this constraint.
    89|         0|            0|            0|  0.00%|        """
    90|         0|            0|            0|  0.00%|        raise NotImplementedError
    91|         0|            0|            0|  0.00%|
    92|         0|            0|            0|  0.00%|    def __repr__(self):
    93|         0|            0|            0|  0.00%|        return self.__class__.__name__[1:] + '()'
    94|         0|            0|            0|  0.00%|
    95|         0|            0|            0|  0.00%|
    96|         0|            0|            0|  0.00%|class _Dependent(Constraint):
    97|         0|            0|            0|  0.00%|    """
    98|         0|            0|            0|  0.00%|    Placeholder for variables whose support depends on other variables.
    99|         0|            0|            0|  0.00%|    These variables obey no simple coordinate-wise constraints.
   100|         0|            0|            0|  0.00%|
   101|         0|            0|            0|  0.00%|    Args:
   102|         0|            0|            0|  0.00%|        is_discrete (bool): Optional value of ``.is_discrete`` in case this
   103|         0|            0|            0|  0.00%|            can be computed statically. If not provided, access to the
   104|         0|            0|            0|  0.00%|            ``.is_discrete`` attribute will raise a NotImplementedError.
   105|         0|            0|            0|  0.00%|        event_dim (int): Optional value of ``.event_dim`` in case this
   106|         0|            0|            0|  0.00%|            can be computed statically. If not provided, access to the
   107|         0|            0|            0|  0.00%|            ``.event_dim`` attribute will raise a NotImplementedError.
   108|         0|            0|            0|  0.00%|    """
   109|         0|            0|            0|  0.00%|    def __init__(self, *, is_discrete=NotImplemented, event_dim=NotImplemented):
   110|         0|            0|            0|  0.00%|        self._is_discrete = is_discrete
   111|         0|            0|            0|  0.00%|        self._event_dim = event_dim
   112|         0|            0|            0|  0.00%|        super().__init__()
   113|         0|            0|            0|  0.00%|
   114|         0|            0|            0|  0.00%|    @property
   115|         0|            0|            0|  0.00%|    def is_discrete(self):
   116|         0|            0|            0|  0.00%|        if self._is_discrete is NotImplemented:
   117|         0|            0|            0|  0.00%|            raise NotImplementedError(".is_discrete cannot be determined statically")
   118|         0|            0|            0|  0.00%|        return self._is_discrete
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|    @property
   121|         0|            0|            0|  0.00%|    def event_dim(self):
   122|         0|            0|            0|  0.00%|        if self._event_dim is NotImplemented:
   123|         0|            0|            0|  0.00%|            raise NotImplementedError(".event_dim cannot be determined statically")
   124|         0|            0|            0|  0.00%|        return self._event_dim
   125|         0|            0|            0|  0.00%|
   126|         0|            0|            0|  0.00%|    def __call__(self, *, is_discrete=NotImplemented, event_dim=NotImplemented):
   127|         0|            0|            0|  0.00%|        """
   128|         0|            0|            0|  0.00%|        Support for syntax to customize static attributes::
   129|         0|            0|            0|  0.00%|
   130|         0|            0|            0|  0.00%|            constraints.dependent(is_discrete=True, event_dim=1)
   131|         0|            0|            0|  0.00%|        """
   132|         0|            0|            0|  0.00%|        if is_discrete is NotImplemented:
   133|         0|            0|            0|  0.00%|            is_discrete = self._is_discrete
   134|         0|            0|            0|  0.00%|        if event_dim is NotImplemented:
   135|         0|            0|            0|  0.00%|            event_dim = self._event_dim
   136|         0|            0|            0|  0.00%|        return _Dependent(is_discrete=is_discrete, event_dim=event_dim)
   137|         0|            0|            0|  0.00%|
   138|         0|            0|            0|  0.00%|    def check(self, x):
   139|         0|            0|            0|  0.00%|        raise ValueError('Cannot determine validity of dependent constraint')
   140|         0|            0|            0|  0.00%|
   141|         0|            0|            0|  0.00%|
   142|      5220|   0.00940514|  1.80175e-06|  0.01%|def is_dependent(constraint):
   143|      5220|    0.0135036|  2.58689e-06|  0.01%|    return isinstance(constraint, _Dependent)
   144|         0|            0|            0|  0.00%|
   145|         0|            0|            0|  0.00%|
   146|         0|            0|            0|  0.00%|class _DependentProperty(property, _Dependent):
   147|         0|            0|            0|  0.00%|    """
   148|         0|            0|            0|  0.00%|    Decorator that extends @property to act like a `Dependent` constraint when
   149|         0|            0|            0|  0.00%|    called on a class and act like a property when called on an object.
   150|         0|            0|            0|  0.00%|
   151|         0|            0|            0|  0.00%|    Example::
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|        class Uniform(Distribution):
   154|         0|            0|            0|  0.00%|            def __init__(self, low, high):
   155|         0|            0|            0|  0.00%|                self.low = low
   156|         0|            0|            0|  0.00%|                self.high = high
   157|         0|            0|            0|  0.00%|            @constraints.dependent_property(is_discrete=False, event_dim=0)
   158|         0|            0|            0|  0.00%|            def support(self):
   159|         0|            0|            0|  0.00%|                return constraints.interval(self.low, self.high)
   160|         0|            0|            0|  0.00%|
   161|         0|            0|            0|  0.00%|    Args:
   162|         0|            0|            0|  0.00%|        fn (callable): The function to be decorated.
   163|         0|            0|            0|  0.00%|        is_discrete (bool): Optional value of ``.is_discrete`` in case this
   164|         0|            0|            0|  0.00%|            can be computed statically. If not provided, access to the
   165|         0|            0|            0|  0.00%|            ``.is_discrete`` attribute will raise a NotImplementedError.
   166|         0|            0|            0|  0.00%|        event_dim (int): Optional value of ``.event_dim`` in case this
   167|         0|            0|            0|  0.00%|            can be computed statically. If not provided, access to the
   168|         0|            0|            0|  0.00%|            ``.event_dim`` attribute will raise a NotImplementedError.
   169|         0|            0|            0|  0.00%|    """
   170|         0|            0|            0|  0.00%|    def __init__(self, fn=None, *, is_discrete=NotImplemented, event_dim=NotImplemented):
   171|         0|            0|            0|  0.00%|        super().__init__(fn)
   172|         0|            0|            0|  0.00%|        self._is_discrete = is_discrete
   173|         0|            0|            0|  0.00%|        self._event_dim = event_dim
   174|         0|            0|            0|  0.00%|
   175|         0|            0|            0|  0.00%|    def __call__(self, fn):
   176|         0|            0|            0|  0.00%|        """
   177|         0|            0|            0|  0.00%|        Support for syntax to customize static attributes::
   178|         0|            0|            0|  0.00%|
   179|         0|            0|            0|  0.00%|            @constraints.dependent_property(is_discrete=True, event_dim=1)
   180|         0|            0|            0|  0.00%|            def support(self):
   181|         0|            0|            0|  0.00%|                ...
   182|         0|            0|            0|  0.00%|        """
   183|         0|            0|            0|  0.00%|        return _DependentProperty(fn, is_discrete=self._is_discrete, event_dim=self._event_dim)
   184|         0|            0|            0|  0.00%|
   185|         0|            0|            0|  0.00%|
   186|         0|            0|            0|  0.00%|class _IndependentConstraint(Constraint):
   187|         0|            0|            0|  0.00%|    """
   188|         0|            0|            0|  0.00%|    Wraps a constraint by aggregating over ``reinterpreted_batch_ndims``-many
   189|         0|            0|            0|  0.00%|    dims in :meth:`check`, so that an event is valid only if all its
   190|         0|            0|            0|  0.00%|    independent entries are valid.
   191|         0|            0|            0|  0.00%|    """
   192|         0|            0|            0|  0.00%|    def __init__(self, base_constraint, reinterpreted_batch_ndims):
   193|         0|            0|            0|  0.00%|        assert isinstance(base_constraint, Constraint)
   194|         0|            0|            0|  0.00%|        assert isinstance(reinterpreted_batch_ndims, int)
   195|         0|            0|            0|  0.00%|        assert reinterpreted_batch_ndims >= 0
   196|         0|            0|            0|  0.00%|        self.base_constraint = base_constraint
   197|         0|            0|            0|  0.00%|        self.reinterpreted_batch_ndims = reinterpreted_batch_ndims
   198|         0|            0|            0|  0.00%|        super().__init__()
   199|         0|            0|            0|  0.00%|
   200|         0|            0|            0|  0.00%|    @property
   201|         0|            0|            0|  0.00%|    def is_discrete(self):
   202|         0|            0|            0|  0.00%|        return self.base_constraint.is_discrete
   203|         0|            0|            0|  0.00%|
   204|         0|            0|            0|  0.00%|    @property
   205|         0|            0|            0|  0.00%|    def event_dim(self):
   206|         0|            0|            0|  0.00%|        return self.base_constraint.event_dim + self.reinterpreted_batch_ndims
   207|         0|            0|            0|  0.00%|
   208|      2610|    0.0059979|  2.29804e-06|  0.01%|    def check(self, value):
   209|      2610|    0.0197225|   7.5565e-06|  0.02%|        result = self.base_constraint.check(value)
(call)|      2610|    0.0330863|  1.26767e-05|  0.03%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/constraints.py:307 check
   210|      2610|   0.00767922|  2.94223e-06|  0.01%|        if result.dim() < self.reinterpreted_batch_ndims:
   211|         0|            0|            0|  0.00%|            expected = self.base_constraint.event_dim + self.reinterpreted_batch_ndims
   212|         0|            0|            0|  0.00%|            raise ValueError(f"Expected value.dim() >= {expected} but got {value.dim()}")
   213|      2610|     0.032517|  1.24586e-05|  0.03%|        result = result.reshape(result.shape[:result.dim() - self.reinterpreted_batch_ndims] + (-1,))
   214|      2610|    0.0389194|  1.49117e-05|  0.04%|        result = result.all(-1)
   215|      2610|   0.00699019|  2.67824e-06|  0.01%|        return result
   216|         0|            0|            0|  0.00%|
   217|         0|            0|            0|  0.00%|    def __repr__(self):
   218|         0|            0|            0|  0.00%|        return "{}({}, {})".format(self.__class__.__name__[1:], repr(self.base_constraint),
   219|         0|            0|            0|  0.00%|                                   self.reinterpreted_batch_ndims)
   220|         0|            0|            0|  0.00%|
   221|         0|            0|            0|  0.00%|
   222|         0|            0|            0|  0.00%|class _Boolean(Constraint):
   223|         0|            0|            0|  0.00%|    """
   224|         0|            0|            0|  0.00%|    Constrain to the two values `{0, 1}`.
   225|         0|            0|            0|  0.00%|    """
   226|         0|            0|            0|  0.00%|    is_discrete = True
   227|         0|            0|            0|  0.00%|
   228|         0|            0|            0|  0.00%|    def check(self, value):
   229|         0|            0|            0|  0.00%|        return (value == 0) | (value == 1)
   230|         0|            0|            0|  0.00%|
   231|         0|            0|            0|  0.00%|
   232|         0|            0|            0|  0.00%|class _OneHot(Constraint):
   233|         0|            0|            0|  0.00%|    """
   234|         0|            0|            0|  0.00%|    Constrain to one-hot vectors.
   235|         0|            0|            0|  0.00%|    """
   236|         0|            0|            0|  0.00%|    is_discrete = True
   237|         0|            0|            0|  0.00%|    event_dim = 1
   238|         0|            0|            0|  0.00%|
   239|         0|            0|            0|  0.00%|    def check(self, value):
   240|         0|            0|            0|  0.00%|        is_boolean = (value == 0) | (value == 1)
   241|         0|            0|            0|  0.00%|        is_normalized = value.sum(-1).eq(1)
   242|         0|            0|            0|  0.00%|        return is_boolean.all(-1) & is_normalized
   243|         0|            0|            0|  0.00%|
   244|         0|            0|            0|  0.00%|
   245|         0|            0|            0|  0.00%|class _IntegerInterval(Constraint):
   246|         0|            0|            0|  0.00%|    """
   247|         0|            0|            0|  0.00%|    Constrain to an integer interval `[lower_bound, upper_bound]`.
   248|         0|            0|            0|  0.00%|    """
   249|         0|            0|            0|  0.00%|    is_discrete = True
   250|         0|            0|            0|  0.00%|
   251|      2610|   0.00463057|  1.77416e-06|  0.00%|    def __init__(self, lower_bound, upper_bound):
   252|      2610|   0.00677228|  2.59474e-06|  0.01%|        self.lower_bound = lower_bound
   253|      2610|   0.00547171|  2.09644e-06|  0.01%|        self.upper_bound = upper_bound
   254|      2610|   0.00871229|  3.33804e-06|  0.01%|        super().__init__()
   255|         0|            0|            0|  0.00%|
   256|      2610|    0.0053525|  2.05077e-06|  0.01%|    def check(self, value):
   257|      2610|     0.127478|  4.88422e-05|  0.12%|        return (value % 1 == 0) & (self.lower_bound <= value) & (value <= self.upper_bound)
   258|         0|            0|            0|  0.00%|
   259|         0|            0|            0|  0.00%|    def __repr__(self):
   260|         0|            0|            0|  0.00%|        fmt_string = self.__class__.__name__[1:]
   261|         0|            0|            0|  0.00%|        fmt_string += '(lower_bound={}, upper_bound={})'.format(self.lower_bound, self.upper_bound)
   262|         0|            0|            0|  0.00%|        return fmt_string
   263|         0|            0|            0|  0.00%|
   264|         0|            0|            0|  0.00%|
   265|         0|            0|            0|  0.00%|class _IntegerLessThan(Constraint):
   266|         0|            0|            0|  0.00%|    """
   267|         0|            0|            0|  0.00%|    Constrain to an integer interval `(-inf, upper_bound]`.
   268|         0|            0|            0|  0.00%|    """
   269|         0|            0|            0|  0.00%|    is_discrete = True
   270|         0|            0|            0|  0.00%|
   271|         0|            0|            0|  0.00%|    def __init__(self, upper_bound):
   272|         0|            0|            0|  0.00%|        self.upper_bound = upper_bound
   273|         0|            0|            0|  0.00%|        super().__init__()
   274|         0|            0|            0|  0.00%|
   275|         0|            0|            0|  0.00%|    def check(self, value):
   276|         0|            0|            0|  0.00%|        return (value % 1 == 0) & (value <= self.upper_bound)
   277|         0|            0|            0|  0.00%|
   278|         0|            0|            0|  0.00%|    def __repr__(self):
   279|         0|            0|            0|  0.00%|        fmt_string = self.__class__.__name__[1:]
   280|         0|            0|            0|  0.00%|        fmt_string += '(upper_bound={})'.format(self.upper_bound)
   281|         0|            0|            0|  0.00%|        return fmt_string
   282|         0|            0|            0|  0.00%|
   283|         0|            0|            0|  0.00%|
   284|         0|            0|            0|  0.00%|class _IntegerGreaterThan(Constraint):
   285|         0|            0|            0|  0.00%|    """
   286|         0|            0|            0|  0.00%|    Constrain to an integer interval `[lower_bound, inf)`.
   287|         0|            0|            0|  0.00%|    """
   288|         0|            0|            0|  0.00%|    is_discrete = True
   289|         0|            0|            0|  0.00%|
   290|         0|            0|            0|  0.00%|    def __init__(self, lower_bound):
   291|         0|            0|            0|  0.00%|        self.lower_bound = lower_bound
   292|         0|            0|            0|  0.00%|        super().__init__()
   293|         0|            0|            0|  0.00%|
   294|         0|            0|            0|  0.00%|    def check(self, value):
   295|         0|            0|            0|  0.00%|        return (value % 1 == 0) & (value >= self.lower_bound)
   296|         0|            0|            0|  0.00%|
   297|         0|            0|            0|  0.00%|    def __repr__(self):
   298|         0|            0|            0|  0.00%|        fmt_string = self.__class__.__name__[1:]
   299|         0|            0|            0|  0.00%|        fmt_string += '(lower_bound={})'.format(self.lower_bound)
   300|         0|            0|            0|  0.00%|        return fmt_string
   301|         0|            0|            0|  0.00%|
   302|         0|            0|            0|  0.00%|
   303|         0|            0|            0|  0.00%|class _Real(Constraint):
   304|         0|            0|            0|  0.00%|    """
   305|         0|            0|            0|  0.00%|    Trivially constrain to the extended real line `[-inf, inf]`.
   306|         0|            0|            0|  0.00%|    """
   307|      2610|   0.00435758|  1.66957e-06|  0.00%|    def check(self, value):
   308|      2610|    0.0287287|  1.10072e-05|  0.03%|        return value == value  # False for NANs.
   309|         0|            0|            0|  0.00%|
   310|         0|            0|            0|  0.00%|
   311|         0|            0|            0|  0.00%|class _GreaterThan(Constraint):
   312|         0|            0|            0|  0.00%|    """
   313|         0|            0|            0|  0.00%|    Constrain to a real half line `(lower_bound, inf]`.
   314|         0|            0|            0|  0.00%|    """
   315|         0|            0|            0|  0.00%|    def __init__(self, lower_bound):
   316|         0|            0|            0|  0.00%|        self.lower_bound = lower_bound
   317|         0|            0|            0|  0.00%|        super().__init__()
   318|         0|            0|            0|  0.00%|
   319|         0|            0|            0|  0.00%|    def check(self, value):
   320|         0|            0|            0|  0.00%|        return self.lower_bound < value
   321|         0|            0|            0|  0.00%|
   322|         0|            0|            0|  0.00%|    def __repr__(self):
   323|         0|            0|            0|  0.00%|        fmt_string = self.__class__.__name__[1:]
   324|         0|            0|            0|  0.00%|        fmt_string += '(lower_bound={})'.format(self.lower_bound)
   325|         0|            0|            0|  0.00%|        return fmt_string
   326|         0|            0|            0|  0.00%|
   327|         0|            0|            0|  0.00%|
   328|         0|            0|            0|  0.00%|class _GreaterThanEq(Constraint):
   329|         0|            0|            0|  0.00%|    """
   330|         0|            0|            0|  0.00%|    Constrain to a real half line `[lower_bound, inf)`.
   331|         0|            0|            0|  0.00%|    """
   332|         0|            0|            0|  0.00%|    def __init__(self, lower_bound):
   333|         0|            0|            0|  0.00%|        self.lower_bound = lower_bound
   334|         0|            0|            0|  0.00%|        super().__init__()
   335|         0|            0|            0|  0.00%|
   336|         0|            0|            0|  0.00%|    def check(self, value):
   337|         0|            0|            0|  0.00%|        return self.lower_bound <= value
   338|         0|            0|            0|  0.00%|
   339|         0|            0|            0|  0.00%|    def __repr__(self):
   340|         0|            0|            0|  0.00%|        fmt_string = self.__class__.__name__[1:]
   341|         0|            0|            0|  0.00%|        fmt_string += '(lower_bound={})'.format(self.lower_bound)
   342|         0|            0|            0|  0.00%|        return fmt_string
   343|         0|            0|            0|  0.00%|
   344|         0|            0|            0|  0.00%|
   345|         0|            0|            0|  0.00%|class _LessThan(Constraint):
   346|         0|            0|            0|  0.00%|    """
   347|         0|            0|            0|  0.00%|    Constrain to a real half line `[-inf, upper_bound)`.
   348|         0|            0|            0|  0.00%|    """
   349|         0|            0|            0|  0.00%|    def __init__(self, upper_bound):
   350|         0|            0|            0|  0.00%|        self.upper_bound = upper_bound
   351|         0|            0|            0|  0.00%|        super().__init__()
   352|         0|            0|            0|  0.00%|
   353|         0|            0|            0|  0.00%|    def check(self, value):
   354|         0|            0|            0|  0.00%|        return value < self.upper_bound
   355|         0|            0|            0|  0.00%|
   356|         0|            0|            0|  0.00%|    def __repr__(self):
   357|         0|            0|            0|  0.00%|        fmt_string = self.__class__.__name__[1:]
   358|         0|            0|            0|  0.00%|        fmt_string += '(upper_bound={})'.format(self.upper_bound)
   359|         0|            0|            0|  0.00%|        return fmt_string
   360|         0|            0|            0|  0.00%|
   361|         0|            0|            0|  0.00%|
   362|         0|            0|            0|  0.00%|class _Interval(Constraint):
   363|         0|            0|            0|  0.00%|    """
   364|         0|            0|            0|  0.00%|    Constrain to a real interval `[lower_bound, upper_bound]`.
   365|         0|            0|            0|  0.00%|    """
   366|         0|            0|            0|  0.00%|    def __init__(self, lower_bound, upper_bound):
   367|         0|            0|            0|  0.00%|        self.lower_bound = lower_bound
   368|         0|            0|            0|  0.00%|        self.upper_bound = upper_bound
   369|         0|            0|            0|  0.00%|        super().__init__()
   370|         0|            0|            0|  0.00%|
   371|         0|            0|            0|  0.00%|    def check(self, value):
   372|         0|            0|            0|  0.00%|        return (self.lower_bound <= value) & (value <= self.upper_bound)
   373|         0|            0|            0|  0.00%|
   374|         0|            0|            0|  0.00%|    def __repr__(self):
   375|         0|            0|            0|  0.00%|        fmt_string = self.__class__.__name__[1:]
   376|         0|            0|            0|  0.00%|        fmt_string += '(lower_bound={}, upper_bound={})'.format(self.lower_bound, self.upper_bound)
   377|         0|            0|            0|  0.00%|        return fmt_string
   378|         0|            0|            0|  0.00%|
   379|         0|            0|            0|  0.00%|
   380|         0|            0|            0|  0.00%|class _HalfOpenInterval(Constraint):
   381|         0|            0|            0|  0.00%|    """
   382|         0|            0|            0|  0.00%|    Constrain to a real interval `[lower_bound, upper_bound)`.
   383|         0|            0|            0|  0.00%|    """
   384|         0|            0|            0|  0.00%|    def __init__(self, lower_bound, upper_bound):
   385|         0|            0|            0|  0.00%|        self.lower_bound = lower_bound
   386|         0|            0|            0|  0.00%|        self.upper_bound = upper_bound
   387|         0|            0|            0|  0.00%|        super().__init__()
   388|         0|            0|            0|  0.00%|
   389|         0|            0|            0|  0.00%|    def check(self, value):
   390|         0|            0|            0|  0.00%|        return (self.lower_bound <= value) & (value < self.upper_bound)
   391|         0|            0|            0|  0.00%|
   392|         0|            0|            0|  0.00%|    def __repr__(self):
   393|         0|            0|            0|  0.00%|        fmt_string = self.__class__.__name__[1:]
   394|         0|            0|            0|  0.00%|        fmt_string += '(lower_bound={}, upper_bound={})'.format(self.lower_bound, self.upper_bound)
   395|         0|            0|            0|  0.00%|        return fmt_string
   396|         0|            0|            0|  0.00%|
   397|         0|            0|            0|  0.00%|
   398|         0|            0|            0|  0.00%|class _Simplex(Constraint):
   399|         0|            0|            0|  0.00%|    """
   400|         0|            0|            0|  0.00%|    Constrain to the unit simplex in the innermost (rightmost) dimension.
   401|         0|            0|            0|  0.00%|    Specifically: `x >= 0` and `x.sum(-1) == 1`.
   402|         0|            0|            0|  0.00%|    """
   403|         0|            0|            0|  0.00%|    event_dim = 1
   404|         0|            0|            0|  0.00%|
   405|         0|            0|            0|  0.00%|    def check(self, value):
   406|         0|            0|            0|  0.00%|        return torch.all(value >= 0, dim=-1) & ((value.sum(-1) - 1).abs() < 1e-6)
   407|         0|            0|            0|  0.00%|
   408|         0|            0|            0|  0.00%|
   409|         0|            0|            0|  0.00%|class _Multinomial(Constraint):
   410|         0|            0|            0|  0.00%|    """
   411|         0|            0|            0|  0.00%|    Constrain to nonnegative integer values summing to at most an upper bound.
   412|         0|            0|            0|  0.00%|
   413|         0|            0|            0|  0.00%|    Note due to limitations of the Multinomial distribution, this currently
   414|         0|            0|            0|  0.00%|    checks the weaker condition ``value.sum(-1) <= upper_bound``. In the future
   415|         0|            0|            0|  0.00%|    this may be strengthened to ``value.sum(-1) == upper_bound``.
   416|         0|            0|            0|  0.00%|    """
   417|         0|            0|            0|  0.00%|    is_discrete = True
   418|         0|            0|            0|  0.00%|    event_dim = 1
   419|         0|            0|            0|  0.00%|
   420|         0|            0|            0|  0.00%|    def __init__(self, upper_bound):
   421|         0|            0|            0|  0.00%|        self.upper_bound = upper_bound
   422|         0|            0|            0|  0.00%|
   423|         0|            0|            0|  0.00%|    def check(self, x):
   424|         0|            0|            0|  0.00%|        return (x >= 0).all(dim=-1) & (x.sum(dim=-1) <= self.upper_bound)
   425|         0|            0|            0|  0.00%|
   426|         0|            0|            0|  0.00%|
   427|         0|            0|            0|  0.00%|class _LowerTriangular(Constraint):
   428|         0|            0|            0|  0.00%|    """
   429|         0|            0|            0|  0.00%|    Constrain to lower-triangular square matrices.
   430|         0|            0|            0|  0.00%|    """
   431|         0|            0|            0|  0.00%|    event_dim = 2
   432|         0|            0|            0|  0.00%|
   433|         0|            0|            0|  0.00%|    def check(self, value):
   434|         0|            0|            0|  0.00%|        value_tril = value.tril()
   435|         0|            0|            0|  0.00%|        return (value_tril == value).view(value.shape[:-2] + (-1,)).min(-1)[0]
   436|         0|            0|            0|  0.00%|
   437|         0|            0|            0|  0.00%|
   438|         0|            0|            0|  0.00%|class _LowerCholesky(Constraint):
   439|         0|            0|            0|  0.00%|    """
   440|         0|            0|            0|  0.00%|    Constrain to lower-triangular square matrices with positive diagonals.
   441|         0|            0|            0|  0.00%|    """
   442|         0|            0|            0|  0.00%|    event_dim = 2
   443|         0|            0|            0|  0.00%|
   444|         0|            0|            0|  0.00%|    def check(self, value):
   445|         0|            0|            0|  0.00%|        value_tril = value.tril()
   446|         0|            0|            0|  0.00%|        lower_triangular = (value_tril == value).view(value.shape[:-2] + (-1,)).min(-1)[0]
   447|         0|            0|            0|  0.00%|
   448|         0|            0|            0|  0.00%|        positive_diagonal = (value.diagonal(dim1=-2, dim2=-1) > 0).min(-1)[0]
   449|         0|            0|            0|  0.00%|        return lower_triangular & positive_diagonal
   450|         0|            0|            0|  0.00%|
   451|         0|            0|            0|  0.00%|
   452|         0|            0|            0|  0.00%|class _CorrCholesky(Constraint):
   453|         0|            0|            0|  0.00%|    """
   454|         0|            0|            0|  0.00%|    Constrain to lower-triangular square matrices with positive diagonals and each
   455|         0|            0|            0|  0.00%|    row vector being of unit length.
   456|         0|            0|            0|  0.00%|    """
   457|         0|            0|            0|  0.00%|    event_dim = 2
   458|         0|            0|            0|  0.00%|
   459|         0|            0|            0|  0.00%|    def check(self, value):
   460|         0|            0|            0|  0.00%|        tol = torch.finfo(value.dtype).eps * value.size(-1) * 10  # 10 is an adjustable fudge factor
   461|         0|            0|            0|  0.00%|        row_norm = torch.linalg.norm(value.detach(), dim=-1)
   462|         0|            0|            0|  0.00%|        unit_row_norm = (row_norm - 1.).abs().le(tol).all(dim=-1)
   463|         0|            0|            0|  0.00%|        return _LowerCholesky().check(value) & unit_row_norm
   464|         0|            0|            0|  0.00%|
   465|         0|            0|            0|  0.00%|
   466|         0|            0|            0|  0.00%|class _Square(Constraint):
   467|         0|            0|            0|  0.00%|    """
   468|         0|            0|            0|  0.00%|    Constrain to square matrices.
   469|         0|            0|            0|  0.00%|    """
   470|         0|            0|            0|  0.00%|    event_dim = 2
   471|         0|            0|            0|  0.00%|
   472|         0|            0|            0|  0.00%|    def check(self, value):
   473|         0|            0|            0|  0.00%|        return torch.full(
   474|         0|            0|            0|  0.00%|            size=value.shape[:-2],
   475|         0|            0|            0|  0.00%|            fill_value=(value.shape[-2] == value.shape[-1]),
   476|         0|            0|            0|  0.00%|            dtype=torch.bool,
   477|         0|            0|            0|  0.00%|            device=value.device
   478|         0|            0|            0|  0.00%|        )
   479|         0|            0|            0|  0.00%|
   480|         0|            0|            0|  0.00%|
   481|         0|            0|            0|  0.00%|class _Symmetric(_Square):
   482|         0|            0|            0|  0.00%|    """
   483|         0|            0|            0|  0.00%|    Constrain to Symmetric square matrices.
   484|         0|            0|            0|  0.00%|    """
   485|         0|            0|            0|  0.00%|
   486|         0|            0|            0|  0.00%|    def check(self, value):
   487|         0|            0|            0|  0.00%|        square_check = super().check(value)
   488|         0|            0|            0|  0.00%|        if not square_check.all():
   489|         0|            0|            0|  0.00%|            return square_check
   490|         0|            0|            0|  0.00%|        return torch.isclose(value, value.mT, atol=1e-6).all(-2).all(-1)
   491|         0|            0|            0|  0.00%|
   492|         0|            0|            0|  0.00%|
   493|         0|            0|            0|  0.00%|class _PositiveSemidefinite(_Symmetric):
   494|         0|            0|            0|  0.00%|    """
   495|         0|            0|            0|  0.00%|    Constrain to positive-semidefinite matrices.
   496|         0|            0|            0|  0.00%|    """
   497|         0|            0|            0|  0.00%|    def check(self, value):
   498|         0|            0|            0|  0.00%|        sym_check = super().check(value)
   499|         0|            0|            0|  0.00%|        if not sym_check.all():
   500|         0|            0|            0|  0.00%|            return sym_check
   501|         0|            0|            0|  0.00%|        return torch.linalg.eigvalsh(value).ge(0).all(-1)
   502|         0|            0|            0|  0.00%|
   503|         0|            0|            0|  0.00%|
   504|         0|            0|            0|  0.00%|class _PositiveDefinite(_Symmetric):
   505|         0|            0|            0|  0.00%|    """
   506|         0|            0|            0|  0.00%|    Constrain to positive-definite matrices.
   507|         0|            0|            0|  0.00%|    """
   508|         0|            0|            0|  0.00%|    def check(self, value):
   509|         0|            0|            0|  0.00%|        sym_check = super().check(value)
   510|         0|            0|            0|  0.00%|        if not sym_check.all():
   511|         0|            0|            0|  0.00%|            return sym_check
   512|         0|            0|            0|  0.00%|        return torch.linalg.cholesky_ex(value).info.eq(0)
   513|         0|            0|            0|  0.00%|
   514|         0|            0|            0|  0.00%|
   515|         0|            0|            0|  0.00%|class _Cat(Constraint):
   516|         0|            0|            0|  0.00%|    """
   517|         0|            0|            0|  0.00%|    Constraint functor that applies a sequence of constraints
   518|         0|            0|            0|  0.00%|    `cseq` at the submatrices at dimension `dim`,
   519|         0|            0|            0|  0.00%|    each of size `lengths[dim]`, in a way compatible with :func:`torch.cat`.
   520|         0|            0|            0|  0.00%|    """
   521|         0|            0|            0|  0.00%|    def __init__(self, cseq, dim=0, lengths=None):
   522|         0|            0|            0|  0.00%|        assert all(isinstance(c, Constraint) for c in cseq)
   523|         0|            0|            0|  0.00%|        self.cseq = list(cseq)
   524|         0|            0|            0|  0.00%|        if lengths is None:
   525|         0|            0|            0|  0.00%|            lengths = [1] * len(self.cseq)
   526|         0|            0|            0|  0.00%|        self.lengths = list(lengths)
   527|         0|            0|            0|  0.00%|        assert len(self.lengths) == len(self.cseq)
   528|         0|            0|            0|  0.00%|        self.dim = dim
   529|         0|            0|            0|  0.00%|        super().__init__()
   530|         0|            0|            0|  0.00%|
   531|         0|            0|            0|  0.00%|    @property
   532|         0|            0|            0|  0.00%|    def is_discrete(self):
   533|         0|            0|            0|  0.00%|        return any(c.is_discrete for c in self.cseq)
   534|         0|            0|            0|  0.00%|
   535|         0|            0|            0|  0.00%|    @property
   536|         0|            0|            0|  0.00%|    def event_dim(self):
   537|         0|            0|            0|  0.00%|        return max(c.event_dim for c in self.cseq)
   538|         0|            0|            0|  0.00%|
   539|         0|            0|            0|  0.00%|    def check(self, value):
   540|         0|            0|            0|  0.00%|        assert -value.dim() <= self.dim < value.dim()
   541|         0|            0|            0|  0.00%|        checks = []
   542|         0|            0|            0|  0.00%|        start = 0
   543|         0|            0|            0|  0.00%|        for constr, length in zip(self.cseq, self.lengths):
   544|         0|            0|            0|  0.00%|            v = value.narrow(self.dim, start, length)
   545|         0|            0|            0|  0.00%|            checks.append(constr.check(v))
   546|         0|            0|            0|  0.00%|            start = start + length  # avoid += for jit compat
   547|         0|            0|            0|  0.00%|        return torch.cat(checks, self.dim)
   548|         0|            0|            0|  0.00%|
   549|         0|            0|            0|  0.00%|
   550|         0|            0|            0|  0.00%|class _Stack(Constraint):
   551|         0|            0|            0|  0.00%|    """
   552|         0|            0|            0|  0.00%|    Constraint functor that applies a sequence of constraints
   553|         0|            0|            0|  0.00%|    `cseq` at the submatrices at dimension `dim`,
   554|         0|            0|            0|  0.00%|    in a way compatible with :func:`torch.stack`.
   555|         0|            0|            0|  0.00%|    """
   556|         0|            0|            0|  0.00%|    def __init__(self, cseq, dim=0):
   557|         0|            0|            0|  0.00%|        assert all(isinstance(c, Constraint) for c in cseq)
   558|         0|            0|            0|  0.00%|        self.cseq = list(cseq)
   559|         0|            0|            0|  0.00%|        self.dim = dim
   560|         0|            0|            0|  0.00%|        super().__init__()
   561|         0|            0|            0|  0.00%|
   562|         0|            0|            0|  0.00%|    @property
   563|         0|            0|            0|  0.00%|    def is_discrete(self):
   564|         0|            0|            0|  0.00%|        return any(c.is_discrete for c in self.cseq)
   565|         0|            0|            0|  0.00%|
   566|         0|            0|            0|  0.00%|    @property
   567|         0|            0|            0|  0.00%|    def event_dim(self):
   568|         0|            0|            0|  0.00%|        dim = max(c.event_dim for c in self.cseq)
   569|         0|            0|            0|  0.00%|        if self.dim + dim < 0:
   570|         0|            0|            0|  0.00%|            dim += 1
   571|         0|            0|            0|  0.00%|        return dim
   572|         0|            0|            0|  0.00%|
   573|         0|            0|            0|  0.00%|    def check(self, value):
   574|         0|            0|            0|  0.00%|        assert -value.dim() <= self.dim < value.dim()
   575|         0|            0|            0|  0.00%|        vs = [value.select(self.dim, i) for i in range(value.size(self.dim))]
   576|         0|            0|            0|  0.00%|        return torch.stack([constr.check(v)
   577|         0|            0|            0|  0.00%|                            for v, constr in zip(vs, self.cseq)], self.dim)
   578|         0|            0|            0|  0.00%|
   579|         0|            0|            0|  0.00%|
   580|         0|            0|            0|  0.00%|# Public interface.
   581|         0|            0|            0|  0.00%|dependent = _Dependent()
   582|         0|            0|            0|  0.00%|dependent_property = _DependentProperty
   583|         0|            0|            0|  0.00%|independent = _IndependentConstraint
   584|         0|            0|            0|  0.00%|boolean = _Boolean()
   585|         0|            0|            0|  0.00%|one_hot = _OneHot()
   586|         0|            0|            0|  0.00%|nonnegative_integer = _IntegerGreaterThan(0)
   587|         0|            0|            0|  0.00%|positive_integer = _IntegerGreaterThan(1)
   588|         0|            0|            0|  0.00%|integer_interval = _IntegerInterval
   589|         0|            0|            0|  0.00%|real = _Real()
   590|         0|            0|            0|  0.00%|real_vector = independent(real, 1)
   591|         0|            0|            0|  0.00%|positive = _GreaterThan(0.)
   592|         0|            0|            0|  0.00%|nonnegative = _GreaterThanEq(0.)
   593|         0|            0|            0|  0.00%|greater_than = _GreaterThan
   594|         0|            0|            0|  0.00%|greater_than_eq = _GreaterThanEq
   595|         0|            0|            0|  0.00%|less_than = _LessThan
   596|         0|            0|            0|  0.00%|multinomial = _Multinomial
   597|         0|            0|            0|  0.00%|unit_interval = _Interval(0., 1.)
   598|         0|            0|            0|  0.00%|interval = _Interval
   599|         0|            0|            0|  0.00%|half_open_interval = _HalfOpenInterval
   600|         0|            0|            0|  0.00%|simplex = _Simplex()
   601|         0|            0|            0|  0.00%|lower_triangular = _LowerTriangular()
   602|         0|            0|            0|  0.00%|lower_cholesky = _LowerCholesky()
   603|         0|            0|            0|  0.00%|corr_cholesky = _CorrCholesky()
   604|         0|            0|            0|  0.00%|square = _Square()
   605|         0|            0|            0|  0.00%|symmetric = _Symmetric()
   606|         0|            0|            0|  0.00%|positive_semidefinite = _PositiveSemidefinite()
   607|         0|            0|            0|  0.00%|positive_definite = _PositiveDefinite()
   608|         0|            0|            0|  0.00%|cat = _Cat
   609|         0|            0|            0|  0.00%|stack = _Stack
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/multiarray.py
File duration: 0.316139s (0.30%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|"""
     2|         0|            0|            0|  0.00%|Create the numpy.core.multiarray namespace for backward compatibility. In v1.16
     3|         0|            0|            0|  0.00%|the multiarray and umath c-extension modules were merged into a single
     4|         0|            0|            0|  0.00%|_multiarray_umath extension module. So we replicate the old namespace
     5|         0|            0|            0|  0.00%|by importing from the extension module.
     6|         0|            0|            0|  0.00%|
     7|         0|            0|            0|  0.00%|"""
     8|         0|            0|            0|  0.00%|
     9|         0|            0|            0|  0.00%|import functools
    10|         0|            0|            0|  0.00%|from . import overrides
    11|         0|            0|            0|  0.00%|from . import _multiarray_umath
    12|         0|            0|            0|  0.00%|from ._multiarray_umath import *  # noqa: F403
    13|         0|            0|            0|  0.00%|# These imports are needed for backward compatibility,
    14|         0|            0|            0|  0.00%|# do not change them. issue gh-15518
    15|         0|            0|            0|  0.00%|# _get_ndarray_c_version is semi-public, on purpose not added to __all__
    16|         0|            0|            0|  0.00%|from ._multiarray_umath import (
    17|         0|            0|            0|  0.00%|    _fastCopyAndTranspose, _flagdict, _from_dlpack, _insert, _reconstruct,
    18|         0|            0|            0|  0.00%|    _vec_string, _ARRAY_API, _monotonicity, _get_ndarray_c_version,
    19|         0|            0|            0|  0.00%|    _set_madvise_hugepage,
    20|         0|            0|            0|  0.00%|    )
    21|         0|            0|            0|  0.00%|
    22|         0|            0|            0|  0.00%|__all__ = [
    23|         0|            0|            0|  0.00%|    '_ARRAY_API', 'ALLOW_THREADS', 'BUFSIZE', 'CLIP', 'DATETIMEUNITS',
    24|         0|            0|            0|  0.00%|    'ITEM_HASOBJECT', 'ITEM_IS_POINTER', 'LIST_PICKLE', 'MAXDIMS',
    25|         0|            0|            0|  0.00%|    'MAY_SHARE_BOUNDS', 'MAY_SHARE_EXACT', 'NEEDS_INIT', 'NEEDS_PYAPI',
    26|         0|            0|            0|  0.00%|    'RAISE', 'USE_GETITEM', 'USE_SETITEM', 'WRAP', '_fastCopyAndTranspose',
    27|         0|            0|            0|  0.00%|    '_flagdict', '_from_dlpack', '_insert', '_reconstruct', '_vec_string',
    28|         0|            0|            0|  0.00%|    '_monotonicity', 'add_docstring', 'arange', 'array', 'asarray',
    29|         0|            0|            0|  0.00%|    'asanyarray', 'ascontiguousarray', 'asfortranarray', 'bincount',
    30|         0|            0|            0|  0.00%|    'broadcast', 'busday_count', 'busday_offset', 'busdaycalendar', 'can_cast',
    31|         0|            0|            0|  0.00%|    'compare_chararrays', 'concatenate', 'copyto', 'correlate', 'correlate2',
    32|         0|            0|            0|  0.00%|    'count_nonzero', 'c_einsum', 'datetime_as_string', 'datetime_data',
    33|         0|            0|            0|  0.00%|    'dot', 'dragon4_positional', 'dragon4_scientific', 'dtype',
    34|         0|            0|            0|  0.00%|    'empty', 'empty_like', 'error', 'flagsobj', 'flatiter', 'format_longfloat',
    35|         0|            0|            0|  0.00%|    'frombuffer', 'fromfile', 'fromiter', 'fromstring',
    36|         0|            0|            0|  0.00%|    'get_handler_name', 'get_handler_version', 'inner', 'interp',
    37|         0|            0|            0|  0.00%|    'interp_complex', 'is_busday', 'lexsort', 'matmul', 'may_share_memory',
    38|         0|            0|            0|  0.00%|    'min_scalar_type', 'ndarray', 'nditer', 'nested_iters',
    39|         0|            0|            0|  0.00%|    'normalize_axis_index', 'packbits', 'promote_types', 'putmask',
    40|         0|            0|            0|  0.00%|    'ravel_multi_index', 'result_type', 'scalar', 'set_datetimeparse_function',
    41|         0|            0|            0|  0.00%|    'set_legacy_print_mode', 'set_numeric_ops', 'set_string_function',
    42|         0|            0|            0|  0.00%|    'set_typeDict', 'shares_memory', 'tracemalloc_domain', 'typeinfo',
    43|         0|            0|            0|  0.00%|    'unpackbits', 'unravel_index', 'vdot', 'where', 'zeros']
    44|         0|            0|            0|  0.00%|
    45|         0|            0|            0|  0.00%|# For backward compatibility, make sure pickle imports these functions from here
    46|         0|            0|            0|  0.00%|_reconstruct.__module__ = 'numpy.core.multiarray'
    47|         0|            0|            0|  0.00%|scalar.__module__ = 'numpy.core.multiarray'
    48|         0|            0|            0|  0.00%|
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|_from_dlpack.__module__ = 'numpy'
    51|         0|            0|            0|  0.00%|arange.__module__ = 'numpy'
    52|         0|            0|            0|  0.00%|array.__module__ = 'numpy'
    53|         0|            0|            0|  0.00%|asarray.__module__ = 'numpy'
    54|         0|            0|            0|  0.00%|asanyarray.__module__ = 'numpy'
    55|         0|            0|            0|  0.00%|ascontiguousarray.__module__ = 'numpy'
    56|         0|            0|            0|  0.00%|asfortranarray.__module__ = 'numpy'
    57|         0|            0|            0|  0.00%|datetime_data.__module__ = 'numpy'
    58|         0|            0|            0|  0.00%|empty.__module__ = 'numpy'
    59|         0|            0|            0|  0.00%|frombuffer.__module__ = 'numpy'
    60|         0|            0|            0|  0.00%|fromfile.__module__ = 'numpy'
    61|         0|            0|            0|  0.00%|fromiter.__module__ = 'numpy'
    62|         0|            0|            0|  0.00%|frompyfunc.__module__ = 'numpy'
    63|         0|            0|            0|  0.00%|fromstring.__module__ = 'numpy'
    64|         0|            0|            0|  0.00%|geterrobj.__module__ = 'numpy'
    65|         0|            0|            0|  0.00%|may_share_memory.__module__ = 'numpy'
    66|         0|            0|            0|  0.00%|nested_iters.__module__ = 'numpy'
    67|         0|            0|            0|  0.00%|promote_types.__module__ = 'numpy'
    68|         0|            0|            0|  0.00%|set_numeric_ops.__module__ = 'numpy'
    69|         0|            0|            0|  0.00%|seterrobj.__module__ = 'numpy'
    70|         0|            0|            0|  0.00%|zeros.__module__ = 'numpy'
    71|         0|            0|            0|  0.00%|
    72|         0|            0|            0|  0.00%|
    73|         0|            0|            0|  0.00%|# We can't verify dispatcher signatures because NumPy's C functions don't
    74|         0|            0|            0|  0.00%|# support introspection.
    75|         0|            0|            0|  0.00%|array_function_from_c_func_and_dispatcher = functools.partial(
    76|         0|            0|            0|  0.00%|    overrides.array_function_from_dispatcher,
    77|         0|            0|            0|  0.00%|    module='numpy', docs_from_dispatcher=True, verify=False)
    78|         0|            0|            0|  0.00%|
    79|         0|            0|            0|  0.00%|
    80|     10557|    0.0177305|   1.6795e-06|  0.02%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)
    81|         0|            0|            0|  0.00%|def empty_like(prototype, dtype=None, order=None, subok=None, shape=None):
    82|         0|            0|            0|  0.00%|    """
    83|         0|            0|            0|  0.00%|    empty_like(prototype, dtype=None, order='K', subok=True, shape=None)
    84|         0|            0|            0|  0.00%|
    85|         0|            0|            0|  0.00%|    Return a new array with the same shape and type as a given array.
    86|         0|            0|            0|  0.00%|
    87|         0|            0|            0|  0.00%|    Parameters
    88|         0|            0|            0|  0.00%|    ----------
    89|         0|            0|            0|  0.00%|    prototype : array_like
    90|         0|            0|            0|  0.00%|        The shape and data-type of `prototype` define these same attributes
    91|         0|            0|            0|  0.00%|        of the returned array.
    92|         0|            0|            0|  0.00%|    dtype : data-type, optional
    93|         0|            0|            0|  0.00%|        Overrides the data type of the result.
    94|         0|            0|            0|  0.00%|
    95|         0|            0|            0|  0.00%|        .. versionadded:: 1.6.0
    96|         0|            0|            0|  0.00%|    order : {'C', 'F', 'A', or 'K'}, optional
    97|         0|            0|            0|  0.00%|        Overrides the memory layout of the result. 'C' means C-order,
    98|         0|            0|            0|  0.00%|        'F' means F-order, 'A' means 'F' if `prototype` is Fortran
    99|         0|            0|            0|  0.00%|        contiguous, 'C' otherwise. 'K' means match the layout of `prototype`
   100|         0|            0|            0|  0.00%|        as closely as possible.
   101|         0|            0|            0|  0.00%|
   102|         0|            0|            0|  0.00%|        .. versionadded:: 1.6.0
   103|         0|            0|            0|  0.00%|    subok : bool, optional.
   104|         0|            0|            0|  0.00%|        If True, then the newly created array will use the sub-class
   105|         0|            0|            0|  0.00%|        type of `prototype`, otherwise it will be a base-class array. Defaults
   106|         0|            0|            0|  0.00%|        to True.
   107|         0|            0|            0|  0.00%|    shape : int or sequence of ints, optional.
   108|         0|            0|            0|  0.00%|        Overrides the shape of the result. If order='K' and the number of
   109|         0|            0|            0|  0.00%|        dimensions is unchanged, will try to keep order, otherwise,
   110|         0|            0|            0|  0.00%|        order='C' is implied.
   111|         0|            0|            0|  0.00%|
   112|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
   113|         0|            0|            0|  0.00%|
   114|         0|            0|            0|  0.00%|    Returns
   115|         0|            0|            0|  0.00%|    -------
   116|         0|            0|            0|  0.00%|    out : ndarray
   117|         0|            0|            0|  0.00%|        Array of uninitialized (arbitrary) data with the same
   118|         0|            0|            0|  0.00%|        shape and type as `prototype`.
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|    See Also
   121|         0|            0|            0|  0.00%|    --------
   122|         0|            0|            0|  0.00%|    ones_like : Return an array of ones with shape and type of input.
   123|         0|            0|            0|  0.00%|    zeros_like : Return an array of zeros with shape and type of input.
   124|         0|            0|            0|  0.00%|    full_like : Return a new array with shape of input filled with value.
   125|         0|            0|            0|  0.00%|    empty : Return a new uninitialized array.
   126|         0|            0|            0|  0.00%|
   127|         0|            0|            0|  0.00%|    Notes
   128|         0|            0|            0|  0.00%|    -----
   129|         0|            0|            0|  0.00%|    This function does *not* initialize the returned array; to do that use
   130|         0|            0|            0|  0.00%|    `zeros_like` or `ones_like` instead.  It may be marginally faster than
   131|         0|            0|            0|  0.00%|    the functions that do set the array values.
   132|         0|            0|            0|  0.00%|
   133|         0|            0|            0|  0.00%|    Examples
   134|         0|            0|            0|  0.00%|    --------
   135|         0|            0|            0|  0.00%|    >>> a = ([1,2,3], [4,5,6])                         # a is array-like
   136|         0|            0|            0|  0.00%|    >>> np.empty_like(a)
   137|         0|            0|            0|  0.00%|    array([[-1073741821, -1073741821,           3],    # uninitialized
   138|         0|            0|            0|  0.00%|           [          0,           0, -1073741821]])
   139|         0|            0|            0|  0.00%|    >>> a = np.array([[1., 2., 3.],[4.,5.,6.]])
   140|         0|            0|            0|  0.00%|    >>> np.empty_like(a)
   141|         0|            0|            0|  0.00%|    array([[ -2.00000715e+000,   1.48219694e-323,  -2.00000572e+000], # uninitialized
   142|         0|            0|            0|  0.00%|           [  4.38791518e-305,  -2.00000715e+000,   4.17269252e-309]])
   143|         0|            0|            0|  0.00%|
   144|         0|            0|            0|  0.00%|    """
   145|     10557|    0.0220017|  2.08409e-06|  0.02%|    return (prototype,)
   146|         0|            0|            0|  0.00%|
   147|         0|            0|            0|  0.00%|
   148|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.concatenate)
   149|         0|            0|            0|  0.00%|def concatenate(arrays, axis=None, out=None, *, dtype=None, casting=None):
   150|         0|            0|            0|  0.00%|    """
   151|         0|            0|            0|  0.00%|    concatenate((a1, a2, ...), axis=0, out=None, dtype=None, casting="same_kind")
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|    Join a sequence of arrays along an existing axis.
   154|         0|            0|            0|  0.00%|
   155|         0|            0|            0|  0.00%|    Parameters
   156|         0|            0|            0|  0.00%|    ----------
   157|         0|            0|            0|  0.00%|    a1, a2, ... : sequence of array_like
   158|         0|            0|            0|  0.00%|        The arrays must have the same shape, except in the dimension
   159|         0|            0|            0|  0.00%|        corresponding to `axis` (the first, by default).
   160|         0|            0|            0|  0.00%|    axis : int, optional
   161|         0|            0|            0|  0.00%|        The axis along which the arrays will be joined.  If axis is None,
   162|         0|            0|            0|  0.00%|        arrays are flattened before use.  Default is 0.
   163|         0|            0|            0|  0.00%|    out : ndarray, optional
   164|         0|            0|            0|  0.00%|        If provided, the destination to place the result. The shape must be
   165|         0|            0|            0|  0.00%|        correct, matching that of what concatenate would have returned if no
   166|         0|            0|            0|  0.00%|        out argument were specified.
   167|         0|            0|            0|  0.00%|    dtype : str or dtype
   168|         0|            0|            0|  0.00%|        If provided, the destination array will have this dtype. Cannot be
   169|         0|            0|            0|  0.00%|        provided together with `out`.
   170|         0|            0|            0|  0.00%|
   171|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
   172|         0|            0|            0|  0.00%|
   173|         0|            0|            0|  0.00%|    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
   174|         0|            0|            0|  0.00%|        Controls what kind of data casting may occur. Defaults to 'same_kind'.
   175|         0|            0|            0|  0.00%|
   176|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
   177|         0|            0|            0|  0.00%|
   178|         0|            0|            0|  0.00%|    Returns
   179|         0|            0|            0|  0.00%|    -------
   180|         0|            0|            0|  0.00%|    res : ndarray
   181|         0|            0|            0|  0.00%|        The concatenated array.
   182|         0|            0|            0|  0.00%|
   183|         0|            0|            0|  0.00%|    See Also
   184|         0|            0|            0|  0.00%|    --------
   185|         0|            0|            0|  0.00%|    ma.concatenate : Concatenate function that preserves input masks.
   186|         0|            0|            0|  0.00%|    array_split : Split an array into multiple sub-arrays of equal or
   187|         0|            0|            0|  0.00%|                  near-equal size.
   188|         0|            0|            0|  0.00%|    split : Split array into a list of multiple sub-arrays of equal size.
   189|         0|            0|            0|  0.00%|    hsplit : Split array into multiple sub-arrays horizontally (column wise).
   190|         0|            0|            0|  0.00%|    vsplit : Split array into multiple sub-arrays vertically (row wise).
   191|         0|            0|            0|  0.00%|    dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).
   192|         0|            0|            0|  0.00%|    stack : Stack a sequence of arrays along a new axis.
   193|         0|            0|            0|  0.00%|    block : Assemble arrays from blocks.
   194|         0|            0|            0|  0.00%|    hstack : Stack arrays in sequence horizontally (column wise).
   195|         0|            0|            0|  0.00%|    vstack : Stack arrays in sequence vertically (row wise).
   196|         0|            0|            0|  0.00%|    dstack : Stack arrays in sequence depth wise (along third dimension).
   197|         0|            0|            0|  0.00%|    column_stack : Stack 1-D arrays as columns into a 2-D array.
   198|         0|            0|            0|  0.00%|
   199|         0|            0|            0|  0.00%|    Notes
   200|         0|            0|            0|  0.00%|    -----
   201|         0|            0|            0|  0.00%|    When one or more of the arrays to be concatenated is a MaskedArray,
   202|         0|            0|            0|  0.00%|    this function will return a MaskedArray object instead of an ndarray,
   203|         0|            0|            0|  0.00%|    but the input masks are *not* preserved. In cases where a MaskedArray
   204|         0|            0|            0|  0.00%|    is expected as input, use the ma.concatenate function from the masked
   205|         0|            0|            0|  0.00%|    array module instead.
   206|         0|            0|            0|  0.00%|
   207|         0|            0|            0|  0.00%|    Examples
   208|         0|            0|            0|  0.00%|    --------
   209|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2], [3, 4]])
   210|         0|            0|            0|  0.00%|    >>> b = np.array([[5, 6]])
   211|         0|            0|            0|  0.00%|    >>> np.concatenate((a, b), axis=0)
   212|         0|            0|            0|  0.00%|    array([[1, 2],
   213|         0|            0|            0|  0.00%|           [3, 4],
   214|         0|            0|            0|  0.00%|           [5, 6]])
   215|         0|            0|            0|  0.00%|    >>> np.concatenate((a, b.T), axis=1)
   216|         0|            0|            0|  0.00%|    array([[1, 2, 5],
   217|         0|            0|            0|  0.00%|           [3, 4, 6]])
   218|         0|            0|            0|  0.00%|    >>> np.concatenate((a, b), axis=None)
   219|         0|            0|            0|  0.00%|    array([1, 2, 3, 4, 5, 6])
   220|         0|            0|            0|  0.00%|
   221|         0|            0|            0|  0.00%|    This function will not preserve masking of MaskedArray inputs.
   222|         0|            0|            0|  0.00%|
   223|         0|            0|            0|  0.00%|    >>> a = np.ma.arange(3)
   224|         0|            0|            0|  0.00%|    >>> a[1] = np.ma.masked
   225|         0|            0|            0|  0.00%|    >>> b = np.arange(2, 5)
   226|         0|            0|            0|  0.00%|    >>> a
   227|         0|            0|            0|  0.00%|    masked_array(data=[0, --, 2],
   228|         0|            0|            0|  0.00%|                 mask=[False,  True, False],
   229|         0|            0|            0|  0.00%|           fill_value=999999)
   230|         0|            0|            0|  0.00%|    >>> b
   231|         0|            0|            0|  0.00%|    array([2, 3, 4])
   232|         0|            0|            0|  0.00%|    >>> np.concatenate([a, b])
   233|         0|            0|            0|  0.00%|    masked_array(data=[0, 1, 2, 2, 3, 4],
   234|         0|            0|            0|  0.00%|                 mask=False,
   235|         0|            0|            0|  0.00%|           fill_value=999999)
   236|         0|            0|            0|  0.00%|    >>> np.ma.concatenate([a, b])
   237|         0|            0|            0|  0.00%|    masked_array(data=[0, --, 2, 2, 3, 4],
   238|         0|            0|            0|  0.00%|                 mask=[False,  True, False, False, False, False],
   239|         0|            0|            0|  0.00%|           fill_value=999999)
   240|         0|            0|            0|  0.00%|
   241|         0|            0|            0|  0.00%|    """
   242|         0|            0|            0|  0.00%|    if out is not None:
   243|         0|            0|            0|  0.00%|        # optimize for the typical case where only arrays is provided
   244|         0|            0|            0|  0.00%|        arrays = list(arrays)
   245|         0|            0|            0|  0.00%|        arrays.append(out)
   246|         0|            0|            0|  0.00%|    return arrays
   247|         0|            0|            0|  0.00%|
   248|         0|            0|            0|  0.00%|
   249|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.inner)
   250|         0|            0|            0|  0.00%|def inner(a, b):
   251|         0|            0|            0|  0.00%|    """
   252|         0|            0|            0|  0.00%|    inner(a, b, /)
   253|         0|            0|            0|  0.00%|
   254|         0|            0|            0|  0.00%|    Inner product of two arrays.
   255|         0|            0|            0|  0.00%|
   256|         0|            0|            0|  0.00%|    Ordinary inner product of vectors for 1-D arrays (without complex
   257|         0|            0|            0|  0.00%|    conjugation), in higher dimensions a sum product over the last axes.
   258|         0|            0|            0|  0.00%|
   259|         0|            0|            0|  0.00%|    Parameters
   260|         0|            0|            0|  0.00%|    ----------
   261|         0|            0|            0|  0.00%|    a, b : array_like
   262|         0|            0|            0|  0.00%|        If `a` and `b` are nonscalar, their last dimensions must match.
   263|         0|            0|            0|  0.00%|
   264|         0|            0|            0|  0.00%|    Returns
   265|         0|            0|            0|  0.00%|    -------
   266|         0|            0|            0|  0.00%|    out : ndarray
   267|         0|            0|            0|  0.00%|        If `a` and `b` are both
   268|         0|            0|            0|  0.00%|        scalars or both 1-D arrays then a scalar is returned; otherwise
   269|         0|            0|            0|  0.00%|        an array is returned.
   270|         0|            0|            0|  0.00%|        ``out.shape = (*a.shape[:-1], *b.shape[:-1])``
   271|         0|            0|            0|  0.00%|
   272|         0|            0|            0|  0.00%|    Raises
   273|         0|            0|            0|  0.00%|    ------
   274|         0|            0|            0|  0.00%|    ValueError
   275|         0|            0|            0|  0.00%|        If both `a` and `b` are nonscalar and their last dimensions have
   276|         0|            0|            0|  0.00%|        different sizes.
   277|         0|            0|            0|  0.00%|
   278|         0|            0|            0|  0.00%|    See Also
   279|         0|            0|            0|  0.00%|    --------
   280|         0|            0|            0|  0.00%|    tensordot : Sum products over arbitrary axes.
   281|         0|            0|            0|  0.00%|    dot : Generalised matrix product, using second last dimension of `b`.
   282|         0|            0|            0|  0.00%|    einsum : Einstein summation convention.
   283|         0|            0|            0|  0.00%|
   284|         0|            0|            0|  0.00%|    Notes
   285|         0|            0|            0|  0.00%|    -----
   286|         0|            0|            0|  0.00%|    For vectors (1-D arrays) it computes the ordinary inner-product::
   287|         0|            0|            0|  0.00%|
   288|         0|            0|            0|  0.00%|        np.inner(a, b) = sum(a[:]*b[:])
   289|         0|            0|            0|  0.00%|
   290|         0|            0|            0|  0.00%|    More generally, if `ndim(a) = r > 0` and `ndim(b) = s > 0`::
   291|         0|            0|            0|  0.00%|
   292|         0|            0|            0|  0.00%|        np.inner(a, b) = np.tensordot(a, b, axes=(-1,-1))
   293|         0|            0|            0|  0.00%|
   294|         0|            0|            0|  0.00%|    or explicitly::
   295|         0|            0|            0|  0.00%|
   296|         0|            0|            0|  0.00%|        np.inner(a, b)[i0,...,ir-2,j0,...,js-2]
   297|         0|            0|            0|  0.00%|             = sum(a[i0,...,ir-2,:]*b[j0,...,js-2,:])
   298|         0|            0|            0|  0.00%|
   299|         0|            0|            0|  0.00%|    In addition `a` or `b` may be scalars, in which case::
   300|         0|            0|            0|  0.00%|
   301|         0|            0|            0|  0.00%|       np.inner(a,b) = a*b
   302|         0|            0|            0|  0.00%|
   303|         0|            0|            0|  0.00%|    Examples
   304|         0|            0|            0|  0.00%|    --------
   305|         0|            0|            0|  0.00%|    Ordinary inner product for vectors:
   306|         0|            0|            0|  0.00%|
   307|         0|            0|            0|  0.00%|    >>> a = np.array([1,2,3])
   308|         0|            0|            0|  0.00%|    >>> b = np.array([0,1,0])
   309|         0|            0|            0|  0.00%|    >>> np.inner(a, b)
   310|         0|            0|            0|  0.00%|    2
   311|         0|            0|            0|  0.00%|
   312|         0|            0|            0|  0.00%|    Some multidimensional examples:
   313|         0|            0|            0|  0.00%|
   314|         0|            0|            0|  0.00%|    >>> a = np.arange(24).reshape((2,3,4))
   315|         0|            0|            0|  0.00%|    >>> b = np.arange(4)
   316|         0|            0|            0|  0.00%|    >>> c = np.inner(a, b)
   317|         0|            0|            0|  0.00%|    >>> c.shape
   318|         0|            0|            0|  0.00%|    (2, 3)
   319|         0|            0|            0|  0.00%|    >>> c
   320|         0|            0|            0|  0.00%|    array([[ 14,  38,  62],
   321|         0|            0|            0|  0.00%|           [ 86, 110, 134]])
   322|         0|            0|            0|  0.00%|
   323|         0|            0|            0|  0.00%|    >>> a = np.arange(2).reshape((1,1,2))
   324|         0|            0|            0|  0.00%|    >>> b = np.arange(6).reshape((3,2))
   325|         0|            0|            0|  0.00%|    >>> c = np.inner(a, b)
   326|         0|            0|            0|  0.00%|    >>> c.shape
   327|         0|            0|            0|  0.00%|    (1, 1, 3)
   328|         0|            0|            0|  0.00%|    >>> c
   329|         0|            0|            0|  0.00%|    array([[[1, 3, 5]]])
   330|         0|            0|            0|  0.00%|
   331|         0|            0|            0|  0.00%|    An example where `b` is a scalar:
   332|         0|            0|            0|  0.00%|
   333|         0|            0|            0|  0.00%|    >>> np.inner(np.eye(2), 7)
   334|         0|            0|            0|  0.00%|    array([[7., 0.],
   335|         0|            0|            0|  0.00%|           [0., 7.]])
   336|         0|            0|            0|  0.00%|
   337|         0|            0|            0|  0.00%|    """
   338|         0|            0|            0|  0.00%|    return (a, b)
   339|         0|            0|            0|  0.00%|
   340|         0|            0|            0|  0.00%|
   341|     59335|      0.10183|  1.71618e-06|  0.10%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.where)
   342|         0|            0|            0|  0.00%|def where(condition, x=None, y=None):
   343|         0|            0|            0|  0.00%|    """
   344|         0|            0|            0|  0.00%|    where(condition, [x, y], /)
   345|         0|            0|            0|  0.00%|
   346|         0|            0|            0|  0.00%|    Return elements chosen from `x` or `y` depending on `condition`.
   347|         0|            0|            0|  0.00%|
   348|         0|            0|            0|  0.00%|    .. note::
   349|         0|            0|            0|  0.00%|        When only `condition` is provided, this function is a shorthand for
   350|         0|            0|            0|  0.00%|        ``np.asarray(condition).nonzero()``. Using `nonzero` directly should be
   351|         0|            0|            0|  0.00%|        preferred, as it behaves correctly for subclasses. The rest of this
   352|         0|            0|            0|  0.00%|        documentation covers only the case where all three arguments are
   353|         0|            0|            0|  0.00%|        provided.
   354|         0|            0|            0|  0.00%|
   355|         0|            0|            0|  0.00%|    Parameters
   356|         0|            0|            0|  0.00%|    ----------
   357|         0|            0|            0|  0.00%|    condition : array_like, bool
   358|         0|            0|            0|  0.00%|        Where True, yield `x`, otherwise yield `y`.
   359|         0|            0|            0|  0.00%|    x, y : array_like
   360|         0|            0|            0|  0.00%|        Values from which to choose. `x`, `y` and `condition` need to be
   361|         0|            0|            0|  0.00%|        broadcastable to some shape.
   362|         0|            0|            0|  0.00%|
   363|         0|            0|            0|  0.00%|    Returns
   364|         0|            0|            0|  0.00%|    -------
   365|         0|            0|            0|  0.00%|    out : ndarray
   366|         0|            0|            0|  0.00%|        An array with elements from `x` where `condition` is True, and elements
   367|         0|            0|            0|  0.00%|        from `y` elsewhere.
   368|         0|            0|            0|  0.00%|
   369|         0|            0|            0|  0.00%|    See Also
   370|         0|            0|            0|  0.00%|    --------
   371|         0|            0|            0|  0.00%|    choose
   372|         0|            0|            0|  0.00%|    nonzero : The function that is called when x and y are omitted
   373|         0|            0|            0|  0.00%|
   374|         0|            0|            0|  0.00%|    Notes
   375|         0|            0|            0|  0.00%|    -----
   376|         0|            0|            0|  0.00%|    If all the arrays are 1-D, `where` is equivalent to::
   377|         0|            0|            0|  0.00%|
   378|         0|            0|            0|  0.00%|        [xv if c else yv
   379|         0|            0|            0|  0.00%|         for c, xv, yv in zip(condition, x, y)]
   380|         0|            0|            0|  0.00%|
   381|         0|            0|            0|  0.00%|    Examples
   382|         0|            0|            0|  0.00%|    --------
   383|         0|            0|            0|  0.00%|    >>> a = np.arange(10)
   384|         0|            0|            0|  0.00%|    >>> a
   385|         0|            0|            0|  0.00%|    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
   386|         0|            0|            0|  0.00%|    >>> np.where(a < 5, a, 10*a)
   387|         0|            0|            0|  0.00%|    array([ 0,  1,  2,  3,  4, 50, 60, 70, 80, 90])
   388|         0|            0|            0|  0.00%|
   389|         0|            0|            0|  0.00%|    This can be used on multidimensional arrays too:
   390|         0|            0|            0|  0.00%|
   391|         0|            0|            0|  0.00%|    >>> np.where([[True, False], [True, True]],
   392|         0|            0|            0|  0.00%|    ...          [[1, 2], [3, 4]],
   393|         0|            0|            0|  0.00%|    ...          [[9, 8], [7, 6]])
   394|         0|            0|            0|  0.00%|    array([[1, 8],
   395|         0|            0|            0|  0.00%|           [3, 4]])
   396|         0|            0|            0|  0.00%|
   397|         0|            0|            0|  0.00%|    The shapes of x, y, and the condition are broadcast together:
   398|         0|            0|            0|  0.00%|
   399|         0|            0|            0|  0.00%|    >>> x, y = np.ogrid[:3, :4]
   400|         0|            0|            0|  0.00%|    >>> np.where(x < y, x, 10 + y)  # both x and 10+y are broadcast
   401|         0|            0|            0|  0.00%|    array([[10,  0,  0,  0],
   402|         0|            0|            0|  0.00%|           [10, 11,  1,  1],
   403|         0|            0|            0|  0.00%|           [10, 11, 12,  2]])
   404|         0|            0|            0|  0.00%|
   405|         0|            0|            0|  0.00%|    >>> a = np.array([[0, 1, 2],
   406|         0|            0|            0|  0.00%|    ...               [0, 2, 4],
   407|         0|            0|            0|  0.00%|    ...               [0, 3, 6]])
   408|         0|            0|            0|  0.00%|    >>> np.where(a < 4, a, -1)  # -1 is broadcast
   409|         0|            0|            0|  0.00%|    array([[ 0,  1,  2],
   410|         0|            0|            0|  0.00%|           [ 0,  2, -1],
   411|         0|            0|            0|  0.00%|           [ 0,  3, -1]])
   412|         0|            0|            0|  0.00%|    """
   413|     59335|     0.127776|  2.15347e-06|  0.12%|    return (condition, x, y)
   414|         0|            0|            0|  0.00%|
   415|         0|            0|            0|  0.00%|
   416|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.lexsort)
   417|         0|            0|            0|  0.00%|def lexsort(keys, axis=None):
   418|         0|            0|            0|  0.00%|    """
   419|         0|            0|            0|  0.00%|    lexsort(keys, axis=-1)
   420|         0|            0|            0|  0.00%|
   421|         0|            0|            0|  0.00%|    Perform an indirect stable sort using a sequence of keys.
   422|         0|            0|            0|  0.00%|
   423|         0|            0|            0|  0.00%|    Given multiple sorting keys, which can be interpreted as columns in a
   424|         0|            0|            0|  0.00%|    spreadsheet, lexsort returns an array of integer indices that describes
   425|         0|            0|            0|  0.00%|    the sort order by multiple columns. The last key in the sequence is used
   426|         0|            0|            0|  0.00%|    for the primary sort order, the second-to-last key for the secondary sort
   427|         0|            0|            0|  0.00%|    order, and so on. The keys argument must be a sequence of objects that
   428|         0|            0|            0|  0.00%|    can be converted to arrays of the same shape. If a 2D array is provided
   429|         0|            0|            0|  0.00%|    for the keys argument, its rows are interpreted as the sorting keys and
   430|         0|            0|            0|  0.00%|    sorting is according to the last row, second last row etc.
   431|         0|            0|            0|  0.00%|
   432|         0|            0|            0|  0.00%|    Parameters
   433|         0|            0|            0|  0.00%|    ----------
   434|         0|            0|            0|  0.00%|    keys : (k, N) array or tuple containing k (N,)-shaped sequences
   435|         0|            0|            0|  0.00%|        The `k` different "columns" to be sorted.  The last column (or row if
   436|         0|            0|            0|  0.00%|        `keys` is a 2D array) is the primary sort key.
   437|         0|            0|            0|  0.00%|    axis : int, optional
   438|         0|            0|            0|  0.00%|        Axis to be indirectly sorted.  By default, sort over the last axis.
   439|         0|            0|            0|  0.00%|
   440|         0|            0|            0|  0.00%|    Returns
   441|         0|            0|            0|  0.00%|    -------
   442|         0|            0|            0|  0.00%|    indices : (N,) ndarray of ints
   443|         0|            0|            0|  0.00%|        Array of indices that sort the keys along the specified axis.
   444|         0|            0|            0|  0.00%|
   445|         0|            0|            0|  0.00%|    See Also
   446|         0|            0|            0|  0.00%|    --------
   447|         0|            0|            0|  0.00%|    argsort : Indirect sort.
   448|         0|            0|            0|  0.00%|    ndarray.sort : In-place sort.
   449|         0|            0|            0|  0.00%|    sort : Return a sorted copy of an array.
   450|         0|            0|            0|  0.00%|
   451|         0|            0|            0|  0.00%|    Examples
   452|         0|            0|            0|  0.00%|    --------
   453|         0|            0|            0|  0.00%|    Sort names: first by surname, then by name.
   454|         0|            0|            0|  0.00%|
   455|         0|            0|            0|  0.00%|    >>> surnames =    ('Hertz',    'Galilei', 'Hertz')
   456|         0|            0|            0|  0.00%|    >>> first_names = ('Heinrich', 'Galileo', 'Gustav')
   457|         0|            0|            0|  0.00%|    >>> ind = np.lexsort((first_names, surnames))
   458|         0|            0|            0|  0.00%|    >>> ind
   459|         0|            0|            0|  0.00%|    array([1, 2, 0])
   460|         0|            0|            0|  0.00%|
   461|         0|            0|            0|  0.00%|    >>> [surnames[i] + ", " + first_names[i] for i in ind]
   462|         0|            0|            0|  0.00%|    ['Galilei, Galileo', 'Hertz, Gustav', 'Hertz, Heinrich']
   463|         0|            0|            0|  0.00%|
   464|         0|            0|            0|  0.00%|    Sort two columns of numbers:
   465|         0|            0|            0|  0.00%|
   466|         0|            0|            0|  0.00%|    >>> a = [1,5,1,4,3,4,4] # First column
   467|         0|            0|            0|  0.00%|    >>> b = [9,4,0,4,0,2,1] # Second column
   468|         0|            0|            0|  0.00%|    >>> ind = np.lexsort((b,a)) # Sort by a, then by b
   469|         0|            0|            0|  0.00%|    >>> ind
   470|         0|            0|            0|  0.00%|    array([2, 0, 4, 6, 5, 3, 1])
   471|         0|            0|            0|  0.00%|
   472|         0|            0|            0|  0.00%|    >>> [(a[i],b[i]) for i in ind]
   473|         0|            0|            0|  0.00%|    [(1, 0), (1, 9), (3, 0), (4, 1), (4, 2), (4, 4), (5, 4)]
   474|         0|            0|            0|  0.00%|
   475|         0|            0|            0|  0.00%|    Note that sorting is first according to the elements of ``a``.
   476|         0|            0|            0|  0.00%|    Secondary sorting is according to the elements of ``b``.
   477|         0|            0|            0|  0.00%|
   478|         0|            0|            0|  0.00%|    A normal ``argsort`` would have yielded:
   479|         0|            0|            0|  0.00%|
   480|         0|            0|            0|  0.00%|    >>> [(a[i],b[i]) for i in np.argsort(a)]
   481|         0|            0|            0|  0.00%|    [(1, 9), (1, 0), (3, 0), (4, 4), (4, 2), (4, 1), (5, 4)]
   482|         0|            0|            0|  0.00%|
   483|         0|            0|            0|  0.00%|    Structured arrays are sorted lexically by ``argsort``:
   484|         0|            0|            0|  0.00%|
   485|         0|            0|            0|  0.00%|    >>> x = np.array([(1,9), (5,4), (1,0), (4,4), (3,0), (4,2), (4,1)],
   486|         0|            0|            0|  0.00%|    ...              dtype=np.dtype([('x', int), ('y', int)]))
   487|         0|            0|            0|  0.00%|
   488|         0|            0|            0|  0.00%|    >>> np.argsort(x) # or np.argsort(x, order=('x', 'y'))
   489|         0|            0|            0|  0.00%|    array([2, 0, 4, 6, 5, 3, 1])
   490|         0|            0|            0|  0.00%|
   491|         0|            0|            0|  0.00%|    """
   492|         0|            0|            0|  0.00%|    if isinstance(keys, tuple):
   493|         0|            0|            0|  0.00%|        return keys
   494|         0|            0|            0|  0.00%|    else:
   495|         0|            0|            0|  0.00%|        return (keys,)
   496|         0|            0|            0|  0.00%|
   497|         0|            0|            0|  0.00%|
   498|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.can_cast)
   499|         0|            0|            0|  0.00%|def can_cast(from_, to, casting=None):
   500|         0|            0|            0|  0.00%|    """
   501|         0|            0|            0|  0.00%|    can_cast(from_, to, casting='safe')
   502|         0|            0|            0|  0.00%|
   503|         0|            0|            0|  0.00%|    Returns True if cast between data types can occur according to the
   504|         0|            0|            0|  0.00%|    casting rule.  If from is a scalar or array scalar, also returns
   505|         0|            0|            0|  0.00%|    True if the scalar value can be cast without overflow or truncation
   506|         0|            0|            0|  0.00%|    to an integer.
   507|         0|            0|            0|  0.00%|
   508|         0|            0|            0|  0.00%|    Parameters
   509|         0|            0|            0|  0.00%|    ----------
   510|         0|            0|            0|  0.00%|    from_ : dtype, dtype specifier, scalar, or array
   511|         0|            0|            0|  0.00%|        Data type, scalar, or array to cast from.
   512|         0|            0|            0|  0.00%|    to : dtype or dtype specifier
   513|         0|            0|            0|  0.00%|        Data type to cast to.
   514|         0|            0|            0|  0.00%|    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
   515|         0|            0|            0|  0.00%|        Controls what kind of data casting may occur.
   516|         0|            0|            0|  0.00%|
   517|         0|            0|            0|  0.00%|          * 'no' means the data types should not be cast at all.
   518|         0|            0|            0|  0.00%|          * 'equiv' means only byte-order changes are allowed.
   519|         0|            0|            0|  0.00%|          * 'safe' means only casts which can preserve values are allowed.
   520|         0|            0|            0|  0.00%|          * 'same_kind' means only safe casts or casts within a kind,
   521|         0|            0|            0|  0.00%|            like float64 to float32, are allowed.
   522|         0|            0|            0|  0.00%|          * 'unsafe' means any data conversions may be done.
   523|         0|            0|            0|  0.00%|
   524|         0|            0|            0|  0.00%|    Returns
   525|         0|            0|            0|  0.00%|    -------
   526|         0|            0|            0|  0.00%|    out : bool
   527|         0|            0|            0|  0.00%|        True if cast can occur according to the casting rule.
   528|         0|            0|            0|  0.00%|
   529|         0|            0|            0|  0.00%|    Notes
   530|         0|            0|            0|  0.00%|    -----
   531|         0|            0|            0|  0.00%|    .. versionchanged:: 1.17.0
   532|         0|            0|            0|  0.00%|       Casting between a simple data type and a structured one is possible only
   533|         0|            0|            0|  0.00%|       for "unsafe" casting.  Casting to multiple fields is allowed, but
   534|         0|            0|            0|  0.00%|       casting from multiple fields is not.
   535|         0|            0|            0|  0.00%|
   536|         0|            0|            0|  0.00%|    .. versionchanged:: 1.9.0
   537|         0|            0|            0|  0.00%|       Casting from numeric to string types in 'safe' casting mode requires
   538|         0|            0|            0|  0.00%|       that the string dtype length is long enough to store the maximum
   539|         0|            0|            0|  0.00%|       integer/float value converted.
   540|         0|            0|            0|  0.00%|
   541|         0|            0|            0|  0.00%|    See also
   542|         0|            0|            0|  0.00%|    --------
   543|         0|            0|            0|  0.00%|    dtype, result_type
   544|         0|            0|            0|  0.00%|
   545|         0|            0|            0|  0.00%|    Examples
   546|         0|            0|            0|  0.00%|    --------
   547|         0|            0|            0|  0.00%|    Basic examples
   548|         0|            0|            0|  0.00%|
   549|         0|            0|            0|  0.00%|    >>> np.can_cast(np.int32, np.int64)
   550|         0|            0|            0|  0.00%|    True
   551|         0|            0|            0|  0.00%|    >>> np.can_cast(np.float64, complex)
   552|         0|            0|            0|  0.00%|    True
   553|         0|            0|            0|  0.00%|    >>> np.can_cast(complex, float)
   554|         0|            0|            0|  0.00%|    False
   555|         0|            0|            0|  0.00%|
   556|         0|            0|            0|  0.00%|    >>> np.can_cast('i8', 'f8')
   557|         0|            0|            0|  0.00%|    True
   558|         0|            0|            0|  0.00%|    >>> np.can_cast('i8', 'f4')
   559|         0|            0|            0|  0.00%|    False
   560|         0|            0|            0|  0.00%|    >>> np.can_cast('i4', 'S4')
   561|         0|            0|            0|  0.00%|    False
   562|         0|            0|            0|  0.00%|
   563|         0|            0|            0|  0.00%|    Casting scalars
   564|         0|            0|            0|  0.00%|
   565|         0|            0|            0|  0.00%|    >>> np.can_cast(100, 'i1')
   566|         0|            0|            0|  0.00%|    True
   567|         0|            0|            0|  0.00%|    >>> np.can_cast(150, 'i1')
   568|         0|            0|            0|  0.00%|    False
   569|         0|            0|            0|  0.00%|    >>> np.can_cast(150, 'u1')
   570|         0|            0|            0|  0.00%|    True
   571|         0|            0|            0|  0.00%|
   572|         0|            0|            0|  0.00%|    >>> np.can_cast(3.5e100, np.float32)
   573|         0|            0|            0|  0.00%|    False
   574|         0|            0|            0|  0.00%|    >>> np.can_cast(1000.0, np.float32)
   575|         0|            0|            0|  0.00%|    True
   576|         0|            0|            0|  0.00%|
   577|         0|            0|            0|  0.00%|    Array scalar checks the value, array does not
   578|         0|            0|            0|  0.00%|
   579|         0|            0|            0|  0.00%|    >>> np.can_cast(np.array(1000.0), np.float32)
   580|         0|            0|            0|  0.00%|    True
   581|         0|            0|            0|  0.00%|    >>> np.can_cast(np.array([1000.0]), np.float32)
   582|         0|            0|            0|  0.00%|    False
   583|         0|            0|            0|  0.00%|
   584|         0|            0|            0|  0.00%|    Using the casting rules
   585|         0|            0|            0|  0.00%|
   586|         0|            0|            0|  0.00%|    >>> np.can_cast('i8', 'i8', 'no')
   587|         0|            0|            0|  0.00%|    True
   588|         0|            0|            0|  0.00%|    >>> np.can_cast('<i8', '>i8', 'no')
   589|         0|            0|            0|  0.00%|    False
   590|         0|            0|            0|  0.00%|
   591|         0|            0|            0|  0.00%|    >>> np.can_cast('<i8', '>i8', 'equiv')
   592|         0|            0|            0|  0.00%|    True
   593|         0|            0|            0|  0.00%|    >>> np.can_cast('<i4', '>i8', 'equiv')
   594|         0|            0|            0|  0.00%|    False
   595|         0|            0|            0|  0.00%|
   596|         0|            0|            0|  0.00%|    >>> np.can_cast('<i4', '>i8', 'safe')
   597|         0|            0|            0|  0.00%|    True
   598|         0|            0|            0|  0.00%|    >>> np.can_cast('<i8', '>i4', 'safe')
   599|         0|            0|            0|  0.00%|    False
   600|         0|            0|            0|  0.00%|
   601|         0|            0|            0|  0.00%|    >>> np.can_cast('<i8', '>i4', 'same_kind')
   602|         0|            0|            0|  0.00%|    True
   603|         0|            0|            0|  0.00%|    >>> np.can_cast('<i8', '>u4', 'same_kind')
   604|         0|            0|            0|  0.00%|    False
   605|         0|            0|            0|  0.00%|
   606|         0|            0|            0|  0.00%|    >>> np.can_cast('<i8', '>u4', 'unsafe')
   607|         0|            0|            0|  0.00%|    True
   608|         0|            0|            0|  0.00%|
   609|         0|            0|            0|  0.00%|    """
   610|         0|            0|            0|  0.00%|    return (from_,)
   611|         0|            0|            0|  0.00%|
   612|         0|            0|            0|  0.00%|
   613|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.min_scalar_type)
   614|         0|            0|            0|  0.00%|def min_scalar_type(a):
   615|         0|            0|            0|  0.00%|    """
   616|         0|            0|            0|  0.00%|    min_scalar_type(a, /)
   617|         0|            0|            0|  0.00%|
   618|         0|            0|            0|  0.00%|    For scalar ``a``, returns the data type with the smallest size
   619|         0|            0|            0|  0.00%|    and smallest scalar kind which can hold its value.  For non-scalar
   620|         0|            0|            0|  0.00%|    array ``a``, returns the vector's dtype unmodified.
   621|         0|            0|            0|  0.00%|
   622|         0|            0|            0|  0.00%|    Floating point values are not demoted to integers,
   623|         0|            0|            0|  0.00%|    and complex values are not demoted to floats.
   624|         0|            0|            0|  0.00%|
   625|         0|            0|            0|  0.00%|    Parameters
   626|         0|            0|            0|  0.00%|    ----------
   627|         0|            0|            0|  0.00%|    a : scalar or array_like
   628|         0|            0|            0|  0.00%|        The value whose minimal data type is to be found.
   629|         0|            0|            0|  0.00%|
   630|         0|            0|            0|  0.00%|    Returns
   631|         0|            0|            0|  0.00%|    -------
   632|         0|            0|            0|  0.00%|    out : dtype
   633|         0|            0|            0|  0.00%|        The minimal data type.
   634|         0|            0|            0|  0.00%|
   635|         0|            0|            0|  0.00%|    Notes
   636|         0|            0|            0|  0.00%|    -----
   637|         0|            0|            0|  0.00%|    .. versionadded:: 1.6.0
   638|         0|            0|            0|  0.00%|
   639|         0|            0|            0|  0.00%|    See Also
   640|         0|            0|            0|  0.00%|    --------
   641|         0|            0|            0|  0.00%|    result_type, promote_types, dtype, can_cast
   642|         0|            0|            0|  0.00%|
   643|         0|            0|            0|  0.00%|    Examples
   644|         0|            0|            0|  0.00%|    --------
   645|         0|            0|            0|  0.00%|    >>> np.min_scalar_type(10)
   646|         0|            0|            0|  0.00%|    dtype('uint8')
   647|         0|            0|            0|  0.00%|
   648|         0|            0|            0|  0.00%|    >>> np.min_scalar_type(-260)
   649|         0|            0|            0|  0.00%|    dtype('int16')
   650|         0|            0|            0|  0.00%|
   651|         0|            0|            0|  0.00%|    >>> np.min_scalar_type(3.1)
   652|         0|            0|            0|  0.00%|    dtype('float16')
   653|         0|            0|            0|  0.00%|
   654|         0|            0|            0|  0.00%|    >>> np.min_scalar_type(1e50)
   655|         0|            0|            0|  0.00%|    dtype('float64')
   656|         0|            0|            0|  0.00%|
   657|         0|            0|            0|  0.00%|    >>> np.min_scalar_type(np.arange(4,dtype='f8'))
   658|         0|            0|            0|  0.00%|    dtype('float64')
   659|         0|            0|            0|  0.00%|
   660|         0|            0|            0|  0.00%|    """
   661|         0|            0|            0|  0.00%|    return (a,)
   662|         0|            0|            0|  0.00%|
   663|         0|            0|            0|  0.00%|
   664|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.result_type)
   665|         0|            0|            0|  0.00%|def result_type(*arrays_and_dtypes):
   666|         0|            0|            0|  0.00%|    """
   667|         0|            0|            0|  0.00%|    result_type(*arrays_and_dtypes)
   668|         0|            0|            0|  0.00%|
   669|         0|            0|            0|  0.00%|    Returns the type that results from applying the NumPy
   670|         0|            0|            0|  0.00%|    type promotion rules to the arguments.
   671|         0|            0|            0|  0.00%|
   672|         0|            0|            0|  0.00%|    Type promotion in NumPy works similarly to the rules in languages
   673|         0|            0|            0|  0.00%|    like C++, with some slight differences.  When both scalars and
   674|         0|            0|            0|  0.00%|    arrays are used, the array's type takes precedence and the actual value
   675|         0|            0|            0|  0.00%|    of the scalar is taken into account.
   676|         0|            0|            0|  0.00%|
   677|         0|            0|            0|  0.00%|    For example, calculating 3*a, where a is an array of 32-bit floats,
   678|         0|            0|            0|  0.00%|    intuitively should result in a 32-bit float output.  If the 3 is a
   679|         0|            0|            0|  0.00%|    32-bit integer, the NumPy rules indicate it can't convert losslessly
   680|         0|            0|            0|  0.00%|    into a 32-bit float, so a 64-bit float should be the result type.
   681|         0|            0|            0|  0.00%|    By examining the value of the constant, '3', we see that it fits in
   682|         0|            0|            0|  0.00%|    an 8-bit integer, which can be cast losslessly into the 32-bit float.
   683|         0|            0|            0|  0.00%|
   684|         0|            0|            0|  0.00%|    Parameters
   685|         0|            0|            0|  0.00%|    ----------
   686|         0|            0|            0|  0.00%|    arrays_and_dtypes : list of arrays and dtypes
   687|         0|            0|            0|  0.00%|        The operands of some operation whose result type is needed.
   688|         0|            0|            0|  0.00%|
   689|         0|            0|            0|  0.00%|    Returns
   690|         0|            0|            0|  0.00%|    -------
   691|         0|            0|            0|  0.00%|    out : dtype
   692|         0|            0|            0|  0.00%|        The result type.
   693|         0|            0|            0|  0.00%|
   694|         0|            0|            0|  0.00%|    See also
   695|         0|            0|            0|  0.00%|    --------
   696|         0|            0|            0|  0.00%|    dtype, promote_types, min_scalar_type, can_cast
   697|         0|            0|            0|  0.00%|
   698|         0|            0|            0|  0.00%|    Notes
   699|         0|            0|            0|  0.00%|    -----
   700|         0|            0|            0|  0.00%|    .. versionadded:: 1.6.0
   701|         0|            0|            0|  0.00%|
   702|         0|            0|            0|  0.00%|    The specific algorithm used is as follows.
   703|         0|            0|            0|  0.00%|
   704|         0|            0|            0|  0.00%|    Categories are determined by first checking which of boolean,
   705|         0|            0|            0|  0.00%|    integer (int/uint), or floating point (float/complex) the maximum
   706|         0|            0|            0|  0.00%|    kind of all the arrays and the scalars are.
   707|         0|            0|            0|  0.00%|
   708|         0|            0|            0|  0.00%|    If there are only scalars or the maximum category of the scalars
   709|         0|            0|            0|  0.00%|    is higher than the maximum category of the arrays,
   710|         0|            0|            0|  0.00%|    the data types are combined with :func:`promote_types`
   711|         0|            0|            0|  0.00%|    to produce the return value.
   712|         0|            0|            0|  0.00%|
   713|         0|            0|            0|  0.00%|    Otherwise, `min_scalar_type` is called on each array, and
   714|         0|            0|            0|  0.00%|    the resulting data types are all combined with :func:`promote_types`
   715|         0|            0|            0|  0.00%|    to produce the return value.
   716|         0|            0|            0|  0.00%|
   717|         0|            0|            0|  0.00%|    The set of int values is not a subset of the uint values for types
   718|         0|            0|            0|  0.00%|    with the same number of bits, something not reflected in
   719|         0|            0|            0|  0.00%|    :func:`min_scalar_type`, but handled as a special case in `result_type`.
   720|         0|            0|            0|  0.00%|
   721|         0|            0|            0|  0.00%|    Examples
   722|         0|            0|            0|  0.00%|    --------
   723|         0|            0|            0|  0.00%|    >>> np.result_type(3, np.arange(7, dtype='i1'))
   724|         0|            0|            0|  0.00%|    dtype('int8')
   725|         0|            0|            0|  0.00%|
   726|         0|            0|            0|  0.00%|    >>> np.result_type('i4', 'c8')
   727|         0|            0|            0|  0.00%|    dtype('complex128')
   728|         0|            0|            0|  0.00%|
   729|         0|            0|            0|  0.00%|    >>> np.result_type(3.0, -2)
   730|         0|            0|            0|  0.00%|    dtype('float64')
   731|         0|            0|            0|  0.00%|
   732|         0|            0|            0|  0.00%|    """
   733|         0|            0|            0|  0.00%|    return arrays_and_dtypes
   734|         0|            0|            0|  0.00%|
   735|         0|            0|            0|  0.00%|
   736|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.dot)
   737|         0|            0|            0|  0.00%|def dot(a, b, out=None):
   738|         0|            0|            0|  0.00%|    """
   739|         0|            0|            0|  0.00%|    dot(a, b, out=None)
   740|         0|            0|            0|  0.00%|
   741|         0|            0|            0|  0.00%|    Dot product of two arrays. Specifically,
   742|         0|            0|            0|  0.00%|
   743|         0|            0|            0|  0.00%|    - If both `a` and `b` are 1-D arrays, it is inner product of vectors
   744|         0|            0|            0|  0.00%|      (without complex conjugation).
   745|         0|            0|            0|  0.00%|
   746|         0|            0|            0|  0.00%|    - If both `a` and `b` are 2-D arrays, it is matrix multiplication,
   747|         0|            0|            0|  0.00%|      but using :func:`matmul` or ``a @ b`` is preferred.
   748|         0|            0|            0|  0.00%|
   749|         0|            0|            0|  0.00%|    - If either `a` or `b` is 0-D (scalar), it is equivalent to :func:`multiply`
   750|         0|            0|            0|  0.00%|      and using ``numpy.multiply(a, b)`` or ``a * b`` is preferred.
   751|         0|            0|            0|  0.00%|
   752|         0|            0|            0|  0.00%|    - If `a` is an N-D array and `b` is a 1-D array, it is a sum product over
   753|         0|            0|            0|  0.00%|      the last axis of `a` and `b`.
   754|         0|            0|            0|  0.00%|
   755|         0|            0|            0|  0.00%|    - If `a` is an N-D array and `b` is an M-D array (where ``M>=2``), it is a
   756|         0|            0|            0|  0.00%|      sum product over the last axis of `a` and the second-to-last axis of `b`::
   757|         0|            0|            0|  0.00%|
   758|         0|            0|            0|  0.00%|        dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])
   759|         0|            0|            0|  0.00%|
   760|         0|            0|            0|  0.00%|    Parameters
   761|         0|            0|            0|  0.00%|    ----------
   762|         0|            0|            0|  0.00%|    a : array_like
   763|         0|            0|            0|  0.00%|        First argument.
   764|         0|            0|            0|  0.00%|    b : array_like
   765|         0|            0|            0|  0.00%|        Second argument.
   766|         0|            0|            0|  0.00%|    out : ndarray, optional
   767|         0|            0|            0|  0.00%|        Output argument. This must have the exact kind that would be returned
   768|         0|            0|            0|  0.00%|        if it was not used. In particular, it must have the right type, must be
   769|         0|            0|            0|  0.00%|        C-contiguous, and its dtype must be the dtype that would be returned
   770|         0|            0|            0|  0.00%|        for `dot(a,b)`. This is a performance feature. Therefore, if these
   771|         0|            0|            0|  0.00%|        conditions are not met, an exception is raised, instead of attempting
   772|         0|            0|            0|  0.00%|        to be flexible.
   773|         0|            0|            0|  0.00%|
   774|         0|            0|            0|  0.00%|    Returns
   775|         0|            0|            0|  0.00%|    -------
   776|         0|            0|            0|  0.00%|    output : ndarray
   777|         0|            0|            0|  0.00%|        Returns the dot product of `a` and `b`.  If `a` and `b` are both
   778|         0|            0|            0|  0.00%|        scalars or both 1-D arrays then a scalar is returned; otherwise
   779|         0|            0|            0|  0.00%|        an array is returned.
   780|         0|            0|            0|  0.00%|        If `out` is given, then it is returned.
   781|         0|            0|            0|  0.00%|
   782|         0|            0|            0|  0.00%|    Raises
   783|         0|            0|            0|  0.00%|    ------
   784|         0|            0|            0|  0.00%|    ValueError
   785|         0|            0|            0|  0.00%|        If the last dimension of `a` is not the same size as
   786|         0|            0|            0|  0.00%|        the second-to-last dimension of `b`.
   787|         0|            0|            0|  0.00%|
   788|         0|            0|            0|  0.00%|    See Also
   789|         0|            0|            0|  0.00%|    --------
   790|         0|            0|            0|  0.00%|    vdot : Complex-conjugating dot product.
   791|         0|            0|            0|  0.00%|    tensordot : Sum products over arbitrary axes.
   792|         0|            0|            0|  0.00%|    einsum : Einstein summation convention.
   793|         0|            0|            0|  0.00%|    matmul : '@' operator as method with out parameter.
   794|         0|            0|            0|  0.00%|    linalg.multi_dot : Chained dot product.
   795|         0|            0|            0|  0.00%|
   796|         0|            0|            0|  0.00%|    Examples
   797|         0|            0|            0|  0.00%|    --------
   798|         0|            0|            0|  0.00%|    >>> np.dot(3, 4)
   799|         0|            0|            0|  0.00%|    12
   800|         0|            0|            0|  0.00%|
   801|         0|            0|            0|  0.00%|    Neither argument is complex-conjugated:
   802|         0|            0|            0|  0.00%|
   803|         0|            0|            0|  0.00%|    >>> np.dot([2j, 3j], [2j, 3j])
   804|         0|            0|            0|  0.00%|    (-13+0j)
   805|         0|            0|            0|  0.00%|
   806|         0|            0|            0|  0.00%|    For 2-D arrays it is the matrix product:
   807|         0|            0|            0|  0.00%|
   808|         0|            0|            0|  0.00%|    >>> a = [[1, 0], [0, 1]]
   809|         0|            0|            0|  0.00%|    >>> b = [[4, 1], [2, 2]]
   810|         0|            0|            0|  0.00%|    >>> np.dot(a, b)
   811|         0|            0|            0|  0.00%|    array([[4, 1],
   812|         0|            0|            0|  0.00%|           [2, 2]])
   813|         0|            0|            0|  0.00%|
   814|         0|            0|            0|  0.00%|    >>> a = np.arange(3*4*5*6).reshape((3,4,5,6))
   815|         0|            0|            0|  0.00%|    >>> b = np.arange(3*4*5*6)[::-1].reshape((5,4,6,3))
   816|         0|            0|            0|  0.00%|    >>> np.dot(a, b)[2,3,2,1,2,2]
   817|         0|            0|            0|  0.00%|    499128
   818|         0|            0|            0|  0.00%|    >>> sum(a[2,3,2,:] * b[1,2,:,2])
   819|         0|            0|            0|  0.00%|    499128
   820|         0|            0|            0|  0.00%|
   821|         0|            0|            0|  0.00%|    """
   822|         0|            0|            0|  0.00%|    return (a, b, out)
   823|         0|            0|            0|  0.00%|
   824|         0|            0|            0|  0.00%|
   825|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.vdot)
   826|         0|            0|            0|  0.00%|def vdot(a, b):
   827|         0|            0|            0|  0.00%|    """
   828|         0|            0|            0|  0.00%|    vdot(a, b, /)
   829|         0|            0|            0|  0.00%|
   830|         0|            0|            0|  0.00%|    Return the dot product of two vectors.
   831|         0|            0|            0|  0.00%|
   832|         0|            0|            0|  0.00%|    The vdot(`a`, `b`) function handles complex numbers differently than
   833|         0|            0|            0|  0.00%|    dot(`a`, `b`).  If the first argument is complex the complex conjugate
   834|         0|            0|            0|  0.00%|    of the first argument is used for the calculation of the dot product.
   835|         0|            0|            0|  0.00%|
   836|         0|            0|            0|  0.00%|    Note that `vdot` handles multidimensional arrays differently than `dot`:
   837|         0|            0|            0|  0.00%|    it does *not* perform a matrix product, but flattens input arguments
   838|         0|            0|            0|  0.00%|    to 1-D vectors first. Consequently, it should only be used for vectors.
   839|         0|            0|            0|  0.00%|
   840|         0|            0|            0|  0.00%|    Parameters
   841|         0|            0|            0|  0.00%|    ----------
   842|         0|            0|            0|  0.00%|    a : array_like
   843|         0|            0|            0|  0.00%|        If `a` is complex the complex conjugate is taken before calculation
   844|         0|            0|            0|  0.00%|        of the dot product.
   845|         0|            0|            0|  0.00%|    b : array_like
   846|         0|            0|            0|  0.00%|        Second argument to the dot product.
   847|         0|            0|            0|  0.00%|
   848|         0|            0|            0|  0.00%|    Returns
   849|         0|            0|            0|  0.00%|    -------
   850|         0|            0|            0|  0.00%|    output : ndarray
   851|         0|            0|            0|  0.00%|        Dot product of `a` and `b`.  Can be an int, float, or
   852|         0|            0|            0|  0.00%|        complex depending on the types of `a` and `b`.
   853|         0|            0|            0|  0.00%|
   854|         0|            0|            0|  0.00%|    See Also
   855|         0|            0|            0|  0.00%|    --------
   856|         0|            0|            0|  0.00%|    dot : Return the dot product without using the complex conjugate of the
   857|         0|            0|            0|  0.00%|          first argument.
   858|         0|            0|            0|  0.00%|
   859|         0|            0|            0|  0.00%|    Examples
   860|         0|            0|            0|  0.00%|    --------
   861|         0|            0|            0|  0.00%|    >>> a = np.array([1+2j,3+4j])
   862|         0|            0|            0|  0.00%|    >>> b = np.array([5+6j,7+8j])
   863|         0|            0|            0|  0.00%|    >>> np.vdot(a, b)
   864|         0|            0|            0|  0.00%|    (70-8j)
   865|         0|            0|            0|  0.00%|    >>> np.vdot(b, a)
   866|         0|            0|            0|  0.00%|    (70+8j)
   867|         0|            0|            0|  0.00%|
   868|         0|            0|            0|  0.00%|    Note that higher-dimensional arrays are flattened!
   869|         0|            0|            0|  0.00%|
   870|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 4], [5, 6]])
   871|         0|            0|            0|  0.00%|    >>> b = np.array([[4, 1], [2, 2]])
   872|         0|            0|            0|  0.00%|    >>> np.vdot(a, b)
   873|         0|            0|            0|  0.00%|    30
   874|         0|            0|            0|  0.00%|    >>> np.vdot(b, a)
   875|         0|            0|            0|  0.00%|    30
   876|         0|            0|            0|  0.00%|    >>> 1*4 + 4*1 + 5*2 + 6*2
   877|         0|            0|            0|  0.00%|    30
   878|         0|            0|            0|  0.00%|
   879|         0|            0|            0|  0.00%|    """
   880|         0|            0|            0|  0.00%|    return (a, b)
   881|         0|            0|            0|  0.00%|
   882|         0|            0|            0|  0.00%|
   883|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.bincount)
   884|         0|            0|            0|  0.00%|def bincount(x, weights=None, minlength=None):
   885|         0|            0|            0|  0.00%|    """
   886|         0|            0|            0|  0.00%|    bincount(x, /, weights=None, minlength=0)
   887|         0|            0|            0|  0.00%|
   888|         0|            0|            0|  0.00%|    Count number of occurrences of each value in array of non-negative ints.
   889|         0|            0|            0|  0.00%|
   890|         0|            0|            0|  0.00%|    The number of bins (of size 1) is one larger than the largest value in
   891|         0|            0|            0|  0.00%|    `x`. If `minlength` is specified, there will be at least this number
   892|         0|            0|            0|  0.00%|    of bins in the output array (though it will be longer if necessary,
   893|         0|            0|            0|  0.00%|    depending on the contents of `x`).
   894|         0|            0|            0|  0.00%|    Each bin gives the number of occurrences of its index value in `x`.
   895|         0|            0|            0|  0.00%|    If `weights` is specified the input array is weighted by it, i.e. if a
   896|         0|            0|            0|  0.00%|    value ``n`` is found at position ``i``, ``out[n] += weight[i]`` instead
   897|         0|            0|            0|  0.00%|    of ``out[n] += 1``.
   898|         0|            0|            0|  0.00%|
   899|         0|            0|            0|  0.00%|    Parameters
   900|         0|            0|            0|  0.00%|    ----------
   901|         0|            0|            0|  0.00%|    x : array_like, 1 dimension, nonnegative ints
   902|         0|            0|            0|  0.00%|        Input array.
   903|         0|            0|            0|  0.00%|    weights : array_like, optional
   904|         0|            0|            0|  0.00%|        Weights, array of the same shape as `x`.
   905|         0|            0|            0|  0.00%|    minlength : int, optional
   906|         0|            0|            0|  0.00%|        A minimum number of bins for the output array.
   907|         0|            0|            0|  0.00%|
   908|         0|            0|            0|  0.00%|        .. versionadded:: 1.6.0
   909|         0|            0|            0|  0.00%|
   910|         0|            0|            0|  0.00%|    Returns
   911|         0|            0|            0|  0.00%|    -------
   912|         0|            0|            0|  0.00%|    out : ndarray of ints
   913|         0|            0|            0|  0.00%|        The result of binning the input array.
   914|         0|            0|            0|  0.00%|        The length of `out` is equal to ``np.amax(x)+1``.
   915|         0|            0|            0|  0.00%|
   916|         0|            0|            0|  0.00%|    Raises
   917|         0|            0|            0|  0.00%|    ------
   918|         0|            0|            0|  0.00%|    ValueError
   919|         0|            0|            0|  0.00%|        If the input is not 1-dimensional, or contains elements with negative
   920|         0|            0|            0|  0.00%|        values, or if `minlength` is negative.
   921|         0|            0|            0|  0.00%|    TypeError
   922|         0|            0|            0|  0.00%|        If the type of the input is float or complex.
   923|         0|            0|            0|  0.00%|
   924|         0|            0|            0|  0.00%|    See Also
   925|         0|            0|            0|  0.00%|    --------
   926|         0|            0|            0|  0.00%|    histogram, digitize, unique
   927|         0|            0|            0|  0.00%|
   928|         0|            0|            0|  0.00%|    Examples
   929|         0|            0|            0|  0.00%|    --------
   930|         0|            0|            0|  0.00%|    >>> np.bincount(np.arange(5))
   931|         0|            0|            0|  0.00%|    array([1, 1, 1, 1, 1])
   932|         0|            0|            0|  0.00%|    >>> np.bincount(np.array([0, 1, 1, 3, 2, 1, 7]))
   933|         0|            0|            0|  0.00%|    array([1, 3, 1, 1, 0, 0, 0, 1])
   934|         0|            0|            0|  0.00%|
   935|         0|            0|            0|  0.00%|    >>> x = np.array([0, 1, 1, 3, 2, 1, 7, 23])
   936|         0|            0|            0|  0.00%|    >>> np.bincount(x).size == np.amax(x)+1
   937|         0|            0|            0|  0.00%|    True
   938|         0|            0|            0|  0.00%|
   939|         0|            0|            0|  0.00%|    The input array needs to be of integer dtype, otherwise a
   940|         0|            0|            0|  0.00%|    TypeError is raised:
   941|         0|            0|            0|  0.00%|
   942|         0|            0|            0|  0.00%|    >>> np.bincount(np.arange(5, dtype=float))
   943|         0|            0|            0|  0.00%|    Traceback (most recent call last):
   944|         0|            0|            0|  0.00%|      ...
   945|         0|            0|            0|  0.00%|    TypeError: Cannot cast array data from dtype('float64') to dtype('int64')
   946|         0|            0|            0|  0.00%|    according to the rule 'safe'
   947|         0|            0|            0|  0.00%|
   948|         0|            0|            0|  0.00%|    A possible use of ``bincount`` is to perform sums over
   949|         0|            0|            0|  0.00%|    variable-size chunks of an array, using the ``weights`` keyword.
   950|         0|            0|            0|  0.00%|
   951|         0|            0|            0|  0.00%|    >>> w = np.array([0.3, 0.5, 0.2, 0.7, 1., -0.6]) # weights
   952|         0|            0|            0|  0.00%|    >>> x = np.array([0, 1, 1, 2, 2, 2])
   953|         0|            0|            0|  0.00%|    >>> np.bincount(x,  weights=w)
   954|         0|            0|            0|  0.00%|    array([ 0.3,  0.7,  1.1])
   955|         0|            0|            0|  0.00%|
   956|         0|            0|            0|  0.00%|    """
   957|         0|            0|            0|  0.00%|    return (x, weights)
   958|         0|            0|            0|  0.00%|
   959|         0|            0|            0|  0.00%|
   960|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.ravel_multi_index)
   961|         0|            0|            0|  0.00%|def ravel_multi_index(multi_index, dims, mode=None, order=None):
   962|         0|            0|            0|  0.00%|    """
   963|         0|            0|            0|  0.00%|    ravel_multi_index(multi_index, dims, mode='raise', order='C')
   964|         0|            0|            0|  0.00%|
   965|         0|            0|            0|  0.00%|    Converts a tuple of index arrays into an array of flat
   966|         0|            0|            0|  0.00%|    indices, applying boundary modes to the multi-index.
   967|         0|            0|            0|  0.00%|
   968|         0|            0|            0|  0.00%|    Parameters
   969|         0|            0|            0|  0.00%|    ----------
   970|         0|            0|            0|  0.00%|    multi_index : tuple of array_like
   971|         0|            0|            0|  0.00%|        A tuple of integer arrays, one array for each dimension.
   972|         0|            0|            0|  0.00%|    dims : tuple of ints
   973|         0|            0|            0|  0.00%|        The shape of array into which the indices from ``multi_index`` apply.
   974|         0|            0|            0|  0.00%|    mode : {'raise', 'wrap', 'clip'}, optional
   975|         0|            0|            0|  0.00%|        Specifies how out-of-bounds indices are handled.  Can specify
   976|         0|            0|            0|  0.00%|        either one mode or a tuple of modes, one mode per index.
   977|         0|            0|            0|  0.00%|
   978|         0|            0|            0|  0.00%|        * 'raise' -- raise an error (default)
   979|         0|            0|            0|  0.00%|        * 'wrap' -- wrap around
   980|         0|            0|            0|  0.00%|        * 'clip' -- clip to the range
   981|         0|            0|            0|  0.00%|
   982|         0|            0|            0|  0.00%|        In 'clip' mode, a negative index which would normally
   983|         0|            0|            0|  0.00%|        wrap will clip to 0 instead.
   984|         0|            0|            0|  0.00%|    order : {'C', 'F'}, optional
   985|         0|            0|            0|  0.00%|        Determines whether the multi-index should be viewed as
   986|         0|            0|            0|  0.00%|        indexing in row-major (C-style) or column-major
   987|         0|            0|            0|  0.00%|        (Fortran-style) order.
   988|         0|            0|            0|  0.00%|
   989|         0|            0|            0|  0.00%|    Returns
   990|         0|            0|            0|  0.00%|    -------
   991|         0|            0|            0|  0.00%|    raveled_indices : ndarray
   992|         0|            0|            0|  0.00%|        An array of indices into the flattened version of an array
   993|         0|            0|            0|  0.00%|        of dimensions ``dims``.
   994|         0|            0|            0|  0.00%|
   995|         0|            0|            0|  0.00%|    See Also
   996|         0|            0|            0|  0.00%|    --------
   997|         0|            0|            0|  0.00%|    unravel_index
   998|         0|            0|            0|  0.00%|
   999|         0|            0|            0|  0.00%|    Notes
  1000|         0|            0|            0|  0.00%|    -----
  1001|         0|            0|            0|  0.00%|    .. versionadded:: 1.6.0
  1002|         0|            0|            0|  0.00%|
  1003|         0|            0|            0|  0.00%|    Examples
  1004|         0|            0|            0|  0.00%|    --------
  1005|         0|            0|            0|  0.00%|    >>> arr = np.array([[3,6,6],[4,5,1]])
  1006|         0|            0|            0|  0.00%|    >>> np.ravel_multi_index(arr, (7,6))
  1007|         0|            0|            0|  0.00%|    array([22, 41, 37])
  1008|         0|            0|            0|  0.00%|    >>> np.ravel_multi_index(arr, (7,6), order='F')
  1009|         0|            0|            0|  0.00%|    array([31, 41, 13])
  1010|         0|            0|            0|  0.00%|    >>> np.ravel_multi_index(arr, (4,6), mode='clip')
  1011|         0|            0|            0|  0.00%|    array([22, 23, 19])
  1012|         0|            0|            0|  0.00%|    >>> np.ravel_multi_index(arr, (4,4), mode=('clip','wrap'))
  1013|         0|            0|            0|  0.00%|    array([12, 13, 13])
  1014|         0|            0|            0|  0.00%|
  1015|         0|            0|            0|  0.00%|    >>> np.ravel_multi_index((3,1,4,1), (6,7,8,9))
  1016|         0|            0|            0|  0.00%|    1621
  1017|         0|            0|            0|  0.00%|    """
  1018|         0|            0|            0|  0.00%|    return multi_index
  1019|         0|            0|            0|  0.00%|
  1020|         0|            0|            0|  0.00%|
  1021|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.unravel_index)
  1022|         0|            0|            0|  0.00%|def unravel_index(indices, shape=None, order=None):
  1023|         0|            0|            0|  0.00%|    """
  1024|         0|            0|            0|  0.00%|    unravel_index(indices, shape, order='C')
  1025|         0|            0|            0|  0.00%|
  1026|         0|            0|            0|  0.00%|    Converts a flat index or array of flat indices into a tuple
  1027|         0|            0|            0|  0.00%|    of coordinate arrays.
  1028|         0|            0|            0|  0.00%|
  1029|         0|            0|            0|  0.00%|    Parameters
  1030|         0|            0|            0|  0.00%|    ----------
  1031|         0|            0|            0|  0.00%|    indices : array_like
  1032|         0|            0|            0|  0.00%|        An integer array whose elements are indices into the flattened
  1033|         0|            0|            0|  0.00%|        version of an array of dimensions ``shape``. Before version 1.6.0,
  1034|         0|            0|            0|  0.00%|        this function accepted just one index value.
  1035|         0|            0|            0|  0.00%|    shape : tuple of ints
  1036|         0|            0|            0|  0.00%|        The shape of the array to use for unraveling ``indices``.
  1037|         0|            0|            0|  0.00%|
  1038|         0|            0|            0|  0.00%|        .. versionchanged:: 1.16.0
  1039|         0|            0|            0|  0.00%|            Renamed from ``dims`` to ``shape``.
  1040|         0|            0|            0|  0.00%|
  1041|         0|            0|            0|  0.00%|    order : {'C', 'F'}, optional
  1042|         0|            0|            0|  0.00%|        Determines whether the indices should be viewed as indexing in
  1043|         0|            0|            0|  0.00%|        row-major (C-style) or column-major (Fortran-style) order.
  1044|         0|            0|            0|  0.00%|
  1045|         0|            0|            0|  0.00%|        .. versionadded:: 1.6.0
  1046|         0|            0|            0|  0.00%|
  1047|         0|            0|            0|  0.00%|    Returns
  1048|         0|            0|            0|  0.00%|    -------
  1049|         0|            0|            0|  0.00%|    unraveled_coords : tuple of ndarray
  1050|         0|            0|            0|  0.00%|        Each array in the tuple has the same shape as the ``indices``
  1051|         0|            0|            0|  0.00%|        array.
  1052|         0|            0|            0|  0.00%|
  1053|         0|            0|            0|  0.00%|    See Also
  1054|         0|            0|            0|  0.00%|    --------
  1055|         0|            0|            0|  0.00%|    ravel_multi_index
  1056|         0|            0|            0|  0.00%|
  1057|         0|            0|            0|  0.00%|    Examples
  1058|         0|            0|            0|  0.00%|    --------
  1059|         0|            0|            0|  0.00%|    >>> np.unravel_index([22, 41, 37], (7,6))
  1060|         0|            0|            0|  0.00%|    (array([3, 6, 6]), array([4, 5, 1]))
  1061|         0|            0|            0|  0.00%|    >>> np.unravel_index([31, 41, 13], (7,6), order='F')
  1062|         0|            0|            0|  0.00%|    (array([3, 6, 6]), array([4, 5, 1]))
  1063|         0|            0|            0|  0.00%|
  1064|         0|            0|            0|  0.00%|    >>> np.unravel_index(1621, (6,7,8,9))
  1065|         0|            0|            0|  0.00%|    (3, 1, 4, 1)
  1066|         0|            0|            0|  0.00%|
  1067|         0|            0|            0|  0.00%|    """
  1068|         0|            0|            0|  0.00%|    return (indices,)
  1069|         0|            0|            0|  0.00%|
  1070|         0|            0|            0|  0.00%|
  1071|     11906|    0.0201812|  1.69504e-06|  0.02%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.copyto)
  1072|         0|            0|            0|  0.00%|def copyto(dst, src, casting=None, where=None):
  1073|         0|            0|            0|  0.00%|    """
  1074|         0|            0|            0|  0.00%|    copyto(dst, src, casting='same_kind', where=True)
  1075|         0|            0|            0|  0.00%|
  1076|         0|            0|            0|  0.00%|    Copies values from one array to another, broadcasting as necessary.
  1077|         0|            0|            0|  0.00%|
  1078|         0|            0|            0|  0.00%|    Raises a TypeError if the `casting` rule is violated, and if
  1079|         0|            0|            0|  0.00%|    `where` is provided, it selects which elements to copy.
  1080|         0|            0|            0|  0.00%|
  1081|         0|            0|            0|  0.00%|    .. versionadded:: 1.7.0
  1082|         0|            0|            0|  0.00%|
  1083|         0|            0|            0|  0.00%|    Parameters
  1084|         0|            0|            0|  0.00%|    ----------
  1085|         0|            0|            0|  0.00%|    dst : ndarray
  1086|         0|            0|            0|  0.00%|        The array into which values are copied.
  1087|         0|            0|            0|  0.00%|    src : array_like
  1088|         0|            0|            0|  0.00%|        The array from which values are copied.
  1089|         0|            0|            0|  0.00%|    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
  1090|         0|            0|            0|  0.00%|        Controls what kind of data casting may occur when copying.
  1091|         0|            0|            0|  0.00%|
  1092|         0|            0|            0|  0.00%|          * 'no' means the data types should not be cast at all.
  1093|         0|            0|            0|  0.00%|          * 'equiv' means only byte-order changes are allowed.
  1094|         0|            0|            0|  0.00%|          * 'safe' means only casts which can preserve values are allowed.
  1095|         0|            0|            0|  0.00%|          * 'same_kind' means only safe casts or casts within a kind,
  1096|         0|            0|            0|  0.00%|            like float64 to float32, are allowed.
  1097|         0|            0|            0|  0.00%|          * 'unsafe' means any data conversions may be done.
  1098|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  1099|         0|            0|            0|  0.00%|        A boolean array which is broadcasted to match the dimensions
  1100|         0|            0|            0|  0.00%|        of `dst`, and selects elements to copy from `src` to `dst`
  1101|         0|            0|            0|  0.00%|        wherever it contains the value True.
  1102|         0|            0|            0|  0.00%|    """
  1103|     11906|    0.0266199|  2.23584e-06|  0.03%|    return (dst, src, where)
  1104|         0|            0|            0|  0.00%|
  1105|         0|            0|            0|  0.00%|
  1106|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.putmask)
  1107|         0|            0|            0|  0.00%|def putmask(a, mask, values):
  1108|         0|            0|            0|  0.00%|    """
  1109|         0|            0|            0|  0.00%|    putmask(a, mask, values)
  1110|         0|            0|            0|  0.00%|
  1111|         0|            0|            0|  0.00%|    Changes elements of an array based on conditional and input values.
  1112|         0|            0|            0|  0.00%|
  1113|         0|            0|            0|  0.00%|    Sets ``a.flat[n] = values[n]`` for each n where ``mask.flat[n]==True``.
  1114|         0|            0|            0|  0.00%|
  1115|         0|            0|            0|  0.00%|    If `values` is not the same size as `a` and `mask` then it will repeat.
  1116|         0|            0|            0|  0.00%|    This gives behavior different from ``a[mask] = values``.
  1117|         0|            0|            0|  0.00%|
  1118|         0|            0|            0|  0.00%|    Parameters
  1119|         0|            0|            0|  0.00%|    ----------
  1120|         0|            0|            0|  0.00%|    a : ndarray
  1121|         0|            0|            0|  0.00%|        Target array.
  1122|         0|            0|            0|  0.00%|    mask : array_like
  1123|         0|            0|            0|  0.00%|        Boolean mask array. It has to be the same shape as `a`.
  1124|         0|            0|            0|  0.00%|    values : array_like
  1125|         0|            0|            0|  0.00%|        Values to put into `a` where `mask` is True. If `values` is smaller
  1126|         0|            0|            0|  0.00%|        than `a` it will be repeated.
  1127|         0|            0|            0|  0.00%|
  1128|         0|            0|            0|  0.00%|    See Also
  1129|         0|            0|            0|  0.00%|    --------
  1130|         0|            0|            0|  0.00%|    place, put, take, copyto
  1131|         0|            0|            0|  0.00%|
  1132|         0|            0|            0|  0.00%|    Examples
  1133|         0|            0|            0|  0.00%|    --------
  1134|         0|            0|            0|  0.00%|    >>> x = np.arange(6).reshape(2, 3)
  1135|         0|            0|            0|  0.00%|    >>> np.putmask(x, x>2, x**2)
  1136|         0|            0|            0|  0.00%|    >>> x
  1137|         0|            0|            0|  0.00%|    array([[ 0,  1,  2],
  1138|         0|            0|            0|  0.00%|           [ 9, 16, 25]])
  1139|         0|            0|            0|  0.00%|
  1140|         0|            0|            0|  0.00%|    If `values` is smaller than `a` it is repeated:
  1141|         0|            0|            0|  0.00%|
  1142|         0|            0|            0|  0.00%|    >>> x = np.arange(5)
  1143|         0|            0|            0|  0.00%|    >>> np.putmask(x, x>1, [-33, -44])
  1144|         0|            0|            0|  0.00%|    >>> x
  1145|         0|            0|            0|  0.00%|    array([  0,   1, -33, -44, -33])
  1146|         0|            0|            0|  0.00%|
  1147|         0|            0|            0|  0.00%|    """
  1148|         0|            0|            0|  0.00%|    return (a, mask, values)
  1149|         0|            0|            0|  0.00%|
  1150|         0|            0|            0|  0.00%|
  1151|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.packbits)
  1152|         0|            0|            0|  0.00%|def packbits(a, axis=None, bitorder='big'):
  1153|         0|            0|            0|  0.00%|    """
  1154|         0|            0|            0|  0.00%|    packbits(a, /, axis=None, bitorder='big')
  1155|         0|            0|            0|  0.00%|
  1156|         0|            0|            0|  0.00%|    Packs the elements of a binary-valued array into bits in a uint8 array.
  1157|         0|            0|            0|  0.00%|
  1158|         0|            0|            0|  0.00%|    The result is padded to full bytes by inserting zero bits at the end.
  1159|         0|            0|            0|  0.00%|
  1160|         0|            0|            0|  0.00%|    Parameters
  1161|         0|            0|            0|  0.00%|    ----------
  1162|         0|            0|            0|  0.00%|    a : array_like
  1163|         0|            0|            0|  0.00%|        An array of integers or booleans whose elements should be packed to
  1164|         0|            0|            0|  0.00%|        bits.
  1165|         0|            0|            0|  0.00%|    axis : int, optional
  1166|         0|            0|            0|  0.00%|        The dimension over which bit-packing is done.
  1167|         0|            0|            0|  0.00%|        ``None`` implies packing the flattened array.
  1168|         0|            0|            0|  0.00%|    bitorder : {'big', 'little'}, optional
  1169|         0|            0|            0|  0.00%|        The order of the input bits. 'big' will mimic bin(val),
  1170|         0|            0|            0|  0.00%|        ``[0, 0, 0, 0, 0, 0, 1, 1] => 3 = 0b00000011``, 'little' will
  1171|         0|            0|            0|  0.00%|        reverse the order so ``[1, 1, 0, 0, 0, 0, 0, 0] => 3``.
  1172|         0|            0|            0|  0.00%|        Defaults to 'big'.
  1173|         0|            0|            0|  0.00%|
  1174|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
  1175|         0|            0|            0|  0.00%|
  1176|         0|            0|            0|  0.00%|    Returns
  1177|         0|            0|            0|  0.00%|    -------
  1178|         0|            0|            0|  0.00%|    packed : ndarray
  1179|         0|            0|            0|  0.00%|        Array of type uint8 whose elements represent bits corresponding to the
  1180|         0|            0|            0|  0.00%|        logical (0 or nonzero) value of the input elements. The shape of
  1181|         0|            0|            0|  0.00%|        `packed` has the same number of dimensions as the input (unless `axis`
  1182|         0|            0|            0|  0.00%|        is None, in which case the output is 1-D).
  1183|         0|            0|            0|  0.00%|
  1184|         0|            0|            0|  0.00%|    See Also
  1185|         0|            0|            0|  0.00%|    --------
  1186|         0|            0|            0|  0.00%|    unpackbits: Unpacks elements of a uint8 array into a binary-valued output
  1187|         0|            0|            0|  0.00%|                array.
  1188|         0|            0|            0|  0.00%|
  1189|         0|            0|            0|  0.00%|    Examples
  1190|         0|            0|            0|  0.00%|    --------
  1191|         0|            0|            0|  0.00%|    >>> a = np.array([[[1,0,1],
  1192|         0|            0|            0|  0.00%|    ...                [0,1,0]],
  1193|         0|            0|            0|  0.00%|    ...               [[1,1,0],
  1194|         0|            0|            0|  0.00%|    ...                [0,0,1]]])
  1195|         0|            0|            0|  0.00%|    >>> b = np.packbits(a, axis=-1)
  1196|         0|            0|            0|  0.00%|    >>> b
  1197|         0|            0|            0|  0.00%|    array([[[160],
  1198|         0|            0|            0|  0.00%|            [ 64]],
  1199|         0|            0|            0|  0.00%|           [[192],
  1200|         0|            0|            0|  0.00%|            [ 32]]], dtype=uint8)
  1201|         0|            0|            0|  0.00%|
  1202|         0|            0|            0|  0.00%|    Note that in binary 160 = 1010 0000, 64 = 0100 0000, 192 = 1100 0000,
  1203|         0|            0|            0|  0.00%|    and 32 = 0010 0000.
  1204|         0|            0|            0|  0.00%|
  1205|         0|            0|            0|  0.00%|    """
  1206|         0|            0|            0|  0.00%|    return (a,)
  1207|         0|            0|            0|  0.00%|
  1208|         0|            0|            0|  0.00%|
  1209|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.unpackbits)
  1210|         0|            0|            0|  0.00%|def unpackbits(a, axis=None, count=None, bitorder='big'):
  1211|         0|            0|            0|  0.00%|    """
  1212|         0|            0|            0|  0.00%|    unpackbits(a, /, axis=None, count=None, bitorder='big')
  1213|         0|            0|            0|  0.00%|
  1214|         0|            0|            0|  0.00%|    Unpacks elements of a uint8 array into a binary-valued output array.
  1215|         0|            0|            0|  0.00%|
  1216|         0|            0|            0|  0.00%|    Each element of `a` represents a bit-field that should be unpacked
  1217|         0|            0|            0|  0.00%|    into a binary-valued output array. The shape of the output array is
  1218|         0|            0|            0|  0.00%|    either 1-D (if `axis` is ``None``) or the same shape as the input
  1219|         0|            0|            0|  0.00%|    array with unpacking done along the axis specified.
  1220|         0|            0|            0|  0.00%|
  1221|         0|            0|            0|  0.00%|    Parameters
  1222|         0|            0|            0|  0.00%|    ----------
  1223|         0|            0|            0|  0.00%|    a : ndarray, uint8 type
  1224|         0|            0|            0|  0.00%|       Input array.
  1225|         0|            0|            0|  0.00%|    axis : int, optional
  1226|         0|            0|            0|  0.00%|        The dimension over which bit-unpacking is done.
  1227|         0|            0|            0|  0.00%|        ``None`` implies unpacking the flattened array.
  1228|         0|            0|            0|  0.00%|    count : int or None, optional
  1229|         0|            0|            0|  0.00%|        The number of elements to unpack along `axis`, provided as a way
  1230|         0|            0|            0|  0.00%|        of undoing the effect of packing a size that is not a multiple
  1231|         0|            0|            0|  0.00%|        of eight. A non-negative number means to only unpack `count`
  1232|         0|            0|            0|  0.00%|        bits. A negative number means to trim off that many bits from
  1233|         0|            0|            0|  0.00%|        the end. ``None`` means to unpack the entire array (the
  1234|         0|            0|            0|  0.00%|        default). Counts larger than the available number of bits will
  1235|         0|            0|            0|  0.00%|        add zero padding to the output. Negative counts must not
  1236|         0|            0|            0|  0.00%|        exceed the available number of bits.
  1237|         0|            0|            0|  0.00%|
  1238|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
  1239|         0|            0|            0|  0.00%|
  1240|         0|            0|            0|  0.00%|    bitorder : {'big', 'little'}, optional
  1241|         0|            0|            0|  0.00%|        The order of the returned bits. 'big' will mimic bin(val),
  1242|         0|            0|            0|  0.00%|        ``3 = 0b00000011 => [0, 0, 0, 0, 0, 0, 1, 1]``, 'little' will reverse
  1243|         0|            0|            0|  0.00%|        the order to ``[1, 1, 0, 0, 0, 0, 0, 0]``.
  1244|         0|            0|            0|  0.00%|        Defaults to 'big'.
  1245|         0|            0|            0|  0.00%|
  1246|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
  1247|         0|            0|            0|  0.00%|
  1248|         0|            0|            0|  0.00%|    Returns
  1249|         0|            0|            0|  0.00%|    -------
  1250|         0|            0|            0|  0.00%|    unpacked : ndarray, uint8 type
  1251|         0|            0|            0|  0.00%|       The elements are binary-valued (0 or 1).
  1252|         0|            0|            0|  0.00%|
  1253|         0|            0|            0|  0.00%|    See Also
  1254|         0|            0|            0|  0.00%|    --------
  1255|         0|            0|            0|  0.00%|    packbits : Packs the elements of a binary-valued array into bits in
  1256|         0|            0|            0|  0.00%|               a uint8 array.
  1257|         0|            0|            0|  0.00%|
  1258|         0|            0|            0|  0.00%|    Examples
  1259|         0|            0|            0|  0.00%|    --------
  1260|         0|            0|            0|  0.00%|    >>> a = np.array([[2], [7], [23]], dtype=np.uint8)
  1261|         0|            0|            0|  0.00%|    >>> a
  1262|         0|            0|            0|  0.00%|    array([[ 2],
  1263|         0|            0|            0|  0.00%|           [ 7],
  1264|         0|            0|            0|  0.00%|           [23]], dtype=uint8)
  1265|         0|            0|            0|  0.00%|    >>> b = np.unpackbits(a, axis=1)
  1266|         0|            0|            0|  0.00%|    >>> b
  1267|         0|            0|            0|  0.00%|    array([[0, 0, 0, 0, 0, 0, 1, 0],
  1268|         0|            0|            0|  0.00%|           [0, 0, 0, 0, 0, 1, 1, 1],
  1269|         0|            0|            0|  0.00%|           [0, 0, 0, 1, 0, 1, 1, 1]], dtype=uint8)
  1270|         0|            0|            0|  0.00%|    >>> c = np.unpackbits(a, axis=1, count=-3)
  1271|         0|            0|            0|  0.00%|    >>> c
  1272|         0|            0|            0|  0.00%|    array([[0, 0, 0, 0, 0],
  1273|         0|            0|            0|  0.00%|           [0, 0, 0, 0, 0],
  1274|         0|            0|            0|  0.00%|           [0, 0, 0, 1, 0]], dtype=uint8)
  1275|         0|            0|            0|  0.00%|
  1276|         0|            0|            0|  0.00%|    >>> p = np.packbits(b, axis=0)
  1277|         0|            0|            0|  0.00%|    >>> np.unpackbits(p, axis=0)
  1278|         0|            0|            0|  0.00%|    array([[0, 0, 0, 0, 0, 0, 1, 0],
  1279|         0|            0|            0|  0.00%|           [0, 0, 0, 0, 0, 1, 1, 1],
  1280|         0|            0|            0|  0.00%|           [0, 0, 0, 1, 0, 1, 1, 1],
  1281|         0|            0|            0|  0.00%|           [0, 0, 0, 0, 0, 0, 0, 0],
  1282|         0|            0|            0|  0.00%|           [0, 0, 0, 0, 0, 0, 0, 0],
  1283|         0|            0|            0|  0.00%|           [0, 0, 0, 0, 0, 0, 0, 0],
  1284|         0|            0|            0|  0.00%|           [0, 0, 0, 0, 0, 0, 0, 0],
  1285|         0|            0|            0|  0.00%|           [0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)
  1286|         0|            0|            0|  0.00%|    >>> np.array_equal(b, np.unpackbits(p, axis=0, count=b.shape[0]))
  1287|         0|            0|            0|  0.00%|    True
  1288|         0|            0|            0|  0.00%|
  1289|         0|            0|            0|  0.00%|    """
  1290|         0|            0|            0|  0.00%|    return (a,)
  1291|         0|            0|            0|  0.00%|
  1292|         0|            0|            0|  0.00%|
  1293|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.shares_memory)
  1294|         0|            0|            0|  0.00%|def shares_memory(a, b, max_work=None):
  1295|         0|            0|            0|  0.00%|    """
  1296|         0|            0|            0|  0.00%|    shares_memory(a, b, /, max_work=None)
  1297|         0|            0|            0|  0.00%|
  1298|         0|            0|            0|  0.00%|    Determine if two arrays share memory.
  1299|         0|            0|            0|  0.00%|
  1300|         0|            0|            0|  0.00%|    .. warning::
  1301|         0|            0|            0|  0.00%|
  1302|         0|            0|            0|  0.00%|       This function can be exponentially slow for some inputs, unless
  1303|         0|            0|            0|  0.00%|       `max_work` is set to a finite number or ``MAY_SHARE_BOUNDS``.
  1304|         0|            0|            0|  0.00%|       If in doubt, use `numpy.may_share_memory` instead.
  1305|         0|            0|            0|  0.00%|
  1306|         0|            0|            0|  0.00%|    Parameters
  1307|         0|            0|            0|  0.00%|    ----------
  1308|         0|            0|            0|  0.00%|    a, b : ndarray
  1309|         0|            0|            0|  0.00%|        Input arrays
  1310|         0|            0|            0|  0.00%|    max_work : int, optional
  1311|         0|            0|            0|  0.00%|        Effort to spend on solving the overlap problem (maximum number
  1312|         0|            0|            0|  0.00%|        of candidate solutions to consider). The following special
  1313|         0|            0|            0|  0.00%|        values are recognized:
  1314|         0|            0|            0|  0.00%|
  1315|         0|            0|            0|  0.00%|        max_work=MAY_SHARE_EXACT  (default)
  1316|         0|            0|            0|  0.00%|            The problem is solved exactly. In this case, the function returns
  1317|         0|            0|            0|  0.00%|            True only if there is an element shared between the arrays. Finding
  1318|         0|            0|            0|  0.00%|            the exact solution may take extremely long in some cases.
  1319|         0|            0|            0|  0.00%|        max_work=MAY_SHARE_BOUNDS
  1320|         0|            0|            0|  0.00%|            Only the memory bounds of a and b are checked.
  1321|         0|            0|            0|  0.00%|
  1322|         0|            0|            0|  0.00%|    Raises
  1323|         0|            0|            0|  0.00%|    ------
  1324|         0|            0|            0|  0.00%|    numpy.TooHardError
  1325|         0|            0|            0|  0.00%|        Exceeded max_work.
  1326|         0|            0|            0|  0.00%|
  1327|         0|            0|            0|  0.00%|    Returns
  1328|         0|            0|            0|  0.00%|    -------
  1329|         0|            0|            0|  0.00%|    out : bool
  1330|         0|            0|            0|  0.00%|
  1331|         0|            0|            0|  0.00%|    See Also
  1332|         0|            0|            0|  0.00%|    --------
  1333|         0|            0|            0|  0.00%|    may_share_memory
  1334|         0|            0|            0|  0.00%|
  1335|         0|            0|            0|  0.00%|    Examples
  1336|         0|            0|            0|  0.00%|    --------
  1337|         0|            0|            0|  0.00%|    >>> x = np.array([1, 2, 3, 4])
  1338|         0|            0|            0|  0.00%|    >>> np.shares_memory(x, np.array([5, 6, 7]))
  1339|         0|            0|            0|  0.00%|    False
  1340|         0|            0|            0|  0.00%|    >>> np.shares_memory(x[::2], x)
  1341|         0|            0|            0|  0.00%|    True
  1342|         0|            0|            0|  0.00%|    >>> np.shares_memory(x[::2], x[1::2])
  1343|         0|            0|            0|  0.00%|    False
  1344|         0|            0|            0|  0.00%|
  1345|         0|            0|            0|  0.00%|    Checking whether two arrays share memory is NP-complete, and
  1346|         0|            0|            0|  0.00%|    runtime may increase exponentially in the number of
  1347|         0|            0|            0|  0.00%|    dimensions. Hence, `max_work` should generally be set to a finite
  1348|         0|            0|            0|  0.00%|    number, as it is possible to construct examples that take
  1349|         0|            0|            0|  0.00%|    extremely long to run:
  1350|         0|            0|            0|  0.00%|
  1351|         0|            0|            0|  0.00%|    >>> from numpy.lib.stride_tricks import as_strided
  1352|         0|            0|            0|  0.00%|    >>> x = np.zeros([192163377], dtype=np.int8)
  1353|         0|            0|            0|  0.00%|    >>> x1 = as_strided(x, strides=(36674, 61119, 85569), shape=(1049, 1049, 1049))
  1354|         0|            0|            0|  0.00%|    >>> x2 = as_strided(x[64023025:], strides=(12223, 12224, 1), shape=(1049, 1049, 1))
  1355|         0|            0|            0|  0.00%|    >>> np.shares_memory(x1, x2, max_work=1000)
  1356|         0|            0|            0|  0.00%|    Traceback (most recent call last):
  1357|         0|            0|            0|  0.00%|    ...
  1358|         0|            0|            0|  0.00%|    numpy.TooHardError: Exceeded max_work
  1359|         0|            0|            0|  0.00%|
  1360|         0|            0|            0|  0.00%|    Running ``np.shares_memory(x1, x2)`` without `max_work` set takes
  1361|         0|            0|            0|  0.00%|    around 1 minute for this case. It is possible to find problems
  1362|         0|            0|            0|  0.00%|    that take still significantly longer.
  1363|         0|            0|            0|  0.00%|
  1364|         0|            0|            0|  0.00%|    """
  1365|         0|            0|            0|  0.00%|    return (a, b)
  1366|         0|            0|            0|  0.00%|
  1367|         0|            0|            0|  0.00%|
  1368|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.may_share_memory)
  1369|         0|            0|            0|  0.00%|def may_share_memory(a, b, max_work=None):
  1370|         0|            0|            0|  0.00%|    """
  1371|         0|            0|            0|  0.00%|    may_share_memory(a, b, /, max_work=None)
  1372|         0|            0|            0|  0.00%|
  1373|         0|            0|            0|  0.00%|    Determine if two arrays might share memory
  1374|         0|            0|            0|  0.00%|
  1375|         0|            0|            0|  0.00%|    A return of True does not necessarily mean that the two arrays
  1376|         0|            0|            0|  0.00%|    share any element.  It just means that they *might*.
  1377|         0|            0|            0|  0.00%|
  1378|         0|            0|            0|  0.00%|    Only the memory bounds of a and b are checked by default.
  1379|         0|            0|            0|  0.00%|
  1380|         0|            0|            0|  0.00%|    Parameters
  1381|         0|            0|            0|  0.00%|    ----------
  1382|         0|            0|            0|  0.00%|    a, b : ndarray
  1383|         0|            0|            0|  0.00%|        Input arrays
  1384|         0|            0|            0|  0.00%|    max_work : int, optional
  1385|         0|            0|            0|  0.00%|        Effort to spend on solving the overlap problem.  See
  1386|         0|            0|            0|  0.00%|        `shares_memory` for details.  Default for ``may_share_memory``
  1387|         0|            0|            0|  0.00%|        is to do a bounds check.
  1388|         0|            0|            0|  0.00%|
  1389|         0|            0|            0|  0.00%|    Returns
  1390|         0|            0|            0|  0.00%|    -------
  1391|         0|            0|            0|  0.00%|    out : bool
  1392|         0|            0|            0|  0.00%|
  1393|         0|            0|            0|  0.00%|    See Also
  1394|         0|            0|            0|  0.00%|    --------
  1395|         0|            0|            0|  0.00%|    shares_memory
  1396|         0|            0|            0|  0.00%|
  1397|         0|            0|            0|  0.00%|    Examples
  1398|         0|            0|            0|  0.00%|    --------
  1399|         0|            0|            0|  0.00%|    >>> np.may_share_memory(np.array([1,2]), np.array([5,8,9]))
  1400|         0|            0|            0|  0.00%|    False
  1401|         0|            0|            0|  0.00%|    >>> x = np.zeros([3, 4])
  1402|         0|            0|            0|  0.00%|    >>> np.may_share_memory(x[:,0], x[:,1])
  1403|         0|            0|            0|  0.00%|    True
  1404|         0|            0|            0|  0.00%|
  1405|         0|            0|            0|  0.00%|    """
  1406|         0|            0|            0|  0.00%|    return (a, b)
  1407|         0|            0|            0|  0.00%|
  1408|         0|            0|            0|  0.00%|
  1409|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.is_busday)
  1410|         0|            0|            0|  0.00%|def is_busday(dates, weekmask=None, holidays=None, busdaycal=None, out=None):
  1411|         0|            0|            0|  0.00%|    """
  1412|         0|            0|            0|  0.00%|    is_busday(dates, weekmask='1111100', holidays=None, busdaycal=None, out=None)
  1413|         0|            0|            0|  0.00%|
  1414|         0|            0|            0|  0.00%|    Calculates which of the given dates are valid days, and which are not.
  1415|         0|            0|            0|  0.00%|
  1416|         0|            0|            0|  0.00%|    .. versionadded:: 1.7.0
  1417|         0|            0|            0|  0.00%|
  1418|         0|            0|            0|  0.00%|    Parameters
  1419|         0|            0|            0|  0.00%|    ----------
  1420|         0|            0|            0|  0.00%|    dates : array_like of datetime64[D]
  1421|         0|            0|            0|  0.00%|        The array of dates to process.
  1422|         0|            0|            0|  0.00%|    weekmask : str or array_like of bool, optional
  1423|         0|            0|            0|  0.00%|        A seven-element array indicating which of Monday through Sunday are
  1424|         0|            0|            0|  0.00%|        valid days. May be specified as a length-seven list or array, like
  1425|         0|            0|            0|  0.00%|        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string
  1426|         0|            0|            0|  0.00%|        like "Mon Tue Wed Thu Fri", made up of 3-character abbreviations for
  1427|         0|            0|            0|  0.00%|        weekdays, optionally separated by white space. Valid abbreviations
  1428|         0|            0|            0|  0.00%|        are: Mon Tue Wed Thu Fri Sat Sun
  1429|         0|            0|            0|  0.00%|    holidays : array_like of datetime64[D], optional
  1430|         0|            0|            0|  0.00%|        An array of dates to consider as invalid dates.  They may be
  1431|         0|            0|            0|  0.00%|        specified in any order, and NaT (not-a-time) dates are ignored.
  1432|         0|            0|            0|  0.00%|        This list is saved in a normalized form that is suited for
  1433|         0|            0|            0|  0.00%|        fast calculations of valid days.
  1434|         0|            0|            0|  0.00%|    busdaycal : busdaycalendar, optional
  1435|         0|            0|            0|  0.00%|        A `busdaycalendar` object which specifies the valid days. If this
  1436|         0|            0|            0|  0.00%|        parameter is provided, neither weekmask nor holidays may be
  1437|         0|            0|            0|  0.00%|        provided.
  1438|         0|            0|            0|  0.00%|    out : array of bool, optional
  1439|         0|            0|            0|  0.00%|        If provided, this array is filled with the result.
  1440|         0|            0|            0|  0.00%|
  1441|         0|            0|            0|  0.00%|    Returns
  1442|         0|            0|            0|  0.00%|    -------
  1443|         0|            0|            0|  0.00%|    out : array of bool
  1444|         0|            0|            0|  0.00%|        An array with the same shape as ``dates``, containing True for
  1445|         0|            0|            0|  0.00%|        each valid day, and False for each invalid day.
  1446|         0|            0|            0|  0.00%|
  1447|         0|            0|            0|  0.00%|    See Also
  1448|         0|            0|            0|  0.00%|    --------
  1449|         0|            0|            0|  0.00%|    busdaycalendar : An object that specifies a custom set of valid days.
  1450|         0|            0|            0|  0.00%|    busday_offset : Applies an offset counted in valid days.
  1451|         0|            0|            0|  0.00%|    busday_count : Counts how many valid days are in a half-open date range.
  1452|         0|            0|            0|  0.00%|
  1453|         0|            0|            0|  0.00%|    Examples
  1454|         0|            0|            0|  0.00%|    --------
  1455|         0|            0|            0|  0.00%|    >>> # The weekdays are Friday, Saturday, and Monday
  1456|         0|            0|            0|  0.00%|    ... np.is_busday(['2011-07-01', '2011-07-02', '2011-07-18'],
  1457|         0|            0|            0|  0.00%|    ...                 holidays=['2011-07-01', '2011-07-04', '2011-07-17'])
  1458|         0|            0|            0|  0.00%|    array([False, False,  True])
  1459|         0|            0|            0|  0.00%|    """
  1460|         0|            0|            0|  0.00%|    return (dates, weekmask, holidays, out)
  1461|         0|            0|            0|  0.00%|
  1462|         0|            0|            0|  0.00%|
  1463|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.busday_offset)
  1464|         0|            0|            0|  0.00%|def busday_offset(dates, offsets, roll=None, weekmask=None, holidays=None,
  1465|         0|            0|            0|  0.00%|                  busdaycal=None, out=None):
  1466|         0|            0|            0|  0.00%|    """
  1467|         0|            0|            0|  0.00%|    busday_offset(dates, offsets, roll='raise', weekmask='1111100', holidays=None, busdaycal=None, out=None)
  1468|         0|            0|            0|  0.00%|
  1469|         0|            0|            0|  0.00%|    First adjusts the date to fall on a valid day according to
  1470|         0|            0|            0|  0.00%|    the ``roll`` rule, then applies offsets to the given dates
  1471|         0|            0|            0|  0.00%|    counted in valid days.
  1472|         0|            0|            0|  0.00%|
  1473|         0|            0|            0|  0.00%|    .. versionadded:: 1.7.0
  1474|         0|            0|            0|  0.00%|
  1475|         0|            0|            0|  0.00%|    Parameters
  1476|         0|            0|            0|  0.00%|    ----------
  1477|         0|            0|            0|  0.00%|    dates : array_like of datetime64[D]
  1478|         0|            0|            0|  0.00%|        The array of dates to process.
  1479|         0|            0|            0|  0.00%|    offsets : array_like of int
  1480|         0|            0|            0|  0.00%|        The array of offsets, which is broadcast with ``dates``.
  1481|         0|            0|            0|  0.00%|    roll : {'raise', 'nat', 'forward', 'following', 'backward', 'preceding', 'modifiedfollowing', 'modifiedpreceding'}, optional
  1482|         0|            0|            0|  0.00%|        How to treat dates that do not fall on a valid day. The default
  1483|         0|            0|            0|  0.00%|        is 'raise'.
  1484|         0|            0|            0|  0.00%|
  1485|         0|            0|            0|  0.00%|          * 'raise' means to raise an exception for an invalid day.
  1486|         0|            0|            0|  0.00%|          * 'nat' means to return a NaT (not-a-time) for an invalid day.
  1487|         0|            0|            0|  0.00%|          * 'forward' and 'following' mean to take the first valid day
  1488|         0|            0|            0|  0.00%|            later in time.
  1489|         0|            0|            0|  0.00%|          * 'backward' and 'preceding' mean to take the first valid day
  1490|         0|            0|            0|  0.00%|            earlier in time.
  1491|         0|            0|            0|  0.00%|          * 'modifiedfollowing' means to take the first valid day
  1492|         0|            0|            0|  0.00%|            later in time unless it is across a Month boundary, in which
  1493|         0|            0|            0|  0.00%|            case to take the first valid day earlier in time.
  1494|         0|            0|            0|  0.00%|          * 'modifiedpreceding' means to take the first valid day
  1495|         0|            0|            0|  0.00%|            earlier in time unless it is across a Month boundary, in which
  1496|         0|            0|            0|  0.00%|            case to take the first valid day later in time.
  1497|         0|            0|            0|  0.00%|    weekmask : str or array_like of bool, optional
  1498|         0|            0|            0|  0.00%|        A seven-element array indicating which of Monday through Sunday are
  1499|         0|            0|            0|  0.00%|        valid days. May be specified as a length-seven list or array, like
  1500|         0|            0|            0|  0.00%|        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string
  1501|         0|            0|            0|  0.00%|        like "Mon Tue Wed Thu Fri", made up of 3-character abbreviations for
  1502|         0|            0|            0|  0.00%|        weekdays, optionally separated by white space. Valid abbreviations
  1503|         0|            0|            0|  0.00%|        are: Mon Tue Wed Thu Fri Sat Sun
  1504|         0|            0|            0|  0.00%|    holidays : array_like of datetime64[D], optional
  1505|         0|            0|            0|  0.00%|        An array of dates to consider as invalid dates.  They may be
  1506|         0|            0|            0|  0.00%|        specified in any order, and NaT (not-a-time) dates are ignored.
  1507|         0|            0|            0|  0.00%|        This list is saved in a normalized form that is suited for
  1508|         0|            0|            0|  0.00%|        fast calculations of valid days.
  1509|         0|            0|            0|  0.00%|    busdaycal : busdaycalendar, optional
  1510|         0|            0|            0|  0.00%|        A `busdaycalendar` object which specifies the valid days. If this
  1511|         0|            0|            0|  0.00%|        parameter is provided, neither weekmask nor holidays may be
  1512|         0|            0|            0|  0.00%|        provided.
  1513|         0|            0|            0|  0.00%|    out : array of datetime64[D], optional
  1514|         0|            0|            0|  0.00%|        If provided, this array is filled with the result.
  1515|         0|            0|            0|  0.00%|
  1516|         0|            0|            0|  0.00%|    Returns
  1517|         0|            0|            0|  0.00%|    -------
  1518|         0|            0|            0|  0.00%|    out : array of datetime64[D]
  1519|         0|            0|            0|  0.00%|        An array with a shape from broadcasting ``dates`` and ``offsets``
  1520|         0|            0|            0|  0.00%|        together, containing the dates with offsets applied.
  1521|         0|            0|            0|  0.00%|
  1522|         0|            0|            0|  0.00%|    See Also
  1523|         0|            0|            0|  0.00%|    --------
  1524|         0|            0|            0|  0.00%|    busdaycalendar : An object that specifies a custom set of valid days.
  1525|         0|            0|            0|  0.00%|    is_busday : Returns a boolean array indicating valid days.
  1526|         0|            0|            0|  0.00%|    busday_count : Counts how many valid days are in a half-open date range.
  1527|         0|            0|            0|  0.00%|
  1528|         0|            0|            0|  0.00%|    Examples
  1529|         0|            0|            0|  0.00%|    --------
  1530|         0|            0|            0|  0.00%|    >>> # First business day in October 2011 (not accounting for holidays)
  1531|         0|            0|            0|  0.00%|    ... np.busday_offset('2011-10', 0, roll='forward')
  1532|         0|            0|            0|  0.00%|    numpy.datetime64('2011-10-03')
  1533|         0|            0|            0|  0.00%|    >>> # Last business day in February 2012 (not accounting for holidays)
  1534|         0|            0|            0|  0.00%|    ... np.busday_offset('2012-03', -1, roll='forward')
  1535|         0|            0|            0|  0.00%|    numpy.datetime64('2012-02-29')
  1536|         0|            0|            0|  0.00%|    >>> # Third Wednesday in January 2011
  1537|         0|            0|            0|  0.00%|    ... np.busday_offset('2011-01', 2, roll='forward', weekmask='Wed')
  1538|         0|            0|            0|  0.00%|    numpy.datetime64('2011-01-19')
  1539|         0|            0|            0|  0.00%|    >>> # 2012 Mother's Day in Canada and the U.S.
  1540|         0|            0|            0|  0.00%|    ... np.busday_offset('2012-05', 1, roll='forward', weekmask='Sun')
  1541|         0|            0|            0|  0.00%|    numpy.datetime64('2012-05-13')
  1542|         0|            0|            0|  0.00%|
  1543|         0|            0|            0|  0.00%|    >>> # First business day on or after a date
  1544|         0|            0|            0|  0.00%|    ... np.busday_offset('2011-03-20', 0, roll='forward')
  1545|         0|            0|            0|  0.00%|    numpy.datetime64('2011-03-21')
  1546|         0|            0|            0|  0.00%|    >>> np.busday_offset('2011-03-22', 0, roll='forward')
  1547|         0|            0|            0|  0.00%|    numpy.datetime64('2011-03-22')
  1548|         0|            0|            0|  0.00%|    >>> # First business day after a date
  1549|         0|            0|            0|  0.00%|    ... np.busday_offset('2011-03-20', 1, roll='backward')
  1550|         0|            0|            0|  0.00%|    numpy.datetime64('2011-03-21')
  1551|         0|            0|            0|  0.00%|    >>> np.busday_offset('2011-03-22', 1, roll='backward')
  1552|         0|            0|            0|  0.00%|    numpy.datetime64('2011-03-23')
  1553|         0|            0|            0|  0.00%|    """
  1554|         0|            0|            0|  0.00%|    return (dates, offsets, weekmask, holidays, out)
  1555|         0|            0|            0|  0.00%|
  1556|         0|            0|            0|  0.00%|
  1557|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.busday_count)
  1558|         0|            0|            0|  0.00%|def busday_count(begindates, enddates, weekmask=None, holidays=None,
  1559|         0|            0|            0|  0.00%|                 busdaycal=None, out=None):
  1560|         0|            0|            0|  0.00%|    """
  1561|         0|            0|            0|  0.00%|    busday_count(begindates, enddates, weekmask='1111100', holidays=[], busdaycal=None, out=None)
  1562|         0|            0|            0|  0.00%|
  1563|         0|            0|            0|  0.00%|    Counts the number of valid days between `begindates` and
  1564|         0|            0|            0|  0.00%|    `enddates`, not including the day of `enddates`.
  1565|         0|            0|            0|  0.00%|
  1566|         0|            0|            0|  0.00%|    If ``enddates`` specifies a date value that is earlier than the
  1567|         0|            0|            0|  0.00%|    corresponding ``begindates`` date value, the count will be negative.
  1568|         0|            0|            0|  0.00%|
  1569|         0|            0|            0|  0.00%|    .. versionadded:: 1.7.0
  1570|         0|            0|            0|  0.00%|
  1571|         0|            0|            0|  0.00%|    Parameters
  1572|         0|            0|            0|  0.00%|    ----------
  1573|         0|            0|            0|  0.00%|    begindates : array_like of datetime64[D]
  1574|         0|            0|            0|  0.00%|        The array of the first dates for counting.
  1575|         0|            0|            0|  0.00%|    enddates : array_like of datetime64[D]
  1576|         0|            0|            0|  0.00%|        The array of the end dates for counting, which are excluded
  1577|         0|            0|            0|  0.00%|        from the count themselves.
  1578|         0|            0|            0|  0.00%|    weekmask : str or array_like of bool, optional
  1579|         0|            0|            0|  0.00%|        A seven-element array indicating which of Monday through Sunday are
  1580|         0|            0|            0|  0.00%|        valid days. May be specified as a length-seven list or array, like
  1581|         0|            0|            0|  0.00%|        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string
  1582|         0|            0|            0|  0.00%|        like "Mon Tue Wed Thu Fri", made up of 3-character abbreviations for
  1583|         0|            0|            0|  0.00%|        weekdays, optionally separated by white space. Valid abbreviations
  1584|         0|            0|            0|  0.00%|        are: Mon Tue Wed Thu Fri Sat Sun
  1585|         0|            0|            0|  0.00%|    holidays : array_like of datetime64[D], optional
  1586|         0|            0|            0|  0.00%|        An array of dates to consider as invalid dates.  They may be
  1587|         0|            0|            0|  0.00%|        specified in any order, and NaT (not-a-time) dates are ignored.
  1588|         0|            0|            0|  0.00%|        This list is saved in a normalized form that is suited for
  1589|         0|            0|            0|  0.00%|        fast calculations of valid days.
  1590|         0|            0|            0|  0.00%|    busdaycal : busdaycalendar, optional
  1591|         0|            0|            0|  0.00%|        A `busdaycalendar` object which specifies the valid days. If this
  1592|         0|            0|            0|  0.00%|        parameter is provided, neither weekmask nor holidays may be
  1593|         0|            0|            0|  0.00%|        provided.
  1594|         0|            0|            0|  0.00%|    out : array of int, optional
  1595|         0|            0|            0|  0.00%|        If provided, this array is filled with the result.
  1596|         0|            0|            0|  0.00%|
  1597|         0|            0|            0|  0.00%|    Returns
  1598|         0|            0|            0|  0.00%|    -------
  1599|         0|            0|            0|  0.00%|    out : array of int
  1600|         0|            0|            0|  0.00%|        An array with a shape from broadcasting ``begindates`` and ``enddates``
  1601|         0|            0|            0|  0.00%|        together, containing the number of valid days between
  1602|         0|            0|            0|  0.00%|        the begin and end dates.
  1603|         0|            0|            0|  0.00%|
  1604|         0|            0|            0|  0.00%|    See Also
  1605|         0|            0|            0|  0.00%|    --------
  1606|         0|            0|            0|  0.00%|    busdaycalendar : An object that specifies a custom set of valid days.
  1607|         0|            0|            0|  0.00%|    is_busday : Returns a boolean array indicating valid days.
  1608|         0|            0|            0|  0.00%|    busday_offset : Applies an offset counted in valid days.
  1609|         0|            0|            0|  0.00%|
  1610|         0|            0|            0|  0.00%|    Examples
  1611|         0|            0|            0|  0.00%|    --------
  1612|         0|            0|            0|  0.00%|    >>> # Number of weekdays in January 2011
  1613|         0|            0|            0|  0.00%|    ... np.busday_count('2011-01', '2011-02')
  1614|         0|            0|            0|  0.00%|    21
  1615|         0|            0|            0|  0.00%|    >>> # Number of weekdays in 2011
  1616|         0|            0|            0|  0.00%|    >>> np.busday_count('2011', '2012')
  1617|         0|            0|            0|  0.00%|    260
  1618|         0|            0|            0|  0.00%|    >>> # Number of Saturdays in 2011
  1619|         0|            0|            0|  0.00%|    ... np.busday_count('2011', '2012', weekmask='Sat')
  1620|         0|            0|            0|  0.00%|    53
  1621|         0|            0|            0|  0.00%|    """
  1622|         0|            0|            0|  0.00%|    return (begindates, enddates, weekmask, holidays, out)
  1623|         0|            0|            0|  0.00%|
  1624|         0|            0|            0|  0.00%|
  1625|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(
  1626|         0|            0|            0|  0.00%|    _multiarray_umath.datetime_as_string)
  1627|         0|            0|            0|  0.00%|def datetime_as_string(arr, unit=None, timezone=None, casting=None):
  1628|         0|            0|            0|  0.00%|    """
  1629|         0|            0|            0|  0.00%|    datetime_as_string(arr, unit=None, timezone='naive', casting='same_kind')
  1630|         0|            0|            0|  0.00%|
  1631|         0|            0|            0|  0.00%|    Convert an array of datetimes into an array of strings.
  1632|         0|            0|            0|  0.00%|
  1633|         0|            0|            0|  0.00%|    Parameters
  1634|         0|            0|            0|  0.00%|    ----------
  1635|         0|            0|            0|  0.00%|    arr : array_like of datetime64
  1636|         0|            0|            0|  0.00%|        The array of UTC timestamps to format.
  1637|         0|            0|            0|  0.00%|    unit : str
  1638|         0|            0|            0|  0.00%|        One of None, 'auto', or a :ref:`datetime unit <arrays.dtypes.dateunits>`.
  1639|         0|            0|            0|  0.00%|    timezone : {'naive', 'UTC', 'local'} or tzinfo
  1640|         0|            0|            0|  0.00%|        Timezone information to use when displaying the datetime. If 'UTC', end
  1641|         0|            0|            0|  0.00%|        with a Z to indicate UTC time. If 'local', convert to the local timezone
  1642|         0|            0|            0|  0.00%|        first, and suffix with a +-#### timezone offset. If a tzinfo object,
  1643|         0|            0|            0|  0.00%|        then do as with 'local', but use the specified timezone.
  1644|         0|            0|            0|  0.00%|    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}
  1645|         0|            0|            0|  0.00%|        Casting to allow when changing between datetime units.
  1646|         0|            0|            0|  0.00%|
  1647|         0|            0|            0|  0.00%|    Returns
  1648|         0|            0|            0|  0.00%|    -------
  1649|         0|            0|            0|  0.00%|    str_arr : ndarray
  1650|         0|            0|            0|  0.00%|        An array of strings the same shape as `arr`.
  1651|         0|            0|            0|  0.00%|
  1652|         0|            0|            0|  0.00%|    Examples
  1653|         0|            0|            0|  0.00%|    --------
  1654|         0|            0|            0|  0.00%|    >>> import pytz
  1655|         0|            0|            0|  0.00%|    >>> d = np.arange('2002-10-27T04:30', 4*60, 60, dtype='M8[m]')
  1656|         0|            0|            0|  0.00%|    >>> d
  1657|         0|            0|            0|  0.00%|    array(['2002-10-27T04:30', '2002-10-27T05:30', '2002-10-27T06:30',
  1658|         0|            0|            0|  0.00%|           '2002-10-27T07:30'], dtype='datetime64[m]')
  1659|         0|            0|            0|  0.00%|
  1660|         0|            0|            0|  0.00%|    Setting the timezone to UTC shows the same information, but with a Z suffix
  1661|         0|            0|            0|  0.00%|
  1662|         0|            0|            0|  0.00%|    >>> np.datetime_as_string(d, timezone='UTC')
  1663|         0|            0|            0|  0.00%|    array(['2002-10-27T04:30Z', '2002-10-27T05:30Z', '2002-10-27T06:30Z',
  1664|         0|            0|            0|  0.00%|           '2002-10-27T07:30Z'], dtype='<U35')
  1665|         0|            0|            0|  0.00%|
  1666|         0|            0|            0|  0.00%|    Note that we picked datetimes that cross a DST boundary. Passing in a
  1667|         0|            0|            0|  0.00%|    ``pytz`` timezone object will print the appropriate offset
  1668|         0|            0|            0|  0.00%|
  1669|         0|            0|            0|  0.00%|    >>> np.datetime_as_string(d, timezone=pytz.timezone('US/Eastern'))
  1670|         0|            0|            0|  0.00%|    array(['2002-10-27T00:30-0400', '2002-10-27T01:30-0400',
  1671|         0|            0|            0|  0.00%|           '2002-10-27T01:30-0500', '2002-10-27T02:30-0500'], dtype='<U39')
  1672|         0|            0|            0|  0.00%|
  1673|         0|            0|            0|  0.00%|    Passing in a unit will change the precision
  1674|         0|            0|            0|  0.00%|
  1675|         0|            0|            0|  0.00%|    >>> np.datetime_as_string(d, unit='h')
  1676|         0|            0|            0|  0.00%|    array(['2002-10-27T04', '2002-10-27T05', '2002-10-27T06', '2002-10-27T07'],
  1677|         0|            0|            0|  0.00%|          dtype='<U32')
  1678|         0|            0|            0|  0.00%|    >>> np.datetime_as_string(d, unit='s')
  1679|         0|            0|            0|  0.00%|    array(['2002-10-27T04:30:00', '2002-10-27T05:30:00', '2002-10-27T06:30:00',
  1680|         0|            0|            0|  0.00%|           '2002-10-27T07:30:00'], dtype='<U38')
  1681|         0|            0|            0|  0.00%|
  1682|         0|            0|            0|  0.00%|    'casting' can be used to specify whether precision can be changed
  1683|         0|            0|            0|  0.00%|
  1684|         0|            0|            0|  0.00%|    >>> np.datetime_as_string(d, unit='h', casting='safe')
  1685|         0|            0|            0|  0.00%|    Traceback (most recent call last):
  1686|         0|            0|            0|  0.00%|        ...
  1687|         0|            0|            0|  0.00%|    TypeError: Cannot create a datetime string as units 'h' from a NumPy
  1688|         0|            0|            0|  0.00%|    datetime with units 'm' according to the rule 'safe'
  1689|         0|            0|            0|  0.00%|    """
  1690|         0|            0|            0|  0.00%|    return (arr,)
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/numpy/core/numeric.py
File duration: 0.311791s (0.30%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import functools
     2|         0|            0|            0|  0.00%|import itertools
     3|         0|            0|            0|  0.00%|import operator
     4|         0|            0|            0|  0.00%|import sys
     5|         0|            0|            0|  0.00%|import warnings
     6|         0|            0|            0|  0.00%|import numbers
     7|         0|            0|            0|  0.00%|
     8|         0|            0|            0|  0.00%|import numpy as np
     9|         0|            0|            0|  0.00%|from . import multiarray
    10|         0|            0|            0|  0.00%|from .multiarray import (
    11|         0|            0|            0|  0.00%|    _fastCopyAndTranspose as fastCopyAndTranspose, ALLOW_THREADS,
    12|         0|            0|            0|  0.00%|    BUFSIZE, CLIP, MAXDIMS, MAY_SHARE_BOUNDS, MAY_SHARE_EXACT, RAISE,
    13|         0|            0|            0|  0.00%|    WRAP, arange, array, asarray, asanyarray, ascontiguousarray,
    14|         0|            0|            0|  0.00%|    asfortranarray, broadcast, can_cast, compare_chararrays,
    15|         0|            0|            0|  0.00%|    concatenate, copyto, dot, dtype, empty,
    16|         0|            0|            0|  0.00%|    empty_like, flatiter, frombuffer, _from_dlpack, fromfile, fromiter,
    17|         0|            0|            0|  0.00%|    fromstring, inner, lexsort, matmul, may_share_memory,
    18|         0|            0|            0|  0.00%|    min_scalar_type, ndarray, nditer, nested_iters, promote_types,
    19|         0|            0|            0|  0.00%|    putmask, result_type, set_numeric_ops, shares_memory, vdot, where,
    20|         0|            0|            0|  0.00%|    zeros, normalize_axis_index)
    21|         0|            0|            0|  0.00%|
    22|         0|            0|            0|  0.00%|from . import overrides
    23|         0|            0|            0|  0.00%|from . import umath
    24|         0|            0|            0|  0.00%|from . import shape_base
    25|         0|            0|            0|  0.00%|from .overrides import set_array_function_like_doc, set_module
    26|         0|            0|            0|  0.00%|from .umath import (multiply, invert, sin, PINF, NAN)
    27|         0|            0|            0|  0.00%|from . import numerictypes
    28|         0|            0|            0|  0.00%|from .numerictypes import longlong, intc, int_, float_, complex_, bool_
    29|         0|            0|            0|  0.00%|from ._exceptions import TooHardError, AxisError
    30|         0|            0|            0|  0.00%|from ._ufunc_config import errstate
    31|         0|            0|            0|  0.00%|
    32|         0|            0|            0|  0.00%|bitwise_not = invert
    33|         0|            0|            0|  0.00%|ufunc = type(sin)
    34|         0|            0|            0|  0.00%|newaxis = None
    35|         0|            0|            0|  0.00%|
    36|         0|            0|            0|  0.00%|array_function_dispatch = functools.partial(
    37|         0|            0|            0|  0.00%|    overrides.array_function_dispatch, module='numpy')
    38|         0|            0|            0|  0.00%|
    39|         0|            0|            0|  0.00%|
    40|         0|            0|            0|  0.00%|__all__ = [
    41|         0|            0|            0|  0.00%|    'newaxis', 'ndarray', 'flatiter', 'nditer', 'nested_iters', 'ufunc',
    42|         0|            0|            0|  0.00%|    'arange', 'array', 'asarray', 'asanyarray', 'ascontiguousarray',
    43|         0|            0|            0|  0.00%|    'asfortranarray', 'zeros', 'count_nonzero', 'empty', 'broadcast', 'dtype',
    44|         0|            0|            0|  0.00%|    'fromstring', 'fromfile', 'frombuffer', '_from_dlpack', 'where',
    45|         0|            0|            0|  0.00%|    'argwhere', 'copyto', 'concatenate', 'fastCopyAndTranspose', 'lexsort',
    46|         0|            0|            0|  0.00%|    'set_numeric_ops', 'can_cast', 'promote_types', 'min_scalar_type',
    47|         0|            0|            0|  0.00%|    'result_type', 'isfortran', 'empty_like', 'zeros_like', 'ones_like',
    48|         0|            0|            0|  0.00%|    'correlate', 'convolve', 'inner', 'dot', 'outer', 'vdot', 'roll',
    49|         0|            0|            0|  0.00%|    'rollaxis', 'moveaxis', 'cross', 'tensordot', 'little_endian',
    50|         0|            0|            0|  0.00%|    'fromiter', 'array_equal', 'array_equiv', 'indices', 'fromfunction',
    51|         0|            0|            0|  0.00%|    'isclose', 'isscalar', 'binary_repr', 'base_repr', 'ones',
    52|         0|            0|            0|  0.00%|    'identity', 'allclose', 'compare_chararrays', 'putmask',
    53|         0|            0|            0|  0.00%|    'flatnonzero', 'Inf', 'inf', 'infty', 'Infinity', 'nan', 'NaN',
    54|         0|            0|            0|  0.00%|    'False_', 'True_', 'bitwise_not', 'CLIP', 'RAISE', 'WRAP', 'MAXDIMS',
    55|         0|            0|            0|  0.00%|    'BUFSIZE', 'ALLOW_THREADS', 'ComplexWarning', 'full', 'full_like',
    56|         0|            0|            0|  0.00%|    'matmul', 'shares_memory', 'may_share_memory', 'MAY_SHARE_BOUNDS',
    57|         0|            0|            0|  0.00%|    'MAY_SHARE_EXACT', 'TooHardError', 'AxisError']
    58|         0|            0|            0|  0.00%|
    59|         0|            0|            0|  0.00%|
    60|         0|            0|            0|  0.00%|@set_module('numpy')
    61|         0|            0|            0|  0.00%|class ComplexWarning(RuntimeWarning):
    62|         0|            0|            0|  0.00%|    """
    63|         0|            0|            0|  0.00%|    The warning raised when casting a complex dtype to a real dtype.
    64|         0|            0|            0|  0.00%|
    65|         0|            0|            0|  0.00%|    As implemented, casting a complex number to a real discards its imaginary
    66|         0|            0|            0|  0.00%|    part, but this behavior may not be what the user actually wants.
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|    """
    69|         0|            0|            0|  0.00%|    pass
    70|         0|            0|            0|  0.00%|
    71|         0|            0|            0|  0.00%|
    72|     10557|    0.0186782|  1.76927e-06|  0.02%|def _zeros_like_dispatcher(a, dtype=None, order=None, subok=None, shape=None):
    73|     10557|     0.023035|  2.18197e-06|  0.02%|    return (a,)
    74|         0|            0|            0|  0.00%|
    75|         0|            0|            0|  0.00%|
    76|     10557|    0.0254703|  2.41264e-06|  0.02%|@array_function_dispatch(_zeros_like_dispatcher)
    77|         0|            0|            0|  0.00%|def zeros_like(a, dtype=None, order='K', subok=True, shape=None):
    78|         0|            0|            0|  0.00%|    """
    79|         0|            0|            0|  0.00%|    Return an array of zeros with the same shape and type as a given array.
    80|         0|            0|            0|  0.00%|
    81|         0|            0|            0|  0.00%|    Parameters
    82|         0|            0|            0|  0.00%|    ----------
    83|         0|            0|            0|  0.00%|    a : array_like
    84|         0|            0|            0|  0.00%|        The shape and data-type of `a` define these same attributes of
    85|         0|            0|            0|  0.00%|        the returned array.
    86|         0|            0|            0|  0.00%|    dtype : data-type, optional
    87|         0|            0|            0|  0.00%|        Overrides the data type of the result.
    88|         0|            0|            0|  0.00%|
    89|         0|            0|            0|  0.00%|        .. versionadded:: 1.6.0
    90|         0|            0|            0|  0.00%|    order : {'C', 'F', 'A', or 'K'}, optional
    91|         0|            0|            0|  0.00%|        Overrides the memory layout of the result. 'C' means C-order,
    92|         0|            0|            0|  0.00%|        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,
    93|         0|            0|            0|  0.00%|        'C' otherwise. 'K' means match the layout of `a` as closely
    94|         0|            0|            0|  0.00%|        as possible.
    95|         0|            0|            0|  0.00%|
    96|         0|            0|            0|  0.00%|        .. versionadded:: 1.6.0
    97|         0|            0|            0|  0.00%|    subok : bool, optional.
    98|         0|            0|            0|  0.00%|        If True, then the newly created array will use the sub-class
    99|         0|            0|            0|  0.00%|        type of `a`, otherwise it will be a base-class array. Defaults
   100|         0|            0|            0|  0.00%|        to True.
   101|         0|            0|            0|  0.00%|    shape : int or sequence of ints, optional.
   102|         0|            0|            0|  0.00%|        Overrides the shape of the result. If order='K' and the number of
   103|         0|            0|            0|  0.00%|        dimensions is unchanged, will try to keep order, otherwise,
   104|         0|            0|            0|  0.00%|        order='C' is implied.
   105|         0|            0|            0|  0.00%|
   106|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
   107|         0|            0|            0|  0.00%|
   108|         0|            0|            0|  0.00%|    Returns
   109|         0|            0|            0|  0.00%|    -------
   110|         0|            0|            0|  0.00%|    out : ndarray
   111|         0|            0|            0|  0.00%|        Array of zeros with the same shape and type as `a`.
   112|         0|            0|            0|  0.00%|
   113|         0|            0|            0|  0.00%|    See Also
   114|         0|            0|            0|  0.00%|    --------
   115|         0|            0|            0|  0.00%|    empty_like : Return an empty array with shape and type of input.
   116|         0|            0|            0|  0.00%|    ones_like : Return an array of ones with shape and type of input.
   117|         0|            0|            0|  0.00%|    full_like : Return a new array with shape of input filled with value.
   118|         0|            0|            0|  0.00%|    zeros : Return a new array setting values to zero.
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|    Examples
   121|         0|            0|            0|  0.00%|    --------
   122|         0|            0|            0|  0.00%|    >>> x = np.arange(6)
   123|         0|            0|            0|  0.00%|    >>> x = x.reshape((2, 3))
   124|         0|            0|            0|  0.00%|    >>> x
   125|         0|            0|            0|  0.00%|    array([[0, 1, 2],
   126|         0|            0|            0|  0.00%|           [3, 4, 5]])
   127|         0|            0|            0|  0.00%|    >>> np.zeros_like(x)
   128|         0|            0|            0|  0.00%|    array([[0, 0, 0],
   129|         0|            0|            0|  0.00%|           [0, 0, 0]])
   130|         0|            0|            0|  0.00%|
   131|         0|            0|            0|  0.00%|    >>> y = np.arange(3, dtype=float)
   132|         0|            0|            0|  0.00%|    >>> y
   133|         0|            0|            0|  0.00%|    array([0., 1., 2.])
   134|         0|            0|            0|  0.00%|    >>> np.zeros_like(y)
   135|         0|            0|            0|  0.00%|    array([0.,  0.,  0.])
   136|         0|            0|            0|  0.00%|
   137|         0|            0|            0|  0.00%|    """
   138|     10557|    0.0815167|  7.72158e-06|  0.08%|    res = empty_like(a, dtype=dtype, order=order, subok=subok, shape=shape)
(call)|     10557|      0.21935|  2.07776e-05|  0.21%|# <__array_function__ internals>:177 empty_like
   139|         0|            0|            0|  0.00%|    # needed instead of a 0 to get same result as zeros for for string dtypes
   140|     10557|    0.0413554|  3.91734e-06|  0.04%|    z = zeros(1, dtype=res.dtype)
   141|     10557|    0.0747209|  7.07785e-06|  0.07%|    multiarray.copyto(res, z, casting='unsafe')
(call)|     10557|     0.204033|  1.93268e-05|  0.20%|# <__array_function__ internals>:177 copyto
   142|     10557|    0.0214927|  2.03587e-06|  0.02%|    return res
   143|         0|            0|            0|  0.00%|
   144|         0|            0|            0|  0.00%|
   145|         0|            0|            0|  0.00%|def _ones_dispatcher(shape, dtype=None, order=None, *, like=None):
   146|         0|            0|            0|  0.00%|    return(like,)
   147|         0|            0|            0|  0.00%|
   148|         0|            0|            0|  0.00%|
   149|      1349|     0.003479|  2.57895e-06|  0.00%|@set_array_function_like_doc
   150|         0|            0|            0|  0.00%|@set_module('numpy')
   151|         0|            0|            0|  0.00%|def ones(shape, dtype=None, order='C', *, like=None):
   152|         0|            0|            0|  0.00%|    """
   153|         0|            0|            0|  0.00%|    Return a new array of given shape and type, filled with ones.
   154|         0|            0|            0|  0.00%|
   155|         0|            0|            0|  0.00%|    Parameters
   156|         0|            0|            0|  0.00%|    ----------
   157|         0|            0|            0|  0.00%|    shape : int or sequence of ints
   158|         0|            0|            0|  0.00%|        Shape of the new array, e.g., ``(2, 3)`` or ``2``.
   159|         0|            0|            0|  0.00%|    dtype : data-type, optional
   160|         0|            0|            0|  0.00%|        The desired data-type for the array, e.g., `numpy.int8`.  Default is
   161|         0|            0|            0|  0.00%|        `numpy.float64`.
   162|         0|            0|            0|  0.00%|    order : {'C', 'F'}, optional, default: C
   163|         0|            0|            0|  0.00%|        Whether to store multi-dimensional data in row-major
   164|         0|            0|            0|  0.00%|        (C-style) or column-major (Fortran-style) order in
   165|         0|            0|            0|  0.00%|        memory.
   166|         0|            0|            0|  0.00%|    ${ARRAY_FUNCTION_LIKE}
   167|         0|            0|            0|  0.00%|
   168|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
   169|         0|            0|            0|  0.00%|
   170|         0|            0|            0|  0.00%|    Returns
   171|         0|            0|            0|  0.00%|    -------
   172|         0|            0|            0|  0.00%|    out : ndarray
   173|         0|            0|            0|  0.00%|        Array of ones with the given shape, dtype, and order.
   174|         0|            0|            0|  0.00%|
   175|         0|            0|            0|  0.00%|    See Also
   176|         0|            0|            0|  0.00%|    --------
   177|         0|            0|            0|  0.00%|    ones_like : Return an array of ones with shape and type of input.
   178|         0|            0|            0|  0.00%|    empty : Return a new uninitialized array.
   179|         0|            0|            0|  0.00%|    zeros : Return a new array setting values to zero.
   180|         0|            0|            0|  0.00%|    full : Return a new array of given shape filled with value.
   181|         0|            0|            0|  0.00%|
   182|         0|            0|            0|  0.00%|
   183|         0|            0|            0|  0.00%|    Examples
   184|         0|            0|            0|  0.00%|    --------
   185|         0|            0|            0|  0.00%|    >>> np.ones(5)
   186|         0|            0|            0|  0.00%|    array([1., 1., 1., 1., 1.])
   187|         0|            0|            0|  0.00%|
   188|         0|            0|            0|  0.00%|    >>> np.ones((5,), dtype=int)
   189|         0|            0|            0|  0.00%|    array([1, 1, 1, 1, 1])
   190|         0|            0|            0|  0.00%|
   191|         0|            0|            0|  0.00%|    >>> np.ones((2, 1))
   192|         0|            0|            0|  0.00%|    array([[1.],
   193|         0|            0|            0|  0.00%|           [1.]])
   194|         0|            0|            0|  0.00%|
   195|         0|            0|            0|  0.00%|    >>> s = (2,2)
   196|         0|            0|            0|  0.00%|    >>> np.ones(s)
   197|         0|            0|            0|  0.00%|    array([[1.,  1.],
   198|         0|            0|            0|  0.00%|           [1.,  1.]])
   199|         0|            0|            0|  0.00%|
   200|         0|            0|            0|  0.00%|    """
   201|      1349|   0.00329232|  2.44056e-06|  0.00%|    if like is not None:
   202|         0|            0|            0|  0.00%|        return _ones_with_like(shape, dtype=dtype, order=order, like=like)
   203|         0|            0|            0|  0.00%|
   204|      1349|   0.00524735|  3.88981e-06|  0.01%|    a = empty(shape, dtype, order)
   205|      1349|    0.0106637|  7.90493e-06|  0.01%|    multiarray.copyto(a, 1, casting='unsafe')
(call)|      1349|    0.0327747|  2.42955e-05|  0.03%|# <__array_function__ internals>:177 copyto
   206|      1349|   0.00283933|  2.10476e-06|  0.00%|    return a
   207|         0|            0|            0|  0.00%|
   208|         0|            0|            0|  0.00%|
   209|         0|            0|            0|  0.00%|_ones_with_like = array_function_dispatch(
   210|         0|            0|            0|  0.00%|    _ones_dispatcher
   211|         0|            0|            0|  0.00%|)(ones)
   212|         0|            0|            0|  0.00%|
   213|         0|            0|            0|  0.00%|
   214|         0|            0|            0|  0.00%|def _ones_like_dispatcher(a, dtype=None, order=None, subok=None, shape=None):
   215|         0|            0|            0|  0.00%|    return (a,)
   216|         0|            0|            0|  0.00%|
   217|         0|            0|            0|  0.00%|
   218|         0|            0|            0|  0.00%|@array_function_dispatch(_ones_like_dispatcher)
   219|         0|            0|            0|  0.00%|def ones_like(a, dtype=None, order='K', subok=True, shape=None):
   220|         0|            0|            0|  0.00%|    """
   221|         0|            0|            0|  0.00%|    Return an array of ones with the same shape and type as a given array.
   222|         0|            0|            0|  0.00%|
   223|         0|            0|            0|  0.00%|    Parameters
   224|         0|            0|            0|  0.00%|    ----------
   225|         0|            0|            0|  0.00%|    a : array_like
   226|         0|            0|            0|  0.00%|        The shape and data-type of `a` define these same attributes of
   227|         0|            0|            0|  0.00%|        the returned array.
   228|         0|            0|            0|  0.00%|    dtype : data-type, optional
   229|         0|            0|            0|  0.00%|        Overrides the data type of the result.
   230|         0|            0|            0|  0.00%|
   231|         0|            0|            0|  0.00%|        .. versionadded:: 1.6.0
   232|         0|            0|            0|  0.00%|    order : {'C', 'F', 'A', or 'K'}, optional
   233|         0|            0|            0|  0.00%|        Overrides the memory layout of the result. 'C' means C-order,
   234|         0|            0|            0|  0.00%|        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,
   235|         0|            0|            0|  0.00%|        'C' otherwise. 'K' means match the layout of `a` as closely
   236|         0|            0|            0|  0.00%|        as possible.
   237|         0|            0|            0|  0.00%|
   238|         0|            0|            0|  0.00%|        .. versionadded:: 1.6.0
   239|         0|            0|            0|  0.00%|    subok : bool, optional.
   240|         0|            0|            0|  0.00%|        If True, then the newly created array will use the sub-class
   241|         0|            0|            0|  0.00%|        type of `a`, otherwise it will be a base-class array. Defaults
   242|         0|            0|            0|  0.00%|        to True.
   243|         0|            0|            0|  0.00%|    shape : int or sequence of ints, optional.
   244|         0|            0|            0|  0.00%|        Overrides the shape of the result. If order='K' and the number of
   245|         0|            0|            0|  0.00%|        dimensions is unchanged, will try to keep order, otherwise,
   246|         0|            0|            0|  0.00%|        order='C' is implied.
   247|         0|            0|            0|  0.00%|
   248|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
   249|         0|            0|            0|  0.00%|
   250|         0|            0|            0|  0.00%|    Returns
   251|         0|            0|            0|  0.00%|    -------
   252|         0|            0|            0|  0.00%|    out : ndarray
   253|         0|            0|            0|  0.00%|        Array of ones with the same shape and type as `a`.
   254|         0|            0|            0|  0.00%|
   255|         0|            0|            0|  0.00%|    See Also
   256|         0|            0|            0|  0.00%|    --------
   257|         0|            0|            0|  0.00%|    empty_like : Return an empty array with shape and type of input.
   258|         0|            0|            0|  0.00%|    zeros_like : Return an array of zeros with shape and type of input.
   259|         0|            0|            0|  0.00%|    full_like : Return a new array with shape of input filled with value.
   260|         0|            0|            0|  0.00%|    ones : Return a new array setting values to one.
   261|         0|            0|            0|  0.00%|
   262|         0|            0|            0|  0.00%|    Examples
   263|         0|            0|            0|  0.00%|    --------
   264|         0|            0|            0|  0.00%|    >>> x = np.arange(6)
   265|         0|            0|            0|  0.00%|    >>> x = x.reshape((2, 3))
   266|         0|            0|            0|  0.00%|    >>> x
   267|         0|            0|            0|  0.00%|    array([[0, 1, 2],
   268|         0|            0|            0|  0.00%|           [3, 4, 5]])
   269|         0|            0|            0|  0.00%|    >>> np.ones_like(x)
   270|         0|            0|            0|  0.00%|    array([[1, 1, 1],
   271|         0|            0|            0|  0.00%|           [1, 1, 1]])
   272|         0|            0|            0|  0.00%|
   273|         0|            0|            0|  0.00%|    >>> y = np.arange(3, dtype=float)
   274|         0|            0|            0|  0.00%|    >>> y
   275|         0|            0|            0|  0.00%|    array([0., 1., 2.])
   276|         0|            0|            0|  0.00%|    >>> np.ones_like(y)
   277|         0|            0|            0|  0.00%|    array([1.,  1.,  1.])
   278|         0|            0|            0|  0.00%|
   279|         0|            0|            0|  0.00%|    """
   280|         0|            0|            0|  0.00%|    res = empty_like(a, dtype=dtype, order=order, subok=subok, shape=shape)
   281|         0|            0|            0|  0.00%|    multiarray.copyto(res, 1, casting='unsafe')
   282|         0|            0|            0|  0.00%|    return res
   283|         0|            0|            0|  0.00%|
   284|         0|            0|            0|  0.00%|
   285|         0|            0|            0|  0.00%|def _full_dispatcher(shape, fill_value, dtype=None, order=None, *, like=None):
   286|         0|            0|            0|  0.00%|    return(like,)
   287|         0|            0|            0|  0.00%|
   288|         0|            0|            0|  0.00%|
   289|         0|            0|            0|  0.00%|@set_array_function_like_doc
   290|         0|            0|            0|  0.00%|@set_module('numpy')
   291|         0|            0|            0|  0.00%|def full(shape, fill_value, dtype=None, order='C', *, like=None):
   292|         0|            0|            0|  0.00%|    """
   293|         0|            0|            0|  0.00%|    Return a new array of given shape and type, filled with `fill_value`.
   294|         0|            0|            0|  0.00%|
   295|         0|            0|            0|  0.00%|    Parameters
   296|         0|            0|            0|  0.00%|    ----------
   297|         0|            0|            0|  0.00%|    shape : int or sequence of ints
   298|         0|            0|            0|  0.00%|        Shape of the new array, e.g., ``(2, 3)`` or ``2``.
   299|         0|            0|            0|  0.00%|    fill_value : scalar or array_like
   300|         0|            0|            0|  0.00%|        Fill value.
   301|         0|            0|            0|  0.00%|    dtype : data-type, optional
   302|         0|            0|            0|  0.00%|        The desired data-type for the array  The default, None, means
   303|         0|            0|            0|  0.00%|         ``np.array(fill_value).dtype``.
   304|         0|            0|            0|  0.00%|    order : {'C', 'F'}, optional
   305|         0|            0|            0|  0.00%|        Whether to store multidimensional data in C- or Fortran-contiguous
   306|         0|            0|            0|  0.00%|        (row- or column-wise) order in memory.
   307|         0|            0|            0|  0.00%|    ${ARRAY_FUNCTION_LIKE}
   308|         0|            0|            0|  0.00%|
   309|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
   310|         0|            0|            0|  0.00%|
   311|         0|            0|            0|  0.00%|    Returns
   312|         0|            0|            0|  0.00%|    -------
   313|         0|            0|            0|  0.00%|    out : ndarray
   314|         0|            0|            0|  0.00%|        Array of `fill_value` with the given shape, dtype, and order.
   315|         0|            0|            0|  0.00%|
   316|         0|            0|            0|  0.00%|    See Also
   317|         0|            0|            0|  0.00%|    --------
   318|         0|            0|            0|  0.00%|    full_like : Return a new array with shape of input filled with value.
   319|         0|            0|            0|  0.00%|    empty : Return a new uninitialized array.
   320|         0|            0|            0|  0.00%|    ones : Return a new array setting values to one.
   321|         0|            0|            0|  0.00%|    zeros : Return a new array setting values to zero.
   322|         0|            0|            0|  0.00%|
   323|         0|            0|            0|  0.00%|    Examples
   324|         0|            0|            0|  0.00%|    --------
   325|         0|            0|            0|  0.00%|    >>> np.full((2, 2), np.inf)
   326|         0|            0|            0|  0.00%|    array([[inf, inf],
   327|         0|            0|            0|  0.00%|           [inf, inf]])
   328|         0|            0|            0|  0.00%|    >>> np.full((2, 2), 10)
   329|         0|            0|            0|  0.00%|    array([[10, 10],
   330|         0|            0|            0|  0.00%|           [10, 10]])
   331|         0|            0|            0|  0.00%|
   332|         0|            0|            0|  0.00%|    >>> np.full((2, 2), [1, 2])
   333|         0|            0|            0|  0.00%|    array([[1, 2],
   334|         0|            0|            0|  0.00%|           [1, 2]])
   335|         0|            0|            0|  0.00%|
   336|         0|            0|            0|  0.00%|    """
   337|         0|            0|            0|  0.00%|    if like is not None:
   338|         0|            0|            0|  0.00%|        return _full_with_like(shape, fill_value, dtype=dtype, order=order, like=like)
   339|         0|            0|            0|  0.00%|
   340|         0|            0|            0|  0.00%|    if dtype is None:
   341|         0|            0|            0|  0.00%|        fill_value = asarray(fill_value)
   342|         0|            0|            0|  0.00%|        dtype = fill_value.dtype
   343|         0|            0|            0|  0.00%|    a = empty(shape, dtype, order)
   344|         0|            0|            0|  0.00%|    multiarray.copyto(a, fill_value, casting='unsafe')
   345|         0|            0|            0|  0.00%|    return a
   346|         0|            0|            0|  0.00%|
   347|         0|            0|            0|  0.00%|
   348|         0|            0|            0|  0.00%|_full_with_like = array_function_dispatch(
   349|         0|            0|            0|  0.00%|    _full_dispatcher
   350|         0|            0|            0|  0.00%|)(full)
   351|         0|            0|            0|  0.00%|
   352|         0|            0|            0|  0.00%|
   353|         0|            0|            0|  0.00%|def _full_like_dispatcher(a, fill_value, dtype=None, order=None, subok=None, shape=None):
   354|         0|            0|            0|  0.00%|    return (a,)
   355|         0|            0|            0|  0.00%|
   356|         0|            0|            0|  0.00%|
   357|         0|            0|            0|  0.00%|@array_function_dispatch(_full_like_dispatcher)
   358|         0|            0|            0|  0.00%|def full_like(a, fill_value, dtype=None, order='K', subok=True, shape=None):
   359|         0|            0|            0|  0.00%|    """
   360|         0|            0|            0|  0.00%|    Return a full array with the same shape and type as a given array.
   361|         0|            0|            0|  0.00%|
   362|         0|            0|            0|  0.00%|    Parameters
   363|         0|            0|            0|  0.00%|    ----------
   364|         0|            0|            0|  0.00%|    a : array_like
   365|         0|            0|            0|  0.00%|        The shape and data-type of `a` define these same attributes of
   366|         0|            0|            0|  0.00%|        the returned array.
   367|         0|            0|            0|  0.00%|    fill_value : scalar
   368|         0|            0|            0|  0.00%|        Fill value.
   369|         0|            0|            0|  0.00%|    dtype : data-type, optional
   370|         0|            0|            0|  0.00%|        Overrides the data type of the result.
   371|         0|            0|            0|  0.00%|    order : {'C', 'F', 'A', or 'K'}, optional
   372|         0|            0|            0|  0.00%|        Overrides the memory layout of the result. 'C' means C-order,
   373|         0|            0|            0|  0.00%|        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,
   374|         0|            0|            0|  0.00%|        'C' otherwise. 'K' means match the layout of `a` as closely
   375|         0|            0|            0|  0.00%|        as possible.
   376|         0|            0|            0|  0.00%|    subok : bool, optional.
   377|         0|            0|            0|  0.00%|        If True, then the newly created array will use the sub-class
   378|         0|            0|            0|  0.00%|        type of `a`, otherwise it will be a base-class array. Defaults
   379|         0|            0|            0|  0.00%|        to True.
   380|         0|            0|            0|  0.00%|    shape : int or sequence of ints, optional.
   381|         0|            0|            0|  0.00%|        Overrides the shape of the result. If order='K' and the number of
   382|         0|            0|            0|  0.00%|        dimensions is unchanged, will try to keep order, otherwise,
   383|         0|            0|            0|  0.00%|        order='C' is implied.
   384|         0|            0|            0|  0.00%|
   385|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
   386|         0|            0|            0|  0.00%|
   387|         0|            0|            0|  0.00%|    Returns
   388|         0|            0|            0|  0.00%|    -------
   389|         0|            0|            0|  0.00%|    out : ndarray
   390|         0|            0|            0|  0.00%|        Array of `fill_value` with the same shape and type as `a`.
   391|         0|            0|            0|  0.00%|
   392|         0|            0|            0|  0.00%|    See Also
   393|         0|            0|            0|  0.00%|    --------
   394|         0|            0|            0|  0.00%|    empty_like : Return an empty array with shape and type of input.
   395|         0|            0|            0|  0.00%|    ones_like : Return an array of ones with shape and type of input.
   396|         0|            0|            0|  0.00%|    zeros_like : Return an array of zeros with shape and type of input.
   397|         0|            0|            0|  0.00%|    full : Return a new array of given shape filled with value.
   398|         0|            0|            0|  0.00%|
   399|         0|            0|            0|  0.00%|    Examples
   400|         0|            0|            0|  0.00%|    --------
   401|         0|            0|            0|  0.00%|    >>> x = np.arange(6, dtype=int)
   402|         0|            0|            0|  0.00%|    >>> np.full_like(x, 1)
   403|         0|            0|            0|  0.00%|    array([1, 1, 1, 1, 1, 1])
   404|         0|            0|            0|  0.00%|    >>> np.full_like(x, 0.1)
   405|         0|            0|            0|  0.00%|    array([0, 0, 0, 0, 0, 0])
   406|         0|            0|            0|  0.00%|    >>> np.full_like(x, 0.1, dtype=np.double)
   407|         0|            0|            0|  0.00%|    array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1])
   408|         0|            0|            0|  0.00%|    >>> np.full_like(x, np.nan, dtype=np.double)
   409|         0|            0|            0|  0.00%|    array([nan, nan, nan, nan, nan, nan])
   410|         0|            0|            0|  0.00%|
   411|         0|            0|            0|  0.00%|    >>> y = np.arange(6, dtype=np.double)
   412|         0|            0|            0|  0.00%|    >>> np.full_like(y, 0.1)
   413|         0|            0|            0|  0.00%|    array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1])
   414|         0|            0|            0|  0.00%|
   415|         0|            0|            0|  0.00%|    """
   416|         0|            0|            0|  0.00%|    res = empty_like(a, dtype=dtype, order=order, subok=subok, shape=shape)
   417|         0|            0|            0|  0.00%|    multiarray.copyto(res, fill_value, casting='unsafe')
   418|         0|            0|            0|  0.00%|    return res
   419|         0|            0|            0|  0.00%|
   420|         0|            0|            0|  0.00%|
   421|         0|            0|            0|  0.00%|def _count_nonzero_dispatcher(a, axis=None, *, keepdims=None):
   422|         0|            0|            0|  0.00%|    return (a,)
   423|         0|            0|            0|  0.00%|
   424|         0|            0|            0|  0.00%|
   425|         0|            0|            0|  0.00%|@array_function_dispatch(_count_nonzero_dispatcher)
   426|         0|            0|            0|  0.00%|def count_nonzero(a, axis=None, *, keepdims=False):
   427|         0|            0|            0|  0.00%|    """
   428|         0|            0|            0|  0.00%|    Counts the number of non-zero values in the array ``a``.
   429|         0|            0|            0|  0.00%|
   430|         0|            0|            0|  0.00%|    The word "non-zero" is in reference to the Python 2.x
   431|         0|            0|            0|  0.00%|    built-in method ``__nonzero__()`` (renamed ``__bool__()``
   432|         0|            0|            0|  0.00%|    in Python 3.x) of Python objects that tests an object's
   433|         0|            0|            0|  0.00%|    "truthfulness". For example, any number is considered
   434|         0|            0|            0|  0.00%|    truthful if it is nonzero, whereas any string is considered
   435|         0|            0|            0|  0.00%|    truthful if it is not the empty string. Thus, this function
   436|         0|            0|            0|  0.00%|    (recursively) counts how many elements in ``a`` (and in
   437|         0|            0|            0|  0.00%|    sub-arrays thereof) have their ``__nonzero__()`` or ``__bool__()``
   438|         0|            0|            0|  0.00%|    method evaluated to ``True``.
   439|         0|            0|            0|  0.00%|
   440|         0|            0|            0|  0.00%|    Parameters
   441|         0|            0|            0|  0.00%|    ----------
   442|         0|            0|            0|  0.00%|    a : array_like
   443|         0|            0|            0|  0.00%|        The array for which to count non-zeros.
   444|         0|            0|            0|  0.00%|    axis : int or tuple, optional
   445|         0|            0|            0|  0.00%|        Axis or tuple of axes along which to count non-zeros.
   446|         0|            0|            0|  0.00%|        Default is None, meaning that non-zeros will be counted
   447|         0|            0|            0|  0.00%|        along a flattened version of ``a``.
   448|         0|            0|            0|  0.00%|
   449|         0|            0|            0|  0.00%|        .. versionadded:: 1.12.0
   450|         0|            0|            0|  0.00%|
   451|         0|            0|            0|  0.00%|    keepdims : bool, optional
   452|         0|            0|            0|  0.00%|        If this is set to True, the axes that are counted are left
   453|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
   454|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
   455|         0|            0|            0|  0.00%|
   456|         0|            0|            0|  0.00%|        .. versionadded:: 1.19.0
   457|         0|            0|            0|  0.00%|
   458|         0|            0|            0|  0.00%|    Returns
   459|         0|            0|            0|  0.00%|    -------
   460|         0|            0|            0|  0.00%|    count : int or array of int
   461|         0|            0|            0|  0.00%|        Number of non-zero values in the array along a given axis.
   462|         0|            0|            0|  0.00%|        Otherwise, the total number of non-zero values in the array
   463|         0|            0|            0|  0.00%|        is returned.
   464|         0|            0|            0|  0.00%|
   465|         0|            0|            0|  0.00%|    See Also
   466|         0|            0|            0|  0.00%|    --------
   467|         0|            0|            0|  0.00%|    nonzero : Return the coordinates of all the non-zero values.
   468|         0|            0|            0|  0.00%|
   469|         0|            0|            0|  0.00%|    Examples
   470|         0|            0|            0|  0.00%|    --------
   471|         0|            0|            0|  0.00%|    >>> np.count_nonzero(np.eye(4))
   472|         0|            0|            0|  0.00%|    4
   473|         0|            0|            0|  0.00%|    >>> a = np.array([[0, 1, 7, 0],
   474|         0|            0|            0|  0.00%|    ...               [3, 0, 2, 19]])
   475|         0|            0|            0|  0.00%|    >>> np.count_nonzero(a)
   476|         0|            0|            0|  0.00%|    5
   477|         0|            0|            0|  0.00%|    >>> np.count_nonzero(a, axis=0)
   478|         0|            0|            0|  0.00%|    array([1, 1, 2, 1])
   479|         0|            0|            0|  0.00%|    >>> np.count_nonzero(a, axis=1)
   480|         0|            0|            0|  0.00%|    array([2, 3])
   481|         0|            0|            0|  0.00%|    >>> np.count_nonzero(a, axis=1, keepdims=True)
   482|         0|            0|            0|  0.00%|    array([[2],
   483|         0|            0|            0|  0.00%|           [3]])
   484|         0|            0|            0|  0.00%|    """
   485|         0|            0|            0|  0.00%|    if axis is None and not keepdims:
   486|         0|            0|            0|  0.00%|        return multiarray.count_nonzero(a)
   487|         0|            0|            0|  0.00%|
   488|         0|            0|            0|  0.00%|    a = asanyarray(a)
   489|         0|            0|            0|  0.00%|
   490|         0|            0|            0|  0.00%|    # TODO: this works around .astype(bool) not working properly (gh-9847)
   491|         0|            0|            0|  0.00%|    if np.issubdtype(a.dtype, np.character):
   492|         0|            0|            0|  0.00%|        a_bool = a != a.dtype.type()
   493|         0|            0|            0|  0.00%|    else:
   494|         0|            0|            0|  0.00%|        a_bool = a.astype(np.bool_, copy=False)
   495|         0|            0|            0|  0.00%|
   496|         0|            0|            0|  0.00%|    return a_bool.sum(axis=axis, dtype=np.intp, keepdims=keepdims)
   497|         0|            0|            0|  0.00%|
   498|         0|            0|            0|  0.00%|
   499|         0|            0|            0|  0.00%|@set_module('numpy')
   500|         0|            0|            0|  0.00%|def isfortran(a):
   501|         0|            0|            0|  0.00%|    """
   502|         0|            0|            0|  0.00%|    Check if the array is Fortran contiguous but *not* C contiguous.
   503|         0|            0|            0|  0.00%|
   504|         0|            0|            0|  0.00%|    This function is obsolete and, because of changes due to relaxed stride
   505|         0|            0|            0|  0.00%|    checking, its return value for the same array may differ for versions
   506|         0|            0|            0|  0.00%|    of NumPy >= 1.10.0 and previous versions. If you only want to check if an
   507|         0|            0|            0|  0.00%|    array is Fortran contiguous use ``a.flags.f_contiguous`` instead.
   508|         0|            0|            0|  0.00%|
   509|         0|            0|            0|  0.00%|    Parameters
   510|         0|            0|            0|  0.00%|    ----------
   511|         0|            0|            0|  0.00%|    a : ndarray
   512|         0|            0|            0|  0.00%|        Input array.
   513|         0|            0|            0|  0.00%|
   514|         0|            0|            0|  0.00%|    Returns
   515|         0|            0|            0|  0.00%|    -------
   516|         0|            0|            0|  0.00%|    isfortran : bool
   517|         0|            0|            0|  0.00%|        Returns True if the array is Fortran contiguous but *not* C contiguous.
   518|         0|            0|            0|  0.00%|
   519|         0|            0|            0|  0.00%|
   520|         0|            0|            0|  0.00%|    Examples
   521|         0|            0|            0|  0.00%|    --------
   522|         0|            0|            0|  0.00%|
   523|         0|            0|            0|  0.00%|    np.array allows to specify whether the array is written in C-contiguous
   524|         0|            0|            0|  0.00%|    order (last index varies the fastest), or FORTRAN-contiguous order in
   525|         0|            0|            0|  0.00%|    memory (first index varies the fastest).
   526|         0|            0|            0|  0.00%|
   527|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2, 3], [4, 5, 6]], order='C')
   528|         0|            0|            0|  0.00%|    >>> a
   529|         0|            0|            0|  0.00%|    array([[1, 2, 3],
   530|         0|            0|            0|  0.00%|           [4, 5, 6]])
   531|         0|            0|            0|  0.00%|    >>> np.isfortran(a)
   532|         0|            0|            0|  0.00%|    False
   533|         0|            0|            0|  0.00%|
   534|         0|            0|            0|  0.00%|    >>> b = np.array([[1, 2, 3], [4, 5, 6]], order='F')
   535|         0|            0|            0|  0.00%|    >>> b
   536|         0|            0|            0|  0.00%|    array([[1, 2, 3],
   537|         0|            0|            0|  0.00%|           [4, 5, 6]])
   538|         0|            0|            0|  0.00%|    >>> np.isfortran(b)
   539|         0|            0|            0|  0.00%|    True
   540|         0|            0|            0|  0.00%|
   541|         0|            0|            0|  0.00%|
   542|         0|            0|            0|  0.00%|    The transpose of a C-ordered array is a FORTRAN-ordered array.
   543|         0|            0|            0|  0.00%|
   544|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2, 3], [4, 5, 6]], order='C')
   545|         0|            0|            0|  0.00%|    >>> a
   546|         0|            0|            0|  0.00%|    array([[1, 2, 3],
   547|         0|            0|            0|  0.00%|           [4, 5, 6]])
   548|         0|            0|            0|  0.00%|    >>> np.isfortran(a)
   549|         0|            0|            0|  0.00%|    False
   550|         0|            0|            0|  0.00%|    >>> b = a.T
   551|         0|            0|            0|  0.00%|    >>> b
   552|         0|            0|            0|  0.00%|    array([[1, 4],
   553|         0|            0|            0|  0.00%|           [2, 5],
   554|         0|            0|            0|  0.00%|           [3, 6]])
   555|         0|            0|            0|  0.00%|    >>> np.isfortran(b)
   556|         0|            0|            0|  0.00%|    True
   557|         0|            0|            0|  0.00%|
   558|         0|            0|            0|  0.00%|    C-ordered arrays evaluate as False even if they are also FORTRAN-ordered.
   559|         0|            0|            0|  0.00%|
   560|         0|            0|            0|  0.00%|    >>> np.isfortran(np.array([1, 2], order='F'))
   561|         0|            0|            0|  0.00%|    False
   562|         0|            0|            0|  0.00%|
   563|         0|            0|            0|  0.00%|    """
   564|         0|            0|            0|  0.00%|    return a.flags.fnc
   565|         0|            0|            0|  0.00%|
   566|         0|            0|            0|  0.00%|
   567|         0|            0|            0|  0.00%|def _argwhere_dispatcher(a):
   568|         0|            0|            0|  0.00%|    return (a,)
   569|         0|            0|            0|  0.00%|
   570|         0|            0|            0|  0.00%|
   571|         0|            0|            0|  0.00%|@array_function_dispatch(_argwhere_dispatcher)
   572|         0|            0|            0|  0.00%|def argwhere(a):
   573|         0|            0|            0|  0.00%|    """
   574|         0|            0|            0|  0.00%|    Find the indices of array elements that are non-zero, grouped by element.
   575|         0|            0|            0|  0.00%|
   576|         0|            0|            0|  0.00%|    Parameters
   577|         0|            0|            0|  0.00%|    ----------
   578|         0|            0|            0|  0.00%|    a : array_like
   579|         0|            0|            0|  0.00%|        Input data.
   580|         0|            0|            0|  0.00%|
   581|         0|            0|            0|  0.00%|    Returns
   582|         0|            0|            0|  0.00%|    -------
   583|         0|            0|            0|  0.00%|    index_array : (N, a.ndim) ndarray
   584|         0|            0|            0|  0.00%|        Indices of elements that are non-zero. Indices are grouped by element.
   585|         0|            0|            0|  0.00%|        This array will have shape ``(N, a.ndim)`` where ``N`` is the number of
   586|         0|            0|            0|  0.00%|        non-zero items.
   587|         0|            0|            0|  0.00%|
   588|         0|            0|            0|  0.00%|    See Also
   589|         0|            0|            0|  0.00%|    --------
   590|         0|            0|            0|  0.00%|    where, nonzero
   591|         0|            0|            0|  0.00%|
   592|         0|            0|            0|  0.00%|    Notes
   593|         0|            0|            0|  0.00%|    -----
   594|         0|            0|            0|  0.00%|    ``np.argwhere(a)`` is almost the same as ``np.transpose(np.nonzero(a))``,
   595|         0|            0|            0|  0.00%|    but produces a result of the correct shape for a 0D array.
   596|         0|            0|            0|  0.00%|
   597|         0|            0|            0|  0.00%|    The output of ``argwhere`` is not suitable for indexing arrays.
   598|         0|            0|            0|  0.00%|    For this purpose use ``nonzero(a)`` instead.
   599|         0|            0|            0|  0.00%|
   600|         0|            0|            0|  0.00%|    Examples
   601|         0|            0|            0|  0.00%|    --------
   602|         0|            0|            0|  0.00%|    >>> x = np.arange(6).reshape(2,3)
   603|         0|            0|            0|  0.00%|    >>> x
   604|         0|            0|            0|  0.00%|    array([[0, 1, 2],
   605|         0|            0|            0|  0.00%|           [3, 4, 5]])
   606|         0|            0|            0|  0.00%|    >>> np.argwhere(x>1)
   607|         0|            0|            0|  0.00%|    array([[0, 2],
   608|         0|            0|            0|  0.00%|           [1, 0],
   609|         0|            0|            0|  0.00%|           [1, 1],
   610|         0|            0|            0|  0.00%|           [1, 2]])
   611|         0|            0|            0|  0.00%|
   612|         0|            0|            0|  0.00%|    """
   613|         0|            0|            0|  0.00%|    # nonzero does not behave well on 0d, so promote to 1d
   614|         0|            0|            0|  0.00%|    if np.ndim(a) == 0:
   615|         0|            0|            0|  0.00%|        a = shape_base.atleast_1d(a)
   616|         0|            0|            0|  0.00%|        # then remove the added dimension
   617|         0|            0|            0|  0.00%|        return argwhere(a)[:,:0]
   618|         0|            0|            0|  0.00%|    return transpose(nonzero(a))
   619|         0|            0|            0|  0.00%|
   620|         0|            0|            0|  0.00%|
   621|         0|            0|            0|  0.00%|def _flatnonzero_dispatcher(a):
   622|         0|            0|            0|  0.00%|    return (a,)
   623|         0|            0|            0|  0.00%|
   624|         0|            0|            0|  0.00%|
   625|         0|            0|            0|  0.00%|@array_function_dispatch(_flatnonzero_dispatcher)
   626|         0|            0|            0|  0.00%|def flatnonzero(a):
   627|         0|            0|            0|  0.00%|    """
   628|         0|            0|            0|  0.00%|    Return indices that are non-zero in the flattened version of a.
   629|         0|            0|            0|  0.00%|
   630|         0|            0|            0|  0.00%|    This is equivalent to np.nonzero(np.ravel(a))[0].
   631|         0|            0|            0|  0.00%|
   632|         0|            0|            0|  0.00%|    Parameters
   633|         0|            0|            0|  0.00%|    ----------
   634|         0|            0|            0|  0.00%|    a : array_like
   635|         0|            0|            0|  0.00%|        Input data.
   636|         0|            0|            0|  0.00%|
   637|         0|            0|            0|  0.00%|    Returns
   638|         0|            0|            0|  0.00%|    -------
   639|         0|            0|            0|  0.00%|    res : ndarray
   640|         0|            0|            0|  0.00%|        Output array, containing the indices of the elements of `a.ravel()`
   641|         0|            0|            0|  0.00%|        that are non-zero.
   642|         0|            0|            0|  0.00%|
   643|         0|            0|            0|  0.00%|    See Also
   644|         0|            0|            0|  0.00%|    --------
   645|         0|            0|            0|  0.00%|    nonzero : Return the indices of the non-zero elements of the input array.
   646|         0|            0|            0|  0.00%|    ravel : Return a 1-D array containing the elements of the input array.
   647|         0|            0|            0|  0.00%|
   648|         0|            0|            0|  0.00%|    Examples
   649|         0|            0|            0|  0.00%|    --------
   650|         0|            0|            0|  0.00%|    >>> x = np.arange(-2, 3)
   651|         0|            0|            0|  0.00%|    >>> x
   652|         0|            0|            0|  0.00%|    array([-2, -1,  0,  1,  2])
   653|         0|            0|            0|  0.00%|    >>> np.flatnonzero(x)
   654|         0|            0|            0|  0.00%|    array([0, 1, 3, 4])
   655|         0|            0|            0|  0.00%|
   656|         0|            0|            0|  0.00%|    Use the indices of the non-zero elements as an index array to extract
   657|         0|            0|            0|  0.00%|    these elements:
   658|         0|            0|            0|  0.00%|
   659|         0|            0|            0|  0.00%|    >>> x.ravel()[np.flatnonzero(x)]
   660|         0|            0|            0|  0.00%|    array([-2, -1,  1,  2])
   661|         0|            0|            0|  0.00%|
   662|         0|            0|            0|  0.00%|    """
   663|         0|            0|            0|  0.00%|    return np.nonzero(np.ravel(a))[0]
   664|         0|            0|            0|  0.00%|
   665|         0|            0|            0|  0.00%|
   666|         0|            0|            0|  0.00%|def _correlate_dispatcher(a, v, mode=None):
   667|         0|            0|            0|  0.00%|    return (a, v)
   668|         0|            0|            0|  0.00%|
   669|         0|            0|            0|  0.00%|
   670|         0|            0|            0|  0.00%|@array_function_dispatch(_correlate_dispatcher)
   671|         0|            0|            0|  0.00%|def correlate(a, v, mode='valid'):
   672|         0|            0|            0|  0.00%|    """
   673|         0|            0|            0|  0.00%|    Cross-correlation of two 1-dimensional sequences.
   674|         0|            0|            0|  0.00%|
   675|         0|            0|            0|  0.00%|    This function computes the correlation as generally defined in signal
   676|         0|            0|            0|  0.00%|    processing texts::
   677|         0|            0|            0|  0.00%|
   678|         0|            0|            0|  0.00%|        c_{av}[k] = sum_n a[n+k] * conj(v[n])
   679|         0|            0|            0|  0.00%|
   680|         0|            0|            0|  0.00%|    with a and v sequences being zero-padded where necessary and conj being
   681|         0|            0|            0|  0.00%|    the conjugate.
   682|         0|            0|            0|  0.00%|
   683|         0|            0|            0|  0.00%|    Parameters
   684|         0|            0|            0|  0.00%|    ----------
   685|         0|            0|            0|  0.00%|    a, v : array_like
   686|         0|            0|            0|  0.00%|        Input sequences.
   687|         0|            0|            0|  0.00%|    mode : {'valid', 'same', 'full'}, optional
   688|         0|            0|            0|  0.00%|        Refer to the `convolve` docstring.  Note that the default
   689|         0|            0|            0|  0.00%|        is 'valid', unlike `convolve`, which uses 'full'.
   690|         0|            0|            0|  0.00%|    old_behavior : bool
   691|         0|            0|            0|  0.00%|        `old_behavior` was removed in NumPy 1.10. If you need the old
   692|         0|            0|            0|  0.00%|        behavior, use `multiarray.correlate`.
   693|         0|            0|            0|  0.00%|
   694|         0|            0|            0|  0.00%|    Returns
   695|         0|            0|            0|  0.00%|    -------
   696|         0|            0|            0|  0.00%|    out : ndarray
   697|         0|            0|            0|  0.00%|        Discrete cross-correlation of `a` and `v`.
   698|         0|            0|            0|  0.00%|
   699|         0|            0|            0|  0.00%|    See Also
   700|         0|            0|            0|  0.00%|    --------
   701|         0|            0|            0|  0.00%|    convolve : Discrete, linear convolution of two one-dimensional sequences.
   702|         0|            0|            0|  0.00%|    multiarray.correlate : Old, no conjugate, version of correlate.
   703|         0|            0|            0|  0.00%|    scipy.signal.correlate : uses FFT which has superior performance on large arrays.
   704|         0|            0|            0|  0.00%|
   705|         0|            0|            0|  0.00%|    Notes
   706|         0|            0|            0|  0.00%|    -----
   707|         0|            0|            0|  0.00%|    The definition of correlation above is not unique and sometimes correlation
   708|         0|            0|            0|  0.00%|    may be defined differently. Another common definition is::
   709|         0|            0|            0|  0.00%|
   710|         0|            0|            0|  0.00%|        c'_{av}[k] = sum_n a[n] conj(v[n+k])
   711|         0|            0|            0|  0.00%|
   712|         0|            0|            0|  0.00%|    which is related to ``c_{av}[k]`` by ``c'_{av}[k] = c_{av}[-k]``.
   713|         0|            0|            0|  0.00%|
   714|         0|            0|            0|  0.00%|    `numpy.correlate` may perform slowly in large arrays (i.e. n = 1e5) because it does
   715|         0|            0|            0|  0.00%|    not use the FFT to compute the convolution; in that case, `scipy.signal.correlate` might
   716|         0|            0|            0|  0.00%|    be preferable.
   717|         0|            0|            0|  0.00%|
   718|         0|            0|            0|  0.00%|
   719|         0|            0|            0|  0.00%|    Examples
   720|         0|            0|            0|  0.00%|    --------
   721|         0|            0|            0|  0.00%|    >>> np.correlate([1, 2, 3], [0, 1, 0.5])
   722|         0|            0|            0|  0.00%|    array([3.5])
   723|         0|            0|            0|  0.00%|    >>> np.correlate([1, 2, 3], [0, 1, 0.5], "same")
   724|         0|            0|            0|  0.00%|    array([2. ,  3.5,  3. ])
   725|         0|            0|            0|  0.00%|    >>> np.correlate([1, 2, 3], [0, 1, 0.5], "full")
   726|         0|            0|            0|  0.00%|    array([0.5,  2. ,  3.5,  3. ,  0. ])
   727|         0|            0|            0|  0.00%|
   728|         0|            0|            0|  0.00%|    Using complex sequences:
   729|         0|            0|            0|  0.00%|
   730|         0|            0|            0|  0.00%|    >>> np.correlate([1+1j, 2, 3-1j], [0, 1, 0.5j], 'full')
   731|         0|            0|            0|  0.00%|    array([ 0.5-0.5j,  1.0+0.j ,  1.5-1.5j,  3.0-1.j ,  0.0+0.j ])
   732|         0|            0|            0|  0.00%|
   733|         0|            0|            0|  0.00%|    Note that you get the time reversed, complex conjugated result
   734|         0|            0|            0|  0.00%|    when the two input sequences change places, i.e.,
   735|         0|            0|            0|  0.00%|    ``c_{va}[k] = c^{*}_{av}[-k]``:
   736|         0|            0|            0|  0.00%|
   737|         0|            0|            0|  0.00%|    >>> np.correlate([0, 1, 0.5j], [1+1j, 2, 3-1j], 'full')
   738|         0|            0|            0|  0.00%|    array([ 0.0+0.j ,  3.0+1.j ,  1.5+1.5j,  1.0+0.j ,  0.5+0.5j])
   739|         0|            0|            0|  0.00%|
   740|         0|            0|            0|  0.00%|    """
   741|         0|            0|            0|  0.00%|    return multiarray.correlate2(a, v, mode)
   742|         0|            0|            0|  0.00%|
   743|         0|            0|            0|  0.00%|
   744|         0|            0|            0|  0.00%|def _convolve_dispatcher(a, v, mode=None):
   745|         0|            0|            0|  0.00%|    return (a, v)
   746|         0|            0|            0|  0.00%|
   747|         0|            0|            0|  0.00%|
   748|         0|            0|            0|  0.00%|@array_function_dispatch(_convolve_dispatcher)
   749|         0|            0|            0|  0.00%|def convolve(a, v, mode='full'):
   750|         0|            0|            0|  0.00%|    """
   751|         0|            0|            0|  0.00%|    Returns the discrete, linear convolution of two one-dimensional sequences.
   752|         0|            0|            0|  0.00%|
   753|         0|            0|            0|  0.00%|    The convolution operator is often seen in signal processing, where it
   754|         0|            0|            0|  0.00%|    models the effect of a linear time-invariant system on a signal [1]_.  In
   755|         0|            0|            0|  0.00%|    probability theory, the sum of two independent random variables is
   756|         0|            0|            0|  0.00%|    distributed according to the convolution of their individual
   757|         0|            0|            0|  0.00%|    distributions.
   758|         0|            0|            0|  0.00%|
   759|         0|            0|            0|  0.00%|    If `v` is longer than `a`, the arrays are swapped before computation.
   760|         0|            0|            0|  0.00%|
   761|         0|            0|            0|  0.00%|    Parameters
   762|         0|            0|            0|  0.00%|    ----------
   763|         0|            0|            0|  0.00%|    a : (N,) array_like
   764|         0|            0|            0|  0.00%|        First one-dimensional input array.
   765|         0|            0|            0|  0.00%|    v : (M,) array_like
   766|         0|            0|            0|  0.00%|        Second one-dimensional input array.
   767|         0|            0|            0|  0.00%|    mode : {'full', 'valid', 'same'}, optional
   768|         0|            0|            0|  0.00%|        'full':
   769|         0|            0|            0|  0.00%|          By default, mode is 'full'.  This returns the convolution
   770|         0|            0|            0|  0.00%|          at each point of overlap, with an output shape of (N+M-1,). At
   771|         0|            0|            0|  0.00%|          the end-points of the convolution, the signals do not overlap
   772|         0|            0|            0|  0.00%|          completely, and boundary effects may be seen.
   773|         0|            0|            0|  0.00%|
   774|         0|            0|            0|  0.00%|        'same':
   775|         0|            0|            0|  0.00%|          Mode 'same' returns output of length ``max(M, N)``.  Boundary
   776|         0|            0|            0|  0.00%|          effects are still visible.
   777|         0|            0|            0|  0.00%|
   778|         0|            0|            0|  0.00%|        'valid':
   779|         0|            0|            0|  0.00%|          Mode 'valid' returns output of length
   780|         0|            0|            0|  0.00%|          ``max(M, N) - min(M, N) + 1``.  The convolution product is only given
   781|         0|            0|            0|  0.00%|          for points where the signals overlap completely.  Values outside
   782|         0|            0|            0|  0.00%|          the signal boundary have no effect.
   783|         0|            0|            0|  0.00%|
   784|         0|            0|            0|  0.00%|    Returns
   785|         0|            0|            0|  0.00%|    -------
   786|         0|            0|            0|  0.00%|    out : ndarray
   787|         0|            0|            0|  0.00%|        Discrete, linear convolution of `a` and `v`.
   788|         0|            0|            0|  0.00%|
   789|         0|            0|            0|  0.00%|    See Also
   790|         0|            0|            0|  0.00%|    --------
   791|         0|            0|            0|  0.00%|    scipy.signal.fftconvolve : Convolve two arrays using the Fast Fourier
   792|         0|            0|            0|  0.00%|                               Transform.
   793|         0|            0|            0|  0.00%|    scipy.linalg.toeplitz : Used to construct the convolution operator.
   794|         0|            0|            0|  0.00%|    polymul : Polynomial multiplication. Same output as convolve, but also
   795|         0|            0|            0|  0.00%|              accepts poly1d objects as input.
   796|         0|            0|            0|  0.00%|
   797|         0|            0|            0|  0.00%|    Notes
   798|         0|            0|            0|  0.00%|    -----
   799|         0|            0|            0|  0.00%|    The discrete convolution operation is defined as
   800|         0|            0|            0|  0.00%|
   801|         0|            0|            0|  0.00%|    .. math:: (a * v)[n] = \\sum_{m = -\\infty}^{\\infty} a[m] v[n - m]
   802|         0|            0|            0|  0.00%|
   803|         0|            0|            0|  0.00%|    It can be shown that a convolution :math:`x(t) * y(t)` in time/space
   804|         0|            0|            0|  0.00%|    is equivalent to the multiplication :math:`X(f) Y(f)` in the Fourier
   805|         0|            0|            0|  0.00%|    domain, after appropriate padding (padding is necessary to prevent
   806|         0|            0|            0|  0.00%|    circular convolution).  Since multiplication is more efficient (faster)
   807|         0|            0|            0|  0.00%|    than convolution, the function `scipy.signal.fftconvolve` exploits the
   808|         0|            0|            0|  0.00%|    FFT to calculate the convolution of large data-sets.
   809|         0|            0|            0|  0.00%|
   810|         0|            0|            0|  0.00%|    References
   811|         0|            0|            0|  0.00%|    ----------
   812|         0|            0|            0|  0.00%|    .. [1] Wikipedia, "Convolution",
   813|         0|            0|            0|  0.00%|        https://en.wikipedia.org/wiki/Convolution
   814|         0|            0|            0|  0.00%|
   815|         0|            0|            0|  0.00%|    Examples
   816|         0|            0|            0|  0.00%|    --------
   817|         0|            0|            0|  0.00%|    Note how the convolution operator flips the second array
   818|         0|            0|            0|  0.00%|    before "sliding" the two across one another:
   819|         0|            0|            0|  0.00%|
   820|         0|            0|            0|  0.00%|    >>> np.convolve([1, 2, 3], [0, 1, 0.5])
   821|         0|            0|            0|  0.00%|    array([0. , 1. , 2.5, 4. , 1.5])
   822|         0|            0|            0|  0.00%|
   823|         0|            0|            0|  0.00%|    Only return the middle values of the convolution.
   824|         0|            0|            0|  0.00%|    Contains boundary effects, where zeros are taken
   825|         0|            0|            0|  0.00%|    into account:
   826|         0|            0|            0|  0.00%|
   827|         0|            0|            0|  0.00%|    >>> np.convolve([1,2,3],[0,1,0.5], 'same')
   828|         0|            0|            0|  0.00%|    array([1. ,  2.5,  4. ])
   829|         0|            0|            0|  0.00%|
   830|         0|            0|            0|  0.00%|    The two arrays are of the same length, so there
   831|         0|            0|            0|  0.00%|    is only one position where they completely overlap:
   832|         0|            0|            0|  0.00%|
   833|         0|            0|            0|  0.00%|    >>> np.convolve([1,2,3],[0,1,0.5], 'valid')
   834|         0|            0|            0|  0.00%|    array([2.5])
   835|         0|            0|            0|  0.00%|
   836|         0|            0|            0|  0.00%|    """
   837|         0|            0|            0|  0.00%|    a, v = array(a, copy=False, ndmin=1), array(v, copy=False, ndmin=1)
   838|         0|            0|            0|  0.00%|    if (len(v) > len(a)):
   839|         0|            0|            0|  0.00%|        a, v = v, a
   840|         0|            0|            0|  0.00%|    if len(a) == 0:
   841|         0|            0|            0|  0.00%|        raise ValueError('a cannot be empty')
   842|         0|            0|            0|  0.00%|    if len(v) == 0:
   843|         0|            0|            0|  0.00%|        raise ValueError('v cannot be empty')
   844|         0|            0|            0|  0.00%|    return multiarray.correlate(a, v[::-1], mode)
   845|         0|            0|            0|  0.00%|
   846|         0|            0|            0|  0.00%|
   847|         0|            0|            0|  0.00%|def _outer_dispatcher(a, b, out=None):
   848|         0|            0|            0|  0.00%|    return (a, b, out)
   849|         0|            0|            0|  0.00%|
   850|         0|            0|            0|  0.00%|
   851|         0|            0|            0|  0.00%|@array_function_dispatch(_outer_dispatcher)
   852|         0|            0|            0|  0.00%|def outer(a, b, out=None):
   853|         0|            0|            0|  0.00%|    """
   854|         0|            0|            0|  0.00%|    Compute the outer product of two vectors.
   855|         0|            0|            0|  0.00%|
   856|         0|            0|            0|  0.00%|    Given two vectors, ``a = [a0, a1, ..., aM]`` and
   857|         0|            0|            0|  0.00%|    ``b = [b0, b1, ..., bN]``,
   858|         0|            0|            0|  0.00%|    the outer product [1]_ is::
   859|         0|            0|            0|  0.00%|
   860|         0|            0|            0|  0.00%|      [[a0*b0  a0*b1 ... a0*bN ]
   861|         0|            0|            0|  0.00%|       [a1*b0    .
   862|         0|            0|            0|  0.00%|       [ ...          .
   863|         0|            0|            0|  0.00%|       [aM*b0            aM*bN ]]
   864|         0|            0|            0|  0.00%|
   865|         0|            0|            0|  0.00%|    Parameters
   866|         0|            0|            0|  0.00%|    ----------
   867|         0|            0|            0|  0.00%|    a : (M,) array_like
   868|         0|            0|            0|  0.00%|        First input vector.  Input is flattened if
   869|         0|            0|            0|  0.00%|        not already 1-dimensional.
   870|         0|            0|            0|  0.00%|    b : (N,) array_like
   871|         0|            0|            0|  0.00%|        Second input vector.  Input is flattened if
   872|         0|            0|            0|  0.00%|        not already 1-dimensional.
   873|         0|            0|            0|  0.00%|    out : (M, N) ndarray, optional
   874|         0|            0|            0|  0.00%|        A location where the result is stored
   875|         0|            0|            0|  0.00%|
   876|         0|            0|            0|  0.00%|        .. versionadded:: 1.9.0
   877|         0|            0|            0|  0.00%|
   878|         0|            0|            0|  0.00%|    Returns
   879|         0|            0|            0|  0.00%|    -------
   880|         0|            0|            0|  0.00%|    out : (M, N) ndarray
   881|         0|            0|            0|  0.00%|        ``out[i, j] = a[i] * b[j]``
   882|         0|            0|            0|  0.00%|
   883|         0|            0|            0|  0.00%|    See also
   884|         0|            0|            0|  0.00%|    --------
   885|         0|            0|            0|  0.00%|    inner
   886|         0|            0|            0|  0.00%|    einsum : ``einsum('i,j->ij', a.ravel(), b.ravel())`` is the equivalent.
   887|         0|            0|            0|  0.00%|    ufunc.outer : A generalization to dimensions other than 1D and other
   888|         0|            0|            0|  0.00%|                  operations. ``np.multiply.outer(a.ravel(), b.ravel())``
   889|         0|            0|            0|  0.00%|                  is the equivalent.
   890|         0|            0|            0|  0.00%|    tensordot : ``np.tensordot(a.ravel(), b.ravel(), axes=((), ()))``
   891|         0|            0|            0|  0.00%|                is the equivalent.
   892|         0|            0|            0|  0.00%|
   893|         0|            0|            0|  0.00%|    References
   894|         0|            0|            0|  0.00%|    ----------
   895|         0|            0|            0|  0.00%|    .. [1] : G. H. Golub and C. F. Van Loan, *Matrix Computations*, 3rd
   896|         0|            0|            0|  0.00%|             ed., Baltimore, MD, Johns Hopkins University Press, 1996,
   897|         0|            0|            0|  0.00%|             pg. 8.
   898|         0|            0|            0|  0.00%|
   899|         0|            0|            0|  0.00%|    Examples
   900|         0|            0|            0|  0.00%|    --------
   901|         0|            0|            0|  0.00%|    Make a (*very* coarse) grid for computing a Mandelbrot set:
   902|         0|            0|            0|  0.00%|
   903|         0|            0|            0|  0.00%|    >>> rl = np.outer(np.ones((5,)), np.linspace(-2, 2, 5))
   904|         0|            0|            0|  0.00%|    >>> rl
   905|         0|            0|            0|  0.00%|    array([[-2., -1.,  0.,  1.,  2.],
   906|         0|            0|            0|  0.00%|           [-2., -1.,  0.,  1.,  2.],
   907|         0|            0|            0|  0.00%|           [-2., -1.,  0.,  1.,  2.],
   908|         0|            0|            0|  0.00%|           [-2., -1.,  0.,  1.,  2.],
   909|         0|            0|            0|  0.00%|           [-2., -1.,  0.,  1.,  2.]])
   910|         0|            0|            0|  0.00%|    >>> im = np.outer(1j*np.linspace(2, -2, 5), np.ones((5,)))
   911|         0|            0|            0|  0.00%|    >>> im
   912|         0|            0|            0|  0.00%|    array([[0.+2.j, 0.+2.j, 0.+2.j, 0.+2.j, 0.+2.j],
   913|         0|            0|            0|  0.00%|           [0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j],
   914|         0|            0|            0|  0.00%|           [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],
   915|         0|            0|            0|  0.00%|           [0.-1.j, 0.-1.j, 0.-1.j, 0.-1.j, 0.-1.j],
   916|         0|            0|            0|  0.00%|           [0.-2.j, 0.-2.j, 0.-2.j, 0.-2.j, 0.-2.j]])
   917|         0|            0|            0|  0.00%|    >>> grid = rl + im
   918|         0|            0|            0|  0.00%|    >>> grid
   919|         0|            0|            0|  0.00%|    array([[-2.+2.j, -1.+2.j,  0.+2.j,  1.+2.j,  2.+2.j],
   920|         0|            0|            0|  0.00%|           [-2.+1.j, -1.+1.j,  0.+1.j,  1.+1.j,  2.+1.j],
   921|         0|            0|            0|  0.00%|           [-2.+0.j, -1.+0.j,  0.+0.j,  1.+0.j,  2.+0.j],
   922|         0|            0|            0|  0.00%|           [-2.-1.j, -1.-1.j,  0.-1.j,  1.-1.j,  2.-1.j],
   923|         0|            0|            0|  0.00%|           [-2.-2.j, -1.-2.j,  0.-2.j,  1.-2.j,  2.-2.j]])
   924|         0|            0|            0|  0.00%|
   925|         0|            0|            0|  0.00%|    An example using a "vector" of letters:
   926|         0|            0|            0|  0.00%|
   927|         0|            0|            0|  0.00%|    >>> x = np.array(['a', 'b', 'c'], dtype=object)
   928|         0|            0|            0|  0.00%|    >>> np.outer(x, [1, 2, 3])
   929|         0|            0|            0|  0.00%|    array([['a', 'aa', 'aaa'],
   930|         0|            0|            0|  0.00%|           ['b', 'bb', 'bbb'],
   931|         0|            0|            0|  0.00%|           ['c', 'cc', 'ccc']], dtype=object)
   932|         0|            0|            0|  0.00%|
   933|         0|            0|            0|  0.00%|    """
   934|         0|            0|            0|  0.00%|    a = asarray(a)
   935|         0|            0|            0|  0.00%|    b = asarray(b)
   936|         0|            0|            0|  0.00%|    return multiply(a.ravel()[:, newaxis], b.ravel()[newaxis, :], out)
   937|         0|            0|            0|  0.00%|
   938|         0|            0|            0|  0.00%|
   939|         0|            0|            0|  0.00%|def _tensordot_dispatcher(a, b, axes=None):
   940|         0|            0|            0|  0.00%|    return (a, b)
   941|         0|            0|            0|  0.00%|
   942|         0|            0|            0|  0.00%|
   943|         0|            0|            0|  0.00%|@array_function_dispatch(_tensordot_dispatcher)
   944|         0|            0|            0|  0.00%|def tensordot(a, b, axes=2):
   945|         0|            0|            0|  0.00%|    """
   946|         0|            0|            0|  0.00%|    Compute tensor dot product along specified axes.
   947|         0|            0|            0|  0.00%|
   948|         0|            0|            0|  0.00%|    Given two tensors, `a` and `b`, and an array_like object containing
   949|         0|            0|            0|  0.00%|    two array_like objects, ``(a_axes, b_axes)``, sum the products of
   950|         0|            0|            0|  0.00%|    `a`'s and `b`'s elements (components) over the axes specified by
   951|         0|            0|            0|  0.00%|    ``a_axes`` and ``b_axes``. The third argument can be a single non-negative
   952|         0|            0|            0|  0.00%|    integer_like scalar, ``N``; if it is such, then the last ``N`` dimensions
   953|         0|            0|            0|  0.00%|    of `a` and the first ``N`` dimensions of `b` are summed over.
   954|         0|            0|            0|  0.00%|
   955|         0|            0|            0|  0.00%|    Parameters
   956|         0|            0|            0|  0.00%|    ----------
   957|         0|            0|            0|  0.00%|    a, b : array_like
   958|         0|            0|            0|  0.00%|        Tensors to "dot".
   959|         0|            0|            0|  0.00%|
   960|         0|            0|            0|  0.00%|    axes : int or (2,) array_like
   961|         0|            0|            0|  0.00%|        * integer_like
   962|         0|            0|            0|  0.00%|          If an int N, sum over the last N axes of `a` and the first N axes
   963|         0|            0|            0|  0.00%|          of `b` in order. The sizes of the corresponding axes must match.
   964|         0|            0|            0|  0.00%|        * (2,) array_like
   965|         0|            0|            0|  0.00%|          Or, a list of axes to be summed over, first sequence applying to `a`,
   966|         0|            0|            0|  0.00%|          second to `b`. Both elements array_like must be of the same length.
   967|         0|            0|            0|  0.00%|
   968|         0|            0|            0|  0.00%|    Returns
   969|         0|            0|            0|  0.00%|    -------
   970|         0|            0|            0|  0.00%|    output : ndarray
   971|         0|            0|            0|  0.00%|        The tensor dot product of the input.
   972|         0|            0|            0|  0.00%|
   973|         0|            0|            0|  0.00%|    See Also
   974|         0|            0|            0|  0.00%|    --------
   975|         0|            0|            0|  0.00%|    dot, einsum
   976|         0|            0|            0|  0.00%|
   977|         0|            0|            0|  0.00%|    Notes
   978|         0|            0|            0|  0.00%|    -----
   979|         0|            0|            0|  0.00%|    Three common use cases are:
   980|         0|            0|            0|  0.00%|        * ``axes = 0`` : tensor product :math:`a\\otimes b`
   981|         0|            0|            0|  0.00%|        * ``axes = 1`` : tensor dot product :math:`a\\cdot b`
   982|         0|            0|            0|  0.00%|        * ``axes = 2`` : (default) tensor double contraction :math:`a:b`
   983|         0|            0|            0|  0.00%|
   984|         0|            0|            0|  0.00%|    When `axes` is integer_like, the sequence for evaluation will be: first
   985|         0|            0|            0|  0.00%|    the -Nth axis in `a` and 0th axis in `b`, and the -1th axis in `a` and
   986|         0|            0|            0|  0.00%|    Nth axis in `b` last.
   987|         0|            0|            0|  0.00%|
   988|         0|            0|            0|  0.00%|    When there is more than one axis to sum over - and they are not the last
   989|         0|            0|            0|  0.00%|    (first) axes of `a` (`b`) - the argument `axes` should consist of
   990|         0|            0|            0|  0.00%|    two sequences of the same length, with the first axis to sum over given
   991|         0|            0|            0|  0.00%|    first in both sequences, the second axis second, and so forth.
   992|         0|            0|            0|  0.00%|
   993|         0|            0|            0|  0.00%|    The shape of the result consists of the non-contracted axes of the
   994|         0|            0|            0|  0.00%|    first tensor, followed by the non-contracted axes of the second.
   995|         0|            0|            0|  0.00%|
   996|         0|            0|            0|  0.00%|    Examples
   997|         0|            0|            0|  0.00%|    --------
   998|         0|            0|            0|  0.00%|    A "traditional" example:
   999|         0|            0|            0|  0.00%|
  1000|         0|            0|            0|  0.00%|    >>> a = np.arange(60.).reshape(3,4,5)
  1001|         0|            0|            0|  0.00%|    >>> b = np.arange(24.).reshape(4,3,2)
  1002|         0|            0|            0|  0.00%|    >>> c = np.tensordot(a,b, axes=([1,0],[0,1]))
  1003|         0|            0|            0|  0.00%|    >>> c.shape
  1004|         0|            0|            0|  0.00%|    (5, 2)
  1005|         0|            0|            0|  0.00%|    >>> c
  1006|         0|            0|            0|  0.00%|    array([[4400., 4730.],
  1007|         0|            0|            0|  0.00%|           [4532., 4874.],
  1008|         0|            0|            0|  0.00%|           [4664., 5018.],
  1009|         0|            0|            0|  0.00%|           [4796., 5162.],
  1010|         0|            0|            0|  0.00%|           [4928., 5306.]])
  1011|         0|            0|            0|  0.00%|    >>> # A slower but equivalent way of computing the same...
  1012|         0|            0|            0|  0.00%|    >>> d = np.zeros((5,2))
  1013|         0|            0|            0|  0.00%|    >>> for i in range(5):
  1014|         0|            0|            0|  0.00%|    ...   for j in range(2):
  1015|         0|            0|            0|  0.00%|    ...     for k in range(3):
  1016|         0|            0|            0|  0.00%|    ...       for n in range(4):
  1017|         0|            0|            0|  0.00%|    ...         d[i,j] += a[k,n,i] * b[n,k,j]
  1018|         0|            0|            0|  0.00%|    >>> c == d
  1019|         0|            0|            0|  0.00%|    array([[ True,  True],
  1020|         0|            0|            0|  0.00%|           [ True,  True],
  1021|         0|            0|            0|  0.00%|           [ True,  True],
  1022|         0|            0|            0|  0.00%|           [ True,  True],
  1023|         0|            0|            0|  0.00%|           [ True,  True]])
  1024|         0|            0|            0|  0.00%|
  1025|         0|            0|            0|  0.00%|    An extended example taking advantage of the overloading of + and \\*:
  1026|         0|            0|            0|  0.00%|
  1027|         0|            0|            0|  0.00%|    >>> a = np.array(range(1, 9))
  1028|         0|            0|            0|  0.00%|    >>> a.shape = (2, 2, 2)
  1029|         0|            0|            0|  0.00%|    >>> A = np.array(('a', 'b', 'c', 'd'), dtype=object)
  1030|         0|            0|            0|  0.00%|    >>> A.shape = (2, 2)
  1031|         0|            0|            0|  0.00%|    >>> a; A
  1032|         0|            0|            0|  0.00%|    array([[[1, 2],
  1033|         0|            0|            0|  0.00%|            [3, 4]],
  1034|         0|            0|            0|  0.00%|           [[5, 6],
  1035|         0|            0|            0|  0.00%|            [7, 8]]])
  1036|         0|            0|            0|  0.00%|    array([['a', 'b'],
  1037|         0|            0|            0|  0.00%|           ['c', 'd']], dtype=object)
  1038|         0|            0|            0|  0.00%|
  1039|         0|            0|            0|  0.00%|    >>> np.tensordot(a, A) # third argument default is 2 for double-contraction
  1040|         0|            0|            0|  0.00%|    array(['abbcccdddd', 'aaaaabbbbbbcccccccdddddddd'], dtype=object)
  1041|         0|            0|            0|  0.00%|
  1042|         0|            0|            0|  0.00%|    >>> np.tensordot(a, A, 1)
  1043|         0|            0|            0|  0.00%|    array([[['acc', 'bdd'],
  1044|         0|            0|            0|  0.00%|            ['aaacccc', 'bbbdddd']],
  1045|         0|            0|            0|  0.00%|           [['aaaaacccccc', 'bbbbbdddddd'],
  1046|         0|            0|            0|  0.00%|            ['aaaaaaacccccccc', 'bbbbbbbdddddddd']]], dtype=object)
  1047|         0|            0|            0|  0.00%|
  1048|         0|            0|            0|  0.00%|    >>> np.tensordot(a, A, 0) # tensor product (result too long to incl.)
  1049|         0|            0|            0|  0.00%|    array([[[[['a', 'b'],
  1050|         0|            0|            0|  0.00%|              ['c', 'd']],
  1051|         0|            0|            0|  0.00%|              ...
  1052|         0|            0|            0|  0.00%|
  1053|         0|            0|            0|  0.00%|    >>> np.tensordot(a, A, (0, 1))
  1054|         0|            0|            0|  0.00%|    array([[['abbbbb', 'cddddd'],
  1055|         0|            0|            0|  0.00%|            ['aabbbbbb', 'ccdddddd']],
  1056|         0|            0|            0|  0.00%|           [['aaabbbbbbb', 'cccddddddd'],
  1057|         0|            0|            0|  0.00%|            ['aaaabbbbbbbb', 'ccccdddddddd']]], dtype=object)
  1058|         0|            0|            0|  0.00%|
  1059|         0|            0|            0|  0.00%|    >>> np.tensordot(a, A, (2, 1))
  1060|         0|            0|            0|  0.00%|    array([[['abb', 'cdd'],
  1061|         0|            0|            0|  0.00%|            ['aaabbbb', 'cccdddd']],
  1062|         0|            0|            0|  0.00%|           [['aaaaabbbbbb', 'cccccdddddd'],
  1063|         0|            0|            0|  0.00%|            ['aaaaaaabbbbbbbb', 'cccccccdddddddd']]], dtype=object)
  1064|         0|            0|            0|  0.00%|
  1065|         0|            0|            0|  0.00%|    >>> np.tensordot(a, A, ((0, 1), (0, 1)))
  1066|         0|            0|            0|  0.00%|    array(['abbbcccccddddddd', 'aabbbbccccccdddddddd'], dtype=object)
  1067|         0|            0|            0|  0.00%|
  1068|         0|            0|            0|  0.00%|    >>> np.tensordot(a, A, ((2, 1), (1, 0)))
  1069|         0|            0|            0|  0.00%|    array(['acccbbdddd', 'aaaaacccccccbbbbbbdddddddd'], dtype=object)
  1070|         0|            0|            0|  0.00%|
  1071|         0|            0|            0|  0.00%|    """
  1072|         0|            0|            0|  0.00%|    try:
  1073|         0|            0|            0|  0.00%|        iter(axes)
  1074|         0|            0|            0|  0.00%|    except Exception:
  1075|         0|            0|            0|  0.00%|        axes_a = list(range(-axes, 0))
  1076|         0|            0|            0|  0.00%|        axes_b = list(range(0, axes))
  1077|         0|            0|            0|  0.00%|    else:
  1078|         0|            0|            0|  0.00%|        axes_a, axes_b = axes
  1079|         0|            0|            0|  0.00%|    try:
  1080|         0|            0|            0|  0.00%|        na = len(axes_a)
  1081|         0|            0|            0|  0.00%|        axes_a = list(axes_a)
  1082|         0|            0|            0|  0.00%|    except TypeError:
  1083|         0|            0|            0|  0.00%|        axes_a = [axes_a]
  1084|         0|            0|            0|  0.00%|        na = 1
  1085|         0|            0|            0|  0.00%|    try:
  1086|         0|            0|            0|  0.00%|        nb = len(axes_b)
  1087|         0|            0|            0|  0.00%|        axes_b = list(axes_b)
  1088|         0|            0|            0|  0.00%|    except TypeError:
  1089|         0|            0|            0|  0.00%|        axes_b = [axes_b]
  1090|         0|            0|            0|  0.00%|        nb = 1
  1091|         0|            0|            0|  0.00%|
  1092|         0|            0|            0|  0.00%|    a, b = asarray(a), asarray(b)
  1093|         0|            0|            0|  0.00%|    as_ = a.shape
  1094|         0|            0|            0|  0.00%|    nda = a.ndim
  1095|         0|            0|            0|  0.00%|    bs = b.shape
  1096|         0|            0|            0|  0.00%|    ndb = b.ndim
  1097|         0|            0|            0|  0.00%|    equal = True
  1098|         0|            0|            0|  0.00%|    if na != nb:
  1099|         0|            0|            0|  0.00%|        equal = False
  1100|         0|            0|            0|  0.00%|    else:
  1101|         0|            0|            0|  0.00%|        for k in range(na):
  1102|         0|            0|            0|  0.00%|            if as_[axes_a[k]] != bs[axes_b[k]]:
  1103|         0|            0|            0|  0.00%|                equal = False
  1104|         0|            0|            0|  0.00%|                break
  1105|         0|            0|            0|  0.00%|            if axes_a[k] < 0:
  1106|         0|            0|            0|  0.00%|                axes_a[k] += nda
  1107|         0|            0|            0|  0.00%|            if axes_b[k] < 0:
  1108|         0|            0|            0|  0.00%|                axes_b[k] += ndb
  1109|         0|            0|            0|  0.00%|    if not equal:
  1110|         0|            0|            0|  0.00%|        raise ValueError("shape-mismatch for sum")
  1111|         0|            0|            0|  0.00%|
  1112|         0|            0|            0|  0.00%|    # Move the axes to sum over to the end of "a"
  1113|         0|            0|            0|  0.00%|    # and to the front of "b"
  1114|         0|            0|            0|  0.00%|    notin = [k for k in range(nda) if k not in axes_a]
  1115|         0|            0|            0|  0.00%|    newaxes_a = notin + axes_a
  1116|         0|            0|            0|  0.00%|    N2 = 1
  1117|         0|            0|            0|  0.00%|    for axis in axes_a:
  1118|         0|            0|            0|  0.00%|        N2 *= as_[axis]
  1119|         0|            0|            0|  0.00%|    newshape_a = (int(multiply.reduce([as_[ax] for ax in notin])), N2)
  1120|         0|            0|            0|  0.00%|    olda = [as_[axis] for axis in notin]
  1121|         0|            0|            0|  0.00%|
  1122|         0|            0|            0|  0.00%|    notin = [k for k in range(ndb) if k not in axes_b]
  1123|         0|            0|            0|  0.00%|    newaxes_b = axes_b + notin
  1124|         0|            0|            0|  0.00%|    N2 = 1
  1125|         0|            0|            0|  0.00%|    for axis in axes_b:
  1126|         0|            0|            0|  0.00%|        N2 *= bs[axis]
  1127|         0|            0|            0|  0.00%|    newshape_b = (N2, int(multiply.reduce([bs[ax] for ax in notin])))
  1128|         0|            0|            0|  0.00%|    oldb = [bs[axis] for axis in notin]
  1129|         0|            0|            0|  0.00%|
  1130|         0|            0|            0|  0.00%|    at = a.transpose(newaxes_a).reshape(newshape_a)
  1131|         0|            0|            0|  0.00%|    bt = b.transpose(newaxes_b).reshape(newshape_b)
  1132|         0|            0|            0|  0.00%|    res = dot(at, bt)
  1133|         0|            0|            0|  0.00%|    return res.reshape(olda + oldb)
  1134|         0|            0|            0|  0.00%|
  1135|         0|            0|            0|  0.00%|
  1136|         0|            0|            0|  0.00%|def _roll_dispatcher(a, shift, axis=None):
  1137|         0|            0|            0|  0.00%|    return (a,)
  1138|         0|            0|            0|  0.00%|
  1139|         0|            0|            0|  0.00%|
  1140|         0|            0|            0|  0.00%|@array_function_dispatch(_roll_dispatcher)
  1141|         0|            0|            0|  0.00%|def roll(a, shift, axis=None):
  1142|         0|            0|            0|  0.00%|    """
  1143|         0|            0|            0|  0.00%|    Roll array elements along a given axis.
  1144|         0|            0|            0|  0.00%|
  1145|         0|            0|            0|  0.00%|    Elements that roll beyond the last position are re-introduced at
  1146|         0|            0|            0|  0.00%|    the first.
  1147|         0|            0|            0|  0.00%|
  1148|         0|            0|            0|  0.00%|    Parameters
  1149|         0|            0|            0|  0.00%|    ----------
  1150|         0|            0|            0|  0.00%|    a : array_like
  1151|         0|            0|            0|  0.00%|        Input array.
  1152|         0|            0|            0|  0.00%|    shift : int or tuple of ints
  1153|         0|            0|            0|  0.00%|        The number of places by which elements are shifted.  If a tuple,
  1154|         0|            0|            0|  0.00%|        then `axis` must be a tuple of the same size, and each of the
  1155|         0|            0|            0|  0.00%|        given axes is shifted by the corresponding number.  If an int
  1156|         0|            0|            0|  0.00%|        while `axis` is a tuple of ints, then the same value is used for
  1157|         0|            0|            0|  0.00%|        all given axes.
  1158|         0|            0|            0|  0.00%|    axis : int or tuple of ints, optional
  1159|         0|            0|            0|  0.00%|        Axis or axes along which elements are shifted.  By default, the
  1160|         0|            0|            0|  0.00%|        array is flattened before shifting, after which the original
  1161|         0|            0|            0|  0.00%|        shape is restored.
  1162|         0|            0|            0|  0.00%|
  1163|         0|            0|            0|  0.00%|    Returns
  1164|         0|            0|            0|  0.00%|    -------
  1165|         0|            0|            0|  0.00%|    res : ndarray
  1166|         0|            0|            0|  0.00%|        Output array, with the same shape as `a`.
  1167|         0|            0|            0|  0.00%|
  1168|         0|            0|            0|  0.00%|    See Also
  1169|         0|            0|            0|  0.00%|    --------
  1170|         0|            0|            0|  0.00%|    rollaxis : Roll the specified axis backwards, until it lies in a
  1171|         0|            0|            0|  0.00%|               given position.
  1172|         0|            0|            0|  0.00%|
  1173|         0|            0|            0|  0.00%|    Notes
  1174|         0|            0|            0|  0.00%|    -----
  1175|         0|            0|            0|  0.00%|    .. versionadded:: 1.12.0
  1176|         0|            0|            0|  0.00%|
  1177|         0|            0|            0|  0.00%|    Supports rolling over multiple dimensions simultaneously.
  1178|         0|            0|            0|  0.00%|
  1179|         0|            0|            0|  0.00%|    Examples
  1180|         0|            0|            0|  0.00%|    --------
  1181|         0|            0|            0|  0.00%|    >>> x = np.arange(10)
  1182|         0|            0|            0|  0.00%|    >>> np.roll(x, 2)
  1183|         0|            0|            0|  0.00%|    array([8, 9, 0, 1, 2, 3, 4, 5, 6, 7])
  1184|         0|            0|            0|  0.00%|    >>> np.roll(x, -2)
  1185|         0|            0|            0|  0.00%|    array([2, 3, 4, 5, 6, 7, 8, 9, 0, 1])
  1186|         0|            0|            0|  0.00%|
  1187|         0|            0|            0|  0.00%|    >>> x2 = np.reshape(x, (2, 5))
  1188|         0|            0|            0|  0.00%|    >>> x2
  1189|         0|            0|            0|  0.00%|    array([[0, 1, 2, 3, 4],
  1190|         0|            0|            0|  0.00%|           [5, 6, 7, 8, 9]])
  1191|         0|            0|            0|  0.00%|    >>> np.roll(x2, 1)
  1192|         0|            0|            0|  0.00%|    array([[9, 0, 1, 2, 3],
  1193|         0|            0|            0|  0.00%|           [4, 5, 6, 7, 8]])
  1194|         0|            0|            0|  0.00%|    >>> np.roll(x2, -1)
  1195|         0|            0|            0|  0.00%|    array([[1, 2, 3, 4, 5],
  1196|         0|            0|            0|  0.00%|           [6, 7, 8, 9, 0]])
  1197|         0|            0|            0|  0.00%|    >>> np.roll(x2, 1, axis=0)
  1198|         0|            0|            0|  0.00%|    array([[5, 6, 7, 8, 9],
  1199|         0|            0|            0|  0.00%|           [0, 1, 2, 3, 4]])
  1200|         0|            0|            0|  0.00%|    >>> np.roll(x2, -1, axis=0)
  1201|         0|            0|            0|  0.00%|    array([[5, 6, 7, 8, 9],
  1202|         0|            0|            0|  0.00%|           [0, 1, 2, 3, 4]])
  1203|         0|            0|            0|  0.00%|    >>> np.roll(x2, 1, axis=1)
  1204|         0|            0|            0|  0.00%|    array([[4, 0, 1, 2, 3],
  1205|         0|            0|            0|  0.00%|           [9, 5, 6, 7, 8]])
  1206|         0|            0|            0|  0.00%|    >>> np.roll(x2, -1, axis=1)
  1207|         0|            0|            0|  0.00%|    array([[1, 2, 3, 4, 0],
  1208|         0|            0|            0|  0.00%|           [6, 7, 8, 9, 5]])
  1209|         0|            0|            0|  0.00%|    >>> np.roll(x2, (1, 1), axis=(1, 0))
  1210|         0|            0|            0|  0.00%|    array([[9, 5, 6, 7, 8],
  1211|         0|            0|            0|  0.00%|           [4, 0, 1, 2, 3]])
  1212|         0|            0|            0|  0.00%|    >>> np.roll(x2, (2, 1), axis=(1, 0))
  1213|         0|            0|            0|  0.00%|    array([[8, 9, 5, 6, 7],
  1214|         0|            0|            0|  0.00%|           [3, 4, 0, 1, 2]])
  1215|         0|            0|            0|  0.00%|
  1216|         0|            0|            0|  0.00%|    """
  1217|         0|            0|            0|  0.00%|    a = asanyarray(a)
  1218|         0|            0|            0|  0.00%|    if axis is None:
  1219|         0|            0|            0|  0.00%|        return roll(a.ravel(), shift, 0).reshape(a.shape)
  1220|         0|            0|            0|  0.00%|
  1221|         0|            0|            0|  0.00%|    else:
  1222|         0|            0|            0|  0.00%|        axis = normalize_axis_tuple(axis, a.ndim, allow_duplicate=True)
  1223|         0|            0|            0|  0.00%|        broadcasted = broadcast(shift, axis)
  1224|         0|            0|            0|  0.00%|        if broadcasted.ndim > 1:
  1225|         0|            0|            0|  0.00%|            raise ValueError(
  1226|         0|            0|            0|  0.00%|                "'shift' and 'axis' should be scalars or 1D sequences")
  1227|         0|            0|            0|  0.00%|        shifts = {ax: 0 for ax in range(a.ndim)}
  1228|         0|            0|            0|  0.00%|        for sh, ax in broadcasted:
  1229|         0|            0|            0|  0.00%|            shifts[ax] += sh
  1230|         0|            0|            0|  0.00%|
  1231|         0|            0|            0|  0.00%|        rolls = [((slice(None), slice(None)),)] * a.ndim
  1232|         0|            0|            0|  0.00%|        for ax, offset in shifts.items():
  1233|         0|            0|            0|  0.00%|            offset %= a.shape[ax] or 1  # If `a` is empty, nothing matters.
  1234|         0|            0|            0|  0.00%|            if offset:
  1235|         0|            0|            0|  0.00%|                # (original, result), (original, result)
  1236|         0|            0|            0|  0.00%|                rolls[ax] = ((slice(None, -offset), slice(offset, None)),
  1237|         0|            0|            0|  0.00%|                             (slice(-offset, None), slice(None, offset)))
  1238|         0|            0|            0|  0.00%|
  1239|         0|            0|            0|  0.00%|        result = empty_like(a)
  1240|         0|            0|            0|  0.00%|        for indices in itertools.product(*rolls):
  1241|         0|            0|            0|  0.00%|            arr_index, res_index = zip(*indices)
  1242|         0|            0|            0|  0.00%|            result[res_index] = a[arr_index]
  1243|         0|            0|            0|  0.00%|
  1244|         0|            0|            0|  0.00%|        return result
  1245|         0|            0|            0|  0.00%|
  1246|         0|            0|            0|  0.00%|
  1247|         0|            0|            0|  0.00%|def _rollaxis_dispatcher(a, axis, start=None):
  1248|         0|            0|            0|  0.00%|    return (a,)
  1249|         0|            0|            0|  0.00%|
  1250|         0|            0|            0|  0.00%|
  1251|         0|            0|            0|  0.00%|@array_function_dispatch(_rollaxis_dispatcher)
  1252|         0|            0|            0|  0.00%|def rollaxis(a, axis, start=0):
  1253|         0|            0|            0|  0.00%|    """
  1254|         0|            0|            0|  0.00%|    Roll the specified axis backwards, until it lies in a given position.
  1255|         0|            0|            0|  0.00%|
  1256|         0|            0|            0|  0.00%|    This function continues to be supported for backward compatibility, but you
  1257|         0|            0|            0|  0.00%|    should prefer `moveaxis`. The `moveaxis` function was added in NumPy
  1258|         0|            0|            0|  0.00%|    1.11.
  1259|         0|            0|            0|  0.00%|
  1260|         0|            0|            0|  0.00%|    Parameters
  1261|         0|            0|            0|  0.00%|    ----------
  1262|         0|            0|            0|  0.00%|    a : ndarray
  1263|         0|            0|            0|  0.00%|        Input array.
  1264|         0|            0|            0|  0.00%|    axis : int
  1265|         0|            0|            0|  0.00%|        The axis to be rolled. The positions of the other axes do not
  1266|         0|            0|            0|  0.00%|        change relative to one another.
  1267|         0|            0|            0|  0.00%|    start : int, optional
  1268|         0|            0|            0|  0.00%|        When ``start <= axis``, the axis is rolled back until it lies in
  1269|         0|            0|            0|  0.00%|        this position. When ``start > axis``, the axis is rolled until it
  1270|         0|            0|            0|  0.00%|        lies before this position. The default, 0, results in a "complete"
  1271|         0|            0|            0|  0.00%|        roll. The following table describes how negative values of ``start``
  1272|         0|            0|            0|  0.00%|        are interpreted:
  1273|         0|            0|            0|  0.00%|
  1274|         0|            0|            0|  0.00%|        .. table::
  1275|         0|            0|            0|  0.00%|           :align: left
  1276|         0|            0|            0|  0.00%|
  1277|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1278|         0|            0|            0|  0.00%|           |     ``start``     | Normalized ``start`` |
  1279|         0|            0|            0|  0.00%|           +===================+======================+
  1280|         0|            0|            0|  0.00%|           | ``-(arr.ndim+1)`` | raise ``AxisError``  |
  1281|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1282|         0|            0|            0|  0.00%|           | ``-arr.ndim``     | 0                    |
  1283|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1284|         0|            0|            0|  0.00%|           | |vdots|           | |vdots|              |
  1285|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1286|         0|            0|            0|  0.00%|           | ``-1``            | ``arr.ndim-1``       |
  1287|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1288|         0|            0|            0|  0.00%|           | ``0``             | ``0``                |
  1289|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1290|         0|            0|            0|  0.00%|           | |vdots|           | |vdots|              |
  1291|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1292|         0|            0|            0|  0.00%|           | ``arr.ndim``      | ``arr.ndim``         |
  1293|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1294|         0|            0|            0|  0.00%|           | ``arr.ndim + 1``  | raise ``AxisError``  |
  1295|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1296|         0|            0|            0|  0.00%|
  1297|         0|            0|            0|  0.00%|        .. |vdots|   unicode:: U+22EE .. Vertical Ellipsis
  1298|         0|            0|            0|  0.00%|
  1299|         0|            0|            0|  0.00%|    Returns
  1300|         0|            0|            0|  0.00%|    -------
  1301|         0|            0|            0|  0.00%|    res : ndarray
  1302|         0|            0|            0|  0.00%|        For NumPy >= 1.10.0 a view of `a` is always returned. For earlier
  1303|         0|            0|            0|  0.00%|        NumPy versions a view of `a` is returned only if the order of the
  1304|         0|            0|            0|  0.00%|        axes is changed, otherwise the input array is returned.
  1305|         0|            0|            0|  0.00%|
  1306|         0|            0|            0|  0.00%|    See Also
  1307|         0|            0|            0|  0.00%|    --------
  1308|         0|            0|            0|  0.00%|    moveaxis : Move array axes to new positions.
  1309|         0|            0|            0|  0.00%|    roll : Roll the elements of an array by a number of positions along a
  1310|         0|            0|            0|  0.00%|        given axis.
  1311|         0|            0|            0|  0.00%|
  1312|         0|            0|            0|  0.00%|    Examples
  1313|         0|            0|            0|  0.00%|    --------
  1314|         0|            0|            0|  0.00%|    >>> a = np.ones((3,4,5,6))
  1315|         0|            0|            0|  0.00%|    >>> np.rollaxis(a, 3, 1).shape
  1316|         0|            0|            0|  0.00%|    (3, 6, 4, 5)
  1317|         0|            0|            0|  0.00%|    >>> np.rollaxis(a, 2).shape
  1318|         0|            0|            0|  0.00%|    (5, 3, 4, 6)
  1319|         0|            0|            0|  0.00%|    >>> np.rollaxis(a, 1, 4).shape
  1320|         0|            0|            0|  0.00%|    (3, 5, 6, 4)
  1321|         0|            0|            0|  0.00%|
  1322|         0|            0|            0|  0.00%|    """
  1323|         0|            0|            0|  0.00%|    n = a.ndim
  1324|         0|            0|            0|  0.00%|    axis = normalize_axis_index(axis, n)
  1325|         0|            0|            0|  0.00%|    if start < 0:
  1326|         0|            0|            0|  0.00%|        start += n
  1327|         0|            0|            0|  0.00%|    msg = "'%s' arg requires %d <= %s < %d, but %d was passed in"
  1328|         0|            0|            0|  0.00%|    if not (0 <= start < n + 1):
  1329|         0|            0|            0|  0.00%|        raise AxisError(msg % ('start', -n, 'start', n + 1, start))
  1330|         0|            0|            0|  0.00%|    if axis < start:
  1331|         0|            0|            0|  0.00%|        # it's been removed
  1332|         0|            0|            0|  0.00%|        start -= 1
  1333|         0|            0|            0|  0.00%|    if axis == start:
  1334|         0|            0|            0|  0.00%|        return a[...]
  1335|         0|            0|            0|  0.00%|    axes = list(range(0, n))
  1336|         0|            0|            0|  0.00%|    axes.remove(axis)
  1337|         0|            0|            0|  0.00%|    axes.insert(start, axis)
  1338|         0|            0|            0|  0.00%|    return a.transpose(axes)
  1339|         0|            0|            0|  0.00%|
  1340|         0|            0|            0|  0.00%|
  1341|         0|            0|            0|  0.00%|def normalize_axis_tuple(axis, ndim, argname=None, allow_duplicate=False):
  1342|         0|            0|            0|  0.00%|    """
  1343|         0|            0|            0|  0.00%|    Normalizes an axis argument into a tuple of non-negative integer axes.
  1344|         0|            0|            0|  0.00%|
  1345|         0|            0|            0|  0.00%|    This handles shorthands such as ``1`` and converts them to ``(1,)``,
  1346|         0|            0|            0|  0.00%|    as well as performing the handling of negative indices covered by
  1347|         0|            0|            0|  0.00%|    `normalize_axis_index`.
  1348|         0|            0|            0|  0.00%|
  1349|         0|            0|            0|  0.00%|    By default, this forbids axes from being specified multiple times.
  1350|         0|            0|            0|  0.00%|
  1351|         0|            0|            0|  0.00%|    Used internally by multi-axis-checking logic.
  1352|         0|            0|            0|  0.00%|
  1353|         0|            0|            0|  0.00%|    .. versionadded:: 1.13.0
  1354|         0|            0|            0|  0.00%|
  1355|         0|            0|            0|  0.00%|    Parameters
  1356|         0|            0|            0|  0.00%|    ----------
  1357|         0|            0|            0|  0.00%|    axis : int, iterable of int
  1358|         0|            0|            0|  0.00%|        The un-normalized index or indices of the axis.
  1359|         0|            0|            0|  0.00%|    ndim : int
  1360|         0|            0|            0|  0.00%|        The number of dimensions of the array that `axis` should be normalized
  1361|         0|            0|            0|  0.00%|        against.
  1362|         0|            0|            0|  0.00%|    argname : str, optional
  1363|         0|            0|            0|  0.00%|        A prefix to put before the error message, typically the name of the
  1364|         0|            0|            0|  0.00%|        argument.
  1365|         0|            0|            0|  0.00%|    allow_duplicate : bool, optional
  1366|         0|            0|            0|  0.00%|        If False, the default, disallow an axis from being specified twice.
  1367|         0|            0|            0|  0.00%|
  1368|         0|            0|            0|  0.00%|    Returns
  1369|         0|            0|            0|  0.00%|    -------
  1370|         0|            0|            0|  0.00%|    normalized_axes : tuple of int
  1371|         0|            0|            0|  0.00%|        The normalized axis index, such that `0 <= normalized_axis < ndim`
  1372|         0|            0|            0|  0.00%|
  1373|         0|            0|            0|  0.00%|    Raises
  1374|         0|            0|            0|  0.00%|    ------
  1375|         0|            0|            0|  0.00%|    AxisError
  1376|         0|            0|            0|  0.00%|        If any axis provided is out of range
  1377|         0|            0|            0|  0.00%|    ValueError
  1378|         0|            0|            0|  0.00%|        If an axis is repeated
  1379|         0|            0|            0|  0.00%|
  1380|         0|            0|            0|  0.00%|    See also
  1381|         0|            0|            0|  0.00%|    --------
  1382|         0|            0|            0|  0.00%|    normalize_axis_index : normalizing a single scalar axis
  1383|         0|            0|            0|  0.00%|    """
  1384|         0|            0|            0|  0.00%|    # Optimization to speed-up the most common cases.
  1385|         0|            0|            0|  0.00%|    if type(axis) not in (tuple, list):
  1386|         0|            0|            0|  0.00%|        try:
  1387|         0|            0|            0|  0.00%|            axis = [operator.index(axis)]
  1388|         0|            0|            0|  0.00%|        except TypeError:
  1389|         0|            0|            0|  0.00%|            pass
  1390|         0|            0|            0|  0.00%|    # Going via an iterator directly is slower than via list comprehension.
  1391|         0|            0|            0|  0.00%|    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
  1392|         0|            0|            0|  0.00%|    if not allow_duplicate and len(set(axis)) != len(axis):
  1393|         0|            0|            0|  0.00%|        if argname:
  1394|         0|            0|            0|  0.00%|            raise ValueError('repeated axis in `{}` argument'.format(argname))
  1395|         0|            0|            0|  0.00%|        else:
  1396|         0|            0|            0|  0.00%|            raise ValueError('repeated axis')
  1397|         0|            0|            0|  0.00%|    return axis
  1398|         0|            0|            0|  0.00%|
  1399|         0|            0|            0|  0.00%|
  1400|         0|            0|            0|  0.00%|def _moveaxis_dispatcher(a, source, destination):
  1401|         0|            0|            0|  0.00%|    return (a,)
  1402|         0|            0|            0|  0.00%|
  1403|         0|            0|            0|  0.00%|
  1404|         0|            0|            0|  0.00%|@array_function_dispatch(_moveaxis_dispatcher)
  1405|         0|            0|            0|  0.00%|def moveaxis(a, source, destination):
  1406|         0|            0|            0|  0.00%|    """
  1407|         0|            0|            0|  0.00%|    Move axes of an array to new positions.
  1408|         0|            0|            0|  0.00%|
  1409|         0|            0|            0|  0.00%|    Other axes remain in their original order.
  1410|         0|            0|            0|  0.00%|
  1411|         0|            0|            0|  0.00%|    .. versionadded:: 1.11.0
  1412|         0|            0|            0|  0.00%|
  1413|         0|            0|            0|  0.00%|    Parameters
  1414|         0|            0|            0|  0.00%|    ----------
  1415|         0|            0|            0|  0.00%|    a : np.ndarray
  1416|         0|            0|            0|  0.00%|        The array whose axes should be reordered.
  1417|         0|            0|            0|  0.00%|    source : int or sequence of int
  1418|         0|            0|            0|  0.00%|        Original positions of the axes to move. These must be unique.
  1419|         0|            0|            0|  0.00%|    destination : int or sequence of int
  1420|         0|            0|            0|  0.00%|        Destination positions for each of the original axes. These must also be
  1421|         0|            0|            0|  0.00%|        unique.
  1422|         0|            0|            0|  0.00%|
  1423|         0|            0|            0|  0.00%|    Returns
  1424|         0|            0|            0|  0.00%|    -------
  1425|         0|            0|            0|  0.00%|    result : np.ndarray
  1426|         0|            0|            0|  0.00%|        Array with moved axes. This array is a view of the input array.
  1427|         0|            0|            0|  0.00%|
  1428|         0|            0|            0|  0.00%|    See Also
  1429|         0|            0|            0|  0.00%|    --------
  1430|         0|            0|            0|  0.00%|    transpose : Permute the dimensions of an array.
  1431|         0|            0|            0|  0.00%|    swapaxes : Interchange two axes of an array.
  1432|         0|            0|            0|  0.00%|
  1433|         0|            0|            0|  0.00%|    Examples
  1434|         0|            0|            0|  0.00%|    --------
  1435|         0|            0|            0|  0.00%|    >>> x = np.zeros((3, 4, 5))
  1436|         0|            0|            0|  0.00%|    >>> np.moveaxis(x, 0, -1).shape
  1437|         0|            0|            0|  0.00%|    (4, 5, 3)
  1438|         0|            0|            0|  0.00%|    >>> np.moveaxis(x, -1, 0).shape
  1439|         0|            0|            0|  0.00%|    (5, 3, 4)
  1440|         0|            0|            0|  0.00%|
  1441|         0|            0|            0|  0.00%|    These all achieve the same result:
  1442|         0|            0|            0|  0.00%|
  1443|         0|            0|            0|  0.00%|    >>> np.transpose(x).shape
  1444|         0|            0|            0|  0.00%|    (5, 4, 3)
  1445|         0|            0|            0|  0.00%|    >>> np.swapaxes(x, 0, -1).shape
  1446|         0|            0|            0|  0.00%|    (5, 4, 3)
  1447|         0|            0|            0|  0.00%|    >>> np.moveaxis(x, [0, 1], [-1, -2]).shape
  1448|         0|            0|            0|  0.00%|    (5, 4, 3)
  1449|         0|            0|            0|  0.00%|    >>> np.moveaxis(x, [0, 1, 2], [-1, -2, -3]).shape
  1450|         0|            0|            0|  0.00%|    (5, 4, 3)
  1451|         0|            0|            0|  0.00%|
  1452|         0|            0|            0|  0.00%|    """
  1453|         0|            0|            0|  0.00%|    try:
  1454|         0|            0|            0|  0.00%|        # allow duck-array types if they define transpose
  1455|         0|            0|            0|  0.00%|        transpose = a.transpose
  1456|         0|            0|            0|  0.00%|    except AttributeError:
  1457|         0|            0|            0|  0.00%|        a = asarray(a)
  1458|         0|            0|            0|  0.00%|        transpose = a.transpose
  1459|         0|            0|            0|  0.00%|
  1460|         0|            0|            0|  0.00%|    source = normalize_axis_tuple(source, a.ndim, 'source')
  1461|         0|            0|            0|  0.00%|    destination = normalize_axis_tuple(destination, a.ndim, 'destination')
  1462|         0|            0|            0|  0.00%|    if len(source) != len(destination):
  1463|         0|            0|            0|  0.00%|        raise ValueError('`source` and `destination` arguments must have '
  1464|         0|            0|            0|  0.00%|                         'the same number of elements')
  1465|         0|            0|            0|  0.00%|
  1466|         0|            0|            0|  0.00%|    order = [n for n in range(a.ndim) if n not in source]
  1467|         0|            0|            0|  0.00%|
  1468|         0|            0|            0|  0.00%|    for dest, src in sorted(zip(destination, source)):
  1469|         0|            0|            0|  0.00%|        order.insert(dest, src)
  1470|         0|            0|            0|  0.00%|
  1471|         0|            0|            0|  0.00%|    result = transpose(order)
  1472|         0|            0|            0|  0.00%|    return result
  1473|         0|            0|            0|  0.00%|
  1474|         0|            0|            0|  0.00%|
  1475|         0|            0|            0|  0.00%|def _cross_dispatcher(a, b, axisa=None, axisb=None, axisc=None, axis=None):
  1476|         0|            0|            0|  0.00%|    return (a, b)
  1477|         0|            0|            0|  0.00%|
  1478|         0|            0|            0|  0.00%|
  1479|         0|            0|            0|  0.00%|@array_function_dispatch(_cross_dispatcher)
  1480|         0|            0|            0|  0.00%|def cross(a, b, axisa=-1, axisb=-1, axisc=-1, axis=None):
  1481|         0|            0|            0|  0.00%|    """
  1482|         0|            0|            0|  0.00%|    Return the cross product of two (arrays of) vectors.
  1483|         0|            0|            0|  0.00%|
  1484|         0|            0|            0|  0.00%|    The cross product of `a` and `b` in :math:`R^3` is a vector perpendicular
  1485|         0|            0|            0|  0.00%|    to both `a` and `b`.  If `a` and `b` are arrays of vectors, the vectors
  1486|         0|            0|            0|  0.00%|    are defined by the last axis of `a` and `b` by default, and these axes
  1487|         0|            0|            0|  0.00%|    can have dimensions 2 or 3.  Where the dimension of either `a` or `b` is
  1488|         0|            0|            0|  0.00%|    2, the third component of the input vector is assumed to be zero and the
  1489|         0|            0|            0|  0.00%|    cross product calculated accordingly.  In cases where both input vectors
  1490|         0|            0|            0|  0.00%|    have dimension 2, the z-component of the cross product is returned.
  1491|         0|            0|            0|  0.00%|
  1492|         0|            0|            0|  0.00%|    Parameters
  1493|         0|            0|            0|  0.00%|    ----------
  1494|         0|            0|            0|  0.00%|    a : array_like
  1495|         0|            0|            0|  0.00%|        Components of the first vector(s).
  1496|         0|            0|            0|  0.00%|    b : array_like
  1497|         0|            0|            0|  0.00%|        Components of the second vector(s).
  1498|         0|            0|            0|  0.00%|    axisa : int, optional
  1499|         0|            0|            0|  0.00%|        Axis of `a` that defines the vector(s).  By default, the last axis.
  1500|         0|            0|            0|  0.00%|    axisb : int, optional
  1501|         0|            0|            0|  0.00%|        Axis of `b` that defines the vector(s).  By default, the last axis.
  1502|         0|            0|            0|  0.00%|    axisc : int, optional
  1503|         0|            0|            0|  0.00%|        Axis of `c` containing the cross product vector(s).  Ignored if
  1504|         0|            0|            0|  0.00%|        both input vectors have dimension 2, as the return is scalar.
  1505|         0|            0|            0|  0.00%|        By default, the last axis.
  1506|         0|            0|            0|  0.00%|    axis : int, optional
  1507|         0|            0|            0|  0.00%|        If defined, the axis of `a`, `b` and `c` that defines the vector(s)
  1508|         0|            0|            0|  0.00%|        and cross product(s).  Overrides `axisa`, `axisb` and `axisc`.
  1509|         0|            0|            0|  0.00%|
  1510|         0|            0|            0|  0.00%|    Returns
  1511|         0|            0|            0|  0.00%|    -------
  1512|         0|            0|            0|  0.00%|    c : ndarray
  1513|         0|            0|            0|  0.00%|        Vector cross product(s).
  1514|         0|            0|            0|  0.00%|
  1515|         0|            0|            0|  0.00%|    Raises
  1516|         0|            0|            0|  0.00%|    ------
  1517|         0|            0|            0|  0.00%|    ValueError
  1518|         0|            0|            0|  0.00%|        When the dimension of the vector(s) in `a` and/or `b` does not
  1519|         0|            0|            0|  0.00%|        equal 2 or 3.
  1520|         0|            0|            0|  0.00%|
  1521|         0|            0|            0|  0.00%|    See Also
  1522|         0|            0|            0|  0.00%|    --------
  1523|         0|            0|            0|  0.00%|    inner : Inner product
  1524|         0|            0|            0|  0.00%|    outer : Outer product.
  1525|         0|            0|            0|  0.00%|    ix_ : Construct index arrays.
  1526|         0|            0|            0|  0.00%|
  1527|         0|            0|            0|  0.00%|    Notes
  1528|         0|            0|            0|  0.00%|    -----
  1529|         0|            0|            0|  0.00%|    .. versionadded:: 1.9.0
  1530|         0|            0|            0|  0.00%|
  1531|         0|            0|            0|  0.00%|    Supports full broadcasting of the inputs.
  1532|         0|            0|            0|  0.00%|
  1533|         0|            0|            0|  0.00%|    Examples
  1534|         0|            0|            0|  0.00%|    --------
  1535|         0|            0|            0|  0.00%|    Vector cross-product.
  1536|         0|            0|            0|  0.00%|
  1537|         0|            0|            0|  0.00%|    >>> x = [1, 2, 3]
  1538|         0|            0|            0|  0.00%|    >>> y = [4, 5, 6]
  1539|         0|            0|            0|  0.00%|    >>> np.cross(x, y)
  1540|         0|            0|            0|  0.00%|    array([-3,  6, -3])
  1541|         0|            0|            0|  0.00%|
  1542|         0|            0|            0|  0.00%|    One vector with dimension 2.
  1543|         0|            0|            0|  0.00%|
  1544|         0|            0|            0|  0.00%|    >>> x = [1, 2]
  1545|         0|            0|            0|  0.00%|    >>> y = [4, 5, 6]
  1546|         0|            0|            0|  0.00%|    >>> np.cross(x, y)
  1547|         0|            0|            0|  0.00%|    array([12, -6, -3])
  1548|         0|            0|            0|  0.00%|
  1549|         0|            0|            0|  0.00%|    Equivalently:
  1550|         0|            0|            0|  0.00%|
  1551|         0|            0|            0|  0.00%|    >>> x = [1, 2, 0]
  1552|         0|            0|            0|  0.00%|    >>> y = [4, 5, 6]
  1553|         0|            0|            0|  0.00%|    >>> np.cross(x, y)
  1554|         0|            0|            0|  0.00%|    array([12, -6, -3])
  1555|         0|            0|            0|  0.00%|
  1556|         0|            0|            0|  0.00%|    Both vectors with dimension 2.
  1557|         0|            0|            0|  0.00%|
  1558|         0|            0|            0|  0.00%|    >>> x = [1,2]
  1559|         0|            0|            0|  0.00%|    >>> y = [4,5]
  1560|         0|            0|            0|  0.00%|    >>> np.cross(x, y)
  1561|         0|            0|            0|  0.00%|    array(-3)
  1562|         0|            0|            0|  0.00%|
  1563|         0|            0|            0|  0.00%|    Multiple vector cross-products. Note that the direction of the cross
  1564|         0|            0|            0|  0.00%|    product vector is defined by the `right-hand rule`.
  1565|         0|            0|            0|  0.00%|
  1566|         0|            0|            0|  0.00%|    >>> x = np.array([[1,2,3], [4,5,6]])
  1567|         0|            0|            0|  0.00%|    >>> y = np.array([[4,5,6], [1,2,3]])
  1568|         0|            0|            0|  0.00%|    >>> np.cross(x, y)
  1569|         0|            0|            0|  0.00%|    array([[-3,  6, -3],
  1570|         0|            0|            0|  0.00%|           [ 3, -6,  3]])
  1571|         0|            0|            0|  0.00%|
  1572|         0|            0|            0|  0.00%|    The orientation of `c` can be changed using the `axisc` keyword.
  1573|         0|            0|            0|  0.00%|
  1574|         0|            0|            0|  0.00%|    >>> np.cross(x, y, axisc=0)
  1575|         0|            0|            0|  0.00%|    array([[-3,  3],
  1576|         0|            0|            0|  0.00%|           [ 6, -6],
  1577|         0|            0|            0|  0.00%|           [-3,  3]])
  1578|         0|            0|            0|  0.00%|
  1579|         0|            0|            0|  0.00%|    Change the vector definition of `x` and `y` using `axisa` and `axisb`.
  1580|         0|            0|            0|  0.00%|
  1581|         0|            0|            0|  0.00%|    >>> x = np.array([[1,2,3], [4,5,6], [7, 8, 9]])
  1582|         0|            0|            0|  0.00%|    >>> y = np.array([[7, 8, 9], [4,5,6], [1,2,3]])
  1583|         0|            0|            0|  0.00%|    >>> np.cross(x, y)
  1584|         0|            0|            0|  0.00%|    array([[ -6,  12,  -6],
  1585|         0|            0|            0|  0.00%|           [  0,   0,   0],
  1586|         0|            0|            0|  0.00%|           [  6, -12,   6]])
  1587|         0|            0|            0|  0.00%|    >>> np.cross(x, y, axisa=0, axisb=0)
  1588|         0|            0|            0|  0.00%|    array([[-24,  48, -24],
  1589|         0|            0|            0|  0.00%|           [-30,  60, -30],
  1590|         0|            0|            0|  0.00%|           [-36,  72, -36]])
  1591|         0|            0|            0|  0.00%|
  1592|         0|            0|            0|  0.00%|    """
  1593|         0|            0|            0|  0.00%|    if axis is not None:
  1594|         0|            0|            0|  0.00%|        axisa, axisb, axisc = (axis,) * 3
  1595|         0|            0|            0|  0.00%|    a = asarray(a)
  1596|         0|            0|            0|  0.00%|    b = asarray(b)
  1597|         0|            0|            0|  0.00%|    # Check axisa and axisb are within bounds
  1598|         0|            0|            0|  0.00%|    axisa = normalize_axis_index(axisa, a.ndim, msg_prefix='axisa')
  1599|         0|            0|            0|  0.00%|    axisb = normalize_axis_index(axisb, b.ndim, msg_prefix='axisb')
  1600|         0|            0|            0|  0.00%|
  1601|         0|            0|            0|  0.00%|    # Move working axis to the end of the shape
  1602|         0|            0|            0|  0.00%|    a = moveaxis(a, axisa, -1)
  1603|         0|            0|            0|  0.00%|    b = moveaxis(b, axisb, -1)
  1604|         0|            0|            0|  0.00%|    msg = ("incompatible dimensions for cross product\n"
  1605|         0|            0|            0|  0.00%|           "(dimension must be 2 or 3)")
  1606|         0|            0|            0|  0.00%|    if a.shape[-1] not in (2, 3) or b.shape[-1] not in (2, 3):
  1607|         0|            0|            0|  0.00%|        raise ValueError(msg)
  1608|         0|            0|            0|  0.00%|
  1609|         0|            0|            0|  0.00%|    # Create the output array
  1610|         0|            0|            0|  0.00%|    shape = broadcast(a[..., 0], b[..., 0]).shape
  1611|         0|            0|            0|  0.00%|    if a.shape[-1] == 3 or b.shape[-1] == 3:
  1612|         0|            0|            0|  0.00%|        shape += (3,)
  1613|         0|            0|            0|  0.00%|        # Check axisc is within bounds
  1614|         0|            0|            0|  0.00%|        axisc = normalize_axis_index(axisc, len(shape), msg_prefix='axisc')
  1615|         0|            0|            0|  0.00%|    dtype = promote_types(a.dtype, b.dtype)
  1616|         0|            0|            0|  0.00%|    cp = empty(shape, dtype)
  1617|         0|            0|            0|  0.00%|
  1618|         0|            0|            0|  0.00%|    # create local aliases for readability
  1619|         0|            0|            0|  0.00%|    a0 = a[..., 0]
  1620|         0|            0|            0|  0.00%|    a1 = a[..., 1]
  1621|         0|            0|            0|  0.00%|    if a.shape[-1] == 3:
  1622|         0|            0|            0|  0.00%|        a2 = a[..., 2]
  1623|         0|            0|            0|  0.00%|    b0 = b[..., 0]
  1624|         0|            0|            0|  0.00%|    b1 = b[..., 1]
  1625|         0|            0|            0|  0.00%|    if b.shape[-1] == 3:
  1626|         0|            0|            0|  0.00%|        b2 = b[..., 2]
  1627|         0|            0|            0|  0.00%|    if cp.ndim != 0 and cp.shape[-1] == 3:
  1628|         0|            0|            0|  0.00%|        cp0 = cp[..., 0]
  1629|         0|            0|            0|  0.00%|        cp1 = cp[..., 1]
  1630|         0|            0|            0|  0.00%|        cp2 = cp[..., 2]
  1631|         0|            0|            0|  0.00%|
  1632|         0|            0|            0|  0.00%|    if a.shape[-1] == 2:
  1633|         0|            0|            0|  0.00%|        if b.shape[-1] == 2:
  1634|         0|            0|            0|  0.00%|            # a0 * b1 - a1 * b0
  1635|         0|            0|            0|  0.00%|            multiply(a0, b1, out=cp)
  1636|         0|            0|            0|  0.00%|            cp -= a1 * b0
  1637|         0|            0|            0|  0.00%|            return cp
  1638|         0|            0|            0|  0.00%|        else:
  1639|         0|            0|            0|  0.00%|            assert b.shape[-1] == 3
  1640|         0|            0|            0|  0.00%|            # cp0 = a1 * b2 - 0  (a2 = 0)
  1641|         0|            0|            0|  0.00%|            # cp1 = 0 - a0 * b2  (a2 = 0)
  1642|         0|            0|            0|  0.00%|            # cp2 = a0 * b1 - a1 * b0
  1643|         0|            0|            0|  0.00%|            multiply(a1, b2, out=cp0)
  1644|         0|            0|            0|  0.00%|            multiply(a0, b2, out=cp1)
  1645|         0|            0|            0|  0.00%|            negative(cp1, out=cp1)
  1646|         0|            0|            0|  0.00%|            multiply(a0, b1, out=cp2)
  1647|         0|            0|            0|  0.00%|            cp2 -= a1 * b0
  1648|         0|            0|            0|  0.00%|    else:
  1649|         0|            0|            0|  0.00%|        assert a.shape[-1] == 3
  1650|         0|            0|            0|  0.00%|        if b.shape[-1] == 3:
  1651|         0|            0|            0|  0.00%|            # cp0 = a1 * b2 - a2 * b1
  1652|         0|            0|            0|  0.00%|            # cp1 = a2 * b0 - a0 * b2
  1653|         0|            0|            0|  0.00%|            # cp2 = a0 * b1 - a1 * b0
  1654|         0|            0|            0|  0.00%|            multiply(a1, b2, out=cp0)
  1655|         0|            0|            0|  0.00%|            tmp = array(a2 * b1)
  1656|         0|            0|            0|  0.00%|            cp0 -= tmp
  1657|         0|            0|            0|  0.00%|            multiply(a2, b0, out=cp1)
  1658|         0|            0|            0|  0.00%|            multiply(a0, b2, out=tmp)
  1659|         0|            0|            0|  0.00%|            cp1 -= tmp
  1660|         0|            0|            0|  0.00%|            multiply(a0, b1, out=cp2)
  1661|         0|            0|            0|  0.00%|            multiply(a1, b0, out=tmp)
  1662|         0|            0|            0|  0.00%|            cp2 -= tmp
  1663|         0|            0|            0|  0.00%|        else:
  1664|         0|            0|            0|  0.00%|            assert b.shape[-1] == 2
  1665|         0|            0|            0|  0.00%|            # cp0 = 0 - a2 * b1  (b2 = 0)
  1666|         0|            0|            0|  0.00%|            # cp1 = a2 * b0 - 0  (b2 = 0)
  1667|         0|            0|            0|  0.00%|            # cp2 = a0 * b1 - a1 * b0
  1668|         0|            0|            0|  0.00%|            multiply(a2, b1, out=cp0)
  1669|         0|            0|            0|  0.00%|            negative(cp0, out=cp0)
  1670|         0|            0|            0|  0.00%|            multiply(a2, b0, out=cp1)
  1671|         0|            0|            0|  0.00%|            multiply(a0, b1, out=cp2)
  1672|         0|            0|            0|  0.00%|            cp2 -= a1 * b0
  1673|         0|            0|            0|  0.00%|
  1674|         0|            0|            0|  0.00%|    return moveaxis(cp, -1, axisc)
  1675|         0|            0|            0|  0.00%|
  1676|         0|            0|            0|  0.00%|
  1677|         0|            0|            0|  0.00%|little_endian = (sys.byteorder == 'little')
  1678|         0|            0|            0|  0.00%|
  1679|         0|            0|            0|  0.00%|
  1680|         0|            0|            0|  0.00%|@set_module('numpy')
  1681|         0|            0|            0|  0.00%|def indices(dimensions, dtype=int, sparse=False):
  1682|         0|            0|            0|  0.00%|    """
  1683|         0|            0|            0|  0.00%|    Return an array representing the indices of a grid.
  1684|         0|            0|            0|  0.00%|
  1685|         0|            0|            0|  0.00%|    Compute an array where the subarrays contain index values 0, 1, ...
  1686|         0|            0|            0|  0.00%|    varying only along the corresponding axis.
  1687|         0|            0|            0|  0.00%|
  1688|         0|            0|            0|  0.00%|    Parameters
  1689|         0|            0|            0|  0.00%|    ----------
  1690|         0|            0|            0|  0.00%|    dimensions : sequence of ints
  1691|         0|            0|            0|  0.00%|        The shape of the grid.
  1692|         0|            0|            0|  0.00%|    dtype : dtype, optional
  1693|         0|            0|            0|  0.00%|        Data type of the result.
  1694|         0|            0|            0|  0.00%|    sparse : boolean, optional
  1695|         0|            0|            0|  0.00%|        Return a sparse representation of the grid instead of a dense
  1696|         0|            0|            0|  0.00%|        representation. Default is False.
  1697|         0|            0|            0|  0.00%|
  1698|         0|            0|            0|  0.00%|        .. versionadded:: 1.17
  1699|         0|            0|            0|  0.00%|
  1700|         0|            0|            0|  0.00%|    Returns
  1701|         0|            0|            0|  0.00%|    -------
  1702|         0|            0|            0|  0.00%|    grid : one ndarray or tuple of ndarrays
  1703|         0|            0|            0|  0.00%|        If sparse is False:
  1704|         0|            0|            0|  0.00%|            Returns one array of grid indices,
  1705|         0|            0|            0|  0.00%|            ``grid.shape = (len(dimensions),) + tuple(dimensions)``.
  1706|         0|            0|            0|  0.00%|        If sparse is True:
  1707|         0|            0|            0|  0.00%|            Returns a tuple of arrays, with
  1708|         0|            0|            0|  0.00%|            ``grid[i].shape = (1, ..., 1, dimensions[i], 1, ..., 1)`` with
  1709|         0|            0|            0|  0.00%|            dimensions[i] in the ith place
  1710|         0|            0|            0|  0.00%|
  1711|         0|            0|            0|  0.00%|    See Also
  1712|         0|            0|            0|  0.00%|    --------
  1713|         0|            0|            0|  0.00%|    mgrid, ogrid, meshgrid
  1714|         0|            0|            0|  0.00%|
  1715|         0|            0|            0|  0.00%|    Notes
  1716|         0|            0|            0|  0.00%|    -----
  1717|         0|            0|            0|  0.00%|    The output shape in the dense case is obtained by prepending the number
  1718|         0|            0|            0|  0.00%|    of dimensions in front of the tuple of dimensions, i.e. if `dimensions`
  1719|         0|            0|            0|  0.00%|    is a tuple ``(r0, ..., rN-1)`` of length ``N``, the output shape is
  1720|         0|            0|            0|  0.00%|    ``(N, r0, ..., rN-1)``.
  1721|         0|            0|            0|  0.00%|
  1722|         0|            0|            0|  0.00%|    The subarrays ``grid[k]`` contains the N-D array of indices along the
  1723|         0|            0|            0|  0.00%|    ``k-th`` axis. Explicitly::
  1724|         0|            0|            0|  0.00%|
  1725|         0|            0|            0|  0.00%|        grid[k, i0, i1, ..., iN-1] = ik
  1726|         0|            0|            0|  0.00%|
  1727|         0|            0|            0|  0.00%|    Examples
  1728|         0|            0|            0|  0.00%|    --------
  1729|         0|            0|            0|  0.00%|    >>> grid = np.indices((2, 3))
  1730|         0|            0|            0|  0.00%|    >>> grid.shape
  1731|         0|            0|            0|  0.00%|    (2, 2, 3)
  1732|         0|            0|            0|  0.00%|    >>> grid[0]        # row indices
  1733|         0|            0|            0|  0.00%|    array([[0, 0, 0],
  1734|         0|            0|            0|  0.00%|           [1, 1, 1]])
  1735|         0|            0|            0|  0.00%|    >>> grid[1]        # column indices
  1736|         0|            0|            0|  0.00%|    array([[0, 1, 2],
  1737|         0|            0|            0|  0.00%|           [0, 1, 2]])
  1738|         0|            0|            0|  0.00%|
  1739|         0|            0|            0|  0.00%|    The indices can be used as an index into an array.
  1740|         0|            0|            0|  0.00%|
  1741|         0|            0|            0|  0.00%|    >>> x = np.arange(20).reshape(5, 4)
  1742|         0|            0|            0|  0.00%|    >>> row, col = np.indices((2, 3))
  1743|         0|            0|            0|  0.00%|    >>> x[row, col]
  1744|         0|            0|            0|  0.00%|    array([[0, 1, 2],
  1745|         0|            0|            0|  0.00%|           [4, 5, 6]])
  1746|         0|            0|            0|  0.00%|
  1747|         0|            0|            0|  0.00%|    Note that it would be more straightforward in the above example to
  1748|         0|            0|            0|  0.00%|    extract the required elements directly with ``x[:2, :3]``.
  1749|         0|            0|            0|  0.00%|
  1750|         0|            0|            0|  0.00%|    If sparse is set to true, the grid will be returned in a sparse
  1751|         0|            0|            0|  0.00%|    representation.
  1752|         0|            0|            0|  0.00%|
  1753|         0|            0|            0|  0.00%|    >>> i, j = np.indices((2, 3), sparse=True)
  1754|         0|            0|            0|  0.00%|    >>> i.shape
  1755|         0|            0|            0|  0.00%|    (2, 1)
  1756|         0|            0|            0|  0.00%|    >>> j.shape
  1757|         0|            0|            0|  0.00%|    (1, 3)
  1758|         0|            0|            0|  0.00%|    >>> i        # row indices
  1759|         0|            0|            0|  0.00%|    array([[0],
  1760|         0|            0|            0|  0.00%|           [1]])
  1761|         0|            0|            0|  0.00%|    >>> j        # column indices
  1762|         0|            0|            0|  0.00%|    array([[0, 1, 2]])
  1763|         0|            0|            0|  0.00%|
  1764|         0|            0|            0|  0.00%|    """
  1765|         0|            0|            0|  0.00%|    dimensions = tuple(dimensions)
  1766|         0|            0|            0|  0.00%|    N = len(dimensions)
  1767|         0|            0|            0|  0.00%|    shape = (1,)*N
  1768|         0|            0|            0|  0.00%|    if sparse:
  1769|         0|            0|            0|  0.00%|        res = tuple()
  1770|         0|            0|            0|  0.00%|    else:
  1771|         0|            0|            0|  0.00%|        res = empty((N,)+dimensions, dtype=dtype)
  1772|         0|            0|            0|  0.00%|    for i, dim in enumerate(dimensions):
  1773|         0|            0|            0|  0.00%|        idx = arange(dim, dtype=dtype).reshape(
  1774|         0|            0|            0|  0.00%|            shape[:i] + (dim,) + shape[i+1:]
  1775|         0|            0|            0|  0.00%|        )
  1776|         0|            0|            0|  0.00%|        if sparse:
  1777|         0|            0|            0|  0.00%|            res = res + (idx,)
  1778|         0|            0|            0|  0.00%|        else:
  1779|         0|            0|            0|  0.00%|            res[i] = idx
  1780|         0|            0|            0|  0.00%|    return res
  1781|         0|            0|            0|  0.00%|
  1782|         0|            0|            0|  0.00%|
  1783|         0|            0|            0|  0.00%|def _fromfunction_dispatcher(function, shape, *, dtype=None, like=None, **kwargs):
  1784|         0|            0|            0|  0.00%|    return (like,)
  1785|         0|            0|            0|  0.00%|
  1786|         0|            0|            0|  0.00%|
  1787|         0|            0|            0|  0.00%|@set_array_function_like_doc
  1788|         0|            0|            0|  0.00%|@set_module('numpy')
  1789|         0|            0|            0|  0.00%|def fromfunction(function, shape, *, dtype=float, like=None, **kwargs):
  1790|         0|            0|            0|  0.00%|    """
  1791|         0|            0|            0|  0.00%|    Construct an array by executing a function over each coordinate.
  1792|         0|            0|            0|  0.00%|
  1793|         0|            0|            0|  0.00%|    The resulting array therefore has a value ``fn(x, y, z)`` at
  1794|         0|            0|            0|  0.00%|    coordinate ``(x, y, z)``.
  1795|         0|            0|            0|  0.00%|
  1796|         0|            0|            0|  0.00%|    Parameters
  1797|         0|            0|            0|  0.00%|    ----------
  1798|         0|            0|            0|  0.00%|    function : callable
  1799|         0|            0|            0|  0.00%|        The function is called with N parameters, where N is the rank of
  1800|         0|            0|            0|  0.00%|        `shape`.  Each parameter represents the coordinates of the array
  1801|         0|            0|            0|  0.00%|        varying along a specific axis.  For example, if `shape`
  1802|         0|            0|            0|  0.00%|        were ``(2, 2)``, then the parameters would be
  1803|         0|            0|            0|  0.00%|        ``array([[0, 0], [1, 1]])`` and ``array([[0, 1], [0, 1]])``
  1804|         0|            0|            0|  0.00%|    shape : (N,) tuple of ints
  1805|         0|            0|            0|  0.00%|        Shape of the output array, which also determines the shape of
  1806|         0|            0|            0|  0.00%|        the coordinate arrays passed to `function`.
  1807|         0|            0|            0|  0.00%|    dtype : data-type, optional
  1808|         0|            0|            0|  0.00%|        Data-type of the coordinate arrays passed to `function`.
  1809|         0|            0|            0|  0.00%|        By default, `dtype` is float.
  1810|         0|            0|            0|  0.00%|    ${ARRAY_FUNCTION_LIKE}
  1811|         0|            0|            0|  0.00%|
  1812|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
  1813|         0|            0|            0|  0.00%|
  1814|         0|            0|            0|  0.00%|    Returns
  1815|         0|            0|            0|  0.00%|    -------
  1816|         0|            0|            0|  0.00%|    fromfunction : any
  1817|         0|            0|            0|  0.00%|        The result of the call to `function` is passed back directly.
  1818|         0|            0|            0|  0.00%|        Therefore the shape of `fromfunction` is completely determined by
  1819|         0|            0|            0|  0.00%|        `function`.  If `function` returns a scalar value, the shape of
  1820|         0|            0|            0|  0.00%|        `fromfunction` would not match the `shape` parameter.
  1821|         0|            0|            0|  0.00%|
  1822|         0|            0|            0|  0.00%|    See Also
  1823|         0|            0|            0|  0.00%|    --------
  1824|         0|            0|            0|  0.00%|    indices, meshgrid
  1825|         0|            0|            0|  0.00%|
  1826|         0|            0|            0|  0.00%|    Notes
  1827|         0|            0|            0|  0.00%|    -----
  1828|         0|            0|            0|  0.00%|    Keywords other than `dtype` are passed to `function`.
  1829|         0|            0|            0|  0.00%|
  1830|         0|            0|            0|  0.00%|    Examples
  1831|         0|            0|            0|  0.00%|    --------
  1832|         0|            0|            0|  0.00%|    >>> np.fromfunction(lambda i, j: i == j, (3, 3), dtype=int)
  1833|         0|            0|            0|  0.00%|    array([[ True, False, False],
  1834|         0|            0|            0|  0.00%|           [False,  True, False],
  1835|         0|            0|            0|  0.00%|           [False, False,  True]])
  1836|         0|            0|            0|  0.00%|
  1837|         0|            0|            0|  0.00%|    >>> np.fromfunction(lambda i, j: i + j, (3, 3), dtype=int)
  1838|         0|            0|            0|  0.00%|    array([[0, 1, 2],
  1839|         0|            0|            0|  0.00%|           [1, 2, 3],
  1840|         0|            0|            0|  0.00%|           [2, 3, 4]])
  1841|         0|            0|            0|  0.00%|
  1842|         0|            0|            0|  0.00%|    """
  1843|         0|            0|            0|  0.00%|    if like is not None:
  1844|         0|            0|            0|  0.00%|        return _fromfunction_with_like(function, shape, dtype=dtype, like=like, **kwargs)
  1845|         0|            0|            0|  0.00%|
  1846|         0|            0|            0|  0.00%|    args = indices(shape, dtype=dtype)
  1847|         0|            0|            0|  0.00%|    return function(*args, **kwargs)
  1848|         0|            0|            0|  0.00%|
  1849|         0|            0|            0|  0.00%|
  1850|         0|            0|            0|  0.00%|_fromfunction_with_like = array_function_dispatch(
  1851|         0|            0|            0|  0.00%|    _fromfunction_dispatcher
  1852|         0|            0|            0|  0.00%|)(fromfunction)
  1853|         0|            0|            0|  0.00%|
  1854|         0|            0|            0|  0.00%|
  1855|         0|            0|            0|  0.00%|def _frombuffer(buf, dtype, shape, order):
  1856|         0|            0|            0|  0.00%|    return frombuffer(buf, dtype=dtype).reshape(shape, order=order)
  1857|         0|            0|            0|  0.00%|
  1858|         0|            0|            0|  0.00%|
  1859|         0|            0|            0|  0.00%|@set_module('numpy')
  1860|         0|            0|            0|  0.00%|def isscalar(element):
  1861|         0|            0|            0|  0.00%|    """
  1862|         0|            0|            0|  0.00%|    Returns True if the type of `element` is a scalar type.
  1863|         0|            0|            0|  0.00%|
  1864|         0|            0|            0|  0.00%|    Parameters
  1865|         0|            0|            0|  0.00%|    ----------
  1866|         0|            0|            0|  0.00%|    element : any
  1867|         0|            0|            0|  0.00%|        Input argument, can be of any type and shape.
  1868|         0|            0|            0|  0.00%|
  1869|         0|            0|            0|  0.00%|    Returns
  1870|         0|            0|            0|  0.00%|    -------
  1871|         0|            0|            0|  0.00%|    val : bool
  1872|         0|            0|            0|  0.00%|        True if `element` is a scalar type, False if it is not.
  1873|         0|            0|            0|  0.00%|
  1874|         0|            0|            0|  0.00%|    See Also
  1875|         0|            0|            0|  0.00%|    --------
  1876|         0|            0|            0|  0.00%|    ndim : Get the number of dimensions of an array
  1877|         0|            0|            0|  0.00%|
  1878|         0|            0|            0|  0.00%|    Notes
  1879|         0|            0|            0|  0.00%|    -----
  1880|         0|            0|            0|  0.00%|    If you need a stricter way to identify a *numerical* scalar, use
  1881|         0|            0|            0|  0.00%|    ``isinstance(x, numbers.Number)``, as that returns ``False`` for most
  1882|         0|            0|            0|  0.00%|    non-numerical elements such as strings.
  1883|         0|            0|            0|  0.00%|
  1884|         0|            0|            0|  0.00%|    In most cases ``np.ndim(x) == 0`` should be used instead of this function,
  1885|         0|            0|            0|  0.00%|    as that will also return true for 0d arrays. This is how numpy overloads
  1886|         0|            0|            0|  0.00%|    functions in the style of the ``dx`` arguments to `gradient` and the ``bins``
  1887|         0|            0|            0|  0.00%|    argument to `histogram`. Some key differences:
  1888|         0|            0|            0|  0.00%|
  1889|         0|            0|            0|  0.00%|    +--------------------------------------+---------------+-------------------+
  1890|         0|            0|            0|  0.00%|    | x                                    |``isscalar(x)``|``np.ndim(x) == 0``|
  1891|         0|            0|            0|  0.00%|    +======================================+===============+===================+
  1892|         0|            0|            0|  0.00%|    | PEP 3141 numeric objects (including  | ``True``      | ``True``          |
  1893|         0|            0|            0|  0.00%|    | builtins)                            |               |                   |
  1894|         0|            0|            0|  0.00%|    +--------------------------------------+---------------+-------------------+
  1895|         0|            0|            0|  0.00%|    | builtin string and buffer objects    | ``True``      | ``True``          |
  1896|         0|            0|            0|  0.00%|    +--------------------------------------+---------------+-------------------+
  1897|         0|            0|            0|  0.00%|    | other builtin objects, like          | ``False``     | ``True``          |
  1898|         0|            0|            0|  0.00%|    | `pathlib.Path`, `Exception`,         |               |                   |
  1899|         0|            0|            0|  0.00%|    | the result of `re.compile`           |               |                   |
  1900|         0|            0|            0|  0.00%|    +--------------------------------------+---------------+-------------------+
  1901|         0|            0|            0|  0.00%|    | third-party objects like             | ``False``     | ``True``          |
  1902|         0|            0|            0|  0.00%|    | `matplotlib.figure.Figure`           |               |                   |
  1903|         0|            0|            0|  0.00%|    +--------------------------------------+---------------+-------------------+
  1904|         0|            0|            0|  0.00%|    | zero-dimensional numpy arrays        | ``False``     | ``True``          |
  1905|         0|            0|            0|  0.00%|    +--------------------------------------+---------------+-------------------+
  1906|         0|            0|            0|  0.00%|    | other numpy arrays                   | ``False``     | ``False``         |
  1907|         0|            0|            0|  0.00%|    +--------------------------------------+---------------+-------------------+
  1908|         0|            0|            0|  0.00%|    | `list`, `tuple`, and other sequence  | ``False``     | ``False``         |
  1909|         0|            0|            0|  0.00%|    | objects                              |               |                   |
  1910|         0|            0|            0|  0.00%|    +--------------------------------------+---------------+-------------------+
  1911|         0|            0|            0|  0.00%|
  1912|         0|            0|            0|  0.00%|    Examples
  1913|         0|            0|            0|  0.00%|    --------
  1914|         0|            0|            0|  0.00%|    >>> np.isscalar(3.1)
  1915|         0|            0|            0|  0.00%|    True
  1916|         0|            0|            0|  0.00%|    >>> np.isscalar(np.array(3.1))
  1917|         0|            0|            0|  0.00%|    False
  1918|         0|            0|            0|  0.00%|    >>> np.isscalar([3.1])
  1919|         0|            0|            0|  0.00%|    False
  1920|         0|            0|            0|  0.00%|    >>> np.isscalar(False)
  1921|         0|            0|            0|  0.00%|    True
  1922|         0|            0|            0|  0.00%|    >>> np.isscalar('numpy')
  1923|         0|            0|            0|  0.00%|    True
  1924|         0|            0|            0|  0.00%|
  1925|         0|            0|            0|  0.00%|    NumPy supports PEP 3141 numbers:
  1926|         0|            0|            0|  0.00%|
  1927|         0|            0|            0|  0.00%|    >>> from fractions import Fraction
  1928|         0|            0|            0|  0.00%|    >>> np.isscalar(Fraction(5, 17))
  1929|         0|            0|            0|  0.00%|    True
  1930|         0|            0|            0|  0.00%|    >>> from numbers import Number
  1931|         0|            0|            0|  0.00%|    >>> np.isscalar(Number())
  1932|         0|            0|            0|  0.00%|    True
  1933|         0|            0|            0|  0.00%|
  1934|         0|            0|            0|  0.00%|    """
  1935|         0|            0|            0|  0.00%|    return (isinstance(element, generic)
  1936|         0|            0|            0|  0.00%|            or type(element) in ScalarType
  1937|         0|            0|            0|  0.00%|            or isinstance(element, numbers.Number))
  1938|         0|            0|            0|  0.00%|
  1939|         0|            0|            0|  0.00%|
  1940|         0|            0|            0|  0.00%|@set_module('numpy')
  1941|         0|            0|            0|  0.00%|def binary_repr(num, width=None):
  1942|         0|            0|            0|  0.00%|    """
  1943|         0|            0|            0|  0.00%|    Return the binary representation of the input number as a string.
  1944|         0|            0|            0|  0.00%|
  1945|         0|            0|            0|  0.00%|    For negative numbers, if width is not given, a minus sign is added to the
  1946|         0|            0|            0|  0.00%|    front. If width is given, the two's complement of the number is
  1947|         0|            0|            0|  0.00%|    returned, with respect to that width.
  1948|         0|            0|            0|  0.00%|
  1949|         0|            0|            0|  0.00%|    In a two's-complement system negative numbers are represented by the two's
  1950|         0|            0|            0|  0.00%|    complement of the absolute value. This is the most common method of
  1951|         0|            0|            0|  0.00%|    representing signed integers on computers [1]_. A N-bit two's-complement
  1952|         0|            0|            0|  0.00%|    system can represent every integer in the range
  1953|         0|            0|            0|  0.00%|    :math:`-2^{N-1}` to :math:`+2^{N-1}-1`.
  1954|         0|            0|            0|  0.00%|
  1955|         0|            0|            0|  0.00%|    Parameters
  1956|         0|            0|            0|  0.00%|    ----------
  1957|         0|            0|            0|  0.00%|    num : int
  1958|         0|            0|            0|  0.00%|        Only an integer decimal number can be used.
  1959|         0|            0|            0|  0.00%|    width : int, optional
  1960|         0|            0|            0|  0.00%|        The length of the returned string if `num` is positive, or the length
  1961|         0|            0|            0|  0.00%|        of the two's complement if `num` is negative, provided that `width` is
  1962|         0|            0|            0|  0.00%|        at least a sufficient number of bits for `num` to be represented in the
  1963|         0|            0|            0|  0.00%|        designated form.
  1964|         0|            0|            0|  0.00%|
  1965|         0|            0|            0|  0.00%|        If the `width` value is insufficient, it will be ignored, and `num` will
  1966|         0|            0|            0|  0.00%|        be returned in binary (`num` > 0) or two's complement (`num` < 0) form
  1967|         0|            0|            0|  0.00%|        with its width equal to the minimum number of bits needed to represent
  1968|         0|            0|            0|  0.00%|        the number in the designated form. This behavior is deprecated and will
  1969|         0|            0|            0|  0.00%|        later raise an error.
  1970|         0|            0|            0|  0.00%|
  1971|         0|            0|            0|  0.00%|        .. deprecated:: 1.12.0
  1972|         0|            0|            0|  0.00%|
  1973|         0|            0|            0|  0.00%|    Returns
  1974|         0|            0|            0|  0.00%|    -------
  1975|         0|            0|            0|  0.00%|    bin : str
  1976|         0|            0|            0|  0.00%|        Binary representation of `num` or two's complement of `num`.
  1977|         0|            0|            0|  0.00%|
  1978|         0|            0|            0|  0.00%|    See Also
  1979|         0|            0|            0|  0.00%|    --------
  1980|         0|            0|            0|  0.00%|    base_repr: Return a string representation of a number in the given base
  1981|         0|            0|            0|  0.00%|               system.
  1982|         0|            0|            0|  0.00%|    bin: Python's built-in binary representation generator of an integer.
  1983|         0|            0|            0|  0.00%|
  1984|         0|            0|            0|  0.00%|    Notes
  1985|         0|            0|            0|  0.00%|    -----
  1986|         0|            0|            0|  0.00%|    `binary_repr` is equivalent to using `base_repr` with base 2, but about 25x
  1987|         0|            0|            0|  0.00%|    faster.
  1988|         0|            0|            0|  0.00%|
  1989|         0|            0|            0|  0.00%|    References
  1990|         0|            0|            0|  0.00%|    ----------
  1991|         0|            0|            0|  0.00%|    .. [1] Wikipedia, "Two's complement",
  1992|         0|            0|            0|  0.00%|        https://en.wikipedia.org/wiki/Two's_complement
  1993|         0|            0|            0|  0.00%|
  1994|         0|            0|            0|  0.00%|    Examples
  1995|         0|            0|            0|  0.00%|    --------
  1996|         0|            0|            0|  0.00%|    >>> np.binary_repr(3)
  1997|         0|            0|            0|  0.00%|    '11'
  1998|         0|            0|            0|  0.00%|    >>> np.binary_repr(-3)
  1999|         0|            0|            0|  0.00%|    '-11'
  2000|         0|            0|            0|  0.00%|    >>> np.binary_repr(3, width=4)
  2001|         0|            0|            0|  0.00%|    '0011'
  2002|         0|            0|            0|  0.00%|
  2003|         0|            0|            0|  0.00%|    The two's complement is returned when the input number is negative and
  2004|         0|            0|            0|  0.00%|    width is specified:
  2005|         0|            0|            0|  0.00%|
  2006|         0|            0|            0|  0.00%|    >>> np.binary_repr(-3, width=3)
  2007|         0|            0|            0|  0.00%|    '101'
  2008|         0|            0|            0|  0.00%|    >>> np.binary_repr(-3, width=5)
  2009|         0|            0|            0|  0.00%|    '11101'
  2010|         0|            0|            0|  0.00%|
  2011|         0|            0|            0|  0.00%|    """
  2012|         0|            0|            0|  0.00%|    def warn_if_insufficient(width, binwidth):
  2013|         0|            0|            0|  0.00%|        if width is not None and width < binwidth:
  2014|         0|            0|            0|  0.00%|            warnings.warn(
  2015|         0|            0|            0|  0.00%|                "Insufficient bit width provided. This behavior "
  2016|         0|            0|            0|  0.00%|                "will raise an error in the future.", DeprecationWarning,
  2017|         0|            0|            0|  0.00%|                stacklevel=3)
  2018|         0|            0|            0|  0.00%|
  2019|         0|            0|            0|  0.00%|    # Ensure that num is a Python integer to avoid overflow or unwanted
  2020|         0|            0|            0|  0.00%|    # casts to floating point.
  2021|         0|            0|            0|  0.00%|    num = operator.index(num)
  2022|         0|            0|            0|  0.00%|
  2023|         0|            0|            0|  0.00%|    if num == 0:
  2024|         0|            0|            0|  0.00%|        return '0' * (width or 1)
  2025|         0|            0|            0|  0.00%|
  2026|         0|            0|            0|  0.00%|    elif num > 0:
  2027|         0|            0|            0|  0.00%|        binary = bin(num)[2:]
  2028|         0|            0|            0|  0.00%|        binwidth = len(binary)
  2029|         0|            0|            0|  0.00%|        outwidth = (binwidth if width is None
  2030|         0|            0|            0|  0.00%|                    else max(binwidth, width))
  2031|         0|            0|            0|  0.00%|        warn_if_insufficient(width, binwidth)
  2032|         0|            0|            0|  0.00%|        return binary.zfill(outwidth)
  2033|         0|            0|            0|  0.00%|
  2034|         0|            0|            0|  0.00%|    else:
  2035|         0|            0|            0|  0.00%|        if width is None:
  2036|         0|            0|            0|  0.00%|            return '-' + bin(-num)[2:]
  2037|         0|            0|            0|  0.00%|
  2038|         0|            0|            0|  0.00%|        else:
  2039|         0|            0|            0|  0.00%|            poswidth = len(bin(-num)[2:])
  2040|         0|            0|            0|  0.00%|
  2041|         0|            0|            0|  0.00%|            # See gh-8679: remove extra digit
  2042|         0|            0|            0|  0.00%|            # for numbers at boundaries.
  2043|         0|            0|            0|  0.00%|            if 2**(poswidth - 1) == -num:
  2044|         0|            0|            0|  0.00%|                poswidth -= 1
  2045|         0|            0|            0|  0.00%|
  2046|         0|            0|            0|  0.00%|            twocomp = 2**(poswidth + 1) + num
  2047|         0|            0|            0|  0.00%|            binary = bin(twocomp)[2:]
  2048|         0|            0|            0|  0.00%|            binwidth = len(binary)
  2049|         0|            0|            0|  0.00%|
  2050|         0|            0|            0|  0.00%|            outwidth = max(binwidth, width)
  2051|         0|            0|            0|  0.00%|            warn_if_insufficient(width, binwidth)
  2052|         0|            0|            0|  0.00%|            return '1' * (outwidth - binwidth) + binary
  2053|         0|            0|            0|  0.00%|
  2054|         0|            0|            0|  0.00%|
  2055|         0|            0|            0|  0.00%|@set_module('numpy')
  2056|         0|            0|            0|  0.00%|def base_repr(number, base=2, padding=0):
  2057|         0|            0|            0|  0.00%|    """
  2058|         0|            0|            0|  0.00%|    Return a string representation of a number in the given base system.
  2059|         0|            0|            0|  0.00%|
  2060|         0|            0|            0|  0.00%|    Parameters
  2061|         0|            0|            0|  0.00%|    ----------
  2062|         0|            0|            0|  0.00%|    number : int
  2063|         0|            0|            0|  0.00%|        The value to convert. Positive and negative values are handled.
  2064|         0|            0|            0|  0.00%|    base : int, optional
  2065|         0|            0|            0|  0.00%|        Convert `number` to the `base` number system. The valid range is 2-36,
  2066|         0|            0|            0|  0.00%|        the default value is 2.
  2067|         0|            0|            0|  0.00%|    padding : int, optional
  2068|         0|            0|            0|  0.00%|        Number of zeros padded on the left. Default is 0 (no padding).
  2069|         0|            0|            0|  0.00%|
  2070|         0|            0|            0|  0.00%|    Returns
  2071|         0|            0|            0|  0.00%|    -------
  2072|         0|            0|            0|  0.00%|    out : str
  2073|         0|            0|            0|  0.00%|        String representation of `number` in `base` system.
  2074|         0|            0|            0|  0.00%|
  2075|         0|            0|            0|  0.00%|    See Also
  2076|         0|            0|            0|  0.00%|    --------
  2077|         0|            0|            0|  0.00%|    binary_repr : Faster version of `base_repr` for base 2.
  2078|         0|            0|            0|  0.00%|
  2079|         0|            0|            0|  0.00%|    Examples
  2080|         0|            0|            0|  0.00%|    --------
  2081|         0|            0|            0|  0.00%|    >>> np.base_repr(5)
  2082|         0|            0|            0|  0.00%|    '101'
  2083|         0|            0|            0|  0.00%|    >>> np.base_repr(6, 5)
  2084|         0|            0|            0|  0.00%|    '11'
  2085|         0|            0|            0|  0.00%|    >>> np.base_repr(7, base=5, padding=3)
  2086|         0|            0|            0|  0.00%|    '00012'
  2087|         0|            0|            0|  0.00%|
  2088|         0|            0|            0|  0.00%|    >>> np.base_repr(10, base=16)
  2089|         0|            0|            0|  0.00%|    'A'
  2090|         0|            0|            0|  0.00%|    >>> np.base_repr(32, base=16)
  2091|         0|            0|            0|  0.00%|    '20'
  2092|         0|            0|            0|  0.00%|
  2093|         0|            0|            0|  0.00%|    """
  2094|         0|            0|            0|  0.00%|    digits = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'
  2095|         0|            0|            0|  0.00%|    if base > len(digits):
  2096|         0|            0|            0|  0.00%|        raise ValueError("Bases greater than 36 not handled in base_repr.")
  2097|         0|            0|            0|  0.00%|    elif base < 2:
  2098|         0|            0|            0|  0.00%|        raise ValueError("Bases less than 2 not handled in base_repr.")
  2099|         0|            0|            0|  0.00%|
  2100|         0|            0|            0|  0.00%|    num = abs(number)
  2101|         0|            0|            0|  0.00%|    res = []
  2102|         0|            0|            0|  0.00%|    while num:
  2103|         0|            0|            0|  0.00%|        res.append(digits[num % base])
  2104|         0|            0|            0|  0.00%|        num //= base
  2105|         0|            0|            0|  0.00%|    if padding:
  2106|         0|            0|            0|  0.00%|        res.append('0' * padding)
  2107|         0|            0|            0|  0.00%|    if number < 0:
  2108|         0|            0|            0|  0.00%|        res.append('-')
  2109|         0|            0|            0|  0.00%|    return ''.join(reversed(res or '0'))
  2110|         0|            0|            0|  0.00%|
  2111|         0|            0|            0|  0.00%|
  2112|         0|            0|            0|  0.00%|# These are all essentially abbreviations
  2113|         0|            0|            0|  0.00%|# These might wind up in a special abbreviations module
  2114|         0|            0|            0|  0.00%|
  2115|         0|            0|            0|  0.00%|
  2116|         0|            0|            0|  0.00%|def _maketup(descr, val):
  2117|         0|            0|            0|  0.00%|    dt = dtype(descr)
  2118|         0|            0|            0|  0.00%|    # Place val in all scalar tuples:
  2119|         0|            0|            0|  0.00%|    fields = dt.fields
  2120|         0|            0|            0|  0.00%|    if fields is None:
  2121|         0|            0|            0|  0.00%|        return val
  2122|         0|            0|            0|  0.00%|    else:
  2123|         0|            0|            0|  0.00%|        res = [_maketup(fields[name][0], val) for name in dt.names]
  2124|         0|            0|            0|  0.00%|        return tuple(res)
  2125|         0|            0|            0|  0.00%|
  2126|         0|            0|            0|  0.00%|
  2127|         0|            0|            0|  0.00%|def _identity_dispatcher(n, dtype=None, *, like=None):
  2128|         0|            0|            0|  0.00%|    return (like,)
  2129|         0|            0|            0|  0.00%|
  2130|         0|            0|            0|  0.00%|
  2131|         0|            0|            0|  0.00%|@set_array_function_like_doc
  2132|         0|            0|            0|  0.00%|@set_module('numpy')
  2133|         0|            0|            0|  0.00%|def identity(n, dtype=None, *, like=None):
  2134|         0|            0|            0|  0.00%|    """
  2135|         0|            0|            0|  0.00%|    Return the identity array.
  2136|         0|            0|            0|  0.00%|
  2137|         0|            0|            0|  0.00%|    The identity array is a square array with ones on
  2138|         0|            0|            0|  0.00%|    the main diagonal.
  2139|         0|            0|            0|  0.00%|
  2140|         0|            0|            0|  0.00%|    Parameters
  2141|         0|            0|            0|  0.00%|    ----------
  2142|         0|            0|            0|  0.00%|    n : int
  2143|         0|            0|            0|  0.00%|        Number of rows (and columns) in `n` x `n` output.
  2144|         0|            0|            0|  0.00%|    dtype : data-type, optional
  2145|         0|            0|            0|  0.00%|        Data-type of the output.  Defaults to ``float``.
  2146|         0|            0|            0|  0.00%|    ${ARRAY_FUNCTION_LIKE}
  2147|         0|            0|            0|  0.00%|
  2148|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
  2149|         0|            0|            0|  0.00%|
  2150|         0|            0|            0|  0.00%|    Returns
  2151|         0|            0|            0|  0.00%|    -------
  2152|         0|            0|            0|  0.00%|    out : ndarray
  2153|         0|            0|            0|  0.00%|        `n` x `n` array with its main diagonal set to one,
  2154|         0|            0|            0|  0.00%|        and all other elements 0.
  2155|         0|            0|            0|  0.00%|
  2156|         0|            0|            0|  0.00%|    Examples
  2157|         0|            0|            0|  0.00%|    --------
  2158|         0|            0|            0|  0.00%|    >>> np.identity(3)
  2159|         0|            0|            0|  0.00%|    array([[1.,  0.,  0.],
  2160|         0|            0|            0|  0.00%|           [0.,  1.,  0.],
  2161|         0|            0|            0|  0.00%|           [0.,  0.,  1.]])
  2162|         0|            0|            0|  0.00%|
  2163|         0|            0|            0|  0.00%|    """
  2164|         0|            0|            0|  0.00%|    if like is not None:
  2165|         0|            0|            0|  0.00%|        return _identity_with_like(n, dtype=dtype, like=like)
  2166|         0|            0|            0|  0.00%|
  2167|         0|            0|            0|  0.00%|    from numpy import eye
  2168|         0|            0|            0|  0.00%|    return eye(n, dtype=dtype, like=like)
  2169|         0|            0|            0|  0.00%|
  2170|         0|            0|            0|  0.00%|
  2171|         0|            0|            0|  0.00%|_identity_with_like = array_function_dispatch(
  2172|         0|            0|            0|  0.00%|    _identity_dispatcher
  2173|         0|            0|            0|  0.00%|)(identity)
  2174|         0|            0|            0|  0.00%|
  2175|         0|            0|            0|  0.00%|
  2176|         0|            0|            0|  0.00%|def _allclose_dispatcher(a, b, rtol=None, atol=None, equal_nan=None):
  2177|         0|            0|            0|  0.00%|    return (a, b)
  2178|         0|            0|            0|  0.00%|
  2179|         0|            0|            0|  0.00%|
  2180|         0|            0|            0|  0.00%|@array_function_dispatch(_allclose_dispatcher)
  2181|         0|            0|            0|  0.00%|def allclose(a, b, rtol=1.e-5, atol=1.e-8, equal_nan=False):
  2182|         0|            0|            0|  0.00%|    """
  2183|         0|            0|            0|  0.00%|    Returns True if two arrays are element-wise equal within a tolerance.
  2184|         0|            0|            0|  0.00%|
  2185|         0|            0|            0|  0.00%|    The tolerance values are positive, typically very small numbers.  The
  2186|         0|            0|            0|  0.00%|    relative difference (`rtol` * abs(`b`)) and the absolute difference
  2187|         0|            0|            0|  0.00%|    `atol` are added together to compare against the absolute difference
  2188|         0|            0|            0|  0.00%|    between `a` and `b`.
  2189|         0|            0|            0|  0.00%|
  2190|         0|            0|            0|  0.00%|    NaNs are treated as equal if they are in the same place and if
  2191|         0|            0|            0|  0.00%|    ``equal_nan=True``.  Infs are treated as equal if they are in the same
  2192|         0|            0|            0|  0.00%|    place and of the same sign in both arrays.
  2193|         0|            0|            0|  0.00%|
  2194|         0|            0|            0|  0.00%|    Parameters
  2195|         0|            0|            0|  0.00%|    ----------
  2196|         0|            0|            0|  0.00%|    a, b : array_like
  2197|         0|            0|            0|  0.00%|        Input arrays to compare.
  2198|         0|            0|            0|  0.00%|    rtol : float
  2199|         0|            0|            0|  0.00%|        The relative tolerance parameter (see Notes).
  2200|         0|            0|            0|  0.00%|    atol : float
  2201|         0|            0|            0|  0.00%|        The absolute tolerance parameter (see Notes).
  2202|         0|            0|            0|  0.00%|    equal_nan : bool
  2203|         0|            0|            0|  0.00%|        Whether to compare NaN's as equal.  If True, NaN's in `a` will be
  2204|         0|            0|            0|  0.00%|        considered equal to NaN's in `b` in the output array.
  2205|         0|            0|            0|  0.00%|
  2206|         0|            0|            0|  0.00%|        .. versionadded:: 1.10.0
  2207|         0|            0|            0|  0.00%|
  2208|         0|            0|            0|  0.00%|    Returns
  2209|         0|            0|            0|  0.00%|    -------
  2210|         0|            0|            0|  0.00%|    allclose : bool
  2211|         0|            0|            0|  0.00%|        Returns True if the two arrays are equal within the given
  2212|         0|            0|            0|  0.00%|        tolerance; False otherwise.
  2213|         0|            0|            0|  0.00%|
  2214|         0|            0|            0|  0.00%|    See Also
  2215|         0|            0|            0|  0.00%|    --------
  2216|         0|            0|            0|  0.00%|    isclose, all, any, equal
  2217|         0|            0|            0|  0.00%|
  2218|         0|            0|            0|  0.00%|    Notes
  2219|         0|            0|            0|  0.00%|    -----
  2220|         0|            0|            0|  0.00%|    If the following equation is element-wise True, then allclose returns
  2221|         0|            0|            0|  0.00%|    True.
  2222|         0|            0|            0|  0.00%|
  2223|         0|            0|            0|  0.00%|     absolute(`a` - `b`) <= (`atol` + `rtol` * absolute(`b`))
  2224|         0|            0|            0|  0.00%|
  2225|         0|            0|            0|  0.00%|    The above equation is not symmetric in `a` and `b`, so that
  2226|         0|            0|            0|  0.00%|    ``allclose(a, b)`` might be different from ``allclose(b, a)`` in
  2227|         0|            0|            0|  0.00%|    some rare cases.
  2228|         0|            0|            0|  0.00%|
  2229|         0|            0|            0|  0.00%|    The comparison of `a` and `b` uses standard broadcasting, which
  2230|         0|            0|            0|  0.00%|    means that `a` and `b` need not have the same shape in order for
  2231|         0|            0|            0|  0.00%|    ``allclose(a, b)`` to evaluate to True.  The same is true for
  2232|         0|            0|            0|  0.00%|    `equal` but not `array_equal`.
  2233|         0|            0|            0|  0.00%|
  2234|         0|            0|            0|  0.00%|    `allclose` is not defined for non-numeric data types.
  2235|         0|            0|            0|  0.00%|    `bool` is considered a numeric data-type for this purpose.
  2236|         0|            0|            0|  0.00%|
  2237|         0|            0|            0|  0.00%|    Examples
  2238|         0|            0|            0|  0.00%|    --------
  2239|         0|            0|            0|  0.00%|    >>> np.allclose([1e10,1e-7], [1.00001e10,1e-8])
  2240|         0|            0|            0|  0.00%|    False
  2241|         0|            0|            0|  0.00%|    >>> np.allclose([1e10,1e-8], [1.00001e10,1e-9])
  2242|         0|            0|            0|  0.00%|    True
  2243|         0|            0|            0|  0.00%|    >>> np.allclose([1e10,1e-8], [1.0001e10,1e-9])
  2244|         0|            0|            0|  0.00%|    False
  2245|         0|            0|            0|  0.00%|    >>> np.allclose([1.0, np.nan], [1.0, np.nan])
  2246|         0|            0|            0|  0.00%|    False
  2247|         0|            0|            0|  0.00%|    >>> np.allclose([1.0, np.nan], [1.0, np.nan], equal_nan=True)
  2248|         0|            0|            0|  0.00%|    True
  2249|         0|            0|            0|  0.00%|
  2250|         0|            0|            0|  0.00%|    """
  2251|         0|            0|            0|  0.00%|    res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan))
  2252|         0|            0|            0|  0.00%|    return bool(res)
  2253|         0|            0|            0|  0.00%|
  2254|         0|            0|            0|  0.00%|
  2255|         0|            0|            0|  0.00%|def _isclose_dispatcher(a, b, rtol=None, atol=None, equal_nan=None):
  2256|         0|            0|            0|  0.00%|    return (a, b)
  2257|         0|            0|            0|  0.00%|
  2258|         0|            0|            0|  0.00%|
  2259|         0|            0|            0|  0.00%|@array_function_dispatch(_isclose_dispatcher)
  2260|         0|            0|            0|  0.00%|def isclose(a, b, rtol=1.e-5, atol=1.e-8, equal_nan=False):
  2261|         0|            0|            0|  0.00%|    """
  2262|         0|            0|            0|  0.00%|    Returns a boolean array where two arrays are element-wise equal within a
  2263|         0|            0|            0|  0.00%|    tolerance.
  2264|         0|            0|            0|  0.00%|
  2265|         0|            0|            0|  0.00%|    The tolerance values are positive, typically very small numbers.  The
  2266|         0|            0|            0|  0.00%|    relative difference (`rtol` * abs(`b`)) and the absolute difference
  2267|         0|            0|            0|  0.00%|    `atol` are added together to compare against the absolute difference
  2268|         0|            0|            0|  0.00%|    between `a` and `b`.
  2269|         0|            0|            0|  0.00%|
  2270|         0|            0|            0|  0.00%|    .. warning:: The default `atol` is not appropriate for comparing numbers
  2271|         0|            0|            0|  0.00%|                 that are much smaller than one (see Notes).
  2272|         0|            0|            0|  0.00%|
  2273|         0|            0|            0|  0.00%|    Parameters
  2274|         0|            0|            0|  0.00%|    ----------
  2275|         0|            0|            0|  0.00%|    a, b : array_like
  2276|         0|            0|            0|  0.00%|        Input arrays to compare.
  2277|         0|            0|            0|  0.00%|    rtol : float
  2278|         0|            0|            0|  0.00%|        The relative tolerance parameter (see Notes).
  2279|         0|            0|            0|  0.00%|    atol : float
  2280|         0|            0|            0|  0.00%|        The absolute tolerance parameter (see Notes).
  2281|         0|            0|            0|  0.00%|    equal_nan : bool
  2282|         0|            0|            0|  0.00%|        Whether to compare NaN's as equal.  If True, NaN's in `a` will be
  2283|         0|            0|            0|  0.00%|        considered equal to NaN's in `b` in the output array.
  2284|         0|            0|            0|  0.00%|
  2285|         0|            0|            0|  0.00%|    Returns
  2286|         0|            0|            0|  0.00%|    -------
  2287|         0|            0|            0|  0.00%|    y : array_like
  2288|         0|            0|            0|  0.00%|        Returns a boolean array of where `a` and `b` are equal within the
  2289|         0|            0|            0|  0.00%|        given tolerance. If both `a` and `b` are scalars, returns a single
  2290|         0|            0|            0|  0.00%|        boolean value.
  2291|         0|            0|            0|  0.00%|
  2292|         0|            0|            0|  0.00%|    See Also
  2293|         0|            0|            0|  0.00%|    --------
  2294|         0|            0|            0|  0.00%|    allclose
  2295|         0|            0|            0|  0.00%|    math.isclose
  2296|         0|            0|            0|  0.00%|
  2297|         0|            0|            0|  0.00%|    Notes
  2298|         0|            0|            0|  0.00%|    -----
  2299|         0|            0|            0|  0.00%|    .. versionadded:: 1.7.0
  2300|         0|            0|            0|  0.00%|
  2301|         0|            0|            0|  0.00%|    For finite values, isclose uses the following equation to test whether
  2302|         0|            0|            0|  0.00%|    two floating point values are equivalent.
  2303|         0|            0|            0|  0.00%|
  2304|         0|            0|            0|  0.00%|     absolute(`a` - `b`) <= (`atol` + `rtol` * absolute(`b`))
  2305|         0|            0|            0|  0.00%|
  2306|         0|            0|            0|  0.00%|    Unlike the built-in `math.isclose`, the above equation is not symmetric
  2307|         0|            0|            0|  0.00%|    in `a` and `b` -- it assumes `b` is the reference value -- so that
  2308|         0|            0|            0|  0.00%|    `isclose(a, b)` might be different from `isclose(b, a)`. Furthermore,
  2309|         0|            0|            0|  0.00%|    the default value of atol is not zero, and is used to determine what
  2310|         0|            0|            0|  0.00%|    small values should be considered close to zero. The default value is
  2311|         0|            0|            0|  0.00%|    appropriate for expected values of order unity: if the expected values
  2312|         0|            0|            0|  0.00%|    are significantly smaller than one, it can result in false positives.
  2313|         0|            0|            0|  0.00%|    `atol` should be carefully selected for the use case at hand. A zero value
  2314|         0|            0|            0|  0.00%|    for `atol` will result in `False` if either `a` or `b` is zero.
  2315|         0|            0|            0|  0.00%|
  2316|         0|            0|            0|  0.00%|    `isclose` is not defined for non-numeric data types.
  2317|         0|            0|            0|  0.00%|    `bool` is considered a numeric data-type for this purpose.
  2318|         0|            0|            0|  0.00%|
  2319|         0|            0|            0|  0.00%|    Examples
  2320|         0|            0|            0|  0.00%|    --------
  2321|         0|            0|            0|  0.00%|    >>> np.isclose([1e10,1e-7], [1.00001e10,1e-8])
  2322|         0|            0|            0|  0.00%|    array([ True, False])
  2323|         0|            0|            0|  0.00%|    >>> np.isclose([1e10,1e-8], [1.00001e10,1e-9])
  2324|         0|            0|            0|  0.00%|    array([ True, True])
  2325|         0|            0|            0|  0.00%|    >>> np.isclose([1e10,1e-8], [1.0001e10,1e-9])
  2326|         0|            0|            0|  0.00%|    array([False,  True])
  2327|         0|            0|            0|  0.00%|    >>> np.isclose([1.0, np.nan], [1.0, np.nan])
  2328|         0|            0|            0|  0.00%|    array([ True, False])
  2329|         0|            0|            0|  0.00%|    >>> np.isclose([1.0, np.nan], [1.0, np.nan], equal_nan=True)
  2330|         0|            0|            0|  0.00%|    array([ True, True])
  2331|         0|            0|            0|  0.00%|    >>> np.isclose([1e-8, 1e-7], [0.0, 0.0])
  2332|         0|            0|            0|  0.00%|    array([ True, False])
  2333|         0|            0|            0|  0.00%|    >>> np.isclose([1e-100, 1e-7], [0.0, 0.0], atol=0.0)
  2334|         0|            0|            0|  0.00%|    array([False, False])
  2335|         0|            0|            0|  0.00%|    >>> np.isclose([1e-10, 1e-10], [1e-20, 0.0])
  2336|         0|            0|            0|  0.00%|    array([ True,  True])
  2337|         0|            0|            0|  0.00%|    >>> np.isclose([1e-10, 1e-10], [1e-20, 0.999999e-10], atol=0.0)
  2338|         0|            0|            0|  0.00%|    array([False,  True])
  2339|         0|            0|            0|  0.00%|    """
  2340|         0|            0|            0|  0.00%|    def within_tol(x, y, atol, rtol):
  2341|         0|            0|            0|  0.00%|        with errstate(invalid='ignore'):
  2342|         0|            0|            0|  0.00%|            return less_equal(abs(x-y), atol + rtol * abs(y))
  2343|         0|            0|            0|  0.00%|
  2344|         0|            0|            0|  0.00%|    x = asanyarray(a)
  2345|         0|            0|            0|  0.00%|    y = asanyarray(b)
  2346|         0|            0|            0|  0.00%|
  2347|         0|            0|            0|  0.00%|    # Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).
  2348|         0|            0|            0|  0.00%|    # This will cause casting of x later. Also, make sure to allow subclasses
  2349|         0|            0|            0|  0.00%|    # (e.g., for numpy.ma).
  2350|         0|            0|            0|  0.00%|    # NOTE: We explicitly allow timedelta, which used to work. This could
  2351|         0|            0|            0|  0.00%|    #       possibly be deprecated. See also gh-18286.
  2352|         0|            0|            0|  0.00%|    #       timedelta works if `atol` is an integer or also a timedelta.
  2353|         0|            0|            0|  0.00%|    #       Although, the default tolerances are unlikely to be useful
  2354|         0|            0|            0|  0.00%|    if y.dtype.kind != "m":
  2355|         0|            0|            0|  0.00%|        dt = multiarray.result_type(y, 1.)
  2356|         0|            0|            0|  0.00%|        y = asanyarray(y, dtype=dt)
  2357|         0|            0|            0|  0.00%|
  2358|         0|            0|            0|  0.00%|    xfin = isfinite(x)
  2359|         0|            0|            0|  0.00%|    yfin = isfinite(y)
  2360|         0|            0|            0|  0.00%|    if all(xfin) and all(yfin):
  2361|         0|            0|            0|  0.00%|        return within_tol(x, y, atol, rtol)
  2362|         0|            0|            0|  0.00%|    else:
  2363|         0|            0|            0|  0.00%|        finite = xfin & yfin
  2364|         0|            0|            0|  0.00%|        cond = zeros_like(finite, subok=True)
  2365|         0|            0|            0|  0.00%|        # Because we're using boolean indexing, x & y must be the same shape.
  2366|         0|            0|            0|  0.00%|        # Ideally, we'd just do x, y = broadcast_arrays(x, y). It's in
  2367|         0|            0|            0|  0.00%|        # lib.stride_tricks, though, so we can't import it here.
  2368|         0|            0|            0|  0.00%|        x = x * ones_like(cond)
  2369|         0|            0|            0|  0.00%|        y = y * ones_like(cond)
  2370|         0|            0|            0|  0.00%|        # Avoid subtraction with infinite/nan values...
  2371|         0|            0|            0|  0.00%|        cond[finite] = within_tol(x[finite], y[finite], atol, rtol)
  2372|         0|            0|            0|  0.00%|        # Check for equality of infinite values...
  2373|         0|            0|            0|  0.00%|        cond[~finite] = (x[~finite] == y[~finite])
  2374|         0|            0|            0|  0.00%|        if equal_nan:
  2375|         0|            0|            0|  0.00%|            # Make NaN == NaN
  2376|         0|            0|            0|  0.00%|            both_nan = isnan(x) & isnan(y)
  2377|         0|            0|            0|  0.00%|
  2378|         0|            0|            0|  0.00%|            # Needed to treat masked arrays correctly. = True would not work.
  2379|         0|            0|            0|  0.00%|            cond[both_nan] = both_nan[both_nan]
  2380|         0|            0|            0|  0.00%|
  2381|         0|            0|            0|  0.00%|        return cond[()]  # Flatten 0d arrays to scalars
  2382|         0|            0|            0|  0.00%|
  2383|         0|            0|            0|  0.00%|
  2384|         0|            0|            0|  0.00%|def _array_equal_dispatcher(a1, a2, equal_nan=None):
  2385|         0|            0|            0|  0.00%|    return (a1, a2)
  2386|         0|            0|            0|  0.00%|
  2387|         0|            0|            0|  0.00%|
  2388|         0|            0|            0|  0.00%|@array_function_dispatch(_array_equal_dispatcher)
  2389|         0|            0|            0|  0.00%|def array_equal(a1, a2, equal_nan=False):
  2390|         0|            0|            0|  0.00%|    """
  2391|         0|            0|            0|  0.00%|    True if two arrays have the same shape and elements, False otherwise.
  2392|         0|            0|            0|  0.00%|
  2393|         0|            0|            0|  0.00%|    Parameters
  2394|         0|            0|            0|  0.00%|    ----------
  2395|         0|            0|            0|  0.00%|    a1, a2 : array_like
  2396|         0|            0|            0|  0.00%|        Input arrays.
  2397|         0|            0|            0|  0.00%|    equal_nan : bool
  2398|         0|            0|            0|  0.00%|        Whether to compare NaN's as equal. If the dtype of a1 and a2 is
  2399|         0|            0|            0|  0.00%|        complex, values will be considered equal if either the real or the
  2400|         0|            0|            0|  0.00%|        imaginary component of a given value is ``nan``.
  2401|         0|            0|            0|  0.00%|
  2402|         0|            0|            0|  0.00%|        .. versionadded:: 1.19.0
  2403|         0|            0|            0|  0.00%|
  2404|         0|            0|            0|  0.00%|    Returns
  2405|         0|            0|            0|  0.00%|    -------
  2406|         0|            0|            0|  0.00%|    b : bool
  2407|         0|            0|            0|  0.00%|        Returns True if the arrays are equal.
  2408|         0|            0|            0|  0.00%|
  2409|         0|            0|            0|  0.00%|    See Also
  2410|         0|            0|            0|  0.00%|    --------
  2411|         0|            0|            0|  0.00%|    allclose: Returns True if two arrays are element-wise equal within a
  2412|         0|            0|            0|  0.00%|              tolerance.
  2413|         0|            0|            0|  0.00%|    array_equiv: Returns True if input arrays are shape consistent and all
  2414|         0|            0|            0|  0.00%|                 elements equal.
  2415|         0|            0|            0|  0.00%|
  2416|         0|            0|            0|  0.00%|    Examples
  2417|         0|            0|            0|  0.00%|    --------
  2418|         0|            0|            0|  0.00%|    >>> np.array_equal([1, 2], [1, 2])
  2419|         0|            0|            0|  0.00%|    True
  2420|         0|            0|            0|  0.00%|    >>> np.array_equal(np.array([1, 2]), np.array([1, 2]))
  2421|         0|            0|            0|  0.00%|    True
  2422|         0|            0|            0|  0.00%|    >>> np.array_equal([1, 2], [1, 2, 3])
  2423|         0|            0|            0|  0.00%|    False
  2424|         0|            0|            0|  0.00%|    >>> np.array_equal([1, 2], [1, 4])
  2425|         0|            0|            0|  0.00%|    False
  2426|         0|            0|            0|  0.00%|    >>> a = np.array([1, np.nan])
  2427|         0|            0|            0|  0.00%|    >>> np.array_equal(a, a)
  2428|         0|            0|            0|  0.00%|    False
  2429|         0|            0|            0|  0.00%|    >>> np.array_equal(a, a, equal_nan=True)
  2430|         0|            0|            0|  0.00%|    True
  2431|         0|            0|            0|  0.00%|
  2432|         0|            0|            0|  0.00%|    When ``equal_nan`` is True, complex values with nan components are
  2433|         0|            0|            0|  0.00%|    considered equal if either the real *or* the imaginary components are nan.
  2434|         0|            0|            0|  0.00%|
  2435|         0|            0|            0|  0.00%|    >>> a = np.array([1 + 1j])
  2436|         0|            0|            0|  0.00%|    >>> b = a.copy()
  2437|         0|            0|            0|  0.00%|    >>> a.real = np.nan
  2438|         0|            0|            0|  0.00%|    >>> b.imag = np.nan
  2439|         0|            0|            0|  0.00%|    >>> np.array_equal(a, b, equal_nan=True)
  2440|         0|            0|            0|  0.00%|    True
  2441|         0|            0|            0|  0.00%|    """
  2442|         0|            0|            0|  0.00%|    try:
  2443|         0|            0|            0|  0.00%|        a1, a2 = asarray(a1), asarray(a2)
  2444|         0|            0|            0|  0.00%|    except Exception:
  2445|         0|            0|            0|  0.00%|        return False
  2446|         0|            0|            0|  0.00%|    if a1.shape != a2.shape:
  2447|         0|            0|            0|  0.00%|        return False
  2448|         0|            0|            0|  0.00%|    if not equal_nan:
  2449|         0|            0|            0|  0.00%|        return bool(asarray(a1 == a2).all())
  2450|         0|            0|            0|  0.00%|    # Handling NaN values if equal_nan is True
  2451|         0|            0|            0|  0.00%|    a1nan, a2nan = isnan(a1), isnan(a2)
  2452|         0|            0|            0|  0.00%|    # NaN's occur at different locations
  2453|         0|            0|            0|  0.00%|    if not (a1nan == a2nan).all():
  2454|         0|            0|            0|  0.00%|        return False
  2455|         0|            0|            0|  0.00%|    # Shapes of a1, a2 and masks are guaranteed to be consistent by this point
  2456|         0|            0|            0|  0.00%|    return bool(asarray(a1[~a1nan] == a2[~a1nan]).all())
  2457|         0|            0|            0|  0.00%|
  2458|         0|            0|            0|  0.00%|
  2459|         0|            0|            0|  0.00%|def _array_equiv_dispatcher(a1, a2):
  2460|         0|            0|            0|  0.00%|    return (a1, a2)
  2461|         0|            0|            0|  0.00%|
  2462|         0|            0|            0|  0.00%|
  2463|         0|            0|            0|  0.00%|@array_function_dispatch(_array_equiv_dispatcher)
  2464|         0|            0|            0|  0.00%|def array_equiv(a1, a2):
  2465|         0|            0|            0|  0.00%|    """
  2466|         0|            0|            0|  0.00%|    Returns True if input arrays are shape consistent and all elements equal.
  2467|         0|            0|            0|  0.00%|
  2468|         0|            0|            0|  0.00%|    Shape consistent means they are either the same shape, or one input array
  2469|         0|            0|            0|  0.00%|    can be broadcasted to create the same shape as the other one.
  2470|         0|            0|            0|  0.00%|
  2471|         0|            0|            0|  0.00%|    Parameters
  2472|         0|            0|            0|  0.00%|    ----------
  2473|         0|            0|            0|  0.00%|    a1, a2 : array_like
  2474|         0|            0|            0|  0.00%|        Input arrays.
  2475|         0|            0|            0|  0.00%|
  2476|         0|            0|            0|  0.00%|    Returns
  2477|         0|            0|            0|  0.00%|    -------
  2478|         0|            0|            0|  0.00%|    out : bool
  2479|         0|            0|            0|  0.00%|        True if equivalent, False otherwise.
  2480|         0|            0|            0|  0.00%|
  2481|         0|            0|            0|  0.00%|    Examples
  2482|         0|            0|            0|  0.00%|    --------
  2483|         0|            0|            0|  0.00%|    >>> np.array_equiv([1, 2], [1, 2])
  2484|         0|            0|            0|  0.00%|    True
  2485|         0|            0|            0|  0.00%|    >>> np.array_equiv([1, 2], [1, 3])
  2486|         0|            0|            0|  0.00%|    False
  2487|         0|            0|            0|  0.00%|
  2488|         0|            0|            0|  0.00%|    Showing the shape equivalence:
  2489|         0|            0|            0|  0.00%|
  2490|         0|            0|            0|  0.00%|    >>> np.array_equiv([1, 2], [[1, 2], [1, 2]])
  2491|         0|            0|            0|  0.00%|    True
  2492|         0|            0|            0|  0.00%|    >>> np.array_equiv([1, 2], [[1, 2, 1, 2], [1, 2, 1, 2]])
  2493|         0|            0|            0|  0.00%|    False
  2494|         0|            0|            0|  0.00%|
  2495|         0|            0|            0|  0.00%|    >>> np.array_equiv([1, 2], [[1, 2], [1, 3]])
  2496|         0|            0|            0|  0.00%|    False
  2497|         0|            0|            0|  0.00%|
  2498|         0|            0|            0|  0.00%|    """
  2499|         0|            0|            0|  0.00%|    try:
  2500|         0|            0|            0|  0.00%|        a1, a2 = asarray(a1), asarray(a2)
  2501|         0|            0|            0|  0.00%|    except Exception:
  2502|         0|            0|            0|  0.00%|        return False
  2503|         0|            0|            0|  0.00%|    try:
  2504|         0|            0|            0|  0.00%|        multiarray.broadcast(a1, a2)
  2505|         0|            0|            0|  0.00%|    except Exception:
  2506|         0|            0|            0|  0.00%|        return False
  2507|         0|            0|            0|  0.00%|
  2508|         0|            0|            0|  0.00%|    return bool(asarray(a1 == a2).all())
  2509|         0|            0|            0|  0.00%|
  2510|         0|            0|            0|  0.00%|
  2511|         0|            0|            0|  0.00%|Inf = inf = infty = Infinity = PINF
  2512|         0|            0|            0|  0.00%|nan = NaN = NAN
  2513|         0|            0|            0|  0.00%|False_ = bool_(False)
  2514|         0|            0|            0|  0.00%|True_ = bool_(True)
  2515|         0|            0|            0|  0.00%|
  2516|         0|            0|            0|  0.00%|
  2517|         0|            0|            0|  0.00%|def extend_all(module):
  2518|         0|            0|            0|  0.00%|    existing = set(__all__)
  2519|         0|            0|            0|  0.00%|    mall = getattr(module, '__all__')
  2520|         0|            0|            0|  0.00%|    for a in mall:
  2521|         0|            0|            0|  0.00%|        if a not in existing:
  2522|         0|            0|            0|  0.00%|            __all__.append(a)
  2523|         0|            0|            0|  0.00%|
  2524|         0|            0|            0|  0.00%|
  2525|         0|            0|            0|  0.00%|from .umath import *
  2526|         0|            0|            0|  0.00%|from .numerictypes import *
  2527|         0|            0|            0|  0.00%|from . import fromnumeric
  2528|         0|            0|            0|  0.00%|from .fromnumeric import *
  2529|         0|            0|            0|  0.00%|from . import arrayprint
  2530|         0|            0|            0|  0.00%|from .arrayprint import *
  2531|         0|            0|            0|  0.00%|from . import _asarray
  2532|         0|            0|            0|  0.00%|from ._asarray import *
  2533|         0|            0|            0|  0.00%|from . import _ufunc_config
  2534|         0|            0|            0|  0.00%|from ._ufunc_config import *
  2535|         0|            0|            0|  0.00%|extend_all(fromnumeric)
  2536|         0|            0|            0|  0.00%|extend_all(umath)
  2537|         0|            0|            0|  0.00%|extend_all(numerictypes)
  2538|         0|            0|            0|  0.00%|extend_all(arrayprint)
  2539|         0|            0|            0|  0.00%|extend_all(_asarray)
  2540|         0|            0|            0|  0.00%|extend_all(_ufunc_config)
File: <string>
File duration: 0.297714s (0.29%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|    113306|     0.297714|  2.62752e-06|  0.29%|
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/functional.py
File duration: 0.226018s (0.22%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|from typing import (
     2|         0|            0|            0|  0.00%|    List, Tuple, Optional, Union, Any, Sequence, TYPE_CHECKING
     3|         0|            0|            0|  0.00%|)
     4|         0|            0|            0|  0.00%|
     5|         0|            0|            0|  0.00%|import torch
     6|         0|            0|            0|  0.00%|from torch._C import _add_docstr
     7|         0|            0|            0|  0.00%|import torch.nn.functional as F
     8|         0|            0|            0|  0.00%|from ._lowrank import svd_lowrank, pca_lowrank
     9|         0|            0|            0|  0.00%|from .overrides import (
    10|         0|            0|            0|  0.00%|    has_torch_function, has_torch_function_unary, has_torch_function_variadic,
    11|         0|            0|            0|  0.00%|    handle_torch_function)
    12|         0|            0|            0|  0.00%|from ._jit_internal import boolean_dispatch
    13|         0|            0|            0|  0.00%|from ._jit_internal import _overload as overload
    14|         0|            0|            0|  0.00%|
    15|         0|            0|            0|  0.00%|Tensor = torch.Tensor
    16|         0|            0|            0|  0.00%|from torch import _VF
    17|         0|            0|            0|  0.00%|
    18|         0|            0|            0|  0.00%|__all__ = [
    19|         0|            0|            0|  0.00%|    'atleast_1d',
    20|         0|            0|            0|  0.00%|    'atleast_2d',
    21|         0|            0|            0|  0.00%|    'atleast_3d',
    22|         0|            0|            0|  0.00%|    'align_tensors',
    23|         0|            0|            0|  0.00%|    'broadcast_shapes',
    24|         0|            0|            0|  0.00%|    'broadcast_tensors',
    25|         0|            0|            0|  0.00%|    'cartesian_prod',
    26|         0|            0|            0|  0.00%|    'block_diag',
    27|         0|            0|            0|  0.00%|    'cdist',
    28|         0|            0|            0|  0.00%|    'chain_matmul',
    29|         0|            0|            0|  0.00%|    'einsum',
    30|         0|            0|            0|  0.00%|    'istft',
    31|         0|            0|            0|  0.00%|    'lu',
    32|         0|            0|            0|  0.00%|    'norm',
    33|         0|            0|            0|  0.00%|    'meshgrid',
    34|         0|            0|            0|  0.00%|    'pca_lowrank',
    35|         0|            0|            0|  0.00%|    'split',
    36|         0|            0|            0|  0.00%|    'stft',
    37|         0|            0|            0|  0.00%|    'svd_lowrank',
    38|         0|            0|            0|  0.00%|    'tensordot',
    39|         0|            0|            0|  0.00%|    'unique',
    40|         0|            0|            0|  0.00%|    'unique_consecutive',
    41|         0|            0|            0|  0.00%|]
    42|         0|            0|            0|  0.00%|
    43|         0|            0|            0|  0.00%|
    44|      2610|   0.00578618|  2.21693e-06|  0.01%|def broadcast_tensors(*tensors):
    45|         0|            0|            0|  0.00%|    r"""broadcast_tensors(*tensors) -> List of Tensors
    46|         0|            0|            0|  0.00%|
    47|         0|            0|            0|  0.00%|    Broadcasts the given tensors according to :ref:`broadcasting-semantics`.
    48|         0|            0|            0|  0.00%|
    49|         0|            0|            0|  0.00%|    Args:
    50|         0|            0|            0|  0.00%|        *tensors: any number of tensors of the same type
    51|         0|            0|            0|  0.00%|
    52|         0|            0|            0|  0.00%|    .. warning::
    53|         0|            0|            0|  0.00%|
    54|         0|            0|            0|  0.00%|        More than one element of a broadcasted tensor may refer to a single
    55|         0|            0|            0|  0.00%|        memory location. As a result, in-place operations (especially ones that
    56|         0|            0|            0|  0.00%|        are vectorized) may result in incorrect behavior. If you need to write
    57|         0|            0|            0|  0.00%|        to the tensors, please clone them first.
    58|         0|            0|            0|  0.00%|
    59|         0|            0|            0|  0.00%|    Example::
    60|         0|            0|            0|  0.00%|
    61|         0|            0|            0|  0.00%|        >>> x = torch.arange(3).view(1, 3)
    62|         0|            0|            0|  0.00%|        >>> y = torch.arange(2).view(2, 1)
    63|         0|            0|            0|  0.00%|        >>> a, b = torch.broadcast_tensors(x, y)
    64|         0|            0|            0|  0.00%|        >>> a.size()
    65|         0|            0|            0|  0.00%|        torch.Size([2, 3])
    66|         0|            0|            0|  0.00%|        >>> a
    67|         0|            0|            0|  0.00%|        tensor([[0, 1, 2],
    68|         0|            0|            0|  0.00%|                [0, 1, 2]])
    69|         0|            0|            0|  0.00%|    """
    70|         0|            0|            0|  0.00%|    # This wrapper exists to support variadic args.
    71|      2610|   0.00716496|  2.74519e-06|  0.01%|    if has_torch_function(tensors):
    72|         0|            0|            0|  0.00%|        return handle_torch_function(broadcast_tensors, tensors, *tensors)
    73|      2610|    0.0551171|  2.11177e-05|  0.05%|    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]
(call)|      2610|    0.0141406|  5.41786e-06|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_VF.py:25 __getattr__
    74|         0|            0|            0|  0.00%|
    75|         0|            0|            0|  0.00%|
    76|         0|            0|            0|  0.00%|def broadcast_shapes(*shapes):
    77|         0|            0|            0|  0.00%|    r"""broadcast_shapes(*shapes) -> Size
    78|         0|            0|            0|  0.00%|
    79|         0|            0|            0|  0.00%|    Similar to :func:`broadcast_tensors` but for shapes.
    80|         0|            0|            0|  0.00%|
    81|         0|            0|            0|  0.00%|    This is equivalent to
    82|         0|            0|            0|  0.00%|    ``torch.broadcast_tensors(*map(torch.empty, shapes))[0].shape``
    83|         0|            0|            0|  0.00%|    but avoids the need create to intermediate tensors. This is useful for
    84|         0|            0|            0|  0.00%|    broadcasting tensors of common batch shape but different rightmost shape,
    85|         0|            0|            0|  0.00%|    e.g. to broadcast mean vectors with covariance matrices.
    86|         0|            0|            0|  0.00%|
    87|         0|            0|            0|  0.00%|    Example::
    88|         0|            0|            0|  0.00%|
    89|         0|            0|            0|  0.00%|        >>> torch.broadcast_shapes((2,), (3, 1), (1, 1, 1))
    90|         0|            0|            0|  0.00%|        torch.Size([1, 3, 2])
    91|         0|            0|            0|  0.00%|
    92|         0|            0|            0|  0.00%|    Args:
    93|         0|            0|            0|  0.00%|        \*shapes (torch.Size): Shapes of tensors.
    94|         0|            0|            0|  0.00%|
    95|         0|            0|            0|  0.00%|    Returns:
    96|         0|            0|            0|  0.00%|        shape (torch.Size): A shape compatible with all input shapes.
    97|         0|            0|            0|  0.00%|
    98|         0|            0|            0|  0.00%|    Raises:
    99|         0|            0|            0|  0.00%|        RuntimeError: If shapes are incompatible.
   100|         0|            0|            0|  0.00%|    """
   101|         0|            0|            0|  0.00%|    # This wrapper exists to support variadic args.
   102|         0|            0|            0|  0.00%|    # TODO Move this to C++ once the jit has better support for torch.Size.
   103|         0|            0|            0|  0.00%|    if not torch.jit.is_tracing():
   104|         0|            0|            0|  0.00%|        max_len = 0
   105|         0|            0|            0|  0.00%|        for shape in shapes:
   106|         0|            0|            0|  0.00%|            if isinstance(shape, int):
   107|         0|            0|            0|  0.00%|                if max_len < 1:
   108|         0|            0|            0|  0.00%|                    max_len = 1
   109|         0|            0|            0|  0.00%|            elif isinstance(shape, tuple) or isinstance(shape, list):
   110|         0|            0|            0|  0.00%|                s = len(shape)
   111|         0|            0|            0|  0.00%|                if max_len < s:
   112|         0|            0|            0|  0.00%|                    max_len = s
   113|         0|            0|            0|  0.00%|        result = [1] * max_len
   114|         0|            0|            0|  0.00%|        for shape in shapes:
   115|         0|            0|            0|  0.00%|            if isinstance(shape, int):
   116|         0|            0|            0|  0.00%|                shape = (shape,)
   117|         0|            0|            0|  0.00%|            if isinstance(shape, tuple) or isinstance(shape, list):
   118|         0|            0|            0|  0.00%|                for i in range(-1, -1 - len(shape), -1):
   119|         0|            0|            0|  0.00%|                    if shape[i] < 0:
   120|         0|            0|            0|  0.00%|                        raise RuntimeError("Trying to create tensor with negative dimension ({}): ({})"
   121|         0|            0|            0|  0.00%|                                           .format(shape[i], shape[i]))
   122|         0|            0|            0|  0.00%|                    if shape[i] == 1 or shape[i] == result[i]:
   123|         0|            0|            0|  0.00%|                        continue
   124|         0|            0|            0|  0.00%|                    if result[i] != 1:
   125|         0|            0|            0|  0.00%|                        raise RuntimeError("Shape mismatch: objects cannot be broadcast to a single shape")
   126|         0|            0|            0|  0.00%|                    result[i] = shape[i]
   127|         0|            0|            0|  0.00%|            else:
   128|         0|            0|            0|  0.00%|                raise RuntimeError("Input shapes should be of type ints, a tuple of ints, or a list of ints, got ", shape)
   129|         0|            0|            0|  0.00%|        return torch.Size(result)
   130|         0|            0|            0|  0.00%|    else:
   131|         0|            0|            0|  0.00%|        # with implementation above, torch.jit.trace hardcodes the sizes which makes subsequent replays fail
   132|         0|            0|            0|  0.00%|        with torch.no_grad():
   133|         0|            0|            0|  0.00%|            scalar = torch.zeros((), device="cpu")
   134|         0|            0|            0|  0.00%|            tensors = [scalar.expand(shape) for shape in shapes]
   135|         0|            0|            0|  0.00%|            tensors = broadcast_tensors(*tensors)
   136|         0|            0|            0|  0.00%|            return tensors[0].shape
   137|         0|            0|            0|  0.00%|
   138|         0|            0|            0|  0.00%|
   139|         0|            0|            0|  0.00%|
   140|         0|            0|            0|  0.00%|def split(
   141|         0|            0|            0|  0.00%|    tensor: Tensor, split_size_or_sections: Union[int, List[int]], dim: int = 0
   142|         0|            0|            0|  0.00%|) -> List[Tensor]:
   143|         0|            0|            0|  0.00%|    r"""Splits the tensor into chunks. Each chunk is a view of the original tensor.
   144|         0|            0|            0|  0.00%|
   145|         0|            0|            0|  0.00%|    If :attr:`split_size_or_sections` is an integer type, then :attr:`tensor` will
   146|         0|            0|            0|  0.00%|    be split into equally sized chunks (if possible). Last chunk will be smaller if
   147|         0|            0|            0|  0.00%|    the tensor size along the given dimension :attr:`dim` is not divisible by
   148|         0|            0|            0|  0.00%|    :attr:`split_size`.
   149|         0|            0|            0|  0.00%|
   150|         0|            0|            0|  0.00%|    If :attr:`split_size_or_sections` is a list, then :attr:`tensor` will be split
   151|         0|            0|            0|  0.00%|    into ``len(split_size_or_sections)`` chunks with sizes in :attr:`dim` according
   152|         0|            0|            0|  0.00%|    to :attr:`split_size_or_sections`.
   153|         0|            0|            0|  0.00%|
   154|         0|            0|            0|  0.00%|    Args:
   155|         0|            0|            0|  0.00%|        tensor (Tensor): tensor to split.
   156|         0|            0|            0|  0.00%|        split_size_or_sections (int) or (list(int)): size of a single chunk or
   157|         0|            0|            0|  0.00%|            list of sizes for each chunk
   158|         0|            0|            0|  0.00%|        dim (int): dimension along which to split the tensor.
   159|         0|            0|            0|  0.00%|
   160|         0|            0|            0|  0.00%|    Example::
   161|         0|            0|            0|  0.00%|
   162|         0|            0|            0|  0.00%|        >>> a = torch.arange(10).reshape(5,2)
   163|         0|            0|            0|  0.00%|        >>> a
   164|         0|            0|            0|  0.00%|        tensor([[0, 1],
   165|         0|            0|            0|  0.00%|                [2, 3],
   166|         0|            0|            0|  0.00%|                [4, 5],
   167|         0|            0|            0|  0.00%|                [6, 7],
   168|         0|            0|            0|  0.00%|                [8, 9]])
   169|         0|            0|            0|  0.00%|        >>> torch.split(a, 2)
   170|         0|            0|            0|  0.00%|        (tensor([[0, 1],
   171|         0|            0|            0|  0.00%|                 [2, 3]]),
   172|         0|            0|            0|  0.00%|         tensor([[4, 5],
   173|         0|            0|            0|  0.00%|                 [6, 7]]),
   174|         0|            0|            0|  0.00%|         tensor([[8, 9]]))
   175|         0|            0|            0|  0.00%|        >>> torch.split(a, [1,4])
   176|         0|            0|            0|  0.00%|        (tensor([[0, 1]]),
   177|         0|            0|            0|  0.00%|         tensor([[2, 3],
   178|         0|            0|            0|  0.00%|                 [4, 5],
   179|         0|            0|            0|  0.00%|                 [6, 7],
   180|         0|            0|            0|  0.00%|                 [8, 9]]))
   181|         0|            0|            0|  0.00%|    """
   182|         0|            0|            0|  0.00%|    if has_torch_function_unary(tensor):
   183|         0|            0|            0|  0.00%|        return handle_torch_function(
   184|         0|            0|            0|  0.00%|            split, (tensor,), tensor, split_size_or_sections, dim=dim)
   185|         0|            0|            0|  0.00%|    # Overwriting reason:
   186|         0|            0|            0|  0.00%|    # This dispatches to two ATen functions depending on the type of
   187|         0|            0|            0|  0.00%|    # split_size_or_sections. The branching code is in _tensor.py, which we
   188|         0|            0|            0|  0.00%|    # call here.
   189|         0|            0|            0|  0.00%|    return tensor.split(split_size_or_sections, dim)
   190|         0|            0|            0|  0.00%|
   191|         0|            0|            0|  0.00%|
   192|         0|            0|            0|  0.00%|def einsum(*args: Any) -> Tensor:
   193|         0|            0|            0|  0.00%|    r"""einsum(equation, *operands) -> Tensor
   194|         0|            0|            0|  0.00%|
   195|         0|            0|            0|  0.00%|    Sums the product of the elements of the input :attr:`operands` along dimensions specified using a notation
   196|         0|            0|            0|  0.00%|    based on the Einstein summation convention.
   197|         0|            0|            0|  0.00%|
   198|         0|            0|            0|  0.00%|    Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them
   199|         0|            0|            0|  0.00%|    in a short-hand format based on the Einstein summation convention, given by :attr:`equation`. The details of
   200|         0|            0|            0|  0.00%|    this format are described below, but the general idea is to label every dimension of the input :attr:`operands`
   201|         0|            0|            0|  0.00%|    with some subscript and define which subscripts are part of the output. The output is then computed by summing
   202|         0|            0|            0|  0.00%|    the product of the elements of the :attr:`operands` along the dimensions whose subscripts are not part of the
   203|         0|            0|            0|  0.00%|    output. For example, matrix multiplication can be computed using einsum as `torch.einsum("ij,jk->ik", A, B)`.
   204|         0|            0|            0|  0.00%|    Here, j is the summation subscript and i and k the output subscripts (see section below for more details on why).
   205|         0|            0|            0|  0.00%|
   206|         0|            0|            0|  0.00%|    Equation:
   207|         0|            0|            0|  0.00%|
   208|         0|            0|            0|  0.00%|        The :attr:`equation` string specifies the subscripts (letters in `[a-zA-Z]`) for each dimension of
   209|         0|            0|            0|  0.00%|        the input :attr:`operands` in the same order as the dimensions, separating subcripts for each operand by a
   210|         0|            0|            0|  0.00%|        comma (','), e.g. `'ij,jk'` specify subscripts for two 2D operands. The dimensions labeled with the same subscript
   211|         0|            0|            0|  0.00%|        must be broadcastable, that is, their size must either match or be `1`. The exception is if a subscript is
   212|         0|            0|            0|  0.00%|        repeated for the same input operand, in which case the dimensions labeled with this subscript for this operand
   213|         0|            0|            0|  0.00%|        must match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that
   214|         0|            0|            0|  0.00%|        appear exactly once in the :attr:`equation` will be part of the output, sorted in increasing alphabetical order.
   215|         0|            0|            0|  0.00%|        The output is computed by multiplying the input :attr:`operands` element-wise, with their dimensions aligned based
   216|         0|            0|            0|  0.00%|        on the subscripts, and then summing out the dimensions whose subscripts are not part of the output.
   217|         0|            0|            0|  0.00%|
   218|         0|            0|            0|  0.00%|        Optionally, the output subscripts can be explicitly defined by adding an arrow ('->') at the end of the equation
   219|         0|            0|            0|  0.00%|        followed by the subscripts for the output. For instance, the following equation computes the transpose of a
   220|         0|            0|            0|  0.00%|        matrix multiplication: 'ij,jk->ki'. The output subscripts must appear at least once for some input operand and
   221|         0|            0|            0|  0.00%|        at most once for the output.
   222|         0|            0|            0|  0.00%|
   223|         0|            0|            0|  0.00%|        Ellipsis ('...') can be used in place of subscripts to broadcast the dimensions covered by the ellipsis.
   224|         0|            0|            0|  0.00%|        Each input operand may contain at most one ellipsis which will cover the dimensions not covered by subscripts,
   225|         0|            0|            0|  0.00%|        e.g. for an input operand with 5 dimensions, the ellipsis in the equation `'ab...c'` cover the third and fourth
   226|         0|            0|            0|  0.00%|        dimensions. The ellipsis does not need to cover the same number of dimensions across the :attr:`operands` but the
   227|         0|            0|            0|  0.00%|        'shape' of the ellipsis (the size of the dimensions covered by them) must broadcast together. If the output is not
   228|         0|            0|            0|  0.00%|        explicitly defined with the arrow ('->') notation, the ellipsis will come first in the output (left-most dimensions),
   229|         0|            0|            0|  0.00%|        before the subscript labels that appear exactly once for the input operands. e.g. the following equation implements
   230|         0|            0|            0|  0.00%|        batch matrix multiplication `'...ij,...jk'`.
   231|         0|            0|            0|  0.00%|
   232|         0|            0|            0|  0.00%|        A few final notes: the equation may contain whitespaces between the different elements (subscripts, ellipsis,
   233|         0|            0|            0|  0.00%|        arrow and comma) but something like `'. . .'` is not valid. An empty string `''` is valid for scalar operands.
   234|         0|            0|            0|  0.00%|
   235|         0|            0|            0|  0.00%|    .. note::
   236|         0|            0|            0|  0.00%|
   237|         0|            0|            0|  0.00%|        ``torch.einsum`` handles ellipsis ('...') differently from NumPy in that it allows dimensions
   238|         0|            0|            0|  0.00%|        covered by the ellipsis to be summed over, that is, ellipsis are not required to be part of the output.
   239|         0|            0|            0|  0.00%|
   240|         0|            0|            0|  0.00%|    .. note::
   241|         0|            0|            0|  0.00%|
   242|         0|            0|            0|  0.00%|        This function does not optimize the given expression, so a different formula for the same computation may
   243|         0|            0|            0|  0.00%|        run faster or consume less memory. Projects like opt_einsum (https://optimized-einsum.readthedocs.io/en/stable/)
   244|         0|            0|            0|  0.00%|        can optimize the formula for you.
   245|         0|            0|            0|  0.00%|
   246|         0|            0|            0|  0.00%|    .. note::
   247|         0|            0|            0|  0.00%|
   248|         0|            0|            0|  0.00%|        As of PyTorch 1.10 :func:`torch.einsum` also supports the sublist format (see examples below). In this format,
   249|         0|            0|            0|  0.00%|        subscripts for each operand are specified by sublists, list of integers in the range [0, 52). These sublists
   250|         0|            0|            0|  0.00%|        follow their operands, and an extra sublist can appear at the end of the input to specify the output's
   251|         0|            0|            0|  0.00%|        subscripts., e.g. `torch.einsum(op1, sublist1, op2, sublist2, ..., [subslist_out])`. Python's `Ellipsis` object
   252|         0|            0|            0|  0.00%|        may be provided in a sublist to enable broadcasting as described in the Equation section above.
   253|         0|            0|            0|  0.00%|
   254|         0|            0|            0|  0.00%|    Args:
   255|         0|            0|            0|  0.00%|        equation (string): The subscripts for the Einstein summation.
   256|         0|            0|            0|  0.00%|        operands (List[Tensor]): The tensors to compute the Einstein summation of.
   257|         0|            0|            0|  0.00%|
   258|         0|            0|            0|  0.00%|    Examples::
   259|         0|            0|            0|  0.00%|
   260|         0|            0|            0|  0.00%|        # trace
   261|         0|            0|            0|  0.00%|        >>> torch.einsum('ii', torch.randn(4, 4))
   262|         0|            0|            0|  0.00%|        tensor(-1.2104)
   263|         0|            0|            0|  0.00%|
   264|         0|            0|            0|  0.00%|        # diagonal
   265|         0|            0|            0|  0.00%|        >>> torch.einsum('ii->i', torch.randn(4, 4))
   266|         0|            0|            0|  0.00%|        tensor([-0.1034,  0.7952, -0.2433,  0.4545])
   267|         0|            0|            0|  0.00%|
   268|         0|            0|            0|  0.00%|        # outer product
   269|         0|            0|            0|  0.00%|        >>> x = torch.randn(5)
   270|         0|            0|            0|  0.00%|        >>> y = torch.randn(4)
   271|         0|            0|            0|  0.00%|        >>> torch.einsum('i,j->ij', x, y)
   272|         0|            0|            0|  0.00%|        tensor([[ 0.1156, -0.2897, -0.3918,  0.4963],
   273|         0|            0|            0|  0.00%|                [-0.3744,  0.9381,  1.2685, -1.6070],
   274|         0|            0|            0|  0.00%|                [ 0.7208, -1.8058, -2.4419,  3.0936],
   275|         0|            0|            0|  0.00%|                [ 0.1713, -0.4291, -0.5802,  0.7350],
   276|         0|            0|            0|  0.00%|                [ 0.5704, -1.4290, -1.9323,  2.4480]])
   277|         0|            0|            0|  0.00%|
   278|         0|            0|            0|  0.00%|        # batch matrix multiplication
   279|         0|            0|            0|  0.00%|        >>> As = torch.randn(3,2,5)
   280|         0|            0|            0|  0.00%|        >>> Bs = torch.randn(3,5,4)
   281|         0|            0|            0|  0.00%|        >>> torch.einsum('bij,bjk->bik', As, Bs)
   282|         0|            0|            0|  0.00%|        tensor([[[-1.0564, -1.5904,  3.2023,  3.1271],
   283|         0|            0|            0|  0.00%|                [-1.6706, -0.8097, -0.8025, -2.1183]],
   284|         0|            0|            0|  0.00%|
   285|         0|            0|            0|  0.00%|                [[ 4.2239,  0.3107, -0.5756, -0.2354],
   286|         0|            0|            0|  0.00%|                [-1.4558, -0.3460,  1.5087, -0.8530]],
   287|         0|            0|            0|  0.00%|
   288|         0|            0|            0|  0.00%|                [[ 2.8153,  1.8787, -4.3839, -1.2112],
   289|         0|            0|            0|  0.00%|                [ 0.3728, -2.1131,  0.0921,  0.8305]]])
   290|         0|            0|            0|  0.00%|
   291|         0|            0|            0|  0.00%|        # with sublist format and ellipsis
   292|         0|            0|            0|  0.00%|        >>> torch.einsum(As, [..., 0, 1], Bs, [..., 1, 2], [..., 0, 2])
   293|         0|            0|            0|  0.00%|        tensor([[[-1.0564, -1.5904,  3.2023,  3.1271],
   294|         0|            0|            0|  0.00%|                [-1.6706, -0.8097, -0.8025, -2.1183]],
   295|         0|            0|            0|  0.00%|
   296|         0|            0|            0|  0.00%|                [[ 4.2239,  0.3107, -0.5756, -0.2354],
   297|         0|            0|            0|  0.00%|                [-1.4558, -0.3460,  1.5087, -0.8530]],
   298|         0|            0|            0|  0.00%|
   299|         0|            0|            0|  0.00%|                [[ 2.8153,  1.8787, -4.3839, -1.2112],
   300|         0|            0|            0|  0.00%|                [ 0.3728, -2.1131,  0.0921,  0.8305]]])
   301|         0|            0|            0|  0.00%|
   302|         0|            0|            0|  0.00%|        # batch permute
   303|         0|            0|            0|  0.00%|        >>> A = torch.randn(2, 3, 4, 5)
   304|         0|            0|            0|  0.00%|        >>> torch.einsum('...ij->...ji', A).shape
   305|         0|            0|            0|  0.00%|        torch.Size([2, 3, 5, 4])
   306|         0|            0|            0|  0.00%|
   307|         0|            0|            0|  0.00%|        # equivalent to torch.nn.functional.bilinear
   308|         0|            0|            0|  0.00%|        >>> A = torch.randn(3,5,4)
   309|         0|            0|            0|  0.00%|        >>> l = torch.randn(2,5)
   310|         0|            0|            0|  0.00%|        >>> r = torch.randn(2,4)
   311|         0|            0|            0|  0.00%|        >>> torch.einsum('bn,anm,bm->ba', l, A, r)
   312|         0|            0|            0|  0.00%|        tensor([[-0.3430, -5.2405,  0.4494],
   313|         0|            0|            0|  0.00%|                [ 0.3311,  5.5201, -3.0356]])
   314|         0|            0|            0|  0.00%|    """
   315|         0|            0|            0|  0.00%|    # This wrapper exists to support variadic args.
   316|         0|            0|            0|  0.00%|    if len(args) < 2:
   317|         0|            0|            0|  0.00%|        raise ValueError('einsum(): must specify the equation string and at least one operand, '
   318|         0|            0|            0|  0.00%|                         'or at least one operand and its subscripts list')
   319|         0|            0|            0|  0.00%|
   320|         0|            0|            0|  0.00%|    equation = None
   321|         0|            0|            0|  0.00%|    operands = None
   322|         0|            0|            0|  0.00%|
   323|         0|            0|            0|  0.00%|    if isinstance(args[0], torch.Tensor):
   324|         0|            0|            0|  0.00%|        # Convert the subscript list format which is an interleaving of operand and its subscripts
   325|         0|            0|            0|  0.00%|        # list with an optional output subscripts list at the end (see documentation for more details on this)
   326|         0|            0|            0|  0.00%|        # to the equation string format by creating the equation string from the subscripts list and grouping the
   327|         0|            0|            0|  0.00%|        # input operands into a tensorlist (List[Tensor]).
   328|         0|            0|            0|  0.00%|        def parse_subscript(n: int) -> str:
   329|         0|            0|            0|  0.00%|            if n == Ellipsis:
   330|         0|            0|            0|  0.00%|                return '...'
   331|         0|            0|            0|  0.00%|            if n >= 0 and n < 26:
   332|         0|            0|            0|  0.00%|                return chr(ord('A') + n)
   333|         0|            0|            0|  0.00%|            if n >= 26 and n < 52:
   334|         0|            0|            0|  0.00%|                return chr(ord('a') + n - 26)
   335|         0|            0|            0|  0.00%|            raise ValueError('einsum(): subscript in subscript list is not within the valid range [0, 52)')
   336|         0|            0|            0|  0.00%|
   337|         0|            0|            0|  0.00%|        # Parse subscripts for input operands
   338|         0|            0|            0|  0.00%|        equation = ','.join(''.join(parse_subscript(s) for s in l) for l in args[1::2])
   339|         0|            0|            0|  0.00%|
   340|         0|            0|            0|  0.00%|        # Parse optional output subscripts (provided when the number of arguments is odd)
   341|         0|            0|            0|  0.00%|        if len(args) % 2 == 1:
   342|         0|            0|            0|  0.00%|            equation += '->' + ''.join(parse_subscript(s) for s in args[-1])
   343|         0|            0|            0|  0.00%|            operands = args[:-1:2]
   344|         0|            0|            0|  0.00%|        else:
   345|         0|            0|            0|  0.00%|            operands = args[::2]
   346|         0|            0|            0|  0.00%|    else:
   347|         0|            0|            0|  0.00%|        equation = args[0]
   348|         0|            0|            0|  0.00%|        operands = args[1:]
   349|         0|            0|            0|  0.00%|
   350|         0|            0|            0|  0.00%|    if has_torch_function(operands):
   351|         0|            0|            0|  0.00%|        return handle_torch_function(einsum, operands, equation, *operands)
   352|         0|            0|            0|  0.00%|
   353|         0|            0|            0|  0.00%|    if len(operands) == 1 and isinstance(operands[0], (list, tuple)):
   354|         0|            0|            0|  0.00%|        # the old interface of passing the operands as one list argument
   355|         0|            0|            0|  0.00%|        _operands = operands[0]
   356|         0|            0|            0|  0.00%|        # recurse incase operands contains value that has torch function
   357|         0|            0|            0|  0.00%|        # in the original implementation this line is omitted
   358|         0|            0|            0|  0.00%|        return einsum(equation, *_operands)
   359|         0|            0|            0|  0.00%|
   360|         0|            0|            0|  0.00%|    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]
   361|         0|            0|            0|  0.00%|
   362|         0|            0|            0|  0.00%|
   363|         0|            0|            0|  0.00%|# This wrapper exists to support variadic args.
   364|         0|            0|            0|  0.00%|if TYPE_CHECKING:
   365|         0|            0|            0|  0.00%|    # The JIT doesn't understand Union, so only add type annotation for mypy
   366|         0|            0|            0|  0.00%|    def meshgrid(*tensors: Union[Tensor, List[Tensor]],
   367|         0|            0|            0|  0.00%|                 indexing: Optional[str] = None) -> Tuple[Tensor, ...]:
   368|         0|            0|            0|  0.00%|        return _meshgrid(*tensors, indexing=indexing)
   369|         0|            0|            0|  0.00%|else:
   370|         0|            0|            0|  0.00%|    def meshgrid(*tensors, indexing: Optional[str] = None) -> Tuple[Tensor, ...]:
   371|         0|            0|            0|  0.00%|        r"""Creates grids of coordinates specified by the 1D inputs in `attr`:tensors.
   372|         0|            0|            0|  0.00%|
   373|         0|            0|            0|  0.00%|        This is helpful when you want to visualize data over some
   374|         0|            0|            0|  0.00%|        range of inputs. See below for a plotting example.
   375|         0|            0|            0|  0.00%|
   376|         0|            0|            0|  0.00%|        Given :math:`N` 1D tensors :math:`T_0 \ldots T_{N-1}` as
   377|         0|            0|            0|  0.00%|        inputs with corresponding sizes :math:`S_0 \ldots S_{N-1}`,
   378|         0|            0|            0|  0.00%|        this creates :math:`N` N-dimensional tensors :math:`G_0 \ldots
   379|         0|            0|            0|  0.00%|        G_{N-1}`, each with shape :math:`(S_0, ..., S_{N-1})` where
   380|         0|            0|            0|  0.00%|        the output :math:`G_i` is constructed by expanding :math:`T_i`
   381|         0|            0|            0|  0.00%|        to the result shape.
   382|         0|            0|            0|  0.00%|
   383|         0|            0|            0|  0.00%|        .. note::
   384|         0|            0|            0|  0.00%|            0D inputs are treated equivalently to 1D inputs of a
   385|         0|            0|            0|  0.00%|            single element.
   386|         0|            0|            0|  0.00%|
   387|         0|            0|            0|  0.00%|        .. warning::
   388|         0|            0|            0|  0.00%|            `torch.meshgrid(*tensors)` currently has the same behavior
   389|         0|            0|            0|  0.00%|            as calling `numpy.meshgrid(*arrays, indexing='ij')`.
   390|         0|            0|            0|  0.00%|
   391|         0|            0|            0|  0.00%|            In the future `torch.meshgrid` will transition to
   392|         0|            0|            0|  0.00%|            `indexing='xy'` as the default.
   393|         0|            0|            0|  0.00%|
   394|         0|            0|            0|  0.00%|            https://github.com/pytorch/pytorch/issues/50276 tracks
   395|         0|            0|            0|  0.00%|            this issue with the goal of migrating to NumPy's behavior.
   396|         0|            0|            0|  0.00%|
   397|         0|            0|            0|  0.00%|        .. seealso::
   398|         0|            0|            0|  0.00%|
   399|         0|            0|            0|  0.00%|            :func:`torch.cartesian_prod` has the same effect but it
   400|         0|            0|            0|  0.00%|            collects the data in a tensor of vectors.
   401|         0|            0|            0|  0.00%|
   402|         0|            0|            0|  0.00%|        Args:
   403|         0|            0|            0|  0.00%|            tensors (list of Tensor): list of scalars or 1 dimensional tensors. Scalars will be
   404|         0|            0|            0|  0.00%|                treated as tensors of size :math:`(1,)` automatically
   405|         0|            0|            0|  0.00%|
   406|         0|            0|            0|  0.00%|            indexing: (str, optional): the indexing mode, either "xy"
   407|         0|            0|            0|  0.00%|                or "ij", defaults to "ij". See warning for future changes.
   408|         0|            0|            0|  0.00%|
   409|         0|            0|            0|  0.00%|                If "xy" is selected, the first dimension corresponds
   410|         0|            0|            0|  0.00%|                to the cardinality of the second input and the second
   411|         0|            0|            0|  0.00%|                dimension corresponds to the cardinality of the first
   412|         0|            0|            0|  0.00%|                input.
   413|         0|            0|            0|  0.00%|
   414|         0|            0|            0|  0.00%|                If "ij" is selected, the dimensions are in the same
   415|         0|            0|            0|  0.00%|                order as the cardinality of the inputs.
   416|         0|            0|            0|  0.00%|
   417|         0|            0|            0|  0.00%|        Returns:
   418|         0|            0|            0|  0.00%|            seq (sequence of Tensors): If the input has :math:`N`
   419|         0|            0|            0|  0.00%|            tensors of size :math:`S_0 \ldots S_{N-1}``, then the
   420|         0|            0|            0|  0.00%|            output will also have :math:`N` tensors, where each tensor
   421|         0|            0|            0|  0.00%|            is of shape :math:`(S_0, ..., S_{N-1})`.
   422|         0|            0|            0|  0.00%|
   423|         0|            0|            0|  0.00%|        Example::
   424|         0|            0|            0|  0.00%|
   425|         0|            0|            0|  0.00%|            >>> x = torch.tensor([1, 2, 3])
   426|         0|            0|            0|  0.00%|            >>> y = torch.tensor([4, 5, 6])
   427|         0|            0|            0|  0.00%|
   428|         0|            0|            0|  0.00%|            Observe the element-wise pairings across the grid, (1, 4),
   429|         0|            0|            0|  0.00%|            (1, 5), ..., (3, 6). This is the same thing as the
   430|         0|            0|            0|  0.00%|            cartesian product.
   431|         0|            0|            0|  0.00%|            >>> grid_x, grid_y = torch.meshgrid(x, y, indexing='ij')
   432|         0|            0|            0|  0.00%|            >>> grid_x
   433|         0|            0|            0|  0.00%|            tensor([[1, 1, 1],
   434|         0|            0|            0|  0.00%|                    [2, 2, 2],
   435|         0|            0|            0|  0.00%|                    [3, 3, 3]])
   436|         0|            0|            0|  0.00%|            >>> grid_y
   437|         0|            0|            0|  0.00%|            tensor([[4, 5, 6],
   438|         0|            0|            0|  0.00%|                    [4, 5, 6],
   439|         0|            0|            0|  0.00%|                    [4, 5, 6]])
   440|         0|            0|            0|  0.00%|
   441|         0|            0|            0|  0.00%|            This correspondence can be seen when these grids are
   442|         0|            0|            0|  0.00%|            stacked properly.
   443|         0|            0|            0|  0.00%|            >>> torch.equal(torch.cat(tuple(torch.dstack([grid_x, grid_y]))),
   444|         0|            0|            0|  0.00%|            ...             torch.cartesian_prod(x, y))
   445|         0|            0|            0|  0.00%|            True
   446|         0|            0|            0|  0.00%|
   447|         0|            0|            0|  0.00%|            `torch.meshgrid` is commonly used to produce a grid for
   448|         0|            0|            0|  0.00%|            plotting.
   449|         0|            0|            0|  0.00%|            >>> import matplotlib.pyplot as plt
   450|         0|            0|            0|  0.00%|            >>> xs = torch.linspace(-5, 5, steps=100)
   451|         0|            0|            0|  0.00%|            >>> ys = torch.linspace(-5, 5, steps=100)
   452|         0|            0|            0|  0.00%|            >>> x, y = torch.meshgrid(xs, ys, indexing='xy')
   453|         0|            0|            0|  0.00%|            >>> z = torch.sin(torch.sqrt(x * x + y * y))
   454|         0|            0|            0|  0.00%|            >>> ax = plt.axes(projection='3d')
   455|         0|            0|            0|  0.00%|            >>> ax.plot_surface(x.numpy(), y.numpy(), z.numpy())
   456|         0|            0|            0|  0.00%|            <mpl_toolkits.mplot3d.art3d.Poly3DCollection object at 0x7f8f30d40100>
   457|         0|            0|            0|  0.00%|            >>> plt.show()
   458|         0|            0|            0|  0.00%|
   459|         0|            0|            0|  0.00%|        .. image:: ../_static/img/meshgrid.png
   460|         0|            0|            0|  0.00%|            :width: 512
   461|         0|            0|            0|  0.00%|
   462|         0|            0|            0|  0.00%|        """
   463|         0|            0|            0|  0.00%|        return _meshgrid(*tensors, indexing=indexing)
   464|         0|            0|            0|  0.00%|
   465|         0|            0|            0|  0.00%|
   466|         0|            0|            0|  0.00%|def _meshgrid(*tensors, indexing: Optional[str]):
   467|         0|            0|            0|  0.00%|    if has_torch_function(tensors):
   468|         0|            0|            0|  0.00%|        return handle_torch_function(meshgrid, tensors, *tensors, indexing=indexing)
   469|         0|            0|            0|  0.00%|    if len(tensors) == 1 and isinstance(tensors[0], (list, tuple)):
   470|         0|            0|            0|  0.00%|        # the old interface of passing the operands as one list argument
   471|         0|            0|            0|  0.00%|        tensors = tensors[0]  # type: ignore[assignment]
   472|         0|            0|            0|  0.00%|
   473|         0|            0|            0|  0.00%|    # Continue allowing call of old method that takes no indexing
   474|         0|            0|            0|  0.00%|    # kwarg for forward compatibility reasons.
   475|         0|            0|            0|  0.00%|    #
   476|         0|            0|            0|  0.00%|    # Remove this two weeks after landing.
   477|         0|            0|            0|  0.00%|    kwargs = {} if indexing is None else {'indexing': indexing}
   478|         0|            0|            0|  0.00%|    return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
   479|         0|            0|            0|  0.00%|
   480|         0|            0|            0|  0.00%|
   481|         0|            0|            0|  0.00%|def stft(input: Tensor, n_fft: int, hop_length: Optional[int] = None,
   482|         0|            0|            0|  0.00%|         win_length: Optional[int] = None, window: Optional[Tensor] = None,
   483|         0|            0|            0|  0.00%|         center: bool = True, pad_mode: str = 'reflect', normalized: bool = False,
   484|         0|            0|            0|  0.00%|         onesided: Optional[bool] = None,
   485|         0|            0|            0|  0.00%|         return_complex: Optional[bool] = None) -> Tensor:
   486|         0|            0|            0|  0.00%|    r"""Short-time Fourier transform (STFT).
   487|         0|            0|            0|  0.00%|
   488|         0|            0|            0|  0.00%|    .. warning::
   489|         0|            0|            0|  0.00%|        From version 1.8.0, :attr:`return_complex` must always be given
   490|         0|            0|            0|  0.00%|        explicitly for real inputs and `return_complex=False` has been
   491|         0|            0|            0|  0.00%|        deprecated. Strongly prefer `return_complex=True` as in a future
   492|         0|            0|            0|  0.00%|        pytorch release, this function will only return complex tensors.
   493|         0|            0|            0|  0.00%|
   494|         0|            0|            0|  0.00%|        Note that :func:`torch.view_as_real` can be used to recover a real
   495|         0|            0|            0|  0.00%|        tensor with an extra last dimension for real and imaginary components.
   496|         0|            0|            0|  0.00%|
   497|         0|            0|            0|  0.00%|    The STFT computes the Fourier transform of short overlapping windows of the
   498|         0|            0|            0|  0.00%|    input. This giving frequency components of the signal as they change over
   499|         0|            0|            0|  0.00%|    time. The interface of this function is modeled after (but *not* a drop-in
   500|         0|            0|            0|  0.00%|    replacement for) librosa_ stft function.
   501|         0|            0|            0|  0.00%|
   502|         0|            0|            0|  0.00%|    .. _librosa: https://librosa.org/doc/latest/generated/librosa.stft.html
   503|         0|            0|            0|  0.00%|
   504|         0|            0|            0|  0.00%|    Ignoring the optional batch dimension, this method computes the following
   505|         0|            0|            0|  0.00%|    expression:
   506|         0|            0|            0|  0.00%|
   507|         0|            0|            0|  0.00%|    .. math::
   508|         0|            0|            0|  0.00%|        X[\omega, m] = \sum_{k = 0}^{\text{win\_length-1}}%
   509|         0|            0|            0|  0.00%|                            \text{window}[k]\ \text{input}[m \times \text{hop\_length} + k]\ %
   510|         0|            0|            0|  0.00%|                            \exp\left(- j \frac{2 \pi \cdot \omega k}{\text{win\_length}}\right),
   511|         0|            0|            0|  0.00%|
   512|         0|            0|            0|  0.00%|    where :math:`m` is the index of the sliding window, and :math:`\omega` is
   513|         0|            0|            0|  0.00%|    the frequency :math:`0 \leq \omega < \text{n\_fft}` for ``onesided=False``,
   514|         0|            0|            0|  0.00%|    or :math:`0 \leq \omega < \lfloor \text{n\_fft} / 2 \rfloor + 1` for ``onesided=True``.
   515|         0|            0|            0|  0.00%|
   516|         0|            0|            0|  0.00%|    * :attr:`input` must be either a 1-D time sequence or a 2-D batch of time
   517|         0|            0|            0|  0.00%|      sequences.
   518|         0|            0|            0|  0.00%|
   519|         0|            0|            0|  0.00%|    * If :attr:`hop_length` is ``None`` (default), it is treated as equal to
   520|         0|            0|            0|  0.00%|      ``floor(n_fft / 4)``.
   521|         0|            0|            0|  0.00%|
   522|         0|            0|            0|  0.00%|    * If :attr:`win_length` is ``None`` (default), it is treated as equal to
   523|         0|            0|            0|  0.00%|      :attr:`n_fft`.
   524|         0|            0|            0|  0.00%|
   525|         0|            0|            0|  0.00%|    * :attr:`window` can be a 1-D tensor of size :attr:`win_length`, e.g., from
   526|         0|            0|            0|  0.00%|      :meth:`torch.hann_window`. If :attr:`window` is ``None`` (default), it is
   527|         0|            0|            0|  0.00%|      treated as if having :math:`1` everywhere in the window. If
   528|         0|            0|            0|  0.00%|      :math:`\text{win\_length} < \text{n\_fft}`, :attr:`window` will be padded on
   529|         0|            0|            0|  0.00%|      both sides to length :attr:`n_fft` before being applied.
   530|         0|            0|            0|  0.00%|
   531|         0|            0|            0|  0.00%|    * If :attr:`center` is ``True`` (default), :attr:`input` will be padded on
   532|         0|            0|            0|  0.00%|      both sides so that the :math:`t`-th frame is centered at time
   533|         0|            0|            0|  0.00%|      :math:`t \times \text{hop\_length}`. Otherwise, the :math:`t`-th frame
   534|         0|            0|            0|  0.00%|      begins at time  :math:`t \times \text{hop\_length}`.
   535|         0|            0|            0|  0.00%|
   536|         0|            0|            0|  0.00%|    * :attr:`pad_mode` determines the padding method used on :attr:`input` when
   537|         0|            0|            0|  0.00%|      :attr:`center` is ``True``. See :meth:`torch.nn.functional.pad` for
   538|         0|            0|            0|  0.00%|      all available options. Default is ``"reflect"``.
   539|         0|            0|            0|  0.00%|
   540|         0|            0|            0|  0.00%|    * If :attr:`onesided` is ``True`` (default for real input), only values for
   541|         0|            0|            0|  0.00%|      :math:`\omega` in :math:`\left[0, 1, 2, \dots, \left\lfloor
   542|         0|            0|            0|  0.00%|      \frac{\text{n\_fft}}{2} \right\rfloor + 1\right]` are returned because
   543|         0|            0|            0|  0.00%|      the real-to-complex Fourier transform satisfies the conjugate symmetry,
   544|         0|            0|            0|  0.00%|      i.e., :math:`X[m, \omega] = X[m, \text{n\_fft} - \omega]^*`.
   545|         0|            0|            0|  0.00%|      Note if the input or window tensors are complex, then :attr:`onesided`
   546|         0|            0|            0|  0.00%|      output is not possible.
   547|         0|            0|            0|  0.00%|
   548|         0|            0|            0|  0.00%|    * If :attr:`normalized` is ``True`` (default is ``False``), the function
   549|         0|            0|            0|  0.00%|      returns the normalized STFT results, i.e., multiplied by :math:`(\text{frame\_length})^{-0.5}`.
   550|         0|            0|            0|  0.00%|
   551|         0|            0|            0|  0.00%|    * If :attr:`return_complex` is ``True`` (default if input is complex), the
   552|         0|            0|            0|  0.00%|      return is a ``input.dim() + 1`` dimensional complex tensor. If ``False``,
   553|         0|            0|            0|  0.00%|      the output is a ``input.dim() + 2`` dimensional real tensor where the last
   554|         0|            0|            0|  0.00%|      dimension represents the real and imaginary components.
   555|         0|            0|            0|  0.00%|
   556|         0|            0|            0|  0.00%|    Returns either a complex tensor of size :math:`(* \times N \times T)` if
   557|         0|            0|            0|  0.00%|    :attr:`return_complex` is true, or a real tensor of size :math:`(* \times N
   558|         0|            0|            0|  0.00%|    \times T \times 2)`. Where :math:`*` is the optional batch size of
   559|         0|            0|            0|  0.00%|    :attr:`input`, :math:`N` is the number of frequencies where STFT is applied
   560|         0|            0|            0|  0.00%|    and :math:`T` is the total number of frames used.
   561|         0|            0|            0|  0.00%|
   562|         0|            0|            0|  0.00%|    .. warning::
   563|         0|            0|            0|  0.00%|      This function changed signature at version 0.4.1. Calling with the
   564|         0|            0|            0|  0.00%|      previous signature may cause error or return incorrect result.
   565|         0|            0|            0|  0.00%|
   566|         0|            0|            0|  0.00%|    Args:
   567|         0|            0|            0|  0.00%|        input (Tensor): the input tensor
   568|         0|            0|            0|  0.00%|        n_fft (int): size of Fourier transform
   569|         0|            0|            0|  0.00%|        hop_length (int, optional): the distance between neighboring sliding window
   570|         0|            0|            0|  0.00%|            frames. Default: ``None`` (treated as equal to ``floor(n_fft / 4)``)
   571|         0|            0|            0|  0.00%|        win_length (int, optional): the size of window frame and STFT filter.
   572|         0|            0|            0|  0.00%|            Default: ``None``  (treated as equal to :attr:`n_fft`)
   573|         0|            0|            0|  0.00%|        window (Tensor, optional): the optional window function.
   574|         0|            0|            0|  0.00%|            Default: ``None`` (treated as window of all :math:`1` s)
   575|         0|            0|            0|  0.00%|        center (bool, optional): whether to pad :attr:`input` on both sides so
   576|         0|            0|            0|  0.00%|            that the :math:`t`-th frame is centered at time :math:`t \times \text{hop\_length}`.
   577|         0|            0|            0|  0.00%|            Default: ``True``
   578|         0|            0|            0|  0.00%|        pad_mode (string, optional): controls the padding method used when
   579|         0|            0|            0|  0.00%|            :attr:`center` is ``True``. Default: ``"reflect"``
   580|         0|            0|            0|  0.00%|        normalized (bool, optional): controls whether to return the normalized STFT results
   581|         0|            0|            0|  0.00%|             Default: ``False``
   582|         0|            0|            0|  0.00%|        onesided (bool, optional): controls whether to return half of results to
   583|         0|            0|            0|  0.00%|            avoid redundancy for real inputs.
   584|         0|            0|            0|  0.00%|            Default: ``True`` for real :attr:`input` and :attr:`window`, ``False`` otherwise.
   585|         0|            0|            0|  0.00%|        return_complex (bool, optional): whether to return a complex tensor, or
   586|         0|            0|            0|  0.00%|            a real tensor with an extra last dimension for the real and
   587|         0|            0|            0|  0.00%|            imaginary components.
   588|         0|            0|            0|  0.00%|
   589|         0|            0|            0|  0.00%|    Returns:
   590|         0|            0|            0|  0.00%|        Tensor: A tensor containing the STFT result with shape described above
   591|         0|            0|            0|  0.00%|
   592|         0|            0|            0|  0.00%|    """
   593|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   594|         0|            0|            0|  0.00%|        return handle_torch_function(
   595|         0|            0|            0|  0.00%|            stft, (input,), input, n_fft, hop_length=hop_length, win_length=win_length,
   596|         0|            0|            0|  0.00%|            window=window, center=center, pad_mode=pad_mode, normalized=normalized,
   597|         0|            0|            0|  0.00%|            onesided=onesided, return_complex=return_complex)
   598|         0|            0|            0|  0.00%|    # NOTE: Do not edit. This code will be removed once the forward-compatibility
   599|         0|            0|            0|  0.00%|    #       period is over for PR #73432
   600|         0|            0|            0|  0.00%|    if center:
   601|         0|            0|            0|  0.00%|        signal_dim = input.dim()
   602|         0|            0|            0|  0.00%|        extended_shape = [1] * (3 - signal_dim) + list(input.size())
   603|         0|            0|            0|  0.00%|        pad = int(n_fft // 2)
   604|         0|            0|            0|  0.00%|        input = F.pad(input.view(extended_shape), [pad, pad], pad_mode)
   605|         0|            0|            0|  0.00%|        input = input.view(input.shape[-signal_dim:])
   606|         0|            0|            0|  0.00%|    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]
   607|         0|            0|            0|  0.00%|                    normalized, onesided, return_complex)
   608|         0|            0|            0|  0.00%|
   609|         0|            0|            0|  0.00%|
   610|         0|            0|            0|  0.00%|istft = _add_docstr(
   611|         0|            0|            0|  0.00%|    torch.istft,
   612|         0|            0|            0|  0.00%|    "istft(input, n_fft, hop_length=None, win_length=None, window=None, center=True, "
   613|         0|            0|            0|  0.00%|    "normalized=False, onesided=None, length=None, return_complex=False) -> Tensor:\n"
   614|         0|            0|            0|  0.00%|    r"""
   615|         0|            0|            0|  0.00%|Inverse short time Fourier Transform. This is expected to be the inverse of :func:`~torch.stft`.
   616|         0|            0|            0|  0.00%|
   617|         0|            0|            0|  0.00%|It has the same parameters (+ additional optional parameter of :attr:`length`) and it should return the
   618|         0|            0|            0|  0.00%|least squares estimation of the original signal. The algorithm will check using the NOLA condition (
   619|         0|            0|            0|  0.00%|nonzero overlap).
   620|         0|            0|            0|  0.00%|
   621|         0|            0|            0|  0.00%|Important consideration in the parameters :attr:`window` and :attr:`center` so that the envelop
   622|         0|            0|            0|  0.00%|created by the summation of all the windows is never zero at certain point in time. Specifically,
   623|         0|            0|            0|  0.00%|:math:`\sum_{t=-\infty}^{\infty} |w|^2[n-t\times hop\_length] \cancel{=} 0`.
   624|         0|            0|            0|  0.00%|
   625|         0|            0|            0|  0.00%|Since :func:`~torch.stft` discards elements at the end of the signal if they do not fit in a frame,
   626|         0|            0|            0|  0.00%|``istft`` may return a shorter signal than the original signal (can occur if :attr:`center` is False
   627|         0|            0|            0|  0.00%|since the signal isn't padded). If `length` is given in the arguments and is longer than expected,
   628|         0|            0|            0|  0.00%|``istft`` will pad zeros to the end of the returned signal.
   629|         0|            0|            0|  0.00%|
   630|         0|            0|            0|  0.00%|If :attr:`center` is ``True``, then there will be padding e.g. ``'constant'``, ``'reflect'``, etc.
   631|         0|            0|            0|  0.00%|Left padding can be trimmed off exactly because they can be calculated but right padding cannot be
   632|         0|            0|            0|  0.00%|calculated without additional information.
   633|         0|            0|            0|  0.00%|
   634|         0|            0|            0|  0.00%|Example: Suppose the last window is:
   635|         0|            0|            0|  0.00%|``[17, 18, 0, 0, 0]`` vs ``[18, 0, 0, 0, 0]``
   636|         0|            0|            0|  0.00%|
   637|         0|            0|            0|  0.00%|The :attr:`n_fft`, :attr:`hop_length`, :attr:`win_length` are all the same which prevents the calculation
   638|         0|            0|            0|  0.00%|of right padding. These additional values could be zeros or a reflection of the signal so providing
   639|         0|            0|            0|  0.00%|:attr:`length` could be useful. If :attr:`length` is ``None`` then padding will be aggressively removed
   640|         0|            0|            0|  0.00%|(some loss of signal).
   641|         0|            0|            0|  0.00%|
   642|         0|            0|            0|  0.00%|[1] D. W. Griffin and J. S. Lim, "Signal estimation from modified short-time Fourier transform,"
   643|         0|            0|            0|  0.00%|IEEE Trans. ASSP, vol.32, no.2, pp.236-243, Apr. 1984.
   644|         0|            0|            0|  0.00%|
   645|         0|            0|            0|  0.00%|Args:
   646|         0|            0|            0|  0.00%|    input (Tensor): The input tensor. Expected to be output of :func:`~torch.stft`,
   647|         0|            0|            0|  0.00%|        can either be complex (``channel``, ``fft_size``, ``n_frame``), or real
   648|         0|            0|            0|  0.00%|        (``channel``, ``fft_size``, ``n_frame``, 2) where the ``channel``
   649|         0|            0|            0|  0.00%|        dimension is optional.
   650|         0|            0|            0|  0.00%|
   651|         0|            0|            0|  0.00%|        .. deprecated:: 1.8.0
   652|         0|            0|            0|  0.00%|            Real input is deprecated, use complex inputs as returned by
   653|         0|            0|            0|  0.00%|            ``stft(..., return_complex=True)`` instead.
   654|         0|            0|            0|  0.00%|    n_fft (int): Size of Fourier transform
   655|         0|            0|            0|  0.00%|    hop_length (Optional[int]): The distance between neighboring sliding window frames.
   656|         0|            0|            0|  0.00%|        (Default: ``n_fft // 4``)
   657|         0|            0|            0|  0.00%|    win_length (Optional[int]): The size of window frame and STFT filter. (Default: ``n_fft``)
   658|         0|            0|            0|  0.00%|    window (Optional[torch.Tensor]): The optional window function.
   659|         0|            0|            0|  0.00%|        (Default: ``torch.ones(win_length)``)
   660|         0|            0|            0|  0.00%|    center (bool): Whether :attr:`input` was padded on both sides so that the :math:`t`-th frame is
   661|         0|            0|            0|  0.00%|        centered at time :math:`t \times \text{hop\_length}`.
   662|         0|            0|            0|  0.00%|        (Default: ``True``)
   663|         0|            0|            0|  0.00%|    normalized (bool): Whether the STFT was normalized. (Default: ``False``)
   664|         0|            0|            0|  0.00%|    onesided (Optional[bool]): Whether the STFT was onesided.
   665|         0|            0|            0|  0.00%|        (Default: ``True`` if ``n_fft != fft_size`` in the input size)
   666|         0|            0|            0|  0.00%|    length (Optional[int]): The amount to trim the signal by (i.e. the
   667|         0|            0|            0|  0.00%|        original signal length). (Default: whole signal)
   668|         0|            0|            0|  0.00%|    return_complex (Optional[bool]):
   669|         0|            0|            0|  0.00%|        Whether the output should be complex, or if the input should be
   670|         0|            0|            0|  0.00%|        assumed to derive from a real signal and window.
   671|         0|            0|            0|  0.00%|        Note that this is incompatible with ``onesided=True``.
   672|         0|            0|            0|  0.00%|        (Default: ``False``)
   673|         0|            0|            0|  0.00%|
   674|         0|            0|            0|  0.00%|Returns:
   675|         0|            0|            0|  0.00%|    Tensor: Least squares estimation of the original signal of size (..., signal_length)
   676|         0|            0|            0|  0.00%|""")
   677|         0|            0|            0|  0.00%|
   678|         0|            0|            0|  0.00%|
   679|         0|            0|            0|  0.00%|if TYPE_CHECKING:
   680|         0|            0|            0|  0.00%|    # These _impl functions return a variable number of tensors as output with
   681|         0|            0|            0|  0.00%|    # __torch_function__; tuple unpacking is done already rather than being
   682|         0|            0|            0|  0.00%|    # done by the caller of the _impl function
   683|         0|            0|            0|  0.00%|    _unique_impl_out = Any
   684|         0|            0|            0|  0.00%|else:
   685|         0|            0|            0|  0.00%|    _unique_impl_out = Tuple[Tensor, Tensor, Tensor]
   686|         0|            0|            0|  0.00%|
   687|         0|            0|            0|  0.00%|
   688|         0|            0|            0|  0.00%|def _unique_impl(input: Tensor, sorted: bool = True,
   689|         0|            0|            0|  0.00%|                 return_inverse: bool = False, return_counts: bool = False,
   690|         0|            0|            0|  0.00%|                 dim: Optional[int] = None) -> _unique_impl_out:
   691|         0|            0|            0|  0.00%|    r"""unique(input, sorted=True, return_inverse=False, return_counts=False, dim=None) -> Tuple[Tensor, Tensor, Tensor]
   692|         0|            0|            0|  0.00%|
   693|         0|            0|            0|  0.00%|    Returns the unique elements of the input tensor.
   694|         0|            0|            0|  0.00%|
   695|         0|            0|            0|  0.00%|    .. note:: This function is different from :func:`torch.unique_consecutive` in the sense that
   696|         0|            0|            0|  0.00%|        this function also eliminates non-consecutive duplicate values.
   697|         0|            0|            0|  0.00%|
   698|         0|            0|            0|  0.00%|    .. note:: Currently in the CUDA implementation and the CPU implementation when dim is specified,
   699|         0|            0|            0|  0.00%|        `torch.unique` always sort the tensor at the beginning regardless of the `sort` argument.
   700|         0|            0|            0|  0.00%|        Sorting could be slow, so if your input tensor is already sorted, it is recommended to use
   701|         0|            0|            0|  0.00%|        :func:`torch.unique_consecutive` which avoids the sorting.
   702|         0|            0|            0|  0.00%|
   703|         0|            0|            0|  0.00%|    Args:
   704|         0|            0|            0|  0.00%|        input (Tensor): the input tensor
   705|         0|            0|            0|  0.00%|        sorted (bool): Whether to sort the unique elements in ascending order
   706|         0|            0|            0|  0.00%|            before returning as output.
   707|         0|            0|            0|  0.00%|        return_inverse (bool): Whether to also return the indices for where
   708|         0|            0|            0|  0.00%|            elements in the original input ended up in the returned unique list.
   709|         0|            0|            0|  0.00%|        return_counts (bool): Whether to also return the counts for each unique
   710|         0|            0|            0|  0.00%|            element.
   711|         0|            0|            0|  0.00%|        dim (int): the dimension to apply unique. If ``None``, the unique of the
   712|         0|            0|            0|  0.00%|            flattened input is returned. default: ``None``
   713|         0|            0|            0|  0.00%|
   714|         0|            0|            0|  0.00%|    Returns:
   715|         0|            0|            0|  0.00%|        (Tensor, Tensor (optional), Tensor (optional)): A tensor or a tuple of tensors containing
   716|         0|            0|            0|  0.00%|
   717|         0|            0|            0|  0.00%|            - **output** (*Tensor*): the output list of unique scalar elements.
   718|         0|            0|            0|  0.00%|            - **inverse_indices** (*Tensor*): (optional) if
   719|         0|            0|            0|  0.00%|              :attr:`return_inverse` is True, there will be an additional
   720|         0|            0|            0|  0.00%|              returned tensor (same shape as input) representing the indices
   721|         0|            0|            0|  0.00%|              for where elements in the original input map to in the output;
   722|         0|            0|            0|  0.00%|              otherwise, this function will only return a single tensor.
   723|         0|            0|            0|  0.00%|            - **counts** (*Tensor*): (optional) if
   724|         0|            0|            0|  0.00%|              :attr:`return_counts` is True, there will be an additional
   725|         0|            0|            0|  0.00%|              returned tensor (same shape as output or output.size(dim),
   726|         0|            0|            0|  0.00%|              if dim was specified) representing the number of occurrences
   727|         0|            0|            0|  0.00%|              for each unique value or tensor.
   728|         0|            0|            0|  0.00%|
   729|         0|            0|            0|  0.00%|    Example::
   730|         0|            0|            0|  0.00%|
   731|         0|            0|            0|  0.00%|        >>> output = torch.unique(torch.tensor([1, 3, 2, 3], dtype=torch.long))
   732|         0|            0|            0|  0.00%|        >>> output
   733|         0|            0|            0|  0.00%|        tensor([ 2,  3,  1])
   734|         0|            0|            0|  0.00%|
   735|         0|            0|            0|  0.00%|        >>> output, inverse_indices = torch.unique(
   736|         0|            0|            0|  0.00%|        ...     torch.tensor([1, 3, 2, 3], dtype=torch.long), sorted=True, return_inverse=True)
   737|         0|            0|            0|  0.00%|        >>> output
   738|         0|            0|            0|  0.00%|        tensor([ 1,  2,  3])
   739|         0|            0|            0|  0.00%|        >>> inverse_indices
   740|         0|            0|            0|  0.00%|        tensor([ 0,  2,  1,  2])
   741|         0|            0|            0|  0.00%|
   742|         0|            0|            0|  0.00%|        >>> output, inverse_indices = torch.unique(
   743|         0|            0|            0|  0.00%|        ...     torch.tensor([[1, 3], [2, 3]], dtype=torch.long), sorted=True, return_inverse=True)
   744|         0|            0|            0|  0.00%|        >>> output
   745|         0|            0|            0|  0.00%|        tensor([ 1,  2,  3])
   746|         0|            0|            0|  0.00%|        >>> inverse_indices
   747|         0|            0|            0|  0.00%|        tensor([[ 0,  2],
   748|         0|            0|            0|  0.00%|                [ 1,  2]])
   749|         0|            0|            0|  0.00%|
   750|         0|            0|            0|  0.00%|    """
   751|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   752|         0|            0|            0|  0.00%|        return handle_torch_function(
   753|         0|            0|            0|  0.00%|            unique, (input,), input, sorted=sorted, return_inverse=return_inverse,
   754|         0|            0|            0|  0.00%|            return_counts=return_counts, dim=dim)
   755|         0|            0|            0|  0.00%|
   756|         0|            0|            0|  0.00%|    if dim is not None:
   757|         0|            0|            0|  0.00%|        output, inverse_indices, counts = _VF.unique_dim(
   758|         0|            0|            0|  0.00%|            input,
   759|         0|            0|            0|  0.00%|            dim,
   760|         0|            0|            0|  0.00%|            sorted=sorted,
   761|         0|            0|            0|  0.00%|            return_inverse=return_inverse,
   762|         0|            0|            0|  0.00%|            return_counts=return_counts,
   763|         0|            0|            0|  0.00%|        )
   764|         0|            0|            0|  0.00%|    else:
   765|         0|            0|            0|  0.00%|        output, inverse_indices, counts = torch._unique2(
   766|         0|            0|            0|  0.00%|            input,
   767|         0|            0|            0|  0.00%|            sorted=sorted,
   768|         0|            0|            0|  0.00%|            return_inverse=return_inverse,
   769|         0|            0|            0|  0.00%|            return_counts=return_counts,
   770|         0|            0|            0|  0.00%|        )
   771|         0|            0|            0|  0.00%|    return output, inverse_indices, counts
   772|         0|            0|            0|  0.00%|
   773|         0|            0|            0|  0.00%|
   774|         0|            0|            0|  0.00%|def _unique_consecutive_impl(input: Tensor, return_inverse: bool = False,
   775|         0|            0|            0|  0.00%|                             return_counts: bool = False,
   776|         0|            0|            0|  0.00%|                             dim: Optional[int] = None) -> _unique_impl_out:
   777|         0|            0|            0|  0.00%|    r"""Eliminates all but the first element from every consecutive group of equivalent elements.
   778|         0|            0|            0|  0.00%|
   779|         0|            0|            0|  0.00%|    .. note:: This function is different from :func:`torch.unique` in the sense that this function
   780|         0|            0|            0|  0.00%|        only eliminates consecutive duplicate values. This semantics is similar to `std::unique`
   781|         0|            0|            0|  0.00%|        in C++.
   782|         0|            0|            0|  0.00%|
   783|         0|            0|            0|  0.00%|    Args:
   784|         0|            0|            0|  0.00%|        input (Tensor): the input tensor
   785|         0|            0|            0|  0.00%|        return_inverse (bool): Whether to also return the indices for where
   786|         0|            0|            0|  0.00%|            elements in the original input ended up in the returned unique list.
   787|         0|            0|            0|  0.00%|        return_counts (bool): Whether to also return the counts for each unique
   788|         0|            0|            0|  0.00%|            element.
   789|         0|            0|            0|  0.00%|        dim (int): the dimension to apply unique. If ``None``, the unique of the
   790|         0|            0|            0|  0.00%|            flattened input is returned. default: ``None``
   791|         0|            0|            0|  0.00%|
   792|         0|            0|            0|  0.00%|    Returns:
   793|         0|            0|            0|  0.00%|        (Tensor, Tensor (optional), Tensor (optional)): A tensor or a tuple of tensors containing
   794|         0|            0|            0|  0.00%|
   795|         0|            0|            0|  0.00%|            - **output** (*Tensor*): the output list of unique scalar elements.
   796|         0|            0|            0|  0.00%|            - **inverse_indices** (*Tensor*): (optional) if
   797|         0|            0|            0|  0.00%|              :attr:`return_inverse` is True, there will be an additional
   798|         0|            0|            0|  0.00%|              returned tensor (same shape as input) representing the indices
   799|         0|            0|            0|  0.00%|              for where elements in the original input map to in the output;
   800|         0|            0|            0|  0.00%|              otherwise, this function will only return a single tensor.
   801|         0|            0|            0|  0.00%|            - **counts** (*Tensor*): (optional) if
   802|         0|            0|            0|  0.00%|              :attr:`return_counts` is True, there will be an additional
   803|         0|            0|            0|  0.00%|              returned tensor (same shape as output or output.size(dim),
   804|         0|            0|            0|  0.00%|              if dim was specified) representing the number of occurrences
   805|         0|            0|            0|  0.00%|              for each unique value or tensor.
   806|         0|            0|            0|  0.00%|
   807|         0|            0|            0|  0.00%|    Example::
   808|         0|            0|            0|  0.00%|
   809|         0|            0|            0|  0.00%|        >>> x = torch.tensor([1, 1, 2, 2, 3, 1, 1, 2])
   810|         0|            0|            0|  0.00%|        >>> output = torch.unique_consecutive(x)
   811|         0|            0|            0|  0.00%|        >>> output
   812|         0|            0|            0|  0.00%|        tensor([1, 2, 3, 1, 2])
   813|         0|            0|            0|  0.00%|
   814|         0|            0|            0|  0.00%|        >>> output, inverse_indices = torch.unique_consecutive(x, return_inverse=True)
   815|         0|            0|            0|  0.00%|        >>> output
   816|         0|            0|            0|  0.00%|        tensor([1, 2, 3, 1, 2])
   817|         0|            0|            0|  0.00%|        >>> inverse_indices
   818|         0|            0|            0|  0.00%|        tensor([0, 0, 1, 1, 2, 3, 3, 4])
   819|         0|            0|            0|  0.00%|
   820|         0|            0|            0|  0.00%|        >>> output, counts = torch.unique_consecutive(x, return_counts=True)
   821|         0|            0|            0|  0.00%|        >>> output
   822|         0|            0|            0|  0.00%|        tensor([1, 2, 3, 1, 2])
   823|         0|            0|            0|  0.00%|        >>> counts
   824|         0|            0|            0|  0.00%|        tensor([2, 2, 1, 2, 1])
   825|         0|            0|            0|  0.00%|    """
   826|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   827|         0|            0|            0|  0.00%|        return handle_torch_function(
   828|         0|            0|            0|  0.00%|            unique_consecutive, (input,), input, return_inverse=return_inverse,
   829|         0|            0|            0|  0.00%|            return_counts=return_counts, dim=dim)
   830|         0|            0|            0|  0.00%|    output, inverse_indices, counts = _VF.unique_consecutive(  # type: ignore[attr-defined]
   831|         0|            0|            0|  0.00%|        input, return_inverse=return_inverse, return_counts=return_counts, dim=dim)
   832|         0|            0|            0|  0.00%|    return output, inverse_indices, counts
   833|         0|            0|            0|  0.00%|
   834|         0|            0|            0|  0.00%|
   835|         0|            0|            0|  0.00%|def _return_counts(input, sorted=True, return_inverse=False, return_counts=False, dim=None):
   836|         0|            0|            0|  0.00%|    # type: (Tensor, bool, bool, bool, Optional[int]) -> Tuple[Tensor, Tensor]
   837|         0|            0|            0|  0.00%|
   838|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   839|         0|            0|            0|  0.00%|        return _unique_impl(input, sorted, return_inverse, return_counts, dim)
   840|         0|            0|            0|  0.00%|
   841|         0|            0|            0|  0.00%|    output, _, counts = _unique_impl(input, sorted, return_inverse, return_counts, dim)
   842|         0|            0|            0|  0.00%|    return output, counts
   843|         0|            0|            0|  0.00%|
   844|         0|            0|            0|  0.00%|
   845|         0|            0|            0|  0.00%|def _return_output(input, sorted=True, return_inverse=False, return_counts=False, dim=None):
   846|         0|            0|            0|  0.00%|    # type: (Tensor, bool, bool, bool, Optional[int]) -> Tensor
   847|         0|            0|            0|  0.00%|
   848|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   849|         0|            0|            0|  0.00%|        return _unique_impl(input, sorted, return_inverse, return_counts, dim)
   850|         0|            0|            0|  0.00%|
   851|         0|            0|            0|  0.00%|    output, _, _ = _unique_impl(input, sorted, return_inverse, return_counts, dim)
   852|         0|            0|            0|  0.00%|    return output
   853|         0|            0|            0|  0.00%|
   854|         0|            0|            0|  0.00%|
   855|         0|            0|            0|  0.00%|def _return_inverse(input, sorted=True, return_inverse=False, return_counts=False, dim=None):
   856|         0|            0|            0|  0.00%|    # type: (Tensor, bool, bool, bool, Optional[int]) -> Tuple[Tensor, Tensor]
   857|         0|            0|            0|  0.00%|
   858|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   859|         0|            0|            0|  0.00%|        return _unique_impl(input, sorted, return_inverse, return_counts, dim)
   860|         0|            0|            0|  0.00%|
   861|         0|            0|            0|  0.00%|    output, inverse_indices, _ = _unique_impl(input, sorted, return_inverse, return_counts, dim)
   862|         0|            0|            0|  0.00%|    return output, inverse_indices
   863|         0|            0|            0|  0.00%|
   864|         0|            0|            0|  0.00%|
   865|         0|            0|            0|  0.00%|_return_inverse_false = boolean_dispatch(
   866|         0|            0|            0|  0.00%|    arg_name='return_counts',
   867|         0|            0|            0|  0.00%|    arg_index=3,
   868|         0|            0|            0|  0.00%|    default=False,
   869|         0|            0|            0|  0.00%|    if_true=_return_counts,
   870|         0|            0|            0|  0.00%|    if_false=_return_output,
   871|         0|            0|            0|  0.00%|    module_name=__name__,
   872|         0|            0|            0|  0.00%|    func_name='unique')
   873|         0|            0|            0|  0.00%|
   874|         0|            0|            0|  0.00%|_return_inverse_true = boolean_dispatch(
   875|         0|            0|            0|  0.00%|    arg_name='return_counts',
   876|         0|            0|            0|  0.00%|    arg_index=3,
   877|         0|            0|            0|  0.00%|    default=False,
   878|         0|            0|            0|  0.00%|    if_true=_unique_impl,
   879|         0|            0|            0|  0.00%|    if_false=_return_inverse,
   880|         0|            0|            0|  0.00%|    module_name=__name__,
   881|         0|            0|            0|  0.00%|    func_name='unique')
   882|         0|            0|            0|  0.00%|
   883|         0|            0|            0|  0.00%|# The return type of unique depends on `return_inverse`, and `return_counts` so in order to
   884|         0|            0|            0|  0.00%|# resolve the output type in TorchScript we need to statically know the value of both parameters
   885|         0|            0|            0|  0.00%|
   886|         0|            0|            0|  0.00%|unique = boolean_dispatch(
   887|         0|            0|            0|  0.00%|    arg_name='return_inverse',
   888|         0|            0|            0|  0.00%|    arg_index=2,
   889|         0|            0|            0|  0.00%|    default=False,
   890|         0|            0|            0|  0.00%|    if_true=_return_inverse_true,
   891|         0|            0|            0|  0.00%|    if_false=_return_inverse_false,
   892|         0|            0|            0|  0.00%|    module_name=__name__,
   893|         0|            0|            0|  0.00%|    func_name='unique')
   894|         0|            0|            0|  0.00%|unique.__doc__ = _unique_impl.__doc__
   895|         0|            0|            0|  0.00%|
   896|         0|            0|            0|  0.00%|
   897|         0|            0|            0|  0.00%|def _consecutive_return_counts(input, return_inverse=False, return_counts=False, dim=None):
   898|         0|            0|            0|  0.00%|    # type: (Tensor, bool, bool, Optional[int]) -> Tuple[Tensor, Tensor]
   899|         0|            0|            0|  0.00%|
   900|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   901|         0|            0|            0|  0.00%|        return _unique_consecutive_impl(input, return_inverse, return_counts, dim)
   902|         0|            0|            0|  0.00%|
   903|         0|            0|            0|  0.00%|    output, _, counts = _unique_consecutive_impl(input, return_inverse, return_counts, dim)
   904|         0|            0|            0|  0.00%|    return output, counts
   905|         0|            0|            0|  0.00%|
   906|         0|            0|            0|  0.00%|
   907|         0|            0|            0|  0.00%|def _consecutive_return_output(input, return_inverse=False, return_counts=False, dim=None):
   908|         0|            0|            0|  0.00%|    # type: (Tensor, bool, bool, Optional[int]) -> Tensor
   909|         0|            0|            0|  0.00%|
   910|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   911|         0|            0|            0|  0.00%|        return _unique_consecutive_impl(input, return_inverse, return_counts, dim)
   912|         0|            0|            0|  0.00%|
   913|         0|            0|            0|  0.00%|    output, _, _ = _unique_consecutive_impl(input, return_inverse, return_counts, dim)
   914|         0|            0|            0|  0.00%|    return output
   915|         0|            0|            0|  0.00%|
   916|         0|            0|            0|  0.00%|
   917|         0|            0|            0|  0.00%|def _consecutive_return_inverse(input, return_inverse=False, return_counts=False, dim=None):
   918|         0|            0|            0|  0.00%|    # type: (Tensor, bool, bool, Optional[int]) -> Tuple[Tensor, Tensor]
   919|         0|            0|            0|  0.00%|
   920|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   921|         0|            0|            0|  0.00%|        return _unique_consecutive_impl(input, return_inverse, return_counts, dim)
   922|         0|            0|            0|  0.00%|
   923|         0|            0|            0|  0.00%|    output, inverse_indices, _ = _unique_consecutive_impl(input, return_inverse, return_counts, dim)
   924|         0|            0|            0|  0.00%|    return output, inverse_indices
   925|         0|            0|            0|  0.00%|
   926|         0|            0|            0|  0.00%|
   927|         0|            0|            0|  0.00%|_consecutive_return_inverse_false = boolean_dispatch(
   928|         0|            0|            0|  0.00%|    arg_name='return_counts',
   929|         0|            0|            0|  0.00%|    arg_index=1,
   930|         0|            0|            0|  0.00%|    default=False,
   931|         0|            0|            0|  0.00%|    if_true=_consecutive_return_counts,
   932|         0|            0|            0|  0.00%|    if_false=_consecutive_return_output,
   933|         0|            0|            0|  0.00%|    module_name=__name__,
   934|         0|            0|            0|  0.00%|    func_name='unique_consecutive')
   935|         0|            0|            0|  0.00%|
   936|         0|            0|            0|  0.00%|_consecutive_return_inverse_true = boolean_dispatch(
   937|         0|            0|            0|  0.00%|    arg_name='return_counts',
   938|         0|            0|            0|  0.00%|    arg_index=1,
   939|         0|            0|            0|  0.00%|    default=False,
   940|         0|            0|            0|  0.00%|    if_true=_unique_consecutive_impl,
   941|         0|            0|            0|  0.00%|    if_false=_consecutive_return_inverse,
   942|         0|            0|            0|  0.00%|    module_name=__name__,
   943|         0|            0|            0|  0.00%|    func_name='unique_consecutive')
   944|         0|            0|            0|  0.00%|
   945|         0|            0|            0|  0.00%|# The return type of unique depends on `return_inverse`, and `return_counts` so in order to
   946|         0|            0|            0|  0.00%|# resolve the output type in TorchScript we need to statically know the value of both parameters
   947|         0|            0|            0|  0.00%|
   948|         0|            0|            0|  0.00%|unique_consecutive = boolean_dispatch(
   949|         0|            0|            0|  0.00%|    arg_name='return_inverse',
   950|         0|            0|            0|  0.00%|    arg_index=2,
   951|         0|            0|            0|  0.00%|    default=False,
   952|         0|            0|            0|  0.00%|    if_true=_consecutive_return_inverse_true,
   953|         0|            0|            0|  0.00%|    if_false=_consecutive_return_inverse_false,
   954|         0|            0|            0|  0.00%|    module_name=__name__,
   955|         0|            0|            0|  0.00%|    func_name='unique_consecutive')
   956|         0|            0|            0|  0.00%|unique_consecutive.__doc__ = _unique_consecutive_impl.__doc__
   957|         0|            0|            0|  0.00%|
   958|         0|            0|            0|  0.00%|if TYPE_CHECKING:
   959|         0|            0|            0|  0.00%|    pass
   960|         0|            0|            0|  0.00%|    # There's no good way to use this type annotation without breaking JIT
   961|         0|            0|            0|  0.00%|    # overloads. So leave untyped for mypy for now.
   962|         0|            0|            0|  0.00%|else:
   963|         0|            0|            0|  0.00%|    @overload
   964|         0|            0|            0|  0.00%|    def tensordot(a, b, dims: int = 2, out: Optional[torch.Tensor] = None):
   965|         0|            0|            0|  0.00%|        pass
   966|         0|            0|            0|  0.00%|
   967|         0|            0|            0|  0.00%|    @overload  # noqa: F811
   968|         0|            0|            0|  0.00%|    def tensordot(a, b, dims: Tuple[List[int], List[int]], out: Optional[torch.Tensor] = None):  # noqa: F811
   969|         0|            0|            0|  0.00%|        pass
   970|         0|            0|            0|  0.00%|
   971|         0|            0|            0|  0.00%|    @overload  # noqa: F811
   972|         0|            0|            0|  0.00%|    def tensordot(a, b, dims: List[List[int]], out: Optional[torch.Tensor] = None):  # noqa: F811
   973|         0|            0|            0|  0.00%|        pass
   974|         0|            0|            0|  0.00%|
   975|         0|            0|            0|  0.00%|    @overload  # noqa: F811
   976|         0|            0|            0|  0.00%|    def tensordot(a, b, dims: torch.Tensor, out: Optional[torch.Tensor] = None):  # noqa: F811
   977|         0|            0|            0|  0.00%|        pass
   978|         0|            0|            0|  0.00%|
   979|         0|            0|            0|  0.00%|def tensordot(a, b, dims=2, out: Optional[torch.Tensor] = None):  # noqa: F811
   980|         0|            0|            0|  0.00%|    r"""Returns a contraction of a and b over multiple dimensions.
   981|         0|            0|            0|  0.00%|
   982|         0|            0|            0|  0.00%|    :attr:`tensordot` implements a generalized matrix product.
   983|         0|            0|            0|  0.00%|
   984|         0|            0|            0|  0.00%|    Args:
   985|         0|            0|            0|  0.00%|      a (Tensor): Left tensor to contract
   986|         0|            0|            0|  0.00%|      b (Tensor): Right tensor to contract
   987|         0|            0|            0|  0.00%|      dims (int or Tuple[List[int], List[int]] or List[List[int]] containing two lists or Tensor): number of dimensions to
   988|         0|            0|            0|  0.00%|         contract or explicit lists of dimensions for :attr:`a` and
   989|         0|            0|            0|  0.00%|         :attr:`b` respectively
   990|         0|            0|            0|  0.00%|
   991|         0|            0|            0|  0.00%|    When called with a non-negative integer argument :attr:`dims` = :math:`d`, and
   992|         0|            0|            0|  0.00%|    the number of dimensions of :attr:`a` and :attr:`b` is :math:`m` and :math:`n`,
   993|         0|            0|            0|  0.00%|    respectively, :func:`~torch.tensordot` computes
   994|         0|            0|            0|  0.00%|
   995|         0|            0|            0|  0.00%|    .. math::
   996|         0|            0|            0|  0.00%|        r_{i_0,...,i_{m-d}, i_d,...,i_n}
   997|         0|            0|            0|  0.00%|          = \sum_{k_0,...,k_{d-1}} a_{i_0,...,i_{m-d},k_0,...,k_{d-1}} \times b_{k_0,...,k_{d-1}, i_d,...,i_n}.
   998|         0|            0|            0|  0.00%|
   999|         0|            0|            0|  0.00%|    When called with :attr:`dims` of the list form, the given dimensions will be contracted
  1000|         0|            0|            0|  0.00%|    in place of the last :math:`d` of :attr:`a` and the first :math:`d` of :math:`b`. The sizes
  1001|         0|            0|            0|  0.00%|    in these dimensions must match, but :func:`~torch.tensordot` will deal with broadcasted
  1002|         0|            0|            0|  0.00%|    dimensions.
  1003|         0|            0|            0|  0.00%|
  1004|         0|            0|            0|  0.00%|    Examples::
  1005|         0|            0|            0|  0.00%|
  1006|         0|            0|            0|  0.00%|        >>> a = torch.arange(60.).reshape(3, 4, 5)
  1007|         0|            0|            0|  0.00%|        >>> b = torch.arange(24.).reshape(4, 3, 2)
  1008|         0|            0|            0|  0.00%|        >>> torch.tensordot(a, b, dims=([1, 0], [0, 1]))
  1009|         0|            0|            0|  0.00%|        tensor([[4400., 4730.],
  1010|         0|            0|            0|  0.00%|                [4532., 4874.],
  1011|         0|            0|            0|  0.00%|                [4664., 5018.],
  1012|         0|            0|            0|  0.00%|                [4796., 5162.],
  1013|         0|            0|            0|  0.00%|                [4928., 5306.]])
  1014|         0|            0|            0|  0.00%|
  1015|         0|            0|            0|  0.00%|        >>> a = torch.randn(3, 4, 5, device='cuda')
  1016|         0|            0|            0|  0.00%|        >>> b = torch.randn(4, 5, 6, device='cuda')
  1017|         0|            0|            0|  0.00%|        >>> c = torch.tensordot(a, b, dims=2).cpu()
  1018|         0|            0|            0|  0.00%|        tensor([[ 8.3504, -2.5436,  6.2922,  2.7556, -1.0732,  3.2741],
  1019|         0|            0|            0|  0.00%|                [ 3.3161,  0.0704,  5.0187, -0.4079, -4.3126,  4.8744],
  1020|         0|            0|            0|  0.00%|                [ 0.8223,  3.9445,  3.2168, -0.2400,  3.4117,  1.7780]])
  1021|         0|            0|            0|  0.00%|
  1022|         0|            0|            0|  0.00%|        >>> a = torch.randn(3, 5, 4, 6)
  1023|         0|            0|            0|  0.00%|        >>> b = torch.randn(6, 4, 5, 3)
  1024|         0|            0|            0|  0.00%|        >>> torch.tensordot(a, b, dims=([2, 1, 3], [1, 2, 0]))
  1025|         0|            0|            0|  0.00%|        tensor([[  7.7193,  -2.4867, -10.3204],
  1026|         0|            0|            0|  0.00%|                [  1.5513, -14.4737,  -6.5113],
  1027|         0|            0|            0|  0.00%|                [ -0.2850,   4.2573,  -3.5997]])
  1028|         0|            0|            0|  0.00%|    """
  1029|         0|            0|            0|  0.00%|    if has_torch_function_variadic(a, b):
  1030|         0|            0|            0|  0.00%|        return handle_torch_function(tensordot, (a, b), a, b, dims=dims, out=out)
  1031|         0|            0|            0|  0.00%|
  1032|         0|            0|            0|  0.00%|    if not isinstance(dims, (tuple, list, torch.Tensor, int)):
  1033|         0|            0|            0|  0.00%|        raise RuntimeError("tensordot expects dims to be int or "
  1034|         0|            0|            0|  0.00%|                           + "Tuple[List[int], List[int]] or "
  1035|         0|            0|            0|  0.00%|                           + "List[List[int]] containing two lists, but got "
  1036|         0|            0|            0|  0.00%|                           + f"dims={dims}")
  1037|         0|            0|            0|  0.00%|
  1038|         0|            0|            0|  0.00%|    dims_a: List[int] = []
  1039|         0|            0|            0|  0.00%|    dims_b: List[int] = []
  1040|         0|            0|            0|  0.00%|
  1041|         0|            0|            0|  0.00%|    if isinstance(dims, (tuple, list)):
  1042|         0|            0|            0|  0.00%|        dims_a, dims_b = dims
  1043|         0|            0|            0|  0.00%|
  1044|         0|            0|            0|  0.00%|    if isinstance(dims, torch.Tensor):
  1045|         0|            0|            0|  0.00%|        num_elements = dims.numel()
  1046|         0|            0|            0|  0.00%|        if num_elements > 1:
  1047|         0|            0|            0|  0.00%|            assert dims.size()[0] == 2
  1048|         0|            0|            0|  0.00%|            dims_a = torch.jit.annotate(List[int], dims[0].tolist())
  1049|         0|            0|            0|  0.00%|            dims_b = torch.jit.annotate(List[int], dims[1].tolist())
  1050|         0|            0|            0|  0.00%|        else:
  1051|         0|            0|            0|  0.00%|            dims_val = int(dims.item())
  1052|         0|            0|            0|  0.00%|            if dims_val < 0:
  1053|         0|            0|            0|  0.00%|                raise RuntimeError(f"tensordot expects dims >= 0, but got dims={dims}")
  1054|         0|            0|            0|  0.00%|            dims_a = list(range(-dims_val, 0))
  1055|         0|            0|            0|  0.00%|            dims_b = list(range(dims_val))
  1056|         0|            0|            0|  0.00%|
  1057|         0|            0|            0|  0.00%|    if isinstance(dims, int):
  1058|         0|            0|            0|  0.00%|        if dims < 0:
  1059|         0|            0|            0|  0.00%|            raise RuntimeError(f"tensordot expects dims >= 0, but got dims={dims}")
  1060|         0|            0|            0|  0.00%|        dims_a = list(range(-dims, 0))
  1061|         0|            0|            0|  0.00%|        dims_b = list(range(dims))
  1062|         0|            0|            0|  0.00%|
  1063|         0|            0|            0|  0.00%|    if out is None:
  1064|         0|            0|            0|  0.00%|        return _VF.tensordot(a, b, dims_a, dims_b)  # type: ignore[attr-defined]
  1065|         0|            0|            0|  0.00%|    else:
  1066|         0|            0|            0|  0.00%|        return _VF.tensordot(a, b, dims_a, dims_b, out=out)  # type: ignore[attr-defined]
  1067|         0|            0|            0|  0.00%|
  1068|         0|            0|            0|  0.00%|def cartesian_prod(*tensors):
  1069|         0|            0|            0|  0.00%|    """Do cartesian product of the given sequence of tensors. The behavior is similar to
  1070|         0|            0|            0|  0.00%|    python's `itertools.product`.
  1071|         0|            0|            0|  0.00%|
  1072|         0|            0|            0|  0.00%|    Args:
  1073|         0|            0|            0|  0.00%|        *tensors: any number of 1 dimensional tensors.
  1074|         0|            0|            0|  0.00%|
  1075|         0|            0|            0|  0.00%|    Returns:
  1076|         0|            0|            0|  0.00%|        Tensor: A tensor equivalent to converting all the input tensors into lists,
  1077|         0|            0|            0|  0.00%|        do `itertools.product` on these lists, and finally convert the resulting list
  1078|         0|            0|            0|  0.00%|        into tensor.
  1079|         0|            0|            0|  0.00%|
  1080|         0|            0|            0|  0.00%|    Example::
  1081|         0|            0|            0|  0.00%|
  1082|         0|            0|            0|  0.00%|        >>> a = [1, 2, 3]
  1083|         0|            0|            0|  0.00%|        >>> b = [4, 5]
  1084|         0|            0|            0|  0.00%|        >>> list(itertools.product(a, b))
  1085|         0|            0|            0|  0.00%|        [(1, 4), (1, 5), (2, 4), (2, 5), (3, 4), (3, 5)]
  1086|         0|            0|            0|  0.00%|        >>> tensor_a = torch.tensor(a)
  1087|         0|            0|            0|  0.00%|        >>> tensor_b = torch.tensor(b)
  1088|         0|            0|            0|  0.00%|        >>> torch.cartesian_prod(tensor_a, tensor_b)
  1089|         0|            0|            0|  0.00%|        tensor([[1, 4],
  1090|         0|            0|            0|  0.00%|                [1, 5],
  1091|         0|            0|            0|  0.00%|                [2, 4],
  1092|         0|            0|            0|  0.00%|                [2, 5],
  1093|         0|            0|            0|  0.00%|                [3, 4],
  1094|         0|            0|            0|  0.00%|                [3, 5]])
  1095|         0|            0|            0|  0.00%|    """
  1096|         0|            0|            0|  0.00%|    # This wrapper exists to support variadic args.
  1097|         0|            0|            0|  0.00%|    if has_torch_function(tensors):
  1098|         0|            0|            0|  0.00%|        return handle_torch_function(cartesian_prod, tensors, *tensors)
  1099|         0|            0|            0|  0.00%|    return _VF.cartesian_prod(tensors)  # type: ignore[attr-defined]
  1100|         0|            0|            0|  0.00%|
  1101|         0|            0|            0|  0.00%|def block_diag(*tensors):
  1102|         0|            0|            0|  0.00%|    """Create a block diagonal matrix from provided tensors.
  1103|         0|            0|            0|  0.00%|
  1104|         0|            0|            0|  0.00%|    Args:
  1105|         0|            0|            0|  0.00%|        *tensors: One or more tensors with 0, 1, or 2 dimensions.
  1106|         0|            0|            0|  0.00%|
  1107|         0|            0|            0|  0.00%|    Returns:
  1108|         0|            0|            0|  0.00%|        Tensor: A 2 dimensional tensor with all the input tensors arranged in
  1109|         0|            0|            0|  0.00%|        order such that their upper left and lower right corners are
  1110|         0|            0|            0|  0.00%|        diagonally adjacent. All other elements are set to 0.
  1111|         0|            0|            0|  0.00%|
  1112|         0|            0|            0|  0.00%|    Example::
  1113|         0|            0|            0|  0.00%|
  1114|         0|            0|            0|  0.00%|        >>> import torch
  1115|         0|            0|            0|  0.00%|        >>> A = torch.tensor([[0, 1], [1, 0]])
  1116|         0|            0|            0|  0.00%|        >>> B = torch.tensor([[3, 4, 5], [6, 7, 8]])
  1117|         0|            0|            0|  0.00%|        >>> C = torch.tensor(7)
  1118|         0|            0|            0|  0.00%|        >>> D = torch.tensor([1, 2, 3])
  1119|         0|            0|            0|  0.00%|        >>> E = torch.tensor([[4], [5], [6]])
  1120|         0|            0|            0|  0.00%|        >>> torch.block_diag(A, B, C, D, E)
  1121|         0|            0|            0|  0.00%|        tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
  1122|         0|            0|            0|  0.00%|                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
  1123|         0|            0|            0|  0.00%|                [0, 0, 3, 4, 5, 0, 0, 0, 0, 0],
  1124|         0|            0|            0|  0.00%|                [0, 0, 6, 7, 8, 0, 0, 0, 0, 0],
  1125|         0|            0|            0|  0.00%|                [0, 0, 0, 0, 0, 7, 0, 0, 0, 0],
  1126|         0|            0|            0|  0.00%|                [0, 0, 0, 0, 0, 0, 1, 2, 3, 0],
  1127|         0|            0|            0|  0.00%|                [0, 0, 0, 0, 0, 0, 0, 0, 0, 4],
  1128|         0|            0|            0|  0.00%|                [0, 0, 0, 0, 0, 0, 0, 0, 0, 5],
  1129|         0|            0|            0|  0.00%|                [0, 0, 0, 0, 0, 0, 0, 0, 0, 6]])
  1130|         0|            0|            0|  0.00%|    """
  1131|         0|            0|            0|  0.00%|    # This wrapper exists to support variadic args.
  1132|         0|            0|            0|  0.00%|    if has_torch_function(tensors):
  1133|         0|            0|            0|  0.00%|        return handle_torch_function(block_diag, tensors, *tensors)
  1134|         0|            0|            0|  0.00%|    return torch._C._VariableFunctions.block_diag(tensors)  # type: ignore[attr-defined]
  1135|         0|            0|            0|  0.00%|
  1136|         0|            0|            0|  0.00%|
  1137|         0|            0|            0|  0.00%|def cdist(x1, x2, p=2., compute_mode='use_mm_for_euclid_dist_if_necessary'):
  1138|         0|            0|            0|  0.00%|    # type: (Tensor, Tensor, float, str) -> (Tensor)
  1139|         0|            0|            0|  0.00%|    r"""Computes batched the p-norm distance between each pair of the two collections of row vectors.
  1140|         0|            0|            0|  0.00%|
  1141|         0|            0|            0|  0.00%|    Args:
  1142|         0|            0|            0|  0.00%|        x1 (Tensor): input tensor of shape :math:`B \times P \times M`.
  1143|         0|            0|            0|  0.00%|        x2 (Tensor): input tensor of shape :math:`B \times R \times M`.
  1144|         0|            0|            0|  0.00%|        p: p value for the p-norm distance to calculate between each vector pair
  1145|         0|            0|            0|  0.00%|            :math:`\in [0, \infty]`.
  1146|         0|            0|            0|  0.00%|        compute_mode:
  1147|         0|            0|            0|  0.00%|            'use_mm_for_euclid_dist_if_necessary' - will use matrix multiplication approach to calculate
  1148|         0|            0|            0|  0.00%|            euclidean distance (p = 2) if P > 25 or R > 25
  1149|         0|            0|            0|  0.00%|            'use_mm_for_euclid_dist' - will always use matrix multiplication approach to calculate
  1150|         0|            0|            0|  0.00%|            euclidean distance (p = 2)
  1151|         0|            0|            0|  0.00%|            'donot_use_mm_for_euclid_dist' - will never use matrix multiplication approach to calculate
  1152|         0|            0|            0|  0.00%|            euclidean distance (p = 2)
  1153|         0|            0|            0|  0.00%|            Default: use_mm_for_euclid_dist_if_necessary.
  1154|         0|            0|            0|  0.00%|
  1155|         0|            0|            0|  0.00%|    If x1 has shape :math:`B \times P \times M` and x2 has shape :math:`B \times R \times M` then the
  1156|         0|            0|            0|  0.00%|    output will have shape :math:`B \times P \times R`.
  1157|         0|            0|            0|  0.00%|
  1158|         0|            0|            0|  0.00%|    This function is equivalent to `scipy.spatial.distance.cdist(input,'minkowski', p=p)`
  1159|         0|            0|            0|  0.00%|    if :math:`p \in (0, \infty)`. When :math:`p = 0` it is equivalent to
  1160|         0|            0|            0|  0.00%|    `scipy.spatial.distance.cdist(input, 'hamming') * M`. When :math:`p = \infty`, the closest
  1161|         0|            0|            0|  0.00%|    scipy function is `scipy.spatial.distance.cdist(xn, lambda x, y: np.abs(x - y).max())`.
  1162|         0|            0|            0|  0.00%|
  1163|         0|            0|            0|  0.00%|    Example:
  1164|         0|            0|            0|  0.00%|
  1165|         0|            0|            0|  0.00%|        >>> a = torch.tensor([[0.9041,  0.0196], [-0.3108, -2.4423], [-0.4821,  1.059]])
  1166|         0|            0|            0|  0.00%|        >>> a
  1167|         0|            0|            0|  0.00%|        tensor([[ 0.9041,  0.0196],
  1168|         0|            0|            0|  0.00%|                [-0.3108, -2.4423],
  1169|         0|            0|            0|  0.00%|                [-0.4821,  1.0590]])
  1170|         0|            0|            0|  0.00%|        >>> b = torch.tensor([[-2.1763, -0.4713], [-0.6986,  1.3702]])
  1171|         0|            0|            0|  0.00%|        >>> b
  1172|         0|            0|            0|  0.00%|        tensor([[-2.1763, -0.4713],
  1173|         0|            0|            0|  0.00%|                [-0.6986,  1.3702]])
  1174|         0|            0|            0|  0.00%|        >>> torch.cdist(a, b, p=2)
  1175|         0|            0|            0|  0.00%|        tensor([[3.1193, 2.0959],
  1176|         0|            0|            0|  0.00%|                [2.7138, 3.8322],
  1177|         0|            0|            0|  0.00%|                [2.2830, 0.3791]])
  1178|         0|            0|            0|  0.00%|    """
  1179|         0|            0|            0|  0.00%|    if has_torch_function_variadic(x1, x2):
  1180|         0|            0|            0|  0.00%|        return handle_torch_function(
  1181|         0|            0|            0|  0.00%|            cdist, (x1, x2), x1, x2, p=p, compute_mode=compute_mode)
  1182|         0|            0|            0|  0.00%|    if compute_mode == 'use_mm_for_euclid_dist_if_necessary':
  1183|         0|            0|            0|  0.00%|        return _VF.cdist(x1, x2, p, None)  # type: ignore[attr-defined]
  1184|         0|            0|            0|  0.00%|    elif compute_mode == 'use_mm_for_euclid_dist':
  1185|         0|            0|            0|  0.00%|        return _VF.cdist(x1, x2, p, 1)  # type: ignore[attr-defined]
  1186|         0|            0|            0|  0.00%|    elif compute_mode == 'donot_use_mm_for_euclid_dist':
  1187|         0|            0|            0|  0.00%|        return _VF.cdist(x1, x2, p, 2)  # type: ignore[attr-defined]
  1188|         0|            0|            0|  0.00%|    else:
  1189|         0|            0|            0|  0.00%|        raise ValueError(f"{compute_mode} is not a valid value for compute_mode")
  1190|         0|            0|            0|  0.00%|
  1191|         0|            0|            0|  0.00%|def atleast_1d(*tensors):
  1192|         0|            0|            0|  0.00%|    r"""
  1193|         0|            0|            0|  0.00%|    Returns a 1-dimensional view of each input tensor with zero dimensions.
  1194|         0|            0|            0|  0.00%|    Input tensors with one or more dimensions are returned as-is.
  1195|         0|            0|            0|  0.00%|
  1196|         0|            0|            0|  0.00%|    Args:
  1197|         0|            0|            0|  0.00%|        input (Tensor or list of Tensors)
  1198|         0|            0|            0|  0.00%|
  1199|         0|            0|            0|  0.00%|    Returns:
  1200|         0|            0|            0|  0.00%|        output (Tensor or tuple of Tensors)
  1201|         0|            0|            0|  0.00%|
  1202|         0|            0|            0|  0.00%|    Example::
  1203|         0|            0|            0|  0.00%|
  1204|         0|            0|            0|  0.00%|        >>> x = torch.randn(2)
  1205|         0|            0|            0|  0.00%|        >>> x
  1206|         0|            0|            0|  0.00%|        tensor([1.4584, 0.7583])
  1207|         0|            0|            0|  0.00%|        >>> torch.atleast_1d(x)
  1208|         0|            0|            0|  0.00%|        tensor([1.4584, 0.7583])
  1209|         0|            0|            0|  0.00%|        >>> x = torch.tensor(1.)
  1210|         0|            0|            0|  0.00%|        >>> x
  1211|         0|            0|            0|  0.00%|        tensor(1.)
  1212|         0|            0|            0|  0.00%|        >>> torch.atleast_1d(x)
  1213|         0|            0|            0|  0.00%|        tensor([1.])
  1214|         0|            0|            0|  0.00%|        >>> x = torch.tensor(0.5)
  1215|         0|            0|            0|  0.00%|        >>> y = torch.tensor(1.)
  1216|         0|            0|            0|  0.00%|        >>> torch.atleast_1d((x,y))
  1217|         0|            0|            0|  0.00%|        (tensor([0.5000]), tensor([1.]))
  1218|         0|            0|            0|  0.00%|    """
  1219|         0|            0|            0|  0.00%|    # This wrapper exists to support variadic args.
  1220|         0|            0|            0|  0.00%|    if has_torch_function(tensors):
  1221|         0|            0|            0|  0.00%|        return handle_torch_function(atleast_1d, tensors, *tensors)
  1222|         0|            0|            0|  0.00%|    if len(tensors) == 1:
  1223|         0|            0|            0|  0.00%|        tensors = tensors[0]
  1224|         0|            0|            0|  0.00%|    return _VF.atleast_1d(tensors)  # type: ignore[attr-defined]
  1225|         0|            0|            0|  0.00%|
  1226|         0|            0|            0|  0.00%|def atleast_2d(*tensors):
  1227|         0|            0|            0|  0.00%|    r"""
  1228|         0|            0|            0|  0.00%|    Returns a 2-dimensional view of each input tensor with zero dimensions.
  1229|         0|            0|            0|  0.00%|    Input tensors with two or more dimensions are returned as-is.
  1230|         0|            0|            0|  0.00%|
  1231|         0|            0|            0|  0.00%|    Args:
  1232|         0|            0|            0|  0.00%|        input (Tensor or list of Tensors)
  1233|         0|            0|            0|  0.00%|
  1234|         0|            0|            0|  0.00%|    Returns:
  1235|         0|            0|            0|  0.00%|        output (Tensor or tuple of Tensors)
  1236|         0|            0|            0|  0.00%|
  1237|         0|            0|            0|  0.00%|    Example::
  1238|         0|            0|            0|  0.00%|
  1239|         0|            0|            0|  0.00%|        >>> x = torch.tensor(1.)
  1240|         0|            0|            0|  0.00%|        >>> x
  1241|         0|            0|            0|  0.00%|        tensor(1.)
  1242|         0|            0|            0|  0.00%|        >>> torch.atleast_2d(x)
  1243|         0|            0|            0|  0.00%|        tensor([[1.]])
  1244|         0|            0|            0|  0.00%|        >>> x = torch.randn(2,2)
  1245|         0|            0|            0|  0.00%|        >>> x
  1246|         0|            0|            0|  0.00%|        tensor([[2.2086, 2.5165],
  1247|         0|            0|            0|  0.00%|                [0.1757, 0.5194]])
  1248|         0|            0|            0|  0.00%|        >>> torch.atleast_2d(x)
  1249|         0|            0|            0|  0.00%|        tensor([[2.2086, 2.5165],
  1250|         0|            0|            0|  0.00%|                [0.1757, 0.5194]])
  1251|         0|            0|            0|  0.00%|        >>> x = torch.tensor(0.5)
  1252|         0|            0|            0|  0.00%|        >>> y = torch.tensor(1.)
  1253|         0|            0|            0|  0.00%|        >>> torch.atleast_2d((x,y))
  1254|         0|            0|            0|  0.00%|        (tensor([[0.5000]]), tensor([[1.]]))
  1255|         0|            0|            0|  0.00%|    """
  1256|         0|            0|            0|  0.00%|    # This wrapper exists to support variadic args.
  1257|         0|            0|            0|  0.00%|    if has_torch_function(tensors):
  1258|         0|            0|            0|  0.00%|        return handle_torch_function(atleast_2d, tensors, *tensors)
  1259|         0|            0|            0|  0.00%|    if len(tensors) == 1:
  1260|         0|            0|            0|  0.00%|        tensors = tensors[0]
  1261|         0|            0|            0|  0.00%|    return _VF.atleast_2d(tensors)  # type: ignore[attr-defined]
  1262|         0|            0|            0|  0.00%|
  1263|         0|            0|            0|  0.00%|def atleast_3d(*tensors):
  1264|         0|            0|            0|  0.00%|    r"""
  1265|         0|            0|            0|  0.00%|    Returns a 3-dimensional view of each input tensor with zero dimensions.
  1266|         0|            0|            0|  0.00%|    Input tensors with three or more dimensions are returned as-is.
  1267|         0|            0|            0|  0.00%|
  1268|         0|            0|            0|  0.00%|    Args:
  1269|         0|            0|            0|  0.00%|        input (Tensor or list of Tensors)
  1270|         0|            0|            0|  0.00%|
  1271|         0|            0|            0|  0.00%|    Returns:
  1272|         0|            0|            0|  0.00%|        output (Tensor or tuple of Tensors)
  1273|         0|            0|            0|  0.00%|
  1274|         0|            0|            0|  0.00%|    Example:
  1275|         0|            0|            0|  0.00%|
  1276|         0|            0|            0|  0.00%|        >>> x = torch.tensor(0.5)
  1277|         0|            0|            0|  0.00%|        >>> x
  1278|         0|            0|            0|  0.00%|        tensor(0.5000)
  1279|         0|            0|            0|  0.00%|        >>> torch.atleast_3d(x)
  1280|         0|            0|            0|  0.00%|        tensor([[[0.5000]]])
  1281|         0|            0|            0|  0.00%|        >>> y = torch.randn(2,2)
  1282|         0|            0|            0|  0.00%|        >>> y
  1283|         0|            0|            0|  0.00%|        tensor([[-0.8079,  0.7460],
  1284|         0|            0|            0|  0.00%|                [-1.1647,  1.4734]])
  1285|         0|            0|            0|  0.00%|        >>> torch.atleast_3d(y)
  1286|         0|            0|            0|  0.00%|        tensor([[[-0.8079],
  1287|         0|            0|            0|  0.00%|                [ 0.7460]],
  1288|         0|            0|            0|  0.00%|                <BLANKLINE>
  1289|         0|            0|            0|  0.00%|                [[-1.1647],
  1290|         0|            0|            0|  0.00%|                [ 1.4734]]])
  1291|         0|            0|            0|  0.00%|        >>> x = torch.randn(1,1,1)
  1292|         0|            0|            0|  0.00%|        >>> x
  1293|         0|            0|            0|  0.00%|        tensor([[[-1.5689]]])
  1294|         0|            0|            0|  0.00%|        >>> torch.atleast_3d(x)
  1295|         0|            0|            0|  0.00%|        tensor([[[-1.5689]]])
  1296|         0|            0|            0|  0.00%|        >>> x = torch.tensor(0.5)
  1297|         0|            0|            0|  0.00%|        >>> y = torch.tensor(1.)
  1298|         0|            0|            0|  0.00%|        >>> torch.atleast_3d((x,y))
  1299|         0|            0|            0|  0.00%|        (tensor([[[0.5000]]]), tensor([[[1.]]]))
  1300|         0|            0|            0|  0.00%|    """
  1301|         0|            0|            0|  0.00%|    # This wrapper exists to support variadic args.
  1302|         0|            0|            0|  0.00%|    if has_torch_function(tensors):
  1303|         0|            0|            0|  0.00%|        return handle_torch_function(atleast_3d, tensors, *tensors)
  1304|         0|            0|            0|  0.00%|    if len(tensors) == 1:
  1305|         0|            0|            0|  0.00%|        tensors = tensors[0]
  1306|         0|            0|            0|  0.00%|    return _VF.atleast_3d(tensors)  # type: ignore[attr-defined]
  1307|         0|            0|            0|  0.00%|
  1308|         0|            0|            0|  0.00%|
  1309|         0|            0|            0|  0.00%|if TYPE_CHECKING:
  1310|         0|            0|            0|  0.00%|    pass
  1311|         0|            0|            0|  0.00%|    # There's no good way to use this type annotation; cannot rename norm() to
  1312|         0|            0|            0|  0.00%|    # _norm_impl() in a way that doesn't break JIT overloads. So leave untyped
  1313|         0|            0|            0|  0.00%|    # for mypy for now.
  1314|         0|            0|            0|  0.00%|    #    def norm(input: Tensor,
  1315|         0|            0|            0|  0.00%|    #             p: Optional[Union[str, Number]] = "fro",
  1316|         0|            0|            0|  0.00%|    #             dim: Optional[Union[int, List[int]]] = None,
  1317|         0|            0|            0|  0.00%|    #             keepdim: bool = False,
  1318|         0|            0|            0|  0.00%|    #             out: Optional[Tensor] = None,
  1319|         0|            0|            0|  0.00%|    #             dtype: _dtype = None) -> Tensor:
  1320|         0|            0|            0|  0.00%|    #        return _norm_impl(input, p, dim, keepdim, out, dtype)
  1321|         0|            0|            0|  0.00%|else:
  1322|         0|            0|            0|  0.00%|    # TODO: type dim as BroadcastingList when
  1323|         0|            0|            0|  0.00%|    # https://github.com/pytorch/pytorch/issues/33782 is fixed
  1324|         0|            0|            0|  0.00%|    @overload
  1325|         0|            0|            0|  0.00%|    def norm(input, p="fro", dim=None, keepdim=False, out=None, dtype=None):
  1326|         0|            0|            0|  0.00%|        # type: (Tensor, str, Optional[List[int]], bool, Optional[Tensor], Optional[int]) -> Tensor
  1327|         0|            0|            0|  0.00%|        pass
  1328|         0|            0|            0|  0.00%|
  1329|         0|            0|            0|  0.00%|    @overload  # noqa: F811
  1330|         0|            0|            0|  0.00%|    def norm(input, p="fro", dim=None, keepdim=False, out=None, dtype=None):  # noqa: F811
  1331|         0|            0|            0|  0.00%|        # type: (Tensor, Optional[number], Optional[List[int]], bool, Optional[Tensor], Optional[int]) -> Tensor
  1332|         0|            0|            0|  0.00%|        pass
  1333|         0|            0|            0|  0.00%|
  1334|         0|            0|            0|  0.00%|    @overload  # noqa: F811
  1335|         0|            0|            0|  0.00%|    def norm(input, p="fro", dim=None, keepdim=False, out=None, dtype=None):  # noqa: F811
  1336|         0|            0|            0|  0.00%|        # type: (Tensor, Optional[number], Optional[int], bool, Optional[Tensor], Optional[int]) -> Tensor
  1337|         0|            0|            0|  0.00%|        pass
  1338|         0|            0|            0|  0.00%|
  1339|         0|            0|            0|  0.00%|    @overload  # noqa: F811
  1340|         0|            0|            0|  0.00%|    def norm(input, p="fro", dim=None, keepdim=False, out=None, dtype=None):  # noqa: F811
  1341|         0|            0|            0|  0.00%|        # type: (Tensor, str, Optional[int], bool, Optional[Tensor], Optional[int]) -> Tensor
  1342|         0|            0|            0|  0.00%|        pass
  1343|         0|            0|            0|  0.00%|
  1344|         0|            0|            0|  0.00%|
  1345|      3744|   0.00854468|  2.28223e-06|  0.01%|def norm(input, p="fro", dim=None, keepdim=False, out=None, dtype=None):  # noqa: F811
  1346|         0|            0|            0|  0.00%|    r"""Returns the matrix norm or vector norm of a given tensor.
  1347|         0|            0|            0|  0.00%|
  1348|         0|            0|            0|  0.00%|    .. warning::
  1349|         0|            0|            0|  0.00%|
  1350|         0|            0|            0|  0.00%|        torch.norm is deprecated and may be removed in a future PyTorch release.
  1351|         0|            0|            0|  0.00%|        Its documentation and behavior may be incorrect, and it is no longer
  1352|         0|            0|            0|  0.00%|        actively maintained.
  1353|         0|            0|            0|  0.00%|
  1354|         0|            0|            0|  0.00%|        Use :func:`torch.linalg.norm`, instead, or :func:`torch.linalg.vector_norm`
  1355|         0|            0|            0|  0.00%|        when computing vector norms and :func:`torch.linalg.matrix_norm` when
  1356|         0|            0|            0|  0.00%|        computing matrix norms. Note, however, the signature for these functions
  1357|         0|            0|            0|  0.00%|        is slightly different than the signature for torch.norm.
  1358|         0|            0|            0|  0.00%|
  1359|         0|            0|            0|  0.00%|    Args:
  1360|         0|            0|            0|  0.00%|        input (Tensor): The input tensor. Its data type must be either a floating
  1361|         0|            0|            0|  0.00%|            point or complex type. For complex inputs, the norm is calculated using the
  1362|         0|            0|            0|  0.00%|            absolute value of each element. If the input is complex and neither
  1363|         0|            0|            0|  0.00%|            :attr:`dtype` nor :attr:`out` is specified, the result's data type will
  1364|         0|            0|            0|  0.00%|            be the corresponding floating point type (e.g. float if :attr:`input` is
  1365|         0|            0|            0|  0.00%|            complexfloat).
  1366|         0|            0|            0|  0.00%|
  1367|         0|            0|            0|  0.00%|        p (int, float, inf, -inf, 'fro', 'nuc', optional): the order of norm. Default: ``'fro'``
  1368|         0|            0|            0|  0.00%|            The following norms can be calculated:
  1369|         0|            0|            0|  0.00%|
  1370|         0|            0|            0|  0.00%|            ======  ==============  ==========================
  1371|         0|            0|            0|  0.00%|            ord     matrix norm     vector norm
  1372|         0|            0|            0|  0.00%|            ======  ==============  ==========================
  1373|         0|            0|            0|  0.00%|            'fro'   Frobenius norm  --
  1374|         0|            0|            0|  0.00%|            'nuc'   nuclear norm    --
  1375|         0|            0|            0|  0.00%|            Number  --              sum(abs(x)**ord)**(1./ord)
  1376|         0|            0|            0|  0.00%|            ======  ==============  ==========================
  1377|         0|            0|            0|  0.00%|
  1378|         0|            0|            0|  0.00%|            The vector norm can be calculated across any number of dimensions.
  1379|         0|            0|            0|  0.00%|            The corresponding dimensions of :attr:`input` are flattened into
  1380|         0|            0|            0|  0.00%|            one dimension, and the norm is calculated on the flattened
  1381|         0|            0|            0|  0.00%|            dimension.
  1382|         0|            0|            0|  0.00%|
  1383|         0|            0|            0|  0.00%|            Frobenius norm produces the same result as ``p=2`` in all cases
  1384|         0|            0|            0|  0.00%|            except when :attr:`dim` is a list of three or more dims, in which
  1385|         0|            0|            0|  0.00%|            case Frobenius norm throws an error.
  1386|         0|            0|            0|  0.00%|
  1387|         0|            0|            0|  0.00%|            Nuclear norm can only be calculated across exactly two dimensions.
  1388|         0|            0|            0|  0.00%|
  1389|         0|            0|            0|  0.00%|        dim (int, tuple of ints, list of ints, optional):
  1390|         0|            0|            0|  0.00%|            Specifies which dimension or dimensions of :attr:`input` to
  1391|         0|            0|            0|  0.00%|            calculate the norm across. If :attr:`dim` is ``None``, the norm will
  1392|         0|            0|            0|  0.00%|            be calculated across all dimensions of :attr:`input`. If the norm
  1393|         0|            0|            0|  0.00%|            type indicated by :attr:`p` does not support the specified number of
  1394|         0|            0|            0|  0.00%|            dimensions, an error will occur.
  1395|         0|            0|            0|  0.00%|        keepdim (bool, optional): whether the output tensors have :attr:`dim`
  1396|         0|            0|            0|  0.00%|            retained or not. Ignored if :attr:`dim` = ``None`` and
  1397|         0|            0|            0|  0.00%|            :attr:`out` = ``None``. Default: ``False``
  1398|         0|            0|            0|  0.00%|        out (Tensor, optional): the output tensor. Ignored if
  1399|         0|            0|            0|  0.00%|            :attr:`dim` = ``None`` and :attr:`out` = ``None``.
  1400|         0|            0|            0|  0.00%|        dtype (:class:`torch.dtype`, optional): the desired data type of
  1401|         0|            0|            0|  0.00%|            returned tensor. If specified, the input tensor is casted to
  1402|         0|            0|            0|  0.00%|            :attr:`dtype` while performing the operation. Default: None.
  1403|         0|            0|            0|  0.00%|
  1404|         0|            0|            0|  0.00%|    .. note::
  1405|         0|            0|            0|  0.00%|        Even though ``p='fro'`` supports any number of dimensions, the true
  1406|         0|            0|            0|  0.00%|        mathematical definition of Frobenius norm only applies to tensors with
  1407|         0|            0|            0|  0.00%|        exactly two dimensions. :func:`torch.linalg.norm` with ``ord='fro'`` aligns
  1408|         0|            0|            0|  0.00%|        with the mathematical definition, since it can only be applied across
  1409|         0|            0|            0|  0.00%|        exactly two dimensions.
  1410|         0|            0|            0|  0.00%|
  1411|         0|            0|            0|  0.00%|    Example::
  1412|         0|            0|            0|  0.00%|
  1413|         0|            0|            0|  0.00%|        >>> import torch
  1414|         0|            0|            0|  0.00%|        >>> a = torch.arange(9, dtype= torch.float) - 4
  1415|         0|            0|            0|  0.00%|        >>> b = a.reshape((3, 3))
  1416|         0|            0|            0|  0.00%|        >>> torch.norm(a)
  1417|         0|            0|            0|  0.00%|        tensor(7.7460)
  1418|         0|            0|            0|  0.00%|        >>> torch.norm(b)
  1419|         0|            0|            0|  0.00%|        tensor(7.7460)
  1420|         0|            0|            0|  0.00%|        >>> torch.norm(a, float('inf'))
  1421|         0|            0|            0|  0.00%|        tensor(4.)
  1422|         0|            0|            0|  0.00%|        >>> torch.norm(b, float('inf'))
  1423|         0|            0|            0|  0.00%|        tensor(4.)
  1424|         0|            0|            0|  0.00%|        >>> c = torch.tensor([[ 1, 2, 3],[-1, 1, 4]] , dtype= torch.float)
  1425|         0|            0|            0|  0.00%|        >>> torch.norm(c, dim=0)
  1426|         0|            0|            0|  0.00%|        tensor([1.4142, 2.2361, 5.0000])
  1427|         0|            0|            0|  0.00%|        >>> torch.norm(c, dim=1)
  1428|         0|            0|            0|  0.00%|        tensor([3.7417, 4.2426])
  1429|         0|            0|            0|  0.00%|        >>> torch.norm(c, p=1, dim=1)
  1430|         0|            0|            0|  0.00%|        tensor([6., 6.])
  1431|         0|            0|            0|  0.00%|        >>> d = torch.arange(8, dtype= torch.float).reshape(2,2,2)
  1432|         0|            0|            0|  0.00%|        >>> torch.norm(d, dim=(1,2))
  1433|         0|            0|            0|  0.00%|        tensor([ 3.7417, 11.2250])
  1434|         0|            0|            0|  0.00%|        >>> torch.norm(d[0, :, :]), torch.norm(d[1, :, :])
  1435|         0|            0|            0|  0.00%|        (tensor(3.7417), tensor(11.2250))
  1436|         0|            0|            0|  0.00%|    """
  1437|         0|            0|            0|  0.00%|
  1438|      3744|    0.0092051|  2.45863e-06|  0.01%|    if has_torch_function_unary(input):
  1439|         0|            0|            0|  0.00%|        return handle_torch_function(
  1440|         0|            0|            0|  0.00%|            norm, (input,), input, p=p, dim=dim, keepdim=keepdim, out=out, dtype=dtype)
  1441|         0|            0|            0|  0.00%|
  1442|      3744|   0.00912666|  2.43768e-06|  0.01%|    ndim = input.dim()
  1443|         0|            0|            0|  0.00%|
  1444|         0|            0|            0|  0.00%|    # catch default case
  1445|      3744|   0.00819874|  2.18983e-06|  0.01%|    if dim is None and out is None and dtype is None and p is not None:
  1446|      3744|   0.00839472|  2.24218e-06|  0.01%|        if isinstance(p, str):
  1447|         0|            0|            0|  0.00%|            if p == "fro":
  1448|         0|            0|            0|  0.00%|                return _VF.frobenius_norm(input, dim=(), keepdim=keepdim)
  1449|      3744|   0.00794387|  2.12176e-06|  0.01%|        if not isinstance(p, str):
  1450|     16704|     0.046165|  2.76371e-06|  0.04%|            _dim = [i for i in range(ndim)]  # noqa: C416 TODO: rewrite as list(range(m))
(call)|      3744|    0.0212388|  5.67276e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/functional.py:1450 <listcomp>
  1451|      3744|    0.0603709|  1.61247e-05|  0.06%|            return _VF.norm(input, p, dim=_dim, keepdim=keepdim)  # type: ignore[attr-defined]
(call)|      3744|    0.0130982|  3.49846e-06|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_VF.py:25 __getattr__
  1452|         0|            0|            0|  0.00%|
  1453|         0|            0|            0|  0.00%|    # TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed
  1454|         0|            0|            0|  0.00%|    # remove the overloads where dim is an int and replace with BraodcastingList1
  1455|         0|            0|            0|  0.00%|    # and remove next four lines, replace _dim with dim
  1456|         0|            0|            0|  0.00%|    if dim is not None:
  1457|         0|            0|            0|  0.00%|        if isinstance(dim, int):
  1458|         0|            0|            0|  0.00%|            _dim = [dim]
  1459|         0|            0|            0|  0.00%|        else:
  1460|         0|            0|            0|  0.00%|            _dim = dim
  1461|         0|            0|            0|  0.00%|    else:
  1462|         0|            0|            0|  0.00%|        _dim = None  # type: ignore[assignment]
  1463|         0|            0|            0|  0.00%|
  1464|         0|            0|            0|  0.00%|    if isinstance(p, str):
  1465|         0|            0|            0|  0.00%|        if p == "fro":
  1466|         0|            0|            0|  0.00%|            if dtype is not None:
  1467|         0|            0|            0|  0.00%|                raise ValueError("dtype argument is not supported in frobenius norm")
  1468|         0|            0|            0|  0.00%|
  1469|         0|            0|            0|  0.00%|            if _dim is None:
  1470|         0|            0|            0|  0.00%|                _dim = list(range(ndim))
  1471|         0|            0|            0|  0.00%|            if out is None:
  1472|         0|            0|            0|  0.00%|                return _VF.frobenius_norm(input, _dim, keepdim=keepdim)
  1473|         0|            0|            0|  0.00%|            else:
  1474|         0|            0|            0|  0.00%|                return _VF.frobenius_norm(input, _dim, keepdim=keepdim, out=out)
  1475|         0|            0|            0|  0.00%|        elif p == "nuc":
  1476|         0|            0|            0|  0.00%|            if dtype is not None:
  1477|         0|            0|            0|  0.00%|                raise ValueError("dtype argument is not supported in nuclear norm")
  1478|         0|            0|            0|  0.00%|            if _dim is None:
  1479|         0|            0|            0|  0.00%|                if out is None:
  1480|         0|            0|            0|  0.00%|                    return _VF.nuclear_norm(input, keepdim=keepdim)
  1481|         0|            0|            0|  0.00%|                else:
  1482|         0|            0|            0|  0.00%|                    return _VF.nuclear_norm(input, keepdim=keepdim, out=out)
  1483|         0|            0|            0|  0.00%|            else:
  1484|         0|            0|            0|  0.00%|                if out is None:
  1485|         0|            0|            0|  0.00%|                    return _VF.nuclear_norm(input, _dim, keepdim=keepdim)
  1486|         0|            0|            0|  0.00%|                else:
  1487|         0|            0|            0|  0.00%|                    return _VF.nuclear_norm(input, _dim, keepdim=keepdim, out=out)
  1488|         0|            0|            0|  0.00%|        raise RuntimeError(f"only valid string values are 'fro' and 'nuc', found {p}")
  1489|         0|            0|            0|  0.00%|    else:
  1490|         0|            0|            0|  0.00%|        if _dim is None:
  1491|         0|            0|            0|  0.00%|            _dim = list(range(ndim))
  1492|         0|            0|            0|  0.00%|
  1493|         0|            0|            0|  0.00%|        if out is None:
  1494|         0|            0|            0|  0.00%|            if dtype is None:
  1495|         0|            0|            0|  0.00%|                return _VF.norm(input, p, _dim, keepdim=keepdim)  # type: ignore[attr-defined]
  1496|         0|            0|            0|  0.00%|            else:
  1497|         0|            0|            0|  0.00%|                return _VF.norm(input, p, _dim, keepdim=keepdim, dtype=dtype)  # type: ignore[attr-defined]
  1498|         0|            0|            0|  0.00%|        else:
  1499|         0|            0|            0|  0.00%|            if dtype is None:
  1500|         0|            0|            0|  0.00%|                return _VF.norm(input, p, _dim, keepdim=keepdim, out=out)  # type: ignore[attr-defined]
  1501|         0|            0|            0|  0.00%|            else:
  1502|         0|            0|            0|  0.00%|                return _VF.norm(input, p, _dim, keepdim=keepdim, dtype=dtype, out=out)  # type: ignore[attr-defined]
  1503|         0|            0|            0|  0.00%|
  1504|         0|            0|            0|  0.00%|def chain_matmul(*matrices, out=None):
  1505|         0|            0|            0|  0.00%|    r"""Returns the matrix product of the :math:`N` 2-D tensors. This product is efficiently computed
  1506|         0|            0|            0|  0.00%|    using the matrix chain order algorithm which selects the order in which incurs the lowest cost in terms
  1507|         0|            0|            0|  0.00%|    of arithmetic operations (`[CLRS]`_). Note that since this is a function to compute the product, :math:`N`
  1508|         0|            0|            0|  0.00%|    needs to be greater than or equal to 2; if equal to 2 then a trivial matrix-matrix product is returned.
  1509|         0|            0|            0|  0.00%|    If :math:`N` is 1, then this is a no-op - the original matrix is returned as is.
  1510|         0|            0|            0|  0.00%|
  1511|         0|            0|            0|  0.00%|    .. warning::
  1512|         0|            0|            0|  0.00%|
  1513|         0|            0|            0|  0.00%|        :func:`torch.chain_matmul` is deprecated and will be removed in a future PyTorch release.
  1514|         0|            0|            0|  0.00%|        Use :func:`torch.linalg.multi_dot` instead, which accepts a list of two or more tensors
  1515|         0|            0|            0|  0.00%|        rather than multiple arguments.
  1516|         0|            0|            0|  0.00%|
  1517|         0|            0|            0|  0.00%|    Args:
  1518|         0|            0|            0|  0.00%|        matrices (Tensors...): a sequence of 2 or more 2-D tensors whose product is to be determined.
  1519|         0|            0|            0|  0.00%|        out (Tensor, optional): the output tensor. Ignored if :attr:`out` = ``None``.
  1520|         0|            0|            0|  0.00%|
  1521|         0|            0|            0|  0.00%|    Returns:
  1522|         0|            0|            0|  0.00%|        Tensor: if the :math:`i^{th}` tensor was of dimensions :math:`p_{i} \times p_{i + 1}`, then the product
  1523|         0|            0|            0|  0.00%|        would be of dimensions :math:`p_{1} \times p_{N + 1}`.
  1524|         0|            0|            0|  0.00%|
  1525|         0|            0|            0|  0.00%|    Example::
  1526|         0|            0|            0|  0.00%|
  1527|         0|            0|            0|  0.00%|        >>> a = torch.randn(3, 4)
  1528|         0|            0|            0|  0.00%|        >>> b = torch.randn(4, 5)
  1529|         0|            0|            0|  0.00%|        >>> c = torch.randn(5, 6)
  1530|         0|            0|            0|  0.00%|        >>> d = torch.randn(6, 7)
  1531|         0|            0|            0|  0.00%|        >>> torch.chain_matmul(a, b, c, d)
  1532|         0|            0|            0|  0.00%|        tensor([[ -2.3375,  -3.9790,  -4.1119,  -6.6577,   9.5609, -11.5095,  -3.2614],
  1533|         0|            0|            0|  0.00%|                [ 21.4038,   3.3378,  -8.4982,  -5.2457, -10.2561,  -2.4684,   2.7163],
  1534|         0|            0|            0|  0.00%|                [ -0.9647,  -5.8917,  -2.3213,  -5.2284,  12.8615, -12.2816,  -2.5095]])
  1535|         0|            0|            0|  0.00%|
  1536|         0|            0|            0|  0.00%|    .. _`[CLRS]`: https://mitpress.mit.edu/books/introduction-algorithms-third-edition
  1537|         0|            0|            0|  0.00%|    """
  1538|         0|            0|            0|  0.00%|    # This wrapper exists to support variadic args.
  1539|         0|            0|            0|  0.00%|    if has_torch_function(matrices):
  1540|         0|            0|            0|  0.00%|        return handle_torch_function(chain_matmul, matrices, *matrices)
  1541|         0|            0|            0|  0.00%|
  1542|         0|            0|            0|  0.00%|    if out is None:
  1543|         0|            0|            0|  0.00%|        return _VF.chain_matmul(matrices)  # type: ignore[attr-defined]
  1544|         0|            0|            0|  0.00%|    else:
  1545|         0|            0|            0|  0.00%|        return _VF.chain_matmul(matrices, out=out)  # type: ignore[attr-defined]
  1546|         0|            0|            0|  0.00%|
  1547|         0|            0|            0|  0.00%|
  1548|         0|            0|            0|  0.00%|def _lu_impl(A, pivot=True, get_infos=False, out=None):
  1549|         0|            0|            0|  0.00%|    # type: (Tensor, bool, bool, Any) -> Tuple[Tensor, Tensor, Tensor]
  1550|         0|            0|            0|  0.00%|    r"""Computes the LU factorization of a matrix or batches of matrices
  1551|         0|            0|            0|  0.00%|    :attr:`A`. Returns a tuple containing the LU factorization and
  1552|         0|            0|            0|  0.00%|    pivots of :attr:`A`.  Pivoting is done if :attr:`pivot` is set to
  1553|         0|            0|            0|  0.00%|    ``True``.
  1554|         0|            0|            0|  0.00%|
  1555|         0|            0|            0|  0.00%|    .. note::
  1556|         0|            0|            0|  0.00%|        * The returned permutation matrix for every matrix in the batch is
  1557|         0|            0|            0|  0.00%|          represented by a 1-indexed vector of size ``min(A.shape[-2], A.shape[-1])``.
  1558|         0|            0|            0|  0.00%|          ``pivots[i] == j`` represents that in the ``i``-th step of the algorithm,
  1559|         0|            0|            0|  0.00%|          the ``i``-th row was permuted with the ``j-1``-th row.
  1560|         0|            0|            0|  0.00%|        * LU factorization with :attr:`pivot` = ``False`` is not available
  1561|         0|            0|            0|  0.00%|          for CPU, and attempting to do so will throw an error. However,
  1562|         0|            0|            0|  0.00%|          LU factorization with :attr:`pivot` = ``False`` is available for
  1563|         0|            0|            0|  0.00%|          CUDA.
  1564|         0|            0|            0|  0.00%|        * This function does not check if the factorization was successful
  1565|         0|            0|            0|  0.00%|          or not if :attr:`get_infos` is ``True`` since the status of the
  1566|         0|            0|            0|  0.00%|          factorization is present in the third element of the return tuple.
  1567|         0|            0|            0|  0.00%|        * In the case of batches of square matrices with size less or equal
  1568|         0|            0|            0|  0.00%|          to 32 on a CUDA device, the LU factorization is repeated for
  1569|         0|            0|            0|  0.00%|          singular matrices due to the bug in the MAGMA library
  1570|         0|            0|            0|  0.00%|          (see magma issue 13).
  1571|         0|            0|            0|  0.00%|        * ``L``, ``U``, and ``P`` can be derived using :func:`torch.lu_unpack`.
  1572|         0|            0|            0|  0.00%|
  1573|         0|            0|            0|  0.00%|    .. warning::
  1574|         0|            0|            0|  0.00%|        The gradients of this function will only be finite when :attr:`A` is full rank.
  1575|         0|            0|            0|  0.00%|        This is because the LU decomposition is just differentiable at full rank matrices.
  1576|         0|            0|            0|  0.00%|        Furthermore, if :attr:`A` is close to not being full rank,
  1577|         0|            0|            0|  0.00%|        the gradient will be numerically unstable as it depends on the computation of :math:`L^{-1}` and :math:`U^{-1}`.
  1578|         0|            0|            0|  0.00%|
  1579|         0|            0|            0|  0.00%|    Args:
  1580|         0|            0|            0|  0.00%|        A (Tensor): the tensor to factor of size :math:`(*, m, n)`
  1581|         0|            0|            0|  0.00%|        pivot (bool, optional): controls whether pivoting is done. Default: ``True``
  1582|         0|            0|            0|  0.00%|        get_infos (bool, optional): if set to ``True``, returns an info IntTensor.
  1583|         0|            0|            0|  0.00%|                                    Default: ``False``
  1584|         0|            0|            0|  0.00%|        out (tuple, optional): optional output tuple. If :attr:`get_infos` is ``True``,
  1585|         0|            0|            0|  0.00%|                               then the elements in the tuple are Tensor, IntTensor,
  1586|         0|            0|            0|  0.00%|                               and IntTensor. If :attr:`get_infos` is ``False``, then the
  1587|         0|            0|            0|  0.00%|                               elements in the tuple are Tensor, IntTensor. Default: ``None``
  1588|         0|            0|            0|  0.00%|
  1589|         0|            0|            0|  0.00%|    Returns:
  1590|         0|            0|            0|  0.00%|        (Tensor, IntTensor, IntTensor (optional)): A tuple of tensors containing
  1591|         0|            0|            0|  0.00%|
  1592|         0|            0|            0|  0.00%|            - **factorization** (*Tensor*): the factorization of size :math:`(*, m, n)`
  1593|         0|            0|            0|  0.00%|
  1594|         0|            0|            0|  0.00%|            - **pivots** (*IntTensor*): the pivots of size :math:`(*, \text{min}(m, n))`.
  1595|         0|            0|            0|  0.00%|              ``pivots`` stores all the intermediate transpositions of rows.
  1596|         0|            0|            0|  0.00%|              The final permutation ``perm`` could be reconstructed by
  1597|         0|            0|            0|  0.00%|              applying ``swap(perm[i], perm[pivots[i] - 1])`` for ``i = 0, ..., pivots.size(-1) - 1``,
  1598|         0|            0|            0|  0.00%|              where ``perm`` is initially the identity permutation of :math:`m` elements
  1599|         0|            0|            0|  0.00%|              (essentially this is what :func:`torch.lu_unpack` is doing).
  1600|         0|            0|            0|  0.00%|
  1601|         0|            0|            0|  0.00%|            - **infos** (*IntTensor*, *optional*): if :attr:`get_infos` is ``True``, this is a tensor of
  1602|         0|            0|            0|  0.00%|              size :math:`(*)` where non-zero values indicate whether factorization for the matrix or
  1603|         0|            0|            0|  0.00%|              each minibatch has succeeded or failed
  1604|         0|            0|            0|  0.00%|
  1605|         0|            0|            0|  0.00%|    Example::
  1606|         0|            0|            0|  0.00%|
  1607|         0|            0|            0|  0.00%|        >>> A = torch.randn(2, 3, 3)
  1608|         0|            0|            0|  0.00%|        >>> A_LU, pivots = torch.lu(A)
  1609|         0|            0|            0|  0.00%|        >>> A_LU
  1610|         0|            0|            0|  0.00%|        tensor([[[ 1.3506,  2.5558, -0.0816],
  1611|         0|            0|            0|  0.00%|                 [ 0.1684,  1.1551,  0.1940],
  1612|         0|            0|            0|  0.00%|                 [ 0.1193,  0.6189, -0.5497]],
  1613|         0|            0|            0|  0.00%|
  1614|         0|            0|            0|  0.00%|                [[ 0.4526,  1.2526, -0.3285],
  1615|         0|            0|            0|  0.00%|                 [-0.7988,  0.7175, -0.9701],
  1616|         0|            0|            0|  0.00%|                 [ 0.2634, -0.9255, -0.3459]]])
  1617|         0|            0|            0|  0.00%|        >>> pivots
  1618|         0|            0|            0|  0.00%|        tensor([[ 3,  3,  3],
  1619|         0|            0|            0|  0.00%|                [ 3,  3,  3]], dtype=torch.int32)
  1620|         0|            0|            0|  0.00%|        >>> A_LU, pivots, info = torch.lu(A, get_infos=True)
  1621|         0|            0|            0|  0.00%|        >>> if info.nonzero().size(0) == 0:
  1622|         0|            0|            0|  0.00%|        ...   print('LU factorization succeeded for all samples!')
  1623|         0|            0|            0|  0.00%|        LU factorization succeeded for all samples!
  1624|         0|            0|            0|  0.00%|    """
  1625|         0|            0|            0|  0.00%|    # If get_infos is True, then we don't need to check for errors and vice versa
  1626|         0|            0|            0|  0.00%|    return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))
  1627|         0|            0|            0|  0.00%|
  1628|         0|            0|            0|  0.00%|if TYPE_CHECKING:
  1629|         0|            0|            0|  0.00%|    _ListOrSeq = Sequence[Tensor]
  1630|         0|            0|            0|  0.00%|else:
  1631|         0|            0|            0|  0.00%|    _ListOrSeq = List[Tensor]
  1632|         0|            0|            0|  0.00%|
  1633|         0|            0|            0|  0.00%|def _check_list_size(out_len: int, get_infos: bool, out: _ListOrSeq) -> None:
  1634|         0|            0|            0|  0.00%|    get_infos_int = 1 if get_infos else 0
  1635|         0|            0|            0|  0.00%|    if out_len - get_infos_int != 2:
  1636|         0|            0|            0|  0.00%|        raise TypeError(f"expected tuple of {2 + int(get_infos)} elements but got {out_len}")
  1637|         0|            0|            0|  0.00%|    if not isinstance(out, (tuple, list)):
  1638|         0|            0|            0|  0.00%|        raise TypeError(f"argument 'out' must be tuple of Tensors, not {type(out).__name__}")
  1639|         0|            0|            0|  0.00%|
  1640|         0|            0|            0|  0.00%|def _lu_with_infos(A, pivot=True, get_infos=False, out=None):
  1641|         0|            0|            0|  0.00%|    # type: (Tensor, bool, bool, Optional[Tuple[Tensor, Tensor, Tensor]]) -> Tuple[Tensor, Tensor, Tensor]
  1642|         0|            0|            0|  0.00%|    if has_torch_function_unary(A):
  1643|         0|            0|            0|  0.00%|        return handle_torch_function(
  1644|         0|            0|            0|  0.00%|            lu, (A,), A, pivot=pivot, get_infos=get_infos, out=out)
  1645|         0|            0|            0|  0.00%|    result = _lu_impl(A, pivot, get_infos, out)
  1646|         0|            0|            0|  0.00%|    if out is not None:
  1647|         0|            0|            0|  0.00%|        _check_list_size(len(out), get_infos, out)
  1648|         0|            0|            0|  0.00%|        for i in range(len(out)):
  1649|         0|            0|            0|  0.00%|            out[i].resize_as_(result[i]).copy_(result[i])
  1650|         0|            0|            0|  0.00%|        return out
  1651|         0|            0|            0|  0.00%|    else:
  1652|         0|            0|            0|  0.00%|        return result  # A_LU, pivots, infos
  1653|         0|            0|            0|  0.00%|
  1654|         0|            0|            0|  0.00%|def _lu_no_infos(A, pivot=True, get_infos=False, out=None):
  1655|         0|            0|            0|  0.00%|    # type: (Tensor, bool, bool, Optional[Tuple[Tensor, Tensor]]) -> Tuple[Tensor, Tensor]
  1656|         0|            0|            0|  0.00%|    # need to check for torch_function here so that we exit if
  1657|         0|            0|            0|  0.00%|    if has_torch_function_unary(A):
  1658|         0|            0|            0|  0.00%|        return handle_torch_function(
  1659|         0|            0|            0|  0.00%|            lu, (A,), A, pivot=pivot, get_infos=get_infos, out=out)
  1660|         0|            0|            0|  0.00%|    result = _lu_impl(A, pivot, get_infos, out)
  1661|         0|            0|            0|  0.00%|    if out is not None:
  1662|         0|            0|            0|  0.00%|        _check_list_size(len(out), get_infos, out)
  1663|         0|            0|            0|  0.00%|        for i in range(len(out)):
  1664|         0|            0|            0|  0.00%|            out[i].resize_as_(result[i]).copy_(result[i])
  1665|         0|            0|            0|  0.00%|        return out
  1666|         0|            0|            0|  0.00%|    else:
  1667|         0|            0|            0|  0.00%|        return result[0], result[1]  # A_LU, pivots
  1668|         0|            0|            0|  0.00%|
  1669|         0|            0|            0|  0.00%|# The return type of lu depends on `get_infos`, so in order to resolve the output type
  1670|         0|            0|            0|  0.00%|# of lu in TorchScript we need to statically know the value of `get_infos`
  1671|         0|            0|            0|  0.00%|lu = boolean_dispatch(
  1672|         0|            0|            0|  0.00%|    arg_name='get_infos',
  1673|         0|            0|            0|  0.00%|    arg_index=2,
  1674|         0|            0|            0|  0.00%|    default=False,
  1675|         0|            0|            0|  0.00%|    if_true=_lu_with_infos,
  1676|         0|            0|            0|  0.00%|    if_false=_lu_no_infos,
  1677|         0|            0|            0|  0.00%|    module_name=__name__,
  1678|         0|            0|            0|  0.00%|    func_name='lu')
  1679|         0|            0|            0|  0.00%|lu.__doc__ = _lu_impl.__doc__
  1680|         0|            0|            0|  0.00%|
  1681|         0|            0|            0|  0.00%|def align_tensors(*tensors):
  1682|         0|            0|            0|  0.00%|    raise RuntimeError('`align_tensors` not yet implemented.')
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py
File duration: 0.205432s (0.20%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import sys
     2|         0|            0|            0|  0.00%|import torch
     3|         0|            0|            0|  0.00%|import functools
     4|         0|            0|            0|  0.00%|import inspect
     5|         0|            0|            0|  0.00%|from typing import Any, Callable, TypeVar, cast
     6|         0|            0|            0|  0.00%|
     7|         0|            0|            0|  0.00%|__all__ = ['no_grad', 'enable_grad', 'set_grad_enabled',
     8|         0|            0|            0|  0.00%|           'inference_mode']
     9|         0|            0|            0|  0.00%|
    10|         0|            0|            0|  0.00%|
    11|         0|            0|            0|  0.00%|# Used for annotating the decorator usage of 'no_grad' and 'enable_grad'.
    12|         0|            0|            0|  0.00%|# See https://mypy.readthedocs.io/en/latest/generics.html#declaring-decorators
    13|         0|            0|            0|  0.00%|FuncType = Callable[..., Any]
    14|         0|            0|            0|  0.00%|F = TypeVar('F', bound=FuncType)
    15|         0|            0|            0|  0.00%|
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|class _DecoratorContextManager:
    18|         0|            0|            0|  0.00%|    """Allow a context manager to be used as a decorator"""
    19|         0|            0|            0|  0.00%|
    20|         0|            0|            0|  0.00%|    def __call__(self, func: F) -> F:
    21|         0|            0|            0|  0.00%|        if inspect.isgeneratorfunction(func):
    22|         0|            0|            0|  0.00%|            return self._wrap_generator(func)
    23|         0|            0|            0|  0.00%|
    24|       288|  0.000534296|  1.85519e-06|  0.00%|        @functools.wraps(func)
    25|         0|            0|            0|  0.00%|        def decorate_context(*args, **kwargs):
    26|       288|   0.00289869|  1.00649e-05|  0.00%|            with self.clone():
(call)|       288|   0.00734687|    2.551e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:82 clone
(call)|       288|   0.00535226|  1.85842e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:131 __enter__
    27|       288|   0.00457811|  1.58962e-05|  0.00%|                return func(*args, **kwargs)
(call)|       288|     0.713513|   0.00247748|  0.68%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/optim/adam.py:105 step
(call)|       288|   0.00593638|  2.06124e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:135 __exit__
    28|         0|            0|            0|  0.00%|        return cast(F, decorate_context)
    29|         0|            0|            0|  0.00%|
    30|         0|            0|            0|  0.00%|    def _wrap_generator(self, func):
    31|         0|            0|            0|  0.00%|        """Wrap each generator invocation with the context manager"""
    32|         0|            0|            0|  0.00%|        @functools.wraps(func)
    33|         0|            0|            0|  0.00%|        def generator_context(*args, **kwargs):
    34|         0|            0|            0|  0.00%|            gen = func(*args, **kwargs)
    35|         0|            0|            0|  0.00%|
    36|         0|            0|            0|  0.00%|            # Generators are suspended and unsuspended at `yield`, hence we
    37|         0|            0|            0|  0.00%|            # make sure the grad mode is properly set every time the execution
    38|         0|            0|            0|  0.00%|            # flow returns into the wrapped generator and restored when it
    39|         0|            0|            0|  0.00%|            # returns through our `yield` to our caller (see PR #49017).
    40|         0|            0|            0|  0.00%|            try:
    41|         0|            0|            0|  0.00%|                # Issuing `None` to a generator fires it up
    42|         0|            0|            0|  0.00%|                with self.clone():
    43|         0|            0|            0|  0.00%|                    response = gen.send(None)
    44|         0|            0|            0|  0.00%|
    45|         0|            0|            0|  0.00%|                while True:
    46|         0|            0|            0|  0.00%|                    try:
    47|         0|            0|            0|  0.00%|                        # Forward the response to our caller and get its next request
    48|         0|            0|            0|  0.00%|                        request = yield response
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|                    except GeneratorExit:
    51|         0|            0|            0|  0.00%|                        # Inform the still active generator about its imminent closure
    52|         0|            0|            0|  0.00%|                        with self.clone():
    53|         0|            0|            0|  0.00%|                            gen.close()
    54|         0|            0|            0|  0.00%|                        raise
    55|         0|            0|            0|  0.00%|
    56|         0|            0|            0|  0.00%|                    except BaseException:
    57|         0|            0|            0|  0.00%|                        # Propagate the exception thrown at us by the caller
    58|         0|            0|            0|  0.00%|                        with self.clone():
    59|         0|            0|            0|  0.00%|                            response = gen.throw(*sys.exc_info())
    60|         0|            0|            0|  0.00%|
    61|         0|            0|            0|  0.00%|                    else:
    62|         0|            0|            0|  0.00%|                        # Pass the last request to the generator and get its response
    63|         0|            0|            0|  0.00%|                        with self.clone():
    64|         0|            0|            0|  0.00%|                            response = gen.send(request)
    65|         0|            0|            0|  0.00%|
    66|         0|            0|            0|  0.00%|            # We let the exceptions raised above by the generator's `.throw` or
    67|         0|            0|            0|  0.00%|            # `.send` methods bubble up to our caller, except for StopIteration
    68|         0|            0|            0|  0.00%|            except StopIteration as e:
    69|         0|            0|            0|  0.00%|                # The generator informed us that it is done: take whatever its
    70|         0|            0|            0|  0.00%|                # returned value (if any) was and indicate that we're done too
    71|         0|            0|            0|  0.00%|                # by returning it (see docs for python's return-statement).
    72|         0|            0|            0|  0.00%|                return e.value
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|        return generator_context
    75|         0|            0|            0|  0.00%|
    76|         0|            0|            0|  0.00%|    def __enter__(self) -> None:
    77|         0|            0|            0|  0.00%|        raise NotImplementedError
    78|         0|            0|            0|  0.00%|
    79|         0|            0|            0|  0.00%|    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:
    80|         0|            0|            0|  0.00%|        raise NotImplementedError
    81|         0|            0|            0|  0.00%|
    82|       288|  0.000416517|  1.44624e-06|  0.00%|    def clone(self):
    83|         0|            0|            0|  0.00%|        # override this method if your children class takes __init__ parameters
    84|       288|   0.00181079|  6.28746e-06|  0.00%|        return self.__class__()
(call)|       288|   0.00511956|  1.77763e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:126 __init__
    85|         0|            0|            0|  0.00%|
    86|         0|            0|            0|  0.00%|
    87|         0|            0|            0|  0.00%|class no_grad(_DecoratorContextManager):
    88|         0|            0|            0|  0.00%|    r"""Context-manager that disabled gradient calculation.
    89|         0|            0|            0|  0.00%|
    90|         0|            0|            0|  0.00%|    Disabling gradient calculation is useful for inference, when you are sure
    91|         0|            0|            0|  0.00%|    that you will not call :meth:`Tensor.backward()`. It will reduce memory
    92|         0|            0|            0|  0.00%|    consumption for computations that would otherwise have `requires_grad=True`.
    93|         0|            0|            0|  0.00%|
    94|         0|            0|            0|  0.00%|    In this mode, the result of every computation will have
    95|         0|            0|            0|  0.00%|    `requires_grad=False`, even when the inputs have `requires_grad=True`.
    96|         0|            0|            0|  0.00%|
    97|         0|            0|            0|  0.00%|    This context manager is thread local; it will not affect computation
    98|         0|            0|            0|  0.00%|    in other threads.
    99|         0|            0|            0|  0.00%|
   100|         0|            0|            0|  0.00%|    Also functions as a decorator. (Make sure to instantiate with parenthesis.)
   101|         0|            0|            0|  0.00%|
   102|         0|            0|            0|  0.00%|    .. note::
   103|         0|            0|            0|  0.00%|        No-grad is one of several mechanisms that can enable or
   104|         0|            0|            0|  0.00%|        disable gradients locally see :ref:`locally-disable-grad-doc` for
   105|         0|            0|            0|  0.00%|        more information on how they compare.
   106|         0|            0|            0|  0.00%|
   107|         0|            0|            0|  0.00%|    .. note::
   108|         0|            0|            0|  0.00%|        This API does not apply to :ref:`forward-mode AD <forward-mode-ad>`.
   109|         0|            0|            0|  0.00%|        If you want to disable forward AD for a computation, you can unpack
   110|         0|            0|            0|  0.00%|        your dual tensors.
   111|         0|            0|            0|  0.00%|
   112|         0|            0|            0|  0.00%|    Example::
   113|         0|            0|            0|  0.00%|
   114|         0|            0|            0|  0.00%|        >>> x = torch.tensor([1.], requires_grad=True)
   115|         0|            0|            0|  0.00%|        >>> with torch.no_grad():
   116|         0|            0|            0|  0.00%|        ...   y = x * 2
   117|         0|            0|            0|  0.00%|        >>> y.requires_grad
   118|         0|            0|            0|  0.00%|        False
   119|         0|            0|            0|  0.00%|        >>> @torch.no_grad()
   120|         0|            0|            0|  0.00%|        ... def doubler(x):
   121|         0|            0|            0|  0.00%|        ...     return x * 2
   122|         0|            0|            0|  0.00%|        >>> z = doubler(x)
   123|         0|            0|            0|  0.00%|        >>> z.requires_grad
   124|         0|            0|            0|  0.00%|        False
   125|         0|            0|            0|  0.00%|    """
   126|      2898|   0.00733519|  2.53112e-06|  0.01%|    def __init__(self) -> None:
   127|      2898|    0.0215459|  7.43474e-06|  0.02%|        if not torch._jit_internal.is_scripting():
(call)|      2898|    0.0108981|  3.76056e-06|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_jit_internal.py:958 is_scripting
   128|      2898|   0.00948501|  3.27295e-06|  0.01%|            super().__init__()
   129|      2898|   0.00664711|  2.29369e-06|  0.01%|        self.prev = False
   130|         0|            0|            0|  0.00%|
   131|      2898|    0.0066452|  2.29303e-06|  0.01%|    def __enter__(self) -> None:
   132|      2898|   0.00820613|  2.83165e-06|  0.01%|        self.prev = torch.is_grad_enabled()
   133|      2898|    0.0190837|  6.58514e-06|  0.02%|        torch.set_grad_enabled(False)
(call)|      2898|    0.0238843|  8.24165e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:226 __init__
   134|         0|            0|            0|  0.00%|
   135|      2898|   0.00821853|  2.83593e-06|  0.01%|    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:
   136|      2898|    0.0240076|  8.28418e-06|  0.02%|        torch.set_grad_enabled(self.prev)
(call)|      2898|     0.027854|  9.61144e-06|  0.03%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:226 __init__
   137|         0|            0|            0|  0.00%|
   138|         0|            0|            0|  0.00%|
   139|         0|            0|            0|  0.00%|class enable_grad(_DecoratorContextManager):
   140|         0|            0|            0|  0.00%|    r"""Context-manager that enables gradient calculation.
   141|         0|            0|            0|  0.00%|
   142|         0|            0|            0|  0.00%|    Enables gradient calculation, if it has been disabled via :class:`~no_grad`
   143|         0|            0|            0|  0.00%|    or :class:`~set_grad_enabled`.
   144|         0|            0|            0|  0.00%|
   145|         0|            0|            0|  0.00%|    This context manager is thread local; it will not affect computation
   146|         0|            0|            0|  0.00%|    in other threads.
   147|         0|            0|            0|  0.00%|
   148|         0|            0|            0|  0.00%|    Also functions as a decorator. (Make sure to instantiate with parenthesis.)
   149|         0|            0|            0|  0.00%|
   150|         0|            0|            0|  0.00%|    .. note::
   151|         0|            0|            0|  0.00%|        enable_grad is one of several mechanisms that can enable or
   152|         0|            0|            0|  0.00%|        disable gradients locally see :ref:`locally-disable-grad-doc` for
   153|         0|            0|            0|  0.00%|        more information on how they compare.
   154|         0|            0|            0|  0.00%|
   155|         0|            0|            0|  0.00%|    .. note::
   156|         0|            0|            0|  0.00%|        This API does not apply to :ref:`forward-mode AD <forward-mode-ad>`.
   157|         0|            0|            0|  0.00%|
   158|         0|            0|            0|  0.00%|    Example::
   159|         0|            0|            0|  0.00%|
   160|         0|            0|            0|  0.00%|        >>> x = torch.tensor([1.], requires_grad=True)
   161|         0|            0|            0|  0.00%|        >>> with torch.no_grad():
   162|         0|            0|            0|  0.00%|        ...   with torch.enable_grad():
   163|         0|            0|            0|  0.00%|        ...     y = x * 2
   164|         0|            0|            0|  0.00%|        >>> y.requires_grad
   165|         0|            0|            0|  0.00%|        True
   166|         0|            0|            0|  0.00%|        >>> y.backward()
   167|         0|            0|            0|  0.00%|        >>> x.grad
   168|         0|            0|            0|  0.00%|        >>> @torch.enable_grad()
   169|         0|            0|            0|  0.00%|        ... def doubler(x):
   170|         0|            0|            0|  0.00%|        ...     return x * 2
   171|         0|            0|            0|  0.00%|        >>> with torch.no_grad():
   172|         0|            0|            0|  0.00%|        ...     z = doubler(x)
   173|         0|            0|            0|  0.00%|        >>> z.requires_grad
   174|         0|            0|            0|  0.00%|        True
   175|         0|            0|            0|  0.00%|
   176|         0|            0|            0|  0.00%|    """
   177|      2610|   0.00435829|  1.66984e-06|  0.00%|    def __enter__(self) -> None:
   178|      2610|    0.0083909|  3.21491e-06|  0.01%|        self.prev = torch.is_grad_enabled()
   179|      2610|   0.00713038|  2.73195e-06|  0.01%|        torch._C._set_grad_enabled(True)
   180|         0|            0|            0|  0.00%|
   181|      2610|   0.00494981|  1.89648e-06|  0.00%|    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:
   182|      2610|    0.0074513|   2.8549e-06|  0.01%|        torch._C._set_grad_enabled(self.prev)
   183|         0|            0|            0|  0.00%|
   184|         0|            0|            0|  0.00%|
   185|         0|            0|            0|  0.00%|class set_grad_enabled(_DecoratorContextManager):
   186|         0|            0|            0|  0.00%|    r"""Context-manager that sets gradient calculation to on or off.
   187|         0|            0|            0|  0.00%|
   188|         0|            0|            0|  0.00%|    ``set_grad_enabled`` will enable or disable grads based on its argument :attr:`mode`.
   189|         0|            0|            0|  0.00%|    It can be used as a context-manager or as a function.
   190|         0|            0|            0|  0.00%|
   191|         0|            0|            0|  0.00%|    This context manager is thread local; it will not affect computation
   192|         0|            0|            0|  0.00%|    in other threads.
   193|         0|            0|            0|  0.00%|
   194|         0|            0|            0|  0.00%|    Args:
   195|         0|            0|            0|  0.00%|        mode (bool): Flag whether to enable grad (``True``), or disable
   196|         0|            0|            0|  0.00%|                     (``False``). This can be used to conditionally enable
   197|         0|            0|            0|  0.00%|                     gradients.
   198|         0|            0|            0|  0.00%|
   199|         0|            0|            0|  0.00%|    .. note::
   200|         0|            0|            0|  0.00%|        set_grad_enabled is one of several mechanisms that can enable or
   201|         0|            0|            0|  0.00%|        disable gradients locally see :ref:`locally-disable-grad-doc` for
   202|         0|            0|            0|  0.00%|        more information on how they compare.
   203|         0|            0|            0|  0.00%|
   204|         0|            0|            0|  0.00%|    .. note::
   205|         0|            0|            0|  0.00%|        This API does not apply to :ref:`forward-mode AD <forward-mode-ad>`.
   206|         0|            0|            0|  0.00%|
   207|         0|            0|            0|  0.00%|    Example::
   208|         0|            0|            0|  0.00%|
   209|         0|            0|            0|  0.00%|        >>> x = torch.tensor([1.], requires_grad=True)
   210|         0|            0|            0|  0.00%|        >>> is_train = False
   211|         0|            0|            0|  0.00%|        >>> with torch.set_grad_enabled(is_train):
   212|         0|            0|            0|  0.00%|        ...   y = x * 2
   213|         0|            0|            0|  0.00%|        >>> y.requires_grad
   214|         0|            0|            0|  0.00%|        False
   215|         0|            0|            0|  0.00%|        >>> torch.set_grad_enabled(True)
   216|         0|            0|            0|  0.00%|        >>> y = x * 2
   217|         0|            0|            0|  0.00%|        >>> y.requires_grad
   218|         0|            0|            0|  0.00%|        True
   219|         0|            0|            0|  0.00%|        >>> torch.set_grad_enabled(False)
   220|         0|            0|            0|  0.00%|        >>> y = x * 2
   221|         0|            0|            0|  0.00%|        >>> y.requires_grad
   222|         0|            0|            0|  0.00%|        False
   223|         0|            0|            0|  0.00%|
   224|         0|            0|            0|  0.00%|    """
   225|         0|            0|            0|  0.00%|
   226|      5796|   0.00987911|  1.70447e-06|  0.01%|    def __init__(self, mode: bool) -> None:
   227|      5796|    0.0161932|  2.79385e-06|  0.02%|        self.prev = torch.is_grad_enabled()
   228|      5796|     0.014231|  2.45531e-06|  0.01%|        torch._C._set_grad_enabled(mode)
   229|      5796|     0.011435|  1.97292e-06|  0.01%|        self.mode = mode
   230|         0|            0|            0|  0.00%|
   231|         0|            0|            0|  0.00%|    def __enter__(self) -> None:
   232|         0|            0|            0|  0.00%|        pass
   233|         0|            0|            0|  0.00%|
   234|         0|            0|            0|  0.00%|    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:
   235|         0|            0|            0|  0.00%|        torch._C._set_grad_enabled(self.prev)
   236|         0|            0|            0|  0.00%|
   237|         0|            0|            0|  0.00%|    def clone(self):
   238|         0|            0|            0|  0.00%|        return self.__class__(self.mode)
   239|         0|            0|            0|  0.00%|
   240|         0|            0|            0|  0.00%|
   241|         0|            0|            0|  0.00%|class inference_mode(_DecoratorContextManager):
   242|         0|            0|            0|  0.00%|    r"""Context-manager that enables or disables inference mode
   243|         0|            0|            0|  0.00%|
   244|         0|            0|            0|  0.00%|    InferenceMode is a new context manager analogous to :class:`~no_grad`
   245|         0|            0|            0|  0.00%|    to be used when you are certain your operations will have no interactions
   246|         0|            0|            0|  0.00%|    with autograd (e.g., model training). Code run under this mode gets better
   247|         0|            0|            0|  0.00%|    performance by disabling view tracking and version counter bumps. Note that
   248|         0|            0|            0|  0.00%|    unlike some other mechanisms that locally enable or disable grad,
   249|         0|            0|            0|  0.00%|    entering inference_mode also disables to :ref:`forward-mode AD <forward-mode-ad>`.
   250|         0|            0|            0|  0.00%|
   251|         0|            0|            0|  0.00%|    This context manager is thread local; it will not affect computation
   252|         0|            0|            0|  0.00%|    in other threads.
   253|         0|            0|            0|  0.00%|
   254|         0|            0|            0|  0.00%|    Also functions as a decorator. (Make sure to instantiate with parenthesis.)
   255|         0|            0|            0|  0.00%|
   256|         0|            0|            0|  0.00%|    .. note::
   257|         0|            0|            0|  0.00%|        Inference mode is one of several mechanisms that can enable or
   258|         0|            0|            0|  0.00%|        disable gradients locally see :ref:`locally-disable-grad-doc` for
   259|         0|            0|            0|  0.00%|        more information on how they compare.
   260|         0|            0|            0|  0.00%|
   261|         0|            0|            0|  0.00%|    Args:
   262|         0|            0|            0|  0.00%|        mode (bool): Flag whether to enable or disable inference mode
   263|         0|            0|            0|  0.00%|
   264|         0|            0|            0|  0.00%|    Example::
   265|         0|            0|            0|  0.00%|        >>> import torch
   266|         0|            0|            0|  0.00%|        >>> x = torch.ones(1, 2, 3, requires_grad=True)
   267|         0|            0|            0|  0.00%|        >>> with torch.inference_mode():
   268|         0|            0|            0|  0.00%|        ...   y = x * x
   269|         0|            0|            0|  0.00%|        >>> y.requires_grad
   270|         0|            0|            0|  0.00%|        False
   271|         0|            0|            0|  0.00%|        >>> y._version
   272|         0|            0|            0|  0.00%|        Traceback (most recent call last):
   273|         0|            0|            0|  0.00%|        File "<stdin>", line 1, in <module>
   274|         0|            0|            0|  0.00%|        RuntimeError: Inference tensors do not track version counter.
   275|         0|            0|            0|  0.00%|        >>> @torch.inference_mode()
   276|         0|            0|            0|  0.00%|        ... def func(x):
   277|         0|            0|            0|  0.00%|        ...   return x * x
   278|         0|            0|            0|  0.00%|        >>> out = func(x)
   279|         0|            0|            0|  0.00%|        >>> out.requires_grad
   280|         0|            0|            0|  0.00%|        False
   281|         0|            0|            0|  0.00%|
   282|         0|            0|            0|  0.00%|    """
   283|         0|            0|            0|  0.00%|    def __init__(self, mode=True):
   284|         0|            0|            0|  0.00%|        if not torch._jit_internal.is_scripting():
   285|         0|            0|            0|  0.00%|            super().__init__()
   286|         0|            0|            0|  0.00%|        # Holds a python binding to a RAII guard that can enable or disable
   287|         0|            0|            0|  0.00%|        # inference mode
   288|         0|            0|            0|  0.00%|        self._inference_mode_raii_guard = None
   289|         0|            0|            0|  0.00%|        self.mode = mode
   290|         0|            0|            0|  0.00%|
   291|         0|            0|            0|  0.00%|    def __enter__(self):
   292|         0|            0|            0|  0.00%|        self._inference_mode_raii_guard = torch._C._InferenceMode(self.mode)
   293|         0|            0|            0|  0.00%|
   294|         0|            0|            0|  0.00%|    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:
   295|         0|            0|            0|  0.00%|        del self._inference_mode_raii_guard
   296|         0|            0|            0|  0.00%|
   297|         0|            0|            0|  0.00%|    def clone(self):
   298|         0|            0|            0|  0.00%|        return self.__class__(self.mode)
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py
File duration: 0.202268s (0.19%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import warnings
     2|         0|            0|            0|  0.00%|import torch
     3|         0|            0|            0|  0.00%|from torch._six import inf
     4|         0|            0|            0|  0.00%|from typing import Union, Iterable
     5|         0|            0|            0|  0.00%|
     6|         0|            0|            0|  0.00%|_tensor_or_tensors = Union[torch.Tensor, Iterable[torch.Tensor]]
     7|         0|            0|            0|  0.00%|
     8|         0|            0|            0|  0.00%|
     9|       288|   0.00211835|  7.35538e-06|  0.00%|def clip_grad_norm_(
    10|         0|            0|            0|  0.00%|        parameters: _tensor_or_tensors, max_norm: float, norm_type: float = 2.0,
    11|         0|            0|            0|  0.00%|        error_if_nonfinite: bool = False) -> torch.Tensor:
    12|         0|            0|            0|  0.00%|    r"""Clips gradient norm of an iterable of parameters.
    13|         0|            0|            0|  0.00%|
    14|         0|            0|            0|  0.00%|    The norm is computed over all gradients together, as if they were
    15|         0|            0|            0|  0.00%|    concatenated into a single vector. Gradients are modified in-place.
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|    Args:
    18|         0|            0|            0|  0.00%|        parameters (Iterable[Tensor] or Tensor): an iterable of Tensors or a
    19|         0|            0|            0|  0.00%|            single Tensor that will have gradients normalized
    20|         0|            0|            0|  0.00%|        max_norm (float or int): max norm of the gradients
    21|         0|            0|            0|  0.00%|        norm_type (float or int): type of the used p-norm. Can be ``'inf'`` for
    22|         0|            0|            0|  0.00%|            infinity norm.
    23|         0|            0|            0|  0.00%|        error_if_nonfinite (bool): if True, an error is thrown if the total
    24|         0|            0|            0|  0.00%|            norm of the gradients from :attr:`parameters` is ``nan``,
    25|         0|            0|            0|  0.00%|            ``inf``, or ``-inf``. Default: False (will switch to True in the future)
    26|         0|            0|            0|  0.00%|
    27|         0|            0|            0|  0.00%|    Returns:
    28|         0|            0|            0|  0.00%|        Total norm of the parameter gradients (viewed as a single vector).
    29|         0|            0|            0|  0.00%|    """
    30|       288|   0.00201964|  7.01265e-06|  0.00%|    if isinstance(parameters, torch.Tensor):
    31|         0|            0|            0|  0.00%|        parameters = [parameters]
    32|      4320|    0.0359845|  8.32975e-06|  0.03%|    parameters = [p for p in parameters if p.grad is not None]
(call)|      3744|     0.478389|  0.000127775|  0.46%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1621 parameters
(call)|      3456|    0.0175974|  5.09185e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:1071 grad
(call)|       288|     0.529031|   0.00183691|  0.51%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py:32 <listcomp>
    33|       288|   0.00113606|  3.94467e-06|  0.00%|    max_norm = float(max_norm)
    34|       288|  0.000975132|  3.38587e-06|  0.00%|    norm_type = float(norm_type)
    35|       288|  0.000989437|  3.43555e-06|  0.00%|    if len(parameters) == 0:
    36|         0|            0|            0|  0.00%|        return torch.tensor(0.)
    37|       288|   0.00233746|  8.11617e-06|  0.00%|    device = parameters[0].grad.device
(call)|       288|   0.00159955|  5.55399e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:1071 grad
    38|       288|   0.00103736|  3.60194e-06|  0.00%|    if norm_type == inf:
    39|         0|            0|            0|  0.00%|        norms = [p.grad.detach().abs().max().to(device) for p in parameters]
    40|         0|            0|            0|  0.00%|        total_norm = norms[0] if len(norms) == 1 else torch.max(torch.stack(norms))
    41|         0|            0|            0|  0.00%|    else:
    42|      4320|    0.0668356|  1.54712e-05|  0.06%|        total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), norm_type).to(device) for p in parameters]), norm_type)
(call)|      3456|    0.0172853|  5.00155e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:1071 grad
(call)|      3456|     0.158072|  4.57384e-05|  0.15%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/functional.py:1345 norm
(call)|       288|     0.231303|  0.000803135|  0.22%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py:42 <listcomp>
(call)|       288|    0.0129759|  4.50553e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/functional.py:1345 norm
    43|       288|  0.000949621|   3.2973e-06|  0.00%|    if error_if_nonfinite and torch.logical_or(total_norm.isnan(), total_norm.isinf()):
    44|         0|            0|            0|  0.00%|        raise RuntimeError(
    45|         0|            0|            0|  0.00%|            f'The total norm of order {norm_type} for gradients from '
    46|         0|            0|            0|  0.00%|            '`parameters` is non-finite, so it cannot be clipped. To disable '
    47|         0|            0|            0|  0.00%|            'this error and scale the gradients by the non-finite norm anyway, '
    48|         0|            0|            0|  0.00%|            'set `error_if_nonfinite=False`')
    49|       288|   0.00745153|  2.58734e-05|  0.01%|    clip_coef = max_norm / (total_norm + 1e-6)
(call)|       288|   0.00946045|  3.28488e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:26 wrapped
    50|         0|            0|            0|  0.00%|    # Note: multiplying by the clamped coef is redundant when the coef is clamped to 1, but doing so
    51|         0|            0|            0|  0.00%|    # avoids a `if clip_coef < 1:` conditional which can require a CPU <=> device synchronization
    52|         0|            0|            0|  0.00%|    # when the gradients do not reside in CPU memory.
    53|       288|   0.00313973|  1.09019e-05|  0.00%|    clip_coef_clamped = torch.clamp(clip_coef, max=1.0)
    54|      3744|    0.0107684|  2.87618e-06|  0.01%|    for p in parameters:
    55|      3456|    0.0657871|  1.90356e-05|  0.06%|        p.grad.detach().mul_(clip_coef_clamped.to(p.grad.device))
(call)|      6912|     0.038727|  5.60287e-06|  0.04%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:1071 grad
    56|       288|  0.000738144|    2.563e-06|  0.00%|    return total_norm
    57|         0|            0|            0|  0.00%|
    58|         0|            0|            0|  0.00%|
    59|         0|            0|            0|  0.00%|def clip_grad_norm(
    60|         0|            0|            0|  0.00%|        parameters: _tensor_or_tensors, max_norm: float, norm_type: float = 2.,
    61|         0|            0|            0|  0.00%|        error_if_nonfinite: bool = False) -> torch.Tensor:
    62|         0|            0|            0|  0.00%|    r"""Clips gradient norm of an iterable of parameters.
    63|         0|            0|            0|  0.00%|
    64|         0|            0|            0|  0.00%|    .. warning::
    65|         0|            0|            0|  0.00%|        This method is now deprecated in favor of
    66|         0|            0|            0|  0.00%|        :func:`torch.nn.utils.clip_grad_norm_`.
    67|         0|            0|            0|  0.00%|    """
    68|         0|            0|            0|  0.00%|    warnings.warn("torch.nn.utils.clip_grad_norm is now deprecated in favor "
    69|         0|            0|            0|  0.00%|                  "of torch.nn.utils.clip_grad_norm_.", stacklevel=2)
    70|         0|            0|            0|  0.00%|    return clip_grad_norm_(parameters, max_norm, norm_type, error_if_nonfinite)
    71|         0|            0|            0|  0.00%|
    72|         0|            0|            0|  0.00%|
    73|         0|            0|            0|  0.00%|def clip_grad_value_(parameters: _tensor_or_tensors, clip_value: float) -> None:
    74|         0|            0|            0|  0.00%|    r"""Clips gradient of an iterable of parameters at specified value.
    75|         0|            0|            0|  0.00%|
    76|         0|            0|            0|  0.00%|    Gradients are modified in-place.
    77|         0|            0|            0|  0.00%|
    78|         0|            0|            0|  0.00%|    Args:
    79|         0|            0|            0|  0.00%|        parameters (Iterable[Tensor] or Tensor): an iterable of Tensors or a
    80|         0|            0|            0|  0.00%|            single Tensor that will have gradients normalized
    81|         0|            0|            0|  0.00%|        clip_value (float or int): maximum allowed value of the gradients.
    82|         0|            0|            0|  0.00%|            The gradients are clipped in the range
    83|         0|            0|            0|  0.00%|            :math:`\left[\text{-clip\_value}, \text{clip\_value}\right]`
    84|         0|            0|            0|  0.00%|    """
    85|         0|            0|            0|  0.00%|    if isinstance(parameters, torch.Tensor):
    86|         0|            0|            0|  0.00%|        parameters = [parameters]
    87|         0|            0|            0|  0.00%|    clip_value = float(clip_value)
    88|         0|            0|            0|  0.00%|    for p in filter(lambda p: p.grad is not None, parameters):
    89|         0|            0|            0|  0.00%|        p.grad.data.clamp_(min=-clip_value, max=clip_value)
File: /apps/open_spiel/open_spiel/python/examples/ubc_math_utils.py
File duration: 0.178328s (0.17%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import numpy as np
     2|         0|            0|            0|  0.00%|
     3|         0|            0|            0|  0.00%|# Much faster than np.random.choice, at least for our current version of numpy and our distribution over the arguments
     4|      5892|    0.0129576|  2.19918e-06|  0.01%|def fast_choice(options, probs, rng=None):
     5|      5892|    0.0428128|  7.26626e-06|  0.04%|    cdf = np.cumsum(probs)
(call)|      5892|     0.430236|  7.30204e-05|  0.41%|# <__array_function__ internals>:177 cumsum
     6|      5892|    0.0295994|  5.02366e-06|  0.03%|    randomness = rng.rand() if rng is not None else np.random.rand()
     7|      5892|    0.0796032|  1.35104e-05|  0.08%|    i = np.searchsorted(cdf / cdf[-1], randomness)
(call)|      5892|     0.260975|  4.42931e-05|  0.25%|# <__array_function__ internals>:177 searchsorted
     8|      5892|    0.0133553|  2.26668e-06|  0.01%|    return options[i]
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/utils.py
File duration: 0.154035s (0.15%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|from functools import update_wrapper
     2|         0|            0|            0|  0.00%|from numbers import Number
     3|         0|            0|            0|  0.00%|import torch
     4|         0|            0|            0|  0.00%|import torch.nn.functional as F
     5|         0|            0|            0|  0.00%|from typing import Dict, Any
     6|         0|            0|            0|  0.00%|from torch.overrides import is_tensor_like
     7|         0|            0|            0|  0.00%|
     8|         0|            0|            0|  0.00%|euler_constant = 0.57721566490153286060  # Euler Mascheroni Constant
     9|         0|            0|            0|  0.00%|
    10|         0|            0|            0|  0.00%|
    11|         0|            0|            0|  0.00%|def broadcast_all(*values):
    12|         0|            0|            0|  0.00%|    r"""
    13|         0|            0|            0|  0.00%|    Given a list of values (possibly containing numbers), returns a list where each
    14|         0|            0|            0|  0.00%|    value is broadcasted based on the following rules:
    15|         0|            0|            0|  0.00%|      - `torch.*Tensor` instances are broadcasted as per :ref:`_broadcasting-semantics`.
    16|         0|            0|            0|  0.00%|      - numbers.Number instances (scalars) are upcast to tensors having
    17|         0|            0|            0|  0.00%|        the same size and type as the first tensor passed to `values`.  If all the
    18|         0|            0|            0|  0.00%|        values are scalars, then they are upcasted to scalar Tensors.
    19|         0|            0|            0|  0.00%|
    20|         0|            0|            0|  0.00%|    Args:
    21|         0|            0|            0|  0.00%|        values (list of `numbers.Number`, `torch.*Tensor` or objects implementing __torch_function__)
    22|         0|            0|            0|  0.00%|
    23|         0|            0|            0|  0.00%|    Raises:
    24|         0|            0|            0|  0.00%|        ValueError: if any of the values is not a `numbers.Number` instance,
    25|         0|            0|            0|  0.00%|            a `torch.*Tensor` instance, or an instance implementing __torch_function__
    26|         0|            0|            0|  0.00%|    """
    27|         0|            0|            0|  0.00%|    if not all(is_tensor_like(v) or isinstance(v, Number)
    28|         0|            0|            0|  0.00%|               for v in values):
    29|         0|            0|            0|  0.00%|        raise ValueError('Input arguments must all be instances of numbers.Number, '
    30|         0|            0|            0|  0.00%|                         'torch.Tensor or objects implementing __torch_function__.')
    31|         0|            0|            0|  0.00%|    if not all(is_tensor_like(v) for v in values):
    32|         0|            0|            0|  0.00%|        options: Dict[str, Any] = dict(dtype=torch.get_default_dtype())
    33|         0|            0|            0|  0.00%|        for value in values:
    34|         0|            0|            0|  0.00%|            if isinstance(value, torch.Tensor):
    35|         0|            0|            0|  0.00%|                options = dict(dtype=value.dtype, device=value.device)
    36|         0|            0|            0|  0.00%|                break
    37|         0|            0|            0|  0.00%|        new_values = [v if is_tensor_like(v) else torch.tensor(v, **options)
    38|         0|            0|            0|  0.00%|                      for v in values]
    39|         0|            0|            0|  0.00%|        return torch.broadcast_tensors(*new_values)
    40|         0|            0|            0|  0.00%|    return torch.broadcast_tensors(*values)
    41|         0|            0|            0|  0.00%|
    42|         0|            0|            0|  0.00%|
    43|         0|            0|            0|  0.00%|def _standard_normal(shape, dtype, device):
    44|         0|            0|            0|  0.00%|    if torch._C._get_tracing_state():
    45|         0|            0|            0|  0.00%|        # [JIT WORKAROUND] lack of support for .normal_()
    46|         0|            0|            0|  0.00%|        return torch.normal(torch.zeros(shape, dtype=dtype, device=device),
    47|         0|            0|            0|  0.00%|                            torch.ones(shape, dtype=dtype, device=device))
    48|         0|            0|            0|  0.00%|    return torch.empty(shape, dtype=dtype, device=device).normal_()
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|
    51|         0|            0|            0|  0.00%|def _sum_rightmost(value, dim):
    52|         0|            0|            0|  0.00%|    r"""
    53|         0|            0|            0|  0.00%|    Sum out ``dim`` many rightmost dimensions of a given tensor.
    54|         0|            0|            0|  0.00%|
    55|         0|            0|            0|  0.00%|    Args:
    56|         0|            0|            0|  0.00%|        value (Tensor): A tensor of ``.dim()`` at least ``dim``.
    57|         0|            0|            0|  0.00%|        dim (int): The number of rightmost dims to sum out.
    58|         0|            0|            0|  0.00%|    """
    59|         0|            0|            0|  0.00%|    if dim == 0:
    60|         0|            0|            0|  0.00%|        return value
    61|         0|            0|            0|  0.00%|    required_shape = value.shape[:-dim] + (-1,)
    62|         0|            0|            0|  0.00%|    return value.reshape(required_shape).sum(-1)
    63|         0|            0|            0|  0.00%|
    64|         0|            0|            0|  0.00%|
    65|      2610|   0.00459623|  1.76101e-06|  0.00%|def logits_to_probs(logits, is_binary=False):
    66|         0|            0|            0|  0.00%|    r"""
    67|         0|            0|            0|  0.00%|    Converts a tensor of logits into probabilities. Note that for the
    68|         0|            0|            0|  0.00%|    binary case, each value denotes log odds, whereas for the
    69|         0|            0|            0|  0.00%|    multi-dimensional case, the values along the last dimension denote
    70|         0|            0|            0|  0.00%|    the log probabilities (possibly unnormalized) of the events.
    71|         0|            0|            0|  0.00%|    """
    72|      2610|   0.00550556|  2.10941e-06|  0.01%|    if is_binary:
    73|         0|            0|            0|  0.00%|        return torch.sigmoid(logits)
    74|      2610|    0.0206892|  7.92692e-06|  0.02%|    return F.softmax(logits, dim=-1)
(call)|      2610|     0.069253|  2.65337e-05|  0.07%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/functional.py:1804 softmax
    75|         0|            0|            0|  0.00%|
    76|         0|            0|            0|  0.00%|
    77|         0|            0|            0|  0.00%|def clamp_probs(probs):
    78|         0|            0|            0|  0.00%|    eps = torch.finfo(probs.dtype).eps
    79|         0|            0|            0|  0.00%|    return probs.clamp(min=eps, max=1 - eps)
    80|         0|            0|            0|  0.00%|
    81|         0|            0|            0|  0.00%|
    82|         0|            0|            0|  0.00%|def probs_to_logits(probs, is_binary=False):
    83|         0|            0|            0|  0.00%|    r"""
    84|         0|            0|            0|  0.00%|    Converts a tensor of probabilities into logits. For the binary case,
    85|         0|            0|            0|  0.00%|    this denotes the probability of occurrence of the event indexed by `1`.
    86|         0|            0|            0|  0.00%|    For the multi-dimensional case, the values along the last dimension
    87|         0|            0|            0|  0.00%|    denote the probabilities of occurrence of each of the events.
    88|         0|            0|            0|  0.00%|    """
    89|         0|            0|            0|  0.00%|    ps_clamped = clamp_probs(probs)
    90|         0|            0|            0|  0.00%|    if is_binary:
    91|         0|            0|            0|  0.00%|        return torch.log(ps_clamped) - torch.log1p(-ps_clamped)
    92|         0|            0|            0|  0.00%|    return torch.log(ps_clamped)
    93|         0|            0|            0|  0.00%|
    94|         0|            0|            0|  0.00%|
    95|         0|            0|            0|  0.00%|class lazy_property:
    96|         0|            0|            0|  0.00%|    r"""
    97|         0|            0|            0|  0.00%|    Used as a decorator for lazy loading of class attributes. This uses a
    98|         0|            0|            0|  0.00%|    non-data descriptor that calls the wrapped method to compute the property on
    99|         0|            0|            0|  0.00%|    first call; thereafter replacing the wrapped method into an instance
   100|         0|            0|            0|  0.00%|    attribute.
   101|         0|            0|            0|  0.00%|    """
   102|         0|            0|            0|  0.00%|    def __init__(self, wrapped):
   103|         0|            0|            0|  0.00%|        self.wrapped = wrapped
   104|         0|            0|            0|  0.00%|        update_wrapper(self, wrapped)
   105|         0|            0|            0|  0.00%|
   106|      5220|    0.0114036|  2.18459e-06|  0.01%|    def __get__(self, instance, obj_type=None):
   107|      5220|     0.012604|  2.41456e-06|  0.01%|        if instance is None:
   108|      2610|     0.020695|  7.92911e-06|  0.02%|            return _lazy_property_and_property(self.wrapped)
(call)|      2610|    0.0139995|  5.36378e-06|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/utils.py:121 __init__
   109|      2610|    0.0196276|  7.52014e-06|  0.02%|        with torch.enable_grad():
(call)|      2610|    0.0198796|   7.6167e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:177 __enter__
   110|      2610|    0.0313625|  1.20163e-05|  0.03%|            value = self.wrapped(instance)
(call)|      2610|     0.121636|  4.66038e-05|  0.12%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/distributions/categorical.py:92 probs
(call)|      2610|    0.0124011|  4.75138e-06|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:181 __exit__
   111|      2610|   0.00794888|  3.04555e-06|  0.01%|        setattr(instance, self.wrapped.__name__, value)
   112|      2610|    0.0056026|  2.14659e-06|  0.01%|        return value
   113|         0|            0|            0|  0.00%|
   114|         0|            0|            0|  0.00%|
   115|         0|            0|            0|  0.00%|class _lazy_property_and_property(lazy_property, property):
   116|         0|            0|            0|  0.00%|    """We want lazy properties to look like multiple things.
   117|         0|            0|            0|  0.00%|
   118|         0|            0|            0|  0.00%|    * property when Sphinx autodoc looks
   119|         0|            0|            0|  0.00%|    * lazy_property when Distribution validate_args looks
   120|         0|            0|            0|  0.00%|    """
   121|      2610|   0.00465941|  1.78522e-06|  0.00%|    def __init__(self, wrapped):
   122|      2610|   0.00934005|  3.57856e-06|  0.01%|        return property.__init__(self, wrapped)
   123|         0|            0|            0|  0.00%|
   124|         0|            0|            0|  0.00%|
   125|         0|            0|            0|  0.00%|def tril_matrix_to_vec(mat, diag=0):
   126|         0|            0|            0|  0.00%|    r"""
   127|         0|            0|            0|  0.00%|    Convert a `D x D` matrix or a batch of matrices into a (batched) vector
   128|         0|            0|            0|  0.00%|    which comprises of lower triangular elements from the matrix in row order.
   129|         0|            0|            0|  0.00%|    """
   130|         0|            0|            0|  0.00%|    n = mat.shape[-1]
   131|         0|            0|            0|  0.00%|    if not torch._C._get_tracing_state() and (diag < -n or diag >= n):
   132|         0|            0|            0|  0.00%|        raise ValueError(f'diag ({diag}) provided is outside [{-n}, {n-1}].')
   133|         0|            0|            0|  0.00%|    arange = torch.arange(n, device=mat.device)
   134|         0|            0|            0|  0.00%|    tril_mask = arange < arange.view(-1, 1) + (diag + 1)
   135|         0|            0|            0|  0.00%|    vec = mat[..., tril_mask]
   136|         0|            0|            0|  0.00%|    return vec
   137|         0|            0|            0|  0.00%|
   138|         0|            0|            0|  0.00%|
   139|         0|            0|            0|  0.00%|def vec_to_tril_matrix(vec, diag=0):
   140|         0|            0|            0|  0.00%|    r"""
   141|         0|            0|            0|  0.00%|    Convert a vector or a batch of vectors into a batched `D x D`
   142|         0|            0|            0|  0.00%|    lower triangular matrix containing elements from the vector in row order.
   143|         0|            0|            0|  0.00%|    """
   144|         0|            0|            0|  0.00%|    # +ve root of D**2 + (1+2*diag)*D - |diag| * (diag+1) - 2*vec.shape[-1] = 0
   145|         0|            0|            0|  0.00%|    n = (-(1 + 2 * diag) + ((1 + 2 * diag)**2 + 8 * vec.shape[-1] + 4 * abs(diag) * (diag + 1))**0.5) / 2
   146|         0|            0|            0|  0.00%|    eps = torch.finfo(vec.dtype).eps
   147|         0|            0|            0|  0.00%|    if not torch._C._get_tracing_state() and (round(n) - n > eps):
   148|         0|            0|            0|  0.00%|        raise ValueError(f'The size of last dimension is {vec.shape[-1]} which cannot be expressed as ' +
   149|         0|            0|            0|  0.00%|                         'the lower triangular part of a square D x D matrix.')
   150|         0|            0|            0|  0.00%|    n = torch.round(n).long() if isinstance(n, torch.Tensor) else round(n)
   151|         0|            0|            0|  0.00%|    mat = vec.new_zeros(vec.shape[:-1] + torch.Size((n, n)))
   152|         0|            0|            0|  0.00%|    arange = torch.arange(n, device=vec.device)
   153|         0|            0|            0|  0.00%|    tril_mask = arange < arange.view(-1, 1) + (diag + 1)
   154|         0|            0|            0|  0.00%|    mat[..., tril_mask] = vec
   155|         0|            0|            0|  0.00%|    return mat
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/optim/optimizer.py
File duration: 0.149141s (0.14%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|from collections import defaultdict, abc as container_abcs
     2|         0|            0|            0|  0.00%|
     3|         0|            0|            0|  0.00%|import torch
     4|         0|            0|            0|  0.00%|from copy import deepcopy
     5|         0|            0|            0|  0.00%|from itertools import chain
     6|         0|            0|            0|  0.00%|import warnings
     7|         0|            0|            0|  0.00%|import functools
     8|         0|            0|            0|  0.00%|
     9|         0|            0|            0|  0.00%|
    10|         0|            0|            0|  0.00%|class _RequiredParameter(object):
    11|         0|            0|            0|  0.00%|    """Singleton class representing a required parameter for an Optimizer."""
    12|         0|            0|            0|  0.00%|    def __repr__(self):
    13|         0|            0|            0|  0.00%|        return "<required parameter>"
    14|         0|            0|            0|  0.00%|
    15|         0|            0|            0|  0.00%|required = _RequiredParameter()
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|
    18|         0|            0|            0|  0.00%|class Optimizer(object):
    19|         0|            0|            0|  0.00%|    r"""Base class for all optimizers.
    20|         0|            0|            0|  0.00%|
    21|         0|            0|            0|  0.00%|    .. warning::
    22|         0|            0|            0|  0.00%|        Parameters need to be specified as collections that have a deterministic
    23|         0|            0|            0|  0.00%|        ordering that is consistent between runs. Examples of objects that don't
    24|         0|            0|            0|  0.00%|        satisfy those properties are sets and iterators over values of dictionaries.
    25|         0|            0|            0|  0.00%|
    26|         0|            0|            0|  0.00%|    Args:
    27|         0|            0|            0|  0.00%|        params (iterable): an iterable of :class:`torch.Tensor` s or
    28|         0|            0|            0|  0.00%|            :class:`dict` s. Specifies what Tensors should be optimized.
    29|         0|            0|            0|  0.00%|        defaults: (dict): a dict containing default values of optimization
    30|         0|            0|            0|  0.00%|            options (used when a parameter group doesn't specify them).
    31|         0|            0|            0|  0.00%|    """
    32|         0|            0|            0|  0.00%|
    33|         0|            0|            0|  0.00%|    def __init__(self, params, defaults):
    34|         0|            0|            0|  0.00%|        torch._C._log_api_usage_once("python.optimizer")
    35|         0|            0|            0|  0.00%|        self.defaults = defaults
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|        self._hook_for_profile()
    38|         0|            0|            0|  0.00%|
    39|         0|            0|            0|  0.00%|        if isinstance(params, torch.Tensor):
    40|         0|            0|            0|  0.00%|            raise TypeError("params argument given to the optimizer should be "
    41|         0|            0|            0|  0.00%|                            "an iterable of Tensors or dicts, but got " +
    42|         0|            0|            0|  0.00%|                            torch.typename(params))
    43|         0|            0|            0|  0.00%|
    44|         0|            0|            0|  0.00%|        self.state = defaultdict(dict)
    45|         0|            0|            0|  0.00%|        self.param_groups = []
    46|         0|            0|            0|  0.00%|
    47|         0|            0|            0|  0.00%|        param_groups = list(params)
    48|         0|            0|            0|  0.00%|        if len(param_groups) == 0:
    49|         0|            0|            0|  0.00%|            raise ValueError("optimizer got an empty parameter list")
    50|         0|            0|            0|  0.00%|        if not isinstance(param_groups[0], dict):
    51|         0|            0|            0|  0.00%|            param_groups = [{'params': param_groups}]
    52|         0|            0|            0|  0.00%|
    53|         0|            0|            0|  0.00%|        for param_group in param_groups:
    54|         0|            0|            0|  0.00%|            self.add_param_group(param_group)
    55|         0|            0|            0|  0.00%|
    56|         0|            0|            0|  0.00%|        # Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,
    57|         0|            0|            0|  0.00%|        # which I don't think exists
    58|         0|            0|            0|  0.00%|        # https://github.com/pytorch/pytorch/issues/72948
    59|         0|            0|            0|  0.00%|        self._warned_capturable_if_run_uncaptured = True
    60|         0|            0|            0|  0.00%|
    61|         0|            0|            0|  0.00%|    def __getstate__(self):
    62|         0|            0|            0|  0.00%|        return {
    63|         0|            0|            0|  0.00%|            'defaults': self.defaults,
    64|         0|            0|            0|  0.00%|            'state': self.state,
    65|         0|            0|            0|  0.00%|            'param_groups': self.param_groups,
    66|         0|            0|            0|  0.00%|        }
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|    def __setstate__(self, state):
    69|         0|            0|            0|  0.00%|        self.__dict__.update(state)
    70|         0|            0|            0|  0.00%|        self._hook_for_profile()  # To support multiprocessing pickle/unpickle.
    71|         0|            0|            0|  0.00%|
    72|         0|            0|            0|  0.00%|    def __repr__(self):
    73|         0|            0|            0|  0.00%|        format_string = self.__class__.__name__ + ' ('
    74|         0|            0|            0|  0.00%|        for i, group in enumerate(self.param_groups):
    75|         0|            0|            0|  0.00%|            format_string += '\n'
    76|         0|            0|            0|  0.00%|            format_string += 'Parameter Group {0}\n'.format(i)
    77|         0|            0|            0|  0.00%|            for key in sorted(group.keys()):
    78|         0|            0|            0|  0.00%|                if key != 'params':
    79|         0|            0|            0|  0.00%|                    format_string += '    {0}: {1}\n'.format(key, group[key])
    80|         0|            0|            0|  0.00%|        format_string += ')'
    81|         0|            0|            0|  0.00%|        return format_string
    82|         0|            0|            0|  0.00%|
    83|         0|            0|            0|  0.00%|    # Currently needed by Adam and AdamW
    84|       288|  0.000671625|  2.33203e-06|  0.00%|    def _cuda_graph_capture_health_check(self):
    85|       288|   0.00199103|  6.91331e-06|  0.00%|        if torch.has_cuda and torch.cuda.is_available():
(call)|       288|    0.0021255|  7.38021e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:77 is_available
    86|       288|   0.00168419|  5.84788e-06|  0.00%|            capturing = torch.cuda.is_current_stream_capturing()
(call)|       288|   0.00100851|  3.50177e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/cuda/graphs.py:18 is_current_stream_capturing
    87|         0|            0|            0|  0.00%|
    88|       288|  0.000517607|  1.79725e-06|  0.00%|            if capturing and not self.defaults['capturable']:
    89|         0|            0|            0|  0.00%|                raise RuntimeError("Attempting CUDA graph capture of step() for an instance of " +
    90|         0|            0|            0|  0.00%|                                   self.__class__.__name__ +
    91|         0|            0|            0|  0.00%|                                   " but this instance was constructed with capturable=False.")
    92|         0|            0|            0|  0.00%|
    93|       288|  0.000527143|  1.83036e-06|  0.00%|            if (
    94|       288|  0.000661135|  2.29561e-06|  0.00%|                (not getattr(self, "_warned_capturable_if_run_uncaptured", False))
    95|         0|            0|            0|  0.00%|                and self.defaults["capturable"]
    96|         0|            0|            0|  0.00%|                and (not capturing)
    97|         0|            0|            0|  0.00%|            ):
    98|         0|            0|            0|  0.00%|                print("Warning: This instance was constructed with capturable=True, but step() " +
    99|         0|            0|            0|  0.00%|                      "is running without CUDA graph capture. If you never intend to graph-capture this " +
   100|         0|            0|            0|  0.00%|                      "instance, capturable=True can impair performance, and you should set capturable=False.")
   101|         0|            0|            0|  0.00%|                self._warned_capturable_if_run_uncaptured = True
   102|         0|            0|            0|  0.00%|
   103|         0|            0|            0|  0.00%|    def _hook_for_profile(self):
   104|         0|            0|            0|  0.00%|        self._zero_grad_profile_name = "Optimizer.zero_grad#{}.zero_grad".format(self.__class__.__name__)
   105|         0|            0|            0|  0.00%|
   106|         0|            0|            0|  0.00%|        def profile_hook_step(func):
   107|         0|            0|            0|  0.00%|
   108|       288|   0.00109935|  3.81718e-06|  0.00%|            @functools.wraps(func)
   109|         0|            0|            0|  0.00%|            def wrapper(*args, **kwargs):
   110|       288|   0.00108337|  3.76172e-06|  0.00%|                obj, *_ = args
   111|       288|   0.00144362|  5.01259e-06|  0.00%|                profile_name = "Optimizer.step#{}.step".format(obj.__class__.__name__)
   112|       288|   0.00378132|  1.31296e-05|  0.00%|                with torch.autograd.profiler.record_function(profile_name):
(call)|       288|   0.00553441|  1.92167e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/profiler.py:436 __init__
(call)|       288|   0.00848794|   2.9472e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/profiler.py:445 __enter__
   113|       288|   0.00396943|  1.37827e-05|  0.00%|                    return func(*args, **kwargs)
(call)|       288|      0.74016|      0.00257|  0.71%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:24 decorate_context
(call)|       288|   0.00697231|  2.42094e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/profiler.py:449 __exit__
   114|         0|            0|            0|  0.00%|            return wrapper
   115|         0|            0|            0|  0.00%|
   116|         0|            0|            0|  0.00%|        hooked = getattr(self.__class__.step, "hooked", None)
   117|         0|            0|            0|  0.00%|        if not hooked:
   118|         0|            0|            0|  0.00%|            self.__class__.step = profile_hook_step(self.__class__.step)
   119|         0|            0|            0|  0.00%|            self.__class__.step.hooked = True
   120|         0|            0|            0|  0.00%|
   121|         0|            0|            0|  0.00%|    def state_dict(self):
   122|         0|            0|            0|  0.00%|        r"""Returns the state of the optimizer as a :class:`dict`.
   123|         0|            0|            0|  0.00%|
   124|         0|            0|            0|  0.00%|        It contains two entries:
   125|         0|            0|            0|  0.00%|
   126|         0|            0|            0|  0.00%|        * state - a dict holding current optimization state. Its content
   127|         0|            0|            0|  0.00%|            differs between optimizer classes.
   128|         0|            0|            0|  0.00%|        * param_groups - a list containing all parameter groups where each
   129|         0|            0|            0|  0.00%|            parameter group is a dict
   130|         0|            0|            0|  0.00%|        """
   131|         0|            0|            0|  0.00%|        # Save order indices instead of Tensors
   132|         0|            0|            0|  0.00%|        param_mappings = {}
   133|         0|            0|            0|  0.00%|        start_index = 0
   134|         0|            0|            0|  0.00%|
   135|         0|            0|            0|  0.00%|        def pack_group(group):
   136|         0|            0|            0|  0.00%|            nonlocal start_index
   137|         0|            0|            0|  0.00%|            packed = {k: v for k, v in group.items() if k != 'params'}
   138|         0|            0|            0|  0.00%|            param_mappings.update({id(p): i for i, p in enumerate(group['params'], start_index)
   139|         0|            0|            0|  0.00%|                                   if id(p) not in param_mappings})
   140|         0|            0|            0|  0.00%|            packed['params'] = [param_mappings[id(p)] for p in group['params']]
   141|         0|            0|            0|  0.00%|            start_index += len(packed['params'])
   142|         0|            0|            0|  0.00%|            return packed
   143|         0|            0|            0|  0.00%|        param_groups = [pack_group(g) for g in self.param_groups]
   144|         0|            0|            0|  0.00%|        # Remap state to use order indices as keys
   145|         0|            0|            0|  0.00%|        packed_state = {(param_mappings[id(k)] if isinstance(k, torch.Tensor) else k): v
   146|         0|            0|            0|  0.00%|                        for k, v in self.state.items()}
   147|         0|            0|            0|  0.00%|        return {
   148|         0|            0|            0|  0.00%|            'state': packed_state,
   149|         0|            0|            0|  0.00%|            'param_groups': param_groups,
   150|         0|            0|            0|  0.00%|        }
   151|         0|            0|            0|  0.00%|
   152|         0|            0|            0|  0.00%|    def load_state_dict(self, state_dict):
   153|         0|            0|            0|  0.00%|        r"""Loads the optimizer state.
   154|         0|            0|            0|  0.00%|
   155|         0|            0|            0|  0.00%|        Args:
   156|         0|            0|            0|  0.00%|            state_dict (dict): optimizer state. Should be an object returned
   157|         0|            0|            0|  0.00%|                from a call to :meth:`state_dict`.
   158|         0|            0|            0|  0.00%|        """
   159|         0|            0|            0|  0.00%|        # deepcopy, to be consistent with module API
   160|         0|            0|            0|  0.00%|        state_dict = deepcopy(state_dict)
   161|         0|            0|            0|  0.00%|        # Validate the state_dict
   162|         0|            0|            0|  0.00%|        groups = self.param_groups
   163|         0|            0|            0|  0.00%|        saved_groups = state_dict['param_groups']
   164|         0|            0|            0|  0.00%|
   165|         0|            0|            0|  0.00%|        if len(groups) != len(saved_groups):
   166|         0|            0|            0|  0.00%|            raise ValueError("loaded state dict has a different number of "
   167|         0|            0|            0|  0.00%|                             "parameter groups")
   168|         0|            0|            0|  0.00%|        param_lens = (len(g['params']) for g in groups)
   169|         0|            0|            0|  0.00%|        saved_lens = (len(g['params']) for g in saved_groups)
   170|         0|            0|            0|  0.00%|        if any(p_len != s_len for p_len, s_len in zip(param_lens, saved_lens)):
   171|         0|            0|            0|  0.00%|            raise ValueError("loaded state dict contains a parameter group "
   172|         0|            0|            0|  0.00%|                             "that doesn't match the size of optimizer's group")
   173|         0|            0|            0|  0.00%|
   174|         0|            0|            0|  0.00%|        # Update the state
   175|         0|            0|            0|  0.00%|        id_map = {old_id: p for old_id, p in
   176|         0|            0|            0|  0.00%|                  zip(chain.from_iterable((g['params'] for g in saved_groups)),
   177|         0|            0|            0|  0.00%|                      chain.from_iterable((g['params'] for g in groups)))}
   178|         0|            0|            0|  0.00%|
   179|         0|            0|            0|  0.00%|        def cast(param, value, key=None):
   180|         0|            0|            0|  0.00%|            r"""Make a deep copy of value, casting all tensors to device of param."""
   181|         0|            0|            0|  0.00%|            if isinstance(value, torch.Tensor):
   182|         0|            0|            0|  0.00%|                # Floating-point types are a bit special here. They are the only ones
   183|         0|            0|            0|  0.00%|                # that are assumed to always match the type of params.
   184|         0|            0|            0|  0.00%|                # Make sure state['step'] is not casted https://github.com/pytorch/pytorch/issues/74424
   185|         0|            0|            0|  0.00%|                if (key != "step"):
   186|         0|            0|            0|  0.00%|                    if param.is_floating_point():
   187|         0|            0|            0|  0.00%|                        value = value.to(param.dtype)
   188|         0|            0|            0|  0.00%|                    value = value.to(param.device)
   189|         0|            0|            0|  0.00%|                return value
   190|         0|            0|            0|  0.00%|            elif isinstance(value, dict):
   191|         0|            0|            0|  0.00%|                return {k: cast(param, v, key=k) for k, v in value.items()}
   192|         0|            0|            0|  0.00%|            elif isinstance(value, container_abcs.Iterable):
   193|         0|            0|            0|  0.00%|                return type(value)(cast(param, v) for v in value)
   194|         0|            0|            0|  0.00%|            else:
   195|         0|            0|            0|  0.00%|                return value
   196|         0|            0|            0|  0.00%|
   197|         0|            0|            0|  0.00%|        # Copy state assigned to params (and cast tensors to appropriate types).
   198|         0|            0|            0|  0.00%|        # State that is not assigned to params is copied as is (needed for
   199|         0|            0|            0|  0.00%|        # backward compatibility).
   200|         0|            0|            0|  0.00%|        state = defaultdict(dict)
   201|         0|            0|            0|  0.00%|        for k, v in state_dict['state'].items():
   202|         0|            0|            0|  0.00%|            if k in id_map:
   203|         0|            0|            0|  0.00%|                param = id_map[k]
   204|         0|            0|            0|  0.00%|                state[param] = cast(param, v)
   205|         0|            0|            0|  0.00%|            else:
   206|         0|            0|            0|  0.00%|                state[k] = v
   207|         0|            0|            0|  0.00%|
   208|         0|            0|            0|  0.00%|        # Update parameter groups, setting their 'params' value
   209|         0|            0|            0|  0.00%|        def update_group(group, new_group):
   210|         0|            0|            0|  0.00%|            new_group['params'] = group['params']
   211|         0|            0|            0|  0.00%|            return new_group
   212|         0|            0|            0|  0.00%|        param_groups = [
   213|         0|            0|            0|  0.00%|            update_group(g, ng) for g, ng in zip(groups, saved_groups)]
   214|         0|            0|            0|  0.00%|        self.__setstate__({'state': state, 'param_groups': param_groups})
   215|         0|            0|            0|  0.00%|
   216|       288|    0.0014832|  5.15001e-06|  0.00%|    def zero_grad(self, set_to_none: bool = False):
   217|         0|            0|            0|  0.00%|        r"""Sets the gradients of all optimized :class:`torch.Tensor` s to zero.
   218|         0|            0|            0|  0.00%|
   219|         0|            0|            0|  0.00%|        Args:
   220|         0|            0|            0|  0.00%|            set_to_none (bool): instead of setting to zero, set the grads to None.
   221|         0|            0|            0|  0.00%|                This will in general have lower memory footprint, and can modestly improve performance.
   222|         0|            0|            0|  0.00%|                However, it changes certain behaviors. For example:
   223|         0|            0|            0|  0.00%|                1. When the user tries to access a gradient and perform manual ops on it,
   224|         0|            0|            0|  0.00%|                a None attribute or a Tensor full of 0s will behave differently.
   225|         0|            0|            0|  0.00%|                2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\ s
   226|         0|            0|            0|  0.00%|                are guaranteed to be None for params that did not receive a gradient.
   227|         0|            0|            0|  0.00%|                3. ``torch.optim`` optimizers have a different behavior if the gradient is 0 or None
   228|         0|            0|            0|  0.00%|                (in one case it does the step with a gradient of 0 and in the other it skips
   229|         0|            0|            0|  0.00%|                the step altogether).
   230|         0|            0|            0|  0.00%|        """
   231|       288|    0.0012033|  4.17812e-06|  0.00%|        foreach = self.defaults.get('foreach', False)
   232|         0|            0|            0|  0.00%|
   233|       288|   0.00108266|  3.75923e-06|  0.00%|        if not hasattr(self, "_zero_grad_profile_name"):
   234|         0|            0|            0|  0.00%|            self._hook_for_profile()
   235|       288|  0.000808001|  2.80556e-06|  0.00%|        if foreach:
   236|         0|            0|            0|  0.00%|            per_device_and_dtype_grads = defaultdict(lambda: defaultdict(list))
   237|       288|   0.00446177|  1.54922e-05|  0.00%|        with torch.autograd.profiler.record_function(self._zero_grad_profile_name):
(call)|       288|   0.00524449|    1.821e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/profiler.py:436 __init__
(call)|       288|   0.00847602|  2.94306e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/profiler.py:445 __enter__
   238|       576|   0.00178599|  3.10068e-06|  0.00%|            for group in self.param_groups:
   239|      3744|   0.00944042|  2.52148e-06|  0.01%|                for p in group['params']:
   240|      3456|    0.0213237|  6.17005e-06|  0.02%|                    if p.grad is not None:
(call)|      3456|    0.0173101|  5.00872e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:1071 grad
   241|      3456|   0.00814271|  2.35611e-06|  0.01%|                        if set_to_none:
   242|         0|            0|            0|  0.00%|                            p.grad = None
   243|         0|            0|            0|  0.00%|                        else:
   244|      3456|    0.0218713|  6.32851e-06|  0.02%|                            if p.grad.grad_fn is not None:
(call)|      3456|    0.0161383|  4.66965e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:1071 grad
   245|         0|            0|            0|  0.00%|                                p.grad.detach_()
   246|         0|            0|            0|  0.00%|                            else:
   247|      3456|    0.0229511|  6.64095e-06|  0.02%|                                p.grad.requires_grad_(False)
(call)|      3456|    0.0159771|  4.62302e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:1071 grad
   248|      3456|   0.00826573|  2.39171e-06|  0.01%|                            if (not foreach or p.grad.is_sparse):
   249|      3456|    0.0264077|  7.64112e-06|  0.03%|                                p.grad.zero_()
(call)|      3456|    0.0161479|  4.67241e-06|  0.02%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_tensor.py:1071 grad
   250|         0|            0|            0|  0.00%|                            else:
   251|         0|            0|            0|  0.00%|                                per_device_and_dtype_grads[p.grad.device][p.grad.dtype].append(p.grad)
   252|       288|   0.00248361|  8.62363e-06|  0.00%|            if foreach:
(call)|       288|   0.00511765|  1.77696e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/profiler.py:449 __exit__
   253|         0|            0|            0|  0.00%|                for _, per_dtype_grads in per_device_and_dtype_grads.items():
   254|         0|            0|            0|  0.00%|                    for grads in per_dtype_grads.values():
   255|         0|            0|            0|  0.00%|                        torch._foreach_zero_(grads)
   256|         0|            0|            0|  0.00%|
   257|         0|            0|            0|  0.00%|    def step(self, closure):
   258|         0|            0|            0|  0.00%|        r"""Performs a single optimization step (parameter update).
   259|         0|            0|            0|  0.00%|
   260|         0|            0|            0|  0.00%|        Args:
   261|         0|            0|            0|  0.00%|            closure (callable): A closure that reevaluates the model and
   262|         0|            0|            0|  0.00%|                returns the loss. Optional for most optimizers.
   263|         0|            0|            0|  0.00%|
   264|         0|            0|            0|  0.00%|        .. note::
   265|         0|            0|            0|  0.00%|            Unless otherwise specified, this function should not modify the
   266|         0|            0|            0|  0.00%|            ``.grad`` field of the parameters.
   267|         0|            0|            0|  0.00%|        """
   268|         0|            0|            0|  0.00%|        raise NotImplementedError
   269|         0|            0|            0|  0.00%|
   270|         0|            0|            0|  0.00%|    def add_param_group(self, param_group):
   271|         0|            0|            0|  0.00%|        r"""Add a param group to the :class:`Optimizer` s `param_groups`.
   272|         0|            0|            0|  0.00%|
   273|         0|            0|            0|  0.00%|        This can be useful when fine tuning a pre-trained network as frozen layers can be made
   274|         0|            0|            0|  0.00%|        trainable and added to the :class:`Optimizer` as training progresses.
   275|         0|            0|            0|  0.00%|
   276|         0|            0|            0|  0.00%|        Args:
   277|         0|            0|            0|  0.00%|            param_group (dict): Specifies what Tensors should be optimized along with group
   278|         0|            0|            0|  0.00%|                specific optimization options.
   279|         0|            0|            0|  0.00%|        """
   280|         0|            0|            0|  0.00%|        assert isinstance(param_group, dict), "param group must be a dict"
   281|         0|            0|            0|  0.00%|
   282|         0|            0|            0|  0.00%|        params = param_group['params']
   283|         0|            0|            0|  0.00%|        if isinstance(params, torch.Tensor):
   284|         0|            0|            0|  0.00%|            param_group['params'] = [params]
   285|         0|            0|            0|  0.00%|        elif isinstance(params, set):
   286|         0|            0|            0|  0.00%|            raise TypeError('optimizer parameters need to be organized in ordered collections, but '
   287|         0|            0|            0|  0.00%|                            'the ordering of tensors in sets will change between runs. Please use a list instead.')
   288|         0|            0|            0|  0.00%|        else:
   289|         0|            0|            0|  0.00%|            param_group['params'] = list(params)
   290|         0|            0|            0|  0.00%|
   291|         0|            0|            0|  0.00%|        for param in param_group['params']:
   292|         0|            0|            0|  0.00%|            if not isinstance(param, torch.Tensor):
   293|         0|            0|            0|  0.00%|                raise TypeError("optimizer can only optimize Tensors, "
   294|         0|            0|            0|  0.00%|                                "but one of the params is " + torch.typename(param))
   295|         0|            0|            0|  0.00%|            if not param.is_leaf:
   296|         0|            0|            0|  0.00%|                raise ValueError("can't optimize a non-leaf Tensor")
   297|         0|            0|            0|  0.00%|
   298|         0|            0|            0|  0.00%|        for name, default in self.defaults.items():
   299|         0|            0|            0|  0.00%|            if default is required and name not in param_group:
   300|         0|            0|            0|  0.00%|                raise ValueError("parameter group didn't specify a value of required optimization parameter " +
   301|         0|            0|            0|  0.00%|                                 name)
   302|         0|            0|            0|  0.00%|            else:
   303|         0|            0|            0|  0.00%|                param_group.setdefault(name, default)
   304|         0|            0|            0|  0.00%|
   305|         0|            0|            0|  0.00%|        params = param_group['params']
   306|         0|            0|            0|  0.00%|        if len(params) != len(set(params)):
   307|         0|            0|            0|  0.00%|            warnings.warn("optimizer contains a parameter group with duplicate parameters; "
   308|         0|            0|            0|  0.00%|                          "in future, this will cause an error; "
   309|         0|            0|            0|  0.00%|                          "see github.com/pytorch/pytorch/issues/40967 for more information", stacklevel=3)
   310|         0|            0|            0|  0.00%|
   311|         0|            0|            0|  0.00%|        param_set = set()
   312|         0|            0|            0|  0.00%|        for group in self.param_groups:
   313|         0|            0|            0|  0.00%|            param_set.update(set(group['params']))
   314|         0|            0|            0|  0.00%|
   315|         0|            0|            0|  0.00%|        if not param_set.isdisjoint(set(param_group['params'])):
   316|         0|            0|            0|  0.00%|            raise ValueError("some parameters appear in more than one parameter group")
   317|         0|            0|            0|  0.00%|
   318|         0|            0|            0|  0.00%|        self.param_groups.append(param_group)
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py
File duration: 0.141984s (0.14%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import warnings
     2|         0|            0|            0|  0.00%|from typing import Optional, Tuple
     3|         0|            0|            0|  0.00%|
     4|         0|            0|            0|  0.00%|import torch
     5|         0|            0|            0|  0.00%|from torch import Tensor
     6|         0|            0|            0|  0.00%|from .linear import NonDynamicallyQuantizableLinear
     7|         0|            0|            0|  0.00%|from torch.nn.init import constant_, xavier_normal_, xavier_uniform_
     8|         0|            0|            0|  0.00%|from torch.nn.parameter import Parameter
     9|         0|            0|            0|  0.00%|from .module import Module
    10|         0|            0|            0|  0.00%|from .. import functional as F
    11|         0|            0|            0|  0.00%|
    12|         0|            0|            0|  0.00%|
    13|         0|            0|            0|  0.00%|class Threshold(Module):
    14|         0|            0|            0|  0.00%|    r"""Thresholds each element of the input Tensor.
    15|         0|            0|            0|  0.00%|
    16|         0|            0|            0|  0.00%|    Threshold is defined as:
    17|         0|            0|            0|  0.00%|
    18|         0|            0|            0|  0.00%|    .. math::
    19|         0|            0|            0|  0.00%|        y =
    20|         0|            0|            0|  0.00%|        \begin{cases}
    21|         0|            0|            0|  0.00%|        x, &\text{ if } x > \text{threshold} \\
    22|         0|            0|            0|  0.00%|        \text{value}, &\text{ otherwise }
    23|         0|            0|            0|  0.00%|        \end{cases}
    24|         0|            0|            0|  0.00%|
    25|         0|            0|            0|  0.00%|    Args:
    26|         0|            0|            0|  0.00%|        threshold: The value to threshold at
    27|         0|            0|            0|  0.00%|        value: The value to replace with
    28|         0|            0|            0|  0.00%|        inplace: can optionally do the operation in-place. Default: ``False``
    29|         0|            0|            0|  0.00%|
    30|         0|            0|            0|  0.00%|    Shape:
    31|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
    32|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
    33|         0|            0|            0|  0.00%|
    34|         0|            0|            0|  0.00%|    Examples::
    35|         0|            0|            0|  0.00%|
    36|         0|            0|            0|  0.00%|        >>> m = nn.Threshold(0.1, 20)
    37|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
    38|         0|            0|            0|  0.00%|        >>> output = m(input)
    39|         0|            0|            0|  0.00%|    """
    40|         0|            0|            0|  0.00%|    __constants__ = ['threshold', 'value', 'inplace']
    41|         0|            0|            0|  0.00%|
    42|         0|            0|            0|  0.00%|    threshold: float
    43|         0|            0|            0|  0.00%|    value: float
    44|         0|            0|            0|  0.00%|    inplace: bool
    45|         0|            0|            0|  0.00%|
    46|         0|            0|            0|  0.00%|    def __init__(self, threshold: float, value: float, inplace: bool = False) -> None:
    47|         0|            0|            0|  0.00%|        super(Threshold, self).__init__()
    48|         0|            0|            0|  0.00%|        self.threshold = threshold
    49|         0|            0|            0|  0.00%|        self.value = value
    50|         0|            0|            0|  0.00%|        self.inplace = inplace
    51|         0|            0|            0|  0.00%|        # TODO: check in THNN (if inplace == True, then assert value <= threshold)
    52|         0|            0|            0|  0.00%|
    53|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
    54|         0|            0|            0|  0.00%|        return F.threshold(input, self.threshold, self.value, self.inplace)
    55|         0|            0|            0|  0.00%|
    56|         0|            0|            0|  0.00%|    def extra_repr(self):
    57|         0|            0|            0|  0.00%|        inplace_str = ', inplace=True' if self.inplace else ''
    58|         0|            0|            0|  0.00%|        return 'threshold={}, value={}{}'.format(
    59|         0|            0|            0|  0.00%|            self.threshold, self.value, inplace_str
    60|         0|            0|            0|  0.00%|        )
    61|         0|            0|            0|  0.00%|
    62|         0|            0|            0|  0.00%|
    63|         0|            0|            0|  0.00%|class ReLU(Module):
    64|         0|            0|            0|  0.00%|    r"""Applies the rectified linear unit function element-wise:
    65|         0|            0|            0|  0.00%|
    66|         0|            0|            0|  0.00%|    :math:`\text{ReLU}(x) = (x)^+ = \max(0, x)`
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|    Args:
    69|         0|            0|            0|  0.00%|        inplace: can optionally do the operation in-place. Default: ``False``
    70|         0|            0|            0|  0.00%|
    71|         0|            0|            0|  0.00%|    Shape:
    72|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
    73|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
    74|         0|            0|            0|  0.00%|
    75|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/ReLU.png
    76|         0|            0|            0|  0.00%|
    77|         0|            0|            0|  0.00%|    Examples::
    78|         0|            0|            0|  0.00%|
    79|         0|            0|            0|  0.00%|        >>> m = nn.ReLU()
    80|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
    81|         0|            0|            0|  0.00%|        >>> output = m(input)
    82|         0|            0|            0|  0.00%|
    83|         0|            0|            0|  0.00%|
    84|         0|            0|            0|  0.00%|      An implementation of CReLU - https://arxiv.org/abs/1603.05201
    85|         0|            0|            0|  0.00%|
    86|         0|            0|            0|  0.00%|        >>> m = nn.ReLU()
    87|         0|            0|            0|  0.00%|        >>> input = torch.randn(2).unsqueeze(0)
    88|         0|            0|            0|  0.00%|        >>> output = torch.cat((m(input),m(-input)))
    89|         0|            0|            0|  0.00%|    """
    90|         0|            0|            0|  0.00%|    __constants__ = ['inplace']
    91|         0|            0|            0|  0.00%|    inplace: bool
    92|         0|            0|            0|  0.00%|
    93|         0|            0|            0|  0.00%|    def __init__(self, inplace: bool = False):
    94|         0|            0|            0|  0.00%|        super(ReLU, self).__init__()
    95|         0|            0|            0|  0.00%|        self.inplace = inplace
    96|         0|            0|            0|  0.00%|
    97|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
    98|         0|            0|            0|  0.00%|        return F.relu(input, inplace=self.inplace)
    99|         0|            0|            0|  0.00%|
   100|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   101|         0|            0|            0|  0.00%|        inplace_str = 'inplace=True' if self.inplace else ''
   102|         0|            0|            0|  0.00%|        return inplace_str
   103|         0|            0|            0|  0.00%|
   104|         0|            0|            0|  0.00%|
   105|         0|            0|            0|  0.00%|class RReLU(Module):
   106|         0|            0|            0|  0.00%|    r"""Applies the randomized leaky rectified liner unit function, element-wise,
   107|         0|            0|            0|  0.00%|    as described in the paper:
   108|         0|            0|            0|  0.00%|
   109|         0|            0|            0|  0.00%|    `Empirical Evaluation of Rectified Activations in Convolutional Network`_.
   110|         0|            0|            0|  0.00%|
   111|         0|            0|            0|  0.00%|    The function is defined as:
   112|         0|            0|            0|  0.00%|
   113|         0|            0|            0|  0.00%|    .. math::
   114|         0|            0|            0|  0.00%|        \text{RReLU}(x) =
   115|         0|            0|            0|  0.00%|        \begin{cases}
   116|         0|            0|            0|  0.00%|            x & \text{if } x \geq 0 \\
   117|         0|            0|            0|  0.00%|            ax & \text{ otherwise }
   118|         0|            0|            0|  0.00%|        \end{cases}
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|    where :math:`a` is randomly sampled from uniform distribution
   121|         0|            0|            0|  0.00%|    :math:`\mathcal{U}(\text{lower}, \text{upper})`.
   122|         0|            0|            0|  0.00%|
   123|         0|            0|            0|  0.00%|     See: https://arxiv.org/pdf/1505.00853.pdf
   124|         0|            0|            0|  0.00%|
   125|         0|            0|            0|  0.00%|    Args:
   126|         0|            0|            0|  0.00%|        lower: lower bound of the uniform distribution. Default: :math:`\frac{1}{8}`
   127|         0|            0|            0|  0.00%|        upper: upper bound of the uniform distribution. Default: :math:`\frac{1}{3}`
   128|         0|            0|            0|  0.00%|        inplace: can optionally do the operation in-place. Default: ``False``
   129|         0|            0|            0|  0.00%|
   130|         0|            0|            0|  0.00%|    Shape:
   131|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   132|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   133|         0|            0|            0|  0.00%|
   134|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/RReLU.png
   135|         0|            0|            0|  0.00%|
   136|         0|            0|            0|  0.00%|    Examples::
   137|         0|            0|            0|  0.00%|
   138|         0|            0|            0|  0.00%|        >>> m = nn.RReLU(0.1, 0.3)
   139|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   140|         0|            0|            0|  0.00%|        >>> output = m(input)
   141|         0|            0|            0|  0.00%|
   142|         0|            0|            0|  0.00%|    .. _`Empirical Evaluation of Rectified Activations in Convolutional Network`:
   143|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1505.00853
   144|         0|            0|            0|  0.00%|    """
   145|         0|            0|            0|  0.00%|    __constants__ = ['lower', 'upper', 'inplace']
   146|         0|            0|            0|  0.00%|
   147|         0|            0|            0|  0.00%|    lower: float
   148|         0|            0|            0|  0.00%|    upper: float
   149|         0|            0|            0|  0.00%|    inplace: bool
   150|         0|            0|            0|  0.00%|
   151|         0|            0|            0|  0.00%|    def __init__(
   152|         0|            0|            0|  0.00%|        self,
   153|         0|            0|            0|  0.00%|        lower: float = 1. / 8,
   154|         0|            0|            0|  0.00%|        upper: float = 1. / 3,
   155|         0|            0|            0|  0.00%|        inplace: bool = False
   156|         0|            0|            0|  0.00%|    ):
   157|         0|            0|            0|  0.00%|        super(RReLU, self).__init__()
   158|         0|            0|            0|  0.00%|        self.lower = lower
   159|         0|            0|            0|  0.00%|        self.upper = upper
   160|         0|            0|            0|  0.00%|        self.inplace = inplace
   161|         0|            0|            0|  0.00%|
   162|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   163|         0|            0|            0|  0.00%|        return F.rrelu(input, self.lower, self.upper, self.training, self.inplace)
   164|         0|            0|            0|  0.00%|
   165|         0|            0|            0|  0.00%|    def extra_repr(self):
   166|         0|            0|            0|  0.00%|        inplace_str = ', inplace=True' if self.inplace else ''
   167|         0|            0|            0|  0.00%|        return 'lower={}, upper={}{}'.format(self.lower, self.upper, inplace_str)
   168|         0|            0|            0|  0.00%|
   169|         0|            0|            0|  0.00%|
   170|         0|            0|            0|  0.00%|class Hardtanh(Module):
   171|         0|            0|            0|  0.00%|    r"""Applies the HardTanh function element-wise.
   172|         0|            0|            0|  0.00%|
   173|         0|            0|            0|  0.00%|    HardTanh is defined as:
   174|         0|            0|            0|  0.00%|
   175|         0|            0|            0|  0.00%|    .. math::
   176|         0|            0|            0|  0.00%|        \text{HardTanh}(x) = \begin{cases}
   177|         0|            0|            0|  0.00%|            \text{max\_val} & \text{ if } x > \text{ max\_val } \\
   178|         0|            0|            0|  0.00%|            \text{min\_val} & \text{ if } x < \text{ min\_val } \\
   179|         0|            0|            0|  0.00%|            x & \text{ otherwise } \\
   180|         0|            0|            0|  0.00%|        \end{cases}
   181|         0|            0|            0|  0.00%|
   182|         0|            0|            0|  0.00%|    Args:
   183|         0|            0|            0|  0.00%|        min_val: minimum value of the linear region range. Default: -1
   184|         0|            0|            0|  0.00%|        max_val: maximum value of the linear region range. Default: 1
   185|         0|            0|            0|  0.00%|        inplace: can optionally do the operation in-place. Default: ``False``
   186|         0|            0|            0|  0.00%|
   187|         0|            0|            0|  0.00%|    Keyword arguments :attr:`min_value` and :attr:`max_value`
   188|         0|            0|            0|  0.00%|    have been deprecated in favor of :attr:`min_val` and :attr:`max_val`.
   189|         0|            0|            0|  0.00%|
   190|         0|            0|            0|  0.00%|    Shape:
   191|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   192|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   193|         0|            0|            0|  0.00%|
   194|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/Hardtanh.png
   195|         0|            0|            0|  0.00%|
   196|         0|            0|            0|  0.00%|    Examples::
   197|         0|            0|            0|  0.00%|
   198|         0|            0|            0|  0.00%|        >>> m = nn.Hardtanh(-2, 2)
   199|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   200|         0|            0|            0|  0.00%|        >>> output = m(input)
   201|         0|            0|            0|  0.00%|    """
   202|         0|            0|            0|  0.00%|    __constants__ = ['min_val', 'max_val', 'inplace']
   203|         0|            0|            0|  0.00%|
   204|         0|            0|            0|  0.00%|    min_val: float
   205|         0|            0|            0|  0.00%|    max_val: float
   206|         0|            0|            0|  0.00%|    inplace: bool
   207|         0|            0|            0|  0.00%|
   208|         0|            0|            0|  0.00%|    def __init__(
   209|         0|            0|            0|  0.00%|        self,
   210|         0|            0|            0|  0.00%|        min_val: float = -1.,
   211|         0|            0|            0|  0.00%|        max_val: float = 1.,
   212|         0|            0|            0|  0.00%|        inplace: bool = False,
   213|         0|            0|            0|  0.00%|        min_value: Optional[float] = None,
   214|         0|            0|            0|  0.00%|        max_value: Optional[float] = None
   215|         0|            0|            0|  0.00%|    ) -> None:
   216|         0|            0|            0|  0.00%|        super(Hardtanh, self).__init__()
   217|         0|            0|            0|  0.00%|        if min_value is not None:
   218|         0|            0|            0|  0.00%|            warnings.warn("keyword argument min_value is deprecated and rename to min_val")
   219|         0|            0|            0|  0.00%|            min_val = min_value
   220|         0|            0|            0|  0.00%|        if max_value is not None:
   221|         0|            0|            0|  0.00%|            warnings.warn("keyword argument max_value is deprecated and rename to max_val")
   222|         0|            0|            0|  0.00%|            max_val = max_value
   223|         0|            0|            0|  0.00%|
   224|         0|            0|            0|  0.00%|        self.min_val = min_val
   225|         0|            0|            0|  0.00%|        self.max_val = max_val
   226|         0|            0|            0|  0.00%|        self.inplace = inplace
   227|         0|            0|            0|  0.00%|        assert self.max_val > self.min_val
   228|         0|            0|            0|  0.00%|
   229|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   230|         0|            0|            0|  0.00%|        return F.hardtanh(input, self.min_val, self.max_val, self.inplace)
   231|         0|            0|            0|  0.00%|
   232|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   233|         0|            0|            0|  0.00%|        inplace_str = ', inplace=True' if self.inplace else ''
   234|         0|            0|            0|  0.00%|        return 'min_val={}, max_val={}{}'.format(
   235|         0|            0|            0|  0.00%|            self.min_val, self.max_val, inplace_str
   236|         0|            0|            0|  0.00%|        )
   237|         0|            0|            0|  0.00%|
   238|         0|            0|            0|  0.00%|
   239|         0|            0|            0|  0.00%|class ReLU6(Hardtanh):
   240|         0|            0|            0|  0.00%|    r"""Applies the element-wise function:
   241|         0|            0|            0|  0.00%|
   242|         0|            0|            0|  0.00%|    .. math::
   243|         0|            0|            0|  0.00%|        \text{ReLU6}(x) = \min(\max(0,x), 6)
   244|         0|            0|            0|  0.00%|
   245|         0|            0|            0|  0.00%|    Args:
   246|         0|            0|            0|  0.00%|        inplace: can optionally do the operation in-place. Default: ``False``
   247|         0|            0|            0|  0.00%|
   248|         0|            0|            0|  0.00%|    Shape:
   249|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   250|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   251|         0|            0|            0|  0.00%|
   252|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/ReLU6.png
   253|         0|            0|            0|  0.00%|
   254|         0|            0|            0|  0.00%|    Examples::
   255|         0|            0|            0|  0.00%|
   256|         0|            0|            0|  0.00%|        >>> m = nn.ReLU6()
   257|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   258|         0|            0|            0|  0.00%|        >>> output = m(input)
   259|         0|            0|            0|  0.00%|    """
   260|         0|            0|            0|  0.00%|
   261|         0|            0|            0|  0.00%|    def __init__(self, inplace: bool = False):
   262|         0|            0|            0|  0.00%|        super(ReLU6, self).__init__(0., 6., inplace)
   263|         0|            0|            0|  0.00%|
   264|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   265|         0|            0|            0|  0.00%|        inplace_str = 'inplace=True' if self.inplace else ''
   266|         0|            0|            0|  0.00%|        return inplace_str
   267|         0|            0|            0|  0.00%|
   268|         0|            0|            0|  0.00%|
   269|         0|            0|            0|  0.00%|class Sigmoid(Module):
   270|         0|            0|            0|  0.00%|    r"""Applies the element-wise function:
   271|         0|            0|            0|  0.00%|
   272|         0|            0|            0|  0.00%|    .. math::
   273|         0|            0|            0|  0.00%|        \text{Sigmoid}(x) = \sigma(x) = \frac{1}{1 + \exp(-x)}
   274|         0|            0|            0|  0.00%|
   275|         0|            0|            0|  0.00%|
   276|         0|            0|            0|  0.00%|    Shape:
   277|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   278|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   279|         0|            0|            0|  0.00%|
   280|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/Sigmoid.png
   281|         0|            0|            0|  0.00%|
   282|         0|            0|            0|  0.00%|    Examples::
   283|         0|            0|            0|  0.00%|
   284|         0|            0|            0|  0.00%|        >>> m = nn.Sigmoid()
   285|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   286|         0|            0|            0|  0.00%|        >>> output = m(input)
   287|         0|            0|            0|  0.00%|    """
   288|         0|            0|            0|  0.00%|
   289|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   290|         0|            0|            0|  0.00%|        return torch.sigmoid(input)
   291|         0|            0|            0|  0.00%|
   292|         0|            0|            0|  0.00%|
   293|         0|            0|            0|  0.00%|class Hardsigmoid(Module):
   294|         0|            0|            0|  0.00%|    r"""Applies the Hardsigmoid function element-wise.
   295|         0|            0|            0|  0.00%|
   296|         0|            0|            0|  0.00%|    Hardsigmoid is defined as:
   297|         0|            0|            0|  0.00%|
   298|         0|            0|            0|  0.00%|    .. math::
   299|         0|            0|            0|  0.00%|        \text{Hardsigmoid}(x) = \begin{cases}
   300|         0|            0|            0|  0.00%|            0 & \text{if~} x \le -3, \\
   301|         0|            0|            0|  0.00%|            1 & \text{if~} x \ge +3, \\
   302|         0|            0|            0|  0.00%|            x / 6 + 1 / 2 & \text{otherwise}
   303|         0|            0|            0|  0.00%|        \end{cases}
   304|         0|            0|            0|  0.00%|
   305|         0|            0|            0|  0.00%|    Args:
   306|         0|            0|            0|  0.00%|        inplace: can optionally do the operation in-place. Default: ``False``
   307|         0|            0|            0|  0.00%|
   308|         0|            0|            0|  0.00%|    Shape:
   309|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   310|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   311|         0|            0|            0|  0.00%|
   312|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/Hardsigmoid.png
   313|         0|            0|            0|  0.00%|
   314|         0|            0|            0|  0.00%|    Examples::
   315|         0|            0|            0|  0.00%|
   316|         0|            0|            0|  0.00%|        >>> m = nn.Hardsigmoid()
   317|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   318|         0|            0|            0|  0.00%|        >>> output = m(input)
   319|         0|            0|            0|  0.00%|    """
   320|         0|            0|            0|  0.00%|    __constants__ = ['inplace']
   321|         0|            0|            0|  0.00%|
   322|         0|            0|            0|  0.00%|    inplace: bool
   323|         0|            0|            0|  0.00%|
   324|         0|            0|            0|  0.00%|    def __init__(self, inplace : bool = False) -> None:
   325|         0|            0|            0|  0.00%|        super(Hardsigmoid, self).__init__()
   326|         0|            0|            0|  0.00%|        self.inplace = inplace
   327|         0|            0|            0|  0.00%|
   328|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   329|         0|            0|            0|  0.00%|        return F.hardsigmoid(input, self.inplace)
   330|         0|            0|            0|  0.00%|
   331|         0|            0|            0|  0.00%|
   332|         0|            0|            0|  0.00%|class Tanh(Module):
   333|         0|            0|            0|  0.00%|    r"""Applies the Hyperbolic Tangent (Tanh) function element-wise.
   334|         0|            0|            0|  0.00%|
   335|         0|            0|            0|  0.00%|    Tanh is defined as:
   336|         0|            0|            0|  0.00%|
   337|         0|            0|            0|  0.00%|    .. math::
   338|         0|            0|            0|  0.00%|        \text{Tanh}(x) = \tanh(x) = \frac{\exp(x) - \exp(-x)} {\exp(x) + \exp(-x)}
   339|         0|            0|            0|  0.00%|
   340|         0|            0|            0|  0.00%|    Shape:
   341|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   342|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   343|         0|            0|            0|  0.00%|
   344|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/Tanh.png
   345|         0|            0|            0|  0.00%|
   346|         0|            0|            0|  0.00%|    Examples::
   347|         0|            0|            0|  0.00%|
   348|         0|            0|            0|  0.00%|        >>> m = nn.Tanh()
   349|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   350|         0|            0|            0|  0.00%|        >>> output = m(input)
   351|         0|            0|            0|  0.00%|    """
   352|         0|            0|            0|  0.00%|
   353|     10476|    0.0191474|  1.82774e-06|  0.02%|    def forward(self, input: Tensor) -> Tensor:
   354|     10476|     0.122837|  1.17255e-05|  0.12%|        return torch.tanh(input)
   355|         0|            0|            0|  0.00%|
   356|         0|            0|            0|  0.00%|class SiLU(Module):
   357|         0|            0|            0|  0.00%|    r"""Applies the Sigmoid Linear Unit (SiLU) function, element-wise.
   358|         0|            0|            0|  0.00%|    The SiLU function is also known as the swish function.
   359|         0|            0|            0|  0.00%|
   360|         0|            0|            0|  0.00%|    .. math::
   361|         0|            0|            0|  0.00%|        \text{silu}(x) = x * \sigma(x), \text{where } \sigma(x) \text{ is the logistic sigmoid.}
   362|         0|            0|            0|  0.00%|
   363|         0|            0|            0|  0.00%|    .. note::
   364|         0|            0|            0|  0.00%|        See `Gaussian Error Linear Units (GELUs) <https://arxiv.org/abs/1606.08415>`_
   365|         0|            0|            0|  0.00%|        where the SiLU (Sigmoid Linear Unit) was originally coined, and see
   366|         0|            0|            0|  0.00%|        `Sigmoid-Weighted Linear Units for Neural Network Function Approximation
   367|         0|            0|            0|  0.00%|        in Reinforcement Learning <https://arxiv.org/abs/1702.03118>`_ and `Swish:
   368|         0|            0|            0|  0.00%|        a Self-Gated Activation Function <https://arxiv.org/abs/1710.05941v1>`_
   369|         0|            0|            0|  0.00%|        where the SiLU was experimented with later.
   370|         0|            0|            0|  0.00%|
   371|         0|            0|            0|  0.00%|    Shape:
   372|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   373|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   374|         0|            0|            0|  0.00%|
   375|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/SiLU.png
   376|         0|            0|            0|  0.00%|
   377|         0|            0|            0|  0.00%|    Examples::
   378|         0|            0|            0|  0.00%|
   379|         0|            0|            0|  0.00%|        >>> m = nn.SiLU()
   380|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   381|         0|            0|            0|  0.00%|        >>> output = m(input)
   382|         0|            0|            0|  0.00%|    """
   383|         0|            0|            0|  0.00%|    __constants__ = ['inplace']
   384|         0|            0|            0|  0.00%|    inplace: bool
   385|         0|            0|            0|  0.00%|
   386|         0|            0|            0|  0.00%|    def __init__(self, inplace: bool = False):
   387|         0|            0|            0|  0.00%|        super(SiLU, self).__init__()
   388|         0|            0|            0|  0.00%|        self.inplace = inplace
   389|         0|            0|            0|  0.00%|
   390|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   391|         0|            0|            0|  0.00%|        return F.silu(input, inplace=self.inplace)
   392|         0|            0|            0|  0.00%|
   393|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   394|         0|            0|            0|  0.00%|        inplace_str = 'inplace=True' if self.inplace else ''
   395|         0|            0|            0|  0.00%|        return inplace_str
   396|         0|            0|            0|  0.00%|
   397|         0|            0|            0|  0.00%|class Mish(Module):
   398|         0|            0|            0|  0.00%|    r"""Applies the Mish function, element-wise.
   399|         0|            0|            0|  0.00%|    Mish: A Self Regularized Non-Monotonic Neural Activation Function.
   400|         0|            0|            0|  0.00%|
   401|         0|            0|            0|  0.00%|    .. math::
   402|         0|            0|            0|  0.00%|        \text{Mish}(x) = x * \text{Tanh}(\text{Softplus}(x))
   403|         0|            0|            0|  0.00%|
   404|         0|            0|            0|  0.00%|    .. note::
   405|         0|            0|            0|  0.00%|        See `Mish: A Self Regularized Non-Monotonic Neural Activation Function <https://arxiv.org/abs/1908.08681>`_
   406|         0|            0|            0|  0.00%|
   407|         0|            0|            0|  0.00%|    Shape:
   408|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   409|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   410|         0|            0|            0|  0.00%|
   411|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/Mish.png
   412|         0|            0|            0|  0.00%|
   413|         0|            0|            0|  0.00%|    Examples::
   414|         0|            0|            0|  0.00%|
   415|         0|            0|            0|  0.00%|        >>> m = nn.Mish()
   416|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   417|         0|            0|            0|  0.00%|        >>> output = m(input)
   418|         0|            0|            0|  0.00%|    """
   419|         0|            0|            0|  0.00%|    __constants__ = ['inplace']
   420|         0|            0|            0|  0.00%|    inplace: bool
   421|         0|            0|            0|  0.00%|
   422|         0|            0|            0|  0.00%|    def __init__(self, inplace: bool = False):
   423|         0|            0|            0|  0.00%|        super(Mish, self).__init__()
   424|         0|            0|            0|  0.00%|        self.inplace = inplace
   425|         0|            0|            0|  0.00%|
   426|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   427|         0|            0|            0|  0.00%|        return F.mish(input, inplace=self.inplace)
   428|         0|            0|            0|  0.00%|
   429|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   430|         0|            0|            0|  0.00%|        inplace_str = 'inplace=True' if self.inplace else ''
   431|         0|            0|            0|  0.00%|        return inplace_str
   432|         0|            0|            0|  0.00%|
   433|         0|            0|            0|  0.00%|class Hardswish(Module):
   434|         0|            0|            0|  0.00%|    r"""Applies the hardswish function, element-wise, as described in the paper:
   435|         0|            0|            0|  0.00%|
   436|         0|            0|            0|  0.00%|    `Searching for MobileNetV3`_.
   437|         0|            0|            0|  0.00%|
   438|         0|            0|            0|  0.00%|    .. math::
   439|         0|            0|            0|  0.00%|        \text{Hardswish}(x) = \begin{cases}
   440|         0|            0|            0|  0.00%|            0 & \text{if~} x \le -3, \\
   441|         0|            0|            0|  0.00%|            x & \text{if~} x \ge +3, \\
   442|         0|            0|            0|  0.00%|            x \cdot (x + 3) /6 & \text{otherwise}
   443|         0|            0|            0|  0.00%|        \end{cases}
   444|         0|            0|            0|  0.00%|
   445|         0|            0|            0|  0.00%|    Args:
   446|         0|            0|            0|  0.00%|        inplace: can optionally do the operation in-place. Default: ``False``
   447|         0|            0|            0|  0.00%|
   448|         0|            0|            0|  0.00%|    Shape:
   449|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   450|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   451|         0|            0|            0|  0.00%|
   452|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/Hardswish.png
   453|         0|            0|            0|  0.00%|
   454|         0|            0|            0|  0.00%|    Examples::
   455|         0|            0|            0|  0.00%|
   456|         0|            0|            0|  0.00%|        >>> m = nn.Hardswish()
   457|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   458|         0|            0|            0|  0.00%|        >>> output = m(input)
   459|         0|            0|            0|  0.00%|
   460|         0|            0|            0|  0.00%|    .. _`Searching for MobileNetV3`:
   461|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1905.02244
   462|         0|            0|            0|  0.00%|    """
   463|         0|            0|            0|  0.00%|    __constants__ = ['inplace']
   464|         0|            0|            0|  0.00%|
   465|         0|            0|            0|  0.00%|    inplace: bool
   466|         0|            0|            0|  0.00%|
   467|         0|            0|            0|  0.00%|    def __init__(self, inplace : bool = False) -> None:
   468|         0|            0|            0|  0.00%|        super(Hardswish, self).__init__()
   469|         0|            0|            0|  0.00%|        self.inplace = inplace
   470|         0|            0|            0|  0.00%|
   471|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   472|         0|            0|            0|  0.00%|        return F.hardswish(input, self.inplace)
   473|         0|            0|            0|  0.00%|
   474|         0|            0|            0|  0.00%|
   475|         0|            0|            0|  0.00%|class ELU(Module):
   476|         0|            0|            0|  0.00%|    r"""Applies the Exponential Linear Unit (ELU) function, element-wise, as described
   477|         0|            0|            0|  0.00%|    in the paper: `Fast and Accurate Deep Network Learning by Exponential Linear
   478|         0|            0|            0|  0.00%|    Units (ELUs) <https://arxiv.org/abs/1511.07289>`__.
   479|         0|            0|            0|  0.00%|
   480|         0|            0|            0|  0.00%|    ELU is defined as:
   481|         0|            0|            0|  0.00%|
   482|         0|            0|            0|  0.00%|    .. math::
   483|         0|            0|            0|  0.00%|        \text{ELU}(x) = \begin{cases}
   484|         0|            0|            0|  0.00%|        x, & \text{ if } x > 0\\
   485|         0|            0|            0|  0.00%|        \alpha * (\exp(x) - 1), & \text{ if } x \leq 0
   486|         0|            0|            0|  0.00%|        \end{cases}
   487|         0|            0|            0|  0.00%|
   488|         0|            0|            0|  0.00%|    Args:
   489|         0|            0|            0|  0.00%|        alpha: the :math:`\alpha` value for the ELU formulation. Default: 1.0
   490|         0|            0|            0|  0.00%|        inplace: can optionally do the operation in-place. Default: ``False``
   491|         0|            0|            0|  0.00%|
   492|         0|            0|            0|  0.00%|    Shape:
   493|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   494|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   495|         0|            0|            0|  0.00%|
   496|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/ELU.png
   497|         0|            0|            0|  0.00%|
   498|         0|            0|            0|  0.00%|    Examples::
   499|         0|            0|            0|  0.00%|
   500|         0|            0|            0|  0.00%|        >>> m = nn.ELU()
   501|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   502|         0|            0|            0|  0.00%|        >>> output = m(input)
   503|         0|            0|            0|  0.00%|    """
   504|         0|            0|            0|  0.00%|    __constants__ = ['alpha', 'inplace']
   505|         0|            0|            0|  0.00%|    alpha: float
   506|         0|            0|            0|  0.00%|    inplace: bool
   507|         0|            0|            0|  0.00%|
   508|         0|            0|            0|  0.00%|    def __init__(self, alpha: float = 1., inplace: bool = False) -> None:
   509|         0|            0|            0|  0.00%|        super(ELU, self).__init__()
   510|         0|            0|            0|  0.00%|        self.alpha = alpha
   511|         0|            0|            0|  0.00%|        self.inplace = inplace
   512|         0|            0|            0|  0.00%|
   513|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   514|         0|            0|            0|  0.00%|        return F.elu(input, self.alpha, self.inplace)
   515|         0|            0|            0|  0.00%|
   516|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   517|         0|            0|            0|  0.00%|        inplace_str = ', inplace=True' if self.inplace else ''
   518|         0|            0|            0|  0.00%|        return 'alpha={}{}'.format(self.alpha, inplace_str)
   519|         0|            0|            0|  0.00%|
   520|         0|            0|            0|  0.00%|
   521|         0|            0|            0|  0.00%|class CELU(Module):
   522|         0|            0|            0|  0.00%|    r"""Applies the element-wise function:
   523|         0|            0|            0|  0.00%|
   524|         0|            0|            0|  0.00%|    .. math::
   525|         0|            0|            0|  0.00%|        \text{CELU}(x) = \max(0,x) + \min(0, \alpha * (\exp(x/\alpha) - 1))
   526|         0|            0|            0|  0.00%|
   527|         0|            0|            0|  0.00%|    More details can be found in the paper `Continuously Differentiable Exponential Linear Units`_ .
   528|         0|            0|            0|  0.00%|
   529|         0|            0|            0|  0.00%|    Args:
   530|         0|            0|            0|  0.00%|        alpha: the :math:`\alpha` value for the CELU formulation. Default: 1.0
   531|         0|            0|            0|  0.00%|        inplace: can optionally do the operation in-place. Default: ``False``
   532|         0|            0|            0|  0.00%|
   533|         0|            0|            0|  0.00%|    Shape:
   534|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   535|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   536|         0|            0|            0|  0.00%|
   537|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/CELU.png
   538|         0|            0|            0|  0.00%|
   539|         0|            0|            0|  0.00%|    Examples::
   540|         0|            0|            0|  0.00%|
   541|         0|            0|            0|  0.00%|        >>> m = nn.CELU()
   542|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   543|         0|            0|            0|  0.00%|        >>> output = m(input)
   544|         0|            0|            0|  0.00%|
   545|         0|            0|            0|  0.00%|    .. _`Continuously Differentiable Exponential Linear Units`:
   546|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1704.07483
   547|         0|            0|            0|  0.00%|    """
   548|         0|            0|            0|  0.00%|    __constants__ = ['alpha', 'inplace']
   549|         0|            0|            0|  0.00%|    alpha: float
   550|         0|            0|            0|  0.00%|    inplace: bool
   551|         0|            0|            0|  0.00%|
   552|         0|            0|            0|  0.00%|    def __init__(self, alpha: float = 1., inplace: bool = False) -> None:
   553|         0|            0|            0|  0.00%|        super(CELU, self).__init__()
   554|         0|            0|            0|  0.00%|        self.alpha = alpha
   555|         0|            0|            0|  0.00%|        self.inplace = inplace
   556|         0|            0|            0|  0.00%|
   557|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   558|         0|            0|            0|  0.00%|        return F.celu(input, self.alpha, self.inplace)
   559|         0|            0|            0|  0.00%|
   560|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   561|         0|            0|            0|  0.00%|        inplace_str = ', inplace=True' if self.inplace else ''
   562|         0|            0|            0|  0.00%|        return 'alpha={}{}'.format(self.alpha, inplace_str)
   563|         0|            0|            0|  0.00%|
   564|         0|            0|            0|  0.00%|
   565|         0|            0|            0|  0.00%|class SELU(Module):
   566|         0|            0|            0|  0.00%|    r"""Applied element-wise, as:
   567|         0|            0|            0|  0.00%|
   568|         0|            0|            0|  0.00%|    .. math::
   569|         0|            0|            0|  0.00%|        \text{SELU}(x) = \text{scale} * (\max(0,x) + \min(0, \alpha * (\exp(x) - 1)))
   570|         0|            0|            0|  0.00%|
   571|         0|            0|            0|  0.00%|    with :math:`\alpha = 1.6732632423543772848170429916717` and
   572|         0|            0|            0|  0.00%|    :math:`\text{scale} = 1.0507009873554804934193349852946`.
   573|         0|            0|            0|  0.00%|
   574|         0|            0|            0|  0.00%|    .. warning::
   575|         0|            0|            0|  0.00%|        When using ``kaiming_normal`` or ``kaiming_normal_`` for initialisation,
   576|         0|            0|            0|  0.00%|        ``nonlinearity='linear'`` should be used instead of ``nonlinearity='selu'``
   577|         0|            0|            0|  0.00%|        in order to get `Self-Normalizing Neural Networks`_.
   578|         0|            0|            0|  0.00%|        See :func:`torch.nn.init.calculate_gain` for more information.
   579|         0|            0|            0|  0.00%|
   580|         0|            0|            0|  0.00%|    More details can be found in the paper `Self-Normalizing Neural Networks`_ .
   581|         0|            0|            0|  0.00%|
   582|         0|            0|            0|  0.00%|    Args:
   583|         0|            0|            0|  0.00%|        inplace (bool, optional): can optionally do the operation in-place. Default: ``False``
   584|         0|            0|            0|  0.00%|
   585|         0|            0|            0|  0.00%|    Shape:
   586|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   587|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   588|         0|            0|            0|  0.00%|
   589|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/SELU.png
   590|         0|            0|            0|  0.00%|
   591|         0|            0|            0|  0.00%|    Examples::
   592|         0|            0|            0|  0.00%|
   593|         0|            0|            0|  0.00%|        >>> m = nn.SELU()
   594|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   595|         0|            0|            0|  0.00%|        >>> output = m(input)
   596|         0|            0|            0|  0.00%|
   597|         0|            0|            0|  0.00%|    .. _Self-Normalizing Neural Networks: https://arxiv.org/abs/1706.02515
   598|         0|            0|            0|  0.00%|    """
   599|         0|            0|            0|  0.00%|    __constants__ = ['inplace']
   600|         0|            0|            0|  0.00%|    inplace: bool
   601|         0|            0|            0|  0.00%|
   602|         0|            0|            0|  0.00%|    def __init__(self, inplace: bool = False) -> None:
   603|         0|            0|            0|  0.00%|        super(SELU, self).__init__()
   604|         0|            0|            0|  0.00%|        self.inplace = inplace
   605|         0|            0|            0|  0.00%|
   606|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   607|         0|            0|            0|  0.00%|        return F.selu(input, self.inplace)
   608|         0|            0|            0|  0.00%|
   609|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   610|         0|            0|            0|  0.00%|        inplace_str = 'inplace=True' if self.inplace else ''
   611|         0|            0|            0|  0.00%|        return inplace_str
   612|         0|            0|            0|  0.00%|
   613|         0|            0|            0|  0.00%|
   614|         0|            0|            0|  0.00%|class GLU(Module):
   615|         0|            0|            0|  0.00%|    r"""Applies the gated linear unit function
   616|         0|            0|            0|  0.00%|    :math:`{GLU}(a, b)= a \otimes \sigma(b)` where :math:`a` is the first half
   617|         0|            0|            0|  0.00%|    of the input matrices and :math:`b` is the second half.
   618|         0|            0|            0|  0.00%|
   619|         0|            0|            0|  0.00%|    Args:
   620|         0|            0|            0|  0.00%|        dim (int): the dimension on which to split the input. Default: -1
   621|         0|            0|            0|  0.00%|
   622|         0|            0|            0|  0.00%|    Shape:
   623|         0|            0|            0|  0.00%|        - Input: :math:`(\ast_1, N, \ast_2)` where `*` means, any number of additional
   624|         0|            0|            0|  0.00%|          dimensions
   625|         0|            0|            0|  0.00%|        - Output: :math:`(\ast_1, M, \ast_2)` where :math:`M=N/2`
   626|         0|            0|            0|  0.00%|
   627|         0|            0|            0|  0.00%|    Examples::
   628|         0|            0|            0|  0.00%|
   629|         0|            0|            0|  0.00%|        >>> m = nn.GLU()
   630|         0|            0|            0|  0.00%|        >>> input = torch.randn(4, 2)
   631|         0|            0|            0|  0.00%|        >>> output = m(input)
   632|         0|            0|            0|  0.00%|    """
   633|         0|            0|            0|  0.00%|    __constants__ = ['dim']
   634|         0|            0|            0|  0.00%|    dim: int
   635|         0|            0|            0|  0.00%|
   636|         0|            0|            0|  0.00%|    def __init__(self, dim: int = -1) -> None:
   637|         0|            0|            0|  0.00%|        super(GLU, self).__init__()
   638|         0|            0|            0|  0.00%|        self.dim = dim
   639|         0|            0|            0|  0.00%|
   640|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   641|         0|            0|            0|  0.00%|        return F.glu(input, self.dim)
   642|         0|            0|            0|  0.00%|
   643|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   644|         0|            0|            0|  0.00%|        return 'dim={}'.format(self.dim)
   645|         0|            0|            0|  0.00%|
   646|         0|            0|            0|  0.00%|
   647|         0|            0|            0|  0.00%|class GELU(Module):
   648|         0|            0|            0|  0.00%|    r"""Applies the Gaussian Error Linear Units function:
   649|         0|            0|            0|  0.00%|
   650|         0|            0|            0|  0.00%|    .. math:: \text{GELU}(x) = x * \Phi(x)
   651|         0|            0|            0|  0.00%|
   652|         0|            0|            0|  0.00%|    where :math:`\Phi(x)` is the Cumulative Distribution Function for Gaussian Distribution.
   653|         0|            0|            0|  0.00%|
   654|         0|            0|            0|  0.00%|    When the approximate argument is 'tanh', Gelu is estimated with:
   655|         0|            0|            0|  0.00%|        :math:: \text{GELU}(x) = 0.5 * x * (1 + \text{Tanh}(\sqrt(2 / \pi) * (x + 0.044715 * x^3)))
   656|         0|            0|            0|  0.00%|
   657|         0|            0|            0|  0.00%|    Args:
   658|         0|            0|            0|  0.00%|        approximate (string, optional): the gelu approximation algorithm to use:
   659|         0|            0|            0|  0.00%|            ``'none'`` | ``'tanh'``. Default: ``'none'``
   660|         0|            0|            0|  0.00%|
   661|         0|            0|            0|  0.00%|    Shape:
   662|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   663|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   664|         0|            0|            0|  0.00%|
   665|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/GELU.png
   666|         0|            0|            0|  0.00%|
   667|         0|            0|            0|  0.00%|    Examples::
   668|         0|            0|            0|  0.00%|
   669|         0|            0|            0|  0.00%|        >>> m = nn.GELU()
   670|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   671|         0|            0|            0|  0.00%|        >>> output = m(input)
   672|         0|            0|            0|  0.00%|    """
   673|         0|            0|            0|  0.00%|    __constants__ = ['approximate']
   674|         0|            0|            0|  0.00%|    approximate: str
   675|         0|            0|            0|  0.00%|
   676|         0|            0|            0|  0.00%|    def __init__(self, approximate: str = 'none') -> None:
   677|         0|            0|            0|  0.00%|        super(GELU, self).__init__()
   678|         0|            0|            0|  0.00%|        self.approximate = approximate
   679|         0|            0|            0|  0.00%|
   680|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   681|         0|            0|            0|  0.00%|        return F.gelu(input, approximate=self.approximate)
   682|         0|            0|            0|  0.00%|
   683|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   684|         0|            0|            0|  0.00%|        return 'approximate={}'.format(self.approximate)
   685|         0|            0|            0|  0.00%|
   686|         0|            0|            0|  0.00%|
   687|         0|            0|            0|  0.00%|class Hardshrink(Module):
   688|         0|            0|            0|  0.00%|    r"""Applies the Hard Shrinkage (Hardshrink) function element-wise.
   689|         0|            0|            0|  0.00%|
   690|         0|            0|            0|  0.00%|    Hardshrink is defined as:
   691|         0|            0|            0|  0.00%|
   692|         0|            0|            0|  0.00%|    .. math::
   693|         0|            0|            0|  0.00%|        \text{HardShrink}(x) =
   694|         0|            0|            0|  0.00%|        \begin{cases}
   695|         0|            0|            0|  0.00%|        x, & \text{ if } x > \lambda \\
   696|         0|            0|            0|  0.00%|        x, & \text{ if } x < -\lambda \\
   697|         0|            0|            0|  0.00%|        0, & \text{ otherwise }
   698|         0|            0|            0|  0.00%|        \end{cases}
   699|         0|            0|            0|  0.00%|
   700|         0|            0|            0|  0.00%|    Args:
   701|         0|            0|            0|  0.00%|        lambd: the :math:`\lambda` value for the Hardshrink formulation. Default: 0.5
   702|         0|            0|            0|  0.00%|
   703|         0|            0|            0|  0.00%|    Shape:
   704|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   705|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   706|         0|            0|            0|  0.00%|
   707|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/Hardshrink.png
   708|         0|            0|            0|  0.00%|
   709|         0|            0|            0|  0.00%|    Examples::
   710|         0|            0|            0|  0.00%|
   711|         0|            0|            0|  0.00%|        >>> m = nn.Hardshrink()
   712|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   713|         0|            0|            0|  0.00%|        >>> output = m(input)
   714|         0|            0|            0|  0.00%|    """
   715|         0|            0|            0|  0.00%|    __constants__ = ['lambd']
   716|         0|            0|            0|  0.00%|    lambd: float
   717|         0|            0|            0|  0.00%|
   718|         0|            0|            0|  0.00%|    def __init__(self, lambd: float = 0.5) -> None:
   719|         0|            0|            0|  0.00%|        super(Hardshrink, self).__init__()
   720|         0|            0|            0|  0.00%|        self.lambd = lambd
   721|         0|            0|            0|  0.00%|
   722|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   723|         0|            0|            0|  0.00%|        return F.hardshrink(input, self.lambd)
   724|         0|            0|            0|  0.00%|
   725|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   726|         0|            0|            0|  0.00%|        return '{}'.format(self.lambd)
   727|         0|            0|            0|  0.00%|
   728|         0|            0|            0|  0.00%|
   729|         0|            0|            0|  0.00%|class LeakyReLU(Module):
   730|         0|            0|            0|  0.00%|    r"""Applies the element-wise function:
   731|         0|            0|            0|  0.00%|
   732|         0|            0|            0|  0.00%|    .. math::
   733|         0|            0|            0|  0.00%|        \text{LeakyReLU}(x) = \max(0, x) + \text{negative\_slope} * \min(0, x)
   734|         0|            0|            0|  0.00%|
   735|         0|            0|            0|  0.00%|
   736|         0|            0|            0|  0.00%|    or
   737|         0|            0|            0|  0.00%|
   738|         0|            0|            0|  0.00%|    .. math::
   739|         0|            0|            0|  0.00%|        \text{LeakyRELU}(x) =
   740|         0|            0|            0|  0.00%|        \begin{cases}
   741|         0|            0|            0|  0.00%|        x, & \text{ if } x \geq 0 \\
   742|         0|            0|            0|  0.00%|        \text{negative\_slope} \times x, & \text{ otherwise }
   743|         0|            0|            0|  0.00%|        \end{cases}
   744|         0|            0|            0|  0.00%|
   745|         0|            0|            0|  0.00%|    Args:
   746|         0|            0|            0|  0.00%|        negative_slope: Controls the angle of the negative slope. Default: 1e-2
   747|         0|            0|            0|  0.00%|        inplace: can optionally do the operation in-place. Default: ``False``
   748|         0|            0|            0|  0.00%|
   749|         0|            0|            0|  0.00%|    Shape:
   750|         0|            0|            0|  0.00%|        - Input: :math:`(*)` where `*` means, any number of additional
   751|         0|            0|            0|  0.00%|          dimensions
   752|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input
   753|         0|            0|            0|  0.00%|
   754|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/LeakyReLU.png
   755|         0|            0|            0|  0.00%|
   756|         0|            0|            0|  0.00%|    Examples::
   757|         0|            0|            0|  0.00%|
   758|         0|            0|            0|  0.00%|        >>> m = nn.LeakyReLU(0.1)
   759|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   760|         0|            0|            0|  0.00%|        >>> output = m(input)
   761|         0|            0|            0|  0.00%|    """
   762|         0|            0|            0|  0.00%|    __constants__ = ['inplace', 'negative_slope']
   763|         0|            0|            0|  0.00%|    inplace: bool
   764|         0|            0|            0|  0.00%|    negative_slope: float
   765|         0|            0|            0|  0.00%|
   766|         0|            0|            0|  0.00%|    def __init__(self, negative_slope: float = 1e-2, inplace: bool = False) -> None:
   767|         0|            0|            0|  0.00%|        super(LeakyReLU, self).__init__()
   768|         0|            0|            0|  0.00%|        self.negative_slope = negative_slope
   769|         0|            0|            0|  0.00%|        self.inplace = inplace
   770|         0|            0|            0|  0.00%|
   771|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   772|         0|            0|            0|  0.00%|        return F.leaky_relu(input, self.negative_slope, self.inplace)
   773|         0|            0|            0|  0.00%|
   774|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   775|         0|            0|            0|  0.00%|        inplace_str = ', inplace=True' if self.inplace else ''
   776|         0|            0|            0|  0.00%|        return 'negative_slope={}{}'.format(self.negative_slope, inplace_str)
   777|         0|            0|            0|  0.00%|
   778|         0|            0|            0|  0.00%|
   779|         0|            0|            0|  0.00%|class LogSigmoid(Module):
   780|         0|            0|            0|  0.00%|    r"""Applies the element-wise function:
   781|         0|            0|            0|  0.00%|
   782|         0|            0|            0|  0.00%|    .. math::
   783|         0|            0|            0|  0.00%|        \text{LogSigmoid}(x) = \log\left(\frac{ 1 }{ 1 + \exp(-x)}\right)
   784|         0|            0|            0|  0.00%|
   785|         0|            0|            0|  0.00%|    Shape:
   786|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   787|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   788|         0|            0|            0|  0.00%|
   789|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/LogSigmoid.png
   790|         0|            0|            0|  0.00%|
   791|         0|            0|            0|  0.00%|    Examples::
   792|         0|            0|            0|  0.00%|
   793|         0|            0|            0|  0.00%|        >>> m = nn.LogSigmoid()
   794|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   795|         0|            0|            0|  0.00%|        >>> output = m(input)
   796|         0|            0|            0|  0.00%|    """
   797|         0|            0|            0|  0.00%|
   798|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   799|         0|            0|            0|  0.00%|        return F.logsigmoid(input)
   800|         0|            0|            0|  0.00%|
   801|         0|            0|            0|  0.00%|
   802|         0|            0|            0|  0.00%|class Softplus(Module):
   803|         0|            0|            0|  0.00%|    r"""Applies the Softplus function :math:`\text{Softplus}(x) = \frac{1}{\beta} *
   804|         0|            0|            0|  0.00%|    \log(1 + \exp(\beta * x))` element-wise.
   805|         0|            0|            0|  0.00%|
   806|         0|            0|            0|  0.00%|    SoftPlus is a smooth approximation to the ReLU function and can be used
   807|         0|            0|            0|  0.00%|    to constrain the output of a machine to always be positive.
   808|         0|            0|            0|  0.00%|
   809|         0|            0|            0|  0.00%|    For numerical stability the implementation reverts to the linear function
   810|         0|            0|            0|  0.00%|    when :math:`input \times \beta > threshold`.
   811|         0|            0|            0|  0.00%|
   812|         0|            0|            0|  0.00%|    Args:
   813|         0|            0|            0|  0.00%|        beta: the :math:`\beta` value for the Softplus formulation. Default: 1
   814|         0|            0|            0|  0.00%|        threshold: values above this revert to a linear function. Default: 20
   815|         0|            0|            0|  0.00%|
   816|         0|            0|            0|  0.00%|    Shape:
   817|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   818|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   819|         0|            0|            0|  0.00%|
   820|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/Softplus.png
   821|         0|            0|            0|  0.00%|
   822|         0|            0|            0|  0.00%|    Examples::
   823|         0|            0|            0|  0.00%|
   824|         0|            0|            0|  0.00%|        >>> m = nn.Softplus()
   825|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   826|         0|            0|            0|  0.00%|        >>> output = m(input)
   827|         0|            0|            0|  0.00%|    """
   828|         0|            0|            0|  0.00%|    __constants__ = ['beta', 'threshold']
   829|         0|            0|            0|  0.00%|    beta: int
   830|         0|            0|            0|  0.00%|    threshold: int
   831|         0|            0|            0|  0.00%|
   832|         0|            0|            0|  0.00%|    def __init__(self, beta: int = 1, threshold: int = 20) -> None:
   833|         0|            0|            0|  0.00%|        super(Softplus, self).__init__()
   834|         0|            0|            0|  0.00%|        self.beta = beta
   835|         0|            0|            0|  0.00%|        self.threshold = threshold
   836|         0|            0|            0|  0.00%|
   837|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   838|         0|            0|            0|  0.00%|        return F.softplus(input, self.beta, self.threshold)
   839|         0|            0|            0|  0.00%|
   840|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   841|         0|            0|            0|  0.00%|        return 'beta={}, threshold={}'.format(self.beta, self.threshold)
   842|         0|            0|            0|  0.00%|
   843|         0|            0|            0|  0.00%|
   844|         0|            0|            0|  0.00%|class Softshrink(Module):
   845|         0|            0|            0|  0.00%|    r"""Applies the soft shrinkage function elementwise:
   846|         0|            0|            0|  0.00%|
   847|         0|            0|            0|  0.00%|    .. math::
   848|         0|            0|            0|  0.00%|        \text{SoftShrinkage}(x) =
   849|         0|            0|            0|  0.00%|        \begin{cases}
   850|         0|            0|            0|  0.00%|        x - \lambda, & \text{ if } x > \lambda \\
   851|         0|            0|            0|  0.00%|        x + \lambda, & \text{ if } x < -\lambda \\
   852|         0|            0|            0|  0.00%|        0, & \text{ otherwise }
   853|         0|            0|            0|  0.00%|        \end{cases}
   854|         0|            0|            0|  0.00%|
   855|         0|            0|            0|  0.00%|    Args:
   856|         0|            0|            0|  0.00%|        lambd: the :math:`\lambda` (must be no less than zero) value for the Softshrink formulation. Default: 0.5
   857|         0|            0|            0|  0.00%|
   858|         0|            0|            0|  0.00%|    Shape:
   859|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
   860|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
   861|         0|            0|            0|  0.00%|
   862|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/Softshrink.png
   863|         0|            0|            0|  0.00%|
   864|         0|            0|            0|  0.00%|    Examples::
   865|         0|            0|            0|  0.00%|
   866|         0|            0|            0|  0.00%|        >>> m = nn.Softshrink()
   867|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
   868|         0|            0|            0|  0.00%|        >>> output = m(input)
   869|         0|            0|            0|  0.00%|    """
   870|         0|            0|            0|  0.00%|    __constants__ = ['lambd']
   871|         0|            0|            0|  0.00%|    lambd: float
   872|         0|            0|            0|  0.00%|
   873|         0|            0|            0|  0.00%|    def __init__(self, lambd: float = 0.5) -> None:
   874|         0|            0|            0|  0.00%|        super(Softshrink, self).__init__()
   875|         0|            0|            0|  0.00%|        self.lambd = lambd
   876|         0|            0|            0|  0.00%|
   877|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
   878|         0|            0|            0|  0.00%|        return F.softshrink(input, self.lambd)
   879|         0|            0|            0|  0.00%|
   880|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
   881|         0|            0|            0|  0.00%|        return str(self.lambd)
   882|         0|            0|            0|  0.00%|
   883|         0|            0|            0|  0.00%|
   884|         0|            0|            0|  0.00%|class MultiheadAttention(Module):
   885|         0|            0|            0|  0.00%|    r"""Allows the model to jointly attend to information
   886|         0|            0|            0|  0.00%|    from different representation subspaces as described in the paper:
   887|         0|            0|            0|  0.00%|    `Attention Is All You Need <https://arxiv.org/abs/1706.03762>`_.
   888|         0|            0|            0|  0.00%|
   889|         0|            0|            0|  0.00%|    Multi-Head Attention is defined as:
   890|         0|            0|            0|  0.00%|
   891|         0|            0|            0|  0.00%|    .. math::
   892|         0|            0|            0|  0.00%|        \text{MultiHead}(Q, K, V) = \text{Concat}(head_1,\dots,head_h)W^O
   893|         0|            0|            0|  0.00%|
   894|         0|            0|            0|  0.00%|    where :math:`head_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)`.
   895|         0|            0|            0|  0.00%|
   896|         0|            0|            0|  0.00%|    ``forward()`` will use a special optimized implementation if all of the following
   897|         0|            0|            0|  0.00%|    conditions are met:
   898|         0|            0|            0|  0.00%|
   899|         0|            0|            0|  0.00%|    - self attention is being computed (i.e., ``query``, ``key``, and ``value`` are the same tensor. This
   900|         0|            0|            0|  0.00%|      restriction will be loosened in the future.)
   901|         0|            0|            0|  0.00%|    - Either autograd is disabled (using ``torch.inference_mode`` or ``torch.no_grad``) or no tensor argument ``requires_grad``
   902|         0|            0|            0|  0.00%|    - training is disabled (using ``.eval()``)
   903|         0|            0|            0|  0.00%|    - dropout is 0
   904|         0|            0|            0|  0.00%|    - ``add_bias_kv`` is ``False``
   905|         0|            0|            0|  0.00%|    - ``add_zero_attn`` is ``False``
   906|         0|            0|            0|  0.00%|    - ``batch_first`` is ``True`` and the input is batched
   907|         0|            0|            0|  0.00%|    - ``kdim`` and ``vdim`` are equal to ``embed_dim``
   908|         0|            0|            0|  0.00%|    - at most one of ``key_padding_mask`` or ``attn_mask`` is passed
   909|         0|            0|            0|  0.00%|    - if a `NestedTensor <https://pytorch.org/docs/stable/nested.html>`_ is passed, neither ``key_padding_mask``
   910|         0|            0|            0|  0.00%|      nor ``attn_mask`` is passed
   911|         0|            0|            0|  0.00%|
   912|         0|            0|            0|  0.00%|    If the optimized implementation is in use, a
   913|         0|            0|            0|  0.00%|    `NestedTensor <https://pytorch.org/docs/stable/nested.html>`_ can be passed for
   914|         0|            0|            0|  0.00%|    ``query``/``key``/``value`` to represent padding more efficiently than using a
   915|         0|            0|            0|  0.00%|    padding mask. In this case, a `NestedTensor <https://pytorch.org/docs/stable/nested.html>`_
   916|         0|            0|            0|  0.00%|    will be returned, and an additional speedup proportional to the fraction of the input
   917|         0|            0|            0|  0.00%|    that is padding can be expected.
   918|         0|            0|            0|  0.00%|
   919|         0|            0|            0|  0.00%|    Args:
   920|         0|            0|            0|  0.00%|        embed_dim: Total dimension of the model.
   921|         0|            0|            0|  0.00%|        num_heads: Number of parallel attention heads. Note that ``embed_dim`` will be split
   922|         0|            0|            0|  0.00%|            across ``num_heads`` (i.e. each head will have dimension ``embed_dim // num_heads``).
   923|         0|            0|            0|  0.00%|        dropout: Dropout probability on ``attn_output_weights``. Default: ``0.0`` (no dropout).
   924|         0|            0|            0|  0.00%|        bias: If specified, adds bias to input / output projection layers. Default: ``True``.
   925|         0|            0|            0|  0.00%|        add_bias_kv: If specified, adds bias to the key and value sequences at dim=0. Default: ``False``.
   926|         0|            0|            0|  0.00%|        add_zero_attn: If specified, adds a new batch of zeros to the key and value sequences at dim=1.
   927|         0|            0|            0|  0.00%|            Default: ``False``.
   928|         0|            0|            0|  0.00%|        kdim: Total number of features for keys. Default: ``None`` (uses ``kdim=embed_dim``).
   929|         0|            0|            0|  0.00%|        vdim: Total number of features for values. Default: ``None`` (uses ``vdim=embed_dim``).
   930|         0|            0|            0|  0.00%|        batch_first: If ``True``, then the input and output tensors are provided
   931|         0|            0|            0|  0.00%|            as (batch, seq, feature). Default: ``False`` (seq, batch, feature).
   932|         0|            0|            0|  0.00%|
   933|         0|            0|            0|  0.00%|    Examples::
   934|         0|            0|            0|  0.00%|
   935|         0|            0|            0|  0.00%|        >>> multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)
   936|         0|            0|            0|  0.00%|        >>> attn_output, attn_output_weights = multihead_attn(query, key, value)
   937|         0|            0|            0|  0.00%|
   938|         0|            0|            0|  0.00%|    """
   939|         0|            0|            0|  0.00%|    __constants__ = ['batch_first']
   940|         0|            0|            0|  0.00%|    bias_k: Optional[torch.Tensor]
   941|         0|            0|            0|  0.00%|    bias_v: Optional[torch.Tensor]
   942|         0|            0|            0|  0.00%|
   943|         0|            0|            0|  0.00%|    def __init__(self, embed_dim, num_heads, dropout=0., bias=True, add_bias_kv=False, add_zero_attn=False,
   944|         0|            0|            0|  0.00%|                 kdim=None, vdim=None, batch_first=False, device=None, dtype=None) -> None:
   945|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}
   946|         0|            0|            0|  0.00%|        super(MultiheadAttention, self).__init__()
   947|         0|            0|            0|  0.00%|        self.embed_dim = embed_dim
   948|         0|            0|            0|  0.00%|        self.kdim = kdim if kdim is not None else embed_dim
   949|         0|            0|            0|  0.00%|        self.vdim = vdim if vdim is not None else embed_dim
   950|         0|            0|            0|  0.00%|        self._qkv_same_embed_dim = self.kdim == embed_dim and self.vdim == embed_dim
   951|         0|            0|            0|  0.00%|
   952|         0|            0|            0|  0.00%|        self.num_heads = num_heads
   953|         0|            0|            0|  0.00%|        self.dropout = dropout
   954|         0|            0|            0|  0.00%|        self.batch_first = batch_first
   955|         0|            0|            0|  0.00%|        self.head_dim = embed_dim // num_heads
   956|         0|            0|            0|  0.00%|        assert self.head_dim * num_heads == self.embed_dim, "embed_dim must be divisible by num_heads"
   957|         0|            0|            0|  0.00%|
   958|         0|            0|            0|  0.00%|        if self._qkv_same_embed_dim is False:
   959|         0|            0|            0|  0.00%|            self.q_proj_weight = Parameter(torch.empty((embed_dim, embed_dim), **factory_kwargs))
   960|         0|            0|            0|  0.00%|            self.k_proj_weight = Parameter(torch.empty((embed_dim, self.kdim), **factory_kwargs))
   961|         0|            0|            0|  0.00%|            self.v_proj_weight = Parameter(torch.empty((embed_dim, self.vdim), **factory_kwargs))
   962|         0|            0|            0|  0.00%|            self.register_parameter('in_proj_weight', None)
   963|         0|            0|            0|  0.00%|        else:
   964|         0|            0|            0|  0.00%|            self.in_proj_weight = Parameter(torch.empty((3 * embed_dim, embed_dim), **factory_kwargs))
   965|         0|            0|            0|  0.00%|            self.register_parameter('q_proj_weight', None)
   966|         0|            0|            0|  0.00%|            self.register_parameter('k_proj_weight', None)
   967|         0|            0|            0|  0.00%|            self.register_parameter('v_proj_weight', None)
   968|         0|            0|            0|  0.00%|
   969|         0|            0|            0|  0.00%|        if bias:
   970|         0|            0|            0|  0.00%|            self.in_proj_bias = Parameter(torch.empty(3 * embed_dim, **factory_kwargs))
   971|         0|            0|            0|  0.00%|        else:
   972|         0|            0|            0|  0.00%|            self.register_parameter('in_proj_bias', None)
   973|         0|            0|            0|  0.00%|        self.out_proj = NonDynamicallyQuantizableLinear(embed_dim, embed_dim, bias=bias, **factory_kwargs)
   974|         0|            0|            0|  0.00%|
   975|         0|            0|            0|  0.00%|        if add_bias_kv:
   976|         0|            0|            0|  0.00%|            self.bias_k = Parameter(torch.empty((1, 1, embed_dim), **factory_kwargs))
   977|         0|            0|            0|  0.00%|            self.bias_v = Parameter(torch.empty((1, 1, embed_dim), **factory_kwargs))
   978|         0|            0|            0|  0.00%|        else:
   979|         0|            0|            0|  0.00%|            self.bias_k = self.bias_v = None
   980|         0|            0|            0|  0.00%|
   981|         0|            0|            0|  0.00%|        self.add_zero_attn = add_zero_attn
   982|         0|            0|            0|  0.00%|
   983|         0|            0|            0|  0.00%|        self._reset_parameters()
   984|         0|            0|            0|  0.00%|
   985|         0|            0|            0|  0.00%|    def _reset_parameters(self):
   986|         0|            0|            0|  0.00%|        if self._qkv_same_embed_dim:
   987|         0|            0|            0|  0.00%|            xavier_uniform_(self.in_proj_weight)
   988|         0|            0|            0|  0.00%|        else:
   989|         0|            0|            0|  0.00%|            xavier_uniform_(self.q_proj_weight)
   990|         0|            0|            0|  0.00%|            xavier_uniform_(self.k_proj_weight)
   991|         0|            0|            0|  0.00%|            xavier_uniform_(self.v_proj_weight)
   992|         0|            0|            0|  0.00%|
   993|         0|            0|            0|  0.00%|        if self.in_proj_bias is not None:
   994|         0|            0|            0|  0.00%|            constant_(self.in_proj_bias, 0.)
   995|         0|            0|            0|  0.00%|            constant_(self.out_proj.bias, 0.)
   996|         0|            0|            0|  0.00%|        if self.bias_k is not None:
   997|         0|            0|            0|  0.00%|            xavier_normal_(self.bias_k)
   998|         0|            0|            0|  0.00%|        if self.bias_v is not None:
   999|         0|            0|            0|  0.00%|            xavier_normal_(self.bias_v)
  1000|         0|            0|            0|  0.00%|
  1001|         0|            0|            0|  0.00%|    def __setstate__(self, state):
  1002|         0|            0|            0|  0.00%|        # Support loading old MultiheadAttention checkpoints generated by v1.1.0
  1003|         0|            0|            0|  0.00%|        if '_qkv_same_embed_dim' not in state:
  1004|         0|            0|            0|  0.00%|            state['_qkv_same_embed_dim'] = True
  1005|         0|            0|            0|  0.00%|
  1006|         0|            0|            0|  0.00%|        super(MultiheadAttention, self).__setstate__(state)
  1007|         0|            0|            0|  0.00%|
  1008|         0|            0|            0|  0.00%|    def forward(self, query: Tensor, key: Tensor, value: Tensor, key_padding_mask: Optional[Tensor] = None,
  1009|         0|            0|            0|  0.00%|                need_weights: bool = True, attn_mask: Optional[Tensor] = None,
  1010|         0|            0|            0|  0.00%|                average_attn_weights: bool = True) -> Tuple[Tensor, Optional[Tensor]]:
  1011|         0|            0|            0|  0.00%|        r"""
  1012|         0|            0|            0|  0.00%|    Args:
  1013|         0|            0|            0|  0.00%|        query: Query embeddings of shape :math:`(L, E_q)` for unbatched input, :math:`(L, N, E_q)` when ``batch_first=False``
  1014|         0|            0|            0|  0.00%|            or :math:`(N, L, E_q)` when ``batch_first=True``, where :math:`L` is the target sequence length,
  1015|         0|            0|            0|  0.00%|            :math:`N` is the batch size, and :math:`E_q` is the query embedding dimension ``embed_dim``.
  1016|         0|            0|            0|  0.00%|            Queries are compared against key-value pairs to produce the output.
  1017|         0|            0|            0|  0.00%|            See "Attention Is All You Need" for more details.
  1018|         0|            0|            0|  0.00%|        key: Key embeddings of shape :math:`(S, E_k)` for unbatched input, :math:`(S, N, E_k)` when ``batch_first=False``
  1019|         0|            0|            0|  0.00%|            or :math:`(N, S, E_k)` when ``batch_first=True``, where :math:`S` is the source sequence length,
  1020|         0|            0|            0|  0.00%|            :math:`N` is the batch size, and :math:`E_k` is the key embedding dimension ``kdim``.
  1021|         0|            0|            0|  0.00%|            See "Attention Is All You Need" for more details.
  1022|         0|            0|            0|  0.00%|        value: Value embeddings of shape :math:`(S, E_v)` for unbatched input, :math:`(S, N, E_v)` when
  1023|         0|            0|            0|  0.00%|            ``batch_first=False`` or :math:`(N, S, E_v)` when ``batch_first=True``, where :math:`S` is the source
  1024|         0|            0|            0|  0.00%|            sequence length, :math:`N` is the batch size, and :math:`E_v` is the value embedding dimension ``vdim``.
  1025|         0|            0|            0|  0.00%|            See "Attention Is All You Need" for more details.
  1026|         0|            0|            0|  0.00%|        key_padding_mask: If specified, a mask of shape :math:`(N, S)` indicating which elements within ``key``
  1027|         0|            0|            0|  0.00%|            to ignore for the purpose of attention (i.e. treat as "padding"). For unbatched `query`, shape should be :math:`(S)`.
  1028|         0|            0|            0|  0.00%|            Binary and byte masks are supported.
  1029|         0|            0|            0|  0.00%|            For a binary mask, a ``True`` value indicates that the corresponding ``key`` value will be ignored for
  1030|         0|            0|            0|  0.00%|            the purpose of attention. For a byte mask, a non-zero value indicates that the corresponding ``key``
  1031|         0|            0|            0|  0.00%|            value will be ignored.
  1032|         0|            0|            0|  0.00%|        need_weights: If specified, returns ``attn_output_weights`` in addition to ``attn_outputs``.
  1033|         0|            0|            0|  0.00%|            Default: ``True``.
  1034|         0|            0|            0|  0.00%|        attn_mask: If specified, a 2D or 3D mask preventing attention to certain positions. Must be of shape
  1035|         0|            0|            0|  0.00%|            :math:`(L, S)` or :math:`(N\cdot\text{num\_heads}, L, S)`, where :math:`N` is the batch size,
  1036|         0|            0|            0|  0.00%|            :math:`L` is the target sequence length, and :math:`S` is the source sequence length. A 2D mask will be
  1037|         0|            0|            0|  0.00%|            broadcasted across the batch while a 3D mask allows for a different mask for each entry in the batch.
  1038|         0|            0|            0|  0.00%|            Binary, byte, and float masks are supported. For a binary mask, a ``True`` value indicates that the
  1039|         0|            0|            0|  0.00%|            corresponding position is not allowed to attend. For a byte mask, a non-zero value indicates that the
  1040|         0|            0|            0|  0.00%|            corresponding position is not allowed to attend. For a float mask, the mask values will be added to
  1041|         0|            0|            0|  0.00%|            the attention weight.
  1042|         0|            0|            0|  0.00%|        average_attn_weights: If true, indicates that the returned ``attn_weights`` should be averaged across
  1043|         0|            0|            0|  0.00%|            heads. Otherwise, ``attn_weights`` are provided separately per head. Note that this flag only has an
  1044|         0|            0|            0|  0.00%|            effect when ``need_weights=True``. Default: ``True`` (i.e. average weights across heads)
  1045|         0|            0|            0|  0.00%|
  1046|         0|            0|            0|  0.00%|    Outputs:
  1047|         0|            0|            0|  0.00%|        - **attn_output** - Attention outputs of shape :math:`(L, E)` when input is unbatched,
  1048|         0|            0|            0|  0.00%|          :math:`(L, N, E)` when ``batch_first=False`` or :math:`(N, L, E)` when ``batch_first=True``,
  1049|         0|            0|            0|  0.00%|          where :math:`L` is the target sequence length, :math:`N` is the batch size, and :math:`E` is the
  1050|         0|            0|            0|  0.00%|          embedding dimension ``embed_dim``.
  1051|         0|            0|            0|  0.00%|        - **attn_output_weights** - Only returned when ``need_weights=True``. If ``average_attn_weights=True``,
  1052|         0|            0|            0|  0.00%|          returns attention weights averaged across heads of shape :math:`(L, S)` when input is unbatched or
  1053|         0|            0|            0|  0.00%|          :math:`(N, L, S)`, where :math:`N` is the batch size, :math:`L` is the target sequence length, and
  1054|         0|            0|            0|  0.00%|          :math:`S` is the source sequence length. If ``average_weights=False``, returns attention weights per
  1055|         0|            0|            0|  0.00%|          head of shape :math:`(\text{num\_heads}, L, S)` when input is unbatched or :math:`(N, \text{num\_heads}, L, S)`.
  1056|         0|            0|            0|  0.00%|
  1057|         0|            0|            0|  0.00%|        .. note::
  1058|         0|            0|            0|  0.00%|            `batch_first` argument is ignored for unbatched inputs.
  1059|         0|            0|            0|  0.00%|        """
  1060|         0|            0|            0|  0.00%|        is_batched = query.dim() == 3
  1061|         0|            0|            0|  0.00%|        why_not_fast_path = ''
  1062|         0|            0|            0|  0.00%|        if not is_batched:
  1063|         0|            0|            0|  0.00%|            why_not_fast_path = f"input not batched; expected query.dim() of 3 but got {query.dim()}"
  1064|         0|            0|            0|  0.00%|        elif query is not key or key is not value:
  1065|         0|            0|            0|  0.00%|            # When lifting this restriction, don't forget to either
  1066|         0|            0|            0|  0.00%|            # enforce that the dtypes all match or test cases where
  1067|         0|            0|            0|  0.00%|            # they don't!
  1068|         0|            0|            0|  0.00%|            why_not_fast_path = "non-self attention was used (query, key, and value are not the same Tensor)"
  1069|         0|            0|            0|  0.00%|        elif self.in_proj_bias is not None and query.dtype != self.in_proj_bias.dtype:
  1070|         0|            0|            0|  0.00%|            why_not_fast_path = f"dtypes of query ({query.dtype}) and self.in_proj_bias ({self.in_proj_bias.dtype}) don't match"
  1071|         0|            0|            0|  0.00%|        elif self.in_proj_weight is not None and query.dtype != self.in_proj_weight.dtype:
  1072|         0|            0|            0|  0.00%|            # this case will fail anyway, but at least they'll get a useful error message.
  1073|         0|            0|            0|  0.00%|            why_not_fast_path = f"dtypes of query ({query.dtype}) and self.in_proj_weight ({self.in_proj_weight.dtype}) don't match"
  1074|         0|            0|            0|  0.00%|        elif self.training:
  1075|         0|            0|            0|  0.00%|            why_not_fast_path = "training is enabled"
  1076|         0|            0|            0|  0.00%|        elif not self.batch_first:
  1077|         0|            0|            0|  0.00%|            why_not_fast_path = "batch_first was not True"
  1078|         0|            0|            0|  0.00%|        elif self.bias_k is not None:
  1079|         0|            0|            0|  0.00%|            why_not_fast_path = "self.bias_k was not None"
  1080|         0|            0|            0|  0.00%|        elif self.bias_v is not None:
  1081|         0|            0|            0|  0.00%|            why_not_fast_path = "self.bias_v was not None"
  1082|         0|            0|            0|  0.00%|        elif self.dropout:
  1083|         0|            0|            0|  0.00%|            why_not_fast_path = f"dropout was {self.dropout}, required zero"
  1084|         0|            0|            0|  0.00%|        elif self.add_zero_attn:
  1085|         0|            0|            0|  0.00%|            why_not_fast_path = "add_zero_attn was enabled"
  1086|         0|            0|            0|  0.00%|        elif not self._qkv_same_embed_dim:
  1087|         0|            0|            0|  0.00%|            why_not_fast_path = "_qkv_same_embed_dim was not True"
  1088|         0|            0|            0|  0.00%|        elif attn_mask is not None:
  1089|         0|            0|            0|  0.00%|            why_not_fast_path = "attn_mask was not None"
  1090|         0|            0|            0|  0.00%|        elif query.is_nested and key_padding_mask is not None:
  1091|         0|            0|            0|  0.00%|            why_not_fast_path = "key_padding_mask is not supported with NestedTensor input"
  1092|         0|            0|            0|  0.00%|
  1093|         0|            0|            0|  0.00%|        if not why_not_fast_path:
  1094|         0|            0|            0|  0.00%|            tensor_args = (
  1095|         0|            0|            0|  0.00%|                query,
  1096|         0|            0|            0|  0.00%|                key,
  1097|         0|            0|            0|  0.00%|                value,
  1098|         0|            0|            0|  0.00%|                self.in_proj_weight,
  1099|         0|            0|            0|  0.00%|                self.in_proj_bias,
  1100|         0|            0|            0|  0.00%|                self.out_proj.weight,
  1101|         0|            0|            0|  0.00%|                self.out_proj.bias,
  1102|         0|            0|            0|  0.00%|            )
  1103|         0|            0|            0|  0.00%|            # We have to use list comprehensions below because TorchScript does not support
  1104|         0|            0|            0|  0.00%|            # generator expressions.
  1105|         0|            0|            0|  0.00%|            if torch.overrides.has_torch_function(tensor_args):
  1106|         0|            0|            0|  0.00%|                why_not_fast_path = "some Tensor argument has_torch_function"
  1107|         0|            0|            0|  0.00%|            elif not all([(x.is_cuda or 'cpu' in str(x.device)) for x in tensor_args]):
  1108|         0|            0|            0|  0.00%|                why_not_fast_path = "some Tensor argument is neither CUDA nor CPU"
  1109|         0|            0|            0|  0.00%|            elif torch.is_grad_enabled() and any([x.requires_grad for x in tensor_args]):
  1110|         0|            0|            0|  0.00%|                why_not_fast_path = ("grad is enabled and at least one of query or the "
  1111|         0|            0|            0|  0.00%|                                     "input/output projection weights or biases requires_grad")
  1112|         0|            0|            0|  0.00%|            if not why_not_fast_path:
  1113|         0|            0|            0|  0.00%|                return torch._native_multi_head_attention(
  1114|         0|            0|            0|  0.00%|                    query,
  1115|         0|            0|            0|  0.00%|                    key,
  1116|         0|            0|            0|  0.00%|                    value,
  1117|         0|            0|            0|  0.00%|                    self.embed_dim,
  1118|         0|            0|            0|  0.00%|                    self.num_heads,
  1119|         0|            0|            0|  0.00%|                    self.in_proj_weight,
  1120|         0|            0|            0|  0.00%|                    self.in_proj_bias,
  1121|         0|            0|            0|  0.00%|                    self.out_proj.weight,
  1122|         0|            0|            0|  0.00%|                    self.out_proj.bias,
  1123|         0|            0|            0|  0.00%|                    key_padding_mask if key_padding_mask is not None else attn_mask,
  1124|         0|            0|            0|  0.00%|                    need_weights,
  1125|         0|            0|            0|  0.00%|                    average_attn_weights)
  1126|         0|            0|            0|  0.00%|        any_nested = query.is_nested or key.is_nested or value.is_nested
  1127|         0|            0|            0|  0.00%|        assert not any_nested, ("MultiheadAttention does not support NestedTensor outside of its fast path. " +
  1128|         0|            0|            0|  0.00%|                                f"The fast path was not hit because {why_not_fast_path}")
  1129|         0|            0|            0|  0.00%|
  1130|         0|            0|            0|  0.00%|        if self.batch_first and is_batched:
  1131|         0|            0|            0|  0.00%|            # make sure that the transpose op does not affect the "is" property
  1132|         0|            0|            0|  0.00%|            if key is value:
  1133|         0|            0|            0|  0.00%|                if query is key:
  1134|         0|            0|            0|  0.00%|                    query = key = value = query.transpose(1, 0)
  1135|         0|            0|            0|  0.00%|                else:
  1136|         0|            0|            0|  0.00%|                    query, key = [x.transpose(1, 0) for x in (query, key)]
  1137|         0|            0|            0|  0.00%|                    value = key
  1138|         0|            0|            0|  0.00%|            else:
  1139|         0|            0|            0|  0.00%|                query, key, value = [x.transpose(1, 0) for x in (query, key, value)]
  1140|         0|            0|            0|  0.00%|
  1141|         0|            0|            0|  0.00%|        if not self._qkv_same_embed_dim:
  1142|         0|            0|            0|  0.00%|            attn_output, attn_output_weights = F.multi_head_attention_forward(
  1143|         0|            0|            0|  0.00%|                query, key, value, self.embed_dim, self.num_heads,
  1144|         0|            0|            0|  0.00%|                self.in_proj_weight, self.in_proj_bias,
  1145|         0|            0|            0|  0.00%|                self.bias_k, self.bias_v, self.add_zero_attn,
  1146|         0|            0|            0|  0.00%|                self.dropout, self.out_proj.weight, self.out_proj.bias,
  1147|         0|            0|            0|  0.00%|                training=self.training,
  1148|         0|            0|            0|  0.00%|                key_padding_mask=key_padding_mask, need_weights=need_weights,
  1149|         0|            0|            0|  0.00%|                attn_mask=attn_mask, use_separate_proj_weight=True,
  1150|         0|            0|            0|  0.00%|                q_proj_weight=self.q_proj_weight, k_proj_weight=self.k_proj_weight,
  1151|         0|            0|            0|  0.00%|                v_proj_weight=self.v_proj_weight, average_attn_weights=average_attn_weights)
  1152|         0|            0|            0|  0.00%|        else:
  1153|         0|            0|            0|  0.00%|            attn_output, attn_output_weights = F.multi_head_attention_forward(
  1154|         0|            0|            0|  0.00%|                query, key, value, self.embed_dim, self.num_heads,
  1155|         0|            0|            0|  0.00%|                self.in_proj_weight, self.in_proj_bias,
  1156|         0|            0|            0|  0.00%|                self.bias_k, self.bias_v, self.add_zero_attn,
  1157|         0|            0|            0|  0.00%|                self.dropout, self.out_proj.weight, self.out_proj.bias,
  1158|         0|            0|            0|  0.00%|                training=self.training,
  1159|         0|            0|            0|  0.00%|                key_padding_mask=key_padding_mask, need_weights=need_weights,
  1160|         0|            0|            0|  0.00%|                attn_mask=attn_mask, average_attn_weights=average_attn_weights)
  1161|         0|            0|            0|  0.00%|        if self.batch_first and is_batched:
  1162|         0|            0|            0|  0.00%|            return attn_output.transpose(1, 0), attn_output_weights
  1163|         0|            0|            0|  0.00%|        else:
  1164|         0|            0|            0|  0.00%|            return attn_output, attn_output_weights
  1165|         0|            0|            0|  0.00%|
  1166|         0|            0|            0|  0.00%|class PReLU(Module):
  1167|         0|            0|            0|  0.00%|    r"""Applies the element-wise function:
  1168|         0|            0|            0|  0.00%|
  1169|         0|            0|            0|  0.00%|    .. math::
  1170|         0|            0|            0|  0.00%|        \text{PReLU}(x) = \max(0,x) + a * \min(0,x)
  1171|         0|            0|            0|  0.00%|
  1172|         0|            0|            0|  0.00%|    or
  1173|         0|            0|            0|  0.00%|
  1174|         0|            0|            0|  0.00%|    .. math::
  1175|         0|            0|            0|  0.00%|        \text{PReLU}(x) =
  1176|         0|            0|            0|  0.00%|        \begin{cases}
  1177|         0|            0|            0|  0.00%|        x, & \text{ if } x \geq 0 \\
  1178|         0|            0|            0|  0.00%|        ax, & \text{ otherwise }
  1179|         0|            0|            0|  0.00%|        \end{cases}
  1180|         0|            0|            0|  0.00%|
  1181|         0|            0|            0|  0.00%|    Here :math:`a` is a learnable parameter. When called without arguments, `nn.PReLU()` uses a single
  1182|         0|            0|            0|  0.00%|    parameter :math:`a` across all input channels. If called with `nn.PReLU(nChannels)`,
  1183|         0|            0|            0|  0.00%|    a separate :math:`a` is used for each input channel.
  1184|         0|            0|            0|  0.00%|
  1185|         0|            0|            0|  0.00%|
  1186|         0|            0|            0|  0.00%|    .. note::
  1187|         0|            0|            0|  0.00%|        weight decay should not be used when learning :math:`a` for good performance.
  1188|         0|            0|            0|  0.00%|
  1189|         0|            0|            0|  0.00%|    .. note::
  1190|         0|            0|            0|  0.00%|        Channel dim is the 2nd dim of input. When input has dims < 2, then there is
  1191|         0|            0|            0|  0.00%|        no channel dim and the number of channels = 1.
  1192|         0|            0|            0|  0.00%|
  1193|         0|            0|            0|  0.00%|    Args:
  1194|         0|            0|            0|  0.00%|        num_parameters (int): number of :math:`a` to learn.
  1195|         0|            0|            0|  0.00%|            Although it takes an int as input, there is only two values are legitimate:
  1196|         0|            0|            0|  0.00%|            1, or the number of channels at input. Default: 1
  1197|         0|            0|            0|  0.00%|        init (float): the initial value of :math:`a`. Default: 0.25
  1198|         0|            0|            0|  0.00%|
  1199|         0|            0|            0|  0.00%|    Shape:
  1200|         0|            0|            0|  0.00%|        - Input: :math:`( *)` where `*` means, any number of additional
  1201|         0|            0|            0|  0.00%|          dimensions.
  1202|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
  1203|         0|            0|            0|  0.00%|
  1204|         0|            0|            0|  0.00%|    Attributes:
  1205|         0|            0|            0|  0.00%|        weight (Tensor): the learnable weights of shape (:attr:`num_parameters`).
  1206|         0|            0|            0|  0.00%|
  1207|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/PReLU.png
  1208|         0|            0|            0|  0.00%|
  1209|         0|            0|            0|  0.00%|    Examples::
  1210|         0|            0|            0|  0.00%|
  1211|         0|            0|            0|  0.00%|        >>> m = nn.PReLU()
  1212|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
  1213|         0|            0|            0|  0.00%|        >>> output = m(input)
  1214|         0|            0|            0|  0.00%|    """
  1215|         0|            0|            0|  0.00%|    __constants__ = ['num_parameters']
  1216|         0|            0|            0|  0.00%|    num_parameters: int
  1217|         0|            0|            0|  0.00%|
  1218|         0|            0|            0|  0.00%|    def __init__(self, num_parameters: int = 1, init: float = 0.25,
  1219|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:
  1220|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}
  1221|         0|            0|            0|  0.00%|        self.num_parameters = num_parameters
  1222|         0|            0|            0|  0.00%|        super(PReLU, self).__init__()
  1223|         0|            0|            0|  0.00%|        self.weight = Parameter(torch.empty(num_parameters, **factory_kwargs).fill_(init))
  1224|         0|            0|            0|  0.00%|
  1225|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
  1226|         0|            0|            0|  0.00%|        return F.prelu(input, self.weight)
  1227|         0|            0|            0|  0.00%|
  1228|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
  1229|         0|            0|            0|  0.00%|        return 'num_parameters={}'.format(self.num_parameters)
  1230|         0|            0|            0|  0.00%|
  1231|         0|            0|            0|  0.00%|
  1232|         0|            0|            0|  0.00%|class Softsign(Module):
  1233|         0|            0|            0|  0.00%|    r"""Applies the element-wise function:
  1234|         0|            0|            0|  0.00%|
  1235|         0|            0|            0|  0.00%|    .. math::
  1236|         0|            0|            0|  0.00%|        \text{SoftSign}(x) = \frac{x}{ 1 + |x|}
  1237|         0|            0|            0|  0.00%|
  1238|         0|            0|            0|  0.00%|    Shape:
  1239|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
  1240|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
  1241|         0|            0|            0|  0.00%|
  1242|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/Softsign.png
  1243|         0|            0|            0|  0.00%|
  1244|         0|            0|            0|  0.00%|    Examples::
  1245|         0|            0|            0|  0.00%|
  1246|         0|            0|            0|  0.00%|        >>> m = nn.Softsign()
  1247|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
  1248|         0|            0|            0|  0.00%|        >>> output = m(input)
  1249|         0|            0|            0|  0.00%|    """
  1250|         0|            0|            0|  0.00%|
  1251|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
  1252|         0|            0|            0|  0.00%|        return F.softsign(input)
  1253|         0|            0|            0|  0.00%|
  1254|         0|            0|            0|  0.00%|
  1255|         0|            0|            0|  0.00%|class Tanhshrink(Module):
  1256|         0|            0|            0|  0.00%|    r"""Applies the element-wise function:
  1257|         0|            0|            0|  0.00%|
  1258|         0|            0|            0|  0.00%|    .. math::
  1259|         0|            0|            0|  0.00%|        \text{Tanhshrink}(x) = x - \tanh(x)
  1260|         0|            0|            0|  0.00%|
  1261|         0|            0|            0|  0.00%|    Shape:
  1262|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
  1263|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.
  1264|         0|            0|            0|  0.00%|
  1265|         0|            0|            0|  0.00%|    .. image:: ../scripts/activation_images/Tanhshrink.png
  1266|         0|            0|            0|  0.00%|
  1267|         0|            0|            0|  0.00%|    Examples::
  1268|         0|            0|            0|  0.00%|
  1269|         0|            0|            0|  0.00%|        >>> m = nn.Tanhshrink()
  1270|         0|            0|            0|  0.00%|        >>> input = torch.randn(2)
  1271|         0|            0|            0|  0.00%|        >>> output = m(input)
  1272|         0|            0|            0|  0.00%|    """
  1273|         0|            0|            0|  0.00%|
  1274|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
  1275|         0|            0|            0|  0.00%|        return F.tanhshrink(input)
  1276|         0|            0|            0|  0.00%|
  1277|         0|            0|            0|  0.00%|
  1278|         0|            0|            0|  0.00%|class Softmin(Module):
  1279|         0|            0|            0|  0.00%|    r"""Applies the Softmin function to an n-dimensional input Tensor
  1280|         0|            0|            0|  0.00%|    rescaling them so that the elements of the n-dimensional output Tensor
  1281|         0|            0|            0|  0.00%|    lie in the range `[0, 1]` and sum to 1.
  1282|         0|            0|            0|  0.00%|
  1283|         0|            0|            0|  0.00%|    Softmin is defined as:
  1284|         0|            0|            0|  0.00%|
  1285|         0|            0|            0|  0.00%|    .. math::
  1286|         0|            0|            0|  0.00%|        \text{Softmin}(x_{i}) = \frac{\exp(-x_i)}{\sum_j \exp(-x_j)}
  1287|         0|            0|            0|  0.00%|
  1288|         0|            0|            0|  0.00%|    Shape:
  1289|         0|            0|            0|  0.00%|        - Input: :math:`(*)` where `*` means, any number of additional
  1290|         0|            0|            0|  0.00%|          dimensions
  1291|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input
  1292|         0|            0|            0|  0.00%|
  1293|         0|            0|            0|  0.00%|    Args:
  1294|         0|            0|            0|  0.00%|        dim (int): A dimension along which Softmin will be computed (so every slice
  1295|         0|            0|            0|  0.00%|            along dim will sum to 1).
  1296|         0|            0|            0|  0.00%|
  1297|         0|            0|            0|  0.00%|    Returns:
  1298|         0|            0|            0|  0.00%|        a Tensor of the same dimension and shape as the input, with
  1299|         0|            0|            0|  0.00%|        values in the range [0, 1]
  1300|         0|            0|            0|  0.00%|
  1301|         0|            0|            0|  0.00%|    Examples::
  1302|         0|            0|            0|  0.00%|
  1303|         0|            0|            0|  0.00%|        >>> m = nn.Softmin()
  1304|         0|            0|            0|  0.00%|        >>> input = torch.randn(2, 3)
  1305|         0|            0|            0|  0.00%|        >>> output = m(input)
  1306|         0|            0|            0|  0.00%|    """
  1307|         0|            0|            0|  0.00%|    __constants__ = ['dim']
  1308|         0|            0|            0|  0.00%|    dim: Optional[int]
  1309|         0|            0|            0|  0.00%|
  1310|         0|            0|            0|  0.00%|    def __init__(self, dim: Optional[int] = None) -> None:
  1311|         0|            0|            0|  0.00%|        super(Softmin, self).__init__()
  1312|         0|            0|            0|  0.00%|        self.dim = dim
  1313|         0|            0|            0|  0.00%|
  1314|         0|            0|            0|  0.00%|    def __setstate__(self, state):
  1315|         0|            0|            0|  0.00%|        super().__setstate__(state)
  1316|         0|            0|            0|  0.00%|        if not hasattr(self, 'dim'):
  1317|         0|            0|            0|  0.00%|            self.dim = None
  1318|         0|            0|            0|  0.00%|
  1319|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
  1320|         0|            0|            0|  0.00%|        return F.softmin(input, self.dim, _stacklevel=5)
  1321|         0|            0|            0|  0.00%|
  1322|         0|            0|            0|  0.00%|    def extra_repr(self):
  1323|         0|            0|            0|  0.00%|        return 'dim={dim}'.format(dim=self.dim)
  1324|         0|            0|            0|  0.00%|
  1325|         0|            0|            0|  0.00%|class Softmax(Module):
  1326|         0|            0|            0|  0.00%|    r"""Applies the Softmax function to an n-dimensional input Tensor
  1327|         0|            0|            0|  0.00%|    rescaling them so that the elements of the n-dimensional output Tensor
  1328|         0|            0|            0|  0.00%|    lie in the range [0,1] and sum to 1.
  1329|         0|            0|            0|  0.00%|
  1330|         0|            0|            0|  0.00%|    Softmax is defined as:
  1331|         0|            0|            0|  0.00%|
  1332|         0|            0|            0|  0.00%|    .. math::
  1333|         0|            0|            0|  0.00%|        \text{Softmax}(x_{i}) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}
  1334|         0|            0|            0|  0.00%|
  1335|         0|            0|            0|  0.00%|    When the input Tensor is a sparse tensor then the unspecifed
  1336|         0|            0|            0|  0.00%|    values are treated as ``-inf``.
  1337|         0|            0|            0|  0.00%|
  1338|         0|            0|            0|  0.00%|    Shape:
  1339|         0|            0|            0|  0.00%|        - Input: :math:`(*)` where `*` means, any number of additional
  1340|         0|            0|            0|  0.00%|          dimensions
  1341|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input
  1342|         0|            0|            0|  0.00%|
  1343|         0|            0|            0|  0.00%|    Returns:
  1344|         0|            0|            0|  0.00%|        a Tensor of the same dimension and shape as the input with
  1345|         0|            0|            0|  0.00%|        values in the range [0, 1]
  1346|         0|            0|            0|  0.00%|
  1347|         0|            0|            0|  0.00%|    Args:
  1348|         0|            0|            0|  0.00%|        dim (int): A dimension along which Softmax will be computed (so every slice
  1349|         0|            0|            0|  0.00%|            along dim will sum to 1).
  1350|         0|            0|            0|  0.00%|
  1351|         0|            0|            0|  0.00%|    .. note::
  1352|         0|            0|            0|  0.00%|        This module doesn't work directly with NLLLoss,
  1353|         0|            0|            0|  0.00%|        which expects the Log to be computed between the Softmax and itself.
  1354|         0|            0|            0|  0.00%|        Use `LogSoftmax` instead (it's faster and has better numerical properties).
  1355|         0|            0|            0|  0.00%|
  1356|         0|            0|            0|  0.00%|    Examples::
  1357|         0|            0|            0|  0.00%|
  1358|         0|            0|            0|  0.00%|        >>> m = nn.Softmax(dim=1)
  1359|         0|            0|            0|  0.00%|        >>> input = torch.randn(2, 3)
  1360|         0|            0|            0|  0.00%|        >>> output = m(input)
  1361|         0|            0|            0|  0.00%|
  1362|         0|            0|            0|  0.00%|    """
  1363|         0|            0|            0|  0.00%|    __constants__ = ['dim']
  1364|         0|            0|            0|  0.00%|    dim: Optional[int]
  1365|         0|            0|            0|  0.00%|
  1366|         0|            0|            0|  0.00%|    def __init__(self, dim: Optional[int] = None) -> None:
  1367|         0|            0|            0|  0.00%|        super(Softmax, self).__init__()
  1368|         0|            0|            0|  0.00%|        self.dim = dim
  1369|         0|            0|            0|  0.00%|
  1370|         0|            0|            0|  0.00%|    def __setstate__(self, state):
  1371|         0|            0|            0|  0.00%|        super().__setstate__(state)
  1372|         0|            0|            0|  0.00%|        if not hasattr(self, 'dim'):
  1373|         0|            0|            0|  0.00%|            self.dim = None
  1374|         0|            0|            0|  0.00%|
  1375|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
  1376|         0|            0|            0|  0.00%|        return F.softmax(input, self.dim, _stacklevel=5)
  1377|         0|            0|            0|  0.00%|
  1378|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:
  1379|         0|            0|            0|  0.00%|        return 'dim={dim}'.format(dim=self.dim)
  1380|         0|            0|            0|  0.00%|
  1381|         0|            0|            0|  0.00%|
  1382|         0|            0|            0|  0.00%|class Softmax2d(Module):
  1383|         0|            0|            0|  0.00%|    r"""Applies SoftMax over features to each spatial location.
  1384|         0|            0|            0|  0.00%|
  1385|         0|            0|            0|  0.00%|    When given an image of ``Channels x Height x Width``, it will
  1386|         0|            0|            0|  0.00%|    apply `Softmax` to each location :math:`(Channels, h_i, w_j)`
  1387|         0|            0|            0|  0.00%|
  1388|         0|            0|            0|  0.00%|    Shape:
  1389|         0|            0|            0|  0.00%|        - Input: :math:`(N, C, H, W)` or :math:`(C, H, W)`.
  1390|         0|            0|            0|  0.00%|        - Output: :math:`(N, C, H, W)` or :math:`(C, H, W)` (same shape as input)
  1391|         0|            0|            0|  0.00%|
  1392|         0|            0|            0|  0.00%|    Returns:
  1393|         0|            0|            0|  0.00%|        a Tensor of the same dimension and shape as the input with
  1394|         0|            0|            0|  0.00%|        values in the range [0, 1]
  1395|         0|            0|            0|  0.00%|
  1396|         0|            0|            0|  0.00%|    Examples::
  1397|         0|            0|            0|  0.00%|
  1398|         0|            0|            0|  0.00%|        >>> m = nn.Softmax2d()
  1399|         0|            0|            0|  0.00%|        >>> # you softmax over the 2nd dimension
  1400|         0|            0|            0|  0.00%|        >>> input = torch.randn(2, 3, 12, 13)
  1401|         0|            0|            0|  0.00%|        >>> output = m(input)
  1402|         0|            0|            0|  0.00%|    """
  1403|         0|            0|            0|  0.00%|
  1404|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
  1405|         0|            0|            0|  0.00%|        assert input.dim() == 4 or input.dim() == 3, 'Softmax2d requires a 3D or 4D tensor as input'
  1406|         0|            0|            0|  0.00%|        return F.softmax(input, -3, _stacklevel=5)
  1407|         0|            0|            0|  0.00%|
  1408|         0|            0|            0|  0.00%|
  1409|         0|            0|            0|  0.00%|class LogSoftmax(Module):
  1410|         0|            0|            0|  0.00%|    r"""Applies the :math:`\log(\text{Softmax}(x))` function to an n-dimensional
  1411|         0|            0|            0|  0.00%|    input Tensor. The LogSoftmax formulation can be simplified as:
  1412|         0|            0|            0|  0.00%|
  1413|         0|            0|            0|  0.00%|    .. math::
  1414|         0|            0|            0|  0.00%|        \text{LogSoftmax}(x_{i}) = \log\left(\frac{\exp(x_i) }{ \sum_j \exp(x_j)} \right)
  1415|         0|            0|            0|  0.00%|
  1416|         0|            0|            0|  0.00%|    Shape:
  1417|         0|            0|            0|  0.00%|        - Input: :math:`(*)` where `*` means, any number of additional
  1418|         0|            0|            0|  0.00%|          dimensions
  1419|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input
  1420|         0|            0|            0|  0.00%|
  1421|         0|            0|            0|  0.00%|    Args:
  1422|         0|            0|            0|  0.00%|        dim (int): A dimension along which LogSoftmax will be computed.
  1423|         0|            0|            0|  0.00%|
  1424|         0|            0|            0|  0.00%|    Returns:
  1425|         0|            0|            0|  0.00%|        a Tensor of the same dimension and shape as the input with
  1426|         0|            0|            0|  0.00%|        values in the range [-inf, 0)
  1427|         0|            0|            0|  0.00%|
  1428|         0|            0|            0|  0.00%|    Examples::
  1429|         0|            0|            0|  0.00%|
  1430|         0|            0|            0|  0.00%|        >>> m = nn.LogSoftmax()
  1431|         0|            0|            0|  0.00%|        >>> input = torch.randn(2, 3)
  1432|         0|            0|            0|  0.00%|        >>> output = m(input)
  1433|         0|            0|            0|  0.00%|    """
  1434|         0|            0|            0|  0.00%|    __constants__ = ['dim']
  1435|         0|            0|            0|  0.00%|    dim: Optional[int]
  1436|         0|            0|            0|  0.00%|
  1437|         0|            0|            0|  0.00%|    def __init__(self, dim: Optional[int] = None) -> None:
  1438|         0|            0|            0|  0.00%|        super(LogSoftmax, self).__init__()
  1439|         0|            0|            0|  0.00%|        self.dim = dim
  1440|         0|            0|            0|  0.00%|
  1441|         0|            0|            0|  0.00%|    def __setstate__(self, state):
  1442|         0|            0|            0|  0.00%|        super().__setstate__(state)
  1443|         0|            0|            0|  0.00%|        if not hasattr(self, 'dim'):
  1444|         0|            0|            0|  0.00%|            self.dim = None
  1445|         0|            0|            0|  0.00%|
  1446|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:
  1447|         0|            0|            0|  0.00%|        return F.log_softmax(input, self.dim, _stacklevel=5)
  1448|         0|            0|            0|  0.00%|
  1449|         0|            0|            0|  0.00%|    def extra_repr(self):
  1450|         0|            0|            0|  0.00%|        return 'dim={dim}'.format(dim=self.dim)
File: /apps/open_spiel/open_spiel/python/examples/ubc_utils.py
File duration: 0.107685s (0.10%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|from ..pytorch.ppo import PPOAgent
     2|         0|            0|            0|  0.00%|import pyspiel
     3|         0|            0|            0|  0.00%|from absl import logging
     4|         0|            0|            0|  0.00%|import numpy as np
     5|         0|            0|            0|  0.00%|import pandas as pd
     6|         0|            0|            0|  0.00%|import itertools
     7|         0|            0|            0|  0.00%|import pulp
     8|         0|            0|            0|  0.00%|from pulp import LpStatus
     9|         0|            0|            0|  0.00%|import random
    10|         0|            0|            0|  0.00%|import string
    11|         0|            0|            0|  0.00%|from open_spiel.python.rl_agent import StepOutput
    12|         0|            0|            0|  0.00%|import torch
    13|         0|            0|            0|  0.00%|import humanize
    14|         0|            0|            0|  0.00%|import datetime as dt
    15|         0|            0|            0|  0.00%|import os
    16|         0|            0|            0|  0.00%|import json
    17|         0|            0|            0|  0.00%|import yaml
    18|         0|            0|            0|  0.00%|import shutil
    19|         0|            0|            0|  0.00%|from open_spiel.python.examples.ubc_math_utils import fast_choice
    20|         0|            0|            0|  0.00%|
    21|         0|            0|            0|  0.00%|CONFIG_ROOT = '/apps/open_spiel/notebooks/configs'
    22|         0|            0|            0|  0.00%|
    23|         0|            0|            0|  0.00%|CLOCK_AUCTION = 'clock_auction'
    24|         0|            0|            0|  0.00%|
    25|         0|            0|            0|  0.00%|BR_DIR = 'best_responses'
    26|         0|            0|            0|  0.00%|CHECKPOINT_FOLDER = 'solving_checkpoints' # Don't use "checkpoints" because jupyter bug
    27|         0|            0|            0|  0.00%|EVAL_DIR = 'evaluations'
    28|         0|            0|            0|  0.00%|
    29|         0|            0|            0|  0.00%|def setup_directory_structure(output_dir, warn_on_overwrite, database=True):
    30|         0|            0|            0|  0.00%|    if not os.path.exists(output_dir):
    31|         0|            0|            0|  0.00%|        os.makedirs(output_dir)
    32|         0|            0|            0|  0.00%|    else:
    33|         0|            0|            0|  0.00%|        if warn_on_overwrite:
    34|         0|            0|            0|  0.00%|            raise ValueError("You are overwriting a folder!")
    35|         0|            0|            0|  0.00%|        shutil.rmtree(output_dir)
    36|         0|            0|            0|  0.00%|        os.makedirs(output_dir)
    37|         0|            0|            0|  0.00%|
    38|         0|            0|            0|  0.00%|    os.makedirs(os.path.join(output_dir, BR_DIR))
    39|         0|            0|            0|  0.00%|    os.makedirs(os.path.join(output_dir, EVAL_DIR))
    40|         0|            0|            0|  0.00%|    if not database:
    41|         0|            0|            0|  0.00%|        os.makedirs(os.path.join(output_dir, CHECKPOINT_FOLDER))
    42|         0|            0|            0|  0.00%|
    43|         1|  4.05312e-06|  4.05312e-06|  0.00%|def fix_seeds(seed):
    44|         1|  1.45435e-05|  1.45435e-05|  0.00%|    logging.info(f"Setting numpy and torch seed to {seed}")
(call)|         1|  0.000153542|  0.000153542|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/absl/logging/__init__.py:413 info
    45|         1|   1.4782e-05|   1.4782e-05|  0.00%|    np.random.seed(seed)
    46|         1|  1.04904e-05|  1.04904e-05|  0.00%|    torch.manual_seed(seed)
(call)|         1|  0.000156403|  0.000156403|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/random.py:26 manual_seed
    47|         0|            0|            0|  0.00%|    # torch.use_deterministic_algorithms(True) # See https://github.com/pytorch/pytorch/issues/50469
    48|         0|            0|            0|  0.00%|
    49|         0|            0|            0|  0.00%|def single_action_result(legal_actions, num_actions, as_output=False):
    50|         0|            0|            0|  0.00%|    probs = np.zeros(num_actions)
    51|         0|            0|            0|  0.00%|    action = legal_actions[0]
    52|         0|            0|            0|  0.00%|    probs[action] = 1.0
    53|         0|            0|            0|  0.00%|    if as_output:
    54|         0|            0|            0|  0.00%|        return StepOutput(action=action, probs=probs)
    55|         0|            0|            0|  0.00%|    return action, probs
    56|         0|            0|            0|  0.00%|
    57|         0|            0|            0|  0.00%|def get_first_actionable_state(game, forced_types=None, player_id=None):
    58|         0|            0|            0|  0.00%|    state = game.new_initial_state()
    59|         0|            0|            0|  0.00%|    # Skip over chance nodes
    60|         0|            0|            0|  0.00%|    i = 0
    61|         0|            0|            0|  0.00%|    while state.current_player() < 0:
    62|         0|            0|            0|  0.00%|        state = state.child(0 if forced_types is None else forced_types[i]) # Let chance choose first outcome. We're assuming all moves are possible at starting prices for all players, that may not really be true though
    63|         0|            0|            0|  0.00%|        i += 1
    64|         0|            0|            0|  0.00%|
    65|         0|            0|            0|  0.00%|    if player_id is not None:
    66|         0|            0|            0|  0.00%|        while state.current_player() != player_id:
    67|         0|            0|            0|  0.00%|            state = state.child(0)
    68|         0|            0|            0|  0.00%|
    69|         0|            0|            0|  0.00%|    return state
    70|         0|            0|            0|  0.00%|
    71|         0|            0|            0|  0.00%|def get_actions(game):
    72|         0|            0|            0|  0.00%|    state = get_first_actionable_state(game)
    73|         0|            0|            0|  0.00%|    action_dict = dict()
    74|         0|            0|            0|  0.00%|    for i in state.legal_actions():
    75|         0|            0|            0|  0.00%|        action_dict[i] = state.action_to_string(i)
    76|         0|            0|            0|  0.00%|    return action_dict
    77|         0|            0|            0|  0.00%|
    78|         0|            0|            0|  0.00%|def load_game_config(game_name):
    79|         0|            0|            0|  0.00%|    game_config_path = os.path.join(os.environ['CLOCK_AUCTION_CONFIG_DIR'], game_name)
    80|         0|            0|            0|  0.00%|    with open(game_config_path, 'r') as f:
    81|         0|            0|            0|  0.00%|        game_config = json.load(f)
    82|         0|            0|            0|  0.00%|    return game_config
    83|         0|            0|            0|  0.00%|
    84|         0|            0|            0|  0.00%|def solve(problem):
    85|         0|            0|            0|  0.00%|    return problem.solve(solver=pulp.CPLEX_PY(msg=0, gapRel=0))
    86|         0|            0|            0|  0.00%|    # return problem.solve(solver=pulp.CPLEX_CMD(msg=0, options=[f'set mip tolerances mipgap 0']))
    87|         0|            0|            0|  0.00%|    # return problem.solve(solver=pulp.CPLEX_CMD(msg=0, options=[f'set mip tolerances mipgap 0'], keepFiles = 1))
    88|         0|            0|            0|  0.00%|
    89|         0|            0|            0|  0.00%|def objective_from_lp(problem):
    90|         0|            0|            0|  0.00%|    return np.round(problem.objective.value())
    91|         0|            0|            0|  0.00%|
    92|         0|            0|            0|  0.00%|def random_string(k):
    93|         0|            0|            0|  0.00%|    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=k))
    94|         0|            0|            0|  0.00%|
    95|         0|            0|            0|  0.00%|def fail_lp(problem, save_lp, status=None):
    96|         0|            0|            0|  0.00%|    error_message = f"Couldn't solve allocation problem optimally. Status was {status}."
    97|         0|            0|            0|  0.00%|    if save_lp:
    98|         0|            0|            0|  0.00%|        fname = ''.join(random_string(10))
    99|         0|            0|            0|  0.00%|        # TODO: Pickle seems to no longer work TypeError: can't pickle SwigPyObject objects
   100|         0|            0|            0|  0.00%|        # with open(f'{fname}.pkl', 'wb') as f:
   101|         0|            0|            0|  0.00%|        #     pickle.dump(problem, f)
   102|         0|            0|            0|  0.00%|        problem.writeLP(f'{fname}.lp')
   103|         0|            0|            0|  0.00%|        error_message += f'Saved LP to {fname}.lp.'
   104|         0|            0|            0|  0.00%|    raise ValueError(error_message)
   105|         0|            0|            0|  0.00%|
   106|         0|            0|            0|  0.00%|def pulp_solve(problem, solve_function=solve, save_if_failed=True):
   107|         0|            0|            0|  0.00%|    try:
   108|         0|            0|            0|  0.00%|        status = LpStatus[solve_function(problem)]
   109|         0|            0|            0|  0.00%|        if status != "Optimal":
   110|         0|            0|            0|  0.00%|            fail_lp(problem, save_if_failed, status=status)
   111|         0|            0|            0|  0.00%|    except pulp.PulpSolverError as e:
   112|         0|            0|            0|  0.00%|        logging.warning(e)
   113|         0|            0|            0|  0.00%|        fail_lp(problem, save_if_failed)
   114|         0|            0|            0|  0.00%|    return objective_from_lp(problem)
   115|         0|            0|            0|  0.00%|
   116|         1|  5.72205e-06|  5.72205e-06|  0.00%|def pretty_time(seconds):
   117|         1|  1.14441e-05|  1.14441e-05|  0.00%|    delta = dt.timedelta(seconds=seconds)
   118|         1|  2.69413e-05|  2.69413e-05|  0.00%|    return humanize.precisedelta(delta)
(call)|         1|   0.00127316|   0.00127316|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/time.py:399 precisedelta
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|def default_device():
   121|         0|            0|            0|  0.00%|    return 'cuda' if torch.cuda.is_available() else 'cpu'
   122|         0|            0|            0|  0.00%|
   123|         0|            0|            0|  0.00%|def apply_optional_overrides(args, argv, config):
   124|         0|            0|            0|  0.00%|    # Override any top-level yaml args with command line arguments
   125|         0|            0|            0|  0.00%|    for arg in vars(args):
   126|         0|            0|            0|  0.00%|        if f'--{arg}' in argv:
   127|         0|            0|            0|  0.00%|            name = arg
   128|         0|            0|            0|  0.00%|            value = getattr(args, arg)
   129|         0|            0|            0|  0.00%|            if name in config:
   130|         0|            0|            0|  0.00%|                logging.warning(f'Overriding {name} from command line')
   131|         0|            0|            0|  0.00%|                config[name] = value
   132|         0|            0|            0|  0.00%|
   133|         0|            0|            0|  0.00%|    # These always get overridden from the command line
   134|         0|            0|            0|  0.00%|    config['seed'] = args.seed
   135|         0|            0|            0|  0.00%|    config['total_timesteps'] = args.total_timesteps
   136|         0|            0|            0|  0.00%|    config['use_wandb'] = args.use_wandb
   137|         0|            0|            0|  0.00%|    if hasattr(args, 'potential_function') and args.potential_function is not None:
   138|         0|            0|            0|  0.00%|        logging.warning(f'Overriding potential function from command line to {args.potential_function}')
   139|         0|            0|            0|  0.00%|        config['potential_function'] = args.potential_function
   140|         0|            0|            0|  0.00%|
   141|         0|            0|            0|  0.00%|class UBCChanceEventSampler(object):
   142|         0|            0|            0|  0.00%|    """Default sampler for external chance events."""
   143|         0|            0|            0|  0.00%|
   144|         0|            0|            0|  0.00%|    def __init__(self, seed=None) -> None:
   145|         0|            0|            0|  0.00%|        self.seed(seed)
   146|         0|            0|            0|  0.00%|
   147|         0|            0|            0|  0.00%|    def seed(self, seed=None):
   148|         0|            0|            0|  0.00%|        self._rng = np.random.RandomState(seed)
   149|         0|            0|            0|  0.00%|
   150|      5892|    0.0122328|  2.07617e-06|  0.01%|    def __call__(self, state):
   151|         0|            0|            0|  0.00%|        """Sample a chance event in the given state."""
   152|      5892|    0.0534739|  9.07569e-06|  0.05%|        actions, probs = zip(*state.chance_outcomes())
(call)|      5892|     0.177771|  3.01716e-05|  0.17%|# /apps/open_spiel/open_spiel/python/games/clock_auction.py:509 chance_outcomes
   153|      5892|    0.0418904|  7.10971e-06|  0.04%|        return fast_choice(actions, probs, rng=self._rng)
(call)|      5892|     0.869539|   0.00014758|  0.83%|# /apps/open_spiel/open_spiel/python/examples/ubc_math_utils.py:4 fast_choice
   154|         0|            0|            0|  0.00%|
   155|         0|            0|            0|  0.00%|
   156|         0|            0|            0|  0.00%|def series_to_quantiles(s: pd.Series):
   157|         0|            0|            0|  0.00%|    quantiles = []
   158|         0|            0|            0|  0.00%|    for quantile in np.arange(0, 1.01, 0.01):
   159|         0|            0|            0|  0.00%|        quantiles.append(s.quantile(quantile)) # TODO: Think about what interpolation method you want to use
   160|         0|            0|            0|  0.00%|    return quantiles
   161|         0|            0|            0|  0.00%|
   162|         0|            0|            0|  0.00%|def config_path_from_config_name(config_name):
   163|         0|            0|            0|  0.00%|    return f'{CONFIG_ROOT}/{config_name}.yml'
   164|         0|            0|            0|  0.00%|
   165|         0|            0|            0|  0.00%|def safe_config_name(name):
   166|         0|            0|            0|  0.00%|    return name.replace("/", "").replace('.yml', '')
   167|         0|            0|            0|  0.00%|
   168|         0|            0|            0|  0.00%|def num_to_letter(i):
   169|         0|            0|            0|  0.00%|    '''Maps 0 to A, 1 to B etc.'''
   170|         0|            0|            0|  0.00%|    return chr(ord('@')+i+1)
   171|         0|            0|            0|  0.00%|
   172|         0|            0|            0|  0.00%|def players_not_me(my_player_id, num_players):
   173|         0|            0|            0|  0.00%|    for i in range(num_players):
   174|         0|            0|            0|  0.00%|        if i == my_player_id:
   175|         0|            0|            0|  0.00%|            continue
   176|         0|            0|            0|  0.00%|        yield i
File: <string>_0
File duration: 0.0727186s (0.07%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|     36864|    0.0727186|  1.97262e-06|  0.07%|
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/functional.py
File duration: 0.069253s (0.07%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|r"""Functional interface"""
     2|         0|            0|            0|  0.00%|from typing import Callable, List, Optional, Tuple, Union
     3|         0|            0|            0|  0.00%|import math
     4|         0|            0|            0|  0.00%|import warnings
     5|         0|            0|            0|  0.00%|
     6|         0|            0|            0|  0.00%|import torch
     7|         0|            0|            0|  0.00%|from torch import _VF
     8|         0|            0|            0|  0.00%|from torch._C import _infer_size, _add_docstr
     9|         0|            0|            0|  0.00%|from torch._torch_docs import reproducibility_notes, tf32_notes
    10|         0|            0|            0|  0.00%|# A workaround to support both TorchScript and MyPy:
    11|         0|            0|            0|  0.00%|from typing import TYPE_CHECKING
    12|         0|            0|            0|  0.00%|if TYPE_CHECKING:
    13|         0|            0|            0|  0.00%|    from torch.types import _dtype as DType
    14|         0|            0|            0|  0.00%|else:
    15|         0|            0|            0|  0.00%|    # The JIT doesn't understand Union, nor torch.dtype here
    16|         0|            0|            0|  0.00%|    DType = int
    17|         0|            0|            0|  0.00%|
    18|         0|            0|            0|  0.00%|from .._jit_internal import boolean_dispatch, _overload, BroadcastingList1, BroadcastingList2, BroadcastingList3
    19|         0|            0|            0|  0.00%|from ..overrides import (
    20|         0|            0|            0|  0.00%|    has_torch_function, has_torch_function_unary, has_torch_function_variadic,
    21|         0|            0|            0|  0.00%|    handle_torch_function)
    22|         0|            0|            0|  0.00%|from . import _reduction as _Reduction
    23|         0|            0|            0|  0.00%|from . import grad  # noqa: F401
    24|         0|            0|            0|  0.00%|from .modules import utils
    25|         0|            0|            0|  0.00%|from .modules.utils import _single, _pair, _triple, _list_with_default
    26|         0|            0|            0|  0.00%|
    27|         0|            0|            0|  0.00%|
    28|         0|            0|            0|  0.00%|Tensor = torch.Tensor
    29|         0|            0|            0|  0.00%|
    30|         0|            0|            0|  0.00%|conv1d = _add_docstr(
    31|         0|            0|            0|  0.00%|    torch.conv1d,
    32|         0|            0|            0|  0.00%|    r"""
    33|         0|            0|            0|  0.00%|conv1d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -> Tensor
    34|         0|            0|            0|  0.00%|
    35|         0|            0|            0|  0.00%|Applies a 1D convolution over an input signal composed of several input
    36|         0|            0|            0|  0.00%|planes.
    37|         0|            0|            0|  0.00%|
    38|         0|            0|            0|  0.00%|{tf32_note}
    39|         0|            0|            0|  0.00%|
    40|         0|            0|            0|  0.00%|See :class:`~torch.nn.Conv1d` for details and output shape.
    41|         0|            0|            0|  0.00%|
    42|         0|            0|            0|  0.00%|Note:
    43|         0|            0|            0|  0.00%|    {cudnn_reproducibility_note}
    44|         0|            0|            0|  0.00%|
    45|         0|            0|            0|  0.00%|Note:
    46|         0|            0|            0|  0.00%|    This operator supports complex data types i.e. ``complex32, complex64, complex128``.
    47|         0|            0|            0|  0.00%|""".format(
    48|         0|            0|            0|  0.00%|        **reproducibility_notes, **tf32_notes
    49|         0|            0|            0|  0.00%|    )
    50|         0|            0|            0|  0.00%|    + r"""
    51|         0|            0|            0|  0.00%|
    52|         0|            0|            0|  0.00%|Args:
    53|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\text{minibatch} , \text{in\_channels} , iW)`
    54|         0|            0|            0|  0.00%|    weight: filters of shape :math:`(\text{out\_channels} , \frac{\text{in\_channels}}{\text{groups}} , kW)`
    55|         0|            0|            0|  0.00%|    bias: optional bias of shape :math:`(\text{out\_channels})`. Default: ``None``
    56|         0|            0|            0|  0.00%|    stride: the stride of the convolving kernel. Can be a single number or
    57|         0|            0|            0|  0.00%|      a one-element tuple `(sW,)`. Default: 1
    58|         0|            0|            0|  0.00%|    padding: implicit paddings on both sides of the input. Can be a string {'valid', 'same'},
    59|         0|            0|            0|  0.00%|      single number or a one-element tuple `(padW,)`. Default: 0
    60|         0|            0|            0|  0.00%|      ``padding='valid'`` is the same as no padding. ``padding='same'`` pads
    61|         0|            0|            0|  0.00%|      the input so the output has the same shape as the input. However, this mode
    62|         0|            0|            0|  0.00%|      doesn't support any stride values other than 1.
    63|         0|            0|            0|  0.00%|
    64|         0|            0|            0|  0.00%|      .. warning::
    65|         0|            0|            0|  0.00%|          For ``padding='same'``, if the ``weight`` is even-length and
    66|         0|            0|            0|  0.00%|          ``dilation`` is odd in any dimension, a full :func:`pad` operation
    67|         0|            0|            0|  0.00%|          may be needed internally. Lowering performance.
    68|         0|            0|            0|  0.00%|    dilation: the spacing between kernel elements. Can be a single number or
    69|         0|            0|            0|  0.00%|      a one-element tuple `(dW,)`. Default: 1
    70|         0|            0|            0|  0.00%|    groups: split input into groups, :math:`\text{in\_channels}` should be divisible by
    71|         0|            0|            0|  0.00%|      the number of groups. Default: 1
    72|         0|            0|            0|  0.00%|
    73|         0|            0|            0|  0.00%|Examples::
    74|         0|            0|            0|  0.00%|
    75|         0|            0|            0|  0.00%|    >>> inputs = torch.randn(33, 16, 30)
    76|         0|            0|            0|  0.00%|    >>> filters = torch.randn(20, 16, 5)
    77|         0|            0|            0|  0.00%|    >>> F.conv1d(inputs, filters)
    78|         0|            0|            0|  0.00%|""",
    79|         0|            0|            0|  0.00%|)
    80|         0|            0|            0|  0.00%|
    81|         0|            0|            0|  0.00%|conv2d = _add_docstr(
    82|         0|            0|            0|  0.00%|    torch.conv2d,
    83|         0|            0|            0|  0.00%|    r"""
    84|         0|            0|            0|  0.00%|conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -> Tensor
    85|         0|            0|            0|  0.00%|
    86|         0|            0|            0|  0.00%|Applies a 2D convolution over an input image composed of several input
    87|         0|            0|            0|  0.00%|planes.
    88|         0|            0|            0|  0.00%|
    89|         0|            0|            0|  0.00%|{tf32_note}
    90|         0|            0|            0|  0.00%|
    91|         0|            0|            0|  0.00%|See :class:`~torch.nn.Conv2d` for details and output shape.
    92|         0|            0|            0|  0.00%|
    93|         0|            0|            0|  0.00%|Note:
    94|         0|            0|            0|  0.00%|    {cudnn_reproducibility_note}
    95|         0|            0|            0|  0.00%|
    96|         0|            0|            0|  0.00%|Note:
    97|         0|            0|            0|  0.00%|    This operator supports complex data types i.e. ``complex32, complex64, complex128``.
    98|         0|            0|            0|  0.00%|""".format(
    99|         0|            0|            0|  0.00%|        **reproducibility_notes, **tf32_notes
   100|         0|            0|            0|  0.00%|    )
   101|         0|            0|            0|  0.00%|    + r"""
   102|         0|            0|            0|  0.00%|
   103|         0|            0|            0|  0.00%|Args:
   104|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\text{minibatch} , \text{in\_channels} , iH , iW)`
   105|         0|            0|            0|  0.00%|    weight: filters of shape :math:`(\text{out\_channels} , \frac{\text{in\_channels}}{\text{groups}} , kH , kW)`
   106|         0|            0|            0|  0.00%|    bias: optional bias tensor of shape :math:`(\text{out\_channels})`. Default: ``None``
   107|         0|            0|            0|  0.00%|    stride: the stride of the convolving kernel. Can be a single number or a
   108|         0|            0|            0|  0.00%|      tuple `(sH, sW)`. Default: 1
   109|         0|            0|            0|  0.00%|    padding: implicit paddings on both sides of the input. Can be a string {'valid', 'same'},
   110|         0|            0|            0|  0.00%|      single number or a tuple `(padH, padW)`. Default: 0
   111|         0|            0|            0|  0.00%|      ``padding='valid'`` is the same as no padding. ``padding='same'`` pads
   112|         0|            0|            0|  0.00%|      the input so the output has the same shape as the input. However, this mode
   113|         0|            0|            0|  0.00%|      doesn't support any stride values other than 1.
   114|         0|            0|            0|  0.00%|
   115|         0|            0|            0|  0.00%|      .. warning::
   116|         0|            0|            0|  0.00%|          For ``padding='same'``, if the ``weight`` is even-length and
   117|         0|            0|            0|  0.00%|          ``dilation`` is odd in any dimension, a full :func:`pad` operation
   118|         0|            0|            0|  0.00%|          may be needed internally. Lowering performance.
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|    dilation: the spacing between kernel elements. Can be a single number or
   121|         0|            0|            0|  0.00%|      a tuple `(dH, dW)`. Default: 1
   122|         0|            0|            0|  0.00%|    groups: split input into groups, :math:`\text{in\_channels}` should be divisible by the
   123|         0|            0|            0|  0.00%|      number of groups. Default: 1
   124|         0|            0|            0|  0.00%|
   125|         0|            0|            0|  0.00%|Examples::
   126|         0|            0|            0|  0.00%|
   127|         0|            0|            0|  0.00%|    >>> # With square kernels and equal stride
   128|         0|            0|            0|  0.00%|    >>> filters = torch.randn(8, 4, 3, 3)
   129|         0|            0|            0|  0.00%|    >>> inputs = torch.randn(1, 4, 5, 5)
   130|         0|            0|            0|  0.00%|    >>> F.conv2d(inputs, filters, padding=1)
   131|         0|            0|            0|  0.00%|""",
   132|         0|            0|            0|  0.00%|)  # noqa: E501
   133|         0|            0|            0|  0.00%|
   134|         0|            0|            0|  0.00%|conv3d = _add_docstr(
   135|         0|            0|            0|  0.00%|    torch.conv3d,
   136|         0|            0|            0|  0.00%|    r"""
   137|         0|            0|            0|  0.00%|conv3d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -> Tensor
   138|         0|            0|            0|  0.00%|
   139|         0|            0|            0|  0.00%|Applies a 3D convolution over an input image composed of several input
   140|         0|            0|            0|  0.00%|planes.
   141|         0|            0|            0|  0.00%|
   142|         0|            0|            0|  0.00%|{tf32_note}
   143|         0|            0|            0|  0.00%|
   144|         0|            0|            0|  0.00%|See :class:`~torch.nn.Conv3d` for details and output shape.
   145|         0|            0|            0|  0.00%|
   146|         0|            0|            0|  0.00%|Note:
   147|         0|            0|            0|  0.00%|    {cudnn_reproducibility_note}
   148|         0|            0|            0|  0.00%|
   149|         0|            0|            0|  0.00%|Note:
   150|         0|            0|            0|  0.00%|    This operator supports complex data types i.e. ``complex32, complex64, complex128``.
   151|         0|            0|            0|  0.00%|""".format(
   152|         0|            0|            0|  0.00%|        **reproducibility_notes, **tf32_notes
   153|         0|            0|            0|  0.00%|    )
   154|         0|            0|            0|  0.00%|    + r"""
   155|         0|            0|            0|  0.00%|
   156|         0|            0|            0|  0.00%|Args:
   157|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\text{minibatch} , \text{in\_channels} , iT , iH , iW)`
   158|         0|            0|            0|  0.00%|    weight: filters of shape :math:`(\text{out\_channels} , \frac{\text{in\_channels}}{\text{groups}} , kT , kH , kW)`
   159|         0|            0|            0|  0.00%|    bias: optional bias tensor of shape :math:`(\text{out\_channels})`. Default: None
   160|         0|            0|            0|  0.00%|    stride: the stride of the convolving kernel. Can be a single number or a
   161|         0|            0|            0|  0.00%|      tuple `(sT, sH, sW)`. Default: 1
   162|         0|            0|            0|  0.00%|    padding: implicit paddings on both sides of the input. Can be a string {'valid', 'same'},
   163|         0|            0|            0|  0.00%|      single number or a tuple `(padT, padH, padW)`. Default: 0
   164|         0|            0|            0|  0.00%|      ``padding='valid'`` is the same as no padding. ``padding='same'`` pads
   165|         0|            0|            0|  0.00%|      the input so the output has the same shape as the input. However, this mode
   166|         0|            0|            0|  0.00%|      doesn't support any stride values other than 1.
   167|         0|            0|            0|  0.00%|
   168|         0|            0|            0|  0.00%|      .. warning::
   169|         0|            0|            0|  0.00%|          For ``padding='same'``, if the ``weight`` is even-length and
   170|         0|            0|            0|  0.00%|          ``dilation`` is odd in any dimension, a full :func:`pad` operation
   171|         0|            0|            0|  0.00%|          may be needed internally. Lowering performance.
   172|         0|            0|            0|  0.00%|
   173|         0|            0|            0|  0.00%|    dilation: the spacing between kernel elements. Can be a single number or
   174|         0|            0|            0|  0.00%|      a tuple `(dT, dH, dW)`. Default: 1
   175|         0|            0|            0|  0.00%|    groups: split input into groups, :math:`\text{in\_channels}` should be divisible by
   176|         0|            0|            0|  0.00%|      the number of groups. Default: 1
   177|         0|            0|            0|  0.00%|
   178|         0|            0|            0|  0.00%|Examples::
   179|         0|            0|            0|  0.00%|
   180|         0|            0|            0|  0.00%|    >>> filters = torch.randn(33, 16, 3, 3, 3)
   181|         0|            0|            0|  0.00%|    >>> inputs = torch.randn(20, 16, 50, 10, 20)
   182|         0|            0|            0|  0.00%|    >>> F.conv3d(inputs, filters)
   183|         0|            0|            0|  0.00%|""",
   184|         0|            0|            0|  0.00%|)  # noqa: E501
   185|         0|            0|            0|  0.00%|
   186|         0|            0|            0|  0.00%|conv_transpose1d = _add_docstr(
   187|         0|            0|            0|  0.00%|    torch.conv_transpose1d,
   188|         0|            0|            0|  0.00%|    r"""
   189|         0|            0|            0|  0.00%|conv_transpose1d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor
   190|         0|            0|            0|  0.00%|
   191|         0|            0|            0|  0.00%|Applies a 1D transposed convolution operator over an input signal
   192|         0|            0|            0|  0.00%|composed of several input planes, sometimes also called "deconvolution".
   193|         0|            0|            0|  0.00%|
   194|         0|            0|            0|  0.00%|{tf32_note}
   195|         0|            0|            0|  0.00%|
   196|         0|            0|            0|  0.00%|See :class:`~torch.nn.ConvTranspose1d` for details and output shape.
   197|         0|            0|            0|  0.00%|
   198|         0|            0|            0|  0.00%|Note:
   199|         0|            0|            0|  0.00%|    {cudnn_reproducibility_note}
   200|         0|            0|            0|  0.00%|""".format(
   201|         0|            0|            0|  0.00%|        **reproducibility_notes, **tf32_notes
   202|         0|            0|            0|  0.00%|    )
   203|         0|            0|            0|  0.00%|    + r"""
   204|         0|            0|            0|  0.00%|
   205|         0|            0|            0|  0.00%|Args:
   206|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\text{minibatch} , \text{in\_channels} , iW)`
   207|         0|            0|            0|  0.00%|    weight: filters of shape :math:`(\text{in\_channels} , \frac{\text{out\_channels}}{\text{groups}} , kW)`
   208|         0|            0|            0|  0.00%|    bias: optional bias of shape :math:`(\text{out\_channels})`. Default: None
   209|         0|            0|            0|  0.00%|    stride: the stride of the convolving kernel. Can be a single number or a
   210|         0|            0|            0|  0.00%|      tuple ``(sW,)``. Default: 1
   211|         0|            0|            0|  0.00%|    padding: ``dilation * (kernel_size - 1) - padding`` zero-padding will be added to both
   212|         0|            0|            0|  0.00%|      sides of each dimension in the input. Can be a single number or a tuple
   213|         0|            0|            0|  0.00%|      ``(padW,)``. Default: 0
   214|         0|            0|            0|  0.00%|    output_padding: additional size added to one side of each dimension in the
   215|         0|            0|            0|  0.00%|      output shape. Can be a single number or a tuple ``(out_padW)``. Default: 0
   216|         0|            0|            0|  0.00%|    groups: split input into groups, :math:`\text{in\_channels}` should be divisible by the
   217|         0|            0|            0|  0.00%|      number of groups. Default: 1
   218|         0|            0|            0|  0.00%|    dilation: the spacing between kernel elements. Can be a single number or
   219|         0|            0|            0|  0.00%|      a tuple ``(dW,)``. Default: 1
   220|         0|            0|            0|  0.00%|
   221|         0|            0|            0|  0.00%|Examples::
   222|         0|            0|            0|  0.00%|
   223|         0|            0|            0|  0.00%|    >>> inputs = torch.randn(20, 16, 50)
   224|         0|            0|            0|  0.00%|    >>> weights = torch.randn(16, 33, 5)
   225|         0|            0|            0|  0.00%|    >>> F.conv_transpose1d(inputs, weights)
   226|         0|            0|            0|  0.00%|""",
   227|         0|            0|            0|  0.00%|)
   228|         0|            0|            0|  0.00%|
   229|         0|            0|            0|  0.00%|conv_transpose2d = _add_docstr(
   230|         0|            0|            0|  0.00%|    torch.conv_transpose2d,
   231|         0|            0|            0|  0.00%|    r"""
   232|         0|            0|            0|  0.00%|conv_transpose2d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor
   233|         0|            0|            0|  0.00%|
   234|         0|            0|            0|  0.00%|Applies a 2D transposed convolution operator over an input image
   235|         0|            0|            0|  0.00%|composed of several input planes, sometimes also called "deconvolution".
   236|         0|            0|            0|  0.00%|
   237|         0|            0|            0|  0.00%|{tf32_note}
   238|         0|            0|            0|  0.00%|
   239|         0|            0|            0|  0.00%|See :class:`~torch.nn.ConvTranspose2d` for details and output shape.
   240|         0|            0|            0|  0.00%|
   241|         0|            0|            0|  0.00%|Note:
   242|         0|            0|            0|  0.00%|    {cudnn_reproducibility_note}
   243|         0|            0|            0|  0.00%|""".format(
   244|         0|            0|            0|  0.00%|        **reproducibility_notes, **tf32_notes
   245|         0|            0|            0|  0.00%|    )
   246|         0|            0|            0|  0.00%|    + r"""
   247|         0|            0|            0|  0.00%|
   248|         0|            0|            0|  0.00%|Args:
   249|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\text{minibatch} , \text{in\_channels} , iH , iW)`
   250|         0|            0|            0|  0.00%|    weight: filters of shape :math:`(\text{in\_channels} , \frac{\text{out\_channels}}{\text{groups}} , kH , kW)`
   251|         0|            0|            0|  0.00%|    bias: optional bias of shape :math:`(\text{out\_channels})`. Default: None
   252|         0|            0|            0|  0.00%|    stride: the stride of the convolving kernel. Can be a single number or a
   253|         0|            0|            0|  0.00%|      tuple ``(sH, sW)``. Default: 1
   254|         0|            0|            0|  0.00%|    padding: ``dilation * (kernel_size - 1) - padding`` zero-padding will be added to both
   255|         0|            0|            0|  0.00%|      sides of each dimension in the input. Can be a single number or a tuple
   256|         0|            0|            0|  0.00%|      ``(padH, padW)``. Default: 0
   257|         0|            0|            0|  0.00%|    output_padding: additional size added to one side of each dimension in the
   258|         0|            0|            0|  0.00%|      output shape. Can be a single number or a tuple ``(out_padH, out_padW)``.
   259|         0|            0|            0|  0.00%|      Default: 0
   260|         0|            0|            0|  0.00%|    groups: split input into groups, :math:`\text{in\_channels}` should be divisible by the
   261|         0|            0|            0|  0.00%|      number of groups. Default: 1
   262|         0|            0|            0|  0.00%|    dilation: the spacing between kernel elements. Can be a single number or
   263|         0|            0|            0|  0.00%|      a tuple ``(dH, dW)``. Default: 1
   264|         0|            0|            0|  0.00%|
   265|         0|            0|            0|  0.00%|Examples::
   266|         0|            0|            0|  0.00%|
   267|         0|            0|            0|  0.00%|    >>> # With square kernels and equal stride
   268|         0|            0|            0|  0.00%|    >>> inputs = torch.randn(1, 4, 5, 5)
   269|         0|            0|            0|  0.00%|    >>> weights = torch.randn(4, 8, 3, 3)
   270|         0|            0|            0|  0.00%|    >>> F.conv_transpose2d(inputs, weights, padding=1)
   271|         0|            0|            0|  0.00%|""",
   272|         0|            0|            0|  0.00%|)  # noqa: E501
   273|         0|            0|            0|  0.00%|
   274|         0|            0|            0|  0.00%|conv_transpose3d = _add_docstr(
   275|         0|            0|            0|  0.00%|    torch.conv_transpose3d,
   276|         0|            0|            0|  0.00%|    r"""
   277|         0|            0|            0|  0.00%|conv_transpose3d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor
   278|         0|            0|            0|  0.00%|
   279|         0|            0|            0|  0.00%|Applies a 3D transposed convolution operator over an input image
   280|         0|            0|            0|  0.00%|composed of several input planes, sometimes also called "deconvolution"
   281|         0|            0|            0|  0.00%|
   282|         0|            0|            0|  0.00%|{tf32_note}
   283|         0|            0|            0|  0.00%|
   284|         0|            0|            0|  0.00%|See :class:`~torch.nn.ConvTranspose3d` for details and output shape.
   285|         0|            0|            0|  0.00%|
   286|         0|            0|            0|  0.00%|Note:
   287|         0|            0|            0|  0.00%|    {cudnn_reproducibility_note}
   288|         0|            0|            0|  0.00%|""".format(
   289|         0|            0|            0|  0.00%|        **reproducibility_notes, **tf32_notes
   290|         0|            0|            0|  0.00%|    )
   291|         0|            0|            0|  0.00%|    + r"""
   292|         0|            0|            0|  0.00%|
   293|         0|            0|            0|  0.00%|Args:
   294|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\text{minibatch} , \text{in\_channels} , iT , iH , iW)`
   295|         0|            0|            0|  0.00%|    weight: filters of shape :math:`(\text{in\_channels} , \frac{\text{out\_channels}}{\text{groups}} , kT , kH , kW)`
   296|         0|            0|            0|  0.00%|    bias: optional bias of shape :math:`(\text{out\_channels})`. Default: None
   297|         0|            0|            0|  0.00%|    stride: the stride of the convolving kernel. Can be a single number or a
   298|         0|            0|            0|  0.00%|      tuple ``(sT, sH, sW)``. Default: 1
   299|         0|            0|            0|  0.00%|    padding: ``dilation * (kernel_size - 1) - padding`` zero-padding will be added to both
   300|         0|            0|            0|  0.00%|      sides of each dimension in the input. Can be a single number or a tuple
   301|         0|            0|            0|  0.00%|      ``(padT, padH, padW)``. Default: 0
   302|         0|            0|            0|  0.00%|    output_padding: additional size added to one side of each dimension in the
   303|         0|            0|            0|  0.00%|      output shape. Can be a single number or a tuple
   304|         0|            0|            0|  0.00%|      ``(out_padT, out_padH, out_padW)``. Default: 0
   305|         0|            0|            0|  0.00%|    groups: split input into groups, :math:`\text{in\_channels}` should be divisible by the
   306|         0|            0|            0|  0.00%|      number of groups. Default: 1
   307|         0|            0|            0|  0.00%|    dilation: the spacing between kernel elements. Can be a single number or
   308|         0|            0|            0|  0.00%|      a tuple `(dT, dH, dW)`. Default: 1
   309|         0|            0|            0|  0.00%|
   310|         0|            0|            0|  0.00%|Examples::
   311|         0|            0|            0|  0.00%|
   312|         0|            0|            0|  0.00%|    >>> inputs = torch.randn(20, 16, 50, 10, 20)
   313|         0|            0|            0|  0.00%|    >>> weights = torch.randn(16, 33, 3, 3, 3)
   314|         0|            0|            0|  0.00%|    >>> F.conv_transpose3d(inputs, weights)
   315|         0|            0|            0|  0.00%|""",
   316|         0|            0|            0|  0.00%|)  # noqa: E501
   317|         0|            0|            0|  0.00%|
   318|         0|            0|            0|  0.00%|conv_tbc = _add_docstr(
   319|         0|            0|            0|  0.00%|    torch.conv_tbc,
   320|         0|            0|            0|  0.00%|    r"""
   321|         0|            0|            0|  0.00%|Applies a 1-dimensional sequence convolution over an input sequence.
   322|         0|            0|            0|  0.00%|Input and output dimensions are (Time, Batch, Channels) - hence TBC.
   323|         0|            0|            0|  0.00%|
   324|         0|            0|            0|  0.00%|Args:
   325|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\text{sequence length} \times batch \times \text{in\_channels})`
   326|         0|            0|            0|  0.00%|    weight: filter of shape (:math:`\text{kernel width} \times \text{in\_channels} \times \text{out\_channels}`)
   327|         0|            0|            0|  0.00%|    bias: bias of shape (:math:`\text{out\_channels}`)
   328|         0|            0|            0|  0.00%|    pad: number of timesteps to pad. Default: 0
   329|         0|            0|            0|  0.00%|""",
   330|         0|            0|            0|  0.00%|)
   331|         0|            0|            0|  0.00%|
   332|         0|            0|            0|  0.00%|
   333|         0|            0|            0|  0.00%|# Pooling
   334|         0|            0|            0|  0.00%|avg_pool1d = _add_docstr(
   335|         0|            0|            0|  0.00%|    torch.avg_pool1d,
   336|         0|            0|            0|  0.00%|    r"""
   337|         0|            0|            0|  0.00%|avg_pool1d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True) -> Tensor
   338|         0|            0|            0|  0.00%|
   339|         0|            0|            0|  0.00%|Applies a 1D average pooling over an input signal composed of several
   340|         0|            0|            0|  0.00%|input planes.
   341|         0|            0|            0|  0.00%|
   342|         0|            0|            0|  0.00%|See :class:`~torch.nn.AvgPool1d` for details and output shape.
   343|         0|            0|            0|  0.00%|
   344|         0|            0|            0|  0.00%|Args:
   345|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\text{minibatch} , \text{in\_channels} , iW)`
   346|         0|            0|            0|  0.00%|    kernel_size: the size of the window. Can be a single number or a
   347|         0|            0|            0|  0.00%|      tuple `(kW,)`
   348|         0|            0|            0|  0.00%|    stride: the stride of the window. Can be a single number or a tuple
   349|         0|            0|            0|  0.00%|      `(sW,)`. Default: :attr:`kernel_size`
   350|         0|            0|            0|  0.00%|    padding: implicit zero paddings on both sides of the input. Can be a
   351|         0|            0|            0|  0.00%|      single number or a tuple `(padW,)`. Default: 0
   352|         0|            0|            0|  0.00%|    ceil_mode: when True, will use `ceil` instead of `floor` to compute the
   353|         0|            0|            0|  0.00%|        output shape. Default: ``False``
   354|         0|            0|            0|  0.00%|    count_include_pad: when True, will include the zero-padding in the
   355|         0|            0|            0|  0.00%|        averaging calculation. Default: ``True``
   356|         0|            0|            0|  0.00%|
   357|         0|            0|            0|  0.00%|Examples::
   358|         0|            0|            0|  0.00%|
   359|         0|            0|            0|  0.00%|    >>> # pool of square window of size=3, stride=2
   360|         0|            0|            0|  0.00%|    >>> input = torch.tensor([[[1, 2, 3, 4, 5, 6, 7]]], dtype=torch.float32)
   361|         0|            0|            0|  0.00%|    >>> F.avg_pool1d(input, kernel_size=3, stride=2)
   362|         0|            0|            0|  0.00%|    tensor([[[ 2.,  4.,  6.]]])
   363|         0|            0|            0|  0.00%|
   364|         0|            0|            0|  0.00%|""",
   365|         0|            0|            0|  0.00%|)
   366|         0|            0|            0|  0.00%|
   367|         0|            0|            0|  0.00%|
   368|         0|            0|            0|  0.00%|avg_pool2d = _add_docstr(
   369|         0|            0|            0|  0.00%|    torch._C._nn.avg_pool2d,
   370|         0|            0|            0|  0.00%|    r"""
   371|         0|            0|            0|  0.00%|avg_pool2d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None) -> Tensor
   372|         0|            0|            0|  0.00%|
   373|         0|            0|            0|  0.00%|Applies 2D average-pooling operation in :math:`kH \times kW` regions by step size
   374|         0|            0|            0|  0.00%|:math:`sH \times sW` steps. The number of output features is equal to the number of
   375|         0|            0|            0|  0.00%|input planes.
   376|         0|            0|            0|  0.00%|
   377|         0|            0|            0|  0.00%|See :class:`~torch.nn.AvgPool2d` for details and output shape.
   378|         0|            0|            0|  0.00%|
   379|         0|            0|            0|  0.00%|Args:
   380|         0|            0|            0|  0.00%|    input: input tensor :math:`(\text{minibatch} , \text{in\_channels} , iH , iW)`
   381|         0|            0|            0|  0.00%|    kernel_size: size of the pooling region. Can be a single number or a
   382|         0|            0|            0|  0.00%|      tuple `(kH, kW)`
   383|         0|            0|            0|  0.00%|    stride: stride of the pooling operation. Can be a single number or a
   384|         0|            0|            0|  0.00%|      tuple `(sH, sW)`. Default: :attr:`kernel_size`
   385|         0|            0|            0|  0.00%|    padding: implicit zero paddings on both sides of the input. Can be a
   386|         0|            0|            0|  0.00%|      single number or a tuple `(padH, padW)`. Default: 0
   387|         0|            0|            0|  0.00%|    ceil_mode: when True, will use `ceil` instead of `floor` in the formula
   388|         0|            0|            0|  0.00%|        to compute the output shape. Default: ``False``
   389|         0|            0|            0|  0.00%|    count_include_pad: when True, will include the zero-padding in the
   390|         0|            0|            0|  0.00%|        averaging calculation. Default: ``True``
   391|         0|            0|            0|  0.00%|    divisor_override: if specified, it will be used as divisor, otherwise
   392|         0|            0|            0|  0.00%|         size of the pooling region will be used. Default: None
   393|         0|            0|            0|  0.00%|""",
   394|         0|            0|            0|  0.00%|)
   395|         0|            0|            0|  0.00%|
   396|         0|            0|            0|  0.00%|avg_pool3d = _add_docstr(
   397|         0|            0|            0|  0.00%|    torch._C._nn.avg_pool3d,
   398|         0|            0|            0|  0.00%|    r"""
   399|         0|            0|            0|  0.00%|avg_pool3d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None) -> Tensor
   400|         0|            0|            0|  0.00%|
   401|         0|            0|            0|  0.00%|Applies 3D average-pooling operation in :math:`kT \times kH \times kW` regions by step
   402|         0|            0|            0|  0.00%|size :math:`sT \times sH \times sW` steps. The number of output features is equal to
   403|         0|            0|            0|  0.00%|:math:`\lfloor\frac{\text{input planes}}{sT}\rfloor`.
   404|         0|            0|            0|  0.00%|
   405|         0|            0|            0|  0.00%|See :class:`~torch.nn.AvgPool3d` for details and output shape.
   406|         0|            0|            0|  0.00%|
   407|         0|            0|            0|  0.00%|Args:
   408|         0|            0|            0|  0.00%|    input: input tensor :math:`(\text{minibatch} , \text{in\_channels} , iT \times iH , iW)`
   409|         0|            0|            0|  0.00%|    kernel_size: size of the pooling region. Can be a single number or a
   410|         0|            0|            0|  0.00%|      tuple `(kT, kH, kW)`
   411|         0|            0|            0|  0.00%|    stride: stride of the pooling operation. Can be a single number or a
   412|         0|            0|            0|  0.00%|      tuple `(sT, sH, sW)`. Default: :attr:`kernel_size`
   413|         0|            0|            0|  0.00%|    padding: implicit zero paddings on both sides of the input. Can be a
   414|         0|            0|            0|  0.00%|      single number or a tuple `(padT, padH, padW)`, Default: 0
   415|         0|            0|            0|  0.00%|    ceil_mode: when True, will use `ceil` instead of `floor` in the formula
   416|         0|            0|            0|  0.00%|        to compute the output shape
   417|         0|            0|            0|  0.00%|    count_include_pad: when True, will include the zero-padding in the
   418|         0|            0|            0|  0.00%|        averaging calculation
   419|         0|            0|            0|  0.00%|    divisor_override: if specified, it will be used as divisor, otherwise
   420|         0|            0|            0|  0.00%|        size of the pooling region will be used. Default: None
   421|         0|            0|            0|  0.00%|""",
   422|         0|            0|            0|  0.00%|)
   423|         0|            0|            0|  0.00%|
   424|         0|            0|            0|  0.00%|
   425|         0|            0|            0|  0.00%|def fractional_max_pool2d_with_indices(
   426|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList2[int],
   427|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList2[int]] = None,
   428|         0|            0|            0|  0.00%|    output_ratio: Optional[BroadcastingList2[float]] = None,
   429|         0|            0|            0|  0.00%|    return_indices: bool = False,
   430|         0|            0|            0|  0.00%|    _random_samples: Optional[Tensor] = None
   431|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:
   432|         0|            0|            0|  0.00%|    r"""Applies 2D fractional max pooling over an input signal composed of several input planes.
   433|         0|            0|            0|  0.00%|
   434|         0|            0|            0|  0.00%|    Fractional MaxPooling is described in detail in the paper `Fractional MaxPooling`_ by Ben Graham
   435|         0|            0|            0|  0.00%|
   436|         0|            0|            0|  0.00%|    The max-pooling operation is applied in :math:`kH \times kW` regions by a stochastic
   437|         0|            0|            0|  0.00%|    step size determined by the target output size.
   438|         0|            0|            0|  0.00%|    The number of output features is equal to the number of input planes.
   439|         0|            0|            0|  0.00%|
   440|         0|            0|            0|  0.00%|    Args:
   441|         0|            0|            0|  0.00%|        kernel_size: the size of the window to take a max over.
   442|         0|            0|            0|  0.00%|                     Can be a single number :math:`k` (for a square kernel of :math:`k \times k`)
   443|         0|            0|            0|  0.00%|                     or a tuple `(kH, kW)`
   444|         0|            0|            0|  0.00%|        output_size: the target output size of the image of the form :math:`oH \times oW`.
   445|         0|            0|            0|  0.00%|                     Can be a tuple `(oH, oW)` or a single number :math:`oH` for a square image :math:`oH \times oH`
   446|         0|            0|            0|  0.00%|        output_ratio: If one wants to have an output size as a ratio of the input size, this option can be given.
   447|         0|            0|            0|  0.00%|                      This has to be a number or tuple in the range (0, 1)
   448|         0|            0|            0|  0.00%|        return_indices: if ``True``, will return the indices along with the outputs.
   449|         0|            0|            0|  0.00%|                        Useful to pass to :func:`~torch.nn.functional.max_unpool2d`.
   450|         0|            0|            0|  0.00%|
   451|         0|            0|            0|  0.00%|    Examples::
   452|         0|            0|            0|  0.00%|        >>> input = torch.randn(20, 16, 50, 32)
   453|         0|            0|            0|  0.00%|        >>> # pool of square window of size=3, and target output size 13x12
   454|         0|            0|            0|  0.00%|        >>> F.fractional_max_pool2d(input, 3, output_size=(13, 12))
   455|         0|            0|            0|  0.00%|        >>> # pool of square window and target output size being half of input image size
   456|         0|            0|            0|  0.00%|        >>> F.fractional_max_pool2d(input, 3, output_ratio=(0.5, 0.5))
   457|         0|            0|            0|  0.00%|
   458|         0|            0|            0|  0.00%|    .. _Fractional MaxPooling:
   459|         0|            0|            0|  0.00%|        http://arxiv.org/abs/1412.6071
   460|         0|            0|            0|  0.00%|    """
   461|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, _random_samples):
   462|         0|            0|            0|  0.00%|        return handle_torch_function(
   463|         0|            0|            0|  0.00%|            fractional_max_pool2d_with_indices,
   464|         0|            0|            0|  0.00%|            (input, _random_samples),
   465|         0|            0|            0|  0.00%|            input,
   466|         0|            0|            0|  0.00%|            kernel_size,
   467|         0|            0|            0|  0.00%|            output_size=output_size,
   468|         0|            0|            0|  0.00%|            output_ratio=output_ratio,
   469|         0|            0|            0|  0.00%|            return_indices=return_indices,
   470|         0|            0|            0|  0.00%|            _random_samples=_random_samples,
   471|         0|            0|            0|  0.00%|        )
   472|         0|            0|            0|  0.00%|    if output_size is None and output_ratio is None:
   473|         0|            0|            0|  0.00%|        raise ValueError("fractional_max_pool2d requires specifying either " "an output_size or an output_ratio")
   474|         0|            0|            0|  0.00%|    if output_size is None:
   475|         0|            0|            0|  0.00%|        assert output_ratio is not None
   476|         0|            0|            0|  0.00%|        _output_ratio = _pair(output_ratio)
   477|         0|            0|            0|  0.00%|        output_size = [int(input.size(-2) * _output_ratio[0]), int(input.size(-1) * _output_ratio[1])]
   478|         0|            0|            0|  0.00%|
   479|         0|            0|            0|  0.00%|    if _random_samples is None:
   480|         0|            0|            0|  0.00%|        n_batch = 1 if input.dim() == 3 else input.size(0)
   481|         0|            0|            0|  0.00%|        _random_samples = torch.rand(n_batch, input.size(-3), 2, dtype=input.dtype, device=input.device)
   482|         0|            0|            0|  0.00%|    return torch._C._nn.fractional_max_pool2d(input, kernel_size, output_size, _random_samples)
   483|         0|            0|            0|  0.00%|
   484|         0|            0|            0|  0.00%|
   485|         0|            0|            0|  0.00%|def _fractional_max_pool2d(
   486|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList2[int],
   487|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList2[int]] = None,
   488|         0|            0|            0|  0.00%|    output_ratio: Optional[BroadcastingList2[float]] = None,
   489|         0|            0|            0|  0.00%|    return_indices: bool = False,
   490|         0|            0|            0|  0.00%|    _random_samples: Optional[Tensor] = None
   491|         0|            0|            0|  0.00%|) -> Tensor:
   492|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, _random_samples):
   493|         0|            0|            0|  0.00%|        return handle_torch_function(
   494|         0|            0|            0|  0.00%|            fractional_max_pool2d,
   495|         0|            0|            0|  0.00%|            (input, _random_samples),
   496|         0|            0|            0|  0.00%|            input,
   497|         0|            0|            0|  0.00%|            kernel_size,
   498|         0|            0|            0|  0.00%|            output_size=output_size,
   499|         0|            0|            0|  0.00%|            output_ratio=output_ratio,
   500|         0|            0|            0|  0.00%|            return_indices=return_indices,
   501|         0|            0|            0|  0.00%|            _random_samples=_random_samples,
   502|         0|            0|            0|  0.00%|        )
   503|         0|            0|            0|  0.00%|    return fractional_max_pool2d_with_indices(
   504|         0|            0|            0|  0.00%|        input, kernel_size, output_size, output_ratio, return_indices, _random_samples
   505|         0|            0|            0|  0.00%|    )[0]
   506|         0|            0|            0|  0.00%|
   507|         0|            0|            0|  0.00%|
   508|         0|            0|            0|  0.00%|fractional_max_pool2d = boolean_dispatch(
   509|         0|            0|            0|  0.00%|    arg_name="return_indices",
   510|         0|            0|            0|  0.00%|    arg_index=4,
   511|         0|            0|            0|  0.00%|    default=False,
   512|         0|            0|            0|  0.00%|    if_true=fractional_max_pool2d_with_indices,
   513|         0|            0|            0|  0.00%|    if_false=_fractional_max_pool2d,
   514|         0|            0|            0|  0.00%|    module_name=__name__,
   515|         0|            0|            0|  0.00%|    func_name="fractional_max_pool2d",
   516|         0|            0|            0|  0.00%|)
   517|         0|            0|            0|  0.00%|
   518|         0|            0|            0|  0.00%|
   519|         0|            0|            0|  0.00%|def fractional_max_pool3d_with_indices(
   520|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList3[int],
   521|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList3[int]] = None,
   522|         0|            0|            0|  0.00%|    output_ratio: Optional[BroadcastingList3[float]] = None,
   523|         0|            0|            0|  0.00%|    return_indices: bool = False,
   524|         0|            0|            0|  0.00%|    _random_samples: Optional[Tensor] = None
   525|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:
   526|         0|            0|            0|  0.00%|    r"""Applies 3D fractional max pooling over an input signal composed of several input planes.
   527|         0|            0|            0|  0.00%|
   528|         0|            0|            0|  0.00%|    Fractional MaxPooling is described in detail in the paper `Fractional MaxPooling`_ by Ben Graham
   529|         0|            0|            0|  0.00%|
   530|         0|            0|            0|  0.00%|    The max-pooling operation is applied in :math:`kT \times kH \times kW` regions by a stochastic
   531|         0|            0|            0|  0.00%|    step size determined by the target output size.
   532|         0|            0|            0|  0.00%|    The number of output features is equal to the number of input planes.
   533|         0|            0|            0|  0.00%|
   534|         0|            0|            0|  0.00%|    Args:
   535|         0|            0|            0|  0.00%|        kernel_size: the size of the window to take a max over.
   536|         0|            0|            0|  0.00%|                     Can be a single number :math:`k` (for a square kernel of :math:`k \times k \times k`)
   537|         0|            0|            0|  0.00%|                     or a tuple `(kT, kH, kW)`
   538|         0|            0|            0|  0.00%|        output_size: the target output size of the form :math:`oT \times oH \times oW`.
   539|         0|            0|            0|  0.00%|                     Can be a tuple `(oT, oH, oW)` or a single number :math:`oH` for a cubic output
   540|         0|            0|            0|  0.00%|                     :math:`oH \times oH \times oH`
   541|         0|            0|            0|  0.00%|        output_ratio: If one wants to have an output size as a ratio of the input size, this option can be given.
   542|         0|            0|            0|  0.00%|                      This has to be a number or tuple in the range (0, 1)
   543|         0|            0|            0|  0.00%|        return_indices: if ``True``, will return the indices along with the outputs.
   544|         0|            0|            0|  0.00%|                        Useful to pass to :func:`~torch.nn.functional.max_unpool3d`.
   545|         0|            0|            0|  0.00%|
   546|         0|            0|            0|  0.00%|    Shape:
   547|         0|            0|            0|  0.00%|        - Input: :math:`(N, C, T_{in}, H_{in}, W_{in})` or :math:`(C, T_{in}, H_{in}, W_{in})`.
   548|         0|            0|            0|  0.00%|        - Output: :math:`(N, C, T_{out}, H_{out}, W_{out})` or :math:`(C, T_{out}, H_{out}, W_{out})`, where
   549|         0|            0|            0|  0.00%|          :math:`(T_{out}, H_{out}, W_{out})=\text{output\_size}` or
   550|         0|            0|            0|  0.00%|          :math:`(T_{out}, H_{out}, W_{out})=\text{output\_ratio} \times (T_{in}, H_{in}, W_{in})`
   551|         0|            0|            0|  0.00%|
   552|         0|            0|            0|  0.00%|    Examples::
   553|         0|            0|            0|  0.00%|        >>> input = torch.randn(20, 16, 50, 32, 16)
   554|         0|            0|            0|  0.00%|        >>> # pool of cubic window of size=3, and target output size 13x12x11
   555|         0|            0|            0|  0.00%|        >>> F.fractional_max_pool3d(input, 3, output_size=(13, 12, 11))
   556|         0|            0|            0|  0.00%|        >>> # pool of cubic window and target output size being half of input size
   557|         0|            0|            0|  0.00%|        >>> F.fractional_max_pool3d(input, 3, output_ratio=(0.5, 0.5, 0.5))
   558|         0|            0|            0|  0.00%|
   559|         0|            0|            0|  0.00%|    .. _Fractional MaxPooling:
   560|         0|            0|            0|  0.00%|        http://arxiv.org/abs/1412.6071
   561|         0|            0|            0|  0.00%|    """
   562|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, _random_samples):
   563|         0|            0|            0|  0.00%|        return handle_torch_function(
   564|         0|            0|            0|  0.00%|            fractional_max_pool3d_with_indices,
   565|         0|            0|            0|  0.00%|            (input, _random_samples),
   566|         0|            0|            0|  0.00%|            input,
   567|         0|            0|            0|  0.00%|            kernel_size,
   568|         0|            0|            0|  0.00%|            output_size=output_size,
   569|         0|            0|            0|  0.00%|            output_ratio=output_ratio,
   570|         0|            0|            0|  0.00%|            return_indices=return_indices,
   571|         0|            0|            0|  0.00%|            _random_samples=_random_samples,
   572|         0|            0|            0|  0.00%|        )
   573|         0|            0|            0|  0.00%|    if output_size is None and output_ratio is None:
   574|         0|            0|            0|  0.00%|        raise ValueError("fractional_max_pool3d requires specifying either " "an output_size or an output_ratio")
   575|         0|            0|            0|  0.00%|    if output_size is None:
   576|         0|            0|            0|  0.00%|        assert output_ratio is not None
   577|         0|            0|            0|  0.00%|        _output_ratio = _triple(output_ratio)
   578|         0|            0|            0|  0.00%|        output_size = [
   579|         0|            0|            0|  0.00%|            int(input.size(-3) * _output_ratio[0]),
   580|         0|            0|            0|  0.00%|            int(input.size(-2) * _output_ratio[1]),
   581|         0|            0|            0|  0.00%|            int(input.size(-1) * _output_ratio[2]),
   582|         0|            0|            0|  0.00%|        ]
   583|         0|            0|            0|  0.00%|
   584|         0|            0|            0|  0.00%|    if _random_samples is None:
   585|         0|            0|            0|  0.00%|        n_batch = 1 if input.dim() == 4 else input.size(0)
   586|         0|            0|            0|  0.00%|        _random_samples = torch.rand(n_batch, input.size(-4), 3, dtype=input.dtype, device=input.device)
   587|         0|            0|            0|  0.00%|    return torch._C._nn.fractional_max_pool3d(input, kernel_size, output_size, _random_samples)
   588|         0|            0|            0|  0.00%|
   589|         0|            0|            0|  0.00%|
   590|         0|            0|            0|  0.00%|def _fractional_max_pool3d(
   591|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList3[int],
   592|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList3[int]] = None,
   593|         0|            0|            0|  0.00%|    output_ratio: Optional[BroadcastingList3[float]] = None,
   594|         0|            0|            0|  0.00%|    return_indices: bool = False,
   595|         0|            0|            0|  0.00%|    _random_samples: Optional[Tensor] = None
   596|         0|            0|            0|  0.00%|) -> Tensor:
   597|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, _random_samples):
   598|         0|            0|            0|  0.00%|        return handle_torch_function(
   599|         0|            0|            0|  0.00%|            fractional_max_pool3d,
   600|         0|            0|            0|  0.00%|            (input, _random_samples),
   601|         0|            0|            0|  0.00%|            input,
   602|         0|            0|            0|  0.00%|            kernel_size,
   603|         0|            0|            0|  0.00%|            output_size=output_size,
   604|         0|            0|            0|  0.00%|            output_ratio=output_ratio,
   605|         0|            0|            0|  0.00%|            return_indices=return_indices,
   606|         0|            0|            0|  0.00%|            _random_samples=_random_samples,
   607|         0|            0|            0|  0.00%|        )
   608|         0|            0|            0|  0.00%|    return fractional_max_pool3d_with_indices(
   609|         0|            0|            0|  0.00%|        input, kernel_size, output_size, output_ratio, return_indices, _random_samples
   610|         0|            0|            0|  0.00%|    )[0]
   611|         0|            0|            0|  0.00%|
   612|         0|            0|            0|  0.00%|
   613|         0|            0|            0|  0.00%|fractional_max_pool3d = boolean_dispatch(
   614|         0|            0|            0|  0.00%|    arg_name="return_indices",
   615|         0|            0|            0|  0.00%|    arg_index=4,
   616|         0|            0|            0|  0.00%|    default=False,
   617|         0|            0|            0|  0.00%|    if_true=fractional_max_pool3d_with_indices,
   618|         0|            0|            0|  0.00%|    if_false=_fractional_max_pool3d,
   619|         0|            0|            0|  0.00%|    module_name=__name__,
   620|         0|            0|            0|  0.00%|    func_name="fractional_max_pool3d",
   621|         0|            0|            0|  0.00%|)
   622|         0|            0|            0|  0.00%|
   623|         0|            0|            0|  0.00%|
   624|         0|            0|            0|  0.00%|def max_pool1d_with_indices(
   625|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList1[int],
   626|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList1[int]] = None,
   627|         0|            0|            0|  0.00%|    padding: BroadcastingList1[int] = 0,
   628|         0|            0|            0|  0.00%|    dilation: BroadcastingList1[int] = 1,
   629|         0|            0|            0|  0.00%|    ceil_mode: bool = False,
   630|         0|            0|            0|  0.00%|    return_indices: bool = False
   631|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:
   632|         0|            0|            0|  0.00%|    r"""
   633|         0|            0|            0|  0.00%|    max_pool1d(input, kernel_size, stride=None, padding=0, dilation=1, ceil_mode=False, return_indices=False)
   634|         0|            0|            0|  0.00%|
   635|         0|            0|            0|  0.00%|    Applies a 1D max pooling over an input signal composed of several input
   636|         0|            0|            0|  0.00%|    planes.
   637|         0|            0|            0|  0.00%|
   638|         0|            0|            0|  0.00%|    .. note::
   639|         0|            0|            0|  0.00%|        The order of :attr:`ceil_mode` and :attr:`return_indices` is different from
   640|         0|            0|            0|  0.00%|        what seen in :class:`~torch.nn.MaxPool1d`, and will change in a future release.
   641|         0|            0|            0|  0.00%|
   642|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxPool1d` for details.
   643|         0|            0|            0|  0.00%|
   644|         0|            0|            0|  0.00%|    Args:
   645|         0|            0|            0|  0.00%|        input: input tensor of shape :math:`(\text{minibatch} , \text{in\_channels} , iW)`, minibatch dim optional.
   646|         0|            0|            0|  0.00%|        kernel_size: the size of the window. Can be a single number or a
   647|         0|            0|            0|  0.00%|            tuple `(kW,)`
   648|         0|            0|            0|  0.00%|        stride: the stride of the window. Can be a single number or a tuple
   649|         0|            0|            0|  0.00%|            `(sW,)`. Default: :attr:`kernel_size`
   650|         0|            0|            0|  0.00%|        padding: Implicit negative infinity padding to be added on both sides, must be >= 0 and <= kernel_size / 2.
   651|         0|            0|            0|  0.00%|        dilation: The stride between elements within a sliding window, must be > 0.
   652|         0|            0|            0|  0.00%|        ceil_mode: If ``True``, will use `ceil` instead of `floor` to compute the output shape. This
   653|         0|            0|            0|  0.00%|                   ensures that every element in the input tensor is covered by a sliding window.
   654|         0|            0|            0|  0.00%|        return_indices: If ``True``, will return the argmax along with the max values.
   655|         0|            0|            0|  0.00%|                        Useful for :class:`torch.nn.functional.max_unpool1d` later
   656|         0|            0|            0|  0.00%|    """
   657|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   658|         0|            0|            0|  0.00%|        return handle_torch_function(
   659|         0|            0|            0|  0.00%|            max_pool1d_with_indices,
   660|         0|            0|            0|  0.00%|            (input,),
   661|         0|            0|            0|  0.00%|            input,
   662|         0|            0|            0|  0.00%|            kernel_size,
   663|         0|            0|            0|  0.00%|            stride=stride,
   664|         0|            0|            0|  0.00%|            padding=padding,
   665|         0|            0|            0|  0.00%|            dilation=dilation,
   666|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,
   667|         0|            0|            0|  0.00%|            return_indices=return_indices,
   668|         0|            0|            0|  0.00%|        )
   669|         0|            0|            0|  0.00%|    if stride is None:
   670|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])
   671|         0|            0|            0|  0.00%|    return torch.max_pool1d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
   672|         0|            0|            0|  0.00%|
   673|         0|            0|            0|  0.00%|
   674|         0|            0|            0|  0.00%|def _max_pool1d(
   675|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList1[int],
   676|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList1[int]] = None,
   677|         0|            0|            0|  0.00%|    padding: BroadcastingList1[int] = 0,
   678|         0|            0|            0|  0.00%|    dilation: BroadcastingList1[int] = 1,
   679|         0|            0|            0|  0.00%|    ceil_mode: bool = False,
   680|         0|            0|            0|  0.00%|    return_indices: bool = False
   681|         0|            0|            0|  0.00%|) -> Tensor:
   682|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   683|         0|            0|            0|  0.00%|        return handle_torch_function(
   684|         0|            0|            0|  0.00%|            max_pool1d,
   685|         0|            0|            0|  0.00%|            (input,),
   686|         0|            0|            0|  0.00%|            input,
   687|         0|            0|            0|  0.00%|            kernel_size,
   688|         0|            0|            0|  0.00%|            stride=stride,
   689|         0|            0|            0|  0.00%|            padding=padding,
   690|         0|            0|            0|  0.00%|            dilation=dilation,
   691|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,
   692|         0|            0|            0|  0.00%|            return_indices=return_indices,
   693|         0|            0|            0|  0.00%|        )
   694|         0|            0|            0|  0.00%|    if stride is None:
   695|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])
   696|         0|            0|            0|  0.00%|    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
   697|         0|            0|            0|  0.00%|
   698|         0|            0|            0|  0.00%|
   699|         0|            0|            0|  0.00%|max_pool1d = boolean_dispatch(
   700|         0|            0|            0|  0.00%|    arg_name="return_indices",
   701|         0|            0|            0|  0.00%|    arg_index=6,
   702|         0|            0|            0|  0.00%|    default=False,
   703|         0|            0|            0|  0.00%|    if_true=max_pool1d_with_indices,
   704|         0|            0|            0|  0.00%|    if_false=_max_pool1d,
   705|         0|            0|            0|  0.00%|    module_name=__name__,
   706|         0|            0|            0|  0.00%|    func_name="max_pool1d",
   707|         0|            0|            0|  0.00%|)
   708|         0|            0|            0|  0.00%|
   709|         0|            0|            0|  0.00%|
   710|         0|            0|            0|  0.00%|def max_pool2d_with_indices(
   711|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList2[int],
   712|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList2[int]] = None,
   713|         0|            0|            0|  0.00%|    padding: BroadcastingList2[int] = 0,
   714|         0|            0|            0|  0.00%|    dilation: BroadcastingList2[int] = 1,
   715|         0|            0|            0|  0.00%|    ceil_mode: bool = False,
   716|         0|            0|            0|  0.00%|    return_indices: bool = False
   717|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:
   718|         0|            0|            0|  0.00%|    r"""
   719|         0|            0|            0|  0.00%|    max_pool2d(input, kernel_size, stride=None, padding=0, dilation=1, ceil_mode=False, return_indices=False)
   720|         0|            0|            0|  0.00%|
   721|         0|            0|            0|  0.00%|    Applies a 2D max pooling over an input signal composed of several input
   722|         0|            0|            0|  0.00%|    planes.
   723|         0|            0|            0|  0.00%|
   724|         0|            0|            0|  0.00%|    .. note::
   725|         0|            0|            0|  0.00%|        The order of :attr:`ceil_mode` and :attr:`return_indices` is different from
   726|         0|            0|            0|  0.00%|        what seen in :class:`~torch.nn.MaxPool2d`, and will change in a future release.
   727|         0|            0|            0|  0.00%|
   728|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxPool2d` for details.
   729|         0|            0|            0|  0.00%|
   730|         0|            0|            0|  0.00%|    Args:
   731|         0|            0|            0|  0.00%|        input: input tensor :math:`(\text{minibatch} , \text{in\_channels} , iH , iW)`, minibatch dim optional.
   732|         0|            0|            0|  0.00%|        kernel_size: size of the pooling region. Can be a single number or a
   733|         0|            0|            0|  0.00%|            tuple `(kH, kW)`
   734|         0|            0|            0|  0.00%|        stride: stride of the pooling operation. Can be a single number or a
   735|         0|            0|            0|  0.00%|            tuple `(sH, sW)`. Default: :attr:`kernel_size`
   736|         0|            0|            0|  0.00%|        padding: Implicit negative infinity padding to be added on both sides, must be >= 0 and <= kernel_size / 2.
   737|         0|            0|            0|  0.00%|        dilation: The stride between elements within a sliding window, must be > 0.
   738|         0|            0|            0|  0.00%|        ceil_mode: If ``True``, will use `ceil` instead of `floor` to compute the output shape. This
   739|         0|            0|            0|  0.00%|                   ensures that every element in the input tensor is covered by a sliding window.
   740|         0|            0|            0|  0.00%|        return_indices: If ``True``, will return the argmax along with the max values.
   741|         0|            0|            0|  0.00%|                        Useful for :class:`torch.nn.functional.max_unpool2d` later
   742|         0|            0|            0|  0.00%|    """
   743|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   744|         0|            0|            0|  0.00%|        return handle_torch_function(
   745|         0|            0|            0|  0.00%|            max_pool2d_with_indices,
   746|         0|            0|            0|  0.00%|            (input,),
   747|         0|            0|            0|  0.00%|            input,
   748|         0|            0|            0|  0.00%|            kernel_size,
   749|         0|            0|            0|  0.00%|            stride=stride,
   750|         0|            0|            0|  0.00%|            padding=padding,
   751|         0|            0|            0|  0.00%|            dilation=dilation,
   752|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,
   753|         0|            0|            0|  0.00%|            return_indices=return_indices,
   754|         0|            0|            0|  0.00%|        )
   755|         0|            0|            0|  0.00%|    if stride is None:
   756|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])
   757|         0|            0|            0|  0.00%|    return torch._C._nn.max_pool2d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
   758|         0|            0|            0|  0.00%|
   759|         0|            0|            0|  0.00%|
   760|         0|            0|            0|  0.00%|def _max_pool2d(
   761|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList2[int],
   762|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList2[int]] = None,
   763|         0|            0|            0|  0.00%|    padding: BroadcastingList2[int] = 0,
   764|         0|            0|            0|  0.00%|    dilation: BroadcastingList2[int] = 1,
   765|         0|            0|            0|  0.00%|    ceil_mode: bool = False,
   766|         0|            0|            0|  0.00%|    return_indices: bool = False
   767|         0|            0|            0|  0.00%|) -> Tensor:
   768|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   769|         0|            0|            0|  0.00%|        return handle_torch_function(
   770|         0|            0|            0|  0.00%|            max_pool2d,
   771|         0|            0|            0|  0.00%|            (input,),
   772|         0|            0|            0|  0.00%|            input,
   773|         0|            0|            0|  0.00%|            kernel_size,
   774|         0|            0|            0|  0.00%|            stride=stride,
   775|         0|            0|            0|  0.00%|            padding=padding,
   776|         0|            0|            0|  0.00%|            dilation=dilation,
   777|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,
   778|         0|            0|            0|  0.00%|            return_indices=return_indices,
   779|         0|            0|            0|  0.00%|        )
   780|         0|            0|            0|  0.00%|    if stride is None:
   781|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])
   782|         0|            0|            0|  0.00%|    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
   783|         0|            0|            0|  0.00%|
   784|         0|            0|            0|  0.00%|
   785|         0|            0|            0|  0.00%|max_pool2d = boolean_dispatch(
   786|         0|            0|            0|  0.00%|    arg_name="return_indices",
   787|         0|            0|            0|  0.00%|    arg_index=6,
   788|         0|            0|            0|  0.00%|    default=False,
   789|         0|            0|            0|  0.00%|    if_true=max_pool2d_with_indices,
   790|         0|            0|            0|  0.00%|    if_false=_max_pool2d,
   791|         0|            0|            0|  0.00%|    module_name=__name__,
   792|         0|            0|            0|  0.00%|    func_name="max_pool2d",
   793|         0|            0|            0|  0.00%|)
   794|         0|            0|            0|  0.00%|
   795|         0|            0|            0|  0.00%|
   796|         0|            0|            0|  0.00%|def max_pool3d_with_indices(
   797|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList3[int],
   798|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList3[int]] = None,
   799|         0|            0|            0|  0.00%|    padding: BroadcastingList3[int] = 0,
   800|         0|            0|            0|  0.00%|    dilation: BroadcastingList3[int] = 1,
   801|         0|            0|            0|  0.00%|    ceil_mode: bool = False,
   802|         0|            0|            0|  0.00%|    return_indices: bool = False
   803|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:
   804|         0|            0|            0|  0.00%|    r"""
   805|         0|            0|            0|  0.00%|    max_pool3d(input, kernel_size, stride=None, padding=0, dilation=1, ceil_mode=False, return_indices=False)
   806|         0|            0|            0|  0.00%|
   807|         0|            0|            0|  0.00%|    Applies a 3D max pooling over an input signal composed of several input
   808|         0|            0|            0|  0.00%|    planes.
   809|         0|            0|            0|  0.00%|
   810|         0|            0|            0|  0.00%|    .. note::
   811|         0|            0|            0|  0.00%|        The order of :attr:`ceil_mode` and :attr:`return_indices` is different from
   812|         0|            0|            0|  0.00%|        what seen in :class:`~torch.nn.MaxPool3d`, and will change in a future release.
   813|         0|            0|            0|  0.00%|
   814|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxPool3d` for details.
   815|         0|            0|            0|  0.00%|
   816|         0|            0|            0|  0.00%|    Args:
   817|         0|            0|            0|  0.00%|        input: input tensor :math:`(\text{minibatch} , \text{in\_channels} , iD, iH , iW)`, minibatch dim optional.
   818|         0|            0|            0|  0.00%|        kernel_size: size of the pooling region. Can be a single number or a
   819|         0|            0|            0|  0.00%|                     tuple `(kT, kH, kW)`
   820|         0|            0|            0|  0.00%|        stride: stride of the pooling operation. Can be a single number or a
   821|         0|            0|            0|  0.00%|                tuple `(sT, sH, sW)`. Default: :attr:`kernel_size`
   822|         0|            0|            0|  0.00%|        padding: Implicit negative infinity padding to be added on both sides, must be >= 0 and <= kernel_size / 2.
   823|         0|            0|            0|  0.00%|        dilation: The stride between elements within a sliding window, must be > 0.
   824|         0|            0|            0|  0.00%|        ceil_mode: If ``True``, will use `ceil` instead of `floor` to compute the output shape. This
   825|         0|            0|            0|  0.00%|                   ensures that every element in the input tensor is covered by a sliding window.
   826|         0|            0|            0|  0.00%|        return_indices: If ``True``, will return the argmax along with the max values.
   827|         0|            0|            0|  0.00%|                        Useful for :class:`torch.nn.functional.max_unpool3d` later
   828|         0|            0|            0|  0.00%|    """
   829|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   830|         0|            0|            0|  0.00%|        return handle_torch_function(
   831|         0|            0|            0|  0.00%|            max_pool3d_with_indices,
   832|         0|            0|            0|  0.00%|            (input,),
   833|         0|            0|            0|  0.00%|            input,
   834|         0|            0|            0|  0.00%|            kernel_size,
   835|         0|            0|            0|  0.00%|            stride=stride,
   836|         0|            0|            0|  0.00%|            padding=padding,
   837|         0|            0|            0|  0.00%|            dilation=dilation,
   838|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,
   839|         0|            0|            0|  0.00%|            return_indices=return_indices,
   840|         0|            0|            0|  0.00%|        )
   841|         0|            0|            0|  0.00%|    if stride is None:
   842|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])
   843|         0|            0|            0|  0.00%|    return torch._C._nn.max_pool3d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
   844|         0|            0|            0|  0.00%|
   845|         0|            0|            0|  0.00%|
   846|         0|            0|            0|  0.00%|def _max_pool3d(
   847|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList3[int],
   848|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList3[int]] = None,
   849|         0|            0|            0|  0.00%|    padding: BroadcastingList3[int] = 0,
   850|         0|            0|            0|  0.00%|    dilation: BroadcastingList3[int] = 1,
   851|         0|            0|            0|  0.00%|    ceil_mode: bool = False,
   852|         0|            0|            0|  0.00%|    return_indices: bool = False
   853|         0|            0|            0|  0.00%|) -> Tensor:
   854|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   855|         0|            0|            0|  0.00%|        return handle_torch_function(
   856|         0|            0|            0|  0.00%|            max_pool3d,
   857|         0|            0|            0|  0.00%|            (input,),
   858|         0|            0|            0|  0.00%|            input,
   859|         0|            0|            0|  0.00%|            kernel_size,
   860|         0|            0|            0|  0.00%|            stride=stride,
   861|         0|            0|            0|  0.00%|            padding=padding,
   862|         0|            0|            0|  0.00%|            dilation=dilation,
   863|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,
   864|         0|            0|            0|  0.00%|            return_indices=return_indices,
   865|         0|            0|            0|  0.00%|        )
   866|         0|            0|            0|  0.00%|    if stride is None:
   867|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])
   868|         0|            0|            0|  0.00%|    return torch.max_pool3d(input, kernel_size, stride, padding, dilation, ceil_mode)
   869|         0|            0|            0|  0.00%|
   870|         0|            0|            0|  0.00%|
   871|         0|            0|            0|  0.00%|max_pool3d = boolean_dispatch(
   872|         0|            0|            0|  0.00%|    arg_name="return_indices",
   873|         0|            0|            0|  0.00%|    arg_index=6,
   874|         0|            0|            0|  0.00%|    default=False,
   875|         0|            0|            0|  0.00%|    if_true=max_pool3d_with_indices,
   876|         0|            0|            0|  0.00%|    if_false=_max_pool3d,
   877|         0|            0|            0|  0.00%|    module_name=__name__,
   878|         0|            0|            0|  0.00%|    func_name="max_pool3d",
   879|         0|            0|            0|  0.00%|)
   880|         0|            0|            0|  0.00%|
   881|         0|            0|            0|  0.00%|
   882|         0|            0|            0|  0.00%|def _unpool_output_size(
   883|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: List[int], stride: List[int], padding: List[int], output_size: Optional[List[int]]
   884|         0|            0|            0|  0.00%|) -> List[int]:
   885|         0|            0|            0|  0.00%|    input_size = input.size()
   886|         0|            0|            0|  0.00%|    default_size = torch.jit.annotate(List[int], [])
   887|         0|            0|            0|  0.00%|    for d in range(len(kernel_size)):
   888|         0|            0|            0|  0.00%|        default_size.append((input_size[-len(kernel_size) + d] - 1) * stride[d] + kernel_size[d] - 2 * padding[d])
   889|         0|            0|            0|  0.00%|    if output_size is None:
   890|         0|            0|            0|  0.00%|        ret = default_size
   891|         0|            0|            0|  0.00%|    else:
   892|         0|            0|            0|  0.00%|        if len(output_size) == len(kernel_size) + 2:
   893|         0|            0|            0|  0.00%|            output_size = output_size[2:]
   894|         0|            0|            0|  0.00%|        if len(output_size) != len(kernel_size):
   895|         0|            0|            0|  0.00%|            raise ValueError(
   896|         0|            0|            0|  0.00%|                "output_size should be a sequence containing "
   897|         0|            0|            0|  0.00%|                "{} or {} elements, but it has a length of '{}'".format(
   898|         0|            0|            0|  0.00%|                    len(kernel_size), len(kernel_size) + 2, len(output_size)
   899|         0|            0|            0|  0.00%|                )
   900|         0|            0|            0|  0.00%|            )
   901|         0|            0|            0|  0.00%|        for d in range(len(kernel_size)):
   902|         0|            0|            0|  0.00%|            min_size = default_size[d] - stride[d]
   903|         0|            0|            0|  0.00%|            max_size = default_size[d] + stride[d]
   904|         0|            0|            0|  0.00%|            if not (min_size < output_size[d] < max_size):
   905|         0|            0|            0|  0.00%|                raise ValueError(
   906|         0|            0|            0|  0.00%|                    'invalid output_size "{}" (dim {} must be between {} and {})'.format(
   907|         0|            0|            0|  0.00%|                        output_size, d, min_size, max_size
   908|         0|            0|            0|  0.00%|                    )
   909|         0|            0|            0|  0.00%|                )
   910|         0|            0|            0|  0.00%|
   911|         0|            0|            0|  0.00%|        ret = output_size
   912|         0|            0|            0|  0.00%|    return ret
   913|         0|            0|            0|  0.00%|
   914|         0|            0|            0|  0.00%|
   915|         0|            0|            0|  0.00%|def max_unpool1d(
   916|         0|            0|            0|  0.00%|    input: Tensor, indices: Tensor,
   917|         0|            0|            0|  0.00%|    kernel_size: BroadcastingList1[int],
   918|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList1[int]] = None,
   919|         0|            0|            0|  0.00%|    padding: BroadcastingList1[int] = 0,
   920|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList1[int]] = None
   921|         0|            0|            0|  0.00%|) -> Tensor:
   922|         0|            0|            0|  0.00%|    r"""Computes a partial inverse of :class:`MaxPool1d`.
   923|         0|            0|            0|  0.00%|
   924|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxUnpool1d` for details.
   925|         0|            0|            0|  0.00%|    """
   926|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   927|         0|            0|            0|  0.00%|        return handle_torch_function(
   928|         0|            0|            0|  0.00%|            max_unpool1d,
   929|         0|            0|            0|  0.00%|            (input,),
   930|         0|            0|            0|  0.00%|            input,
   931|         0|            0|            0|  0.00%|            indices,
   932|         0|            0|            0|  0.00%|            kernel_size,
   933|         0|            0|            0|  0.00%|            stride=stride,
   934|         0|            0|            0|  0.00%|            padding=padding,
   935|         0|            0|            0|  0.00%|            output_size=output_size,
   936|         0|            0|            0|  0.00%|        )
   937|         0|            0|            0|  0.00%|    kernel_size = _single(kernel_size)
   938|         0|            0|            0|  0.00%|    if stride is not None:
   939|         0|            0|            0|  0.00%|        _stride = _single(stride)
   940|         0|            0|            0|  0.00%|    else:
   941|         0|            0|            0|  0.00%|        _stride = kernel_size
   942|         0|            0|            0|  0.00%|    padding = _single(padding)
   943|         0|            0|            0|  0.00%|    output_size = _unpool_output_size(input, kernel_size, _stride, padding, output_size)
   944|         0|            0|            0|  0.00%|    if isinstance(output_size, list):
   945|         0|            0|            0|  0.00%|        output_size = output_size + [1]
   946|         0|            0|            0|  0.00%|    else:
   947|         0|            0|            0|  0.00%|        output_size = output_size + (1,)
   948|         0|            0|            0|  0.00%|    return torch._C._nn.max_unpool2d(input.unsqueeze(-1), indices.unsqueeze(-1), output_size).squeeze(-1)
   949|         0|            0|            0|  0.00%|
   950|         0|            0|            0|  0.00%|
   951|         0|            0|            0|  0.00%|def max_unpool2d(
   952|         0|            0|            0|  0.00%|    input: Tensor, indices: Tensor,
   953|         0|            0|            0|  0.00%|    kernel_size: BroadcastingList2[int],
   954|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList2[int]] = None,
   955|         0|            0|            0|  0.00%|    padding: BroadcastingList2[int] = 0,
   956|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList2[int]] = None
   957|         0|            0|            0|  0.00%|) -> Tensor:
   958|         0|            0|            0|  0.00%|    r"""Computes a partial inverse of :class:`MaxPool2d`.
   959|         0|            0|            0|  0.00%|
   960|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxUnpool2d` for details.
   961|         0|            0|            0|  0.00%|    """
   962|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   963|         0|            0|            0|  0.00%|        return handle_torch_function(
   964|         0|            0|            0|  0.00%|            max_unpool2d,
   965|         0|            0|            0|  0.00%|            (input,),
   966|         0|            0|            0|  0.00%|            input,
   967|         0|            0|            0|  0.00%|            indices,
   968|         0|            0|            0|  0.00%|            kernel_size,
   969|         0|            0|            0|  0.00%|            stride=stride,
   970|         0|            0|            0|  0.00%|            padding=padding,
   971|         0|            0|            0|  0.00%|            output_size=output_size,
   972|         0|            0|            0|  0.00%|        )
   973|         0|            0|            0|  0.00%|    kernel_size = _pair(kernel_size)
   974|         0|            0|            0|  0.00%|    if stride is not None:
   975|         0|            0|            0|  0.00%|        _stride = _pair(stride)
   976|         0|            0|            0|  0.00%|    else:
   977|         0|            0|            0|  0.00%|        _stride = kernel_size
   978|         0|            0|            0|  0.00%|    padding = _pair(padding)
   979|         0|            0|            0|  0.00%|    output_size = _unpool_output_size(input, kernel_size, _stride, padding, output_size)
   980|         0|            0|            0|  0.00%|    return torch._C._nn.max_unpool2d(input, indices, output_size)
   981|         0|            0|            0|  0.00%|
   982|         0|            0|            0|  0.00%|
   983|         0|            0|            0|  0.00%|def max_unpool3d(
   984|         0|            0|            0|  0.00%|    input: Tensor, indices: Tensor,
   985|         0|            0|            0|  0.00%|    kernel_size: BroadcastingList3[int],
   986|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList3[int]] = None,
   987|         0|            0|            0|  0.00%|    padding: BroadcastingList3[int] = 0,
   988|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList3[int]] = None
   989|         0|            0|            0|  0.00%|) -> Tensor:
   990|         0|            0|            0|  0.00%|    r"""Computes a partial inverse of :class:`MaxPool3d`.
   991|         0|            0|            0|  0.00%|
   992|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxUnpool3d` for details.
   993|         0|            0|            0|  0.00%|    """
   994|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
   995|         0|            0|            0|  0.00%|        return handle_torch_function(
   996|         0|            0|            0|  0.00%|            max_unpool3d,
   997|         0|            0|            0|  0.00%|            (input,),
   998|         0|            0|            0|  0.00%|            input,
   999|         0|            0|            0|  0.00%|            indices,
  1000|         0|            0|            0|  0.00%|            kernel_size,
  1001|         0|            0|            0|  0.00%|            stride=stride,
  1002|         0|            0|            0|  0.00%|            padding=padding,
  1003|         0|            0|            0|  0.00%|            output_size=output_size,
  1004|         0|            0|            0|  0.00%|        )
  1005|         0|            0|            0|  0.00%|    kernel_size = _triple(kernel_size)
  1006|         0|            0|            0|  0.00%|    if stride is not None:
  1007|         0|            0|            0|  0.00%|        _stride = _triple(stride)
  1008|         0|            0|            0|  0.00%|    else:
  1009|         0|            0|            0|  0.00%|        _stride = kernel_size
  1010|         0|            0|            0|  0.00%|    padding = _triple(padding)
  1011|         0|            0|            0|  0.00%|    output_size = _unpool_output_size(input, kernel_size, _stride, padding, output_size)
  1012|         0|            0|            0|  0.00%|    return torch._C._nn.max_unpool3d(input, indices, output_size, _stride, padding)
  1013|         0|            0|            0|  0.00%|
  1014|         0|            0|            0|  0.00%|
  1015|         0|            0|            0|  0.00%|def lp_pool2d(
  1016|         0|            0|            0|  0.00%|    input: Tensor, norm_type: Union[int, float],
  1017|         0|            0|            0|  0.00%|    kernel_size: BroadcastingList2[int],
  1018|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList2[int]] = None,
  1019|         0|            0|            0|  0.00%|    ceil_mode: bool = False
  1020|         0|            0|            0|  0.00%|) -> Tensor:
  1021|         0|            0|            0|  0.00%|    r"""Applies a 2D power-average pooling over an input signal composed of
  1022|         0|            0|            0|  0.00%|    several input planes. If the sum of all inputs to the power of `p` is
  1023|         0|            0|            0|  0.00%|    zero, the gradient is set to zero as well.
  1024|         0|            0|            0|  0.00%|
  1025|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LPPool2d` for details.
  1026|         0|            0|            0|  0.00%|    """
  1027|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1028|         0|            0|            0|  0.00%|        return handle_torch_function(
  1029|         0|            0|            0|  0.00%|            lp_pool2d, (input,), input, norm_type, kernel_size, stride=stride, ceil_mode=ceil_mode
  1030|         0|            0|            0|  0.00%|        )
  1031|         0|            0|            0|  0.00%|    kw, kh = utils._pair(kernel_size)
  1032|         0|            0|            0|  0.00%|    if stride is not None:
  1033|         0|            0|            0|  0.00%|        out = avg_pool2d(input.pow(norm_type), kernel_size, stride, 0, ceil_mode)
  1034|         0|            0|            0|  0.00%|    else:
  1035|         0|            0|            0|  0.00%|        out = avg_pool2d(input.pow(norm_type), kernel_size, padding=0, ceil_mode=ceil_mode)
  1036|         0|            0|            0|  0.00%|
  1037|         0|            0|            0|  0.00%|    return (torch.sign(out) * relu(torch.abs(out))).mul(kw * kh).pow(1.0 / norm_type)
  1038|         0|            0|            0|  0.00%|
  1039|         0|            0|            0|  0.00%|
  1040|         0|            0|            0|  0.00%|def lp_pool1d(
  1041|         0|            0|            0|  0.00%|    input: Tensor, norm_type: Union[int, float],
  1042|         0|            0|            0|  0.00%|    kernel_size: int,
  1043|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList1[int]] = None,
  1044|         0|            0|            0|  0.00%|    ceil_mode: bool = False
  1045|         0|            0|            0|  0.00%|) -> Tensor:
  1046|         0|            0|            0|  0.00%|    r"""Applies a 1D power-average pooling over an input signal composed of
  1047|         0|            0|            0|  0.00%|    several input planes. If the sum of all inputs to the power of `p` is
  1048|         0|            0|            0|  0.00%|    zero, the gradient is set to zero as well.
  1049|         0|            0|            0|  0.00%|
  1050|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LPPool1d` for details.
  1051|         0|            0|            0|  0.00%|    """
  1052|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1053|         0|            0|            0|  0.00%|        return handle_torch_function(
  1054|         0|            0|            0|  0.00%|            lp_pool1d, (input,), input, norm_type, kernel_size, stride=stride, ceil_mode=ceil_mode
  1055|         0|            0|            0|  0.00%|        )
  1056|         0|            0|            0|  0.00%|    if stride is not None:
  1057|         0|            0|            0|  0.00%|        out = avg_pool1d(input.pow(norm_type), kernel_size, stride, 0, ceil_mode)
  1058|         0|            0|            0|  0.00%|    else:
  1059|         0|            0|            0|  0.00%|        out = avg_pool1d(input.pow(norm_type), kernel_size, padding=0, ceil_mode=ceil_mode)
  1060|         0|            0|            0|  0.00%|
  1061|         0|            0|            0|  0.00%|    return (torch.sign(out) * relu(torch.abs(out))).mul(kernel_size).pow(1.0 / norm_type)
  1062|         0|            0|            0|  0.00%|
  1063|         0|            0|            0|  0.00%|
  1064|         0|            0|            0|  0.00%|def adaptive_max_pool1d_with_indices(
  1065|         0|            0|            0|  0.00%|    input: Tensor, output_size: BroadcastingList1[int], return_indices: bool = False
  1066|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:
  1067|         0|            0|            0|  0.00%|    r"""Applies a 1D adaptive max pooling over an input signal composed of
  1068|         0|            0|            0|  0.00%|    several input planes.
  1069|         0|            0|            0|  0.00%|
  1070|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AdaptiveMaxPool1d` for details and output shape.
  1071|         0|            0|            0|  0.00%|
  1072|         0|            0|            0|  0.00%|    Args:
  1073|         0|            0|            0|  0.00%|        output_size: the target output size (single integer)
  1074|         0|            0|            0|  0.00%|        return_indices: whether to return pooling indices. Default: ``False``
  1075|         0|            0|            0|  0.00%|    """
  1076|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1077|         0|            0|            0|  0.00%|        return handle_torch_function(
  1078|         0|            0|            0|  0.00%|            adaptive_max_pool1d_with_indices, (input,), input, output_size, return_indices=return_indices
  1079|         0|            0|            0|  0.00%|        )
  1080|         0|            0|            0|  0.00%|    return torch.adaptive_max_pool1d(input, output_size)
  1081|         0|            0|            0|  0.00%|
  1082|         0|            0|            0|  0.00%|
  1083|         0|            0|            0|  0.00%|def _adaptive_max_pool1d(input: Tensor, output_size: BroadcastingList1[int], return_indices: bool = False) -> Tensor:
  1084|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1085|         0|            0|            0|  0.00%|        return handle_torch_function(
  1086|         0|            0|            0|  0.00%|            adaptive_max_pool1d, (input,), input, output_size, return_indices=return_indices
  1087|         0|            0|            0|  0.00%|        )
  1088|         0|            0|            0|  0.00%|    return adaptive_max_pool1d_with_indices(input, output_size)[0]
  1089|         0|            0|            0|  0.00%|
  1090|         0|            0|            0|  0.00%|
  1091|         0|            0|            0|  0.00%|adaptive_max_pool1d = boolean_dispatch(
  1092|         0|            0|            0|  0.00%|    arg_name="return_indices",
  1093|         0|            0|            0|  0.00%|    arg_index=2,
  1094|         0|            0|            0|  0.00%|    default=False,
  1095|         0|            0|            0|  0.00%|    if_true=adaptive_max_pool1d_with_indices,
  1096|         0|            0|            0|  0.00%|    if_false=_adaptive_max_pool1d,
  1097|         0|            0|            0|  0.00%|    module_name=__name__,
  1098|         0|            0|            0|  0.00%|    func_name="adaptive_max_pool1d",
  1099|         0|            0|            0|  0.00%|)
  1100|         0|            0|            0|  0.00%|
  1101|         0|            0|            0|  0.00%|
  1102|         0|            0|            0|  0.00%|def adaptive_max_pool2d_with_indices(
  1103|         0|            0|            0|  0.00%|    input: Tensor, output_size: BroadcastingList2[int],
  1104|         0|            0|            0|  0.00%|    return_indices: bool = False
  1105|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:
  1106|         0|            0|            0|  0.00%|    r"""Applies a 2D adaptive max pooling over an input signal composed of
  1107|         0|            0|            0|  0.00%|    several input planes.
  1108|         0|            0|            0|  0.00%|
  1109|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AdaptiveMaxPool2d` for details and output shape.
  1110|         0|            0|            0|  0.00%|
  1111|         0|            0|            0|  0.00%|    Args:
  1112|         0|            0|            0|  0.00%|        output_size: the target output size (single integer or
  1113|         0|            0|            0|  0.00%|            double-integer tuple)
  1114|         0|            0|            0|  0.00%|        return_indices: whether to return pooling indices. Default: ``False``
  1115|         0|            0|            0|  0.00%|    """
  1116|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1117|         0|            0|            0|  0.00%|        return handle_torch_function(
  1118|         0|            0|            0|  0.00%|            adaptive_max_pool2d_with_indices, (input,), input, output_size, return_indices=return_indices
  1119|         0|            0|            0|  0.00%|        )
  1120|         0|            0|            0|  0.00%|    output_size = _list_with_default(output_size, input.size())
  1121|         0|            0|            0|  0.00%|    return torch._C._nn.adaptive_max_pool2d(input, output_size)
  1122|         0|            0|            0|  0.00%|
  1123|         0|            0|            0|  0.00%|
  1124|         0|            0|            0|  0.00%|def _adaptive_max_pool2d(input: Tensor, output_size: BroadcastingList2[int], return_indices: bool = False) -> Tensor:
  1125|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1126|         0|            0|            0|  0.00%|        return handle_torch_function(
  1127|         0|            0|            0|  0.00%|            adaptive_max_pool2d, (input,), input, output_size, return_indices=return_indices
  1128|         0|            0|            0|  0.00%|        )
  1129|         0|            0|            0|  0.00%|    return adaptive_max_pool2d_with_indices(input, output_size)[0]
  1130|         0|            0|            0|  0.00%|
  1131|         0|            0|            0|  0.00%|
  1132|         0|            0|            0|  0.00%|adaptive_max_pool2d = boolean_dispatch(
  1133|         0|            0|            0|  0.00%|    arg_name="return_indices",
  1134|         0|            0|            0|  0.00%|    arg_index=2,
  1135|         0|            0|            0|  0.00%|    default=False,
  1136|         0|            0|            0|  0.00%|    if_true=adaptive_max_pool2d_with_indices,
  1137|         0|            0|            0|  0.00%|    if_false=_adaptive_max_pool2d,
  1138|         0|            0|            0|  0.00%|    module_name=__name__,
  1139|         0|            0|            0|  0.00%|    func_name="adaptive_max_pool2d",
  1140|         0|            0|            0|  0.00%|)
  1141|         0|            0|            0|  0.00%|
  1142|         0|            0|            0|  0.00%|
  1143|         0|            0|            0|  0.00%|def adaptive_max_pool3d_with_indices(
  1144|         0|            0|            0|  0.00%|    input: Tensor, output_size: BroadcastingList3[int],
  1145|         0|            0|            0|  0.00%|    return_indices: bool = False
  1146|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:
  1147|         0|            0|            0|  0.00%|    r"""Applies a 3D adaptive max pooling over an input signal composed of
  1148|         0|            0|            0|  0.00%|    several input planes.
  1149|         0|            0|            0|  0.00%|
  1150|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AdaptiveMaxPool3d` for details and output shape.
  1151|         0|            0|            0|  0.00%|
  1152|         0|            0|            0|  0.00%|    Args:
  1153|         0|            0|            0|  0.00%|        output_size: the target output size (single integer or
  1154|         0|            0|            0|  0.00%|            triple-integer tuple)
  1155|         0|            0|            0|  0.00%|        return_indices: whether to return pooling indices. Default: ``False``
  1156|         0|            0|            0|  0.00%|    """
  1157|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1158|         0|            0|            0|  0.00%|        return handle_torch_function(
  1159|         0|            0|            0|  0.00%|            adaptive_max_pool3d_with_indices, (input,), input, output_size, return_indices=return_indices
  1160|         0|            0|            0|  0.00%|        )
  1161|         0|            0|            0|  0.00%|    output_size = _list_with_default(output_size, input.size())
  1162|         0|            0|            0|  0.00%|    return torch._C._nn.adaptive_max_pool3d(input, output_size)
  1163|         0|            0|            0|  0.00%|
  1164|         0|            0|            0|  0.00%|
  1165|         0|            0|            0|  0.00%|def _adaptive_max_pool3d(input: Tensor, output_size: BroadcastingList3[int], return_indices: bool = False) -> Tensor:
  1166|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1167|         0|            0|            0|  0.00%|        return handle_torch_function(
  1168|         0|            0|            0|  0.00%|            adaptive_max_pool3d, (input,), input, output_size, return_indices=return_indices
  1169|         0|            0|            0|  0.00%|        )
  1170|         0|            0|            0|  0.00%|    return adaptive_max_pool3d_with_indices(input, output_size)[0]
  1171|         0|            0|            0|  0.00%|
  1172|         0|            0|            0|  0.00%|
  1173|         0|            0|            0|  0.00%|adaptive_max_pool3d = boolean_dispatch(
  1174|         0|            0|            0|  0.00%|    arg_name="return_indices",
  1175|         0|            0|            0|  0.00%|    arg_index=2,
  1176|         0|            0|            0|  0.00%|    default=False,
  1177|         0|            0|            0|  0.00%|    if_true=adaptive_max_pool3d_with_indices,
  1178|         0|            0|            0|  0.00%|    if_false=_adaptive_max_pool3d,
  1179|         0|            0|            0|  0.00%|    module_name=__name__,
  1180|         0|            0|            0|  0.00%|    func_name="adaptive_max_pool3d",
  1181|         0|            0|            0|  0.00%|)
  1182|         0|            0|            0|  0.00%|
  1183|         0|            0|            0|  0.00%|
  1184|         0|            0|            0|  0.00%|adaptive_avg_pool1d = _add_docstr(
  1185|         0|            0|            0|  0.00%|    torch.adaptive_avg_pool1d,
  1186|         0|            0|            0|  0.00%|    r"""
  1187|         0|            0|            0|  0.00%|adaptive_avg_pool1d(input, output_size) -> Tensor
  1188|         0|            0|            0|  0.00%|
  1189|         0|            0|            0|  0.00%|Applies a 1D adaptive average pooling over an input signal composed of
  1190|         0|            0|            0|  0.00%|several input planes.
  1191|         0|            0|            0|  0.00%|
  1192|         0|            0|            0|  0.00%|See :class:`~torch.nn.AdaptiveAvgPool1d` for details and output shape.
  1193|         0|            0|            0|  0.00%|
  1194|         0|            0|            0|  0.00%|Args:
  1195|         0|            0|            0|  0.00%|    output_size: the target output size (single integer)
  1196|         0|            0|            0|  0.00%|""",
  1197|         0|            0|            0|  0.00%|)
  1198|         0|            0|            0|  0.00%|
  1199|         0|            0|            0|  0.00%|
  1200|         0|            0|            0|  0.00%|def adaptive_avg_pool2d(input: Tensor, output_size: BroadcastingList2[int]) -> Tensor:
  1201|         0|            0|            0|  0.00%|    r"""
  1202|         0|            0|            0|  0.00%|    Applies a 2D adaptive average pooling over an input signal composed of
  1203|         0|            0|            0|  0.00%|    several input planes.
  1204|         0|            0|            0|  0.00%|
  1205|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AdaptiveAvgPool2d` for details and output shape.
  1206|         0|            0|            0|  0.00%|
  1207|         0|            0|            0|  0.00%|    Args:
  1208|         0|            0|            0|  0.00%|        output_size: the target output size (single integer or
  1209|         0|            0|            0|  0.00%|            double-integer tuple)
  1210|         0|            0|            0|  0.00%|    """
  1211|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1212|         0|            0|            0|  0.00%|        return handle_torch_function(adaptive_avg_pool2d, (input,), input, output_size)
  1213|         0|            0|            0|  0.00%|    _output_size = _list_with_default(output_size, input.size())
  1214|         0|            0|            0|  0.00%|    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)
  1215|         0|            0|            0|  0.00%|
  1216|         0|            0|            0|  0.00%|
  1217|         0|            0|            0|  0.00%|def adaptive_avg_pool3d(input: Tensor, output_size: BroadcastingList3[int]) -> Tensor:
  1218|         0|            0|            0|  0.00%|    r"""
  1219|         0|            0|            0|  0.00%|    Applies a 3D adaptive average pooling over an input signal composed of
  1220|         0|            0|            0|  0.00%|    several input planes.
  1221|         0|            0|            0|  0.00%|
  1222|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AdaptiveAvgPool3d` for details and output shape.
  1223|         0|            0|            0|  0.00%|
  1224|         0|            0|            0|  0.00%|    Args:
  1225|         0|            0|            0|  0.00%|        output_size: the target output size (single integer or
  1226|         0|            0|            0|  0.00%|            triple-integer tuple)
  1227|         0|            0|            0|  0.00%|    """
  1228|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1229|         0|            0|            0|  0.00%|        return handle_torch_function(adaptive_avg_pool3d, (input,), input, output_size)
  1230|         0|            0|            0|  0.00%|    _output_size = _list_with_default(output_size, input.size())
  1231|         0|            0|            0|  0.00%|    return torch._C._nn.adaptive_avg_pool3d(input, _output_size)
  1232|         0|            0|            0|  0.00%|
  1233|         0|            0|            0|  0.00%|
  1234|         0|            0|            0|  0.00%|# Activation functions
  1235|         0|            0|            0|  0.00%|def dropout(input: Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> Tensor:
  1236|         0|            0|            0|  0.00%|    r"""
  1237|         0|            0|            0|  0.00%|    During training, randomly zeroes some of the elements of the input
  1238|         0|            0|            0|  0.00%|    tensor with probability :attr:`p` using samples from a Bernoulli
  1239|         0|            0|            0|  0.00%|    distribution.
  1240|         0|            0|            0|  0.00%|
  1241|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Dropout` for details.
  1242|         0|            0|            0|  0.00%|
  1243|         0|            0|            0|  0.00%|    Args:
  1244|         0|            0|            0|  0.00%|        p: probability of an element to be zeroed. Default: 0.5
  1245|         0|            0|            0|  0.00%|        training: apply dropout if is ``True``. Default: ``True``
  1246|         0|            0|            0|  0.00%|        inplace: If set to ``True``, will do this operation in-place. Default: ``False``
  1247|         0|            0|            0|  0.00%|    """
  1248|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1249|         0|            0|            0|  0.00%|        return handle_torch_function(dropout, (input,), input, p=p, training=training, inplace=inplace)
  1250|         0|            0|            0|  0.00%|    if p < 0.0 or p > 1.0:
  1251|         0|            0|            0|  0.00%|        raise ValueError("dropout probability has to be between 0 and 1, " "but got {}".format(p))
  1252|         0|            0|            0|  0.00%|    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
  1253|         0|            0|            0|  0.00%|
  1254|         0|            0|            0|  0.00%|
  1255|         0|            0|            0|  0.00%|def alpha_dropout(input: Tensor, p: float = 0.5, training: bool = False, inplace: bool = False) -> Tensor:
  1256|         0|            0|            0|  0.00%|    r"""Applies alpha dropout to the input.
  1257|         0|            0|            0|  0.00%|
  1258|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AlphaDropout` for details.
  1259|         0|            0|            0|  0.00%|    """
  1260|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1261|         0|            0|            0|  0.00%|        return handle_torch_function(alpha_dropout, (input,), input, p=p, training=training, inplace=inplace)
  1262|         0|            0|            0|  0.00%|    if p < 0.0 or p > 1.0:
  1263|         0|            0|            0|  0.00%|        raise ValueError("dropout probability has to be between 0 and 1, " "but got {}".format(p))
  1264|         0|            0|            0|  0.00%|    return _VF.alpha_dropout_(input, p, training) if inplace else _VF.alpha_dropout(input, p, training)
  1265|         0|            0|            0|  0.00%|
  1266|         0|            0|            0|  0.00%|
  1267|         0|            0|            0|  0.00%|def dropout1d(input: Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> Tensor:
  1268|         0|            0|            0|  0.00%|    r"""
  1269|         0|            0|            0|  0.00%|    Randomly zero out entire channels (a channel is a 1D feature map,
  1270|         0|            0|            0|  0.00%|    e.g., the :math:`j`-th channel of the :math:`i`-th sample in the
  1271|         0|            0|            0|  0.00%|    batched input is a 1D tensor :math:`\text{input}[i, j]`) of the input tensor).
  1272|         0|            0|            0|  0.00%|    Each channel will be zeroed out independently on every forward call with
  1273|         0|            0|            0|  0.00%|    probability :attr:`p` using samples from a Bernoulli distribution.
  1274|         0|            0|            0|  0.00%|
  1275|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Dropout1d` for details.
  1276|         0|            0|            0|  0.00%|
  1277|         0|            0|            0|  0.00%|    Args:
  1278|         0|            0|            0|  0.00%|        p: probability of a channel to be zeroed. Default: 0.5
  1279|         0|            0|            0|  0.00%|        training: apply dropout if is ``True``. Default: ``True``
  1280|         0|            0|            0|  0.00%|        inplace: If set to ``True``, will do this operation in-place. Default: ``False``
  1281|         0|            0|            0|  0.00%|    """
  1282|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1283|         0|            0|            0|  0.00%|        return handle_torch_function(dropout1d, (input,), input, p=p, training=training, inplace=inplace)
  1284|         0|            0|            0|  0.00%|    if p < 0.0 or p > 1.0:
  1285|         0|            0|            0|  0.00%|        raise ValueError("dropout probability has to be between 0 and 1, " "but got {}".format(p))
  1286|         0|            0|            0|  0.00%|    inp_dim = input.dim()
  1287|         0|            0|            0|  0.00%|    if inp_dim not in (2, 3):
  1288|         0|            0|            0|  0.00%|        raise RuntimeError(f"dropout1d: Expected 2D or 3D input, but received a {inp_dim}D input. "
  1289|         0|            0|            0|  0.00%|                           "Note that dropout1d exists to provide channel-wise dropout on inputs with 1 "
  1290|         0|            0|            0|  0.00%|                           "spatial dimension, a channel dimension, and an optional batch dimension "
  1291|         0|            0|            0|  0.00%|                           "(i.e. 2D or 3D inputs).")
  1292|         0|            0|            0|  0.00%|
  1293|         0|            0|            0|  0.00%|    is_batched = inp_dim == 3
  1294|         0|            0|            0|  0.00%|    if not is_batched:
  1295|         0|            0|            0|  0.00%|        input = input.unsqueeze_(0) if inplace else input.unsqueeze(0)
  1296|         0|            0|            0|  0.00%|
  1297|         0|            0|            0|  0.00%|    result = _VF.feature_dropout_(input, p, training) if inplace else _VF.feature_dropout(input, p, training)
  1298|         0|            0|            0|  0.00%|
  1299|         0|            0|            0|  0.00%|    if not is_batched:
  1300|         0|            0|            0|  0.00%|        result = result.squeeze_(0) if inplace else result.squeeze(0)
  1301|         0|            0|            0|  0.00%|
  1302|         0|            0|            0|  0.00%|    return result
  1303|         0|            0|            0|  0.00%|
  1304|         0|            0|            0|  0.00%|
  1305|         0|            0|            0|  0.00%|def dropout2d(input: Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> Tensor:
  1306|         0|            0|            0|  0.00%|    r"""
  1307|         0|            0|            0|  0.00%|    Randomly zero out entire channels (a channel is a 2D feature map,
  1308|         0|            0|            0|  0.00%|    e.g., the :math:`j`-th channel of the :math:`i`-th sample in the
  1309|         0|            0|            0|  0.00%|    batched input is a 2D tensor :math:`\text{input}[i, j]`) of the input tensor).
  1310|         0|            0|            0|  0.00%|    Each channel will be zeroed out independently on every forward call with
  1311|         0|            0|            0|  0.00%|    probability :attr:`p` using samples from a Bernoulli distribution.
  1312|         0|            0|            0|  0.00%|
  1313|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Dropout2d` for details.
  1314|         0|            0|            0|  0.00%|
  1315|         0|            0|            0|  0.00%|    Args:
  1316|         0|            0|            0|  0.00%|        p: probability of a channel to be zeroed. Default: 0.5
  1317|         0|            0|            0|  0.00%|        training: apply dropout if is ``True``. Default: ``True``
  1318|         0|            0|            0|  0.00%|        inplace: If set to ``True``, will do this operation in-place. Default: ``False``
  1319|         0|            0|            0|  0.00%|    """
  1320|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1321|         0|            0|            0|  0.00%|        return handle_torch_function(dropout2d, (input,), input, p=p, training=training, inplace=inplace)
  1322|         0|            0|            0|  0.00%|    if p < 0.0 or p > 1.0:
  1323|         0|            0|            0|  0.00%|        raise ValueError("dropout probability has to be between 0 and 1, " "but got {}".format(p))
  1324|         0|            0|            0|  0.00%|    inp_dim = input.dim()
  1325|         0|            0|            0|  0.00%|    if inp_dim not in (3, 4):
  1326|         0|            0|            0|  0.00%|        warn_msg = (f"dropout2d: Received a {inp_dim}-D input to dropout2d, which is deprecated "
  1327|         0|            0|            0|  0.00%|                    "and will result in an error in a future release. To retain the behavior "
  1328|         0|            0|            0|  0.00%|                    "and silence this warning, please use dropout instead. Note that dropout2d "
  1329|         0|            0|            0|  0.00%|                    "exists to provide channel-wise dropout on inputs with 2 spatial dimensions, "
  1330|         0|            0|            0|  0.00%|                    "a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).")
  1331|         0|            0|            0|  0.00%|        warnings.warn(warn_msg)
  1332|         0|            0|            0|  0.00%|
  1333|         0|            0|            0|  0.00%|    # TODO: Properly support no-batch-dim inputs. For now, these are NOT supported; passing
  1334|         0|            0|            0|  0.00%|    # a 3D input will perform dropout1d behavior instead. This was done historically and the
  1335|         0|            0|            0|  0.00%|    # behavior is maintained here for now.
  1336|         0|            0|            0|  0.00%|    # See https://github.com/pytorch/pytorch/issues/77081
  1337|         0|            0|            0|  0.00%|    if inp_dim == 3:
  1338|         0|            0|            0|  0.00%|        warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
  1339|         0|            0|            0|  0.00%|                      "1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C "
  1340|         0|            0|            0|  0.00%|                      "is the channel dim. This behavior will change in a future release to interpret the "
  1341|         0|            0|            0|  0.00%|                      "input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D "
  1342|         0|            0|            0|  0.00%|                      "channel-wise dropout behavior, please switch to using dropout1d instead.")
  1343|         0|            0|            0|  0.00%|
  1344|         0|            0|            0|  0.00%|    result = _VF.feature_dropout_(input, p, training) if inplace else _VF.feature_dropout(input, p, training)
  1345|         0|            0|            0|  0.00%|
  1346|         0|            0|            0|  0.00%|    return result
  1347|         0|            0|            0|  0.00%|
  1348|         0|            0|            0|  0.00%|
  1349|         0|            0|            0|  0.00%|def dropout3d(input: Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> Tensor:
  1350|         0|            0|            0|  0.00%|    r"""
  1351|         0|            0|            0|  0.00%|    Randomly zero out entire channels (a channel is a 3D feature map,
  1352|         0|            0|            0|  0.00%|    e.g., the :math:`j`-th channel of the :math:`i`-th sample in the
  1353|         0|            0|            0|  0.00%|    batched input is a 3D tensor :math:`\text{input}[i, j]`) of the input tensor).
  1354|         0|            0|            0|  0.00%|    Each channel will be zeroed out independently on every forward call with
  1355|         0|            0|            0|  0.00%|    probability :attr:`p` using samples from a Bernoulli distribution.
  1356|         0|            0|            0|  0.00%|
  1357|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Dropout3d` for details.
  1358|         0|            0|            0|  0.00%|
  1359|         0|            0|            0|  0.00%|    Args:
  1360|         0|            0|            0|  0.00%|        p: probability of a channel to be zeroed. Default: 0.5
  1361|         0|            0|            0|  0.00%|        training: apply dropout if is ``True``. Default: ``True``
  1362|         0|            0|            0|  0.00%|        inplace: If set to ``True``, will do this operation in-place. Default: ``False``
  1363|         0|            0|            0|  0.00%|    """
  1364|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1365|         0|            0|            0|  0.00%|        return handle_torch_function(dropout3d, (input,), input, p=p, training=training, inplace=inplace)
  1366|         0|            0|            0|  0.00%|    if p < 0.0 or p > 1.0:
  1367|         0|            0|            0|  0.00%|        raise ValueError("dropout probability has to be between 0 and 1, " "but got {}".format(p))
  1368|         0|            0|            0|  0.00%|    inp_dim = input.dim()
  1369|         0|            0|            0|  0.00%|    if inp_dim not in (4, 5):
  1370|         0|            0|            0|  0.00%|        warn_msg = (f"dropout3d: Received a {inp_dim}-D input to dropout3d, which is deprecated "
  1371|         0|            0|            0|  0.00%|                    "and will result in an error in a future release. To retain the behavior "
  1372|         0|            0|            0|  0.00%|                    "and silence this warning, please use dropout instead. Note that dropout3d "
  1373|         0|            0|            0|  0.00%|                    "exists to provide channel-wise dropout on inputs with 3 spatial dimensions, "
  1374|         0|            0|            0|  0.00%|                    "a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).")
  1375|         0|            0|            0|  0.00%|        warnings.warn(warn_msg)
  1376|         0|            0|            0|  0.00%|
  1377|         0|            0|            0|  0.00%|    is_batched = inp_dim == 5
  1378|         0|            0|            0|  0.00%|    if not is_batched:
  1379|         0|            0|            0|  0.00%|        input = input.unsqueeze_(0) if inplace else input.unsqueeze(0)
  1380|         0|            0|            0|  0.00%|
  1381|         0|            0|            0|  0.00%|    result = _VF.feature_dropout_(input, p, training) if inplace else _VF.feature_dropout(input, p, training)
  1382|         0|            0|            0|  0.00%|
  1383|         0|            0|            0|  0.00%|    if not is_batched:
  1384|         0|            0|            0|  0.00%|        result = result.squeeze_(0) if inplace else result.squeeze(0)
  1385|         0|            0|            0|  0.00%|    return result
  1386|         0|            0|            0|  0.00%|
  1387|         0|            0|            0|  0.00%|
  1388|         0|            0|            0|  0.00%|def feature_alpha_dropout(input: Tensor, p: float = 0.5, training: bool = False, inplace: bool = False) -> Tensor:
  1389|         0|            0|            0|  0.00%|    r"""
  1390|         0|            0|            0|  0.00%|    Randomly masks out entire channels (a channel is a feature map,
  1391|         0|            0|            0|  0.00%|    e.g. the :math:`j`-th channel of the :math:`i`-th sample in the batch input
  1392|         0|            0|            0|  0.00%|    is a tensor :math:`\text{input}[i, j]`) of the input tensor). Instead of
  1393|         0|            0|            0|  0.00%|    setting activations to zero, as in regular Dropout, the activations are set
  1394|         0|            0|            0|  0.00%|    to the negative saturation value of the SELU activation function.
  1395|         0|            0|            0|  0.00%|
  1396|         0|            0|            0|  0.00%|    Each element will be masked independently on every forward call with
  1397|         0|            0|            0|  0.00%|    probability :attr:`p` using samples from a Bernoulli distribution.
  1398|         0|            0|            0|  0.00%|    The elements to be masked are randomized on every forward call, and scaled
  1399|         0|            0|            0|  0.00%|    and shifted to maintain zero mean and unit variance.
  1400|         0|            0|            0|  0.00%|
  1401|         0|            0|            0|  0.00%|    See :class:`~torch.nn.FeatureAlphaDropout` for details.
  1402|         0|            0|            0|  0.00%|
  1403|         0|            0|            0|  0.00%|    Args:
  1404|         0|            0|            0|  0.00%|        p: dropout probability of a channel to be zeroed. Default: 0.5
  1405|         0|            0|            0|  0.00%|        training: apply dropout if is ``True``. Default: ``True``
  1406|         0|            0|            0|  0.00%|        inplace: If set to ``True``, will do this operation in-place. Default: ``False``
  1407|         0|            0|            0|  0.00%|    """
  1408|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1409|         0|            0|            0|  0.00%|        return handle_torch_function(
  1410|         0|            0|            0|  0.00%|            feature_alpha_dropout, (input,), input, p=p, training=training, inplace=inplace
  1411|         0|            0|            0|  0.00%|        )
  1412|         0|            0|            0|  0.00%|    if p < 0.0 or p > 1.0:
  1413|         0|            0|            0|  0.00%|        raise ValueError("dropout probability has to be between 0 and 1, " "but got {}".format(p))
  1414|         0|            0|            0|  0.00%|    return _VF.feature_alpha_dropout_(input, p, training) if inplace else _VF.feature_alpha_dropout(input, p, training)
  1415|         0|            0|            0|  0.00%|
  1416|         0|            0|            0|  0.00%|
  1417|         0|            0|            0|  0.00%|def _threshold(input: Tensor, threshold: float, value: float, inplace: bool = False) -> Tensor:
  1418|         0|            0|            0|  0.00%|    r"""Thresholds each element of the input Tensor.
  1419|         0|            0|            0|  0.00%|
  1420|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Threshold` for more details.
  1421|         0|            0|            0|  0.00%|    """
  1422|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1423|         0|            0|            0|  0.00%|        return handle_torch_function(_threshold, (input,), input, threshold, value, inplace=inplace)
  1424|         0|            0|            0|  0.00%|    if inplace:
  1425|         0|            0|            0|  0.00%|        result = _VF.threshold_(input, threshold, value)
  1426|         0|            0|            0|  0.00%|    else:
  1427|         0|            0|            0|  0.00%|        result = _VF.threshold(input, threshold, value)
  1428|         0|            0|            0|  0.00%|    return result
  1429|         0|            0|            0|  0.00%|
  1430|         0|            0|            0|  0.00%|
  1431|         0|            0|            0|  0.00%|# We define this function as _threshold because it takes an argument
  1432|         0|            0|            0|  0.00%|# named threshold, which clobbers the recursive reference to the
  1433|         0|            0|            0|  0.00%|# function needed for __torch_function__ support
  1434|         0|            0|            0|  0.00%|threshold = _threshold
  1435|         0|            0|            0|  0.00%|
  1436|         0|            0|            0|  0.00%|threshold_ = _add_docstr(
  1437|         0|            0|            0|  0.00%|    _VF.threshold_,
  1438|         0|            0|            0|  0.00%|    r"""
  1439|         0|            0|            0|  0.00%|threshold_(input, threshold, value) -> Tensor
  1440|         0|            0|            0|  0.00%|
  1441|         0|            0|            0|  0.00%|In-place version of :func:`~threshold`.
  1442|         0|            0|            0|  0.00%|""",
  1443|         0|            0|            0|  0.00%|)
  1444|         0|            0|            0|  0.00%|
  1445|         0|            0|            0|  0.00%|
  1446|         0|            0|            0|  0.00%|def relu(input: Tensor, inplace: bool = False) -> Tensor:
  1447|         0|            0|            0|  0.00%|    r"""relu(input, inplace=False) -> Tensor
  1448|         0|            0|            0|  0.00%|
  1449|         0|            0|            0|  0.00%|    Applies the rectified linear unit function element-wise. See
  1450|         0|            0|            0|  0.00%|    :class:`~torch.nn.ReLU` for more details.
  1451|         0|            0|            0|  0.00%|    """
  1452|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1453|         0|            0|            0|  0.00%|        return handle_torch_function(relu, (input,), input, inplace=inplace)
  1454|         0|            0|            0|  0.00%|    if inplace:
  1455|         0|            0|            0|  0.00%|        result = torch.relu_(input)
  1456|         0|            0|            0|  0.00%|    else:
  1457|         0|            0|            0|  0.00%|        result = torch.relu(input)
  1458|         0|            0|            0|  0.00%|    return result
  1459|         0|            0|            0|  0.00%|
  1460|         0|            0|            0|  0.00%|
  1461|         0|            0|            0|  0.00%|relu_ = _add_docstr(
  1462|         0|            0|            0|  0.00%|    torch.relu_,
  1463|         0|            0|            0|  0.00%|    r"""
  1464|         0|            0|            0|  0.00%|relu_(input) -> Tensor
  1465|         0|            0|            0|  0.00%|
  1466|         0|            0|            0|  0.00%|In-place version of :func:`~relu`.
  1467|         0|            0|            0|  0.00%|""",
  1468|         0|            0|            0|  0.00%|)
  1469|         0|            0|            0|  0.00%|
  1470|         0|            0|            0|  0.00%|
  1471|         0|            0|            0|  0.00%|def glu(input: Tensor, dim: int = -1) -> Tensor:
  1472|         0|            0|            0|  0.00%|    r"""
  1473|         0|            0|            0|  0.00%|    glu(input, dim=-1) -> Tensor
  1474|         0|            0|            0|  0.00%|
  1475|         0|            0|            0|  0.00%|    The gated linear unit. Computes:
  1476|         0|            0|            0|  0.00%|
  1477|         0|            0|            0|  0.00%|    .. math ::
  1478|         0|            0|            0|  0.00%|        \text{GLU}(a, b) = a \otimes \sigma(b)
  1479|         0|            0|            0|  0.00%|
  1480|         0|            0|            0|  0.00%|    where `input` is split in half along `dim` to form `a` and `b`, :math:`\sigma`
  1481|         0|            0|            0|  0.00%|    is the sigmoid function and :math:`\otimes` is the element-wise product between matrices.
  1482|         0|            0|            0|  0.00%|
  1483|         0|            0|            0|  0.00%|    See `Language Modeling with Gated Convolutional Networks <https://arxiv.org/abs/1612.08083>`_.
  1484|         0|            0|            0|  0.00%|
  1485|         0|            0|            0|  0.00%|    Args:
  1486|         0|            0|            0|  0.00%|        input (Tensor): input tensor
  1487|         0|            0|            0|  0.00%|        dim (int): dimension on which to split the input. Default: -1
  1488|         0|            0|            0|  0.00%|    """
  1489|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1490|         0|            0|            0|  0.00%|        return handle_torch_function(glu, (input,), input, dim=dim)
  1491|         0|            0|            0|  0.00%|    if input.dim() == 0:
  1492|         0|            0|            0|  0.00%|        raise RuntimeError("glu does not support scalars because halving size must be even")
  1493|         0|            0|            0|  0.00%|    return torch._C._nn.glu(input, dim)
  1494|         0|            0|            0|  0.00%|
  1495|         0|            0|            0|  0.00%|
  1496|         0|            0|            0|  0.00%|def hardtanh(input: Tensor, min_val: float = -1., max_val: float = 1., inplace: bool = False) -> Tensor:
  1497|         0|            0|            0|  0.00%|    r"""
  1498|         0|            0|            0|  0.00%|    hardtanh(input, min_val=-1., max_val=1., inplace=False) -> Tensor
  1499|         0|            0|            0|  0.00%|
  1500|         0|            0|            0|  0.00%|    Applies the HardTanh function element-wise. See :class:`~torch.nn.Hardtanh` for more
  1501|         0|            0|            0|  0.00%|    details.
  1502|         0|            0|            0|  0.00%|    """
  1503|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1504|         0|            0|            0|  0.00%|        return handle_torch_function(hardtanh, (input,), input, min_val=min_val, max_val=max_val, inplace=inplace)
  1505|         0|            0|            0|  0.00%|    if inplace:
  1506|         0|            0|            0|  0.00%|        result = torch._C._nn.hardtanh_(input, min_val, max_val)
  1507|         0|            0|            0|  0.00%|    else:
  1508|         0|            0|            0|  0.00%|        result = torch._C._nn.hardtanh(input, min_val, max_val)
  1509|         0|            0|            0|  0.00%|    return result
  1510|         0|            0|            0|  0.00%|
  1511|         0|            0|            0|  0.00%|
  1512|         0|            0|            0|  0.00%|hardtanh_ = _add_docstr(
  1513|         0|            0|            0|  0.00%|    torch._C._nn.hardtanh_,
  1514|         0|            0|            0|  0.00%|    r"""
  1515|         0|            0|            0|  0.00%|hardtanh_(input, min_val=-1., max_val=1.) -> Tensor
  1516|         0|            0|            0|  0.00%|
  1517|         0|            0|            0|  0.00%|In-place version of :func:`~hardtanh`.
  1518|         0|            0|            0|  0.00%|""",
  1519|         0|            0|            0|  0.00%|)
  1520|         0|            0|            0|  0.00%|
  1521|         0|            0|            0|  0.00%|
  1522|         0|            0|            0|  0.00%|def relu6(input: Tensor, inplace: bool = False) -> Tensor:
  1523|         0|            0|            0|  0.00%|    r"""relu6(input, inplace=False) -> Tensor
  1524|         0|            0|            0|  0.00%|
  1525|         0|            0|            0|  0.00%|    Applies the element-wise function :math:`\text{ReLU6}(x) = \min(\max(0,x), 6)`.
  1526|         0|            0|            0|  0.00%|
  1527|         0|            0|            0|  0.00%|    See :class:`~torch.nn.ReLU6` for more details.
  1528|         0|            0|            0|  0.00%|    """
  1529|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1530|         0|            0|            0|  0.00%|        return handle_torch_function(relu6, (input,), input, inplace=inplace)
  1531|         0|            0|            0|  0.00%|    if inplace:
  1532|         0|            0|            0|  0.00%|        result = torch._C._nn.relu6_(input)
  1533|         0|            0|            0|  0.00%|    else:
  1534|         0|            0|            0|  0.00%|        result = torch._C._nn.relu6(input)
  1535|         0|            0|            0|  0.00%|    return result
  1536|         0|            0|            0|  0.00%|
  1537|         0|            0|            0|  0.00%|
  1538|         0|            0|            0|  0.00%|def elu(input: Tensor, alpha: float = 1.0, inplace: bool = False) -> Tensor:
  1539|         0|            0|            0|  0.00%|    r"""Applies element-wise,
  1540|         0|            0|            0|  0.00%|    :math:`\text{ELU}(x) = \max(0,x) + \min(0, \alpha * (\exp(x) - 1))`.
  1541|         0|            0|            0|  0.00%|
  1542|         0|            0|            0|  0.00%|    See :class:`~torch.nn.ELU` for more details.
  1543|         0|            0|            0|  0.00%|    """
  1544|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1545|         0|            0|            0|  0.00%|        return handle_torch_function(elu, (input,), input, alpha=alpha, inplace=inplace)
  1546|         0|            0|            0|  0.00%|    if inplace:
  1547|         0|            0|            0|  0.00%|        result = torch._C._nn.elu_(input, alpha)
  1548|         0|            0|            0|  0.00%|    else:
  1549|         0|            0|            0|  0.00%|        result = torch._C._nn.elu(input, alpha)
  1550|         0|            0|            0|  0.00%|    return result
  1551|         0|            0|            0|  0.00%|
  1552|         0|            0|            0|  0.00%|
  1553|         0|            0|            0|  0.00%|elu_ = _add_docstr(
  1554|         0|            0|            0|  0.00%|    torch._C._nn.elu_,
  1555|         0|            0|            0|  0.00%|    r"""
  1556|         0|            0|            0|  0.00%|elu_(input, alpha=1.) -> Tensor
  1557|         0|            0|            0|  0.00%|
  1558|         0|            0|            0|  0.00%|In-place version of :func:`~elu`.
  1559|         0|            0|            0|  0.00%|""",
  1560|         0|            0|            0|  0.00%|)
  1561|         0|            0|            0|  0.00%|
  1562|         0|            0|            0|  0.00%|
  1563|         0|            0|            0|  0.00%|def selu(input: Tensor, inplace: bool = False) -> Tensor:
  1564|         0|            0|            0|  0.00%|    r"""selu(input, inplace=False) -> Tensor
  1565|         0|            0|            0|  0.00%|
  1566|         0|            0|            0|  0.00%|    Applies element-wise,
  1567|         0|            0|            0|  0.00%|    :math:`\text{SELU}(x) = scale * (\max(0,x) + \min(0, \alpha * (\exp(x) - 1)))`,
  1568|         0|            0|            0|  0.00%|    with :math:`\alpha=1.6732632423543772848170429916717` and
  1569|         0|            0|            0|  0.00%|    :math:`scale=1.0507009873554804934193349852946`.
  1570|         0|            0|            0|  0.00%|
  1571|         0|            0|            0|  0.00%|    See :class:`~torch.nn.SELU` for more details.
  1572|         0|            0|            0|  0.00%|    """
  1573|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1574|         0|            0|            0|  0.00%|        return handle_torch_function(selu, (input,), input, inplace=inplace)
  1575|         0|            0|            0|  0.00%|    if inplace:
  1576|         0|            0|            0|  0.00%|        result = torch.selu_(input)
  1577|         0|            0|            0|  0.00%|    else:
  1578|         0|            0|            0|  0.00%|        result = torch.selu(input)
  1579|         0|            0|            0|  0.00%|    return result
  1580|         0|            0|            0|  0.00%|
  1581|         0|            0|            0|  0.00%|
  1582|         0|            0|            0|  0.00%|selu_ = _add_docstr(
  1583|         0|            0|            0|  0.00%|    torch.selu_,
  1584|         0|            0|            0|  0.00%|    r"""
  1585|         0|            0|            0|  0.00%|selu_(input) -> Tensor
  1586|         0|            0|            0|  0.00%|
  1587|         0|            0|            0|  0.00%|In-place version of :func:`~selu`.
  1588|         0|            0|            0|  0.00%|""",
  1589|         0|            0|            0|  0.00%|)
  1590|         0|            0|            0|  0.00%|
  1591|         0|            0|            0|  0.00%|
  1592|         0|            0|            0|  0.00%|def celu(input: Tensor, alpha: float = 1.0, inplace: bool = False) -> Tensor:
  1593|         0|            0|            0|  0.00%|    r"""celu(input, alpha=1., inplace=False) -> Tensor
  1594|         0|            0|            0|  0.00%|
  1595|         0|            0|            0|  0.00%|    Applies element-wise,
  1596|         0|            0|            0|  0.00%|    :math:`\text{CELU}(x) = \max(0,x) + \min(0, \alpha * (\exp(x/\alpha) - 1))`.
  1597|         0|            0|            0|  0.00%|
  1598|         0|            0|            0|  0.00%|    See :class:`~torch.nn.CELU` for more details.
  1599|         0|            0|            0|  0.00%|    """
  1600|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1601|         0|            0|            0|  0.00%|        return handle_torch_function(celu, (input,), input, alpha=alpha, inplace=inplace)
  1602|         0|            0|            0|  0.00%|    if inplace:
  1603|         0|            0|            0|  0.00%|        result = torch.celu_(input, alpha)
  1604|         0|            0|            0|  0.00%|    else:
  1605|         0|            0|            0|  0.00%|        result = torch.celu(input, alpha)
  1606|         0|            0|            0|  0.00%|    return result
  1607|         0|            0|            0|  0.00%|
  1608|         0|            0|            0|  0.00%|
  1609|         0|            0|            0|  0.00%|celu_ = _add_docstr(
  1610|         0|            0|            0|  0.00%|    torch.celu_,
  1611|         0|            0|            0|  0.00%|    r"""
  1612|         0|            0|            0|  0.00%|celu_(input, alpha=1.) -> Tensor
  1613|         0|            0|            0|  0.00%|
  1614|         0|            0|            0|  0.00%|In-place version of :func:`~celu`.
  1615|         0|            0|            0|  0.00%|""",
  1616|         0|            0|            0|  0.00%|)
  1617|         0|            0|            0|  0.00%|
  1618|         0|            0|            0|  0.00%|
  1619|         0|            0|            0|  0.00%|def leaky_relu(input: Tensor, negative_slope: float = 0.01, inplace: bool = False) -> Tensor:
  1620|         0|            0|            0|  0.00%|    r"""
  1621|         0|            0|            0|  0.00%|    leaky_relu(input, negative_slope=0.01, inplace=False) -> Tensor
  1622|         0|            0|            0|  0.00%|
  1623|         0|            0|            0|  0.00%|    Applies element-wise,
  1624|         0|            0|            0|  0.00%|    :math:`\text{LeakyReLU}(x) = \max(0, x) + \text{negative\_slope} * \min(0, x)`
  1625|         0|            0|            0|  0.00%|
  1626|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LeakyReLU` for more details.
  1627|         0|            0|            0|  0.00%|    """
  1628|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1629|         0|            0|            0|  0.00%|        return handle_torch_function(leaky_relu, (input,), input, negative_slope=negative_slope, inplace=inplace)
  1630|         0|            0|            0|  0.00%|    if inplace:
  1631|         0|            0|            0|  0.00%|        result = torch._C._nn.leaky_relu_(input, negative_slope)
  1632|         0|            0|            0|  0.00%|    else:
  1633|         0|            0|            0|  0.00%|        result = torch._C._nn.leaky_relu(input, negative_slope)
  1634|         0|            0|            0|  0.00%|    return result
  1635|         0|            0|            0|  0.00%|
  1636|         0|            0|            0|  0.00%|
  1637|         0|            0|            0|  0.00%|leaky_relu_ = _add_docstr(
  1638|         0|            0|            0|  0.00%|    torch._C._nn.leaky_relu_,
  1639|         0|            0|            0|  0.00%|    r"""
  1640|         0|            0|            0|  0.00%|leaky_relu_(input, negative_slope=0.01) -> Tensor
  1641|         0|            0|            0|  0.00%|
  1642|         0|            0|            0|  0.00%|In-place version of :func:`~leaky_relu`.
  1643|         0|            0|            0|  0.00%|""",
  1644|         0|            0|            0|  0.00%|)
  1645|         0|            0|            0|  0.00%|
  1646|         0|            0|            0|  0.00%|
  1647|         0|            0|            0|  0.00%|prelu = _add_docstr(
  1648|         0|            0|            0|  0.00%|    torch.prelu,
  1649|         0|            0|            0|  0.00%|    r"""prelu(input, weight) -> Tensor
  1650|         0|            0|            0|  0.00%|
  1651|         0|            0|            0|  0.00%|Applies element-wise the function
  1652|         0|            0|            0|  0.00%|:math:`\text{PReLU}(x) = \max(0,x) + \text{weight} * \min(0,x)` where weight is a
  1653|         0|            0|            0|  0.00%|learnable parameter.
  1654|         0|            0|            0|  0.00%|
  1655|         0|            0|            0|  0.00%|See :class:`~torch.nn.PReLU` for more details.
  1656|         0|            0|            0|  0.00%|""")
  1657|         0|            0|            0|  0.00%|
  1658|         0|            0|            0|  0.00%|
  1659|         0|            0|            0|  0.00%|def rrelu(
  1660|         0|            0|            0|  0.00%|    input: Tensor, lower: float = 1.0 / 8, upper: float = 1.0 / 3, training: bool = False, inplace: bool = False
  1661|         0|            0|            0|  0.00%|) -> Tensor:
  1662|         0|            0|            0|  0.00%|    r"""rrelu(input, lower=1./8, upper=1./3, training=False, inplace=False) -> Tensor
  1663|         0|            0|            0|  0.00%|
  1664|         0|            0|            0|  0.00%|    Randomized leaky ReLU.
  1665|         0|            0|            0|  0.00%|
  1666|         0|            0|            0|  0.00%|    See :class:`~torch.nn.RReLU` for more details.
  1667|         0|            0|            0|  0.00%|    """
  1668|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1669|         0|            0|            0|  0.00%|        return handle_torch_function(
  1670|         0|            0|            0|  0.00%|            rrelu, (input,), input, lower=lower, upper=upper, training=training, inplace=inplace
  1671|         0|            0|            0|  0.00%|        )
  1672|         0|            0|            0|  0.00%|    if inplace:
  1673|         0|            0|            0|  0.00%|        result = torch.rrelu_(input, lower, upper, training)
  1674|         0|            0|            0|  0.00%|    else:
  1675|         0|            0|            0|  0.00%|        result = torch.rrelu(input, lower, upper, training)
  1676|         0|            0|            0|  0.00%|    return result
  1677|         0|            0|            0|  0.00%|
  1678|         0|            0|            0|  0.00%|
  1679|         0|            0|            0|  0.00%|rrelu_ = _add_docstr(
  1680|         0|            0|            0|  0.00%|    torch.rrelu_,
  1681|         0|            0|            0|  0.00%|    r"""
  1682|         0|            0|            0|  0.00%|rrelu_(input, lower=1./8, upper=1./3, training=False) -> Tensor
  1683|         0|            0|            0|  0.00%|
  1684|         0|            0|            0|  0.00%|In-place version of :func:`~rrelu`.
  1685|         0|            0|            0|  0.00%|""",
  1686|         0|            0|            0|  0.00%|)
  1687|         0|            0|            0|  0.00%|
  1688|         0|            0|            0|  0.00%|logsigmoid = _add_docstr(
  1689|         0|            0|            0|  0.00%|    torch._C._nn.log_sigmoid,
  1690|         0|            0|            0|  0.00%|    r"""
  1691|         0|            0|            0|  0.00%|logsigmoid(input) -> Tensor
  1692|         0|            0|            0|  0.00%|
  1693|         0|            0|            0|  0.00%|Applies element-wise :math:`\text{LogSigmoid}(x_i) = \log \left(\frac{1}{1 + \exp(-x_i)}\right)`
  1694|         0|            0|            0|  0.00%|
  1695|         0|            0|            0|  0.00%|See :class:`~torch.nn.LogSigmoid` for more details.
  1696|         0|            0|            0|  0.00%|""",
  1697|         0|            0|            0|  0.00%|)
  1698|         0|            0|            0|  0.00%|
  1699|         0|            0|            0|  0.00%|gelu = _add_docstr(
  1700|         0|            0|            0|  0.00%|    torch._C._nn.gelu,
  1701|         0|            0|            0|  0.00%|    r"""
  1702|         0|            0|            0|  0.00%|gelu(input, approximate = 'none') -> Tensor
  1703|         0|            0|            0|  0.00%|
  1704|         0|            0|            0|  0.00%|When the approximate argument is 'none', it applies element-wise the function
  1705|         0|            0|            0|  0.00%|:math:`\text{GELU}(x) = x * \Phi(x)`
  1706|         0|            0|            0|  0.00%|
  1707|         0|            0|            0|  0.00%|where :math:`\Phi(x)` is the Cumulative Distribution Function for Gaussian Distribution.
  1708|         0|            0|            0|  0.00%|
  1709|         0|            0|            0|  0.00%|When the approximate argument is 'tanh', Gelu is estimated with:
  1710|         0|            0|            0|  0.00%|    :math::  \text{GELU}(x) = 0.5 * x * (1 + \text{Tanh}(\sqrt(2 / \pi) * (x + 0.044715 * x^3)))
  1711|         0|            0|            0|  0.00%|
  1712|         0|            0|            0|  0.00%|See `Gaussian Error Linear Units (GELUs) <https://arxiv.org/abs/1606.08415>`_.
  1713|         0|            0|            0|  0.00%|""")
  1714|         0|            0|            0|  0.00%|
  1715|         0|            0|            0|  0.00%|hardshrink = _add_docstr(
  1716|         0|            0|            0|  0.00%|    torch.hardshrink,
  1717|         0|            0|            0|  0.00%|    r"""
  1718|         0|            0|            0|  0.00%|hardshrink(input, lambd=0.5) -> Tensor
  1719|         0|            0|            0|  0.00%|
  1720|         0|            0|            0|  0.00%|Applies the hard shrinkage function element-wise
  1721|         0|            0|            0|  0.00%|
  1722|         0|            0|            0|  0.00%|See :class:`~torch.nn.Hardshrink` for more details.
  1723|         0|            0|            0|  0.00%|""")
  1724|         0|            0|            0|  0.00%|
  1725|         0|            0|            0|  0.00%|
  1726|         0|            0|            0|  0.00%|def tanhshrink(input):
  1727|         0|            0|            0|  0.00%|    r"""tanhshrink(input) -> Tensor
  1728|         0|            0|            0|  0.00%|
  1729|         0|            0|            0|  0.00%|    Applies element-wise, :math:`\text{Tanhshrink}(x) = x - \text{Tanh}(x)`
  1730|         0|            0|            0|  0.00%|
  1731|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Tanhshrink` for more details.
  1732|         0|            0|            0|  0.00%|    """
  1733|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1734|         0|            0|            0|  0.00%|        return handle_torch_function(tanhshrink, (input,), input)
  1735|         0|            0|            0|  0.00%|    return input - input.tanh()
  1736|         0|            0|            0|  0.00%|
  1737|         0|            0|            0|  0.00%|
  1738|         0|            0|            0|  0.00%|def softsign(input):
  1739|         0|            0|            0|  0.00%|    r"""softsign(input) -> Tensor
  1740|         0|            0|            0|  0.00%|
  1741|         0|            0|            0|  0.00%|    Applies element-wise, the function :math:`\text{SoftSign}(x) = \frac{x}{1 + |x|}`
  1742|         0|            0|            0|  0.00%|
  1743|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Softsign` for more details.
  1744|         0|            0|            0|  0.00%|    """
  1745|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1746|         0|            0|            0|  0.00%|        return handle_torch_function(softsign, (input,), input)
  1747|         0|            0|            0|  0.00%|    return input / (input.abs() + 1)
  1748|         0|            0|            0|  0.00%|
  1749|         0|            0|            0|  0.00%|
  1750|         0|            0|            0|  0.00%|softplus = _add_docstr(
  1751|         0|            0|            0|  0.00%|    torch._C._nn.softplus,
  1752|         0|            0|            0|  0.00%|    r"""
  1753|         0|            0|            0|  0.00%|softplus(input, beta=1, threshold=20) -> Tensor
  1754|         0|            0|            0|  0.00%|
  1755|         0|            0|            0|  0.00%|Applies element-wise, the function :math:`\text{Softplus}(x) = \frac{1}{\beta} * \log(1 + \exp(\beta * x))`.
  1756|         0|            0|            0|  0.00%|
  1757|         0|            0|            0|  0.00%|For numerical stability the implementation reverts to the linear function
  1758|         0|            0|            0|  0.00%|when :math:`input \times \beta > threshold`.
  1759|         0|            0|            0|  0.00%|
  1760|         0|            0|            0|  0.00%|See :class:`~torch.nn.Softplus` for more details.
  1761|         0|            0|            0|  0.00%|""",
  1762|         0|            0|            0|  0.00%|)
  1763|         0|            0|            0|  0.00%|
  1764|         0|            0|            0|  0.00%|
  1765|         0|            0|            0|  0.00%|def _get_softmax_dim(name: str, ndim: int, stacklevel: int) -> int:
  1766|         0|            0|            0|  0.00%|    warnings.warn(
  1767|         0|            0|            0|  0.00%|        "Implicit dimension choice for {} has been deprecated. "
  1768|         0|            0|            0|  0.00%|        "Change the call to include dim=X as an argument.".format(name),
  1769|         0|            0|            0|  0.00%|        stacklevel=stacklevel,
  1770|         0|            0|            0|  0.00%|    )
  1771|         0|            0|            0|  0.00%|    if ndim == 0 or ndim == 1 or ndim == 3:
  1772|         0|            0|            0|  0.00%|        ret = 0
  1773|         0|            0|            0|  0.00%|    else:
  1774|         0|            0|            0|  0.00%|        ret = 1
  1775|         0|            0|            0|  0.00%|    return ret
  1776|         0|            0|            0|  0.00%|
  1777|         0|            0|            0|  0.00%|
  1778|         0|            0|            0|  0.00%|def softmin(input: Tensor, dim: Optional[int] = None, _stacklevel: int = 3, dtype: Optional[DType] = None) -> Tensor:
  1779|         0|            0|            0|  0.00%|    r"""Applies a softmin function.
  1780|         0|            0|            0|  0.00%|
  1781|         0|            0|            0|  0.00%|    Note that :math:`\text{Softmin}(x) = \text{Softmax}(-x)`. See softmax definition for mathematical formula.
  1782|         0|            0|            0|  0.00%|
  1783|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Softmin` for more details.
  1784|         0|            0|            0|  0.00%|
  1785|         0|            0|            0|  0.00%|    Args:
  1786|         0|            0|            0|  0.00%|        input (Tensor): input
  1787|         0|            0|            0|  0.00%|        dim (int): A dimension along which softmin will be computed (so every slice
  1788|         0|            0|            0|  0.00%|            along dim will sum to 1).
  1789|         0|            0|            0|  0.00%|        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.
  1790|         0|            0|            0|  0.00%|          If specified, the input tensor is casted to :attr:`dtype` before the operation
  1791|         0|            0|            0|  0.00%|          is performed. This is useful for preventing data type overflows. Default: None.
  1792|         0|            0|            0|  0.00%|    """
  1793|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1794|         0|            0|            0|  0.00%|        return handle_torch_function(softmin, (input,), input, dim=dim, _stacklevel=_stacklevel, dtype=dtype)
  1795|         0|            0|            0|  0.00%|    if dim is None:
  1796|         0|            0|            0|  0.00%|        dim = _get_softmax_dim("softmin", input.dim(), _stacklevel)
  1797|         0|            0|            0|  0.00%|    if dtype is None:
  1798|         0|            0|            0|  0.00%|        ret = (-input).softmax(dim)
  1799|         0|            0|            0|  0.00%|    else:
  1800|         0|            0|            0|  0.00%|        ret = (-input).softmax(dim, dtype=dtype)
  1801|         0|            0|            0|  0.00%|    return ret
  1802|         0|            0|            0|  0.00%|
  1803|         0|            0|            0|  0.00%|
  1804|      2610|   0.00619221|  2.37249e-06|  0.01%|def softmax(input: Tensor, dim: Optional[int] = None, _stacklevel: int = 3, dtype: Optional[DType] = None) -> Tensor:
  1805|         0|            0|            0|  0.00%|    r"""Applies a softmax function.
  1806|         0|            0|            0|  0.00%|
  1807|         0|            0|            0|  0.00%|    Softmax is defined as:
  1808|         0|            0|            0|  0.00%|
  1809|         0|            0|            0|  0.00%|    :math:`\text{Softmax}(x_{i}) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}`
  1810|         0|            0|            0|  0.00%|
  1811|         0|            0|            0|  0.00%|    It is applied to all slices along dim, and will re-scale them so that the elements
  1812|         0|            0|            0|  0.00%|    lie in the range `[0, 1]` and sum to 1.
  1813|         0|            0|            0|  0.00%|
  1814|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Softmax` for more details.
  1815|         0|            0|            0|  0.00%|
  1816|         0|            0|            0|  0.00%|    Args:
  1817|         0|            0|            0|  0.00%|        input (Tensor): input
  1818|         0|            0|            0|  0.00%|        dim (int): A dimension along which softmax will be computed.
  1819|         0|            0|            0|  0.00%|        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.
  1820|         0|            0|            0|  0.00%|          If specified, the input tensor is casted to :attr:`dtype` before the operation
  1821|         0|            0|            0|  0.00%|          is performed. This is useful for preventing data type overflows. Default: None.
  1822|         0|            0|            0|  0.00%|
  1823|         0|            0|            0|  0.00%|    .. note::
  1824|         0|            0|            0|  0.00%|        This function doesn't work directly with NLLLoss,
  1825|         0|            0|            0|  0.00%|        which expects the Log to be computed between the Softmax and itself.
  1826|         0|            0|            0|  0.00%|        Use log_softmax instead (it's faster and has better numerical properties).
  1827|         0|            0|            0|  0.00%|
  1828|         0|            0|            0|  0.00%|    """
  1829|      2610|   0.00793171|  3.03897e-06|  0.01%|    if has_torch_function_unary(input):
  1830|         0|            0|            0|  0.00%|        return handle_torch_function(softmax, (input,), input, dim=dim, _stacklevel=_stacklevel, dtype=dtype)
  1831|      2610|   0.00627184|    2.403e-06|  0.01%|    if dim is None:
  1832|         0|            0|            0|  0.00%|        dim = _get_softmax_dim("softmax", input.dim(), _stacklevel)
  1833|      2610|   0.00588059|   2.2531e-06|  0.01%|    if dtype is None:
  1834|      2610|    0.0364566|   1.3968e-05|  0.03%|        ret = input.softmax(dim)
  1835|         0|            0|            0|  0.00%|    else:
  1836|         0|            0|            0|  0.00%|        ret = input.softmax(dim, dtype=dtype)
  1837|      2610|   0.00652003|   2.4981e-06|  0.01%|    return ret
  1838|         0|            0|            0|  0.00%|
  1839|         0|            0|            0|  0.00%|
  1840|         0|            0|            0|  0.00%|def gumbel_softmax(logits: Tensor, tau: float = 1, hard: bool = False, eps: float = 1e-10, dim: int = -1) -> Tensor:
  1841|         0|            0|            0|  0.00%|    r"""
  1842|         0|            0|            0|  0.00%|    Samples from the Gumbel-Softmax distribution (`Link 1`_  `Link 2`_) and optionally discretizes.
  1843|         0|            0|            0|  0.00%|
  1844|         0|            0|            0|  0.00%|    Args:
  1845|         0|            0|            0|  0.00%|      logits: `[..., num_features]` unnormalized log probabilities
  1846|         0|            0|            0|  0.00%|      tau: non-negative scalar temperature
  1847|         0|            0|            0|  0.00%|      hard: if ``True``, the returned samples will be discretized as one-hot vectors,
  1848|         0|            0|            0|  0.00%|            but will be differentiated as if it is the soft sample in autograd
  1849|         0|            0|            0|  0.00%|      dim (int): A dimension along which softmax will be computed. Default: -1.
  1850|         0|            0|            0|  0.00%|
  1851|         0|            0|            0|  0.00%|    Returns:
  1852|         0|            0|            0|  0.00%|      Sampled tensor of same shape as `logits` from the Gumbel-Softmax distribution.
  1853|         0|            0|            0|  0.00%|      If ``hard=True``, the returned samples will be one-hot, otherwise they will
  1854|         0|            0|            0|  0.00%|      be probability distributions that sum to 1 across `dim`.
  1855|         0|            0|            0|  0.00%|
  1856|         0|            0|            0|  0.00%|    .. note::
  1857|         0|            0|            0|  0.00%|      This function is here for legacy reasons, may be removed from nn.Functional in the future.
  1858|         0|            0|            0|  0.00%|
  1859|         0|            0|            0|  0.00%|    .. note::
  1860|         0|            0|            0|  0.00%|      The main trick for `hard` is to do  `y_hard - y_soft.detach() + y_soft`
  1861|         0|            0|            0|  0.00%|
  1862|         0|            0|            0|  0.00%|      It achieves two things:
  1863|         0|            0|            0|  0.00%|      - makes the output value exactly one-hot
  1864|         0|            0|            0|  0.00%|      (since we add then subtract y_soft value)
  1865|         0|            0|            0|  0.00%|      - makes the gradient equal to y_soft gradient
  1866|         0|            0|            0|  0.00%|      (since we strip all other gradients)
  1867|         0|            0|            0|  0.00%|
  1868|         0|            0|            0|  0.00%|    Examples::
  1869|         0|            0|            0|  0.00%|        >>> logits = torch.randn(20, 32)
  1870|         0|            0|            0|  0.00%|        >>> # Sample soft categorical using reparametrization trick:
  1871|         0|            0|            0|  0.00%|        >>> F.gumbel_softmax(logits, tau=1, hard=False)
  1872|         0|            0|            0|  0.00%|        >>> # Sample hard categorical using "Straight-through" trick:
  1873|         0|            0|            0|  0.00%|        >>> F.gumbel_softmax(logits, tau=1, hard=True)
  1874|         0|            0|            0|  0.00%|
  1875|         0|            0|            0|  0.00%|    .. _Link 1:
  1876|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1611.00712
  1877|         0|            0|            0|  0.00%|    .. _Link 2:
  1878|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1611.01144
  1879|         0|            0|            0|  0.00%|    """
  1880|         0|            0|            0|  0.00%|    if has_torch_function_unary(logits):
  1881|         0|            0|            0|  0.00%|        return handle_torch_function(gumbel_softmax, (logits,), logits, tau=tau, hard=hard, eps=eps, dim=dim)
  1882|         0|            0|            0|  0.00%|    if eps != 1e-10:
  1883|         0|            0|            0|  0.00%|        warnings.warn("`eps` parameter is deprecated and has no effect.")
  1884|         0|            0|            0|  0.00%|
  1885|         0|            0|            0|  0.00%|    gumbels = (
  1886|         0|            0|            0|  0.00%|        -torch.empty_like(logits, memory_format=torch.legacy_contiguous_format).exponential_().log()
  1887|         0|            0|            0|  0.00%|    )  # ~Gumbel(0,1)
  1888|         0|            0|            0|  0.00%|    gumbels = (logits + gumbels) / tau  # ~Gumbel(logits,tau)
  1889|         0|            0|            0|  0.00%|    y_soft = gumbels.softmax(dim)
  1890|         0|            0|            0|  0.00%|
  1891|         0|            0|            0|  0.00%|    if hard:
  1892|         0|            0|            0|  0.00%|        # Straight through.
  1893|         0|            0|            0|  0.00%|        index = y_soft.max(dim, keepdim=True)[1]
  1894|         0|            0|            0|  0.00%|        y_hard = torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format).scatter_(dim, index, 1.0)
  1895|         0|            0|            0|  0.00%|        ret = y_hard - y_soft.detach() + y_soft
  1896|         0|            0|            0|  0.00%|    else:
  1897|         0|            0|            0|  0.00%|        # Reparametrization trick.
  1898|         0|            0|            0|  0.00%|        ret = y_soft
  1899|         0|            0|            0|  0.00%|    return ret
  1900|         0|            0|            0|  0.00%|
  1901|         0|            0|            0|  0.00%|
  1902|         0|            0|            0|  0.00%|def log_softmax(input: Tensor, dim: Optional[int] = None, _stacklevel: int = 3, dtype: Optional[DType] = None) -> Tensor:
  1903|         0|            0|            0|  0.00%|    r"""Applies a softmax followed by a logarithm.
  1904|         0|            0|            0|  0.00%|
  1905|         0|            0|            0|  0.00%|    While mathematically equivalent to log(softmax(x)), doing these two
  1906|         0|            0|            0|  0.00%|    operations separately is slower and numerically unstable. This function
  1907|         0|            0|            0|  0.00%|    uses an alternative formulation to compute the output and gradient correctly.
  1908|         0|            0|            0|  0.00%|
  1909|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LogSoftmax` for more details.
  1910|         0|            0|            0|  0.00%|
  1911|         0|            0|            0|  0.00%|    Args:
  1912|         0|            0|            0|  0.00%|        input (Tensor): input
  1913|         0|            0|            0|  0.00%|        dim (int): A dimension along which log_softmax will be computed.
  1914|         0|            0|            0|  0.00%|        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.
  1915|         0|            0|            0|  0.00%|          If specified, the input tensor is cast to :attr:`dtype` before the operation
  1916|         0|            0|            0|  0.00%|          is performed. This is useful for preventing data type overflows. Default: None.
  1917|         0|            0|            0|  0.00%|    """
  1918|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1919|         0|            0|            0|  0.00%|        return handle_torch_function(log_softmax, (input,), input, dim=dim, _stacklevel=_stacklevel, dtype=dtype)
  1920|         0|            0|            0|  0.00%|    if dim is None:
  1921|         0|            0|            0|  0.00%|        dim = _get_softmax_dim("log_softmax", input.dim(), _stacklevel)
  1922|         0|            0|            0|  0.00%|    if dtype is None:
  1923|         0|            0|            0|  0.00%|        ret = input.log_softmax(dim)
  1924|         0|            0|            0|  0.00%|    else:
  1925|         0|            0|            0|  0.00%|        ret = input.log_softmax(dim, dtype=dtype)
  1926|         0|            0|            0|  0.00%|    return ret
  1927|         0|            0|            0|  0.00%|
  1928|         0|            0|            0|  0.00%|
  1929|         0|            0|            0|  0.00%|softshrink = _add_docstr(
  1930|         0|            0|            0|  0.00%|    torch._C._nn.softshrink,
  1931|         0|            0|            0|  0.00%|    r"""
  1932|         0|            0|            0|  0.00%|softshrink(input, lambd=0.5) -> Tensor
  1933|         0|            0|            0|  0.00%|
  1934|         0|            0|            0|  0.00%|Applies the soft shrinkage function elementwise
  1935|         0|            0|            0|  0.00%|
  1936|         0|            0|            0|  0.00%|See :class:`~torch.nn.Softshrink` for more details.
  1937|         0|            0|            0|  0.00%|""",
  1938|         0|            0|            0|  0.00%|)
  1939|         0|            0|            0|  0.00%|
  1940|         0|            0|            0|  0.00%|
  1941|         0|            0|            0|  0.00%|def tanh(input):
  1942|         0|            0|            0|  0.00%|    r"""tanh(input) -> Tensor
  1943|         0|            0|            0|  0.00%|
  1944|         0|            0|            0|  0.00%|    Applies element-wise,
  1945|         0|            0|            0|  0.00%|    :math:`\text{Tanh}(x) = \tanh(x) = \frac{\exp(x) - \exp(-x)}{\exp(x) + \exp(-x)}`
  1946|         0|            0|            0|  0.00%|
  1947|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Tanh` for more details.
  1948|         0|            0|            0|  0.00%|    """
  1949|         0|            0|            0|  0.00%|    warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
  1950|         0|            0|            0|  0.00%|    return input.tanh()
  1951|         0|            0|            0|  0.00%|
  1952|         0|            0|            0|  0.00%|
  1953|         0|            0|            0|  0.00%|def sigmoid(input):
  1954|         0|            0|            0|  0.00%|    r"""sigmoid(input) -> Tensor
  1955|         0|            0|            0|  0.00%|
  1956|         0|            0|            0|  0.00%|    Applies the element-wise function :math:`\text{Sigmoid}(x) = \frac{1}{1 + \exp(-x)}`
  1957|         0|            0|            0|  0.00%|
  1958|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Sigmoid` for more details.
  1959|         0|            0|            0|  0.00%|    """
  1960|         0|            0|            0|  0.00%|    warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
  1961|         0|            0|            0|  0.00%|    return input.sigmoid()
  1962|         0|            0|            0|  0.00%|
  1963|         0|            0|            0|  0.00%|
  1964|         0|            0|            0|  0.00%|def hardsigmoid(input: Tensor, inplace: bool = False) -> Tensor:
  1965|         0|            0|            0|  0.00%|    r"""Applies the element-wise function
  1966|         0|            0|            0|  0.00%|
  1967|         0|            0|            0|  0.00%|    .. math::
  1968|         0|            0|            0|  0.00%|        \text{Hardsigmoid}(x) = \begin{cases}
  1969|         0|            0|            0|  0.00%|            0 & \text{if~} x \le -3, \\
  1970|         0|            0|            0|  0.00%|            1 & \text{if~} x \ge +3, \\
  1971|         0|            0|            0|  0.00%|            x / 6 + 1 / 2 & \text{otherwise}
  1972|         0|            0|            0|  0.00%|        \end{cases}
  1973|         0|            0|            0|  0.00%|
  1974|         0|            0|            0|  0.00%|    Args:
  1975|         0|            0|            0|  0.00%|        inplace: If set to ``True``, will do this operation in-place. Default: ``False``
  1976|         0|            0|            0|  0.00%|
  1977|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Hardsigmoid` for more details.
  1978|         0|            0|            0|  0.00%|    """
  1979|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  1980|         0|            0|            0|  0.00%|        return handle_torch_function(hardsigmoid, (input,), input, inplace=inplace)
  1981|         0|            0|            0|  0.00%|    if inplace:
  1982|         0|            0|            0|  0.00%|        return torch._C._nn.hardsigmoid_(input)
  1983|         0|            0|            0|  0.00%|    return torch._C._nn.hardsigmoid(input)
  1984|         0|            0|            0|  0.00%|
  1985|         0|            0|            0|  0.00%|
  1986|         0|            0|            0|  0.00%|linear = _add_docstr(
  1987|         0|            0|            0|  0.00%|    torch._C._nn.linear,
  1988|         0|            0|            0|  0.00%|    r"""
  1989|         0|            0|            0|  0.00%|linear(input, weight, bias=None) -> Tensor
  1990|         0|            0|            0|  0.00%|
  1991|         0|            0|            0|  0.00%|Applies a linear transformation to the incoming data: :math:`y = xA^T + b`.
  1992|         0|            0|            0|  0.00%|
  1993|         0|            0|            0|  0.00%|This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.
  1994|         0|            0|            0|  0.00%|
  1995|         0|            0|            0|  0.00%|Shape:
  1996|         0|            0|            0|  0.00%|
  1997|         0|            0|            0|  0.00%|    - Input: :math:`(*, in\_features)` where `*` means any number of
  1998|         0|            0|            0|  0.00%|      additional dimensions, including none
  1999|         0|            0|            0|  0.00%|    - Weight: :math:`(out\_features, in\_features)` or :math:`(in\_features)`
  2000|         0|            0|            0|  0.00%|    - Bias: :math:`(out\_features)` or :math:`()`
  2001|         0|            0|            0|  0.00%|    - Output: :math:`(*, out\_features)` or :math:`(*)`, based on the shape of the weight
  2002|         0|            0|            0|  0.00%|""")
  2003|         0|            0|            0|  0.00%|
  2004|         0|            0|            0|  0.00%|
  2005|         0|            0|            0|  0.00%|bilinear = _add_docstr(
  2006|         0|            0|            0|  0.00%|    torch.bilinear,
  2007|         0|            0|            0|  0.00%|    r"""
  2008|         0|            0|            0|  0.00%|bilinear(input1, input2, weight, bias=None) -> Tensor
  2009|         0|            0|            0|  0.00%|
  2010|         0|            0|            0|  0.00%|Applies a bilinear transformation to the incoming data:
  2011|         0|            0|            0|  0.00%|:math:`y = x_1^T A x_2 + b`
  2012|         0|            0|            0|  0.00%|
  2013|         0|            0|            0|  0.00%|Shape:
  2014|         0|            0|            0|  0.00%|
  2015|         0|            0|            0|  0.00%|    - input1: :math:`(N, *, H_{in1})` where :math:`H_{in1}=\text{in1\_features}`
  2016|         0|            0|            0|  0.00%|      and :math:`*` means any number of additional dimensions.
  2017|         0|            0|            0|  0.00%|      All but the last dimension of the inputs should be the same.
  2018|         0|            0|            0|  0.00%|    - input2: :math:`(N, *, H_{in2})` where :math:`H_{in2}=\text{in2\_features}`
  2019|         0|            0|            0|  0.00%|    - weight: :math:`(\text{out\_features}, \text{in1\_features},
  2020|         0|            0|            0|  0.00%|      \text{in2\_features})`
  2021|         0|            0|            0|  0.00%|    - bias: :math:`(\text{out\_features})`
  2022|         0|            0|            0|  0.00%|    - output: :math:`(N, *, H_{out})` where :math:`H_{out}=\text{out\_features}`
  2023|         0|            0|            0|  0.00%|      and all but the last dimension are the same shape as the input.
  2024|         0|            0|            0|  0.00%|""")
  2025|         0|            0|            0|  0.00%|
  2026|         0|            0|            0|  0.00%|
  2027|         0|            0|            0|  0.00%|def silu(input: Tensor, inplace: bool = False) -> Tensor:
  2028|         0|            0|            0|  0.00%|    r"""Applies the Sigmoid Linear Unit (SiLU) function, element-wise.
  2029|         0|            0|            0|  0.00%|    The SiLU function is also known as the swish function.
  2030|         0|            0|            0|  0.00%|
  2031|         0|            0|            0|  0.00%|    .. math::
  2032|         0|            0|            0|  0.00%|        \text{silu}(x) = x * \sigma(x), \text{where } \sigma(x) \text{ is the logistic sigmoid.}
  2033|         0|            0|            0|  0.00%|
  2034|         0|            0|            0|  0.00%|    .. note::
  2035|         0|            0|            0|  0.00%|        See `Gaussian Error Linear Units (GELUs) <https://arxiv.org/abs/1606.08415>`_
  2036|         0|            0|            0|  0.00%|        where the SiLU (Sigmoid Linear Unit) was originally coined, and see
  2037|         0|            0|            0|  0.00%|        `Sigmoid-Weighted Linear Units for Neural Network Function Approximation
  2038|         0|            0|            0|  0.00%|        in Reinforcement Learning <https://arxiv.org/abs/1702.03118>`_ and `Swish:
  2039|         0|            0|            0|  0.00%|        a Self-Gated Activation Function <https://arxiv.org/abs/1710.05941v1>`_
  2040|         0|            0|            0|  0.00%|        where the SiLU was experimented with later.
  2041|         0|            0|            0|  0.00%|
  2042|         0|            0|            0|  0.00%|    See :class:`~torch.nn.SiLU` for more details.
  2043|         0|            0|            0|  0.00%|    """
  2044|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  2045|         0|            0|            0|  0.00%|        return handle_torch_function(silu, (input,), input, inplace=inplace)
  2046|         0|            0|            0|  0.00%|    if inplace:
  2047|         0|            0|            0|  0.00%|        return torch._C._nn.silu_(input)
  2048|         0|            0|            0|  0.00%|    return torch._C._nn.silu(input)
  2049|         0|            0|            0|  0.00%|
  2050|         0|            0|            0|  0.00%|
  2051|         0|            0|            0|  0.00%|def mish(input: Tensor, inplace: bool = False) -> Tensor:
  2052|         0|            0|            0|  0.00%|    r"""Applies the Mish function, element-wise.
  2053|         0|            0|            0|  0.00%|    Mish: A Self Regularized Non-Monotonic Neural Activation Function.
  2054|         0|            0|            0|  0.00%|
  2055|         0|            0|            0|  0.00%|    .. math::
  2056|         0|            0|            0|  0.00%|        \text{Mish}(x) = x * \text{Tanh}(\text{Softplus}(x))
  2057|         0|            0|            0|  0.00%|
  2058|         0|            0|            0|  0.00%|    .. note::
  2059|         0|            0|            0|  0.00%|        See `Mish: A Self Regularized Non-Monotonic Neural Activation Function <https://arxiv.org/abs/1908.08681>`_
  2060|         0|            0|            0|  0.00%|
  2061|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Mish` for more details.
  2062|         0|            0|            0|  0.00%|    """
  2063|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  2064|         0|            0|            0|  0.00%|        return handle_torch_function(mish, (input,), input, inplace=inplace)
  2065|         0|            0|            0|  0.00%|    if inplace:
  2066|         0|            0|            0|  0.00%|        return torch._C._nn.mish_(input)
  2067|         0|            0|            0|  0.00%|    return torch._C._nn.mish(input)
  2068|         0|            0|            0|  0.00%|
  2069|         0|            0|            0|  0.00%|
  2070|         0|            0|            0|  0.00%|def hardswish(input: Tensor, inplace: bool = False) -> Tensor:
  2071|         0|            0|            0|  0.00%|    r"""Applies the hardswish function, element-wise, as described in the paper:
  2072|         0|            0|            0|  0.00%|
  2073|         0|            0|            0|  0.00%|    `Searching for MobileNetV3`_.
  2074|         0|            0|            0|  0.00%|
  2075|         0|            0|            0|  0.00%|    .. math::
  2076|         0|            0|            0|  0.00%|        \text{Hardswish}(x) = \begin{cases}
  2077|         0|            0|            0|  0.00%|            0 & \text{if~} x \le -3, \\
  2078|         0|            0|            0|  0.00%|            x & \text{if~} x \ge +3, \\
  2079|         0|            0|            0|  0.00%|            x \cdot (x + 3) /6 & \text{otherwise}
  2080|         0|            0|            0|  0.00%|        \end{cases}
  2081|         0|            0|            0|  0.00%|
  2082|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Hardswish` for more details.
  2083|         0|            0|            0|  0.00%|
  2084|         0|            0|            0|  0.00%|    .. _`Searching for MobileNetV3`:
  2085|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1905.02244
  2086|         0|            0|            0|  0.00%|    """
  2087|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  2088|         0|            0|            0|  0.00%|        return handle_torch_function(hardswish, (input,), input, inplace=inplace)
  2089|         0|            0|            0|  0.00%|    if inplace:
  2090|         0|            0|            0|  0.00%|        return torch._C._nn.hardswish_(input)
  2091|         0|            0|            0|  0.00%|    return torch._C._nn.hardswish(input)
  2092|         0|            0|            0|  0.00%|
  2093|         0|            0|            0|  0.00%|
  2094|         0|            0|            0|  0.00%|def _no_grad_embedding_renorm_(weight: Tensor, input: Tensor, max_norm: float, norm_type: float) -> Tensor:
  2095|         0|            0|            0|  0.00%|    with torch.no_grad():
  2096|         0|            0|            0|  0.00%|        torch.embedding_renorm_(weight, input, max_norm, norm_type)
  2097|         0|            0|            0|  0.00%|
  2098|         0|            0|            0|  0.00%|
  2099|         0|            0|            0|  0.00%|def embedding(
  2100|         0|            0|            0|  0.00%|    input: Tensor,
  2101|         0|            0|            0|  0.00%|    weight: Tensor,
  2102|         0|            0|            0|  0.00%|    padding_idx: Optional[int] = None,
  2103|         0|            0|            0|  0.00%|    max_norm: Optional[float] = None,
  2104|         0|            0|            0|  0.00%|    norm_type: float = 2.0,
  2105|         0|            0|            0|  0.00%|    scale_grad_by_freq: bool = False,
  2106|         0|            0|            0|  0.00%|    sparse: bool = False,
  2107|         0|            0|            0|  0.00%|) -> Tensor:
  2108|         0|            0|            0|  0.00%|    r"""A simple lookup table that looks up embeddings in a fixed dictionary and size.
  2109|         0|            0|            0|  0.00%|
  2110|         0|            0|            0|  0.00%|    This module is often used to retrieve word embeddings using indices.
  2111|         0|            0|            0|  0.00%|    The input to the module is a list of indices, and the embedding matrix,
  2112|         0|            0|            0|  0.00%|    and the output is the corresponding word embeddings.
  2113|         0|            0|            0|  0.00%|
  2114|         0|            0|            0|  0.00%|    See :class:`torch.nn.Embedding` for more details.
  2115|         0|            0|            0|  0.00%|
  2116|         0|            0|            0|  0.00%|    Args:
  2117|         0|            0|            0|  0.00%|        input (LongTensor): Tensor containing indices into the embedding matrix
  2118|         0|            0|            0|  0.00%|        weight (Tensor): The embedding matrix with number of rows equal to the maximum possible index + 1,
  2119|         0|            0|            0|  0.00%|            and number of columns equal to the embedding size
  2120|         0|            0|            0|  0.00%|        padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the gradient;
  2121|         0|            0|            0|  0.00%|                                     therefore, the embedding vector at :attr:`padding_idx` is not updated during training,
  2122|         0|            0|            0|  0.00%|                                     i.e. it remains as a fixed "pad".
  2123|         0|            0|            0|  0.00%|        max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`
  2124|         0|            0|            0|  0.00%|                                    is renormalized to have norm :attr:`max_norm`.
  2125|         0|            0|            0|  0.00%|                                    Note: this will modify :attr:`weight` in-place.
  2126|         0|            0|            0|  0.00%|        norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.
  2127|         0|            0|            0|  0.00%|        scale_grad_by_freq (boolean, optional): If given, this will scale gradients by the inverse of frequency of
  2128|         0|            0|            0|  0.00%|                                                the words in the mini-batch. Default ``False``.
  2129|         0|            0|            0|  0.00%|        sparse (bool, optional): If ``True``, gradient w.r.t. :attr:`weight` will be a sparse tensor. See Notes under
  2130|         0|            0|            0|  0.00%|                                 :class:`torch.nn.Embedding` for more details regarding sparse gradients.
  2131|         0|            0|            0|  0.00%|
  2132|         0|            0|            0|  0.00%|    Shape:
  2133|         0|            0|            0|  0.00%|        - Input: LongTensor of arbitrary shape containing the indices to extract
  2134|         0|            0|            0|  0.00%|        - Weight: Embedding matrix of floating point type with shape `(V, embedding_dim)`,
  2135|         0|            0|            0|  0.00%|          where V = maximum index + 1 and embedding_dim = the embedding size
  2136|         0|            0|            0|  0.00%|        - Output: `(*, embedding_dim)`, where `*` is the input shape
  2137|         0|            0|            0|  0.00%|
  2138|         0|            0|            0|  0.00%|    Examples::
  2139|         0|            0|            0|  0.00%|
  2140|         0|            0|            0|  0.00%|        >>> # a batch of 2 samples of 4 indices each
  2141|         0|            0|            0|  0.00%|        >>> input = torch.tensor([[1,2,4,5],[4,3,2,9]])
  2142|         0|            0|            0|  0.00%|        >>> # an embedding matrix containing 10 tensors of size 3
  2143|         0|            0|            0|  0.00%|        >>> embedding_matrix = torch.rand(10, 3)
  2144|         0|            0|            0|  0.00%|        >>> F.embedding(input, embedding_matrix)
  2145|         0|            0|            0|  0.00%|        tensor([[[ 0.8490,  0.9625,  0.6753],
  2146|         0|            0|            0|  0.00%|                 [ 0.9666,  0.7761,  0.6108],
  2147|         0|            0|            0|  0.00%|                 [ 0.6246,  0.9751,  0.3618],
  2148|         0|            0|            0|  0.00%|                 [ 0.4161,  0.2419,  0.7383]],
  2149|         0|            0|            0|  0.00%|
  2150|         0|            0|            0|  0.00%|                [[ 0.6246,  0.9751,  0.3618],
  2151|         0|            0|            0|  0.00%|                 [ 0.0237,  0.7794,  0.0528],
  2152|         0|            0|            0|  0.00%|                 [ 0.9666,  0.7761,  0.6108],
  2153|         0|            0|            0|  0.00%|                 [ 0.3385,  0.8612,  0.1867]]])
  2154|         0|            0|            0|  0.00%|
  2155|         0|            0|            0|  0.00%|        >>> # example with padding_idx
  2156|         0|            0|            0|  0.00%|        >>> weights = torch.rand(10, 3)
  2157|         0|            0|            0|  0.00%|        >>> weights[0, :].zero_()
  2158|         0|            0|            0|  0.00%|        >>> embedding_matrix = weights
  2159|         0|            0|            0|  0.00%|        >>> input = torch.tensor([[0,2,0,5]])
  2160|         0|            0|            0|  0.00%|        >>> F.embedding(input, embedding_matrix, padding_idx=0)
  2161|         0|            0|            0|  0.00%|        tensor([[[ 0.0000,  0.0000,  0.0000],
  2162|         0|            0|            0|  0.00%|                 [ 0.5609,  0.5384,  0.8720],
  2163|         0|            0|            0|  0.00%|                 [ 0.0000,  0.0000,  0.0000],
  2164|         0|            0|            0|  0.00%|                 [ 0.6262,  0.2438,  0.7471]]])
  2165|         0|            0|            0|  0.00%|    """
  2166|         0|            0|            0|  0.00%|
  2167|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, weight):
  2168|         0|            0|            0|  0.00%|        return handle_torch_function(
  2169|         0|            0|            0|  0.00%|            embedding,
  2170|         0|            0|            0|  0.00%|            (input, weight),
  2171|         0|            0|            0|  0.00%|            input,
  2172|         0|            0|            0|  0.00%|            weight,
  2173|         0|            0|            0|  0.00%|            padding_idx=padding_idx,
  2174|         0|            0|            0|  0.00%|            max_norm=max_norm,
  2175|         0|            0|            0|  0.00%|            norm_type=norm_type,
  2176|         0|            0|            0|  0.00%|            scale_grad_by_freq=scale_grad_by_freq,
  2177|         0|            0|            0|  0.00%|            sparse=sparse,
  2178|         0|            0|            0|  0.00%|        )
  2179|         0|            0|            0|  0.00%|    if padding_idx is not None:
  2180|         0|            0|            0|  0.00%|        if padding_idx > 0:
  2181|         0|            0|            0|  0.00%|            assert padding_idx < weight.size(0), "Padding_idx must be within num_embeddings"
  2182|         0|            0|            0|  0.00%|        elif padding_idx < 0:
  2183|         0|            0|            0|  0.00%|            assert padding_idx >= -weight.size(0), "Padding_idx must be within num_embeddings"
  2184|         0|            0|            0|  0.00%|            padding_idx = weight.size(0) + padding_idx
  2185|         0|            0|            0|  0.00%|    else:
  2186|         0|            0|            0|  0.00%|        padding_idx = -1
  2187|         0|            0|            0|  0.00%|    if max_norm is not None:
  2188|         0|            0|            0|  0.00%|        # Note [embedding_renorm contiguous]
  2189|         0|            0|            0|  0.00%|        # `embedding_renorm_` will call .contiguous() on input anyways, so we
  2190|         0|            0|            0|  0.00%|        # call it here and take advantage of the improved locality in the
  2191|         0|            0|            0|  0.00%|        # `embedding` call below too.
  2192|         0|            0|            0|  0.00%|        input = input.contiguous()
  2193|         0|            0|            0|  0.00%|        # Note [embedding_renorm set_grad_enabled]
  2194|         0|            0|            0|  0.00%|        # XXX: equivalent to
  2195|         0|            0|            0|  0.00%|        # with torch.no_grad():
  2196|         0|            0|            0|  0.00%|        #   torch.embedding_renorm_
  2197|         0|            0|            0|  0.00%|        # remove once script supports set_grad_enabled
  2198|         0|            0|            0|  0.00%|        _no_grad_embedding_renorm_(weight, input, max_norm, norm_type)
  2199|         0|            0|            0|  0.00%|    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
  2200|         0|            0|            0|  0.00%|
  2201|         0|            0|            0|  0.00%|
  2202|         0|            0|            0|  0.00%|def embedding_bag(
  2203|         0|            0|            0|  0.00%|    input: Tensor,
  2204|         0|            0|            0|  0.00%|    weight: Tensor,
  2205|         0|            0|            0|  0.00%|    offsets: Optional[Tensor] = None,
  2206|         0|            0|            0|  0.00%|    max_norm: Optional[float] = None,
  2207|         0|            0|            0|  0.00%|    norm_type: float = 2,
  2208|         0|            0|            0|  0.00%|    scale_grad_by_freq: bool = False,
  2209|         0|            0|            0|  0.00%|    mode: str = "mean",
  2210|         0|            0|            0|  0.00%|    sparse: bool = False,
  2211|         0|            0|            0|  0.00%|    per_sample_weights: Optional[Tensor] = None,
  2212|         0|            0|            0|  0.00%|    include_last_offset: bool = False,
  2213|         0|            0|            0|  0.00%|    padding_idx: Optional[int] = None,
  2214|         0|            0|            0|  0.00%|) -> Tensor:
  2215|         0|            0|            0|  0.00%|    r"""Computes sums, means or maxes of `bags` of embeddings, without instantiating the
  2216|         0|            0|            0|  0.00%|    intermediate embeddings.
  2217|         0|            0|            0|  0.00%|
  2218|         0|            0|            0|  0.00%|    See :class:`torch.nn.EmbeddingBag` for more details.
  2219|         0|            0|            0|  0.00%|
  2220|         0|            0|            0|  0.00%|    Note:
  2221|         0|            0|            0|  0.00%|        {backward_reproducibility_note}
  2222|         0|            0|            0|  0.00%|
  2223|         0|            0|            0|  0.00%|    Args:
  2224|         0|            0|            0|  0.00%|        input (LongTensor): Tensor containing bags of indices into the embedding matrix
  2225|         0|            0|            0|  0.00%|        weight (Tensor): The embedding matrix with number of rows equal to the maximum possible index + 1,
  2226|         0|            0|            0|  0.00%|            and number of columns equal to the embedding size
  2227|         0|            0|            0|  0.00%|        offsets (LongTensor, optional): Only used when :attr:`input` is 1D. :attr:`offsets` determines
  2228|         0|            0|            0|  0.00%|                             the starting index position of each bag (sequence) in :attr:`input`.
  2229|         0|            0|            0|  0.00%|        max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`
  2230|         0|            0|            0|  0.00%|                                    is renormalized to have norm :attr:`max_norm`.
  2231|         0|            0|            0|  0.00%|                                    Note: this will modify :attr:`weight` in-place.
  2232|         0|            0|            0|  0.00%|        norm_type (float, optional): The ``p`` in the ``p``-norm to compute for the :attr:`max_norm` option.
  2233|         0|            0|            0|  0.00%|                                     Default ``2``.
  2234|         0|            0|            0|  0.00%|        scale_grad_by_freq (boolean, optional): if given, this will scale gradients by the inverse of frequency of
  2235|         0|            0|            0|  0.00%|                                                the words in the mini-batch. Default ``False``.
  2236|         0|            0|            0|  0.00%|                                                Note: this option is not supported when ``mode="max"``.
  2237|         0|            0|            0|  0.00%|        mode (string, optional): ``"sum"``, ``"mean"`` or ``"max"``. Specifies the way to reduce the bag.
  2238|         0|            0|            0|  0.00%|                                 Default: ``"mean"``
  2239|         0|            0|            0|  0.00%|        sparse (bool, optional): if ``True``, gradient w.r.t. :attr:`weight` will be a sparse tensor. See Notes under
  2240|         0|            0|            0|  0.00%|                                 :class:`torch.nn.Embedding` for more details regarding sparse gradients.
  2241|         0|            0|            0|  0.00%|                                 Note: this option is not supported when ``mode="max"``.
  2242|         0|            0|            0|  0.00%|        per_sample_weights (Tensor, optional): a tensor of float / double weights, or None
  2243|         0|            0|            0|  0.00%|            to indicate all weights should be taken to be 1. If specified, :attr:`per_sample_weights`
  2244|         0|            0|            0|  0.00%|            must have exactly the same shape as input and is treated as having the same
  2245|         0|            0|            0|  0.00%|            :attr:`offsets`, if those are not None.
  2246|         0|            0|            0|  0.00%|
  2247|         0|            0|            0|  0.00%|        include_last_offset (bool, optional): if ``True``, the size of offsets is equal to the number of bags + 1.
  2248|         0|            0|            0|  0.00%|            The last element is the size of the input, or the ending index position of the last bag (sequence).
  2249|         0|            0|            0|  0.00%|
  2250|         0|            0|            0|  0.00%|        padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the
  2251|         0|            0|            0|  0.00%|                                     gradient; therefore, the embedding vector at :attr:`padding_idx` is not updated
  2252|         0|            0|            0|  0.00%|                                     during training, i.e. it remains as a fixed "pad". Note that the embedding
  2253|         0|            0|            0|  0.00%|                                     vector at :attr:`padding_idx` is excluded from the reduction.
  2254|         0|            0|            0|  0.00%|
  2255|         0|            0|            0|  0.00%|    Shape:
  2256|         0|            0|            0|  0.00%|        - :attr:`input` (LongTensor) and :attr:`offsets` (LongTensor, optional)
  2257|         0|            0|            0|  0.00%|
  2258|         0|            0|            0|  0.00%|          - If :attr:`input` is 2D of shape `(B, N)`, it will be treated as ``B`` bags (sequences)
  2259|         0|            0|            0|  0.00%|            each of fixed length ``N``, and this will return ``B`` values aggregated in a way
  2260|         0|            0|            0|  0.00%|            depending on the :attr:`mode`. :attr:`offsets` is ignored and required to be ``None`` in this case.
  2261|         0|            0|            0|  0.00%|
  2262|         0|            0|            0|  0.00%|          - If :attr:`input` is 1D of shape `(N)`, it will be treated as a concatenation of
  2263|         0|            0|            0|  0.00%|            multiple bags (sequences). :attr:`offsets` is required to be a 1D tensor containing
  2264|         0|            0|            0|  0.00%|            the starting index positions of each bag in :attr:`input`. Therefore, for :attr:`offsets`
  2265|         0|            0|            0|  0.00%|            of shape `(B)`, :attr:`input` will be viewed as having ``B`` bags.
  2266|         0|            0|            0|  0.00%|            Empty bags (i.e., having 0-length) will have returned vectors filled by zeros.
  2267|         0|            0|            0|  0.00%|
  2268|         0|            0|            0|  0.00%|        - :attr:`weight` (Tensor): the learnable weights of the module of shape `(num_embeddings, embedding_dim)`
  2269|         0|            0|            0|  0.00%|
  2270|         0|            0|            0|  0.00%|        - :attr:`per_sample_weights` (Tensor, optional). Has the same shape as :attr:`input`.
  2271|         0|            0|            0|  0.00%|
  2272|         0|            0|            0|  0.00%|        - :attr:`output`: aggregated embedding values of shape `(B, embedding_dim)`
  2273|         0|            0|            0|  0.00%|
  2274|         0|            0|            0|  0.00%|    Examples::
  2275|         0|            0|            0|  0.00%|
  2276|         0|            0|            0|  0.00%|        >>> # an Embedding module containing 10 tensors of size 3
  2277|         0|            0|            0|  0.00%|        >>> embedding_matrix = torch.rand(10, 3)
  2278|         0|            0|            0|  0.00%|        >>> # a batch of 2 samples of 4 indices each
  2279|         0|            0|            0|  0.00%|        >>> input = torch.tensor([1,2,4,5,4,3,2,9])
  2280|         0|            0|            0|  0.00%|        >>> offsets = torch.tensor([0,4])
  2281|         0|            0|            0|  0.00%|        >>> F.embedding_bag(input, embedding_matrix, offsets)
  2282|         0|            0|            0|  0.00%|        tensor([[ 0.3397,  0.3552,  0.5545],
  2283|         0|            0|            0|  0.00%|                [ 0.5893,  0.4386,  0.5882]])
  2284|         0|            0|            0|  0.00%|
  2285|         0|            0|            0|  0.00%|        >>> # example with padding_idx
  2286|         0|            0|            0|  0.00%|        >>> embedding_matrix = torch.rand(10, 3)
  2287|         0|            0|            0|  0.00%|        >>> input = torch.tensor([2, 2, 2, 2, 4, 3, 2, 9])
  2288|         0|            0|            0|  0.00%|        >>> offsets = torch.tensor([0,4])
  2289|         0|            0|            0|  0.00%|        >>> F.embedding_bag(input, embedding_matrix, offsets, padding_idx=2, mode='sum')
  2290|         0|            0|            0|  0.00%|        tensor([[ 0.0000,  0.0000,  0.0000],
  2291|         0|            0|            0|  0.00%|                [-0.7082,  3.2145, -2.6251]])
  2292|         0|            0|            0|  0.00%|    """
  2293|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, weight, offsets, per_sample_weights):
  2294|         0|            0|            0|  0.00%|        return handle_torch_function(
  2295|         0|            0|            0|  0.00%|            embedding_bag,
  2296|         0|            0|            0|  0.00%|            (input, weight, offsets, per_sample_weights),
  2297|         0|            0|            0|  0.00%|            input,
  2298|         0|            0|            0|  0.00%|            weight,
  2299|         0|            0|            0|  0.00%|            offsets=offsets,
  2300|         0|            0|            0|  0.00%|            max_norm=max_norm,
  2301|         0|            0|            0|  0.00%|            norm_type=norm_type,
  2302|         0|            0|            0|  0.00%|            scale_grad_by_freq=scale_grad_by_freq,
  2303|         0|            0|            0|  0.00%|            mode=mode,
  2304|         0|            0|            0|  0.00%|            sparse=sparse,
  2305|         0|            0|            0|  0.00%|            per_sample_weights=per_sample_weights,
  2306|         0|            0|            0|  0.00%|            include_last_offset=include_last_offset,
  2307|         0|            0|            0|  0.00%|            padding_idx=padding_idx,
  2308|         0|            0|            0|  0.00%|        )
  2309|         0|            0|            0|  0.00%|    # Check for backward compatibility.
  2310|         0|            0|            0|  0.00%|    # Used to be embedding_bag(weight, input, ...)
  2311|         0|            0|            0|  0.00%|    # Now is     embedding_bag(input, weight, ...)
  2312|         0|            0|            0|  0.00%|    if weight.dtype == torch.long and input.is_floating_point():
  2313|         0|            0|            0|  0.00%|        warnings.warn(
  2314|         0|            0|            0|  0.00%|            "Argument order of nn.functional.embedding_bag was changed. "
  2315|         0|            0|            0|  0.00%|            "Usage `embedding_bag(weight, input, ...)` is deprecated, "
  2316|         0|            0|            0|  0.00%|            "and should now be `embedding_bag(input, weight, ...)`."
  2317|         0|            0|            0|  0.00%|        )
  2318|         0|            0|            0|  0.00%|        weight, input = input, weight
  2319|         0|            0|            0|  0.00%|
  2320|         0|            0|            0|  0.00%|    if per_sample_weights is not None and input.size() != per_sample_weights.size():
  2321|         0|            0|            0|  0.00%|        raise ValueError(
  2322|         0|            0|            0|  0.00%|            "embedding_bag: If per_sample_weights ({}) is not None, "
  2323|         0|            0|            0|  0.00%|            "then it must have the same shape as the input ({})".format(per_sample_weights.shape, input.shape)
  2324|         0|            0|            0|  0.00%|        )
  2325|         0|            0|            0|  0.00%|
  2326|         0|            0|            0|  0.00%|    if input.dim() == 2:
  2327|         0|            0|            0|  0.00%|        if offsets is not None:
  2328|         0|            0|            0|  0.00%|            type_str = "<unknown>"
  2329|         0|            0|            0|  0.00%|            # TODO: Remove this once script supports type() calls
  2330|         0|            0|            0|  0.00%|            if not torch.jit.is_scripting():
  2331|         0|            0|            0|  0.00%|                type_str = str(type(offsets))
  2332|         0|            0|            0|  0.00%|            raise ValueError(
  2333|         0|            0|            0|  0.00%|                "if input is 2D, then offsets has to be None"
  2334|         0|            0|            0|  0.00%|                ", as input is treated is a mini-batch of"
  2335|         0|            0|            0|  0.00%|                " fixed length sequences. However, found "
  2336|         0|            0|            0|  0.00%|                "offsets of type {}".format(type_str)
  2337|         0|            0|            0|  0.00%|            )
  2338|         0|            0|            0|  0.00%|        offsets = torch.arange(0, input.numel(), input.size(1), dtype=input.dtype, device=input.device)
  2339|         0|            0|            0|  0.00%|
  2340|         0|            0|            0|  0.00%|        input = input.reshape(-1)
  2341|         0|            0|            0|  0.00%|        if per_sample_weights is not None:
  2342|         0|            0|            0|  0.00%|            per_sample_weights = per_sample_weights.reshape(-1)
  2343|         0|            0|            0|  0.00%|    elif input.dim() == 1:
  2344|         0|            0|            0|  0.00%|        if offsets is None:
  2345|         0|            0|            0|  0.00%|            raise ValueError("offsets has to be a 1D Tensor but got None")
  2346|         0|            0|            0|  0.00%|        if offsets.dim() != 1:
  2347|         0|            0|            0|  0.00%|            raise ValueError("offsets has to be a 1D Tensor")
  2348|         0|            0|            0|  0.00%|    else:
  2349|         0|            0|            0|  0.00%|        raise ValueError("input has to be 1D or 2D Tensor," " but got Tensor of dimension {}".format(input.dim()))
  2350|         0|            0|            0|  0.00%|    if mode == "sum":
  2351|         0|            0|            0|  0.00%|        mode_enum = 0
  2352|         0|            0|            0|  0.00%|    elif mode == "mean":
  2353|         0|            0|            0|  0.00%|        mode_enum = 1
  2354|         0|            0|            0|  0.00%|    elif mode == "max":
  2355|         0|            0|            0|  0.00%|        mode_enum = 2
  2356|         0|            0|            0|  0.00%|
  2357|         0|            0|            0|  0.00%|        if scale_grad_by_freq:
  2358|         0|            0|            0|  0.00%|            raise ValueError("max mode does not support scaling the gradient by the frequency")
  2359|         0|            0|            0|  0.00%|
  2360|         0|            0|            0|  0.00%|        if sparse:
  2361|         0|            0|            0|  0.00%|            raise ValueError("max mode does not support sparse weights")
  2362|         0|            0|            0|  0.00%|
  2363|         0|            0|            0|  0.00%|    else:
  2364|         0|            0|            0|  0.00%|        raise ValueError("mode has to be one of sum, mean or max")
  2365|         0|            0|            0|  0.00%|
  2366|         0|            0|            0|  0.00%|    if max_norm is not None:
  2367|         0|            0|            0|  0.00%|        # XXX: equivalent to
  2368|         0|            0|            0|  0.00%|        # with torch.no_grad():
  2369|         0|            0|            0|  0.00%|        #   torch.nembedding_renorm_
  2370|         0|            0|            0|  0.00%|        # remove once script supports set_grad_enabled
  2371|         0|            0|            0|  0.00%|        _no_grad_embedding_renorm_(weight, input, max_norm, norm_type)
  2372|         0|            0|            0|  0.00%|
  2373|         0|            0|            0|  0.00%|    if per_sample_weights is not None and mode != "sum":
  2374|         0|            0|            0|  0.00%|        raise NotImplementedError(
  2375|         0|            0|            0|  0.00%|            "embedding_bag: per_sample_weights was not None. "
  2376|         0|            0|            0|  0.00%|            "per_sample_weights is only supported for mode='sum' "
  2377|         0|            0|            0|  0.00%|            "(got mode='{}'). Please open a feature request on GitHub.".format(mode)
  2378|         0|            0|            0|  0.00%|        )
  2379|         0|            0|            0|  0.00%|
  2380|         0|            0|            0|  0.00%|    ret, _, _, _ = torch.embedding_bag(
  2381|         0|            0|            0|  0.00%|        weight, input, offsets, scale_grad_by_freq, mode_enum, sparse, per_sample_weights, include_last_offset, padding_idx
  2382|         0|            0|            0|  0.00%|    )
  2383|         0|            0|            0|  0.00%|    return ret
  2384|         0|            0|            0|  0.00%|
  2385|         0|            0|            0|  0.00%|
  2386|         0|            0|            0|  0.00%|if embedding_bag.__doc__:
  2387|         0|            0|            0|  0.00%|    embedding_bag.__doc__ = embedding_bag.__doc__.format(**reproducibility_notes)
  2388|         0|            0|            0|  0.00%|
  2389|         0|            0|            0|  0.00%|
  2390|         0|            0|            0|  0.00%|def _verify_batch_size(size: List[int]) -> None:
  2391|         0|            0|            0|  0.00%|    # XXX: JIT script does not support the reduce from functools, and mul op is a
  2392|         0|            0|            0|  0.00%|    # builtin, which cannot be used as a value to a func yet, so rewrite this size
  2393|         0|            0|            0|  0.00%|    # check to a simple equivalent for loop
  2394|         0|            0|            0|  0.00%|    #
  2395|         0|            0|            0|  0.00%|    # TODO: make use of reduce like below when JIT is ready with the missing features:
  2396|         0|            0|            0|  0.00%|    # from operator import mul
  2397|         0|            0|            0|  0.00%|    # from functools import reduce
  2398|         0|            0|            0|  0.00%|    #
  2399|         0|            0|            0|  0.00%|    #   if reduce(mul, size[2:], size[0]) == 1
  2400|         0|            0|            0|  0.00%|    size_prods = size[0]
  2401|         0|            0|            0|  0.00%|    for i in range(len(size) - 2):
  2402|         0|            0|            0|  0.00%|        size_prods *= size[i + 2]
  2403|         0|            0|            0|  0.00%|    if size_prods == 1:
  2404|         0|            0|            0|  0.00%|        raise ValueError("Expected more than 1 value per channel when training, got input size {}".format(size))
  2405|         0|            0|            0|  0.00%|
  2406|         0|            0|            0|  0.00%|
  2407|         0|            0|            0|  0.00%|def batch_norm(
  2408|         0|            0|            0|  0.00%|    input: Tensor,
  2409|         0|            0|            0|  0.00%|    running_mean: Optional[Tensor],
  2410|         0|            0|            0|  0.00%|    running_var: Optional[Tensor],
  2411|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,
  2412|         0|            0|            0|  0.00%|    bias: Optional[Tensor] = None,
  2413|         0|            0|            0|  0.00%|    training: bool = False,
  2414|         0|            0|            0|  0.00%|    momentum: float = 0.1,
  2415|         0|            0|            0|  0.00%|    eps: float = 1e-5,
  2416|         0|            0|            0|  0.00%|) -> Tensor:
  2417|         0|            0|            0|  0.00%|    r"""Applies Batch Normalization for each channel across a batch of data.
  2418|         0|            0|            0|  0.00%|
  2419|         0|            0|            0|  0.00%|    See :class:`~torch.nn.BatchNorm1d`, :class:`~torch.nn.BatchNorm2d`,
  2420|         0|            0|            0|  0.00%|    :class:`~torch.nn.BatchNorm3d` for details.
  2421|         0|            0|            0|  0.00%|    """
  2422|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, running_mean, running_var, weight, bias):
  2423|         0|            0|            0|  0.00%|        return handle_torch_function(
  2424|         0|            0|            0|  0.00%|            batch_norm,
  2425|         0|            0|            0|  0.00%|            (input, running_mean, running_var, weight, bias),
  2426|         0|            0|            0|  0.00%|            input,
  2427|         0|            0|            0|  0.00%|            running_mean,
  2428|         0|            0|            0|  0.00%|            running_var,
  2429|         0|            0|            0|  0.00%|            weight=weight,
  2430|         0|            0|            0|  0.00%|            bias=bias,
  2431|         0|            0|            0|  0.00%|            training=training,
  2432|         0|            0|            0|  0.00%|            momentum=momentum,
  2433|         0|            0|            0|  0.00%|            eps=eps,
  2434|         0|            0|            0|  0.00%|        )
  2435|         0|            0|            0|  0.00%|    if training:
  2436|         0|            0|            0|  0.00%|        _verify_batch_size(input.size())
  2437|         0|            0|            0|  0.00%|
  2438|         0|            0|            0|  0.00%|    return torch.batch_norm(
  2439|         0|            0|            0|  0.00%|        input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled
  2440|         0|            0|            0|  0.00%|    )
  2441|         0|            0|            0|  0.00%|
  2442|         0|            0|            0|  0.00%|
  2443|         0|            0|            0|  0.00%|def _verify_spatial_size(size: List[int]) -> None:
  2444|         0|            0|            0|  0.00%|    # Verify that there is > 1 spatial element for instance norm calculation.
  2445|         0|            0|            0|  0.00%|    size_prods = 1
  2446|         0|            0|            0|  0.00%|    for i in range(2, len(size)):
  2447|         0|            0|            0|  0.00%|        size_prods *= size[i]
  2448|         0|            0|            0|  0.00%|    if size_prods == 1:
  2449|         0|            0|            0|  0.00%|        raise ValueError("Expected more than 1 spatial element when training, got input size {}".format(size))
  2450|         0|            0|            0|  0.00%|
  2451|         0|            0|            0|  0.00%|
  2452|         0|            0|            0|  0.00%|def instance_norm(
  2453|         0|            0|            0|  0.00%|    input: Tensor,
  2454|         0|            0|            0|  0.00%|    running_mean: Optional[Tensor] = None,
  2455|         0|            0|            0|  0.00%|    running_var: Optional[Tensor] = None,
  2456|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,
  2457|         0|            0|            0|  0.00%|    bias: Optional[Tensor] = None,
  2458|         0|            0|            0|  0.00%|    use_input_stats: bool = True,
  2459|         0|            0|            0|  0.00%|    momentum: float = 0.1,
  2460|         0|            0|            0|  0.00%|    eps: float = 1e-5,
  2461|         0|            0|            0|  0.00%|) -> Tensor:
  2462|         0|            0|            0|  0.00%|    r"""Applies Instance Normalization for each channel in each data sample in a
  2463|         0|            0|            0|  0.00%|    batch.
  2464|         0|            0|            0|  0.00%|
  2465|         0|            0|            0|  0.00%|    See :class:`~torch.nn.InstanceNorm1d`, :class:`~torch.nn.InstanceNorm2d`,
  2466|         0|            0|            0|  0.00%|    :class:`~torch.nn.InstanceNorm3d` for details.
  2467|         0|            0|            0|  0.00%|    """
  2468|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, running_mean, running_var, weight, bias):
  2469|         0|            0|            0|  0.00%|        return handle_torch_function(
  2470|         0|            0|            0|  0.00%|            instance_norm,
  2471|         0|            0|            0|  0.00%|            (input, running_mean, running_var, weight, bias),
  2472|         0|            0|            0|  0.00%|            input,
  2473|         0|            0|            0|  0.00%|            running_mean=running_mean,
  2474|         0|            0|            0|  0.00%|            running_var=running_var,
  2475|         0|            0|            0|  0.00%|            weight=weight,
  2476|         0|            0|            0|  0.00%|            bias=bias,
  2477|         0|            0|            0|  0.00%|            use_input_stats=use_input_stats,
  2478|         0|            0|            0|  0.00%|            momentum=momentum,
  2479|         0|            0|            0|  0.00%|            eps=eps,
  2480|         0|            0|            0|  0.00%|        )
  2481|         0|            0|            0|  0.00%|    if use_input_stats:
  2482|         0|            0|            0|  0.00%|        _verify_spatial_size(input.size())
  2483|         0|            0|            0|  0.00%|    return torch.instance_norm(
  2484|         0|            0|            0|  0.00%|        input, weight, bias, running_mean, running_var, use_input_stats, momentum, eps, torch.backends.cudnn.enabled
  2485|         0|            0|            0|  0.00%|    )
  2486|         0|            0|            0|  0.00%|
  2487|         0|            0|            0|  0.00%|
  2488|         0|            0|            0|  0.00%|def layer_norm(
  2489|         0|            0|            0|  0.00%|    input: Tensor,
  2490|         0|            0|            0|  0.00%|    normalized_shape: List[int],
  2491|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,
  2492|         0|            0|            0|  0.00%|    bias: Optional[Tensor] = None,
  2493|         0|            0|            0|  0.00%|    eps: float = 1e-5,
  2494|         0|            0|            0|  0.00%|) -> Tensor:
  2495|         0|            0|            0|  0.00%|    r"""Applies Layer Normalization for last certain number of dimensions.
  2496|         0|            0|            0|  0.00%|
  2497|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LayerNorm` for details.
  2498|         0|            0|            0|  0.00%|    """
  2499|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, weight, bias):
  2500|         0|            0|            0|  0.00%|        return handle_torch_function(
  2501|         0|            0|            0|  0.00%|            layer_norm, (input, weight, bias), input, normalized_shape, weight=weight, bias=bias, eps=eps
  2502|         0|            0|            0|  0.00%|        )
  2503|         0|            0|            0|  0.00%|    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
  2504|         0|            0|            0|  0.00%|
  2505|         0|            0|            0|  0.00%|
  2506|         0|            0|            0|  0.00%|def group_norm(
  2507|         0|            0|            0|  0.00%|    input: Tensor, num_groups: int, weight: Optional[Tensor] = None, bias: Optional[Tensor] = None, eps: float = 1e-5
  2508|         0|            0|            0|  0.00%|) -> Tensor:
  2509|         0|            0|            0|  0.00%|    r"""Applies Group Normalization for last certain number of dimensions.
  2510|         0|            0|            0|  0.00%|
  2511|         0|            0|            0|  0.00%|    See :class:`~torch.nn.GroupNorm` for details.
  2512|         0|            0|            0|  0.00%|    """
  2513|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, weight, bias):
  2514|         0|            0|            0|  0.00%|        return handle_torch_function(group_norm, (input, weight, bias,), input, num_groups, weight=weight, bias=bias, eps=eps)
  2515|         0|            0|            0|  0.00%|    _verify_batch_size([input.size(0) * input.size(1) // num_groups, num_groups] + list(input.size()[2:]))
  2516|         0|            0|            0|  0.00%|    return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)
  2517|         0|            0|            0|  0.00%|
  2518|         0|            0|            0|  0.00%|
  2519|         0|            0|            0|  0.00%|def local_response_norm(input: Tensor, size: int, alpha: float = 1e-4, beta: float = 0.75, k: float = 1.0) -> Tensor:
  2520|         0|            0|            0|  0.00%|    r"""Applies local response normalization over an input signal composed of
  2521|         0|            0|            0|  0.00%|    several input planes, where channels occupy the second dimension.
  2522|         0|            0|            0|  0.00%|    Applies normalization across channels.
  2523|         0|            0|            0|  0.00%|
  2524|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LocalResponseNorm` for details.
  2525|         0|            0|            0|  0.00%|    """
  2526|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  2527|         0|            0|            0|  0.00%|        return handle_torch_function(local_response_norm, (input,), input, size, alpha=alpha, beta=beta, k=k)
  2528|         0|            0|            0|  0.00%|    dim = input.dim()
  2529|         0|            0|            0|  0.00%|    if dim < 3:
  2530|         0|            0|            0|  0.00%|        raise ValueError(
  2531|         0|            0|            0|  0.00%|            "Expected 3D or higher dimensionality \
  2532|         0|            0|            0|  0.00%|                         input (got {} dimensions)".format(
  2533|         0|            0|            0|  0.00%|                dim
  2534|         0|            0|            0|  0.00%|            )
  2535|         0|            0|            0|  0.00%|        )
  2536|         0|            0|            0|  0.00%|
  2537|         0|            0|            0|  0.00%|    if input.numel() == 0:
  2538|         0|            0|            0|  0.00%|        return input
  2539|         0|            0|            0|  0.00%|
  2540|         0|            0|            0|  0.00%|    div = input.mul(input).unsqueeze(1)
  2541|         0|            0|            0|  0.00%|    if dim == 3:
  2542|         0|            0|            0|  0.00%|        div = pad(div, (0, 0, size // 2, (size - 1) // 2))
  2543|         0|            0|            0|  0.00%|        div = avg_pool2d(div, (size, 1), stride=1).squeeze(1)
  2544|         0|            0|            0|  0.00%|    else:
  2545|         0|            0|            0|  0.00%|        sizes = input.size()
  2546|         0|            0|            0|  0.00%|        div = div.view(sizes[0], 1, sizes[1], sizes[2], -1)
  2547|         0|            0|            0|  0.00%|        div = pad(div, (0, 0, 0, 0, size // 2, (size - 1) // 2))
  2548|         0|            0|            0|  0.00%|        div = avg_pool3d(div, (size, 1, 1), stride=1).squeeze(1)
  2549|         0|            0|            0|  0.00%|        div = div.view(sizes)
  2550|         0|            0|            0|  0.00%|    div = div.mul(alpha).add(k).pow(beta)
  2551|         0|            0|            0|  0.00%|    return input / div
  2552|         0|            0|            0|  0.00%|
  2553|         0|            0|            0|  0.00%|
  2554|         0|            0|            0|  0.00%|# loss
  2555|         0|            0|            0|  0.00%|
  2556|         0|            0|            0|  0.00%|
  2557|         0|            0|            0|  0.00%|def ctc_loss(
  2558|         0|            0|            0|  0.00%|    log_probs: Tensor,
  2559|         0|            0|            0|  0.00%|    targets: Tensor,
  2560|         0|            0|            0|  0.00%|    input_lengths: Tensor,
  2561|         0|            0|            0|  0.00%|    target_lengths: Tensor,
  2562|         0|            0|            0|  0.00%|    blank: int = 0,
  2563|         0|            0|            0|  0.00%|    reduction: str = "mean",
  2564|         0|            0|            0|  0.00%|    zero_infinity: bool = False,
  2565|         0|            0|            0|  0.00%|) -> Tensor:
  2566|         0|            0|            0|  0.00%|    r"""The Connectionist Temporal Classification loss.
  2567|         0|            0|            0|  0.00%|
  2568|         0|            0|            0|  0.00%|    See :class:`~torch.nn.CTCLoss` for details.
  2569|         0|            0|            0|  0.00%|
  2570|         0|            0|            0|  0.00%|    Note:
  2571|         0|            0|            0|  0.00%|        {cudnn_reproducibility_note}
  2572|         0|            0|            0|  0.00%|
  2573|         0|            0|            0|  0.00%|    Note:
  2574|         0|            0|            0|  0.00%|        {backward_reproducibility_note}
  2575|         0|            0|            0|  0.00%|
  2576|         0|            0|            0|  0.00%|    Args:
  2577|         0|            0|            0|  0.00%|        log_probs: :math:`(T, N, C)` or :math:`(T, C)` where `C = number of characters in alphabet including blank`,
  2578|         0|            0|            0|  0.00%|            `T = input length`, and `N = batch size`.
  2579|         0|            0|            0|  0.00%|            The logarithmized probabilities of the outputs
  2580|         0|            0|            0|  0.00%|            (e.g. obtained with :func:`torch.nn.functional.log_softmax`).
  2581|         0|            0|            0|  0.00%|        targets: :math:`(N, S)` or `(sum(target_lengths))`.
  2582|         0|            0|            0|  0.00%|            Targets cannot be blank. In the second form, the targets are assumed to be concatenated.
  2583|         0|            0|            0|  0.00%|        input_lengths: :math:`(N)` or :math:`()`.
  2584|         0|            0|            0|  0.00%|            Lengths of the inputs (must each be :math:`\leq T`)
  2585|         0|            0|            0|  0.00%|        target_lengths: :math:`(N)` or :math:`()`.
  2586|         0|            0|            0|  0.00%|            Lengths of the targets
  2587|         0|            0|            0|  0.00%|        blank (int, optional):
  2588|         0|            0|            0|  0.00%|            Blank label. Default :math:`0`.
  2589|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:
  2590|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
  2591|         0|            0|            0|  0.00%|            ``'mean'``: the output losses will be divided by the target lengths and
  2592|         0|            0|            0|  0.00%|            then the mean over the batch is taken, ``'sum'``: the output will be
  2593|         0|            0|            0|  0.00%|            summed. Default: ``'mean'``
  2594|         0|            0|            0|  0.00%|        zero_infinity (bool, optional):
  2595|         0|            0|            0|  0.00%|            Whether to zero infinite losses and the associated gradients.
  2596|         0|            0|            0|  0.00%|            Default: ``False``
  2597|         0|            0|            0|  0.00%|            Infinite losses mainly occur when the inputs are too short
  2598|         0|            0|            0|  0.00%|            to be aligned to the targets.
  2599|         0|            0|            0|  0.00%|
  2600|         0|            0|            0|  0.00%|    Example::
  2601|         0|            0|            0|  0.00%|
  2602|         0|            0|            0|  0.00%|        >>> log_probs = torch.randn(50, 16, 20).log_softmax(2).detach().requires_grad_()
  2603|         0|            0|            0|  0.00%|        >>> targets = torch.randint(1, 20, (16, 30), dtype=torch.long)
  2604|         0|            0|            0|  0.00%|        >>> input_lengths = torch.full((16,), 50, dtype=torch.long)
  2605|         0|            0|            0|  0.00%|        >>> target_lengths = torch.randint(10,30,(16,), dtype=torch.long)
  2606|         0|            0|            0|  0.00%|        >>> loss = F.ctc_loss(log_probs, targets, input_lengths, target_lengths)
  2607|         0|            0|            0|  0.00%|        >>> loss.backward()
  2608|         0|            0|            0|  0.00%|    """
  2609|         0|            0|            0|  0.00%|    if has_torch_function_variadic(log_probs, targets, input_lengths, target_lengths):
  2610|         0|            0|            0|  0.00%|        return handle_torch_function(
  2611|         0|            0|            0|  0.00%|            ctc_loss,
  2612|         0|            0|            0|  0.00%|            (log_probs, targets, input_lengths, target_lengths),
  2613|         0|            0|            0|  0.00%|            log_probs, targets, input_lengths, target_lengths,
  2614|         0|            0|            0|  0.00%|            blank=blank, reduction=reduction, zero_infinity=zero_infinity
  2615|         0|            0|            0|  0.00%|        )
  2616|         0|            0|            0|  0.00%|    return torch.ctc_loss(
  2617|         0|            0|            0|  0.00%|        log_probs, targets, input_lengths, target_lengths, blank, _Reduction.get_enum(reduction), zero_infinity
  2618|         0|            0|            0|  0.00%|    )
  2619|         0|            0|            0|  0.00%|
  2620|         0|            0|            0|  0.00%|
  2621|         0|            0|            0|  0.00%|if ctc_loss.__doc__:
  2622|         0|            0|            0|  0.00%|    ctc_loss.__doc__ = ctc_loss.__doc__.format(**reproducibility_notes)
  2623|         0|            0|            0|  0.00%|
  2624|         0|            0|            0|  0.00%|
  2625|         0|            0|            0|  0.00%|def nll_loss(
  2626|         0|            0|            0|  0.00%|    input: Tensor,
  2627|         0|            0|            0|  0.00%|    target: Tensor,
  2628|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,
  2629|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  2630|         0|            0|            0|  0.00%|    ignore_index: int = -100,
  2631|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  2632|         0|            0|            0|  0.00%|    reduction: str = "mean",
  2633|         0|            0|            0|  0.00%|) -> Tensor:
  2634|         0|            0|            0|  0.00%|    r"""The negative log likelihood loss.
  2635|         0|            0|            0|  0.00%|
  2636|         0|            0|            0|  0.00%|    See :class:`~torch.nn.NLLLoss` for details.
  2637|         0|            0|            0|  0.00%|
  2638|         0|            0|            0|  0.00%|    Args:
  2639|         0|            0|            0|  0.00%|        input: :math:`(N, C)` where `C = number of classes` or :math:`(N, C, H, W)`
  2640|         0|            0|            0|  0.00%|            in case of 2D Loss, or :math:`(N, C, d_1, d_2, ..., d_K)` where :math:`K \geq 1`
  2641|         0|            0|            0|  0.00%|            in the case of K-dimensional loss. `input` is expected to be log-probabilities.
  2642|         0|            0|            0|  0.00%|        target: :math:`(N)` where each value is :math:`0 \leq \text{targets}[i] \leq C-1`,
  2643|         0|            0|            0|  0.00%|            or :math:`(N, d_1, d_2, ..., d_K)` where :math:`K \geq 1` for
  2644|         0|            0|            0|  0.00%|            K-dimensional loss.
  2645|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to each
  2646|         0|            0|            0|  0.00%|            class. If given, has to be a Tensor of size `C`
  2647|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
  2648|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for
  2649|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`
  2650|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored
  2651|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``
  2652|         0|            0|            0|  0.00%|        ignore_index (int, optional): Specifies a target value that is ignored
  2653|         0|            0|            0|  0.00%|            and does not contribute to the input gradient. When :attr:`size_average` is
  2654|         0|            0|            0|  0.00%|            ``True``, the loss is averaged over non-ignored targets. Default: -100
  2655|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
  2656|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending
  2657|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
  2658|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``
  2659|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:
  2660|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
  2661|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of
  2662|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
  2663|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,
  2664|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
  2665|         0|            0|            0|  0.00%|
  2666|         0|            0|            0|  0.00%|    Example::
  2667|         0|            0|            0|  0.00%|
  2668|         0|            0|            0|  0.00%|        >>> # input is of size N x C = 3 x 5
  2669|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)
  2670|         0|            0|            0|  0.00%|        >>> # each element in target has to have 0 <= value < C
  2671|         0|            0|            0|  0.00%|        >>> target = torch.tensor([1, 0, 4])
  2672|         0|            0|            0|  0.00%|        >>> output = F.nll_loss(F.log_softmax(input), target)
  2673|         0|            0|            0|  0.00%|        >>> output.backward()
  2674|         0|            0|            0|  0.00%|    """
  2675|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, weight):
  2676|         0|            0|            0|  0.00%|        return handle_torch_function(
  2677|         0|            0|            0|  0.00%|            nll_loss,
  2678|         0|            0|            0|  0.00%|            (input, target, weight),
  2679|         0|            0|            0|  0.00%|            input,
  2680|         0|            0|            0|  0.00%|            target,
  2681|         0|            0|            0|  0.00%|            weight=weight,
  2682|         0|            0|            0|  0.00%|            size_average=size_average,
  2683|         0|            0|            0|  0.00%|            ignore_index=ignore_index,
  2684|         0|            0|            0|  0.00%|            reduce=reduce,
  2685|         0|            0|            0|  0.00%|            reduction=reduction,
  2686|         0|            0|            0|  0.00%|        )
  2687|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  2688|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)
  2689|         0|            0|            0|  0.00%|    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
  2690|         0|            0|            0|  0.00%|
  2691|         0|            0|            0|  0.00%|
  2692|         0|            0|            0|  0.00%|def poisson_nll_loss(
  2693|         0|            0|            0|  0.00%|    input: Tensor,
  2694|         0|            0|            0|  0.00%|    target: Tensor,
  2695|         0|            0|            0|  0.00%|    log_input: bool = True,
  2696|         0|            0|            0|  0.00%|    full: bool = False,
  2697|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  2698|         0|            0|            0|  0.00%|    eps: float = 1e-8,
  2699|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  2700|         0|            0|            0|  0.00%|    reduction: str = "mean",
  2701|         0|            0|            0|  0.00%|) -> Tensor:
  2702|         0|            0|            0|  0.00%|    r"""Poisson negative log likelihood loss.
  2703|         0|            0|            0|  0.00%|
  2704|         0|            0|            0|  0.00%|    See :class:`~torch.nn.PoissonNLLLoss` for details.
  2705|         0|            0|            0|  0.00%|
  2706|         0|            0|            0|  0.00%|    Args:
  2707|         0|            0|            0|  0.00%|        input: expectation of underlying Poisson distribution.
  2708|         0|            0|            0|  0.00%|        target: random sample :math:`target \sim \text{Poisson}(input)`.
  2709|         0|            0|            0|  0.00%|        log_input: if ``True`` the loss is computed as
  2710|         0|            0|            0|  0.00%|            :math:`\exp(\text{input}) - \text{target} * \text{input}`, if ``False`` then loss is
  2711|         0|            0|            0|  0.00%|            :math:`\text{input} - \text{target} * \log(\text{input}+\text{eps})`. Default: ``True``
  2712|         0|            0|            0|  0.00%|        full: whether to compute full loss, i. e. to add the Stirling
  2713|         0|            0|            0|  0.00%|            approximation term. Default: ``False``
  2714|         0|            0|            0|  0.00%|            :math:`\text{target} * \log(\text{target}) - \text{target} + 0.5 * \log(2 * \pi * \text{target})`.
  2715|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
  2716|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for
  2717|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`
  2718|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored
  2719|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``
  2720|         0|            0|            0|  0.00%|        eps (float, optional): Small value to avoid evaluation of :math:`\log(0)` when
  2721|         0|            0|            0|  0.00%|            :attr:`log_input`\ =\ ``False``. Default: 1e-8
  2722|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
  2723|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending
  2724|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
  2725|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``
  2726|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:
  2727|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
  2728|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of
  2729|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
  2730|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,
  2731|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
  2732|         0|            0|            0|  0.00%|
  2733|         0|            0|            0|  0.00%|    """
  2734|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):
  2735|         0|            0|            0|  0.00%|        return handle_torch_function(
  2736|         0|            0|            0|  0.00%|            poisson_nll_loss,
  2737|         0|            0|            0|  0.00%|            (input, target),
  2738|         0|            0|            0|  0.00%|            input,
  2739|         0|            0|            0|  0.00%|            target,
  2740|         0|            0|            0|  0.00%|            log_input=log_input,
  2741|         0|            0|            0|  0.00%|            full=full,
  2742|         0|            0|            0|  0.00%|            size_average=size_average,
  2743|         0|            0|            0|  0.00%|            eps=eps,
  2744|         0|            0|            0|  0.00%|            reduce=reduce,
  2745|         0|            0|            0|  0.00%|            reduction=reduction,
  2746|         0|            0|            0|  0.00%|        )
  2747|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  2748|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)
  2749|         0|            0|            0|  0.00%|    if reduction != "none" and reduction != "mean" and reduction != "sum":
  2750|         0|            0|            0|  0.00%|        ret = input
  2751|         0|            0|            0|  0.00%|        raise ValueError(reduction + " is not valid")
  2752|         0|            0|            0|  0.00%|
  2753|         0|            0|            0|  0.00%|    ret = torch.poisson_nll_loss(input, target, log_input, full, eps, _Reduction.get_enum(reduction))
  2754|         0|            0|            0|  0.00%|    return ret
  2755|         0|            0|            0|  0.00%|
  2756|         0|            0|            0|  0.00%|
  2757|         0|            0|            0|  0.00%|def gaussian_nll_loss(
  2758|         0|            0|            0|  0.00%|    input: Tensor,
  2759|         0|            0|            0|  0.00%|    target: Tensor,
  2760|         0|            0|            0|  0.00%|    var: Tensor,
  2761|         0|            0|            0|  0.00%|    full: bool = False,
  2762|         0|            0|            0|  0.00%|    eps: float = 1e-6,
  2763|         0|            0|            0|  0.00%|    reduction: str = "mean",
  2764|         0|            0|            0|  0.00%|) -> Tensor:
  2765|         0|            0|            0|  0.00%|    r"""Gaussian negative log likelihood loss.
  2766|         0|            0|            0|  0.00%|
  2767|         0|            0|            0|  0.00%|    See :class:`~torch.nn.GaussianNLLLoss` for details.
  2768|         0|            0|            0|  0.00%|
  2769|         0|            0|            0|  0.00%|    Args:
  2770|         0|            0|            0|  0.00%|        input: expectation of the Gaussian distribution.
  2771|         0|            0|            0|  0.00%|        target: sample from the Gaussian distribution.
  2772|         0|            0|            0|  0.00%|        var: tensor of positive variance(s), one for each of the expectations
  2773|         0|            0|            0|  0.00%|            in the input (heteroscedastic), or a single one (homoscedastic).
  2774|         0|            0|            0|  0.00%|        full (bool, optional): include the constant term in the loss calculation. Default: ``False``.
  2775|         0|            0|            0|  0.00%|        eps (float, optional): value added to var, for stability. Default: 1e-6.
  2776|         0|            0|            0|  0.00%|        reduction (string, optional): specifies the reduction to apply to the output:
  2777|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
  2778|         0|            0|            0|  0.00%|            ``'mean'``: the output is the average of all batch member losses,
  2779|         0|            0|            0|  0.00%|            ``'sum'``: the output is the sum of all batch member losses.
  2780|         0|            0|            0|  0.00%|            Default: ``'mean'``.
  2781|         0|            0|            0|  0.00%|    """
  2782|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, var):
  2783|         0|            0|            0|  0.00%|        return handle_torch_function(
  2784|         0|            0|            0|  0.00%|            gaussian_nll_loss,
  2785|         0|            0|            0|  0.00%|            (input, target, var),
  2786|         0|            0|            0|  0.00%|            input,
  2787|         0|            0|            0|  0.00%|            target,
  2788|         0|            0|            0|  0.00%|            var,
  2789|         0|            0|            0|  0.00%|            full=full,
  2790|         0|            0|            0|  0.00%|            eps=eps,
  2791|         0|            0|            0|  0.00%|            reduction=reduction,
  2792|         0|            0|            0|  0.00%|        )
  2793|         0|            0|            0|  0.00%|
  2794|         0|            0|            0|  0.00%|    # Check var size
  2795|         0|            0|            0|  0.00%|    # If var.size == input.size, the case is heteroscedastic and no further checks are needed.
  2796|         0|            0|            0|  0.00%|    # Otherwise:
  2797|         0|            0|            0|  0.00%|    if var.size() != input.size():
  2798|         0|            0|            0|  0.00%|
  2799|         0|            0|            0|  0.00%|        # If var is one dimension short of input, but the sizes match otherwise, then this is a homoscedastic case.
  2800|         0|            0|            0|  0.00%|        # e.g. input.size = (10, 2, 3), var.size = (10, 2)
  2801|         0|            0|            0|  0.00%|        # -> unsqueeze var so that var.shape = (10, 2, 1)
  2802|         0|            0|            0|  0.00%|        # this is done so that broadcasting can happen in the loss calculation
  2803|         0|            0|            0|  0.00%|        if input.size()[:-1] == var.size():
  2804|         0|            0|            0|  0.00%|            var = torch.unsqueeze(var, -1)
  2805|         0|            0|            0|  0.00%|
  2806|         0|            0|            0|  0.00%|        # This checks if the sizes match up to the final dimension, and the final dimension of var is of size 1.
  2807|         0|            0|            0|  0.00%|        # This is also a homoscedastic case.
  2808|         0|            0|            0|  0.00%|        # e.g. input.size = (10, 2, 3), var.size = (10, 2, 1)
  2809|         0|            0|            0|  0.00%|        elif input.size()[:-1] == var.size()[:-1] and var.size(-1) == 1:  # Heteroscedastic case
  2810|         0|            0|            0|  0.00%|            pass
  2811|         0|            0|            0|  0.00%|
  2812|         0|            0|            0|  0.00%|        # If none of the above pass, then the size of var is incorrect.
  2813|         0|            0|            0|  0.00%|        else:
  2814|         0|            0|            0|  0.00%|            raise ValueError("var is of incorrect size")
  2815|         0|            0|            0|  0.00%|
  2816|         0|            0|            0|  0.00%|    # Check validity of reduction mode
  2817|         0|            0|            0|  0.00%|    if reduction != 'none' and reduction != 'mean' and reduction != 'sum':
  2818|         0|            0|            0|  0.00%|        raise ValueError(reduction + " is not valid")
  2819|         0|            0|            0|  0.00%|
  2820|         0|            0|            0|  0.00%|    # Entries of var must be non-negative
  2821|         0|            0|            0|  0.00%|    if torch.any(var < 0):
  2822|         0|            0|            0|  0.00%|        raise ValueError("var has negative entry/entries")
  2823|         0|            0|            0|  0.00%|
  2824|         0|            0|            0|  0.00%|    # Clamp for stability
  2825|         0|            0|            0|  0.00%|    var = var.clone()
  2826|         0|            0|            0|  0.00%|    with torch.no_grad():
  2827|         0|            0|            0|  0.00%|        var.clamp_(min=eps)
  2828|         0|            0|            0|  0.00%|
  2829|         0|            0|            0|  0.00%|    # Calculate the loss
  2830|         0|            0|            0|  0.00%|    loss = 0.5 * (torch.log(var) + (input - target)**2 / var)
  2831|         0|            0|            0|  0.00%|    if full:
  2832|         0|            0|            0|  0.00%|        loss += 0.5 * math.log(2 * math.pi)
  2833|         0|            0|            0|  0.00%|
  2834|         0|            0|            0|  0.00%|    if reduction == 'mean':
  2835|         0|            0|            0|  0.00%|        return loss.mean()
  2836|         0|            0|            0|  0.00%|    elif reduction == 'sum':
  2837|         0|            0|            0|  0.00%|        return loss.sum()
  2838|         0|            0|            0|  0.00%|    else:
  2839|         0|            0|            0|  0.00%|        return loss
  2840|         0|            0|            0|  0.00%|
  2841|         0|            0|            0|  0.00%|
  2842|         0|            0|            0|  0.00%|def kl_div(
  2843|         0|            0|            0|  0.00%|    input: Tensor,
  2844|         0|            0|            0|  0.00%|    target: Tensor,
  2845|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  2846|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  2847|         0|            0|            0|  0.00%|    reduction: str = "mean",
  2848|         0|            0|            0|  0.00%|    log_target: bool = False,
  2849|         0|            0|            0|  0.00%|) -> Tensor:
  2850|         0|            0|            0|  0.00%|    r"""The `Kullback-Leibler divergence Loss
  2851|         0|            0|            0|  0.00%|    <https://en.wikipedia.org/wiki/Kullback-Leibler_divergence>`__
  2852|         0|            0|            0|  0.00%|
  2853|         0|            0|            0|  0.00%|    See :class:`~torch.nn.KLDivLoss` for details.
  2854|         0|            0|            0|  0.00%|
  2855|         0|            0|            0|  0.00%|    Args:
  2856|         0|            0|            0|  0.00%|        input: Tensor of arbitrary shape in log-probabilities.
  2857|         0|            0|            0|  0.00%|        target: Tensor of the same shape as input. See :attr:`log_target` for
  2858|         0|            0|            0|  0.00%|            the target's interpretation.
  2859|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
  2860|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for
  2861|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`
  2862|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored
  2863|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``
  2864|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
  2865|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending
  2866|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
  2867|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``
  2868|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:
  2869|         0|            0|            0|  0.00%|            ``'none'`` | ``'batchmean'`` | ``'sum'`` | ``'mean'``.
  2870|         0|            0|            0|  0.00%|            ``'none'``: no reduction will be applied
  2871|         0|            0|            0|  0.00%|            ``'batchmean'``: the sum of the output will be divided by the batchsize
  2872|         0|            0|            0|  0.00%|            ``'sum'``: the output will be summed
  2873|         0|            0|            0|  0.00%|            ``'mean'``: the output will be divided by the number of elements in the output
  2874|         0|            0|            0|  0.00%|            Default: ``'mean'``
  2875|         0|            0|            0|  0.00%|        log_target (bool): A flag indicating whether ``target`` is passed in the log space.
  2876|         0|            0|            0|  0.00%|            It is recommended to pass certain distributions (like ``softmax``)
  2877|         0|            0|            0|  0.00%|            in the log space to avoid numerical issues caused by explicit ``log``.
  2878|         0|            0|            0|  0.00%|            Default: ``False``
  2879|         0|            0|            0|  0.00%|
  2880|         0|            0|            0|  0.00%|    .. note::
  2881|         0|            0|            0|  0.00%|        :attr:`size_average` and :attr:`reduce` are in the process of being deprecated,
  2882|         0|            0|            0|  0.00%|        and in the meantime, specifying either of those two args will override :attr:`reduction`.
  2883|         0|            0|            0|  0.00%|
  2884|         0|            0|            0|  0.00%|    .. note::
  2885|         0|            0|            0|  0.00%|        :attr:`reduction` = ``'mean'`` doesn't return the true kl divergence value, please use
  2886|         0|            0|            0|  0.00%|        :attr:`reduction` = ``'batchmean'`` which aligns with KL math definition.
  2887|         0|            0|            0|  0.00%|        In the next major release, ``'mean'`` will be changed to be the same as 'batchmean'.
  2888|         0|            0|            0|  0.00%|    """
  2889|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):
  2890|         0|            0|            0|  0.00%|        return handle_torch_function(
  2891|         0|            0|            0|  0.00%|            kl_div,
  2892|         0|            0|            0|  0.00%|            (input, target),
  2893|         0|            0|            0|  0.00%|            input,
  2894|         0|            0|            0|  0.00%|            target,
  2895|         0|            0|            0|  0.00%|            size_average=size_average,
  2896|         0|            0|            0|  0.00%|            reduce=reduce,
  2897|         0|            0|            0|  0.00%|            reduction=reduction,
  2898|         0|            0|            0|  0.00%|            log_target=log_target,
  2899|         0|            0|            0|  0.00%|        )
  2900|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  2901|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)
  2902|         0|            0|            0|  0.00%|    else:
  2903|         0|            0|            0|  0.00%|        if reduction == "mean":
  2904|         0|            0|            0|  0.00%|            warnings.warn(
  2905|         0|            0|            0|  0.00%|                "reduction: 'mean' divides the total loss by both the batch size and the support size."
  2906|         0|            0|            0|  0.00%|                "'batchmean' divides only by the batch size, and aligns with the KL div math definition."
  2907|         0|            0|            0|  0.00%|                "'mean' will be changed to behave the same as 'batchmean' in the next major release."
  2908|         0|            0|            0|  0.00%|            )
  2909|         0|            0|            0|  0.00%|
  2910|         0|            0|            0|  0.00%|        # special case for batchmean
  2911|         0|            0|            0|  0.00%|        if reduction == "batchmean":
  2912|         0|            0|            0|  0.00%|            reduction_enum = _Reduction.get_enum("sum")
  2913|         0|            0|            0|  0.00%|        else:
  2914|         0|            0|            0|  0.00%|            reduction_enum = _Reduction.get_enum(reduction)
  2915|         0|            0|            0|  0.00%|
  2916|         0|            0|            0|  0.00%|    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
  2917|         0|            0|            0|  0.00%|
  2918|         0|            0|            0|  0.00%|    if reduction == "batchmean" and input.dim() != 0:
  2919|         0|            0|            0|  0.00%|        reduced = reduced / input.size()[0]
  2920|         0|            0|            0|  0.00%|
  2921|         0|            0|            0|  0.00%|    return reduced
  2922|         0|            0|            0|  0.00%|
  2923|         0|            0|            0|  0.00%|
  2924|         0|            0|            0|  0.00%|def cross_entropy(
  2925|         0|            0|            0|  0.00%|    input: Tensor,
  2926|         0|            0|            0|  0.00%|    target: Tensor,
  2927|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,
  2928|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  2929|         0|            0|            0|  0.00%|    ignore_index: int = -100,
  2930|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  2931|         0|            0|            0|  0.00%|    reduction: str = "mean",
  2932|         0|            0|            0|  0.00%|    label_smoothing: float = 0.0,
  2933|         0|            0|            0|  0.00%|) -> Tensor:
  2934|         0|            0|            0|  0.00%|    r"""This criterion computes the cross entropy loss between input and target.
  2935|         0|            0|            0|  0.00%|
  2936|         0|            0|            0|  0.00%|    See :class:`~torch.nn.CrossEntropyLoss` for details.
  2937|         0|            0|            0|  0.00%|
  2938|         0|            0|            0|  0.00%|    Args:
  2939|         0|            0|            0|  0.00%|        input (Tensor) : Predicted unnormalized scores (often referred to as logits);
  2940|         0|            0|            0|  0.00%|            see Shape section below for supported shapes.
  2941|         0|            0|            0|  0.00%|        target (Tensor) : Ground truth class indices or class probabilities;
  2942|         0|            0|            0|  0.00%|            see Shape section below for supported shapes.
  2943|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to each
  2944|         0|            0|            0|  0.00%|            class. If given, has to be a Tensor of size `C`
  2945|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
  2946|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for
  2947|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`
  2948|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored
  2949|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``
  2950|         0|            0|            0|  0.00%|        ignore_index (int, optional): Specifies a target value that is ignored
  2951|         0|            0|            0|  0.00%|            and does not contribute to the input gradient. When :attr:`size_average` is
  2952|         0|            0|            0|  0.00%|            ``True``, the loss is averaged over non-ignored targets. Note that
  2953|         0|            0|            0|  0.00%|            :attr:`ignore_index` is only applicable when the target contains class indices.
  2954|         0|            0|            0|  0.00%|            Default: -100
  2955|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
  2956|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending
  2957|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
  2958|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``
  2959|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:
  2960|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
  2961|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of
  2962|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
  2963|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,
  2964|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
  2965|         0|            0|            0|  0.00%|        label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount
  2966|         0|            0|            0|  0.00%|            of smoothing when computing the loss, where 0.0 means no smoothing. The targets
  2967|         0|            0|            0|  0.00%|            become a mixture of the original ground truth and a uniform distribution as described in
  2968|         0|            0|            0|  0.00%|            `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.
  2969|         0|            0|            0|  0.00%|
  2970|         0|            0|            0|  0.00%|    Shape:
  2971|         0|            0|            0|  0.00%|        - Input: Shape :math:`(C)`, :math:`(N, C)` or :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \geq 1`
  2972|         0|            0|            0|  0.00%|          in the case of `K`-dimensional loss.
  2973|         0|            0|            0|  0.00%|        - Target: If containing class indices, shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with
  2974|         0|            0|            0|  0.00%|          :math:`K \geq 1` in the case of K-dimensional loss where each value should be between :math:`[0, C)`.
  2975|         0|            0|            0|  0.00%|          If containing class probabilities, same shape as the input and each value should be between :math:`[0, 1]`.
  2976|         0|            0|            0|  0.00%|
  2977|         0|            0|            0|  0.00%|        where:
  2978|         0|            0|            0|  0.00%|
  2979|         0|            0|            0|  0.00%|        .. math::
  2980|         0|            0|            0|  0.00%|            \begin{aligned}
  2981|         0|            0|            0|  0.00%|                C ={} & \text{number of classes} \\
  2982|         0|            0|            0|  0.00%|                N ={} & \text{batch size} \\
  2983|         0|            0|            0|  0.00%|            \end{aligned}
  2984|         0|            0|            0|  0.00%|
  2985|         0|            0|            0|  0.00%|    Examples::
  2986|         0|            0|            0|  0.00%|
  2987|         0|            0|            0|  0.00%|        >>> # Example of target with class indices
  2988|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)
  2989|         0|            0|            0|  0.00%|        >>> target = torch.randint(5, (3,), dtype=torch.int64)
  2990|         0|            0|            0|  0.00%|        >>> loss = F.cross_entropy(input, target)
  2991|         0|            0|            0|  0.00%|        >>> loss.backward()
  2992|         0|            0|            0|  0.00%|        >>>
  2993|         0|            0|            0|  0.00%|        >>> # Example of target with class probabilities
  2994|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)
  2995|         0|            0|            0|  0.00%|        >>> target = torch.randn(3, 5).softmax(dim=1)
  2996|         0|            0|            0|  0.00%|        >>> loss = F.cross_entropy(input, target)
  2997|         0|            0|            0|  0.00%|        >>> loss.backward()
  2998|         0|            0|            0|  0.00%|    """
  2999|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, weight):
  3000|         0|            0|            0|  0.00%|        return handle_torch_function(
  3001|         0|            0|            0|  0.00%|            cross_entropy,
  3002|         0|            0|            0|  0.00%|            (input, target, weight),
  3003|         0|            0|            0|  0.00%|            input,
  3004|         0|            0|            0|  0.00%|            target,
  3005|         0|            0|            0|  0.00%|            weight=weight,
  3006|         0|            0|            0|  0.00%|            size_average=size_average,
  3007|         0|            0|            0|  0.00%|            ignore_index=ignore_index,
  3008|         0|            0|            0|  0.00%|            reduce=reduce,
  3009|         0|            0|            0|  0.00%|            reduction=reduction,
  3010|         0|            0|            0|  0.00%|            label_smoothing=label_smoothing,
  3011|         0|            0|            0|  0.00%|        )
  3012|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  3013|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)
  3014|         0|            0|            0|  0.00%|    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
  3015|         0|            0|            0|  0.00%|
  3016|         0|            0|            0|  0.00%|
  3017|         0|            0|            0|  0.00%|def binary_cross_entropy(
  3018|         0|            0|            0|  0.00%|    input: Tensor,
  3019|         0|            0|            0|  0.00%|    target: Tensor,
  3020|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,
  3021|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  3022|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  3023|         0|            0|            0|  0.00%|    reduction: str = "mean",
  3024|         0|            0|            0|  0.00%|) -> Tensor:
  3025|         0|            0|            0|  0.00%|    r"""Function that measures the Binary Cross Entropy between the target and input
  3026|         0|            0|            0|  0.00%|    probabilities.
  3027|         0|            0|            0|  0.00%|
  3028|         0|            0|            0|  0.00%|    See :class:`~torch.nn.BCELoss` for details.
  3029|         0|            0|            0|  0.00%|
  3030|         0|            0|            0|  0.00%|    Args:
  3031|         0|            0|            0|  0.00%|        input: Tensor of arbitrary shape as probabilities.
  3032|         0|            0|            0|  0.00%|        target: Tensor of the same shape as input with values between 0 and 1.
  3033|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight
  3034|         0|            0|            0|  0.00%|                if provided it's repeated to match input tensor shape
  3035|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
  3036|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for
  3037|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`
  3038|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored
  3039|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``
  3040|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
  3041|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending
  3042|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
  3043|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``
  3044|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:
  3045|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
  3046|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of
  3047|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
  3048|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,
  3049|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
  3050|         0|            0|            0|  0.00%|
  3051|         0|            0|            0|  0.00%|    Examples::
  3052|         0|            0|            0|  0.00%|
  3053|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 2, requires_grad=True)
  3054|         0|            0|            0|  0.00%|        >>> target = torch.rand(3, 2, requires_grad=False)
  3055|         0|            0|            0|  0.00%|        >>> loss = F.binary_cross_entropy(torch.sigmoid(input), target)
  3056|         0|            0|            0|  0.00%|        >>> loss.backward()
  3057|         0|            0|            0|  0.00%|    """
  3058|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, weight):
  3059|         0|            0|            0|  0.00%|        return handle_torch_function(
  3060|         0|            0|            0|  0.00%|            binary_cross_entropy,
  3061|         0|            0|            0|  0.00%|            (input, target, weight),
  3062|         0|            0|            0|  0.00%|            input,
  3063|         0|            0|            0|  0.00%|            target,
  3064|         0|            0|            0|  0.00%|            weight=weight,
  3065|         0|            0|            0|  0.00%|            size_average=size_average,
  3066|         0|            0|            0|  0.00%|            reduce=reduce,
  3067|         0|            0|            0|  0.00%|            reduction=reduction,
  3068|         0|            0|            0|  0.00%|        )
  3069|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  3070|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)
  3071|         0|            0|            0|  0.00%|    else:
  3072|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)
  3073|         0|            0|            0|  0.00%|    if target.size() != input.size():
  3074|         0|            0|            0|  0.00%|        raise ValueError(
  3075|         0|            0|            0|  0.00%|            "Using a target size ({}) that is different to the input size ({}) is deprecated. "
  3076|         0|            0|            0|  0.00%|            "Please ensure they have the same size.".format(target.size(), input.size())
  3077|         0|            0|            0|  0.00%|        )
  3078|         0|            0|            0|  0.00%|
  3079|         0|            0|            0|  0.00%|    if weight is not None:
  3080|         0|            0|            0|  0.00%|        new_size = _infer_size(target.size(), weight.size())
  3081|         0|            0|            0|  0.00%|        weight = weight.expand(new_size)
  3082|         0|            0|            0|  0.00%|
  3083|         0|            0|            0|  0.00%|    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
  3084|         0|            0|            0|  0.00%|
  3085|         0|            0|            0|  0.00%|
  3086|         0|            0|            0|  0.00%|def binary_cross_entropy_with_logits(
  3087|         0|            0|            0|  0.00%|    input: Tensor,
  3088|         0|            0|            0|  0.00%|    target: Tensor,
  3089|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,
  3090|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  3091|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  3092|         0|            0|            0|  0.00%|    reduction: str = "mean",
  3093|         0|            0|            0|  0.00%|    pos_weight: Optional[Tensor] = None,
  3094|         0|            0|            0|  0.00%|) -> Tensor:
  3095|         0|            0|            0|  0.00%|    r"""Function that measures Binary Cross Entropy between target and input
  3096|         0|            0|            0|  0.00%|    logits.
  3097|         0|            0|            0|  0.00%|
  3098|         0|            0|            0|  0.00%|    See :class:`~torch.nn.BCEWithLogitsLoss` for details.
  3099|         0|            0|            0|  0.00%|
  3100|         0|            0|            0|  0.00%|    Args:
  3101|         0|            0|            0|  0.00%|        input: Tensor of arbitrary shape as unnormalized scores (often referred to as logits).
  3102|         0|            0|            0|  0.00%|        target: Tensor of the same shape as input with values between 0 and 1
  3103|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight
  3104|         0|            0|            0|  0.00%|            if provided it's repeated to match input tensor shape
  3105|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
  3106|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for
  3107|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`
  3108|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored
  3109|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``
  3110|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
  3111|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending
  3112|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
  3113|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``
  3114|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:
  3115|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
  3116|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of
  3117|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
  3118|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,
  3119|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
  3120|         0|            0|            0|  0.00%|        pos_weight (Tensor, optional): a weight of positive examples.
  3121|         0|            0|            0|  0.00%|                Must be a vector with length equal to the number of classes.
  3122|         0|            0|            0|  0.00%|
  3123|         0|            0|            0|  0.00%|    Examples::
  3124|         0|            0|            0|  0.00%|
  3125|         0|            0|            0|  0.00%|         >>> input = torch.randn(3, requires_grad=True)
  3126|         0|            0|            0|  0.00%|         >>> target = torch.empty(3).random_(2)
  3127|         0|            0|            0|  0.00%|         >>> loss = F.binary_cross_entropy_with_logits(input, target)
  3128|         0|            0|            0|  0.00%|         >>> loss.backward()
  3129|         0|            0|            0|  0.00%|    """
  3130|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, weight, pos_weight):
  3131|         0|            0|            0|  0.00%|        return handle_torch_function(
  3132|         0|            0|            0|  0.00%|            binary_cross_entropy_with_logits,
  3133|         0|            0|            0|  0.00%|            (input, target, weight, pos_weight),
  3134|         0|            0|            0|  0.00%|            input,
  3135|         0|            0|            0|  0.00%|            target,
  3136|         0|            0|            0|  0.00%|            weight=weight,
  3137|         0|            0|            0|  0.00%|            size_average=size_average,
  3138|         0|            0|            0|  0.00%|            reduce=reduce,
  3139|         0|            0|            0|  0.00%|            reduction=reduction,
  3140|         0|            0|            0|  0.00%|            pos_weight=pos_weight,
  3141|         0|            0|            0|  0.00%|        )
  3142|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  3143|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)
  3144|         0|            0|            0|  0.00%|    else:
  3145|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)
  3146|         0|            0|            0|  0.00%|
  3147|         0|            0|            0|  0.00%|    if not (target.size() == input.size()):
  3148|         0|            0|            0|  0.00%|        raise ValueError("Target size ({}) must be the same as input size ({})".format(target.size(), input.size()))
  3149|         0|            0|            0|  0.00%|
  3150|         0|            0|            0|  0.00%|    return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)
  3151|         0|            0|            0|  0.00%|
  3152|         0|            0|            0|  0.00%|
  3153|         0|            0|            0|  0.00%|def smooth_l1_loss(
  3154|         0|            0|            0|  0.00%|    input: Tensor,
  3155|         0|            0|            0|  0.00%|    target: Tensor,
  3156|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  3157|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  3158|         0|            0|            0|  0.00%|    reduction: str = "mean",
  3159|         0|            0|            0|  0.00%|    beta: float = 1.0,
  3160|         0|            0|            0|  0.00%|) -> Tensor:
  3161|         0|            0|            0|  0.00%|    r"""Function that uses a squared term if the absolute
  3162|         0|            0|            0|  0.00%|    element-wise error falls below beta and an L1 term otherwise.
  3163|         0|            0|            0|  0.00%|
  3164|         0|            0|            0|  0.00%|    See :class:`~torch.nn.SmoothL1Loss` for details.
  3165|         0|            0|            0|  0.00%|    """
  3166|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):
  3167|         0|            0|            0|  0.00%|        return handle_torch_function(
  3168|         0|            0|            0|  0.00%|            smooth_l1_loss,
  3169|         0|            0|            0|  0.00%|            (input, target),
  3170|         0|            0|            0|  0.00%|            input,
  3171|         0|            0|            0|  0.00%|            target,
  3172|         0|            0|            0|  0.00%|            size_average=size_average,
  3173|         0|            0|            0|  0.00%|            reduce=reduce,
  3174|         0|            0|            0|  0.00%|            reduction=reduction,
  3175|         0|            0|            0|  0.00%|            beta=beta,
  3176|         0|            0|            0|  0.00%|        )
  3177|         0|            0|            0|  0.00%|    if not (target.size() == input.size()):
  3178|         0|            0|            0|  0.00%|        warnings.warn(
  3179|         0|            0|            0|  0.00%|            "Using a target size ({}) that is different to the input size ({}). "
  3180|         0|            0|            0|  0.00%|            "This will likely lead to incorrect results due to broadcasting. "
  3181|         0|            0|            0|  0.00%|            "Please ensure they have the same size.".format(target.size(), input.size()),
  3182|         0|            0|            0|  0.00%|            stacklevel=2,
  3183|         0|            0|            0|  0.00%|        )
  3184|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  3185|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)
  3186|         0|            0|            0|  0.00%|
  3187|         0|            0|            0|  0.00%|    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
  3188|         0|            0|            0|  0.00%|    return torch._C._nn.smooth_l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction), beta)
  3189|         0|            0|            0|  0.00%|
  3190|         0|            0|            0|  0.00%|
  3191|         0|            0|            0|  0.00%|def huber_loss(
  3192|         0|            0|            0|  0.00%|    input: Tensor,
  3193|         0|            0|            0|  0.00%|    target: Tensor,
  3194|         0|            0|            0|  0.00%|    reduction: str = 'mean',
  3195|         0|            0|            0|  0.00%|    delta: float = 1.0,
  3196|         0|            0|            0|  0.00%|) -> Tensor:
  3197|         0|            0|            0|  0.00%|    r"""Function that uses a squared term if the absolute
  3198|         0|            0|            0|  0.00%|    element-wise error falls below delta and a delta-scaled L1 term otherwise.
  3199|         0|            0|            0|  0.00%|
  3200|         0|            0|            0|  0.00%|    See :class:`~torch.nn.HuberLoss` for details.
  3201|         0|            0|            0|  0.00%|    """
  3202|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):
  3203|         0|            0|            0|  0.00%|        return handle_torch_function(
  3204|         0|            0|            0|  0.00%|            huber_loss,
  3205|         0|            0|            0|  0.00%|            (input, target),
  3206|         0|            0|            0|  0.00%|            input,
  3207|         0|            0|            0|  0.00%|            target,
  3208|         0|            0|            0|  0.00%|            reduction=reduction,
  3209|         0|            0|            0|  0.00%|            delta=delta,
  3210|         0|            0|            0|  0.00%|        )
  3211|         0|            0|            0|  0.00%|    if not (target.size() == input.size()):
  3212|         0|            0|            0|  0.00%|        warnings.warn("Using a target size ({}) that is different to the input size ({}). "
  3213|         0|            0|            0|  0.00%|                      "This will likely lead to incorrect results due to broadcasting. "
  3214|         0|            0|            0|  0.00%|                      "Please ensure they have the same size.".format(target.size(), input.size()),
  3215|         0|            0|            0|  0.00%|                      stacklevel=2)
  3216|         0|            0|            0|  0.00%|
  3217|         0|            0|            0|  0.00%|    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
  3218|         0|            0|            0|  0.00%|    return torch._C._nn.huber_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction), delta)
  3219|         0|            0|            0|  0.00%|
  3220|         0|            0|            0|  0.00%|
  3221|         0|            0|            0|  0.00%|def l1_loss(
  3222|         0|            0|            0|  0.00%|    input: Tensor,
  3223|         0|            0|            0|  0.00%|    target: Tensor,
  3224|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  3225|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  3226|         0|            0|            0|  0.00%|    reduction: str = "mean",
  3227|         0|            0|            0|  0.00%|) -> Tensor:
  3228|         0|            0|            0|  0.00%|    r"""l1_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor
  3229|         0|            0|            0|  0.00%|
  3230|         0|            0|            0|  0.00%|    Function that takes the mean element-wise absolute value difference.
  3231|         0|            0|            0|  0.00%|
  3232|         0|            0|            0|  0.00%|    See :class:`~torch.nn.L1Loss` for details.
  3233|         0|            0|            0|  0.00%|    """
  3234|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):
  3235|         0|            0|            0|  0.00%|        return handle_torch_function(
  3236|         0|            0|            0|  0.00%|            l1_loss, (input, target), input, target, size_average=size_average, reduce=reduce, reduction=reduction
  3237|         0|            0|            0|  0.00%|        )
  3238|         0|            0|            0|  0.00%|    if not (target.size() == input.size()):
  3239|         0|            0|            0|  0.00%|        warnings.warn(
  3240|         0|            0|            0|  0.00%|            "Using a target size ({}) that is different to the input size ({}). "
  3241|         0|            0|            0|  0.00%|            "This will likely lead to incorrect results due to broadcasting. "
  3242|         0|            0|            0|  0.00%|            "Please ensure they have the same size.".format(target.size(), input.size()),
  3243|         0|            0|            0|  0.00%|            stacklevel=2,
  3244|         0|            0|            0|  0.00%|        )
  3245|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  3246|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)
  3247|         0|            0|            0|  0.00%|
  3248|         0|            0|            0|  0.00%|    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
  3249|         0|            0|            0|  0.00%|    return torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
  3250|         0|            0|            0|  0.00%|
  3251|         0|            0|            0|  0.00%|
  3252|         0|            0|            0|  0.00%|def mse_loss(
  3253|         0|            0|            0|  0.00%|    input: Tensor,
  3254|         0|            0|            0|  0.00%|    target: Tensor,
  3255|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  3256|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  3257|         0|            0|            0|  0.00%|    reduction: str = "mean",
  3258|         0|            0|            0|  0.00%|) -> Tensor:
  3259|         0|            0|            0|  0.00%|    r"""mse_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor
  3260|         0|            0|            0|  0.00%|
  3261|         0|            0|            0|  0.00%|    Measures the element-wise mean squared error.
  3262|         0|            0|            0|  0.00%|
  3263|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MSELoss` for details.
  3264|         0|            0|            0|  0.00%|    """
  3265|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):
  3266|         0|            0|            0|  0.00%|        return handle_torch_function(
  3267|         0|            0|            0|  0.00%|            mse_loss, (input, target), input, target, size_average=size_average, reduce=reduce, reduction=reduction
  3268|         0|            0|            0|  0.00%|        )
  3269|         0|            0|            0|  0.00%|    if not (target.size() == input.size()):
  3270|         0|            0|            0|  0.00%|        warnings.warn(
  3271|         0|            0|            0|  0.00%|            "Using a target size ({}) that is different to the input size ({}). "
  3272|         0|            0|            0|  0.00%|            "This will likely lead to incorrect results due to broadcasting. "
  3273|         0|            0|            0|  0.00%|            "Please ensure they have the same size.".format(target.size(), input.size()),
  3274|         0|            0|            0|  0.00%|            stacklevel=2,
  3275|         0|            0|            0|  0.00%|        )
  3276|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  3277|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)
  3278|         0|            0|            0|  0.00%|
  3279|         0|            0|            0|  0.00%|    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
  3280|         0|            0|            0|  0.00%|    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
  3281|         0|            0|            0|  0.00%|
  3282|         0|            0|            0|  0.00%|
  3283|         0|            0|            0|  0.00%|def margin_ranking_loss(
  3284|         0|            0|            0|  0.00%|    input1: Tensor,
  3285|         0|            0|            0|  0.00%|    input2: Tensor,
  3286|         0|            0|            0|  0.00%|    target: Tensor,
  3287|         0|            0|            0|  0.00%|    margin: float = 0,
  3288|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  3289|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  3290|         0|            0|            0|  0.00%|    reduction: str = "mean",
  3291|         0|            0|            0|  0.00%|) -> Tensor:
  3292|         0|            0|            0|  0.00%|    r"""margin_ranking_loss(input1, input2, target, margin=0, size_average=None, reduce=None, reduction='mean') -> Tensor
  3293|         0|            0|            0|  0.00%|
  3294|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MarginRankingLoss` for details.
  3295|         0|            0|            0|  0.00%|    """
  3296|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input1, input2, target):
  3297|         0|            0|            0|  0.00%|        return handle_torch_function(
  3298|         0|            0|            0|  0.00%|            margin_ranking_loss,
  3299|         0|            0|            0|  0.00%|            (input1, input2, target),
  3300|         0|            0|            0|  0.00%|            input1,
  3301|         0|            0|            0|  0.00%|            input2,
  3302|         0|            0|            0|  0.00%|            target,
  3303|         0|            0|            0|  0.00%|            margin=margin,
  3304|         0|            0|            0|  0.00%|            size_average=size_average,
  3305|         0|            0|            0|  0.00%|            reduce=reduce,
  3306|         0|            0|            0|  0.00%|            reduction=reduction,
  3307|         0|            0|            0|  0.00%|        )
  3308|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  3309|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)
  3310|         0|            0|            0|  0.00%|    else:
  3311|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)
  3312|         0|            0|            0|  0.00%|    if (input1.dim() != input2.dim() or input1.dim() != target.dim()):
  3313|         0|            0|            0|  0.00%|        raise RuntimeError(
  3314|         0|            0|            0|  0.00%|            (
  3315|         0|            0|            0|  0.00%|                "margin_ranking_loss : All input tensors should have same dimension but got sizes: "
  3316|         0|            0|            0|  0.00%|                "input1: {}, input2: {}, target: {} ".format(input1.size(), input2.size(), target.size())
  3317|         0|            0|            0|  0.00%|            )
  3318|         0|            0|            0|  0.00%|        )
  3319|         0|            0|            0|  0.00%|    return torch.margin_ranking_loss(input1, input2, target, margin, reduction_enum)
  3320|         0|            0|            0|  0.00%|
  3321|         0|            0|            0|  0.00%|
  3322|         0|            0|            0|  0.00%|def hinge_embedding_loss(
  3323|         0|            0|            0|  0.00%|    input: Tensor,
  3324|         0|            0|            0|  0.00%|    target: Tensor,
  3325|         0|            0|            0|  0.00%|    margin: float = 1.0,
  3326|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  3327|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  3328|         0|            0|            0|  0.00%|    reduction: str = "mean",
  3329|         0|            0|            0|  0.00%|) -> Tensor:
  3330|         0|            0|            0|  0.00%|    r"""hinge_embedding_loss(input, target, margin=1.0, size_average=None, reduce=None, reduction='mean') -> Tensor
  3331|         0|            0|            0|  0.00%|
  3332|         0|            0|            0|  0.00%|    See :class:`~torch.nn.HingeEmbeddingLoss` for details.
  3333|         0|            0|            0|  0.00%|    """
  3334|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):
  3335|         0|            0|            0|  0.00%|        return handle_torch_function(
  3336|         0|            0|            0|  0.00%|            hinge_embedding_loss,
  3337|         0|            0|            0|  0.00%|            (input, target),
  3338|         0|            0|            0|  0.00%|            input,
  3339|         0|            0|            0|  0.00%|            target,
  3340|         0|            0|            0|  0.00%|            margin=margin,
  3341|         0|            0|            0|  0.00%|            size_average=size_average,
  3342|         0|            0|            0|  0.00%|            reduce=reduce,
  3343|         0|            0|            0|  0.00%|            reduction=reduction,
  3344|         0|            0|            0|  0.00%|        )
  3345|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  3346|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)
  3347|         0|            0|            0|  0.00%|    else:
  3348|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)
  3349|         0|            0|            0|  0.00%|    return torch.hinge_embedding_loss(input, target, margin, reduction_enum)
  3350|         0|            0|            0|  0.00%|
  3351|         0|            0|            0|  0.00%|
  3352|         0|            0|            0|  0.00%|def multilabel_margin_loss(
  3353|         0|            0|            0|  0.00%|    input: Tensor,
  3354|         0|            0|            0|  0.00%|    target: Tensor,
  3355|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  3356|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  3357|         0|            0|            0|  0.00%|    reduction: str = "mean",
  3358|         0|            0|            0|  0.00%|) -> Tensor:
  3359|         0|            0|            0|  0.00%|    r"""multilabel_margin_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor
  3360|         0|            0|            0|  0.00%|
  3361|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MultiLabelMarginLoss` for details.
  3362|         0|            0|            0|  0.00%|    """
  3363|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):
  3364|         0|            0|            0|  0.00%|        return handle_torch_function(
  3365|         0|            0|            0|  0.00%|            multilabel_margin_loss,
  3366|         0|            0|            0|  0.00%|            (input, target),
  3367|         0|            0|            0|  0.00%|            input,
  3368|         0|            0|            0|  0.00%|            target,
  3369|         0|            0|            0|  0.00%|            size_average=size_average,
  3370|         0|            0|            0|  0.00%|            reduce=reduce,
  3371|         0|            0|            0|  0.00%|            reduction=reduction,
  3372|         0|            0|            0|  0.00%|        )
  3373|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  3374|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)
  3375|         0|            0|            0|  0.00%|    else:
  3376|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)
  3377|         0|            0|            0|  0.00%|    return torch._C._nn.multilabel_margin_loss(input, target, reduction_enum)
  3378|         0|            0|            0|  0.00%|
  3379|         0|            0|            0|  0.00%|
  3380|         0|            0|            0|  0.00%|def soft_margin_loss(
  3381|         0|            0|            0|  0.00%|    input: Tensor,
  3382|         0|            0|            0|  0.00%|    target: Tensor,
  3383|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  3384|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  3385|         0|            0|            0|  0.00%|    reduction: str = "mean",
  3386|         0|            0|            0|  0.00%|) -> Tensor:
  3387|         0|            0|            0|  0.00%|    r"""soft_margin_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor
  3388|         0|            0|            0|  0.00%|
  3389|         0|            0|            0|  0.00%|    See :class:`~torch.nn.SoftMarginLoss` for details.
  3390|         0|            0|            0|  0.00%|    """
  3391|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):
  3392|         0|            0|            0|  0.00%|        return handle_torch_function(
  3393|         0|            0|            0|  0.00%|            soft_margin_loss, (input, target), input, target, size_average=size_average, reduce=reduce, reduction=reduction
  3394|         0|            0|            0|  0.00%|        )
  3395|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  3396|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)
  3397|         0|            0|            0|  0.00%|    else:
  3398|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)
  3399|         0|            0|            0|  0.00%|    return torch._C._nn.soft_margin_loss(input, target, reduction_enum)
  3400|         0|            0|            0|  0.00%|
  3401|         0|            0|            0|  0.00%|
  3402|         0|            0|            0|  0.00%|def multilabel_soft_margin_loss(
  3403|         0|            0|            0|  0.00%|    input: Tensor,
  3404|         0|            0|            0|  0.00%|    target: Tensor,
  3405|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,
  3406|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  3407|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  3408|         0|            0|            0|  0.00%|    reduction: str = "mean",
  3409|         0|            0|            0|  0.00%|) -> Tensor:
  3410|         0|            0|            0|  0.00%|    r"""multilabel_soft_margin_loss(input, target, weight=None, size_average=None, reduce=None, reduction='mean') -> Tensor
  3411|         0|            0|            0|  0.00%|
  3412|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MultiLabelSoftMarginLoss` for details.
  3413|         0|            0|            0|  0.00%|    """
  3414|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, weight):
  3415|         0|            0|            0|  0.00%|        return handle_torch_function(
  3416|         0|            0|            0|  0.00%|            multilabel_soft_margin_loss,
  3417|         0|            0|            0|  0.00%|            (input, target, weight),
  3418|         0|            0|            0|  0.00%|            input,
  3419|         0|            0|            0|  0.00%|            target,
  3420|         0|            0|            0|  0.00%|            weight=weight,
  3421|         0|            0|            0|  0.00%|            size_average=size_average,
  3422|         0|            0|            0|  0.00%|            reduce=reduce,
  3423|         0|            0|            0|  0.00%|            reduction=reduction,
  3424|         0|            0|            0|  0.00%|        )
  3425|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  3426|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)
  3427|         0|            0|            0|  0.00%|
  3428|         0|            0|            0|  0.00%|    loss = -(target * logsigmoid(input) + (1 - target) * logsigmoid(-input))
  3429|         0|            0|            0|  0.00%|
  3430|         0|            0|            0|  0.00%|    if weight is not None:
  3431|         0|            0|            0|  0.00%|        loss = loss * weight
  3432|         0|            0|            0|  0.00%|
  3433|         0|            0|            0|  0.00%|    class_dim = input.dim() - 1
  3434|         0|            0|            0|  0.00%|    C = input.size(class_dim)
  3435|         0|            0|            0|  0.00%|    loss = loss.sum(dim=class_dim) / C  # only return N loss values
  3436|         0|            0|            0|  0.00%|
  3437|         0|            0|            0|  0.00%|    if reduction == "none":
  3438|         0|            0|            0|  0.00%|        ret = loss
  3439|         0|            0|            0|  0.00%|    elif reduction == "mean":
  3440|         0|            0|            0|  0.00%|        ret = loss.mean()
  3441|         0|            0|            0|  0.00%|    elif reduction == "sum":
  3442|         0|            0|            0|  0.00%|        ret = loss.sum()
  3443|         0|            0|            0|  0.00%|    else:
  3444|         0|            0|            0|  0.00%|        ret = input
  3445|         0|            0|            0|  0.00%|        raise ValueError(reduction + " is not valid")
  3446|         0|            0|            0|  0.00%|    return ret
  3447|         0|            0|            0|  0.00%|
  3448|         0|            0|            0|  0.00%|
  3449|         0|            0|            0|  0.00%|def cosine_embedding_loss(
  3450|         0|            0|            0|  0.00%|    input1: Tensor,
  3451|         0|            0|            0|  0.00%|    input2: Tensor,
  3452|         0|            0|            0|  0.00%|    target: Tensor,
  3453|         0|            0|            0|  0.00%|    margin: float = 0,
  3454|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  3455|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  3456|         0|            0|            0|  0.00%|    reduction: str = "mean",
  3457|         0|            0|            0|  0.00%|) -> Tensor:
  3458|         0|            0|            0|  0.00%|    r"""cosine_embedding_loss(input1, input2, target, margin=0, size_average=None, reduce=None, reduction='mean') -> Tensor
  3459|         0|            0|            0|  0.00%|
  3460|         0|            0|            0|  0.00%|    See :class:`~torch.nn.CosineEmbeddingLoss` for details.
  3461|         0|            0|            0|  0.00%|    """
  3462|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input1, input2, target):
  3463|         0|            0|            0|  0.00%|        return handle_torch_function(
  3464|         0|            0|            0|  0.00%|            cosine_embedding_loss,
  3465|         0|            0|            0|  0.00%|            (input1, input2, target),
  3466|         0|            0|            0|  0.00%|            input1,
  3467|         0|            0|            0|  0.00%|            input2,
  3468|         0|            0|            0|  0.00%|            target,
  3469|         0|            0|            0|  0.00%|            margin=margin,
  3470|         0|            0|            0|  0.00%|            size_average=size_average,
  3471|         0|            0|            0|  0.00%|            reduce=reduce,
  3472|         0|            0|            0|  0.00%|            reduction=reduction,
  3473|         0|            0|            0|  0.00%|        )
  3474|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  3475|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)
  3476|         0|            0|            0|  0.00%|    else:
  3477|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)
  3478|         0|            0|            0|  0.00%|    return torch.cosine_embedding_loss(input1, input2, target, margin, reduction_enum)
  3479|         0|            0|            0|  0.00%|
  3480|         0|            0|            0|  0.00%|
  3481|         0|            0|            0|  0.00%|def multi_margin_loss(
  3482|         0|            0|            0|  0.00%|    input: Tensor,
  3483|         0|            0|            0|  0.00%|    target: Tensor,
  3484|         0|            0|            0|  0.00%|    p: int = 1,
  3485|         0|            0|            0|  0.00%|    margin: float = 1.0,
  3486|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,
  3487|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  3488|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  3489|         0|            0|            0|  0.00%|    reduction: str = "mean",
  3490|         0|            0|            0|  0.00%|) -> Tensor:
  3491|         0|            0|            0|  0.00%|    r"""multi_margin_loss(input, target, p=1, margin=1, weight=None, size_average=None, reduce=None, reduction='mean') -> Tensor
  3492|         0|            0|            0|  0.00%|
  3493|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MultiMarginLoss` for details.
  3494|         0|            0|            0|  0.00%|    """
  3495|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, weight):
  3496|         0|            0|            0|  0.00%|        return handle_torch_function(
  3497|         0|            0|            0|  0.00%|            multi_margin_loss,
  3498|         0|            0|            0|  0.00%|            (input, target, weight),
  3499|         0|            0|            0|  0.00%|            input,
  3500|         0|            0|            0|  0.00%|            target,
  3501|         0|            0|            0|  0.00%|            p=p,
  3502|         0|            0|            0|  0.00%|            margin=margin,
  3503|         0|            0|            0|  0.00%|            weight=weight,
  3504|         0|            0|            0|  0.00%|            size_average=size_average,
  3505|         0|            0|            0|  0.00%|            reduce=reduce,
  3506|         0|            0|            0|  0.00%|            reduction=reduction,
  3507|         0|            0|            0|  0.00%|        )
  3508|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  3509|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)
  3510|         0|            0|            0|  0.00%|    else:
  3511|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)
  3512|         0|            0|            0|  0.00%|    if p != 1 and p != 2:
  3513|         0|            0|            0|  0.00%|        raise ValueError("only p == 1 and p == 2 supported")
  3514|         0|            0|            0|  0.00%|    if weight is not None:
  3515|         0|            0|            0|  0.00%|        if weight.dim() != 1:
  3516|         0|            0|            0|  0.00%|            raise ValueError("weight must be one-dimensional")
  3517|         0|            0|            0|  0.00%|
  3518|         0|            0|            0|  0.00%|    return torch._C._nn.multi_margin_loss(input, target, p, margin, weight, reduction_enum)
  3519|         0|            0|            0|  0.00%|
  3520|         0|            0|            0|  0.00%|
  3521|         0|            0|            0|  0.00%|pixel_shuffle = _add_docstr(
  3522|         0|            0|            0|  0.00%|    torch.pixel_shuffle,
  3523|         0|            0|            0|  0.00%|    r"""
  3524|         0|            0|            0|  0.00%|pixel_shuffle(input, upscale_factor) -> Tensor
  3525|         0|            0|            0|  0.00%|
  3526|         0|            0|            0|  0.00%|Rearranges elements in a tensor of shape :math:`(*, C \times r^2, H, W)` to a
  3527|         0|            0|            0|  0.00%|tensor of shape :math:`(*, C, H \times r, W \times r)`, where r is the :attr:`upscale_factor`.
  3528|         0|            0|            0|  0.00%|
  3529|         0|            0|            0|  0.00%|See :class:`~torch.nn.PixelShuffle` for details.
  3530|         0|            0|            0|  0.00%|
  3531|         0|            0|            0|  0.00%|Args:
  3532|         0|            0|            0|  0.00%|    input (Tensor): the input tensor
  3533|         0|            0|            0|  0.00%|    upscale_factor (int): factor to increase spatial resolution by
  3534|         0|            0|            0|  0.00%|
  3535|         0|            0|            0|  0.00%|Examples::
  3536|         0|            0|            0|  0.00%|
  3537|         0|            0|            0|  0.00%|    >>> input = torch.randn(1, 9, 4, 4)
  3538|         0|            0|            0|  0.00%|    >>> output = torch.nn.functional.pixel_shuffle(input, 3)
  3539|         0|            0|            0|  0.00%|    >>> print(output.size())
  3540|         0|            0|            0|  0.00%|    torch.Size([1, 1, 12, 12])
  3541|         0|            0|            0|  0.00%|""",
  3542|         0|            0|            0|  0.00%|)
  3543|         0|            0|            0|  0.00%|
  3544|         0|            0|            0|  0.00%|pixel_unshuffle = _add_docstr(
  3545|         0|            0|            0|  0.00%|    torch.pixel_unshuffle,
  3546|         0|            0|            0|  0.00%|    r"""
  3547|         0|            0|            0|  0.00%|pixel_unshuffle(input, downscale_factor) -> Tensor
  3548|         0|            0|            0|  0.00%|
  3549|         0|            0|            0|  0.00%|Reverses the :class:`~torch.nn.PixelShuffle` operation by rearranging elements in a
  3550|         0|            0|            0|  0.00%|tensor of shape :math:`(*, C, H \times r, W \times r)` to a tensor of shape
  3551|         0|            0|            0|  0.00%|:math:`(*, C \times r^2, H, W)`, where r is the :attr:`downscale_factor`.
  3552|         0|            0|            0|  0.00%|
  3553|         0|            0|            0|  0.00%|See :class:`~torch.nn.PixelUnshuffle` for details.
  3554|         0|            0|            0|  0.00%|
  3555|         0|            0|            0|  0.00%|Args:
  3556|         0|            0|            0|  0.00%|    input (Tensor): the input tensor
  3557|         0|            0|            0|  0.00%|    downscale_factor (int): factor to increase spatial resolution by
  3558|         0|            0|            0|  0.00%|
  3559|         0|            0|            0|  0.00%|Examples::
  3560|         0|            0|            0|  0.00%|
  3561|         0|            0|            0|  0.00%|    >>> input = torch.randn(1, 1, 12, 12)
  3562|         0|            0|            0|  0.00%|    >>> output = torch.nn.functional.pixel_unshuffle(input, 3)
  3563|         0|            0|            0|  0.00%|    >>> print(output.size())
  3564|         0|            0|            0|  0.00%|    torch.Size([1, 9, 4, 4])
  3565|         0|            0|            0|  0.00%|""",
  3566|         0|            0|            0|  0.00%|)
  3567|         0|            0|            0|  0.00%|
  3568|         0|            0|            0|  0.00%|channel_shuffle = _add_docstr(
  3569|         0|            0|            0|  0.00%|    torch.channel_shuffle,
  3570|         0|            0|            0|  0.00%|    r"""
  3571|         0|            0|            0|  0.00%|channel_shuffle(input, groups) -> Tensor
  3572|         0|            0|            0|  0.00%|
  3573|         0|            0|            0|  0.00%|Divide the channels in a tensor of shape :math:`(*, C , H, W)`
  3574|         0|            0|            0|  0.00%|into g groups and rearrange them as :math:`(*, C \frac g, g, H, W)`,
  3575|         0|            0|            0|  0.00%|while keeping the original tensor shape.
  3576|         0|            0|            0|  0.00%|
  3577|         0|            0|            0|  0.00%|See :class:`~torch.nn.ChannelShuffle` for details.
  3578|         0|            0|            0|  0.00%|
  3579|         0|            0|            0|  0.00%|Args:
  3580|         0|            0|            0|  0.00%|    input (Tensor): the input tensor
  3581|         0|            0|            0|  0.00%|    groups (int): number of groups to divide channels in and rearrange.
  3582|         0|            0|            0|  0.00%|
  3583|         0|            0|            0|  0.00%|Examples::
  3584|         0|            0|            0|  0.00%|
  3585|         0|            0|            0|  0.00%|    >>> input = torch.randn(1, 4, 2, 2)
  3586|         0|            0|            0|  0.00%|    >>> print(input)
  3587|         0|            0|            0|  0.00%|    [[[[1, 2],
  3588|         0|            0|            0|  0.00%|       [3, 4]],
  3589|         0|            0|            0|  0.00%|      [[5, 6],
  3590|         0|            0|            0|  0.00%|       [7, 8]],
  3591|         0|            0|            0|  0.00%|      [[9, 10],
  3592|         0|            0|            0|  0.00%|       [11, 12]],
  3593|         0|            0|            0|  0.00%|      [[13, 14],
  3594|         0|            0|            0|  0.00%|       [15, 16]],
  3595|         0|            0|            0|  0.00%|     ]]
  3596|         0|            0|            0|  0.00%|    >>> output = torch.nn.functional.channel_shuffle(input, 2)
  3597|         0|            0|            0|  0.00%|    >>> print(output)
  3598|         0|            0|            0|  0.00%|    [[[[1, 2],
  3599|         0|            0|            0|  0.00%|       [3, 4]],
  3600|         0|            0|            0|  0.00%|      [[9, 10],
  3601|         0|            0|            0|  0.00%|       [11, 12]],
  3602|         0|            0|            0|  0.00%|      [[5, 6],
  3603|         0|            0|            0|  0.00%|       [7, 8]],
  3604|         0|            0|            0|  0.00%|      [[13, 14],
  3605|         0|            0|            0|  0.00%|       [15, 16]],
  3606|         0|            0|            0|  0.00%|     ]]
  3607|         0|            0|            0|  0.00%|""",
  3608|         0|            0|            0|  0.00%|)
  3609|         0|            0|            0|  0.00%|
  3610|         0|            0|            0|  0.00%|native_channel_shuffle = _add_docstr(
  3611|         0|            0|            0|  0.00%|    torch.native_channel_shuffle,
  3612|         0|            0|            0|  0.00%|    r"""
  3613|         0|            0|            0|  0.00%|native_channel_shuffle(input, groups) -> Tensor
  3614|         0|            0|            0|  0.00%|
  3615|         0|            0|            0|  0.00%|Native kernel level implementation of the `channel_shuffle`.
  3616|         0|            0|            0|  0.00%|This function might become private in future releases, use with caution.
  3617|         0|            0|            0|  0.00%|
  3618|         0|            0|            0|  0.00%|Divide the channels in a tensor of shape :math:`(*, C , H, W)`
  3619|         0|            0|            0|  0.00%|into g groups and rearrange them as :math:`(*, C \frac g, g, H, W)`,
  3620|         0|            0|            0|  0.00%|while keeping the original tensor shape.
  3621|         0|            0|            0|  0.00%|
  3622|         0|            0|            0|  0.00%|See :class:`~torch.nn.ChannelShuffle` for details.
  3623|         0|            0|            0|  0.00%|
  3624|         0|            0|            0|  0.00%|Args:
  3625|         0|            0|            0|  0.00%|    input (Tensor): the input tensor
  3626|         0|            0|            0|  0.00%|    groups (int): number of groups to divide channels in and rearrange.
  3627|         0|            0|            0|  0.00%|
  3628|         0|            0|            0|  0.00%|Examples::
  3629|         0|            0|            0|  0.00%|
  3630|         0|            0|            0|  0.00%|    >>> input = torch.randn(1, 4, 2, 2)
  3631|         0|            0|            0|  0.00%|    >>> print(input)
  3632|         0|            0|            0|  0.00%|    [[[[1, 2],
  3633|         0|            0|            0|  0.00%|       [3, 4]],
  3634|         0|            0|            0|  0.00%|      [[5, 6],
  3635|         0|            0|            0|  0.00%|       [7, 8]],
  3636|         0|            0|            0|  0.00%|      [[9, 10],
  3637|         0|            0|            0|  0.00%|       [11, 12]],
  3638|         0|            0|            0|  0.00%|      [[13, 14],
  3639|         0|            0|            0|  0.00%|       [15, 16]],
  3640|         0|            0|            0|  0.00%|     ]]
  3641|         0|            0|            0|  0.00%|    >>> output = torch.nn.functional.native_channel_shuffle(input, 2)
  3642|         0|            0|            0|  0.00%|    >>> print(output)
  3643|         0|            0|            0|  0.00%|    [[[[1, 2],
  3644|         0|            0|            0|  0.00%|       [3, 4]],
  3645|         0|            0|            0|  0.00%|      [[9, 10],
  3646|         0|            0|            0|  0.00%|       [11, 12]],
  3647|         0|            0|            0|  0.00%|      [[5, 6],
  3648|         0|            0|            0|  0.00%|       [7, 8]],
  3649|         0|            0|            0|  0.00%|      [[13, 14],
  3650|         0|            0|            0|  0.00%|       [15, 16]],
  3651|         0|            0|            0|  0.00%|     ]]
  3652|         0|            0|            0|  0.00%|""",
  3653|         0|            0|            0|  0.00%|)
  3654|         0|            0|            0|  0.00%|
  3655|         0|            0|            0|  0.00%|@_overload  # noqa: F811
  3656|         0|            0|            0|  0.00%|def upsample(input: Tensor, size: Optional[int] = None, scale_factor: Optional[float] = None, mode: str = "nearest", align_corners: Optional[bool] = None) -> Tensor:  # noqa: F811
  3657|         0|            0|            0|  0.00%|    pass
  3658|         0|            0|            0|  0.00%|
  3659|         0|            0|            0|  0.00%|
  3660|         0|            0|            0|  0.00%|@_overload  # noqa: F811
  3661|         0|            0|            0|  0.00%|def upsample(input: Tensor, size: Optional[List[int]] = None, scale_factor: Optional[float] = None, mode: str = "nearest", align_corners: Optional[bool] = None) -> Tensor:  # noqa: F811
  3662|         0|            0|            0|  0.00%|    pass
  3663|         0|            0|            0|  0.00%|
  3664|         0|            0|            0|  0.00%|
  3665|         0|            0|            0|  0.00%|def upsample(input, size=None, scale_factor=None, mode="nearest", align_corners=None):  # noqa: F811
  3666|         0|            0|            0|  0.00%|    r"""Upsamples the input to either the given :attr:`size` or the given
  3667|         0|            0|            0|  0.00%|    :attr:`scale_factor`
  3668|         0|            0|            0|  0.00%|
  3669|         0|            0|            0|  0.00%|    .. warning::
  3670|         0|            0|            0|  0.00%|        This function is deprecated in favor of :func:`torch.nn.functional.interpolate`.
  3671|         0|            0|            0|  0.00%|        This is equivalent with ``nn.functional.interpolate(...)``.
  3672|         0|            0|            0|  0.00%|
  3673|         0|            0|            0|  0.00%|    Note:
  3674|         0|            0|            0|  0.00%|        {backward_reproducibility_note}
  3675|         0|            0|            0|  0.00%|
  3676|         0|            0|            0|  0.00%|    The algorithm used for upsampling is determined by :attr:`mode`.
  3677|         0|            0|            0|  0.00%|
  3678|         0|            0|            0|  0.00%|    Currently temporal, spatial and volumetric upsampling are supported, i.e.
  3679|         0|            0|            0|  0.00%|    expected inputs are 3-D, 4-D or 5-D in shape.
  3680|         0|            0|            0|  0.00%|
  3681|         0|            0|            0|  0.00%|    The input dimensions are interpreted in the form:
  3682|         0|            0|            0|  0.00%|    `mini-batch x channels x [optional depth] x [optional height] x width`.
  3683|         0|            0|            0|  0.00%|
  3684|         0|            0|            0|  0.00%|    The modes available for upsampling are: `nearest`, `linear` (3D-only),
  3685|         0|            0|            0|  0.00%|    `bilinear`, `bicubic` (4D-only), `trilinear` (5D-only)
  3686|         0|            0|            0|  0.00%|
  3687|         0|            0|            0|  0.00%|    Args:
  3688|         0|            0|            0|  0.00%|        input (Tensor): the input tensor
  3689|         0|            0|            0|  0.00%|        size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]):
  3690|         0|            0|            0|  0.00%|            output spatial size.
  3691|         0|            0|            0|  0.00%|        scale_factor (float or Tuple[float]): multiplier for spatial size. Has to match input size if it is a tuple.
  3692|         0|            0|            0|  0.00%|        mode (string): algorithm used for upsampling:
  3693|         0|            0|            0|  0.00%|            ``'nearest'`` | ``'linear'`` | ``'bilinear'`` | ``'bicubic'`` |
  3694|         0|            0|            0|  0.00%|            ``'trilinear'``. Default: ``'nearest'``
  3695|         0|            0|            0|  0.00%|        align_corners (bool, optional): Geometrically, we consider the pixels of the
  3696|         0|            0|            0|  0.00%|            input and output as squares rather than points.
  3697|         0|            0|            0|  0.00%|            If set to ``True``, the input and output tensors are aligned by the
  3698|         0|            0|            0|  0.00%|            center points of their corner pixels, preserving the values at the corner pixels.
  3699|         0|            0|            0|  0.00%|            If set to ``False``, the input and output tensors are aligned by the corner
  3700|         0|            0|            0|  0.00%|            points of their corner pixels, and the interpolation uses edge value padding
  3701|         0|            0|            0|  0.00%|            for out-of-boundary values, making this operation *independent* of input size
  3702|         0|            0|            0|  0.00%|            when :attr:`scale_factor` is kept the same. This only has an effect when :attr:`mode`
  3703|         0|            0|            0|  0.00%|            is ``'linear'``, ``'bilinear'``, ``'bicubic'`` or ``'trilinear'``.
  3704|         0|            0|            0|  0.00%|            Default: ``False``
  3705|         0|            0|            0|  0.00%|
  3706|         0|            0|            0|  0.00%|    .. note::
  3707|         0|            0|            0|  0.00%|        With ``mode='bicubic'``, it's possible to cause overshoot, in other words it can produce
  3708|         0|            0|            0|  0.00%|        negative values or values greater than 255 for images.
  3709|         0|            0|            0|  0.00%|        Explicitly call ``result.clamp(min=0, max=255)`` if you want to reduce the overshoot
  3710|         0|            0|            0|  0.00%|        when displaying the image.
  3711|         0|            0|            0|  0.00%|
  3712|         0|            0|            0|  0.00%|    .. warning::
  3713|         0|            0|            0|  0.00%|        With ``align_corners = True``, the linearly interpolating modes
  3714|         0|            0|            0|  0.00%|        (`linear`, `bilinear`, and `trilinear`) don't proportionally align the
  3715|         0|            0|            0|  0.00%|        output and input pixels, and thus the output values can depend on the
  3716|         0|            0|            0|  0.00%|        input size. This was the default behavior for these modes up to version
  3717|         0|            0|            0|  0.00%|        0.3.1. Since then, the default behavior is ``align_corners = False``.
  3718|         0|            0|            0|  0.00%|        See :class:`~torch.nn.Upsample` for concrete examples on how this
  3719|         0|            0|            0|  0.00%|        affects the outputs.
  3720|         0|            0|            0|  0.00%|
  3721|         0|            0|            0|  0.00%|    """
  3722|         0|            0|            0|  0.00%|    warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
  3723|         0|            0|            0|  0.00%|    return interpolate(input, size, scale_factor, mode, align_corners)
  3724|         0|            0|            0|  0.00%|
  3725|         0|            0|            0|  0.00%|
  3726|         0|            0|            0|  0.00%|if upsample.__doc__:
  3727|         0|            0|            0|  0.00%|    upsample.__doc__ = upsample.__doc__.format(**reproducibility_notes)
  3728|         0|            0|            0|  0.00%|
  3729|         0|            0|            0|  0.00%|
  3730|         0|            0|            0|  0.00%|@_overload  # noqa: F811
  3731|         0|            0|            0|  0.00%|def interpolate(input: Tensor, size: Optional[int] = None, scale_factor: Optional[List[float]] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None, antialias: bool = False) -> Tensor:  # noqa: F811
  3732|         0|            0|            0|  0.00%|    pass
  3733|         0|            0|            0|  0.00%|
  3734|         0|            0|            0|  0.00%|
  3735|         0|            0|            0|  0.00%|@_overload  # noqa: F811
  3736|         0|            0|            0|  0.00%|def interpolate(input: Tensor, size: Optional[List[int]] = None, scale_factor: Optional[List[float]] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None, antialias: bool = False) -> Tensor:  # noqa: F811
  3737|         0|            0|            0|  0.00%|    pass
  3738|         0|            0|            0|  0.00%|
  3739|         0|            0|            0|  0.00%|
  3740|         0|            0|            0|  0.00%|@_overload  # noqa: F811
  3741|         0|            0|            0|  0.00%|def interpolate(input: Tensor, size: Optional[int] = None, scale_factor: Optional[float] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None, antialias: bool = False) -> Tensor:  # noqa: F811
  3742|         0|            0|            0|  0.00%|    pass
  3743|         0|            0|            0|  0.00%|
  3744|         0|            0|            0|  0.00%|
  3745|         0|            0|            0|  0.00%|@_overload  # noqa: F811
  3746|         0|            0|            0|  0.00%|def interpolate(  # noqa: F811
  3747|         0|            0|            0|  0.00%|    input: Tensor,
  3748|         0|            0|            0|  0.00%|    size: Optional[List[int]] = None,
  3749|         0|            0|            0|  0.00%|    scale_factor: Optional[float] = None,
  3750|         0|            0|            0|  0.00%|    mode: str = "nearest",
  3751|         0|            0|            0|  0.00%|    align_corners: Optional[bool] = None,
  3752|         0|            0|            0|  0.00%|    recompute_scale_factor: Optional[bool] = None,
  3753|         0|            0|            0|  0.00%|    antialias: bool = False,
  3754|         0|            0|            0|  0.00%|) -> Tensor:  # noqa: F811
  3755|         0|            0|            0|  0.00%|    pass
  3756|         0|            0|            0|  0.00%|
  3757|         0|            0|            0|  0.00%|def interpolate(input: Tensor, size: Optional[int] = None, scale_factor: Optional[List[float]] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None, antialias: bool = False) -> Tensor:  # noqa: F811
  3758|         0|            0|            0|  0.00%|    r"""Down/up samples the input to either the given :attr:`size` or the given
  3759|         0|            0|            0|  0.00%|    :attr:`scale_factor`
  3760|         0|            0|            0|  0.00%|
  3761|         0|            0|            0|  0.00%|    The algorithm used for interpolation is determined by :attr:`mode`.
  3762|         0|            0|            0|  0.00%|
  3763|         0|            0|            0|  0.00%|    Currently temporal, spatial and volumetric sampling are supported, i.e.
  3764|         0|            0|            0|  0.00%|    expected inputs are 3-D, 4-D or 5-D in shape.
  3765|         0|            0|            0|  0.00%|
  3766|         0|            0|            0|  0.00%|    The input dimensions are interpreted in the form:
  3767|         0|            0|            0|  0.00%|    `mini-batch x channels x [optional depth] x [optional height] x width`.
  3768|         0|            0|            0|  0.00%|
  3769|         0|            0|            0|  0.00%|    The modes available for resizing are: `nearest`, `linear` (3D-only),
  3770|         0|            0|            0|  0.00%|    `bilinear`, `bicubic` (4D-only), `trilinear` (5D-only), `area`, `nearest-exact`
  3771|         0|            0|            0|  0.00%|
  3772|         0|            0|            0|  0.00%|    Args:
  3773|         0|            0|            0|  0.00%|        input (Tensor): the input tensor
  3774|         0|            0|            0|  0.00%|        size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]):
  3775|         0|            0|            0|  0.00%|            output spatial size.
  3776|         0|            0|            0|  0.00%|        scale_factor (float or Tuple[float]): multiplier for spatial size. If `scale_factor` is a tuple,
  3777|         0|            0|            0|  0.00%|            its length has to match `input.dim()`.
  3778|         0|            0|            0|  0.00%|        mode (str): algorithm used for upsampling:
  3779|         0|            0|            0|  0.00%|            ``'nearest'`` | ``'linear'`` | ``'bilinear'`` | ``'bicubic'`` |
  3780|         0|            0|            0|  0.00%|            ``'trilinear'`` | ``'area'`` | ``'nearest-exact'``. Default: ``'nearest'``
  3781|         0|            0|            0|  0.00%|        align_corners (bool, optional): Geometrically, we consider the pixels of the
  3782|         0|            0|            0|  0.00%|            input and output as squares rather than points.
  3783|         0|            0|            0|  0.00%|            If set to ``True``, the input and output tensors are aligned by the
  3784|         0|            0|            0|  0.00%|            center points of their corner pixels, preserving the values at the corner pixels.
  3785|         0|            0|            0|  0.00%|            If set to ``False``, the input and output tensors are aligned by the corner
  3786|         0|            0|            0|  0.00%|            points of their corner pixels, and the interpolation uses edge value padding
  3787|         0|            0|            0|  0.00%|            for out-of-boundary values, making this operation *independent* of input size
  3788|         0|            0|            0|  0.00%|            when :attr:`scale_factor` is kept the same. This only has an effect when :attr:`mode`
  3789|         0|            0|            0|  0.00%|            is ``'linear'``, ``'bilinear'``, ``'bicubic'`` or ``'trilinear'``.
  3790|         0|            0|            0|  0.00%|            Default: ``False``
  3791|         0|            0|            0|  0.00%|        recompute_scale_factor (bool, optional): recompute the scale_factor for use in the
  3792|         0|            0|            0|  0.00%|            interpolation calculation. If `recompute_scale_factor` is ``True``, then
  3793|         0|            0|            0|  0.00%|            `scale_factor` must be passed in and `scale_factor` is used to compute the
  3794|         0|            0|            0|  0.00%|            output `size`. The computed output `size` will be used to infer new scales for
  3795|         0|            0|            0|  0.00%|            the interpolation. Note that when `scale_factor` is floating-point, it may differ
  3796|         0|            0|            0|  0.00%|            from the recomputed `scale_factor` due to rounding and precision issues.
  3797|         0|            0|            0|  0.00%|            If `recompute_scale_factor` is ``False``, then `size` or `scale_factor` will
  3798|         0|            0|            0|  0.00%|            be used directly for interpolation. Default: ``None``.
  3799|         0|            0|            0|  0.00%|        antialias (bool, optional): flag to apply anti-aliasing. Default: ``False``. Using anti-alias
  3800|         0|            0|            0|  0.00%|            option together with ``align_corners=False``, interpolation result would match Pillow
  3801|         0|            0|            0|  0.00%|            result for downsampling operation. Supported modes: ``'bilinear'``, ``'bicubic'``.
  3802|         0|            0|            0|  0.00%|
  3803|         0|            0|            0|  0.00%|    .. note::
  3804|         0|            0|            0|  0.00%|        With ``mode='bicubic'``, it's possible to cause overshoot, in other words it can produce
  3805|         0|            0|            0|  0.00%|        negative values or values greater than 255 for images.
  3806|         0|            0|            0|  0.00%|        Explicitly call ``result.clamp(min=0, max=255)`` if you want to reduce the overshoot
  3807|         0|            0|            0|  0.00%|        when displaying the image.
  3808|         0|            0|            0|  0.00%|
  3809|         0|            0|            0|  0.00%|    .. note::
  3810|         0|            0|            0|  0.00%|        Mode ``mode='nearest-exact'`` matches Scikit-Image and PIL nearest neighbours interpolation
  3811|         0|            0|            0|  0.00%|        algorithms and fixes known issues with ``mode='nearest'``. This mode is introduced to keep
  3812|         0|            0|            0|  0.00%|        backward compatibility.
  3813|         0|            0|            0|  0.00%|        Mode ``mode='nearest'`` matches buggy OpenCV's ``INTER_NEAREST`` interpolation algorithm.
  3814|         0|            0|            0|  0.00%|
  3815|         0|            0|            0|  0.00%|    Note:
  3816|         0|            0|            0|  0.00%|        {backward_reproducibility_note}
  3817|         0|            0|            0|  0.00%|    """
  3818|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  3819|         0|            0|            0|  0.00%|        return handle_torch_function(
  3820|         0|            0|            0|  0.00%|            interpolate,
  3821|         0|            0|            0|  0.00%|            (input,),
  3822|         0|            0|            0|  0.00%|            input,
  3823|         0|            0|            0|  0.00%|            size=size,
  3824|         0|            0|            0|  0.00%|            scale_factor=scale_factor,
  3825|         0|            0|            0|  0.00%|            mode=mode,
  3826|         0|            0|            0|  0.00%|            align_corners=align_corners,
  3827|         0|            0|            0|  0.00%|            recompute_scale_factor=recompute_scale_factor,
  3828|         0|            0|            0|  0.00%|            antialias=antialias
  3829|         0|            0|            0|  0.00%|        )
  3830|         0|            0|            0|  0.00%|
  3831|         0|            0|            0|  0.00%|    if mode in ("nearest", "area", "nearest-exact"):
  3832|         0|            0|            0|  0.00%|        if align_corners is not None:
  3833|         0|            0|            0|  0.00%|            raise ValueError(
  3834|         0|            0|            0|  0.00%|                "align_corners option can only be set with the "
  3835|         0|            0|            0|  0.00%|                "interpolating modes: linear | bilinear | bicubic | trilinear"
  3836|         0|            0|            0|  0.00%|            )
  3837|         0|            0|            0|  0.00%|    else:
  3838|         0|            0|            0|  0.00%|        if align_corners is None:
  3839|         0|            0|            0|  0.00%|            align_corners = False
  3840|         0|            0|            0|  0.00%|
  3841|         0|            0|            0|  0.00%|    dim = input.dim() - 2  # Number of spatial dimensions.
  3842|         0|            0|            0|  0.00%|
  3843|         0|            0|            0|  0.00%|    # Process size and scale_factor.  Validate that exactly one is set.
  3844|         0|            0|            0|  0.00%|    # Validate its length if it is a list, or expand it if it is a scalar.
  3845|         0|            0|            0|  0.00%|    # After this block, exactly one of output_size and scale_factors will
  3846|         0|            0|            0|  0.00%|    # be non-None, and it will be a list (or tuple).
  3847|         0|            0|            0|  0.00%|    if size is not None and scale_factor is not None:
  3848|         0|            0|            0|  0.00%|        raise ValueError("only one of size or scale_factor should be defined")
  3849|         0|            0|            0|  0.00%|    elif size is not None:
  3850|         0|            0|            0|  0.00%|        assert scale_factor is None
  3851|         0|            0|            0|  0.00%|        scale_factors = None
  3852|         0|            0|            0|  0.00%|        if isinstance(size, (list, tuple)):
  3853|         0|            0|            0|  0.00%|            if len(size) != dim:
  3854|         0|            0|            0|  0.00%|                raise ValueError(
  3855|         0|            0|            0|  0.00%|                    "Input and output must have the same number of spatial dimensions, but got "
  3856|         0|            0|            0|  0.00%|                    f"input with with spatial dimensions of {list(input.shape[2:])} and output size of {size}. "
  3857|         0|            0|            0|  0.00%|                    "Please provide input tensor in (N, C, d1, d2, ...,dK) format and "
  3858|         0|            0|            0|  0.00%|                    "output size in (o1, o2, ...,oK) format."
  3859|         0|            0|            0|  0.00%|
  3860|         0|            0|            0|  0.00%|                )
  3861|         0|            0|            0|  0.00%|            output_size = size
  3862|         0|            0|            0|  0.00%|        else:
  3863|         0|            0|            0|  0.00%|            output_size = [size for _ in range(dim)]
  3864|         0|            0|            0|  0.00%|    elif scale_factor is not None:
  3865|         0|            0|            0|  0.00%|        assert size is None
  3866|         0|            0|            0|  0.00%|        output_size = None
  3867|         0|            0|            0|  0.00%|        if isinstance(scale_factor, (list, tuple)):
  3868|         0|            0|            0|  0.00%|            if len(scale_factor) != dim:
  3869|         0|            0|            0|  0.00%|                raise ValueError(
  3870|         0|            0|            0|  0.00%|                    "Input and scale_factor must have the same number of spatial dimensions, but "
  3871|         0|            0|            0|  0.00%|                    f"got input with spatial dimensions of {list(input.shape[2:])} and "
  3872|         0|            0|            0|  0.00%|                    f"scale_factor of shape {scale_factor}. "
  3873|         0|            0|            0|  0.00%|                    "Please provide input tensor in (N, C, d1, d2, ...,dK) format and "
  3874|         0|            0|            0|  0.00%|                    "scale_factor in (s1, s2, ...,sK) format."
  3875|         0|            0|            0|  0.00%|                )
  3876|         0|            0|            0|  0.00%|            scale_factors = scale_factor
  3877|         0|            0|            0|  0.00%|        else:
  3878|         0|            0|            0|  0.00%|            scale_factors = [scale_factor for _ in range(dim)]
  3879|         0|            0|            0|  0.00%|    else:
  3880|         0|            0|            0|  0.00%|        raise ValueError("either size or scale_factor should be defined")
  3881|         0|            0|            0|  0.00%|
  3882|         0|            0|            0|  0.00%|    if recompute_scale_factor is not None and recompute_scale_factor and size is not None:
  3883|         0|            0|            0|  0.00%|        raise ValueError("recompute_scale_factor is not meaningful with an explicit size.")
  3884|         0|            0|            0|  0.00%|
  3885|         0|            0|            0|  0.00%|    # "area" mode always requires an explicit size rather than scale factor.
  3886|         0|            0|            0|  0.00%|    # Re-use the recompute_scale_factor code path.
  3887|         0|            0|            0|  0.00%|    if mode == "area" and output_size is None:
  3888|         0|            0|            0|  0.00%|        recompute_scale_factor = True
  3889|         0|            0|            0|  0.00%|
  3890|         0|            0|            0|  0.00%|    if recompute_scale_factor is not None and recompute_scale_factor:
  3891|         0|            0|            0|  0.00%|        # We compute output_size here, then un-set scale_factors.
  3892|         0|            0|            0|  0.00%|        # The C++ code will recompute it based on the (integer) output size.
  3893|         0|            0|            0|  0.00%|        if not torch.jit.is_scripting() and torch._C._get_tracing_state():
  3894|         0|            0|            0|  0.00%|            # make scale_factor a tensor in tracing so constant doesn't get baked in
  3895|         0|            0|            0|  0.00%|            output_size = [
  3896|         0|            0|            0|  0.00%|                (torch.floor((input.size(i + 2).float() * torch.tensor(scale_factors[i], dtype=torch.float32)).float()))
  3897|         0|            0|            0|  0.00%|                for i in range(dim)
  3898|         0|            0|            0|  0.00%|            ]
  3899|         0|            0|            0|  0.00%|        else:
  3900|         0|            0|            0|  0.00%|            assert scale_factors is not None
  3901|         0|            0|            0|  0.00%|            output_size = [int(math.floor(float(input.size(i + 2)) * scale_factors[i])) for i in range(dim)]
  3902|         0|            0|            0|  0.00%|        scale_factors = None
  3903|         0|            0|            0|  0.00%|
  3904|         0|            0|            0|  0.00%|    if antialias and not (mode in ("bilinear", "bicubic") and input.ndim == 4):
  3905|         0|            0|            0|  0.00%|        raise ValueError("Anti-alias option is only supported for bilinear and bicubic modes")
  3906|         0|            0|            0|  0.00%|
  3907|         0|            0|            0|  0.00%|    if input.dim() == 3 and mode == "nearest":
  3908|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_nearest1d(input, output_size, scale_factors)
  3909|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == "nearest":
  3910|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_nearest2d(input, output_size, scale_factors)
  3911|         0|            0|            0|  0.00%|    if input.dim() == 5 and mode == "nearest":
  3912|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_nearest3d(input, output_size, scale_factors)
  3913|         0|            0|            0|  0.00%|
  3914|         0|            0|            0|  0.00%|    if input.dim() == 3 and mode == "nearest-exact":
  3915|         0|            0|            0|  0.00%|        return torch._C._nn._upsample_nearest_exact1d(input, output_size, scale_factors)
  3916|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == "nearest-exact":
  3917|         0|            0|            0|  0.00%|        return torch._C._nn._upsample_nearest_exact2d(input, output_size, scale_factors)
  3918|         0|            0|            0|  0.00%|    if input.dim() == 5 and mode == "nearest-exact":
  3919|         0|            0|            0|  0.00%|        return torch._C._nn._upsample_nearest_exact3d(input, output_size, scale_factors)
  3920|         0|            0|            0|  0.00%|
  3921|         0|            0|            0|  0.00%|    if input.dim() == 3 and mode == "area":
  3922|         0|            0|            0|  0.00%|        assert output_size is not None
  3923|         0|            0|            0|  0.00%|        return adaptive_avg_pool1d(input, output_size)
  3924|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == "area":
  3925|         0|            0|            0|  0.00%|        assert output_size is not None
  3926|         0|            0|            0|  0.00%|        return adaptive_avg_pool2d(input, output_size)
  3927|         0|            0|            0|  0.00%|    if input.dim() == 5 and mode == "area":
  3928|         0|            0|            0|  0.00%|        assert output_size is not None
  3929|         0|            0|            0|  0.00%|        return adaptive_avg_pool3d(input, output_size)
  3930|         0|            0|            0|  0.00%|
  3931|         0|            0|            0|  0.00%|    if input.dim() == 3 and mode == "linear":
  3932|         0|            0|            0|  0.00%|        assert align_corners is not None
  3933|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_linear1d(input, output_size, align_corners, scale_factors)
  3934|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == "bilinear":
  3935|         0|            0|            0|  0.00%|        assert align_corners is not None
  3936|         0|            0|            0|  0.00%|        if antialias:
  3937|         0|            0|            0|  0.00%|            return torch._C._nn._upsample_bilinear2d_aa(input, output_size, align_corners, scale_factors)
  3938|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
  3939|         0|            0|            0|  0.00%|    if input.dim() == 5 and mode == "trilinear":
  3940|         0|            0|            0|  0.00%|        assert align_corners is not None
  3941|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_trilinear3d(input, output_size, align_corners, scale_factors)
  3942|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == "bicubic":
  3943|         0|            0|            0|  0.00%|        assert align_corners is not None
  3944|         0|            0|            0|  0.00%|        if antialias:
  3945|         0|            0|            0|  0.00%|            return torch._C._nn._upsample_bicubic2d_aa(input, output_size, align_corners, scale_factors)
  3946|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
  3947|         0|            0|            0|  0.00%|
  3948|         0|            0|            0|  0.00%|    if input.dim() == 3 and mode == "bilinear":
  3949|         0|            0|            0|  0.00%|        raise NotImplementedError("Got 3D input, but bilinear mode needs 4D input")
  3950|         0|            0|            0|  0.00%|    if input.dim() == 3 and mode == "trilinear":
  3951|         0|            0|            0|  0.00%|        raise NotImplementedError("Got 3D input, but trilinear mode needs 5D input")
  3952|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == "linear":
  3953|         0|            0|            0|  0.00%|        raise NotImplementedError("Got 4D input, but linear mode needs 3D input")
  3954|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == "trilinear":
  3955|         0|            0|            0|  0.00%|        raise NotImplementedError("Got 4D input, but trilinear mode needs 5D input")
  3956|         0|            0|            0|  0.00%|    if input.dim() == 5 and mode == "linear":
  3957|         0|            0|            0|  0.00%|        raise NotImplementedError("Got 5D input, but linear mode needs 3D input")
  3958|         0|            0|            0|  0.00%|    if input.dim() == 5 and mode == "bilinear":
  3959|         0|            0|            0|  0.00%|        raise NotImplementedError("Got 5D input, but bilinear mode needs 4D input")
  3960|         0|            0|            0|  0.00%|
  3961|         0|            0|            0|  0.00%|    raise NotImplementedError(
  3962|         0|            0|            0|  0.00%|        "Input Error: Only 3D, 4D and 5D input Tensors supported"
  3963|         0|            0|            0|  0.00%|        " (got {}D) for the modes: nearest | linear | bilinear | bicubic | trilinear | area | nearest-exact"
  3964|         0|            0|            0|  0.00%|        " (got {})".format(input.dim(), mode)
  3965|         0|            0|            0|  0.00%|    )
  3966|         0|            0|            0|  0.00%|
  3967|         0|            0|            0|  0.00%|
  3968|         0|            0|            0|  0.00%|if interpolate.__doc__:
  3969|         0|            0|            0|  0.00%|    interpolate.__doc__ = interpolate.__doc__.format(**reproducibility_notes)
  3970|         0|            0|            0|  0.00%|
  3971|         0|            0|            0|  0.00%|
  3972|         0|            0|            0|  0.00%|@_overload  # noqa: F811
  3973|         0|            0|            0|  0.00%|def upsample_nearest(input: Tensor, size: Optional[int] = None, scale_factor: Optional[float] = None) -> Tensor:  # noqa: F811
  3974|         0|            0|            0|  0.00%|    pass
  3975|         0|            0|            0|  0.00%|
  3976|         0|            0|            0|  0.00%|
  3977|         0|            0|            0|  0.00%|@_overload  # noqa: F811
  3978|         0|            0|            0|  0.00%|def upsample_nearest(input: Tensor, size: Optional[List[int]] = None, scale_factor: Optional[float] = None) -> Tensor:  # noqa: F811
  3979|         0|            0|            0|  0.00%|    pass
  3980|         0|            0|            0|  0.00%|
  3981|         0|            0|            0|  0.00%|
  3982|         0|            0|            0|  0.00%|def upsample_nearest(input, size=None, scale_factor=None):  # noqa: F811
  3983|         0|            0|            0|  0.00%|    r"""Upsamples the input, using nearest neighbours' pixel values.
  3984|         0|            0|            0|  0.00%|
  3985|         0|            0|            0|  0.00%|    .. warning::
  3986|         0|            0|            0|  0.00%|        This function is deprecated in favor of :func:`torch.nn.functional.interpolate`.
  3987|         0|            0|            0|  0.00%|        This is equivalent with ``nn.functional.interpolate(..., mode='nearest')``.
  3988|         0|            0|            0|  0.00%|
  3989|         0|            0|            0|  0.00%|    Currently spatial and volumetric upsampling are supported (i.e. expected
  3990|         0|            0|            0|  0.00%|    inputs are 4 or 5 dimensional).
  3991|         0|            0|            0|  0.00%|
  3992|         0|            0|            0|  0.00%|    Args:
  3993|         0|            0|            0|  0.00%|        input (Tensor): input
  3994|         0|            0|            0|  0.00%|        size (int or Tuple[int, int] or Tuple[int, int, int]): output spatia
  3995|         0|            0|            0|  0.00%|            size.
  3996|         0|            0|            0|  0.00%|        scale_factor (int): multiplier for spatial size. Has to be an integer.
  3997|         0|            0|            0|  0.00%|
  3998|         0|            0|            0|  0.00%|    Note:
  3999|         0|            0|            0|  0.00%|        {backward_reproducibility_note}
  4000|         0|            0|            0|  0.00%|    """
  4001|         0|            0|            0|  0.00%|    # DeprecationWarning is ignored by default
  4002|         0|            0|            0|  0.00%|    warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
  4003|         0|            0|            0|  0.00%|    return interpolate(input, size, scale_factor, mode="nearest")
  4004|         0|            0|            0|  0.00%|
  4005|         0|            0|            0|  0.00%|
  4006|         0|            0|            0|  0.00%|if upsample_nearest.__doc__:
  4007|         0|            0|            0|  0.00%|    upsample_nearest.__doc__ = upsample_nearest.__doc__.format(**reproducibility_notes)
  4008|         0|            0|            0|  0.00%|
  4009|         0|            0|            0|  0.00%|
  4010|         0|            0|            0|  0.00%|@_overload  # noqa: F811
  4011|         0|            0|            0|  0.00%|def upsample_bilinear(
  4012|         0|            0|            0|  0.00%|    input: Tensor, size: Optional[int] = None, scale_factor: Optional[float] = None
  4013|         0|            0|            0|  0.00%|) -> Tensor:  # noqa: F811
  4014|         0|            0|            0|  0.00%|    pass
  4015|         0|            0|            0|  0.00%|
  4016|         0|            0|            0|  0.00%|
  4017|         0|            0|            0|  0.00%|@_overload  # noqa: F811
  4018|         0|            0|            0|  0.00%|def upsample_bilinear(  # noqa: F811
  4019|         0|            0|            0|  0.00%|    input: Tensor, size: Optional[List[int]] = None, scale_factor: Optional[float] = None
  4020|         0|            0|            0|  0.00%|) -> Tensor:  # noqa: F811
  4021|         0|            0|            0|  0.00%|    pass
  4022|         0|            0|            0|  0.00%|
  4023|         0|            0|            0|  0.00%|
  4024|         0|            0|            0|  0.00%|@_overload  # noqa: F811
  4025|         0|            0|            0|  0.00%|def upsample_bilinear(  # noqa: F811
  4026|         0|            0|            0|  0.00%|    input: Tensor, size: Optional[int] = None, scale_factor: Optional[List[float]] = None
  4027|         0|            0|            0|  0.00%|) -> Tensor:  # noqa: F811
  4028|         0|            0|            0|  0.00%|    pass
  4029|         0|            0|            0|  0.00%|
  4030|         0|            0|            0|  0.00%|
  4031|         0|            0|            0|  0.00%|@_overload  # noqa: F811
  4032|         0|            0|            0|  0.00%|def upsample_bilinear(  # noqa: F811
  4033|         0|            0|            0|  0.00%|    input: Tensor, size: Optional[List[int]] = None, scale_factor: Optional[List[float]] = None
  4034|         0|            0|            0|  0.00%|) -> Tensor:  # noqa: F811
  4035|         0|            0|            0|  0.00%|    pass
  4036|         0|            0|            0|  0.00%|
  4037|         0|            0|            0|  0.00%|
  4038|         0|            0|            0|  0.00%|def upsample_bilinear(input, size=None, scale_factor=None):  # noqa: F811
  4039|         0|            0|            0|  0.00%|    r"""Upsamples the input, using bilinear upsampling.
  4040|         0|            0|            0|  0.00%|
  4041|         0|            0|            0|  0.00%|    .. warning::
  4042|         0|            0|            0|  0.00%|        This function is deprecated in favor of :func:`torch.nn.functional.interpolate`.
  4043|         0|            0|            0|  0.00%|        This is equivalent with
  4044|         0|            0|            0|  0.00%|        ``nn.functional.interpolate(..., mode='bilinear', align_corners=True)``.
  4045|         0|            0|            0|  0.00%|
  4046|         0|            0|            0|  0.00%|    Expected inputs are spatial (4 dimensional). Use `upsample_trilinear` fo
  4047|         0|            0|            0|  0.00%|    volumetric (5 dimensional) inputs.
  4048|         0|            0|            0|  0.00%|
  4049|         0|            0|            0|  0.00%|    Args:
  4050|         0|            0|            0|  0.00%|        input (Tensor): input
  4051|         0|            0|            0|  0.00%|        size (int or Tuple[int, int]): output spatial size.
  4052|         0|            0|            0|  0.00%|        scale_factor (int or Tuple[int, int]): multiplier for spatial size
  4053|         0|            0|            0|  0.00%|
  4054|         0|            0|            0|  0.00%|    Note:
  4055|         0|            0|            0|  0.00%|        {backward_reproducibility_note}
  4056|         0|            0|            0|  0.00%|    """
  4057|         0|            0|            0|  0.00%|    # DeprecationWarning is ignored by default
  4058|         0|            0|            0|  0.00%|    warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
  4059|         0|            0|            0|  0.00%|    return interpolate(input, size, scale_factor, mode="bilinear", align_corners=True)
  4060|         0|            0|            0|  0.00%|
  4061|         0|            0|            0|  0.00%|
  4062|         0|            0|            0|  0.00%|if upsample_bilinear.__doc__:
  4063|         0|            0|            0|  0.00%|    upsample_bilinear.__doc__ = upsample_bilinear.__doc__.format(**reproducibility_notes)
  4064|         0|            0|            0|  0.00%|
  4065|         0|            0|            0|  0.00%|GRID_SAMPLE_INTERPOLATION_MODES = {
  4066|         0|            0|            0|  0.00%|    "bilinear": 0,
  4067|         0|            0|            0|  0.00%|    "nearest": 1,
  4068|         0|            0|            0|  0.00%|    "bicubic": 2,
  4069|         0|            0|            0|  0.00%|}
  4070|         0|            0|            0|  0.00%|
  4071|         0|            0|            0|  0.00%|GRID_SAMPLE_PADDING_MODES = {
  4072|         0|            0|            0|  0.00%|    "zeros": 0,
  4073|         0|            0|            0|  0.00%|    "border": 1,
  4074|         0|            0|            0|  0.00%|    "reflection": 2,
  4075|         0|            0|            0|  0.00%|}
  4076|         0|            0|            0|  0.00%|
  4077|         0|            0|            0|  0.00%|
  4078|         0|            0|            0|  0.00%|def grid_sample(
  4079|         0|            0|            0|  0.00%|    input: Tensor,
  4080|         0|            0|            0|  0.00%|    grid: Tensor,
  4081|         0|            0|            0|  0.00%|    mode: str = "bilinear",
  4082|         0|            0|            0|  0.00%|    padding_mode: str = "zeros",
  4083|         0|            0|            0|  0.00%|    align_corners: Optional[bool] = None,
  4084|         0|            0|            0|  0.00%|) -> Tensor:
  4085|         0|            0|            0|  0.00%|    r"""Given an :attr:`input` and a flow-field :attr:`grid`, computes the
  4086|         0|            0|            0|  0.00%|    ``output`` using :attr:`input` values and pixel locations from :attr:`grid`.
  4087|         0|            0|            0|  0.00%|
  4088|         0|            0|            0|  0.00%|    Currently, only spatial (4-D) and volumetric (5-D) :attr:`input` are
  4089|         0|            0|            0|  0.00%|    supported.
  4090|         0|            0|            0|  0.00%|
  4091|         0|            0|            0|  0.00%|    In the spatial (4-D) case, for :attr:`input` with shape
  4092|         0|            0|            0|  0.00%|    :math:`(N, C, H_\text{in}, W_\text{in})` and :attr:`grid` with shape
  4093|         0|            0|            0|  0.00%|    :math:`(N, H_\text{out}, W_\text{out}, 2)`, the output will have shape
  4094|         0|            0|            0|  0.00%|    :math:`(N, C, H_\text{out}, W_\text{out})`.
  4095|         0|            0|            0|  0.00%|
  4096|         0|            0|            0|  0.00%|    For each output location ``output[n, :, h, w]``, the size-2 vector
  4097|         0|            0|            0|  0.00%|    ``grid[n, h, w]`` specifies :attr:`input` pixel locations ``x`` and ``y``,
  4098|         0|            0|            0|  0.00%|    which are used to interpolate the output value ``output[n, :, h, w]``.
  4099|         0|            0|            0|  0.00%|    In the case of 5D inputs, ``grid[n, d, h, w]`` specifies the
  4100|         0|            0|            0|  0.00%|    ``x``, ``y``, ``z`` pixel locations for interpolating
  4101|         0|            0|            0|  0.00%|    ``output[n, :, d, h, w]``. :attr:`mode` argument specifies ``nearest`` or
  4102|         0|            0|            0|  0.00%|    ``bilinear`` interpolation method to sample the input pixels.
  4103|         0|            0|            0|  0.00%|
  4104|         0|            0|            0|  0.00%|    :attr:`grid` specifies the sampling pixel locations normalized by the
  4105|         0|            0|            0|  0.00%|    :attr:`input` spatial dimensions. Therefore, it should have most values in
  4106|         0|            0|            0|  0.00%|    the range of ``[-1, 1]``. For example, values ``x = -1, y = -1`` is the
  4107|         0|            0|            0|  0.00%|    left-top pixel of :attr:`input`, and values  ``x = 1, y = 1`` is the
  4108|         0|            0|            0|  0.00%|    right-bottom pixel of :attr:`input`.
  4109|         0|            0|            0|  0.00%|
  4110|         0|            0|            0|  0.00%|    If :attr:`grid` has values outside the range of ``[-1, 1]``, the corresponding
  4111|         0|            0|            0|  0.00%|    outputs are handled as defined by :attr:`padding_mode`. Options are
  4112|         0|            0|            0|  0.00%|
  4113|         0|            0|            0|  0.00%|        * ``padding_mode="zeros"``: use ``0`` for out-of-bound grid locations,
  4114|         0|            0|            0|  0.00%|        * ``padding_mode="border"``: use border values for out-of-bound grid locations,
  4115|         0|            0|            0|  0.00%|        * ``padding_mode="reflection"``: use values at locations reflected by
  4116|         0|            0|            0|  0.00%|          the border for out-of-bound grid locations. For location far away
  4117|         0|            0|            0|  0.00%|          from the border, it will keep being reflected until becoming in bound,
  4118|         0|            0|            0|  0.00%|          e.g., (normalized) pixel location ``x = -3.5`` reflects by border ``-1``
  4119|         0|            0|            0|  0.00%|          and becomes ``x' = 1.5``, then reflects by border ``1`` and becomes
  4120|         0|            0|            0|  0.00%|          ``x'' = -0.5``.
  4121|         0|            0|            0|  0.00%|
  4122|         0|            0|            0|  0.00%|    Note:
  4123|         0|            0|            0|  0.00%|        This function is often used in conjunction with :func:`affine_grid`
  4124|         0|            0|            0|  0.00%|        to build `Spatial Transformer Networks`_ .
  4125|         0|            0|            0|  0.00%|
  4126|         0|            0|            0|  0.00%|    Note:
  4127|         0|            0|            0|  0.00%|        When using the CUDA backend, this operation may induce nondeterministic
  4128|         0|            0|            0|  0.00%|        behaviour in its backward pass that is not easily switched off.
  4129|         0|            0|            0|  0.00%|        Please see the notes on :doc:`/notes/randomness` for background.
  4130|         0|            0|            0|  0.00%|
  4131|         0|            0|            0|  0.00%|    Note:
  4132|         0|            0|            0|  0.00%|        NaN values in :attr:`grid` would be interpreted as ``-1``.
  4133|         0|            0|            0|  0.00%|
  4134|         0|            0|            0|  0.00%|    Args:
  4135|         0|            0|            0|  0.00%|        input (Tensor): input of shape :math:`(N, C, H_\text{in}, W_\text{in})` (4-D case)
  4136|         0|            0|            0|  0.00%|                        or :math:`(N, C, D_\text{in}, H_\text{in}, W_\text{in})` (5-D case)
  4137|         0|            0|            0|  0.00%|        grid (Tensor): flow-field of shape :math:`(N, H_\text{out}, W_\text{out}, 2)` (4-D case)
  4138|         0|            0|            0|  0.00%|                       or :math:`(N, D_\text{out}, H_\text{out}, W_\text{out}, 3)` (5-D case)
  4139|         0|            0|            0|  0.00%|        mode (str): interpolation mode to calculate output values
  4140|         0|            0|            0|  0.00%|            ``'bilinear'`` | ``'nearest'`` | ``'bicubic'``. Default: ``'bilinear'``
  4141|         0|            0|            0|  0.00%|            Note: ``mode='bicubic'`` supports only 4-D input.
  4142|         0|            0|            0|  0.00%|            When ``mode='bilinear'`` and the input is 5-D, the interpolation mode
  4143|         0|            0|            0|  0.00%|            used internally will actually be trilinear. However, when the input is 4-D,
  4144|         0|            0|            0|  0.00%|            the interpolation mode will legitimately be bilinear.
  4145|         0|            0|            0|  0.00%|        padding_mode (str): padding mode for outside grid values
  4146|         0|            0|            0|  0.00%|            ``'zeros'`` | ``'border'`` | ``'reflection'``. Default: ``'zeros'``
  4147|         0|            0|            0|  0.00%|        align_corners (bool, optional): Geometrically, we consider the pixels of the
  4148|         0|            0|            0|  0.00%|            input  as squares rather than points.
  4149|         0|            0|            0|  0.00%|            If set to ``True``, the extrema (``-1`` and ``1``) are considered as referring
  4150|         0|            0|            0|  0.00%|            to the center points of the input's corner pixels. If set to ``False``, they
  4151|         0|            0|            0|  0.00%|            are instead considered as referring to the corner points of the input's corner
  4152|         0|            0|            0|  0.00%|            pixels, making the sampling more resolution agnostic.
  4153|         0|            0|            0|  0.00%|            This option parallels the ``align_corners`` option in
  4154|         0|            0|            0|  0.00%|            :func:`interpolate`, and so whichever option is used here
  4155|         0|            0|            0|  0.00%|            should also be used there to resize the input image before grid sampling.
  4156|         0|            0|            0|  0.00%|            Default: ``False``
  4157|         0|            0|            0|  0.00%|
  4158|         0|            0|            0|  0.00%|    Returns:
  4159|         0|            0|            0|  0.00%|        output (Tensor): output Tensor
  4160|         0|            0|            0|  0.00%|
  4161|         0|            0|            0|  0.00%|    .. _`Spatial Transformer Networks`:
  4162|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1506.02025
  4163|         0|            0|            0|  0.00%|
  4164|         0|            0|            0|  0.00%|    .. warning::
  4165|         0|            0|            0|  0.00%|        When ``align_corners = True``, the grid positions depend on the pixel
  4166|         0|            0|            0|  0.00%|        size relative to the input image size, and so the locations sampled by
  4167|         0|            0|            0|  0.00%|        :func:`grid_sample` will differ for the same input given at different
  4168|         0|            0|            0|  0.00%|        resolutions (that is, after being upsampled or downsampled).
  4169|         0|            0|            0|  0.00%|        The default behavior up to version 1.2.0 was ``align_corners = True``.
  4170|         0|            0|            0|  0.00%|        Since then, the default behavior has been changed to ``align_corners = False``,
  4171|         0|            0|            0|  0.00%|        in order to bring it in line with the default for :func:`interpolate`.
  4172|         0|            0|            0|  0.00%|
  4173|         0|            0|            0|  0.00%|    .. note::
  4174|         0|            0|            0|  0.00%|        ``mode='bicubic'`` is implemented using the `cubic convolution algorithm`_ with :math:`\alpha=-0.75`.
  4175|         0|            0|            0|  0.00%|        The constant :math:`\alpha` might be different from packages to packages.
  4176|         0|            0|            0|  0.00%|        For example, `PIL`_ and `OpenCV`_ use -0.5 and -0.75 respectively.
  4177|         0|            0|            0|  0.00%|        This algorithm may "overshoot" the range of values it's interpolating.
  4178|         0|            0|            0|  0.00%|        For example, it may produce negative values or values greater than 255 when interpolating input in [0, 255].
  4179|         0|            0|            0|  0.00%|        Clamp the results with :func: `torch.clamp` to ensure they are within the valid range.
  4180|         0|            0|            0|  0.00%|    .. _`cubic convolution algorithm`: https://en.wikipedia.org/wiki/Bicubic_interpolation
  4181|         0|            0|            0|  0.00%|    .. _`PIL`: https://github.com/python-pillow/Pillow/blob/4634eafe3c695a014267eefdce830b4a825beed7/src/libImaging/Resample.c#L51
  4182|         0|            0|            0|  0.00%|    .. _`OpenCV`: https://github.com/opencv/opencv/blob/f345ed564a06178670750bad59526cfa4033be55/modules/imgproc/src/resize.cpp#L908
  4183|         0|            0|            0|  0.00%|    """
  4184|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, grid):
  4185|         0|            0|            0|  0.00%|        return handle_torch_function(
  4186|         0|            0|            0|  0.00%|            grid_sample, (input, grid), input, grid, mode=mode, padding_mode=padding_mode, align_corners=align_corners
  4187|         0|            0|            0|  0.00%|        )
  4188|         0|            0|            0|  0.00%|    if mode != "bilinear" and mode != "nearest" and mode != "bicubic":
  4189|         0|            0|            0|  0.00%|        raise ValueError(
  4190|         0|            0|            0|  0.00%|            "nn.functional.grid_sample(): expected mode to be "
  4191|         0|            0|            0|  0.00%|            "'bilinear', 'nearest' or 'bicubic', but got: '{}'".format(mode)
  4192|         0|            0|            0|  0.00%|        )
  4193|         0|            0|            0|  0.00%|    if padding_mode != "zeros" and padding_mode != "border" and padding_mode != "reflection":
  4194|         0|            0|            0|  0.00%|        raise ValueError(
  4195|         0|            0|            0|  0.00%|            "nn.functional.grid_sample(): expected padding_mode "
  4196|         0|            0|            0|  0.00%|            "to be 'zeros', 'border', or 'reflection', "
  4197|         0|            0|            0|  0.00%|            "but got: '{}'".format(padding_mode)
  4198|         0|            0|            0|  0.00%|        )
  4199|         0|            0|            0|  0.00%|
  4200|         0|            0|            0|  0.00%|    if mode == "bilinear":
  4201|         0|            0|            0|  0.00%|        mode_enum = 0
  4202|         0|            0|            0|  0.00%|    elif mode == "nearest":
  4203|         0|            0|            0|  0.00%|        mode_enum = 1
  4204|         0|            0|            0|  0.00%|    else:  # mode == 'bicubic'
  4205|         0|            0|            0|  0.00%|        mode_enum = 2
  4206|         0|            0|            0|  0.00%|
  4207|         0|            0|            0|  0.00%|    if padding_mode == "zeros":
  4208|         0|            0|            0|  0.00%|        padding_mode_enum = 0
  4209|         0|            0|            0|  0.00%|    elif padding_mode == "border":
  4210|         0|            0|            0|  0.00%|        padding_mode_enum = 1
  4211|         0|            0|            0|  0.00%|    else:  # padding_mode == 'reflection'
  4212|         0|            0|            0|  0.00%|        padding_mode_enum = 2
  4213|         0|            0|            0|  0.00%|
  4214|         0|            0|            0|  0.00%|    if align_corners is None:
  4215|         0|            0|            0|  0.00%|        warnings.warn(
  4216|         0|            0|            0|  0.00%|            "Default grid_sample and affine_grid behavior has changed "
  4217|         0|            0|            0|  0.00%|            "to align_corners=False since 1.3.0. Please specify "
  4218|         0|            0|            0|  0.00%|            "align_corners=True if the old behavior is desired. "
  4219|         0|            0|            0|  0.00%|            "See the documentation of grid_sample for details."
  4220|         0|            0|            0|  0.00%|        )
  4221|         0|            0|            0|  0.00%|        align_corners = False
  4222|         0|            0|            0|  0.00%|
  4223|         0|            0|            0|  0.00%|    return torch.grid_sampler(input, grid, mode_enum, padding_mode_enum, align_corners)
  4224|         0|            0|            0|  0.00%|
  4225|         0|            0|            0|  0.00%|
  4226|         0|            0|            0|  0.00%|def affine_grid(theta: Tensor, size: List[int], align_corners: Optional[bool] = None) -> Tensor:
  4227|         0|            0|            0|  0.00%|    r"""Generates a 2D or 3D flow field (sampling grid), given a batch of
  4228|         0|            0|            0|  0.00%|    affine matrices :attr:`theta`.
  4229|         0|            0|            0|  0.00%|
  4230|         0|            0|            0|  0.00%|    .. note::
  4231|         0|            0|            0|  0.00%|        This function is often used in conjunction with :func:`grid_sample`
  4232|         0|            0|            0|  0.00%|        to build `Spatial Transformer Networks`_ .
  4233|         0|            0|            0|  0.00%|
  4234|         0|            0|            0|  0.00%|    Args:
  4235|         0|            0|            0|  0.00%|        theta (Tensor): input batch of affine matrices with shape
  4236|         0|            0|            0|  0.00%|            (:math:`N \times 2 \times 3`) for 2D or
  4237|         0|            0|            0|  0.00%|            (:math:`N \times 3 \times 4`) for 3D
  4238|         0|            0|            0|  0.00%|        size (torch.Size): the target output image size.
  4239|         0|            0|            0|  0.00%|            (:math:`N \times C \times H \times W` for 2D or
  4240|         0|            0|            0|  0.00%|            :math:`N \times C \times D \times H \times W` for 3D)
  4241|         0|            0|            0|  0.00%|            Example: torch.Size((32, 3, 24, 24))
  4242|         0|            0|            0|  0.00%|        align_corners (bool, optional): if ``True``, consider ``-1`` and ``1``
  4243|         0|            0|            0|  0.00%|            to refer to the centers of the corner pixels rather than the image corners.
  4244|         0|            0|            0|  0.00%|            Refer to :func:`grid_sample` for a more complete description.
  4245|         0|            0|            0|  0.00%|            A grid generated by :func:`affine_grid` should be passed to :func:`grid_sample`
  4246|         0|            0|            0|  0.00%|            with the same setting for this option.
  4247|         0|            0|            0|  0.00%|            Default: ``False``
  4248|         0|            0|            0|  0.00%|
  4249|         0|            0|            0|  0.00%|    Returns:
  4250|         0|            0|            0|  0.00%|        output (Tensor): output Tensor of size (:math:`N \times H \times W \times 2`)
  4251|         0|            0|            0|  0.00%|
  4252|         0|            0|            0|  0.00%|    .. _`Spatial Transformer Networks`:
  4253|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1506.02025
  4254|         0|            0|            0|  0.00%|
  4255|         0|            0|            0|  0.00%|    .. warning::
  4256|         0|            0|            0|  0.00%|        When ``align_corners = True``, the grid positions depend on the pixel
  4257|         0|            0|            0|  0.00%|        size relative to the input image size, and so the locations sampled by
  4258|         0|            0|            0|  0.00%|        :func:`grid_sample` will differ for the same input given at different
  4259|         0|            0|            0|  0.00%|        resolutions (that is, after being upsampled or downsampled).
  4260|         0|            0|            0|  0.00%|        The default behavior up to version 1.2.0 was ``align_corners = True``.
  4261|         0|            0|            0|  0.00%|        Since then, the default behavior has been changed to ``align_corners = False``,
  4262|         0|            0|            0|  0.00%|        in order to bring it in line with the default for :func:`interpolate`.
  4263|         0|            0|            0|  0.00%|    .. warning::
  4264|         0|            0|            0|  0.00%|        When ``align_corners = True``, 2D affine transforms on 1D data and
  4265|         0|            0|            0|  0.00%|        3D affine transforms on 2D data (that is, when one of the spatial
  4266|         0|            0|            0|  0.00%|        dimensions has unit size) are ill-defined, and not an intended use case.
  4267|         0|            0|            0|  0.00%|        This is not a problem when ``align_corners = False``.
  4268|         0|            0|            0|  0.00%|        Up to version 1.2.0, all grid points along a unit dimension were
  4269|         0|            0|            0|  0.00%|        considered arbitrarily to be at ``-1``.
  4270|         0|            0|            0|  0.00%|        From version 1.3.0, under ``align_corners = True`` all grid points
  4271|         0|            0|            0|  0.00%|        along a unit dimension are considered to be at ``0``
  4272|         0|            0|            0|  0.00%|        (the center of the input image).
  4273|         0|            0|            0|  0.00%|    """
  4274|         0|            0|            0|  0.00%|    if has_torch_function_unary(theta):
  4275|         0|            0|            0|  0.00%|        return handle_torch_function(affine_grid, (theta,), theta, size, align_corners=align_corners)
  4276|         0|            0|            0|  0.00%|    if align_corners is None:
  4277|         0|            0|            0|  0.00%|        warnings.warn(
  4278|         0|            0|            0|  0.00%|            "Default grid_sample and affine_grid behavior has changed "
  4279|         0|            0|            0|  0.00%|            "to align_corners=False since 1.3.0. Please specify "
  4280|         0|            0|            0|  0.00%|            "align_corners=True if the old behavior is desired. "
  4281|         0|            0|            0|  0.00%|            "See the documentation of grid_sample for details."
  4282|         0|            0|            0|  0.00%|        )
  4283|         0|            0|            0|  0.00%|        align_corners = False
  4284|         0|            0|            0|  0.00%|
  4285|         0|            0|            0|  0.00%|    # enforce floating point dtype on theta
  4286|         0|            0|            0|  0.00%|    if not theta.is_floating_point():
  4287|         0|            0|            0|  0.00%|        raise ValueError("Expected theta to have floating point type, but got {}".format(theta.dtype))
  4288|         0|            0|            0|  0.00%|    # check that shapes and sizes match
  4289|         0|            0|            0|  0.00%|    if len(size) == 4:
  4290|         0|            0|            0|  0.00%|        if theta.dim() != 3 or theta.shape[-2] != 2 or theta.shape[-1] != 3:
  4291|         0|            0|            0|  0.00%|            raise ValueError(
  4292|         0|            0|            0|  0.00%|                "Expected a batch of 2D affine matrices of shape Nx2x3 "
  4293|         0|            0|            0|  0.00%|                "for size {}. Got {}.".format(size, theta.shape)
  4294|         0|            0|            0|  0.00%|            )
  4295|         0|            0|            0|  0.00%|        spatial_size = size[-2:]  # spatial dimension sizes
  4296|         0|            0|            0|  0.00%|    elif len(size) == 5:
  4297|         0|            0|            0|  0.00%|        if theta.dim() != 3 or theta.shape[-2] != 3 or theta.shape[-1] != 4:
  4298|         0|            0|            0|  0.00%|            raise ValueError(
  4299|         0|            0|            0|  0.00%|                "Expected a batch of 3D affine matrices of shape Nx3x4 "
  4300|         0|            0|            0|  0.00%|                "for size {}. Got {}.".format(size, theta.shape)
  4301|         0|            0|            0|  0.00%|            )
  4302|         0|            0|            0|  0.00%|        spatial_size = size[-3:]  # spatial dimension sizes
  4303|         0|            0|            0|  0.00%|    else:
  4304|         0|            0|            0|  0.00%|        raise NotImplementedError(
  4305|         0|            0|            0|  0.00%|            "affine_grid only supports 4D and 5D sizes, "
  4306|         0|            0|            0|  0.00%|            "for 2D and 3D affine transforms, respectively. "
  4307|         0|            0|            0|  0.00%|            "Got size {}.".format(size)
  4308|         0|            0|            0|  0.00%|        )
  4309|         0|            0|            0|  0.00%|    # check for empty span
  4310|         0|            0|            0|  0.00%|    if align_corners and min(spatial_size) == 1:
  4311|         0|            0|            0|  0.00%|        warnings.warn(
  4312|         0|            0|            0|  0.00%|            "Since version 1.3.0, affine_grid behavior has changed "
  4313|         0|            0|            0|  0.00%|            "for unit-size grids when align_corners=True. "
  4314|         0|            0|            0|  0.00%|            "This is not an intended use case of affine_grid. "
  4315|         0|            0|            0|  0.00%|            "See the documentation of affine_grid for details."
  4316|         0|            0|            0|  0.00%|        )
  4317|         0|            0|            0|  0.00%|    elif min(size) <= 0:
  4318|         0|            0|            0|  0.00%|        raise ValueError("Expected non-zero, positive output size. Got {}".format(size))
  4319|         0|            0|            0|  0.00%|
  4320|         0|            0|            0|  0.00%|    return torch.affine_grid_generator(theta, size, align_corners)
  4321|         0|            0|            0|  0.00%|
  4322|         0|            0|            0|  0.00%|
  4323|         0|            0|            0|  0.00%|pad = _add_docstr(
  4324|         0|            0|            0|  0.00%|    torch._C._nn.pad,
  4325|         0|            0|            0|  0.00%|    r"""
  4326|         0|            0|            0|  0.00%|pad(input, pad, mode="constant", value=None) -> Tensor
  4327|         0|            0|            0|  0.00%|
  4328|         0|            0|            0|  0.00%|Pads tensor.
  4329|         0|            0|            0|  0.00%|
  4330|         0|            0|            0|  0.00%|Padding size:
  4331|         0|            0|            0|  0.00%|    The padding size by which to pad some dimensions of :attr:`input`
  4332|         0|            0|            0|  0.00%|    are described starting from the last dimension and moving forward.
  4333|         0|            0|            0|  0.00%|    :math:`\left\lfloor\frac{\text{len(pad)}}{2}\right\rfloor` dimensions
  4334|         0|            0|            0|  0.00%|    of ``input`` will be padded.
  4335|         0|            0|            0|  0.00%|    For example, to pad only the last dimension of the input tensor, then
  4336|         0|            0|            0|  0.00%|    :attr:`pad` has the form
  4337|         0|            0|            0|  0.00%|    :math:`(\text{padding\_left}, \text{padding\_right})`;
  4338|         0|            0|            0|  0.00%|    to pad the last 2 dimensions of the input tensor, then use
  4339|         0|            0|            0|  0.00%|    :math:`(\text{padding\_left}, \text{padding\_right},`
  4340|         0|            0|            0|  0.00%|    :math:`\text{padding\_top}, \text{padding\_bottom})`;
  4341|         0|            0|            0|  0.00%|    to pad the last 3 dimensions, use
  4342|         0|            0|            0|  0.00%|    :math:`(\text{padding\_left}, \text{padding\_right},`
  4343|         0|            0|            0|  0.00%|    :math:`\text{padding\_top}, \text{padding\_bottom}`
  4344|         0|            0|            0|  0.00%|    :math:`\text{padding\_front}, \text{padding\_back})`.
  4345|         0|            0|            0|  0.00%|
  4346|         0|            0|            0|  0.00%|Padding mode:
  4347|         0|            0|            0|  0.00%|    See :class:`torch.nn.ConstantPad2d`, :class:`torch.nn.ReflectionPad2d`, and
  4348|         0|            0|            0|  0.00%|    :class:`torch.nn.ReplicationPad2d` for concrete examples on how each of the
  4349|         0|            0|            0|  0.00%|    padding modes works. Constant padding is implemented for arbitrary dimensions.
  4350|         0|            0|            0|  0.00%|    Replicate and reflection padding are implemented for padding the last 3
  4351|         0|            0|            0|  0.00%|    dimensions of a 4D or 5D input tensor, the last 2 dimensions of a 3D
  4352|         0|            0|            0|  0.00%|    or 4D input tensor, or the last dimension of a 2D or 3D input tensor.
  4353|         0|            0|            0|  0.00%|
  4354|         0|            0|            0|  0.00%|Note:
  4355|         0|            0|            0|  0.00%|    When using the CUDA backend, this operation may induce nondeterministic
  4356|         0|            0|            0|  0.00%|    behaviour in its backward pass that is not easily switched off.
  4357|         0|            0|            0|  0.00%|    Please see the notes on :doc:`/notes/randomness` for background.
  4358|         0|            0|            0|  0.00%|
  4359|         0|            0|            0|  0.00%|Args:
  4360|         0|            0|            0|  0.00%|    input (Tensor): N-dimensional tensor
  4361|         0|            0|            0|  0.00%|    pad (tuple): m-elements tuple, where
  4362|         0|            0|            0|  0.00%|        :math:`\frac{m}{2} \leq` input dimensions and :math:`m` is even.
  4363|         0|            0|            0|  0.00%|    mode: ``'constant'``, ``'reflect'``, ``'replicate'`` or ``'circular'``.
  4364|         0|            0|            0|  0.00%|        Default: ``'constant'``
  4365|         0|            0|            0|  0.00%|    value: fill value for ``'constant'`` padding. Default: ``0``
  4366|         0|            0|            0|  0.00%|
  4367|         0|            0|            0|  0.00%|Examples::
  4368|         0|            0|            0|  0.00%|
  4369|         0|            0|            0|  0.00%|    >>> t4d = torch.empty(3, 3, 4, 2)
  4370|         0|            0|            0|  0.00%|    >>> p1d = (1, 1) # pad last dim by 1 on each side
  4371|         0|            0|            0|  0.00%|    >>> out = F.pad(t4d, p1d, "constant", 0)  # effectively zero padding
  4372|         0|            0|            0|  0.00%|    >>> print(out.size())
  4373|         0|            0|            0|  0.00%|    torch.Size([3, 3, 4, 4])
  4374|         0|            0|            0|  0.00%|    >>> p2d = (1, 1, 2, 2) # pad last dim by (1, 1) and 2nd to last by (2, 2)
  4375|         0|            0|            0|  0.00%|    >>> out = F.pad(t4d, p2d, "constant", 0)
  4376|         0|            0|            0|  0.00%|    >>> print(out.size())
  4377|         0|            0|            0|  0.00%|    torch.Size([3, 3, 8, 4])
  4378|         0|            0|            0|  0.00%|    >>> t4d = torch.empty(3, 3, 4, 2)
  4379|         0|            0|            0|  0.00%|    >>> p3d = (0, 1, 2, 1, 3, 3) # pad by (0, 1), (2, 1), and (3, 3)
  4380|         0|            0|            0|  0.00%|    >>> out = F.pad(t4d, p3d, "constant", 0)
  4381|         0|            0|            0|  0.00%|    >>> print(out.size())
  4382|         0|            0|            0|  0.00%|    torch.Size([3, 9, 7, 3])
  4383|         0|            0|            0|  0.00%|
  4384|         0|            0|            0|  0.00%|""")
  4385|         0|            0|            0|  0.00%|# TODO: Fix via https://github.com/pytorch/pytorch/issues/75798
  4386|         0|            0|            0|  0.00%|pad.__module__ = "torch.nn.functional"
  4387|         0|            0|            0|  0.00%|
  4388|         0|            0|            0|  0.00%|# distance
  4389|         0|            0|            0|  0.00%|
  4390|         0|            0|            0|  0.00%|
  4391|         0|            0|            0|  0.00%|pairwise_distance = _add_docstr(
  4392|         0|            0|            0|  0.00%|    torch.pairwise_distance,
  4393|         0|            0|            0|  0.00%|    r"""
  4394|         0|            0|            0|  0.00%|pairwise_distance(x1, x2, p=2.0, eps=1e-6, keepdim=False) -> Tensor
  4395|         0|            0|            0|  0.00%|
  4396|         0|            0|            0|  0.00%|See :class:`torch.nn.PairwiseDistance` for details
  4397|         0|            0|            0|  0.00%|""")
  4398|         0|            0|            0|  0.00%|
  4399|         0|            0|            0|  0.00%|
  4400|         0|            0|            0|  0.00%|pdist = _add_docstr(
  4401|         0|            0|            0|  0.00%|    torch.pdist,
  4402|         0|            0|            0|  0.00%|    r"""
  4403|         0|            0|            0|  0.00%|pdist(input, p=2) -> Tensor
  4404|         0|            0|            0|  0.00%|
  4405|         0|            0|            0|  0.00%|Computes the p-norm distance between every pair of row vectors in the input.
  4406|         0|            0|            0|  0.00%|This is identical to the upper triangular portion, excluding the diagonal, of
  4407|         0|            0|            0|  0.00%|`torch.norm(input[:, None] - input, dim=2, p=p)`. This function will be faster
  4408|         0|            0|            0|  0.00%|if the rows are contiguous.
  4409|         0|            0|            0|  0.00%|
  4410|         0|            0|            0|  0.00%|If input has shape :math:`N \times M` then the output will have shape
  4411|         0|            0|            0|  0.00%|:math:`\frac{1}{2} N (N - 1)`.
  4412|         0|            0|            0|  0.00%|
  4413|         0|            0|            0|  0.00%|This function is equivalent to ``scipy.spatial.distance.pdist(input,
  4414|         0|            0|            0|  0.00%|'minkowski', p=p)`` if :math:`p \in (0, \infty)`. When :math:`p = 0` it is
  4415|         0|            0|            0|  0.00%|equivalent to ``scipy.spatial.distance.pdist(input, 'hamming') * M``.
  4416|         0|            0|            0|  0.00%|When :math:`p = \infty`, the closest scipy function is
  4417|         0|            0|            0|  0.00%|``scipy.spatial.distance.pdist(xn, lambda x, y: np.abs(x - y).max())``.
  4418|         0|            0|            0|  0.00%|
  4419|         0|            0|            0|  0.00%|Args:
  4420|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`N \times M`.
  4421|         0|            0|            0|  0.00%|    p: p value for the p-norm distance to calculate between each vector pair
  4422|         0|            0|            0|  0.00%|        :math:`\in [0, \infty]`.
  4423|         0|            0|            0|  0.00%|""",
  4424|         0|            0|            0|  0.00%|)
  4425|         0|            0|            0|  0.00%|
  4426|         0|            0|            0|  0.00%|
  4427|         0|            0|            0|  0.00%|cosine_similarity = _add_docstr(
  4428|         0|            0|            0|  0.00%|    torch.cosine_similarity,
  4429|         0|            0|            0|  0.00%|    r"""
  4430|         0|            0|            0|  0.00%|cosine_similarity(x1, x2, dim=1, eps=1e-8) -> Tensor
  4431|         0|            0|            0|  0.00%|
  4432|         0|            0|            0|  0.00%|Returns cosine similarity between ``x1`` and ``x2``, computed along dim. ``x1`` and ``x2`` must be broadcastable
  4433|         0|            0|            0|  0.00%|to a common shape. ``dim`` refers to the dimension in this common shape. Dimension ``dim`` of the output is
  4434|         0|            0|            0|  0.00%|squeezed (see :func:`torch.squeeze`), resulting in the
  4435|         0|            0|            0|  0.00%|output tensor having 1 fewer dimension.
  4436|         0|            0|            0|  0.00%|
  4437|         0|            0|            0|  0.00%|.. math ::
  4438|         0|            0|            0|  0.00%|    \text{similarity} = \dfrac{x_1 \cdot x_2}{\max(\Vert x_1 \Vert _2 \cdot \Vert x_2 \Vert _2, \epsilon)}
  4439|         0|            0|            0|  0.00%|
  4440|         0|            0|            0|  0.00%|Supports :ref:`type promotion <type-promotion-doc>`.
  4441|         0|            0|            0|  0.00%|
  4442|         0|            0|            0|  0.00%|Args:
  4443|         0|            0|            0|  0.00%|    x1 (Tensor): First input.
  4444|         0|            0|            0|  0.00%|    x2 (Tensor): Second input.
  4445|         0|            0|            0|  0.00%|    dim (int, optional): Dimension along which cosine similarity is computed. Default: 1
  4446|         0|            0|            0|  0.00%|    eps (float, optional): Small value to avoid division by zero.
  4447|         0|            0|            0|  0.00%|        Default: 1e-8
  4448|         0|            0|            0|  0.00%|
  4449|         0|            0|            0|  0.00%|Example::
  4450|         0|            0|            0|  0.00%|
  4451|         0|            0|            0|  0.00%|    >>> input1 = torch.randn(100, 128)
  4452|         0|            0|            0|  0.00%|    >>> input2 = torch.randn(100, 128)
  4453|         0|            0|            0|  0.00%|    >>> output = F.cosine_similarity(input1, input2)
  4454|         0|            0|            0|  0.00%|    >>> print(output)
  4455|         0|            0|            0|  0.00%|""",
  4456|         0|            0|            0|  0.00%|)
  4457|         0|            0|            0|  0.00%|
  4458|         0|            0|            0|  0.00%|
  4459|         0|            0|            0|  0.00%|one_hot = _add_docstr(
  4460|         0|            0|            0|  0.00%|    torch._C._nn.one_hot,
  4461|         0|            0|            0|  0.00%|    r"""
  4462|         0|            0|            0|  0.00%|one_hot(tensor, num_classes=-1) -> LongTensor
  4463|         0|            0|            0|  0.00%|
  4464|         0|            0|            0|  0.00%|Takes LongTensor with index values of shape ``(*)`` and returns a tensor
  4465|         0|            0|            0|  0.00%|of shape ``(*, num_classes)`` that have zeros everywhere except where the
  4466|         0|            0|            0|  0.00%|index of last dimension matches the corresponding value of the input tensor,
  4467|         0|            0|            0|  0.00%|in which case it will be 1.
  4468|         0|            0|            0|  0.00%|
  4469|         0|            0|            0|  0.00%|See also `One-hot on Wikipedia`_ .
  4470|         0|            0|            0|  0.00%|
  4471|         0|            0|            0|  0.00%|.. _One-hot on Wikipedia:
  4472|         0|            0|            0|  0.00%|    https://en.wikipedia.org/wiki/One-hot
  4473|         0|            0|            0|  0.00%|
  4474|         0|            0|            0|  0.00%|Arguments:
  4475|         0|            0|            0|  0.00%|    tensor (LongTensor): class values of any shape.
  4476|         0|            0|            0|  0.00%|    num_classes (int):  Total number of classes. If set to -1, the number
  4477|         0|            0|            0|  0.00%|        of classes will be inferred as one greater than the largest class
  4478|         0|            0|            0|  0.00%|        value in the input tensor.
  4479|         0|            0|            0|  0.00%|
  4480|         0|            0|            0|  0.00%|Returns:
  4481|         0|            0|            0|  0.00%|    LongTensor that has one more dimension with 1 values at the
  4482|         0|            0|            0|  0.00%|    index of last dimension indicated by the input, and 0 everywhere
  4483|         0|            0|            0|  0.00%|    else.
  4484|         0|            0|            0|  0.00%|
  4485|         0|            0|            0|  0.00%|Examples:
  4486|         0|            0|            0|  0.00%|    >>> F.one_hot(torch.arange(0, 5) % 3)
  4487|         0|            0|            0|  0.00%|    tensor([[1, 0, 0],
  4488|         0|            0|            0|  0.00%|            [0, 1, 0],
  4489|         0|            0|            0|  0.00%|            [0, 0, 1],
  4490|         0|            0|            0|  0.00%|            [1, 0, 0],
  4491|         0|            0|            0|  0.00%|            [0, 1, 0]])
  4492|         0|            0|            0|  0.00%|    >>> F.one_hot(torch.arange(0, 5) % 3, num_classes=5)
  4493|         0|            0|            0|  0.00%|    tensor([[1, 0, 0, 0, 0],
  4494|         0|            0|            0|  0.00%|            [0, 1, 0, 0, 0],
  4495|         0|            0|            0|  0.00%|            [0, 0, 1, 0, 0],
  4496|         0|            0|            0|  0.00%|            [1, 0, 0, 0, 0],
  4497|         0|            0|            0|  0.00%|            [0, 1, 0, 0, 0]])
  4498|         0|            0|            0|  0.00%|    >>> F.one_hot(torch.arange(0, 6).view(3,2) % 3)
  4499|         0|            0|            0|  0.00%|    tensor([[[1, 0, 0],
  4500|         0|            0|            0|  0.00%|             [0, 1, 0]],
  4501|         0|            0|            0|  0.00%|            [[0, 0, 1],
  4502|         0|            0|            0|  0.00%|             [1, 0, 0]],
  4503|         0|            0|            0|  0.00%|            [[0, 1, 0],
  4504|         0|            0|            0|  0.00%|             [0, 0, 1]]])
  4505|         0|            0|            0|  0.00%|""",
  4506|         0|            0|            0|  0.00%|)
  4507|         0|            0|            0|  0.00%|
  4508|         0|            0|            0|  0.00%|
  4509|         0|            0|            0|  0.00%|def triplet_margin_loss(
  4510|         0|            0|            0|  0.00%|    anchor: Tensor,
  4511|         0|            0|            0|  0.00%|    positive: Tensor,
  4512|         0|            0|            0|  0.00%|    negative: Tensor,
  4513|         0|            0|            0|  0.00%|    margin: float = 1.0,
  4514|         0|            0|            0|  0.00%|    p: float = 2,
  4515|         0|            0|            0|  0.00%|    eps: float = 1e-6,
  4516|         0|            0|            0|  0.00%|    swap: bool = False,
  4517|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,
  4518|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,
  4519|         0|            0|            0|  0.00%|    reduction: str = "mean",
  4520|         0|            0|            0|  0.00%|) -> Tensor:
  4521|         0|            0|            0|  0.00%|    r"""
  4522|         0|            0|            0|  0.00%|    See :class:`~torch.nn.TripletMarginLoss` for details
  4523|         0|            0|            0|  0.00%|    """
  4524|         0|            0|            0|  0.00%|    if has_torch_function_variadic(anchor, positive, negative):
  4525|         0|            0|            0|  0.00%|        return handle_torch_function(
  4526|         0|            0|            0|  0.00%|            triplet_margin_loss,
  4527|         0|            0|            0|  0.00%|            (anchor, positive, negative),
  4528|         0|            0|            0|  0.00%|            anchor,
  4529|         0|            0|            0|  0.00%|            positive,
  4530|         0|            0|            0|  0.00%|            negative,
  4531|         0|            0|            0|  0.00%|            margin=margin,
  4532|         0|            0|            0|  0.00%|            p=p,
  4533|         0|            0|            0|  0.00%|            eps=eps,
  4534|         0|            0|            0|  0.00%|            swap=swap,
  4535|         0|            0|            0|  0.00%|            size_average=size_average,
  4536|         0|            0|            0|  0.00%|            reduce=reduce,
  4537|         0|            0|            0|  0.00%|            reduction=reduction,
  4538|         0|            0|            0|  0.00%|        )
  4539|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:
  4540|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)
  4541|         0|            0|            0|  0.00%|    else:
  4542|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)
  4543|         0|            0|            0|  0.00%|    return torch.triplet_margin_loss(anchor, positive, negative, margin, p, eps, swap, reduction_enum)
  4544|         0|            0|            0|  0.00%|
  4545|         0|            0|            0|  0.00%|
  4546|         0|            0|            0|  0.00%|def triplet_margin_with_distance_loss(
  4547|         0|            0|            0|  0.00%|    anchor: Tensor,
  4548|         0|            0|            0|  0.00%|    positive: Tensor,
  4549|         0|            0|            0|  0.00%|    negative: Tensor,
  4550|         0|            0|            0|  0.00%|    *,
  4551|         0|            0|            0|  0.00%|    distance_function: Optional[Callable[[Tensor, Tensor], Tensor]] = None,
  4552|         0|            0|            0|  0.00%|    margin: float = 1.0,
  4553|         0|            0|            0|  0.00%|    swap: bool = False,
  4554|         0|            0|            0|  0.00%|    reduction: str = "mean"
  4555|         0|            0|            0|  0.00%|) -> Tensor:
  4556|         0|            0|            0|  0.00%|    r"""
  4557|         0|            0|            0|  0.00%|    See :class:`~torch.nn.TripletMarginWithDistanceLoss` for details.
  4558|         0|            0|            0|  0.00%|    """
  4559|         0|            0|            0|  0.00%|    if torch.jit.is_scripting():
  4560|         0|            0|            0|  0.00%|        raise NotImplementedError(
  4561|         0|            0|            0|  0.00%|            "F.triplet_margin_with_distance_loss does not support JIT scripting: "
  4562|         0|            0|            0|  0.00%|            "functions requiring Callables cannot be scripted."
  4563|         0|            0|            0|  0.00%|        )
  4564|         0|            0|            0|  0.00%|
  4565|         0|            0|            0|  0.00%|    if has_torch_function_variadic(anchor, positive, negative):
  4566|         0|            0|            0|  0.00%|        return handle_torch_function(
  4567|         0|            0|            0|  0.00%|            triplet_margin_with_distance_loss,
  4568|         0|            0|            0|  0.00%|            (anchor, positive, negative),
  4569|         0|            0|            0|  0.00%|            anchor,
  4570|         0|            0|            0|  0.00%|            positive,
  4571|         0|            0|            0|  0.00%|            negative,
  4572|         0|            0|            0|  0.00%|            distance_function=distance_function,
  4573|         0|            0|            0|  0.00%|            margin=margin,
  4574|         0|            0|            0|  0.00%|            swap=swap,
  4575|         0|            0|            0|  0.00%|            reduction=reduction,
  4576|         0|            0|            0|  0.00%|        )
  4577|         0|            0|            0|  0.00%|
  4578|         0|            0|            0|  0.00%|    distance_function = distance_function if distance_function is not None else pairwise_distance
  4579|         0|            0|            0|  0.00%|
  4580|         0|            0|            0|  0.00%|    positive_dist = distance_function(anchor, positive)
  4581|         0|            0|            0|  0.00%|    negative_dist = distance_function(anchor, negative)
  4582|         0|            0|            0|  0.00%|
  4583|         0|            0|            0|  0.00%|    if swap:
  4584|         0|            0|            0|  0.00%|        swap_dist = distance_function(positive, negative)
  4585|         0|            0|            0|  0.00%|        negative_dist = torch.min(negative_dist, swap_dist)
  4586|         0|            0|            0|  0.00%|
  4587|         0|            0|            0|  0.00%|    output = torch.clamp(positive_dist - negative_dist + margin, min=0.0)
  4588|         0|            0|            0|  0.00%|
  4589|         0|            0|            0|  0.00%|    reduction_enum = _Reduction.get_enum(reduction)
  4590|         0|            0|            0|  0.00%|    if reduction_enum == 1:
  4591|         0|            0|            0|  0.00%|        return output.mean()
  4592|         0|            0|            0|  0.00%|    elif reduction_enum == 2:
  4593|         0|            0|            0|  0.00%|        return output.sum()
  4594|         0|            0|            0|  0.00%|    else:
  4595|         0|            0|            0|  0.00%|        return output
  4596|         0|            0|            0|  0.00%|
  4597|         0|            0|            0|  0.00%|
  4598|         0|            0|            0|  0.00%|def normalize(input: Tensor, p: float = 2.0, dim: int = 1, eps: float = 1e-12, out: Optional[Tensor] = None) -> Tensor:
  4599|         0|            0|            0|  0.00%|    r"""Performs :math:`L_p` normalization of inputs over specified dimension.
  4600|         0|            0|            0|  0.00%|
  4601|         0|            0|            0|  0.00%|    For a tensor :attr:`input` of sizes :math:`(n_0, ..., n_{dim}, ..., n_k)`, each
  4602|         0|            0|            0|  0.00%|    :math:`n_{dim}` -element vector :math:`v` along dimension :attr:`dim` is transformed as
  4603|         0|            0|            0|  0.00%|
  4604|         0|            0|            0|  0.00%|    .. math::
  4605|         0|            0|            0|  0.00%|        v = \frac{v}{\max(\lVert v \rVert_p, \epsilon)}.
  4606|         0|            0|            0|  0.00%|
  4607|         0|            0|            0|  0.00%|    With the default arguments it uses the Euclidean norm over vectors along dimension :math:`1` for normalization.
  4608|         0|            0|            0|  0.00%|
  4609|         0|            0|            0|  0.00%|    Args:
  4610|         0|            0|            0|  0.00%|        input: input tensor of any shape
  4611|         0|            0|            0|  0.00%|        p (float): the exponent value in the norm formulation. Default: 2
  4612|         0|            0|            0|  0.00%|        dim (int): the dimension to reduce. Default: 1
  4613|         0|            0|            0|  0.00%|        eps (float): small value to avoid division by zero. Default: 1e-12
  4614|         0|            0|            0|  0.00%|        out (Tensor, optional): the output tensor. If :attr:`out` is used, this
  4615|         0|            0|            0|  0.00%|                                operation won't be differentiable.
  4616|         0|            0|            0|  0.00%|    """
  4617|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, out):
  4618|         0|            0|            0|  0.00%|        return handle_torch_function(normalize, (input, out), input, p=p, dim=dim, eps=eps, out=out)
  4619|         0|            0|            0|  0.00%|    if out is None:
  4620|         0|            0|            0|  0.00%|        denom = input.norm(p, dim, keepdim=True).clamp_min(eps).expand_as(input)
  4621|         0|            0|            0|  0.00%|        return input / denom
  4622|         0|            0|            0|  0.00%|    else:
  4623|         0|            0|            0|  0.00%|        denom = input.norm(p, dim, keepdim=True).clamp_min_(eps).expand_as(input)
  4624|         0|            0|            0|  0.00%|        return torch.div(input, denom, out=out)
  4625|         0|            0|            0|  0.00%|
  4626|         0|            0|            0|  0.00%|
  4627|         0|            0|            0|  0.00%|def assert_int_or_pair(arg: List[int], arg_name: str, message: str) -> None:
  4628|         0|            0|            0|  0.00%|    assert isinstance(arg, int) or len(arg) == 2, message.format(arg_name)
  4629|         0|            0|            0|  0.00%|
  4630|         0|            0|            0|  0.00%|
  4631|         0|            0|            0|  0.00%|def unfold(
  4632|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList2[int],
  4633|         0|            0|            0|  0.00%|    dilation: BroadcastingList2[int] = 1,
  4634|         0|            0|            0|  0.00%|    padding: BroadcastingList2[int] = 0,
  4635|         0|            0|            0|  0.00%|    stride: BroadcastingList2[int] = 1
  4636|         0|            0|            0|  0.00%|) -> Tensor:
  4637|         0|            0|            0|  0.00%|    r"""Extracts sliding local blocks from a batched input tensor.
  4638|         0|            0|            0|  0.00%|
  4639|         0|            0|            0|  0.00%|    .. warning::
  4640|         0|            0|            0|  0.00%|        Currently, only 4-D input tensors (batched image-like tensors) are
  4641|         0|            0|            0|  0.00%|        supported.
  4642|         0|            0|            0|  0.00%|
  4643|         0|            0|            0|  0.00%|    .. warning::
  4644|         0|            0|            0|  0.00%|
  4645|         0|            0|            0|  0.00%|        More than one element of the unfolded tensor may refer to a single
  4646|         0|            0|            0|  0.00%|        memory location. As a result, in-place operations (especially ones that
  4647|         0|            0|            0|  0.00%|        are vectorized) may result in incorrect behavior. If you need to write
  4648|         0|            0|            0|  0.00%|        to the tensor, please clone it first.
  4649|         0|            0|            0|  0.00%|
  4650|         0|            0|            0|  0.00%|
  4651|         0|            0|            0|  0.00%|    See :class:`torch.nn.Unfold` for details
  4652|         0|            0|            0|  0.00%|    """
  4653|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  4654|         0|            0|            0|  0.00%|        return handle_torch_function(
  4655|         0|            0|            0|  0.00%|            unfold, (input,), input, kernel_size, dilation=dilation, padding=padding, stride=stride
  4656|         0|            0|            0|  0.00%|        )
  4657|         0|            0|            0|  0.00%|    if input.dim() == 4:
  4658|         0|            0|            0|  0.00%|        msg = "{} must be int or 2-tuple for 4D input"
  4659|         0|            0|            0|  0.00%|        assert_int_or_pair(kernel_size, "kernel_size", msg)
  4660|         0|            0|            0|  0.00%|        assert_int_or_pair(dilation, "dilation", msg)
  4661|         0|            0|            0|  0.00%|        assert_int_or_pair(padding, "padding", msg)
  4662|         0|            0|            0|  0.00%|        assert_int_or_pair(stride, "stride", msg)
  4663|         0|            0|            0|  0.00%|
  4664|         0|            0|            0|  0.00%|        return torch._C._nn.im2col(input, _pair(kernel_size), _pair(dilation), _pair(padding), _pair(stride))
  4665|         0|            0|            0|  0.00%|    else:
  4666|         0|            0|            0|  0.00%|        raise NotImplementedError("Input Error: Only 4D input Tensors are supported (got {}D)".format(input.dim()))
  4667|         0|            0|            0|  0.00%|
  4668|         0|            0|            0|  0.00%|
  4669|         0|            0|            0|  0.00%|def fold(
  4670|         0|            0|            0|  0.00%|    input: Tensor, output_size: BroadcastingList2[int],
  4671|         0|            0|            0|  0.00%|    kernel_size: BroadcastingList2[int],
  4672|         0|            0|            0|  0.00%|    dilation: BroadcastingList2[int] = 1,
  4673|         0|            0|            0|  0.00%|    padding: BroadcastingList2[int] = 0,
  4674|         0|            0|            0|  0.00%|    stride: BroadcastingList2[int] = 1
  4675|         0|            0|            0|  0.00%|) -> Tensor:
  4676|         0|            0|            0|  0.00%|    r"""Combines an array of sliding local blocks into a large containing
  4677|         0|            0|            0|  0.00%|    tensor.
  4678|         0|            0|            0|  0.00%|
  4679|         0|            0|            0|  0.00%|    .. warning::
  4680|         0|            0|            0|  0.00%|        Currently, only unbatched (3D) or batched (4D) image-like output tensors are supported.
  4681|         0|            0|            0|  0.00%|
  4682|         0|            0|            0|  0.00%|    See :class:`torch.nn.Fold` for details
  4683|         0|            0|            0|  0.00%|    """
  4684|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):
  4685|         0|            0|            0|  0.00%|        return handle_torch_function(
  4686|         0|            0|            0|  0.00%|            fold, (input,), input, output_size, kernel_size, dilation=dilation, padding=padding, stride=stride
  4687|         0|            0|            0|  0.00%|        )
  4688|         0|            0|            0|  0.00%|    if input.dim() == 3 or input.dim() == 2:
  4689|         0|            0|            0|  0.00%|        msg = "{} must be int or 2-tuple for 3D input"
  4690|         0|            0|            0|  0.00%|        assert_int_or_pair(output_size, "output_size", msg)
  4691|         0|            0|            0|  0.00%|        assert_int_or_pair(kernel_size, "kernel_size", msg)
  4692|         0|            0|            0|  0.00%|        assert_int_or_pair(dilation, "dilation", msg)
  4693|         0|            0|            0|  0.00%|        assert_int_or_pair(padding, "padding", msg)
  4694|         0|            0|            0|  0.00%|        assert_int_or_pair(stride, "stride", msg)
  4695|         0|            0|            0|  0.00%|
  4696|         0|            0|            0|  0.00%|        return torch._C._nn.col2im(
  4697|         0|            0|            0|  0.00%|            input, _pair(output_size), _pair(kernel_size), _pair(dilation), _pair(padding), _pair(stride)
  4698|         0|            0|            0|  0.00%|        )
  4699|         0|            0|            0|  0.00%|    else:
  4700|         0|            0|            0|  0.00%|        raise NotImplementedError("Input Error: Only unbatched (2D) or batched (3D) input Tensors"
  4701|         0|            0|            0|  0.00%|                                  f"are supported (got {input.dim()}D)")
  4702|         0|            0|            0|  0.00%|
  4703|         0|            0|            0|  0.00%|#
  4704|         0|            0|            0|  0.00%|# multihead attention
  4705|         0|            0|            0|  0.00%|#
  4706|         0|            0|            0|  0.00%|
  4707|         0|            0|            0|  0.00%|def _in_projection_packed(
  4708|         0|            0|            0|  0.00%|    q: Tensor,
  4709|         0|            0|            0|  0.00%|    k: Tensor,
  4710|         0|            0|            0|  0.00%|    v: Tensor,
  4711|         0|            0|            0|  0.00%|    w: Tensor,
  4712|         0|            0|            0|  0.00%|    b: Optional[Tensor] = None,
  4713|         0|            0|            0|  0.00%|) -> List[Tensor]:
  4714|         0|            0|            0|  0.00%|    r"""
  4715|         0|            0|            0|  0.00%|    Performs the in-projection step of the attention operation, using packed weights.
  4716|         0|            0|            0|  0.00%|    Output is a triple containing projection tensors for query, key and value.
  4717|         0|            0|            0|  0.00%|
  4718|         0|            0|            0|  0.00%|    Args:
  4719|         0|            0|            0|  0.00%|        q, k, v: query, key and value tensors to be projected. For self-attention,
  4720|         0|            0|            0|  0.00%|            these are typically the same tensor; for encoder-decoder attention,
  4721|         0|            0|            0|  0.00%|            k and v are typically the same tensor. (We take advantage of these
  4722|         0|            0|            0|  0.00%|            identities for performance if they are present.) Regardless, q, k and v
  4723|         0|            0|            0|  0.00%|            must share a common embedding dimension; otherwise their shapes may vary.
  4724|         0|            0|            0|  0.00%|        w: projection weights for q, k and v, packed into a single tensor. Weights
  4725|         0|            0|            0|  0.00%|            are packed along dimension 0, in q, k, v order.
  4726|         0|            0|            0|  0.00%|        b: optional projection biases for q, k and v, packed into a single tensor
  4727|         0|            0|            0|  0.00%|            in q, k, v order.
  4728|         0|            0|            0|  0.00%|
  4729|         0|            0|            0|  0.00%|    Shape:
  4730|         0|            0|            0|  0.00%|        Inputs:
  4731|         0|            0|            0|  0.00%|        - q: :math:`(..., E)` where E is the embedding dimension
  4732|         0|            0|            0|  0.00%|        - k: :math:`(..., E)` where E is the embedding dimension
  4733|         0|            0|            0|  0.00%|        - v: :math:`(..., E)` where E is the embedding dimension
  4734|         0|            0|            0|  0.00%|        - w: :math:`(E * 3, E)` where E is the embedding dimension
  4735|         0|            0|            0|  0.00%|        - b: :math:`E * 3` where E is the embedding dimension
  4736|         0|            0|            0|  0.00%|
  4737|         0|            0|            0|  0.00%|        Output:
  4738|         0|            0|            0|  0.00%|        - in output list :math:`[q', k', v']`, each output tensor will have the
  4739|         0|            0|            0|  0.00%|            same shape as the corresponding input tensor.
  4740|         0|            0|            0|  0.00%|    """
  4741|         0|            0|            0|  0.00%|    E = q.size(-1)
  4742|         0|            0|            0|  0.00%|    if k is v:
  4743|         0|            0|            0|  0.00%|        if q is k:
  4744|         0|            0|            0|  0.00%|            # self-attention
  4745|         0|            0|            0|  0.00%|            return linear(q, w, b).chunk(3, dim=-1)
  4746|         0|            0|            0|  0.00%|        else:
  4747|         0|            0|            0|  0.00%|            # encoder-decoder attention
  4748|         0|            0|            0|  0.00%|            w_q, w_kv = w.split([E, E * 2])
  4749|         0|            0|            0|  0.00%|            if b is None:
  4750|         0|            0|            0|  0.00%|                b_q = b_kv = None
  4751|         0|            0|            0|  0.00%|            else:
  4752|         0|            0|            0|  0.00%|                b_q, b_kv = b.split([E, E * 2])
  4753|         0|            0|            0|  0.00%|            return (linear(q, w_q, b_q),) + linear(k, w_kv, b_kv).chunk(2, dim=-1)
  4754|         0|            0|            0|  0.00%|    else:
  4755|         0|            0|            0|  0.00%|        w_q, w_k, w_v = w.chunk(3)
  4756|         0|            0|            0|  0.00%|        if b is None:
  4757|         0|            0|            0|  0.00%|            b_q = b_k = b_v = None
  4758|         0|            0|            0|  0.00%|        else:
  4759|         0|            0|            0|  0.00%|            b_q, b_k, b_v = b.chunk(3)
  4760|         0|            0|            0|  0.00%|        return linear(q, w_q, b_q), linear(k, w_k, b_k), linear(v, w_v, b_v)
  4761|         0|            0|            0|  0.00%|
  4762|         0|            0|            0|  0.00%|
  4763|         0|            0|            0|  0.00%|def _in_projection(
  4764|         0|            0|            0|  0.00%|    q: Tensor,
  4765|         0|            0|            0|  0.00%|    k: Tensor,
  4766|         0|            0|            0|  0.00%|    v: Tensor,
  4767|         0|            0|            0|  0.00%|    w_q: Tensor,
  4768|         0|            0|            0|  0.00%|    w_k: Tensor,
  4769|         0|            0|            0|  0.00%|    w_v: Tensor,
  4770|         0|            0|            0|  0.00%|    b_q: Optional[Tensor] = None,
  4771|         0|            0|            0|  0.00%|    b_k: Optional[Tensor] = None,
  4772|         0|            0|            0|  0.00%|    b_v: Optional[Tensor] = None,
  4773|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor, Tensor]:
  4774|         0|            0|            0|  0.00%|    r"""
  4775|         0|            0|            0|  0.00%|    Performs the in-projection step of the attention operation. This is simply
  4776|         0|            0|            0|  0.00%|    a triple of linear projections, with shape constraints on the weights which
  4777|         0|            0|            0|  0.00%|    ensure embedding dimension uniformity in the projected outputs.
  4778|         0|            0|            0|  0.00%|    Output is a triple containing projection tensors for query, key and value.
  4779|         0|            0|            0|  0.00%|
  4780|         0|            0|            0|  0.00%|    Args:
  4781|         0|            0|            0|  0.00%|        q, k, v: query, key and value tensors to be projected.
  4782|         0|            0|            0|  0.00%|        w_q, w_k, w_v: weights for q, k and v, respectively.
  4783|         0|            0|            0|  0.00%|        b_q, b_k, b_v: optional biases for q, k and v, respectively.
  4784|         0|            0|            0|  0.00%|
  4785|         0|            0|            0|  0.00%|    Shape:
  4786|         0|            0|            0|  0.00%|        Inputs:
  4787|         0|            0|            0|  0.00%|        - q: :math:`(Qdims..., Eq)` where Eq is the query embedding dimension and Qdims are any
  4788|         0|            0|            0|  0.00%|            number of leading dimensions.
  4789|         0|            0|            0|  0.00%|        - k: :math:`(Kdims..., Ek)` where Ek is the key embedding dimension and Kdims are any
  4790|         0|            0|            0|  0.00%|            number of leading dimensions.
  4791|         0|            0|            0|  0.00%|        - v: :math:`(Vdims..., Ev)` where Ev is the value embedding dimension and Vdims are any
  4792|         0|            0|            0|  0.00%|            number of leading dimensions.
  4793|         0|            0|            0|  0.00%|        - w_q: :math:`(Eq, Eq)`
  4794|         0|            0|            0|  0.00%|        - w_k: :math:`(Eq, Ek)`
  4795|         0|            0|            0|  0.00%|        - w_v: :math:`(Eq, Ev)`
  4796|         0|            0|            0|  0.00%|        - b_q: :math:`(Eq)`
  4797|         0|            0|            0|  0.00%|        - b_k: :math:`(Eq)`
  4798|         0|            0|            0|  0.00%|        - b_v: :math:`(Eq)`
  4799|         0|            0|            0|  0.00%|
  4800|         0|            0|            0|  0.00%|        Output: in output triple :math:`(q', k', v')`,
  4801|         0|            0|            0|  0.00%|         - q': :math:`[Qdims..., Eq]`
  4802|         0|            0|            0|  0.00%|         - k': :math:`[Kdims..., Eq]`
  4803|         0|            0|            0|  0.00%|         - v': :math:`[Vdims..., Eq]`
  4804|         0|            0|            0|  0.00%|
  4805|         0|            0|            0|  0.00%|    """
  4806|         0|            0|            0|  0.00%|    Eq, Ek, Ev = q.size(-1), k.size(-1), v.size(-1)
  4807|         0|            0|            0|  0.00%|    assert w_q.shape == (Eq, Eq), f"expecting query weights shape of {(Eq, Eq)}, but got {w_q.shape}"
  4808|         0|            0|            0|  0.00%|    assert w_k.shape == (Eq, Ek), f"expecting key weights shape of {(Eq, Ek)}, but got {w_k.shape}"
  4809|         0|            0|            0|  0.00%|    assert w_v.shape == (Eq, Ev), f"expecting value weights shape of {(Eq, Ev)}, but got {w_v.shape}"
  4810|         0|            0|            0|  0.00%|    assert b_q is None or b_q.shape == (Eq,), f"expecting query bias shape of {(Eq,)}, but got {b_q.shape}"
  4811|         0|            0|            0|  0.00%|    assert b_k is None or b_k.shape == (Eq,), f"expecting key bias shape of {(Eq,)}, but got {b_k.shape}"
  4812|         0|            0|            0|  0.00%|    assert b_v is None or b_v.shape == (Eq,), f"expecting value bias shape of {(Eq,)}, but got {b_v.shape}"
  4813|         0|            0|            0|  0.00%|    return linear(q, w_q, b_q), linear(k, w_k, b_k), linear(v, w_v, b_v)
  4814|         0|            0|            0|  0.00%|
  4815|         0|            0|            0|  0.00%|
  4816|         0|            0|            0|  0.00%|def _scaled_dot_product_attention(
  4817|         0|            0|            0|  0.00%|    q: Tensor,
  4818|         0|            0|            0|  0.00%|    k: Tensor,
  4819|         0|            0|            0|  0.00%|    v: Tensor,
  4820|         0|            0|            0|  0.00%|    attn_mask: Optional[Tensor] = None,
  4821|         0|            0|            0|  0.00%|    dropout_p: float = 0.0,
  4822|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:
  4823|         0|            0|            0|  0.00%|    r"""
  4824|         0|            0|            0|  0.00%|    Computes scaled dot product attention on query, key and value tensors, using
  4825|         0|            0|            0|  0.00%|    an optional attention mask if passed, and applying dropout if a probability
  4826|         0|            0|            0|  0.00%|    greater than 0.0 is specified.
  4827|         0|            0|            0|  0.00%|    Returns a tensor pair containing attended values and attention weights.
  4828|         0|            0|            0|  0.00%|
  4829|         0|            0|            0|  0.00%|    Args:
  4830|         0|            0|            0|  0.00%|        q, k, v: query, key and value tensors. See Shape section for shape details.
  4831|         0|            0|            0|  0.00%|        attn_mask: optional tensor containing mask values to be added to calculated
  4832|         0|            0|            0|  0.00%|            attention. May be 2D or 3D; see Shape section for details.
  4833|         0|            0|            0|  0.00%|        dropout_p: dropout probability. If greater than 0.0, dropout is applied.
  4834|         0|            0|            0|  0.00%|
  4835|         0|            0|            0|  0.00%|    Shape:
  4836|         0|            0|            0|  0.00%|        - q: :math:`(B, Nt, E)` where B is batch size, Nt is the target sequence length,
  4837|         0|            0|            0|  0.00%|            and E is embedding dimension.
  4838|         0|            0|            0|  0.00%|        - key: :math:`(B, Ns, E)` where B is batch size, Ns is the source sequence length,
  4839|         0|            0|            0|  0.00%|            and E is embedding dimension.
  4840|         0|            0|            0|  0.00%|        - value: :math:`(B, Ns, E)` where B is batch size, Ns is the source sequence length,
  4841|         0|            0|            0|  0.00%|            and E is embedding dimension.
  4842|         0|            0|            0|  0.00%|        - attn_mask: either a 3D tensor of shape :math:`(B, Nt, Ns)` or a 2D tensor of
  4843|         0|            0|            0|  0.00%|            shape :math:`(Nt, Ns)`.
  4844|         0|            0|            0|  0.00%|
  4845|         0|            0|            0|  0.00%|        - Output: attention values have shape :math:`(B, Nt, E)`; attention weights
  4846|         0|            0|            0|  0.00%|            have shape :math:`(B, Nt, Ns)`
  4847|         0|            0|            0|  0.00%|    """
  4848|         0|            0|            0|  0.00%|    B, Nt, E = q.shape
  4849|         0|            0|            0|  0.00%|    q = q / math.sqrt(E)
  4850|         0|            0|            0|  0.00%|    # (B, Nt, E) x (B, E, Ns) -> (B, Nt, Ns)
  4851|         0|            0|            0|  0.00%|    if attn_mask is not None:
  4852|         0|            0|            0|  0.00%|        attn = torch.baddbmm(attn_mask, q, k.transpose(-2, -1))
  4853|         0|            0|            0|  0.00%|    else:
  4854|         0|            0|            0|  0.00%|        attn = torch.bmm(q, k.transpose(-2, -1))
  4855|         0|            0|            0|  0.00%|
  4856|         0|            0|            0|  0.00%|    attn = softmax(attn, dim=-1)
  4857|         0|            0|            0|  0.00%|    if dropout_p > 0.0:
  4858|         0|            0|            0|  0.00%|        attn = dropout(attn, p=dropout_p)
  4859|         0|            0|            0|  0.00%|    # (B, Nt, Ns) x (B, Ns, E) -> (B, Nt, E)
  4860|         0|            0|            0|  0.00%|    output = torch.bmm(attn, v)
  4861|         0|            0|            0|  0.00%|    return output, attn
  4862|         0|            0|            0|  0.00%|
  4863|         0|            0|            0|  0.00%|
  4864|         0|            0|            0|  0.00%|def _mha_shape_check(query: Tensor, key: Tensor, value: Tensor,
  4865|         0|            0|            0|  0.00%|                     key_padding_mask: Optional[Tensor], attn_mask: Optional[Tensor], num_heads: int):
  4866|         0|            0|            0|  0.00%|    # Verifies the expected shape for `query, `key`, `value`, `key_padding_mask` and `attn_mask`
  4867|         0|            0|            0|  0.00%|    # and returns if the input is batched or not.
  4868|         0|            0|            0|  0.00%|    # Raises an error if `query` is not 2-D (unbatched) or 3-D (batched) tensor.
  4869|         0|            0|            0|  0.00%|
  4870|         0|            0|            0|  0.00%|    # Shape check.
  4871|         0|            0|            0|  0.00%|    if query.dim() == 3:
  4872|         0|            0|            0|  0.00%|        # Batched Inputs
  4873|         0|            0|            0|  0.00%|        is_batched = True
  4874|         0|            0|            0|  0.00%|        assert key.dim() == 3 and value.dim() == 3, \
  4875|         0|            0|            0|  0.00%|            ("For batched (3-D) `query`, expected `key` and `value` to be 3-D"
  4876|         0|            0|            0|  0.00%|             f" but found {key.dim()}-D and {value.dim()}-D tensors respectively")
  4877|         0|            0|            0|  0.00%|        if key_padding_mask is not None:
  4878|         0|            0|            0|  0.00%|            assert key_padding_mask.dim() == 2, \
  4879|         0|            0|            0|  0.00%|                ("For batched (3-D) `query`, expected `key_padding_mask` to be `None` or 2-D"
  4880|         0|            0|            0|  0.00%|                 f" but found {key_padding_mask.dim()}-D tensor instead")
  4881|         0|            0|            0|  0.00%|        if attn_mask is not None:
  4882|         0|            0|            0|  0.00%|            assert attn_mask.dim() in (2, 3), \
  4883|         0|            0|            0|  0.00%|                ("For batched (3-D) `query`, expected `attn_mask` to be `None`, 2-D or 3-D"
  4884|         0|            0|            0|  0.00%|                 f" but found {attn_mask.dim()}-D tensor instead")
  4885|         0|            0|            0|  0.00%|    elif query.dim() == 2:
  4886|         0|            0|            0|  0.00%|        # Unbatched Inputs
  4887|         0|            0|            0|  0.00%|        is_batched = False
  4888|         0|            0|            0|  0.00%|        assert key.dim() == 2 and value.dim() == 2, \
  4889|         0|            0|            0|  0.00%|            ("For unbatched (2-D) `query`, expected `key` and `value` to be 2-D"
  4890|         0|            0|            0|  0.00%|             f" but found {key.dim()}-D and {value.dim()}-D tensors respectively")
  4891|         0|            0|            0|  0.00%|
  4892|         0|            0|            0|  0.00%|        if key_padding_mask is not None:
  4893|         0|            0|            0|  0.00%|            assert key_padding_mask.dim() == 1, \
  4894|         0|            0|            0|  0.00%|                ("For unbatched (2-D) `query`, expected `key_padding_mask` to be `None` or 1-D"
  4895|         0|            0|            0|  0.00%|                 f" but found {key_padding_mask.dim()}-D tensor instead")
  4896|         0|            0|            0|  0.00%|
  4897|         0|            0|            0|  0.00%|        if attn_mask is not None:
  4898|         0|            0|            0|  0.00%|            assert attn_mask.dim() in (2, 3), \
  4899|         0|            0|            0|  0.00%|                ("For unbatched (2-D) `query`, expected `attn_mask` to be `None`, 2-D or 3-D"
  4900|         0|            0|            0|  0.00%|                 f" but found {attn_mask.dim()}-D tensor instead")
  4901|         0|            0|            0|  0.00%|            if attn_mask.dim() == 3:
  4902|         0|            0|            0|  0.00%|                expected_shape = (num_heads, query.shape[0], key.shape[0])
  4903|         0|            0|            0|  0.00%|                assert attn_mask.shape == expected_shape, \
  4904|         0|            0|            0|  0.00%|                    (f"Expected `attn_mask` shape to be {expected_shape} but got {attn_mask.shape}")
  4905|         0|            0|            0|  0.00%|    else:
  4906|         0|            0|            0|  0.00%|        raise AssertionError(
  4907|         0|            0|            0|  0.00%|            f"query should be unbatched 2D or batched 3D tensor but received {query.dim()}-D query tensor")
  4908|         0|            0|            0|  0.00%|
  4909|         0|            0|            0|  0.00%|    return is_batched
  4910|         0|            0|            0|  0.00%|
  4911|         0|            0|            0|  0.00%|def multi_head_attention_forward(
  4912|         0|            0|            0|  0.00%|    query: Tensor,
  4913|         0|            0|            0|  0.00%|    key: Tensor,
  4914|         0|            0|            0|  0.00%|    value: Tensor,
  4915|         0|            0|            0|  0.00%|    embed_dim_to_check: int,
  4916|         0|            0|            0|  0.00%|    num_heads: int,
  4917|         0|            0|            0|  0.00%|    in_proj_weight: Optional[Tensor],
  4918|         0|            0|            0|  0.00%|    in_proj_bias: Optional[Tensor],
  4919|         0|            0|            0|  0.00%|    bias_k: Optional[Tensor],
  4920|         0|            0|            0|  0.00%|    bias_v: Optional[Tensor],
  4921|         0|            0|            0|  0.00%|    add_zero_attn: bool,
  4922|         0|            0|            0|  0.00%|    dropout_p: float,
  4923|         0|            0|            0|  0.00%|    out_proj_weight: Tensor,
  4924|         0|            0|            0|  0.00%|    out_proj_bias: Optional[Tensor],
  4925|         0|            0|            0|  0.00%|    training: bool = True,
  4926|         0|            0|            0|  0.00%|    key_padding_mask: Optional[Tensor] = None,
  4927|         0|            0|            0|  0.00%|    need_weights: bool = True,
  4928|         0|            0|            0|  0.00%|    attn_mask: Optional[Tensor] = None,
  4929|         0|            0|            0|  0.00%|    use_separate_proj_weight: bool = False,
  4930|         0|            0|            0|  0.00%|    q_proj_weight: Optional[Tensor] = None,
  4931|         0|            0|            0|  0.00%|    k_proj_weight: Optional[Tensor] = None,
  4932|         0|            0|            0|  0.00%|    v_proj_weight: Optional[Tensor] = None,
  4933|         0|            0|            0|  0.00%|    static_k: Optional[Tensor] = None,
  4934|         0|            0|            0|  0.00%|    static_v: Optional[Tensor] = None,
  4935|         0|            0|            0|  0.00%|    average_attn_weights: bool = True,
  4936|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Optional[Tensor]]:
  4937|         0|            0|            0|  0.00%|    r"""
  4938|         0|            0|            0|  0.00%|    Args:
  4939|         0|            0|            0|  0.00%|        query, key, value: map a query and a set of key-value pairs to an output.
  4940|         0|            0|            0|  0.00%|            See "Attention Is All You Need" for more details.
  4941|         0|            0|            0|  0.00%|        embed_dim_to_check: total dimension of the model.
  4942|         0|            0|            0|  0.00%|        num_heads: parallel attention heads.
  4943|         0|            0|            0|  0.00%|        in_proj_weight, in_proj_bias: input projection weight and bias.
  4944|         0|            0|            0|  0.00%|        bias_k, bias_v: bias of the key and value sequences to be added at dim=0.
  4945|         0|            0|            0|  0.00%|        add_zero_attn: add a new batch of zeros to the key and
  4946|         0|            0|            0|  0.00%|                       value sequences at dim=1.
  4947|         0|            0|            0|  0.00%|        dropout_p: probability of an element to be zeroed.
  4948|         0|            0|            0|  0.00%|        out_proj_weight, out_proj_bias: the output projection weight and bias.
  4949|         0|            0|            0|  0.00%|        training: apply dropout if is ``True``.
  4950|         0|            0|            0|  0.00%|        key_padding_mask: if provided, specified padding elements in the key will
  4951|         0|            0|            0|  0.00%|            be ignored by the attention. This is an binary mask. When the value is True,
  4952|         0|            0|            0|  0.00%|            the corresponding value on the attention layer will be filled with -inf.
  4953|         0|            0|            0|  0.00%|        need_weights: output attn_output_weights.
  4954|         0|            0|            0|  0.00%|        attn_mask: 2D or 3D mask that prevents attention to certain positions. A 2D mask will be broadcasted for all
  4955|         0|            0|            0|  0.00%|            the batches while a 3D mask allows to specify a different mask for the entries of each batch.
  4956|         0|            0|            0|  0.00%|        use_separate_proj_weight: the function accept the proj. weights for query, key,
  4957|         0|            0|            0|  0.00%|            and value in different forms. If false, in_proj_weight will be used, which is
  4958|         0|            0|            0|  0.00%|            a combination of q_proj_weight, k_proj_weight, v_proj_weight.
  4959|         0|            0|            0|  0.00%|        q_proj_weight, k_proj_weight, v_proj_weight, in_proj_bias: input projection weight and bias.
  4960|         0|            0|            0|  0.00%|        static_k, static_v: static key and value used for attention operators.
  4961|         0|            0|            0|  0.00%|        average_attn_weights: If true, indicates that the returned ``attn_weights`` should be averaged across heads.
  4962|         0|            0|            0|  0.00%|            Otherwise, ``attn_weights`` are provided separately per head. Note that this flag only has an effect
  4963|         0|            0|            0|  0.00%|            when ``need_weights=True.``. Default: True
  4964|         0|            0|            0|  0.00%|
  4965|         0|            0|            0|  0.00%|
  4966|         0|            0|            0|  0.00%|    Shape:
  4967|         0|            0|            0|  0.00%|        Inputs:
  4968|         0|            0|            0|  0.00%|        - query: :math:`(L, E)` or :math:`(L, N, E)` where L is the target sequence length, N is the batch size, E is
  4969|         0|            0|            0|  0.00%|          the embedding dimension.
  4970|         0|            0|            0|  0.00%|        - key: :math:`(S, E)` or :math:`(S, N, E)`, where S is the source sequence length, N is the batch size, E is
  4971|         0|            0|            0|  0.00%|          the embedding dimension.
  4972|         0|            0|            0|  0.00%|        - value: :math:`(S, E)` or :math:`(S, N, E)` where S is the source sequence length, N is the batch size, E is
  4973|         0|            0|            0|  0.00%|          the embedding dimension.
  4974|         0|            0|            0|  0.00%|        - key_padding_mask: :math:`(S)` or :math:`(N, S)` where N is the batch size, S is the source sequence length.
  4975|         0|            0|            0|  0.00%|          If a ByteTensor is provided, the non-zero positions will be ignored while the zero positions
  4976|         0|            0|            0|  0.00%|          will be unchanged. If a BoolTensor is provided, the positions with the
  4977|         0|            0|            0|  0.00%|          value of ``True`` will be ignored while the position with the value of ``False`` will be unchanged.
  4978|         0|            0|            0|  0.00%|        - attn_mask: 2D mask :math:`(L, S)` where L is the target sequence length, S is the source sequence length.
  4979|         0|            0|            0|  0.00%|          3D mask :math:`(N*num_heads, L, S)` where N is the batch size, L is the target sequence length,
  4980|         0|            0|            0|  0.00%|          S is the source sequence length. attn_mask ensures that position i is allowed to attend the unmasked
  4981|         0|            0|            0|  0.00%|          positions. If a ByteTensor is provided, the non-zero positions are not allowed to attend
  4982|         0|            0|            0|  0.00%|          while the zero positions will be unchanged. If a BoolTensor is provided, positions with ``True``
  4983|         0|            0|            0|  0.00%|          are not allowed to attend while ``False`` values will be unchanged. If a FloatTensor
  4984|         0|            0|            0|  0.00%|          is provided, it will be added to the attention weight.
  4985|         0|            0|            0|  0.00%|        - static_k: :math:`(N*num_heads, S, E/num_heads)`, where S is the source sequence length,
  4986|         0|            0|            0|  0.00%|          N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.
  4987|         0|            0|            0|  0.00%|        - static_v: :math:`(N*num_heads, S, E/num_heads)`, where S is the source sequence length,
  4988|         0|            0|            0|  0.00%|          N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.
  4989|         0|            0|            0|  0.00%|
  4990|         0|            0|            0|  0.00%|        Outputs:
  4991|         0|            0|            0|  0.00%|        - attn_output: :math:`(L, E)` or :math:`(L, N, E)` where L is the target sequence length, N is the batch size,
  4992|         0|            0|            0|  0.00%|          E is the embedding dimension.
  4993|         0|            0|            0|  0.00%|        - attn_output_weights: Only returned when ``need_weights=True``. If ``average_attn_weights=True``, returns
  4994|         0|            0|            0|  0.00%|          attention weights averaged across heads of shape :math:`(L, S)` when input is unbatched or
  4995|         0|            0|            0|  0.00%|          :math:`(N, L, S)`, where :math:`N` is the batch size, :math:`L` is the target sequence length, and
  4996|         0|            0|            0|  0.00%|          :math:`S` is the source sequence length. If ``average_weights=False``, returns attention weights per
  4997|         0|            0|            0|  0.00%|          head of shape :math:`(num_heads, L, S)` when input is unbatched or :math:`(N, num_heads, L, S)`.
  4998|         0|            0|            0|  0.00%|    """
  4999|         0|            0|            0|  0.00%|    tens_ops = (query, key, value, in_proj_weight, in_proj_bias, bias_k, bias_v, out_proj_weight, out_proj_bias)
  5000|         0|            0|            0|  0.00%|    if has_torch_function(tens_ops):
  5001|         0|            0|            0|  0.00%|        return handle_torch_function(
  5002|         0|            0|            0|  0.00%|            multi_head_attention_forward,
  5003|         0|            0|            0|  0.00%|            tens_ops,
  5004|         0|            0|            0|  0.00%|            query,
  5005|         0|            0|            0|  0.00%|            key,
  5006|         0|            0|            0|  0.00%|            value,
  5007|         0|            0|            0|  0.00%|            embed_dim_to_check,
  5008|         0|            0|            0|  0.00%|            num_heads,
  5009|         0|            0|            0|  0.00%|            in_proj_weight,
  5010|         0|            0|            0|  0.00%|            in_proj_bias,
  5011|         0|            0|            0|  0.00%|            bias_k,
  5012|         0|            0|            0|  0.00%|            bias_v,
  5013|         0|            0|            0|  0.00%|            add_zero_attn,
  5014|         0|            0|            0|  0.00%|            dropout_p,
  5015|         0|            0|            0|  0.00%|            out_proj_weight,
  5016|         0|            0|            0|  0.00%|            out_proj_bias,
  5017|         0|            0|            0|  0.00%|            training=training,
  5018|         0|            0|            0|  0.00%|            key_padding_mask=key_padding_mask,
  5019|         0|            0|            0|  0.00%|            need_weights=need_weights,
  5020|         0|            0|            0|  0.00%|            attn_mask=attn_mask,
  5021|         0|            0|            0|  0.00%|            use_separate_proj_weight=use_separate_proj_weight,
  5022|         0|            0|            0|  0.00%|            q_proj_weight=q_proj_weight,
  5023|         0|            0|            0|  0.00%|            k_proj_weight=k_proj_weight,
  5024|         0|            0|            0|  0.00%|            v_proj_weight=v_proj_weight,
  5025|         0|            0|            0|  0.00%|            static_k=static_k,
  5026|         0|            0|            0|  0.00%|            static_v=static_v,
  5027|         0|            0|            0|  0.00%|            average_attn_weights=average_attn_weights,
  5028|         0|            0|            0|  0.00%|        )
  5029|         0|            0|            0|  0.00%|
  5030|         0|            0|            0|  0.00%|    is_batched = _mha_shape_check(query, key, value, key_padding_mask, attn_mask, num_heads)
  5031|         0|            0|            0|  0.00%|
  5032|         0|            0|            0|  0.00%|    # For unbatched input, we unsqueeze at the expected batch-dim to pretend that the input
  5033|         0|            0|            0|  0.00%|    # is batched, run the computation and before returning squeeze the
  5034|         0|            0|            0|  0.00%|    # batch dimension so that the output doesn't carry this temporary batch dimension.
  5035|         0|            0|            0|  0.00%|    if not is_batched:
  5036|         0|            0|            0|  0.00%|        # unsqueeze if the input is unbatched
  5037|         0|            0|            0|  0.00%|        query = query.unsqueeze(1)
  5038|         0|            0|            0|  0.00%|        key = key.unsqueeze(1)
  5039|         0|            0|            0|  0.00%|        value = value.unsqueeze(1)
  5040|         0|            0|            0|  0.00%|        if key_padding_mask is not None:
  5041|         0|            0|            0|  0.00%|            key_padding_mask = key_padding_mask.unsqueeze(0)
  5042|         0|            0|            0|  0.00%|
  5043|         0|            0|            0|  0.00%|    # set up shape vars
  5044|         0|            0|            0|  0.00%|    tgt_len, bsz, embed_dim = query.shape
  5045|         0|            0|            0|  0.00%|    src_len, _, _ = key.shape
  5046|         0|            0|            0|  0.00%|    assert embed_dim == embed_dim_to_check, \
  5047|         0|            0|            0|  0.00%|        f"was expecting embedding dimension of {embed_dim_to_check}, but got {embed_dim}"
  5048|         0|            0|            0|  0.00%|    if isinstance(embed_dim, torch.Tensor):
  5049|         0|            0|            0|  0.00%|        # embed_dim can be a tensor when JIT tracing
  5050|         0|            0|            0|  0.00%|        head_dim = embed_dim.div(num_heads, rounding_mode='trunc')
  5051|         0|            0|            0|  0.00%|    else:
  5052|         0|            0|            0|  0.00%|        head_dim = embed_dim // num_heads
  5053|         0|            0|            0|  0.00%|    assert head_dim * num_heads == embed_dim, f"embed_dim {embed_dim} not divisible by num_heads {num_heads}"
  5054|         0|            0|            0|  0.00%|    if use_separate_proj_weight:
  5055|         0|            0|            0|  0.00%|        # allow MHA to have different embedding dimensions when separate projection weights are used
  5056|         0|            0|            0|  0.00%|        assert key.shape[:2] == value.shape[:2], \
  5057|         0|            0|            0|  0.00%|            f"key's sequence and batch dims {key.shape[:2]} do not match value's {value.shape[:2]}"
  5058|         0|            0|            0|  0.00%|    else:
  5059|         0|            0|            0|  0.00%|        assert key.shape == value.shape, f"key shape {key.shape} does not match value shape {value.shape}"
  5060|         0|            0|            0|  0.00%|
  5061|         0|            0|            0|  0.00%|    #
  5062|         0|            0|            0|  0.00%|    # compute in-projection
  5063|         0|            0|            0|  0.00%|    #
  5064|         0|            0|            0|  0.00%|    if not use_separate_proj_weight:
  5065|         0|            0|            0|  0.00%|        assert in_proj_weight is not None, "use_separate_proj_weight is False but in_proj_weight is None"
  5066|         0|            0|            0|  0.00%|        q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
  5067|         0|            0|            0|  0.00%|    else:
  5068|         0|            0|            0|  0.00%|        assert q_proj_weight is not None, "use_separate_proj_weight is True but q_proj_weight is None"
  5069|         0|            0|            0|  0.00%|        assert k_proj_weight is not None, "use_separate_proj_weight is True but k_proj_weight is None"
  5070|         0|            0|            0|  0.00%|        assert v_proj_weight is not None, "use_separate_proj_weight is True but v_proj_weight is None"
  5071|         0|            0|            0|  0.00%|        if in_proj_bias is None:
  5072|         0|            0|            0|  0.00%|            b_q = b_k = b_v = None
  5073|         0|            0|            0|  0.00%|        else:
  5074|         0|            0|            0|  0.00%|            b_q, b_k, b_v = in_proj_bias.chunk(3)
  5075|         0|            0|            0|  0.00%|        q, k, v = _in_projection(query, key, value, q_proj_weight, k_proj_weight, v_proj_weight, b_q, b_k, b_v)
  5076|         0|            0|            0|  0.00%|
  5077|         0|            0|            0|  0.00%|    # prep attention mask
  5078|         0|            0|            0|  0.00%|    if attn_mask is not None:
  5079|         0|            0|            0|  0.00%|        if attn_mask.dtype == torch.uint8:
  5080|         0|            0|            0|  0.00%|            warnings.warn("Byte tensor for attn_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.")
  5081|         0|            0|            0|  0.00%|            attn_mask = attn_mask.to(torch.bool)
  5082|         0|            0|            0|  0.00%|        else:
  5083|         0|            0|            0|  0.00%|            assert attn_mask.is_floating_point() or attn_mask.dtype == torch.bool, \
  5084|         0|            0|            0|  0.00%|                f"Only float, byte, and bool types are supported for attn_mask, not {attn_mask.dtype}"
  5085|         0|            0|            0|  0.00%|        # ensure attn_mask's dim is 3
  5086|         0|            0|            0|  0.00%|        if attn_mask.dim() == 2:
  5087|         0|            0|            0|  0.00%|            correct_2d_size = (tgt_len, src_len)
  5088|         0|            0|            0|  0.00%|            if attn_mask.shape != correct_2d_size:
  5089|         0|            0|            0|  0.00%|                raise RuntimeError(f"The shape of the 2D attn_mask is {attn_mask.shape}, but should be {correct_2d_size}.")
  5090|         0|            0|            0|  0.00%|            attn_mask = attn_mask.unsqueeze(0)
  5091|         0|            0|            0|  0.00%|        elif attn_mask.dim() == 3:
  5092|         0|            0|            0|  0.00%|            correct_3d_size = (bsz * num_heads, tgt_len, src_len)
  5093|         0|            0|            0|  0.00%|            if attn_mask.shape != correct_3d_size:
  5094|         0|            0|            0|  0.00%|                raise RuntimeError(f"The shape of the 3D attn_mask is {attn_mask.shape}, but should be {correct_3d_size}.")
  5095|         0|            0|            0|  0.00%|        else:
  5096|         0|            0|            0|  0.00%|            raise RuntimeError(f"attn_mask's dimension {attn_mask.dim()} is not supported")
  5097|         0|            0|            0|  0.00%|
  5098|         0|            0|            0|  0.00%|    # prep key padding mask
  5099|         0|            0|            0|  0.00%|    if key_padding_mask is not None and key_padding_mask.dtype == torch.uint8:
  5100|         0|            0|            0|  0.00%|        warnings.warn("Byte tensor for key_padding_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.")
  5101|         0|            0|            0|  0.00%|        key_padding_mask = key_padding_mask.to(torch.bool)
  5102|         0|            0|            0|  0.00%|
  5103|         0|            0|            0|  0.00%|    # add bias along batch dimension (currently second)
  5104|         0|            0|            0|  0.00%|    if bias_k is not None and bias_v is not None:
  5105|         0|            0|            0|  0.00%|        assert static_k is None, "bias cannot be added to static key."
  5106|         0|            0|            0|  0.00%|        assert static_v is None, "bias cannot be added to static value."
  5107|         0|            0|            0|  0.00%|        k = torch.cat([k, bias_k.repeat(1, bsz, 1)])
  5108|         0|            0|            0|  0.00%|        v = torch.cat([v, bias_v.repeat(1, bsz, 1)])
  5109|         0|            0|            0|  0.00%|        if attn_mask is not None:
  5110|         0|            0|            0|  0.00%|            attn_mask = pad(attn_mask, (0, 1))
  5111|         0|            0|            0|  0.00%|        if key_padding_mask is not None:
  5112|         0|            0|            0|  0.00%|            key_padding_mask = pad(key_padding_mask, (0, 1))
  5113|         0|            0|            0|  0.00%|    else:
  5114|         0|            0|            0|  0.00%|        assert bias_k is None
  5115|         0|            0|            0|  0.00%|        assert bias_v is None
  5116|         0|            0|            0|  0.00%|
  5117|         0|            0|            0|  0.00%|    #
  5118|         0|            0|            0|  0.00%|    # reshape q, k, v for multihead attention and make em batch first
  5119|         0|            0|            0|  0.00%|    #
  5120|         0|            0|            0|  0.00%|    q = q.contiguous().view(tgt_len, bsz * num_heads, head_dim).transpose(0, 1)
  5121|         0|            0|            0|  0.00%|    if static_k is None:
  5122|         0|            0|            0|  0.00%|        k = k.contiguous().view(k.shape[0], bsz * num_heads, head_dim).transpose(0, 1)
  5123|         0|            0|            0|  0.00%|    else:
  5124|         0|            0|            0|  0.00%|        # TODO finish disentangling control flow so we don't do in-projections when statics are passed
  5125|         0|            0|            0|  0.00%|        assert static_k.size(0) == bsz * num_heads, \
  5126|         0|            0|            0|  0.00%|            f"expecting static_k.size(0) of {bsz * num_heads}, but got {static_k.size(0)}"
  5127|         0|            0|            0|  0.00%|        assert static_k.size(2) == head_dim, \
  5128|         0|            0|            0|  0.00%|            f"expecting static_k.size(2) of {head_dim}, but got {static_k.size(2)}"
  5129|         0|            0|            0|  0.00%|        k = static_k
  5130|         0|            0|            0|  0.00%|    if static_v is None:
  5131|         0|            0|            0|  0.00%|        v = v.contiguous().view(v.shape[0], bsz * num_heads, head_dim).transpose(0, 1)
  5132|         0|            0|            0|  0.00%|    else:
  5133|         0|            0|            0|  0.00%|        # TODO finish disentangling control flow so we don't do in-projections when statics are passed
  5134|         0|            0|            0|  0.00%|        assert static_v.size(0) == bsz * num_heads, \
  5135|         0|            0|            0|  0.00%|            f"expecting static_v.size(0) of {bsz * num_heads}, but got {static_v.size(0)}"
  5136|         0|            0|            0|  0.00%|        assert static_v.size(2) == head_dim, \
  5137|         0|            0|            0|  0.00%|            f"expecting static_v.size(2) of {head_dim}, but got {static_v.size(2)}"
  5138|         0|            0|            0|  0.00%|        v = static_v
  5139|         0|            0|            0|  0.00%|
  5140|         0|            0|            0|  0.00%|    # add zero attention along batch dimension (now first)
  5141|         0|            0|            0|  0.00%|    if add_zero_attn:
  5142|         0|            0|            0|  0.00%|        zero_attn_shape = (bsz * num_heads, 1, head_dim)
  5143|         0|            0|            0|  0.00%|        k = torch.cat([k, torch.zeros(zero_attn_shape, dtype=k.dtype, device=k.device)], dim=1)
  5144|         0|            0|            0|  0.00%|        v = torch.cat([v, torch.zeros(zero_attn_shape, dtype=v.dtype, device=v.device)], dim=1)
  5145|         0|            0|            0|  0.00%|        if attn_mask is not None:
  5146|         0|            0|            0|  0.00%|            attn_mask = pad(attn_mask, (0, 1))
  5147|         0|            0|            0|  0.00%|        if key_padding_mask is not None:
  5148|         0|            0|            0|  0.00%|            key_padding_mask = pad(key_padding_mask, (0, 1))
  5149|         0|            0|            0|  0.00%|
  5150|         0|            0|            0|  0.00%|    # update source sequence length after adjustments
  5151|         0|            0|            0|  0.00%|    src_len = k.size(1)
  5152|         0|            0|            0|  0.00%|
  5153|         0|            0|            0|  0.00%|    # merge key padding and attention masks
  5154|         0|            0|            0|  0.00%|    if key_padding_mask is not None:
  5155|         0|            0|            0|  0.00%|        assert key_padding_mask.shape == (bsz, src_len), \
  5156|         0|            0|            0|  0.00%|            f"expecting key_padding_mask shape of {(bsz, src_len)}, but got {key_padding_mask.shape}"
  5157|         0|            0|            0|  0.00%|        key_padding_mask = key_padding_mask.view(bsz, 1, 1, src_len).   \
  5158|         0|            0|            0|  0.00%|            expand(-1, num_heads, -1, -1).reshape(bsz * num_heads, 1, src_len)
  5159|         0|            0|            0|  0.00%|        if attn_mask is None:
  5160|         0|            0|            0|  0.00%|            attn_mask = key_padding_mask
  5161|         0|            0|            0|  0.00%|        elif attn_mask.dtype == torch.bool:
  5162|         0|            0|            0|  0.00%|            attn_mask = attn_mask.logical_or(key_padding_mask)
  5163|         0|            0|            0|  0.00%|        else:
  5164|         0|            0|            0|  0.00%|            attn_mask = attn_mask.masked_fill(key_padding_mask, float("-inf"))
  5165|         0|            0|            0|  0.00%|
  5166|         0|            0|            0|  0.00%|    # convert mask to float
  5167|         0|            0|            0|  0.00%|    if attn_mask is not None and attn_mask.dtype == torch.bool:
  5168|         0|            0|            0|  0.00%|        new_attn_mask = torch.zeros_like(attn_mask, dtype=q.dtype)
  5169|         0|            0|            0|  0.00%|        new_attn_mask.masked_fill_(attn_mask, float("-inf"))
  5170|         0|            0|            0|  0.00%|        attn_mask = new_attn_mask
  5171|         0|            0|            0|  0.00%|
  5172|         0|            0|            0|  0.00%|    # adjust dropout probability
  5173|         0|            0|            0|  0.00%|    if not training:
  5174|         0|            0|            0|  0.00%|        dropout_p = 0.0
  5175|         0|            0|            0|  0.00%|
  5176|         0|            0|            0|  0.00%|    #
  5177|         0|            0|            0|  0.00%|    # (deep breath) calculate attention and out projection
  5178|         0|            0|            0|  0.00%|    #
  5179|         0|            0|            0|  0.00%|    attn_output, attn_output_weights = _scaled_dot_product_attention(q, k, v, attn_mask, dropout_p)
  5180|         0|            0|            0|  0.00%|    attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len * bsz, embed_dim)
  5181|         0|            0|            0|  0.00%|    attn_output = linear(attn_output, out_proj_weight, out_proj_bias)
  5182|         0|            0|            0|  0.00%|    attn_output = attn_output.view(tgt_len, bsz, attn_output.size(1))
  5183|         0|            0|            0|  0.00%|
  5184|         0|            0|            0|  0.00%|    if need_weights:
  5185|         0|            0|            0|  0.00%|        # optionally average attention weights over heads
  5186|         0|            0|            0|  0.00%|        attn_output_weights = attn_output_weights.view(bsz, num_heads, tgt_len, src_len)
  5187|         0|            0|            0|  0.00%|        if average_attn_weights:
  5188|         0|            0|            0|  0.00%|            attn_output_weights = attn_output_weights.sum(dim=1) / num_heads
  5189|         0|            0|            0|  0.00%|
  5190|         0|            0|            0|  0.00%|        if not is_batched:
  5191|         0|            0|            0|  0.00%|            # squeeze the output if input was unbatched
  5192|         0|            0|            0|  0.00%|            attn_output = attn_output.squeeze(1)
  5193|         0|            0|            0|  0.00%|            attn_output_weights = attn_output_weights.squeeze(0)
  5194|         0|            0|            0|  0.00%|        return attn_output, attn_output_weights
  5195|         0|            0|            0|  0.00%|    else:
  5196|         0|            0|            0|  0.00%|        if not is_batched:
  5197|         0|            0|            0|  0.00%|            # squeeze the output if input was unbatched
  5198|         0|            0|            0|  0.00%|            attn_output = attn_output.squeeze(1)
  5199|         0|            0|            0|  0.00%|        return attn_output, None
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/nn/parameter.py
File duration: 0.0396039s (0.04%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import torch
     2|         0|            0|            0|  0.00%|from torch._C import _disabled_torch_function_impl
     3|         0|            0|            0|  0.00%|from collections import OrderedDict
     4|         0|            0|            0|  0.00%|
     5|         0|            0|            0|  0.00%|
     6|         0|            0|            0|  0.00%|# Metaclass to combine _TensorMeta and the instance check override for Parameter.
     7|         0|            0|            0|  0.00%|class _ParameterMeta(torch._C._TensorMeta):
     8|         0|            0|            0|  0.00%|    # Make `isinstance(t, Parameter)` return True for custom tensor instances that have the _is_param flag.
     9|      4662|   0.00816607|  1.75162e-06|  0.01%|    def __instancecheck__(self, instance):
    10|      9324|    0.0212159|  2.27541e-06|  0.02%|        return super().__instancecheck__(instance) or (
    11|      4662|     0.010222|  2.19261e-06|  0.01%|            isinstance(instance, torch.Tensor) and getattr(instance, '_is_param', False))
    12|         0|            0|            0|  0.00%|
    13|         0|            0|            0|  0.00%|
    14|         0|            0|            0|  0.00%|class Parameter(torch.Tensor, metaclass=_ParameterMeta):
    15|         0|            0|            0|  0.00%|    r"""A kind of Tensor that is to be considered a module parameter.
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|    Parameters are :class:`~torch.Tensor` subclasses, that have a
    18|         0|            0|            0|  0.00%|    very special property when used with :class:`Module` s - when they're
    19|         0|            0|            0|  0.00%|    assigned as Module attributes they are automatically added to the list of
    20|         0|            0|            0|  0.00%|    its parameters, and will appear e.g. in :meth:`~Module.parameters` iterator.
    21|         0|            0|            0|  0.00%|    Assigning a Tensor doesn't have such effect. This is because one might
    22|         0|            0|            0|  0.00%|    want to cache some temporary state, like last hidden state of the RNN, in
    23|         0|            0|            0|  0.00%|    the model. If there was no such class as :class:`Parameter`, these
    24|         0|            0|            0|  0.00%|    temporaries would get registered too.
    25|         0|            0|            0|  0.00%|
    26|         0|            0|            0|  0.00%|    Args:
    27|         0|            0|            0|  0.00%|        data (Tensor): parameter tensor.
    28|         0|            0|            0|  0.00%|        requires_grad (bool, optional): if the parameter requires gradient. See
    29|         0|            0|            0|  0.00%|            :ref:`locally-disable-grad-doc` for more details. Default: `True`
    30|         0|            0|            0|  0.00%|    """
    31|         0|            0|            0|  0.00%|    def __new__(cls, data=None, requires_grad=True):
    32|         0|            0|            0|  0.00%|        if data is None:
    33|         0|            0|            0|  0.00%|            data = torch.empty(0)
    34|         0|            0|            0|  0.00%|        if type(data) is torch.Tensor or type(data) is Parameter:
    35|         0|            0|            0|  0.00%|            # For ease of BC maintenance, keep this path for standard Tensor.
    36|         0|            0|            0|  0.00%|            # Eventually (tm), we should change the behavior for standard Tensor to match.
    37|         0|            0|            0|  0.00%|            return torch.Tensor._make_subclass(cls, data, requires_grad)
    38|         0|            0|            0|  0.00%|
    39|         0|            0|            0|  0.00%|        # Path for custom tensors: set a flag on the instance to indicate parameter-ness.
    40|         0|            0|            0|  0.00%|        t = data.detach().requires_grad_(requires_grad)
    41|         0|            0|            0|  0.00%|        if type(t) is not type(data):
    42|         0|            0|            0|  0.00%|            raise RuntimeError(f"Creating a Parameter from an instance of type {type(data).__name__} "
    43|         0|            0|            0|  0.00%|                               "requires that detach() returns an instance of the same type, but return "
    44|         0|            0|            0|  0.00%|                               f"type {type(t).__name__} was found instead. To use the type as a "
    45|         0|            0|            0|  0.00%|                               "Parameter, please correct the detach() semantics defined by "
    46|         0|            0|            0|  0.00%|                               "its __torch_dispatch__() implementation.")
    47|         0|            0|            0|  0.00%|        t._is_param = True
    48|         0|            0|            0|  0.00%|        return t
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|    # Note: the 3 methods below only apply to standard Tensor. Parameters of custom tensor types
    51|         0|            0|            0|  0.00%|    # are still considered that custom tensor type and these methods will not be called for them.
    52|         0|            0|            0|  0.00%|    def __deepcopy__(self, memo):
    53|         0|            0|            0|  0.00%|        if id(self) in memo:
    54|         0|            0|            0|  0.00%|            return memo[id(self)]
    55|         0|            0|            0|  0.00%|        else:
    56|         0|            0|            0|  0.00%|            result = type(self)(self.data.clone(memory_format=torch.preserve_format), self.requires_grad)
    57|         0|            0|            0|  0.00%|            memo[id(self)] = result
    58|         0|            0|            0|  0.00%|            return result
    59|         0|            0|            0|  0.00%|
    60|         0|            0|            0|  0.00%|    def __repr__(self):
    61|         0|            0|            0|  0.00%|        return 'Parameter containing:\n' + super(Parameter, self).__repr__()
    62|         0|            0|            0|  0.00%|
    63|         0|            0|            0|  0.00%|    def __reduce_ex__(self, proto):
    64|         0|            0|            0|  0.00%|        # See Note [Don't serialize hooks]
    65|         0|            0|            0|  0.00%|        return (
    66|         0|            0|            0|  0.00%|            torch._utils._rebuild_parameter,
    67|         0|            0|            0|  0.00%|            (self.data, self.requires_grad, OrderedDict())
    68|         0|            0|            0|  0.00%|        )
    69|         0|            0|            0|  0.00%|
    70|         0|            0|            0|  0.00%|    __torch_function__ = _disabled_torch_function_impl
    71|         0|            0|            0|  0.00%|
    72|         0|            0|            0|  0.00%|
    73|         0|            0|            0|  0.00%|class UninitializedTensorMixin:
    74|         0|            0|            0|  0.00%|    _allowed_methods = [
    75|         0|            0|            0|  0.00%|        torch.Tensor.__hash__,
    76|         0|            0|            0|  0.00%|        torch.Tensor.size,
    77|         0|            0|            0|  0.00%|        torch.Tensor.copy_,
    78|         0|            0|            0|  0.00%|        torch.Tensor.is_floating_point,
    79|         0|            0|            0|  0.00%|        torch.Tensor.half,
    80|         0|            0|            0|  0.00%|        torch.Tensor.float,
    81|         0|            0|            0|  0.00%|        torch.Tensor.double,
    82|         0|            0|            0|  0.00%|        torch.Tensor.char,
    83|         0|            0|            0|  0.00%|        torch.Tensor.short,
    84|         0|            0|            0|  0.00%|        torch.Tensor.int,
    85|         0|            0|            0|  0.00%|        torch.Tensor.long,
    86|         0|            0|            0|  0.00%|        torch.Tensor.cuda,
    87|         0|            0|            0|  0.00%|        torch.Tensor.cpu,
    88|         0|            0|            0|  0.00%|        torch.Tensor.to,
    89|         0|            0|            0|  0.00%|        torch.Tensor.get_device,
    90|         0|            0|            0|  0.00%|        torch._has_compatible_shallow_copy_type,
    91|         0|            0|            0|  0.00%|    ]
    92|         0|            0|            0|  0.00%|
    93|         0|            0|            0|  0.00%|    def materialize(self, shape, device=None, dtype=None):
    94|         0|            0|            0|  0.00%|        r"""Create a Parameter or Tensor with the same properties of the uninitialized one.
    95|         0|            0|            0|  0.00%|        Given a shape, it materializes a parameter in the same device
    96|         0|            0|            0|  0.00%|        and with the same `dtype` as the current one or the specified ones in the
    97|         0|            0|            0|  0.00%|        arguments.
    98|         0|            0|            0|  0.00%|
    99|         0|            0|            0|  0.00%|        Args:
   100|         0|            0|            0|  0.00%|            shape : (tuple): the shape for the materialized tensor.
   101|         0|            0|            0|  0.00%|            device (:class:`torch.device`): the desired device of the parameters
   102|         0|            0|            0|  0.00%|                and buffers in this module. Optional.
   103|         0|            0|            0|  0.00%|            dtype (:class:`torch.dtype`): the desired floating point type of
   104|         0|            0|            0|  0.00%|                the floating point parameters and buffers in this module. Optional.
   105|         0|            0|            0|  0.00%|        """
   106|         0|            0|            0|  0.00%|        if device is None:
   107|         0|            0|            0|  0.00%|            device = self.data.device
   108|         0|            0|            0|  0.00%|        if dtype is None:
   109|         0|            0|            0|  0.00%|            dtype = self.data.dtype
   110|         0|            0|            0|  0.00%|        self.data = torch.empty(shape, device=device, dtype=dtype)
   111|         0|            0|            0|  0.00%|        self.__class__ = self.cls_to_become
   112|         0|            0|            0|  0.00%|
   113|         0|            0|            0|  0.00%|    @property
   114|         0|            0|            0|  0.00%|    def shape(self):
   115|         0|            0|            0|  0.00%|        raise RuntimeError(
   116|         0|            0|            0|  0.00%|            'Can\'t access the shape of an uninitialized parameter or buffer. '
   117|         0|            0|            0|  0.00%|            'This error usually happens in `load_state_dict` when trying to load '
   118|         0|            0|            0|  0.00%|            'an uninitialized parameter into an initialized one. '
   119|         0|            0|            0|  0.00%|            'Call `forward` to initialize the parameters before accessing their attributes.')
   120|         0|            0|            0|  0.00%|
   121|         0|            0|            0|  0.00%|    def share_memory_(self):
   122|         0|            0|            0|  0.00%|        raise RuntimeError(
   123|         0|            0|            0|  0.00%|            'Can\'t share memory on an uninitialized parameter or buffer. '
   124|         0|            0|            0|  0.00%|            'Call `forward` to initialize the parameters before calling '
   125|         0|            0|            0|  0.00%|            '`module.share_memory()`.')
   126|         0|            0|            0|  0.00%|
   127|         0|            0|            0|  0.00%|    def __repr__(self):
   128|         0|            0|            0|  0.00%|        return f'<{self.__class__.__name__}>'
   129|         0|            0|            0|  0.00%|
   130|         0|            0|            0|  0.00%|    def __reduce_ex__(self, proto):
   131|         0|            0|            0|  0.00%|        # See Note [Don't serialize hooks]
   132|         0|            0|            0|  0.00%|        return (
   133|         0|            0|            0|  0.00%|            self.__class__,
   134|         0|            0|            0|  0.00%|            (self.requires_grad,)
   135|         0|            0|            0|  0.00%|        )
   136|         0|            0|            0|  0.00%|
   137|         0|            0|            0|  0.00%|    @classmethod
   138|         0|            0|            0|  0.00%|    def __torch_function__(cls, func, types, args=(), kwargs=None):
   139|         0|            0|            0|  0.00%|        # method-wrapper is to detect access to Tensor properties that are
   140|         0|            0|            0|  0.00%|        # wrapped in descriptors
   141|         0|            0|            0|  0.00%|        if func in cls._allowed_methods or func.__class__.__name__ == 'method-wrapper':
   142|         0|            0|            0|  0.00%|            if kwargs is None:
   143|         0|            0|            0|  0.00%|                kwargs = {}
   144|         0|            0|            0|  0.00%|            return super().__torch_function__(func, types, args, kwargs)
   145|         0|            0|            0|  0.00%|        raise ValueError(
   146|         0|            0|            0|  0.00%|            'Attempted to use an uninitialized parameter in {}. '
   147|         0|            0|            0|  0.00%|            'This error happens when you are using a `LazyModule` or '
   148|         0|            0|            0|  0.00%|            'explicitly manipulating `torch.nn.parameter.{}` '
   149|         0|            0|            0|  0.00%|            'objects. When using LazyModules Call `forward` with a dummy batch '
   150|         0|            0|            0|  0.00%|            'to initialize the parameters before calling torch functions'.format(func, cls.__name__))
   151|         0|            0|            0|  0.00%|
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|def is_lazy(param):
   154|         0|            0|            0|  0.00%|    return isinstance(param, UninitializedTensorMixin)
   155|         0|            0|            0|  0.00%|
   156|         0|            0|            0|  0.00%|
   157|         0|            0|            0|  0.00%|class UninitializedParameter(UninitializedTensorMixin, Parameter):
   158|         0|            0|            0|  0.00%|    r"""A parameter that is not initialized.
   159|         0|            0|            0|  0.00%|
   160|         0|            0|            0|  0.00%|    Unitialized Parameters are a a special case of :class:`torch.nn.Parameter`
   161|         0|            0|            0|  0.00%|    where the shape of the data is still unknown.
   162|         0|            0|            0|  0.00%|
   163|         0|            0|            0|  0.00%|    Unlike a :class:`torch.nn.Parameter`, uninitialized parameters
   164|         0|            0|            0|  0.00%|    hold no data and attempting to access some properties, like their shape,
   165|         0|            0|            0|  0.00%|    will throw a runtime error. The only operations that can be performed on a uninitialized
   166|         0|            0|            0|  0.00%|    parameter are changing its datatype, moving it to a different device and
   167|         0|            0|            0|  0.00%|    converting it to a regular :class:`torch.nn.Parameter`.
   168|         0|            0|            0|  0.00%|
   169|         0|            0|            0|  0.00%|    The default device or dtype to use when the parameter is materialized can be set
   170|         0|            0|            0|  0.00%|    during construction using e.g. ``device='cuda'``.
   171|         0|            0|            0|  0.00%|    """
   172|         0|            0|            0|  0.00%|
   173|         0|            0|            0|  0.00%|    cls_to_become = Parameter
   174|         0|            0|            0|  0.00%|
   175|         0|            0|            0|  0.00%|    def __new__(cls, requires_grad=True, device=None, dtype=None) -> None:
   176|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}
   177|         0|            0|            0|  0.00%|        data = torch.empty(0, **factory_kwargs)
   178|         0|            0|            0|  0.00%|        return torch.Tensor._make_subclass(cls, data, requires_grad)
   179|         0|            0|            0|  0.00%|
   180|         0|            0|            0|  0.00%|
   181|         0|            0|            0|  0.00%|class UninitializedBuffer(UninitializedTensorMixin, torch.Tensor):
   182|         0|            0|            0|  0.00%|    r"""A buffer that is not initialized.
   183|         0|            0|            0|  0.00%|
   184|         0|            0|            0|  0.00%|    Unitialized Buffer is a a special case of :class:`torch.Tensor`
   185|         0|            0|            0|  0.00%|    where the shape of the data is still unknown.
   186|         0|            0|            0|  0.00%|
   187|         0|            0|            0|  0.00%|    Unlike a :class:`torch.Tensor`, uninitialized parameters
   188|         0|            0|            0|  0.00%|    hold no data and attempting to access some properties, like their shape,
   189|         0|            0|            0|  0.00%|    will throw a runtime error. The only operations that can be performed on a uninitialized
   190|         0|            0|            0|  0.00%|    parameter are changing its datatype, moving it to a different device and
   191|         0|            0|            0|  0.00%|    converting it to a regular :class:`torch.Tensor`.
   192|         0|            0|            0|  0.00%|
   193|         0|            0|            0|  0.00%|    The default device or dtype to use when the buffer is materialized can be set
   194|         0|            0|            0|  0.00%|    during construction using e.g. ``device='cuda'``.
   195|         0|            0|            0|  0.00%|    """
   196|         0|            0|            0|  0.00%|
   197|         0|            0|            0|  0.00%|    cls_to_become = torch.Tensor
   198|         0|            0|            0|  0.00%|
   199|         0|            0|            0|  0.00%|    def __new__(cls, requires_grad=False, device=None, dtype=None) -> None:
   200|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}
   201|         0|            0|            0|  0.00%|        data = torch.empty(0, **factory_kwargs)
   202|         0|            0|            0|  0.00%|        return torch.Tensor._make_subclass(cls, data, requires_grad)
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_VF.py
File duration: 0.0272388s (0.03%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|"""
     2|         0|            0|            0|  0.00%|This makes the functions in torch._C._VariableFunctions available as
     3|         0|            0|            0|  0.00%|    torch._VF.<funcname>
     4|         0|            0|            0|  0.00%|without mypy being able to find them.
     5|         0|            0|            0|  0.00%|
     6|         0|            0|            0|  0.00%|A subset of those functions are mapped to ATen functions in
     7|         0|            0|            0|  0.00%|torch/jit/_builtins.py
     8|         0|            0|            0|  0.00%|
     9|         0|            0|            0|  0.00%|See https://github.com/pytorch/pytorch/issues/21478 for the reason for
    10|         0|            0|            0|  0.00%|introducing torch._VF
    11|         0|            0|            0|  0.00%|
    12|         0|            0|            0|  0.00%|"""
    13|         0|            0|            0|  0.00%|import torch
    14|         0|            0|            0|  0.00%|import sys
    15|         0|            0|            0|  0.00%|import types
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|
    18|         0|            0|            0|  0.00%|class VFModule(types.ModuleType):
    19|         0|            0|            0|  0.00%|    vf: types.ModuleType
    20|         0|            0|            0|  0.00%|
    21|         0|            0|            0|  0.00%|    def __init__(self, name):
    22|         0|            0|            0|  0.00%|        super(VFModule, self).__init__(name)
    23|         0|            0|            0|  0.00%|        self.vf = torch._C._VariableFunctions
    24|         0|            0|            0|  0.00%|
    25|      6354|    0.0114586|  1.80337e-06|  0.01%|    def __getattr__(self, attr):
    26|      6354|    0.0157802|  2.48351e-06|  0.02%|        return getattr(self.vf, attr)
    27|         0|            0|            0|  0.00%|
    28|         0|            0|            0|  0.00%|
    29|         0|            0|            0|  0.00%|sys.modules[__name__] = VFModule(__name__)
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/autograd/profiler.py
File duration: 0.0257237s (0.02%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|from torch.autograd.profiler_util import (
     2|         0|            0|            0|  0.00%|    EventList, FunctionEvent, MemRecordsAcc, MEMORY_EVENT_NAME,
     3|         0|            0|            0|  0.00%|    _filter_name, _filter_stack_entry, _rewrite_name
     4|         0|            0|            0|  0.00%|)
     5|         0|            0|            0|  0.00%|
     6|         0|            0|            0|  0.00%|from torch.autograd import (
     7|         0|            0|            0|  0.00%|    DeviceType, ProfilerActivity, ProfilerConfig, ProfilerState,
     8|         0|            0|            0|  0.00%|    kineto_available, _ProfilerResult, _disable_profiler, _enable_profiler,
     9|         0|            0|            0|  0.00%|    _prepare_profiler, _supported_activities, _kineto_step,
    10|         0|            0|            0|  0.00%|)
    11|         0|            0|            0|  0.00%|from torch._C._autograd import _ExperimentalConfig
    12|         0|            0|            0|  0.00%|import torch
    13|         0|            0|            0|  0.00%|import torch.cuda
    14|         0|            0|            0|  0.00%|from torch.futures import Future
    15|         0|            0|            0|  0.00%|from typing import Any, Dict, List, Optional
    16|         0|            0|            0|  0.00%|from warnings import warn
    17|         0|            0|            0|  0.00%|
    18|         0|            0|            0|  0.00%|
    19|         0|            0|            0|  0.00%|try:
    20|         0|            0|            0|  0.00%|    # Available in Python >= 3.2
    21|         0|            0|            0|  0.00%|    from contextlib import ContextDecorator
    22|         0|            0|            0|  0.00%|except ImportError:
    23|         0|            0|            0|  0.00%|    import functools
    24|         0|            0|            0|  0.00%|
    25|         0|            0|            0|  0.00%|    class ContextDecorator(object):  # type: ignore[no-redef]
    26|         0|            0|            0|  0.00%|
    27|         0|            0|            0|  0.00%|        def __enter__(self):
    28|         0|            0|            0|  0.00%|            raise NotImplementedError
    29|         0|            0|            0|  0.00%|
    30|         0|            0|            0|  0.00%|        def __exit__(self, exc_type, exc_val, exc_tb):
    31|         0|            0|            0|  0.00%|            raise NotImplementedError
    32|         0|            0|            0|  0.00%|
    33|         0|            0|            0|  0.00%|        def __call__(self, func):
    34|         0|            0|            0|  0.00%|            @functools.wraps(func)
    35|         0|            0|            0|  0.00%|            def wrapped(*args, **kwargs):
    36|         0|            0|            0|  0.00%|                with self:
    37|         0|            0|            0|  0.00%|                    return func(*args, **kwargs)
    38|         0|            0|            0|  0.00%|
    39|         0|            0|            0|  0.00%|            return wrapped
    40|         0|            0|            0|  0.00%|
    41|         0|            0|            0|  0.00%|
    42|         0|            0|            0|  0.00%|class profile(object):
    43|         0|            0|            0|  0.00%|    """Context manager that manages autograd profiler state and holds a summary of results.
    44|         0|            0|            0|  0.00%|    Under the hood it just records events of functions being executed in C++ and
    45|         0|            0|            0|  0.00%|    exposes those events to Python. You can wrap any code into it and it will
    46|         0|            0|            0|  0.00%|    only report runtime of PyTorch functions.
    47|         0|            0|            0|  0.00%|    Note: profiler is thread local and is automatically propagated into the async tasks
    48|         0|            0|            0|  0.00%|
    49|         0|            0|            0|  0.00%|    Args:
    50|         0|            0|            0|  0.00%|        enabled (bool, optional): Setting this to False makes this context manager a no-op.
    51|         0|            0|            0|  0.00%|
    52|         0|            0|            0|  0.00%|        use_cuda (bool, optional): Enables timing of CUDA events as well using the cudaEvent API.
    53|         0|            0|            0|  0.00%|            Adds approximately 4us of overhead to each tensor operation.
    54|         0|            0|            0|  0.00%|
    55|         0|            0|            0|  0.00%|        record_shapes (bool, optional): If shapes recording is set, information
    56|         0|            0|            0|  0.00%|            about input dimensions will be collected. This allows one to see which
    57|         0|            0|            0|  0.00%|            dimensions have been used under the hood and further group by them
    58|         0|            0|            0|  0.00%|            using prof.key_averages(group_by_input_shape=True). Please note that
    59|         0|            0|            0|  0.00%|            shape recording might skew your profiling data. It is recommended to
    60|         0|            0|            0|  0.00%|            use separate runs with and without shape recording to validate the timing.
    61|         0|            0|            0|  0.00%|            Most likely the skew will be negligible for bottom most events (in a case
    62|         0|            0|            0|  0.00%|            of nested function calls). But for higher level functions the total
    63|         0|            0|            0|  0.00%|            self cpu time might be artificially increased because of the shape
    64|         0|            0|            0|  0.00%|            collection.
    65|         0|            0|            0|  0.00%|
    66|         0|            0|            0|  0.00%|        with_flops (bool, optional): If with_flops is set, the profiler will estimate
    67|         0|            0|            0|  0.00%|            the FLOPs (floating point operations) value using the operator's input shape.
    68|         0|            0|            0|  0.00%|            This allows one to estimate the hardware performance. Currently,
    69|         0|            0|            0|  0.00%|            this option only works for the matrix multiplication and 2D convolution operators.
    70|         0|            0|            0|  0.00%|
    71|         0|            0|            0|  0.00%|        profile_memory (bool, optional): track tensor memory allocation/deallocation.
    72|         0|            0|            0|  0.00%|
    73|         0|            0|            0|  0.00%|        with_stack (bool, optional): record source information (file and line number) for the ops.
    74|         0|            0|            0|  0.00%|
    75|         0|            0|            0|  0.00%|        with_modules (bool): record module hierarchy (including function names)
    76|         0|            0|            0|  0.00%|            corresponding to the callstack of the op. e.g. If module A's forward call's
    77|         0|            0|            0|  0.00%|            module B's forward which contains an aten::add op,
    78|         0|            0|            0|  0.00%|            then aten::add's module hierarchy is A.B
    79|         0|            0|            0|  0.00%|            Note that this support exist, at the moment, only for TorchScript models
    80|         0|            0|            0|  0.00%|            and not eager mode models.
    81|         0|            0|            0|  0.00%|
    82|         0|            0|            0|  0.00%|        use_kineto (bool, optional): experimental, enable profiling with Kineto profiler.
    83|         0|            0|            0|  0.00%|
    84|         0|            0|            0|  0.00%|        use_cpu (bool, optional): profile CPU events; setting to ``False`` requires
    85|         0|            0|            0|  0.00%|            ``use_kineto=True`` and can be used to lower the overhead for GPU-only profiling.
    86|         0|            0|            0|  0.00%|
    87|         0|            0|            0|  0.00%|        experimental_config (_ExperimentalConfig) : A set of experimental options
    88|         0|            0|            0|  0.00%|            used by profiler libraries like Kineto. Note, backward compatibility is not guaranteed.
    89|         0|            0|            0|  0.00%|
    90|         0|            0|            0|  0.00%|
    91|         0|            0|            0|  0.00%|    .. warning:
    92|         0|            0|            0|  0.00%|        Enabling memory profiling or source attribution incurs additional profiler
    93|         0|            0|            0|  0.00%|        overhead
    94|         0|            0|            0|  0.00%|
    95|         0|            0|            0|  0.00%|    .. warning:
    96|         0|            0|            0|  0.00%|        This context managers should not be called recursively, i.e. no nested
    97|         0|            0|            0|  0.00%|        instances are allowed
    98|         0|            0|            0|  0.00%|
    99|         0|            0|            0|  0.00%|    .. warning:
   100|         0|            0|            0|  0.00%|        Due to some CUDA multiprocessing limitations (multiprocessing-cuda-note_),
   101|         0|            0|            0|  0.00%|        one cannot use the profiler with ``use_cuda = True`` to benchmark
   102|         0|            0|            0|  0.00%|        DataLoaders with ``num_workers > 0``. If you wish to benchmark data loading,
   103|         0|            0|            0|  0.00%|        please use ``use_cuda = False`` or ``num_workers = 0``.
   104|         0|            0|            0|  0.00%|
   105|         0|            0|            0|  0.00%|    Example:
   106|         0|            0|            0|  0.00%|        >>> x = torch.randn((1, 1), requires_grad=True)
   107|         0|            0|            0|  0.00%|        >>> with torch.autograd.profiler.profile() as prof:
   108|         0|            0|            0|  0.00%|        >>>     for _ in range(100):  # any normal python code, really!
   109|         0|            0|            0|  0.00%|        >>>         y = x ** 2
   110|         0|            0|            0|  0.00%|        >>          y.backward()
   111|         0|            0|            0|  0.00%|        >>> # NOTE: some columns were removed for brevity
   112|         0|            0|            0|  0.00%|        >>> print(prof.key_averages().table(sort_by="self_cpu_time_total"))
   113|         0|            0|            0|  0.00%|        -----------------------------------  ---------------  ---------------  ---------------
   114|         0|            0|            0|  0.00%|        Name                                 Self CPU total   CPU time avg     Number of Calls
   115|         0|            0|            0|  0.00%|        -----------------------------------  ---------------  ---------------  ---------------
   116|         0|            0|            0|  0.00%|        mul                                  32.048ms         32.048ms         200
   117|         0|            0|            0|  0.00%|        pow                                  27.041ms         27.041ms         200
   118|         0|            0|            0|  0.00%|        PowBackward0                         9.727ms          55.483ms         100
   119|         0|            0|            0|  0.00%|        torch::autograd::AccumulateGrad      9.148ms          9.148ms          100
   120|         0|            0|            0|  0.00%|        torch::autograd::GraphRoot           691.816us        691.816us        100
   121|         0|            0|            0|  0.00%|        -----------------------------------  ---------------  ---------------  ---------------
   122|         0|            0|            0|  0.00%|
   123|         0|            0|            0|  0.00%|    """
   124|         0|            0|            0|  0.00%|    def __init__(
   125|         0|            0|            0|  0.00%|            self,
   126|         0|            0|            0|  0.00%|            enabled=True,
   127|         0|            0|            0|  0.00%|            *,
   128|         0|            0|            0|  0.00%|            use_cuda=False,
   129|         0|            0|            0|  0.00%|            record_shapes=False,
   130|         0|            0|            0|  0.00%|            with_flops=False,
   131|         0|            0|            0|  0.00%|            profile_memory=False,
   132|         0|            0|            0|  0.00%|            with_stack=False,
   133|         0|            0|            0|  0.00%|            with_modules=False,
   134|         0|            0|            0|  0.00%|            use_kineto=False,
   135|         0|            0|            0|  0.00%|            use_cpu=True,
   136|         0|            0|            0|  0.00%|            experimental_config=None):
   137|         0|            0|            0|  0.00%|        self.enabled: bool = enabled
   138|         0|            0|            0|  0.00%|        if not self.enabled:
   139|         0|            0|            0|  0.00%|            return
   140|         0|            0|            0|  0.00%|        self.use_cuda = use_cuda
   141|         0|            0|            0|  0.00%|        self.function_events: Optional[EventList] = None
   142|         0|            0|            0|  0.00%|        self.entered = False
   143|         0|            0|            0|  0.00%|        self.record_shapes = record_shapes
   144|         0|            0|            0|  0.00%|        self.with_flops = with_flops
   145|         0|            0|            0|  0.00%|        self.record_shapes |= self.with_flops
   146|         0|            0|            0|  0.00%|        self.profile_memory = profile_memory
   147|         0|            0|            0|  0.00%|        self.with_stack = with_stack
   148|         0|            0|            0|  0.00%|        self.with_modules = with_modules
   149|         0|            0|            0|  0.00%|        self.use_cpu = use_cpu
   150|         0|            0|            0|  0.00%|        if experimental_config is None:
   151|         0|            0|            0|  0.00%|            experimental_config = _ExperimentalConfig()
   152|         0|            0|            0|  0.00%|        self.experimental_config = experimental_config
   153|         0|            0|            0|  0.00%|        self.kineto_results: Optional[_ProfilerResult] = None
   154|         0|            0|            0|  0.00%|
   155|         0|            0|            0|  0.00%|        if not self.use_cpu:
   156|         0|            0|            0|  0.00%|            assert use_kineto, \
   157|         0|            0|            0|  0.00%|                "Device-only events supported only with Kineto (use_kineto=True)"
   158|         0|            0|            0|  0.00%|
   159|         0|            0|            0|  0.00%|        if self.use_cuda and not torch.cuda.is_available():
   160|         0|            0|            0|  0.00%|            warn("CUDA is not available, disabling CUDA profiling")
   161|         0|            0|            0|  0.00%|            self.use_cuda = False
   162|         0|            0|            0|  0.00%|
   163|         0|            0|            0|  0.00%|        self.kineto_activities = set()
   164|         0|            0|            0|  0.00%|        if self.use_cpu:
   165|         0|            0|            0|  0.00%|            self.kineto_activities.add(ProfilerActivity.CPU)
   166|         0|            0|            0|  0.00%|
   167|         0|            0|            0|  0.00%|        self.profiler_kind = ProfilerState.KINETO
   168|         0|            0|            0|  0.00%|        if self.use_cuda:
   169|         0|            0|            0|  0.00%|            if (not use_kineto or ProfilerActivity.CUDA not in
   170|         0|            0|            0|  0.00%|                    _supported_activities()):
   171|         0|            0|            0|  0.00%|                assert self.use_cpu, "Legacy CUDA profiling requires use_cpu=True"
   172|         0|            0|            0|  0.00%|                self.profiler_kind = ProfilerState.KINETO_GPU_FALLBACK
   173|         0|            0|            0|  0.00%|            else:
   174|         0|            0|            0|  0.00%|                self.kineto_activities.add(ProfilerActivity.CUDA)
   175|         0|            0|            0|  0.00%|
   176|         0|            0|            0|  0.00%|        assert len(self.kineto_activities) > 0, \
   177|         0|            0|            0|  0.00%|            "No activities specified for the profiler"
   178|         0|            0|            0|  0.00%|
   179|         0|            0|            0|  0.00%|
   180|         0|            0|            0|  0.00%|    def config(self):
   181|         0|            0|            0|  0.00%|        return ProfilerConfig(
   182|         0|            0|            0|  0.00%|            self.profiler_kind,
   183|         0|            0|            0|  0.00%|            self.record_shapes,
   184|         0|            0|            0|  0.00%|            self.profile_memory,
   185|         0|            0|            0|  0.00%|            self.with_stack,
   186|         0|            0|            0|  0.00%|            self.with_flops,
   187|         0|            0|            0|  0.00%|            self.with_modules,
   188|         0|            0|            0|  0.00%|            self.experimental_config)
   189|         0|            0|            0|  0.00%|
   190|         0|            0|            0|  0.00%|    def __enter__(self):
   191|         0|            0|            0|  0.00%|        if not self.enabled:
   192|         0|            0|            0|  0.00%|            return
   193|         0|            0|            0|  0.00%|        if self.entered:
   194|         0|            0|            0|  0.00%|            raise RuntimeError("Profiler context manager is not reentrant")
   195|         0|            0|            0|  0.00%|        self._prepare_trace()
   196|         0|            0|            0|  0.00%|        self._start_trace()
   197|         0|            0|            0|  0.00%|        return self
   198|         0|            0|            0|  0.00%|
   199|         0|            0|            0|  0.00%|    def _prepare_trace(self):
   200|         0|            0|            0|  0.00%|        self.entered = True
   201|         0|            0|            0|  0.00%|        _prepare_profiler(self.config(), self.kineto_activities)
   202|         0|            0|            0|  0.00%|
   203|         0|            0|            0|  0.00%|    def _start_trace(self):
   204|         0|            0|            0|  0.00%|        self.entered = True
   205|         0|            0|            0|  0.00%|        _enable_profiler(self.config(), self.kineto_activities)
   206|         0|            0|            0|  0.00%|
   207|         0|            0|            0|  0.00%|    def __exit__(self, exc_type, exc_val, exc_tb):
   208|         0|            0|            0|  0.00%|        if not self.enabled:
   209|         0|            0|            0|  0.00%|            return
   210|         0|            0|            0|  0.00%|        if self.use_cuda:
   211|         0|            0|            0|  0.00%|            torch.cuda.synchronize()
   212|         0|            0|            0|  0.00%|        self.kineto_results = _disable_profiler()
   213|         0|            0|            0|  0.00%|        parsed_results = self._parse_kineto_results(self.kineto_results)
   214|         0|            0|            0|  0.00%|        self.function_events = EventList(
   215|         0|            0|            0|  0.00%|            parsed_results,
   216|         0|            0|            0|  0.00%|            use_cuda=self.use_cuda,
   217|         0|            0|            0|  0.00%|            profile_memory=self.profile_memory,
   218|         0|            0|            0|  0.00%|            with_flops=self.with_flops)
   219|         0|            0|            0|  0.00%|        self.function_events._build_tree()
   220|         0|            0|            0|  0.00%|        return False
   221|         0|            0|            0|  0.00%|
   222|         0|            0|            0|  0.00%|    def __repr__(self):
   223|         0|            0|            0|  0.00%|        if self.function_events is None:
   224|         0|            0|            0|  0.00%|            return '<unfinished torch.autograd.profile>'
   225|         0|            0|            0|  0.00%|        return repr(self.function_events)
   226|         0|            0|            0|  0.00%|
   227|         0|            0|            0|  0.00%|    def __str__(self):
   228|         0|            0|            0|  0.00%|        if self.function_events is None:
   229|         0|            0|            0|  0.00%|            return '<unfinished torch.autograd.profile>'
   230|         0|            0|            0|  0.00%|        return str(self.function_events)
   231|         0|            0|            0|  0.00%|
   232|         0|            0|            0|  0.00%|    def _check_finish(self):
   233|         0|            0|            0|  0.00%|        if self.function_events is None:
   234|         0|            0|            0|  0.00%|            raise RuntimeError("Profiler didn't finish running")
   235|         0|            0|            0|  0.00%|
   236|         0|            0|            0|  0.00%|    def table(self, sort_by=None, row_limit=100, max_src_column_width=75, header=None, top_level_events_only=False):
   237|         0|            0|            0|  0.00%|        self._check_finish()
   238|         0|            0|            0|  0.00%|        assert self.function_events is not None
   239|         0|            0|            0|  0.00%|        return self.function_events.table(
   240|         0|            0|            0|  0.00%|            sort_by=sort_by, row_limit=row_limit, max_src_column_width=max_src_column_width, header=header,
   241|         0|            0|            0|  0.00%|            top_level_events_only=top_level_events_only
   242|         0|            0|            0|  0.00%|        )
   243|         0|            0|            0|  0.00%|    table.__doc__ = EventList.table.__doc__
   244|         0|            0|            0|  0.00%|
   245|         0|            0|            0|  0.00%|    def export_chrome_trace(self, path):
   246|         0|            0|            0|  0.00%|        self._check_finish()
   247|         0|            0|            0|  0.00%|        if kineto_available():
   248|         0|            0|            0|  0.00%|            self.kineto_results.save(path)  # type: ignore[union-attr]
   249|         0|            0|            0|  0.00%|        else:
   250|         0|            0|            0|  0.00%|            return self.function_events.export_chrome_trace(path)  # type: ignore[union-attr]
   251|         0|            0|            0|  0.00%|    export_chrome_trace.__doc__ = EventList.export_chrome_trace.__doc__
   252|         0|            0|            0|  0.00%|
   253|         0|            0|            0|  0.00%|    def export_stacks(self, path: str, metric: str = "self_cpu_time_total"):
   254|         0|            0|            0|  0.00%|        self._check_finish()
   255|         0|            0|            0|  0.00%|        assert self.function_events is not None, "Expected profiling results"
   256|         0|            0|            0|  0.00%|        assert self.with_stack, "export_stacks() requires with_stack=True"
   257|         0|            0|            0|  0.00%|        return self.function_events.export_stacks(path, metric)
   258|         0|            0|            0|  0.00%|
   259|         0|            0|            0|  0.00%|    def key_averages(self, group_by_input_shape=False, group_by_stack_n=0):
   260|         0|            0|            0|  0.00%|        self._check_finish()
   261|         0|            0|            0|  0.00%|        assert self.function_events is not None, "Expected profiling results"
   262|         0|            0|            0|  0.00%|        return self.function_events.key_averages(group_by_input_shape, group_by_stack_n)
   263|         0|            0|            0|  0.00%|    key_averages.__doc__ = EventList.key_averages.__doc__
   264|         0|            0|            0|  0.00%|
   265|         0|            0|            0|  0.00%|    def total_average(self):
   266|         0|            0|            0|  0.00%|        self._check_finish()
   267|         0|            0|            0|  0.00%|        assert self.function_events is not None, "Expected profiling results"
   268|         0|            0|            0|  0.00%|        return self.function_events.total_average()
   269|         0|            0|            0|  0.00%|    total_average.__doc__ = EventList.total_average.__doc__
   270|         0|            0|            0|  0.00%|
   271|         0|            0|            0|  0.00%|    @property
   272|         0|            0|            0|  0.00%|    def self_cpu_time_total(self):
   273|         0|            0|            0|  0.00%|        """ Returns total time spent on CPU obtained as a sum of
   274|         0|            0|            0|  0.00%|        all self times across all the events.
   275|         0|            0|            0|  0.00%|        """
   276|         0|            0|            0|  0.00%|        self._check_finish()
   277|         0|            0|            0|  0.00%|        assert self.function_events is not None
   278|         0|            0|            0|  0.00%|        return self.function_events.self_cpu_time_total
   279|         0|            0|            0|  0.00%|
   280|         0|            0|            0|  0.00%|    def _parse_kineto_results(self, result):
   281|         0|            0|            0|  0.00%|        # result.events() has most of the events - PyTorch op-level and device-level events
   282|         0|            0|            0|  0.00%|
   283|         0|            0|            0|  0.00%|        trace_start_us = result.trace_start_us()
   284|         0|            0|            0|  0.00%|        mem_records = [[evt, False] for evt in result.events() if evt.name() == MEMORY_EVENT_NAME]
   285|         0|            0|            0|  0.00%|        mem_records_acc = MemRecordsAcc(mem_records)
   286|         0|            0|            0|  0.00%|
   287|         0|            0|            0|  0.00%|        def _cpu_memory_usage(mem_record):
   288|         0|            0|            0|  0.00%|            return mem_record.nbytes() if \
   289|         0|            0|            0|  0.00%|                mem_record.device_type() in [DeviceType.CPU, DeviceType.MKLDNN, DeviceType.IDEEP] \
   290|         0|            0|            0|  0.00%|                else 0
   291|         0|            0|            0|  0.00%|
   292|         0|            0|            0|  0.00%|        def _cuda_memory_usage(mem_record):
   293|         0|            0|            0|  0.00%|            return mem_record.nbytes() if \
   294|         0|            0|            0|  0.00%|                mem_record.device_type() in [DeviceType.CUDA, DeviceType.HIP] \
   295|         0|            0|            0|  0.00%|                else 0
   296|         0|            0|            0|  0.00%|
   297|         0|            0|            0|  0.00%|        # Create and return FunctionEvent list
   298|         0|            0|            0|  0.00%|        function_events = []
   299|         0|            0|            0|  0.00%|        cuda_corr_map: Dict[int, List[FunctionEvent]] = {}
   300|         0|            0|            0|  0.00%|        max_evt_id = 0
   301|         0|            0|            0|  0.00%|        for kineto_event in result.events():
   302|         0|            0|            0|  0.00%|            if _filter_name(kineto_event.name()):
   303|         0|            0|            0|  0.00%|                continue
   304|         0|            0|            0|  0.00%|            rel_start_us = kineto_event.start_us() - trace_start_us
   305|         0|            0|            0|  0.00%|            rel_end_us = rel_start_us + kineto_event.duration_us()
   306|         0|            0|            0|  0.00%|            abs_end_us = kineto_event.start_us() + kineto_event.duration_us()
   307|         0|            0|            0|  0.00%|
   308|         0|            0|            0|  0.00%|            cpu_memory_usage = 0
   309|         0|            0|            0|  0.00%|            cuda_memory_usage = 0
   310|         0|            0|            0|  0.00%|            if kineto_event.device_type() == DeviceType.CPU:
   311|         0|            0|            0|  0.00%|                # find the corresponding memory allocation events
   312|         0|            0|            0|  0.00%|                for mem_record in mem_records_acc.in_interval(kineto_event.start_us(), abs_end_us):
   313|         0|            0|            0|  0.00%|                    cpu_memory_usage += _cpu_memory_usage(mem_record[0])
   314|         0|            0|            0|  0.00%|                    cuda_memory_usage += _cuda_memory_usage(mem_record[0])
   315|         0|            0|            0|  0.00%|                    mem_record[1] = True
   316|         0|            0|            0|  0.00%|
   317|         0|            0|            0|  0.00%|            is_async = kineto_event.is_async() or (
   318|         0|            0|            0|  0.00%|                kineto_event.start_thread_id() != kineto_event.end_thread_id()
   319|         0|            0|            0|  0.00%|            )
   320|         0|            0|            0|  0.00%|
   321|         0|            0|            0|  0.00%|            fe = FunctionEvent(
   322|         0|            0|            0|  0.00%|                id=kineto_event.correlation_id(),
   323|         0|            0|            0|  0.00%|                name=_rewrite_name(name=kineto_event.name(), with_wildcard=True),
   324|         0|            0|            0|  0.00%|                trace_name=_rewrite_name(name=kineto_event.name(), with_wildcard=False),
   325|         0|            0|            0|  0.00%|                thread=kineto_event.start_thread_id(),
   326|         0|            0|            0|  0.00%|                start_us=rel_start_us,
   327|         0|            0|            0|  0.00%|                end_us=rel_end_us,
   328|         0|            0|            0|  0.00%|                fwd_thread=kineto_event.fwd_thread_id(),
   329|         0|            0|            0|  0.00%|                input_shapes=kineto_event.shapes(),
   330|         0|            0|            0|  0.00%|                stack=[entry for entry in kineto_event.stack() if _filter_stack_entry(entry)],
   331|         0|            0|            0|  0.00%|                scope=kineto_event.scope(),
   332|         0|            0|            0|  0.00%|                cpu_memory_usage=cpu_memory_usage,
   333|         0|            0|            0|  0.00%|                cuda_memory_usage=cuda_memory_usage,
   334|         0|            0|            0|  0.00%|                is_async=is_async,
   335|         0|            0|            0|  0.00%|                sequence_nr=kineto_event.sequence_nr(),
   336|         0|            0|            0|  0.00%|                device_type=kineto_event.device_type(),
   337|         0|            0|            0|  0.00%|                device_index=kineto_event.device_index(),
   338|         0|            0|            0|  0.00%|                flops=kineto_event.flops(),
   339|         0|            0|            0|  0.00%|            )
   340|         0|            0|            0|  0.00%|            max_evt_id = fe.id if fe.id > max_evt_id else max_evt_id
   341|         0|            0|            0|  0.00%|            if fe.device_type == DeviceType.CPU and not fe.is_async:
   342|         0|            0|            0|  0.00%|                # Check if we have CUDA time as a fallback
   343|         0|            0|            0|  0.00%|                cuda_time = kineto_event.cuda_elapsed_us()
   344|         0|            0|            0|  0.00%|                if cuda_time > 0:
   345|         0|            0|            0|  0.00%|                    fe.append_kernel(
   346|         0|            0|            0|  0.00%|                        fe.name,
   347|         0|            0|            0|  0.00%|                        fe.device_index,
   348|         0|            0|            0|  0.00%|                        cuda_time)
   349|         0|            0|            0|  0.00%|                    fe.is_legacy = True
   350|         0|            0|            0|  0.00%|            function_events.append(fe)
   351|         0|            0|            0|  0.00%|            corr_id = kineto_event.linked_correlation_id()
   352|         0|            0|            0|  0.00%|            if corr_id > 0:
   353|         0|            0|            0|  0.00%|                if corr_id not in cuda_corr_map:
   354|         0|            0|            0|  0.00%|                    cuda_corr_map[corr_id] = []
   355|         0|            0|            0|  0.00%|                cuda_corr_map[corr_id].append(fe)
   356|         0|            0|            0|  0.00%|
   357|         0|            0|            0|  0.00%|        # associate CUDA kernels and CUDA runtime (CPU) with CPU events
   358|         0|            0|            0|  0.00%|        for fe in function_events:
   359|         0|            0|            0|  0.00%|            if (fe.device_type == DeviceType.CPU and not fe.is_async and
   360|         0|            0|            0|  0.00%|                    fe.id in cuda_corr_map):
   361|         0|            0|            0|  0.00%|                for f_evt in cuda_corr_map[fe.id]:
   362|         0|            0|            0|  0.00%|                    if f_evt.device_type == DeviceType.CUDA:
   363|         0|            0|            0|  0.00%|                        fe.append_kernel(
   364|         0|            0|            0|  0.00%|                            f_evt.name,
   365|         0|            0|            0|  0.00%|                            f_evt.device_index,
   366|         0|            0|            0|  0.00%|                            f_evt.time_range.end - f_evt.time_range.start)
   367|         0|            0|            0|  0.00%|                    elif f_evt.device_type == DeviceType.CPU:
   368|         0|            0|            0|  0.00%|                        # make sure that 'thread' of a CPU Kineto (e.g. CUDA Runtime) event is associated
   369|         0|            0|            0|  0.00%|                        # with the 'thread' of the corresponding linked PyTorch event to properly track
   370|         0|            0|            0|  0.00%|                        # parents and children
   371|         0|            0|            0|  0.00%|                        f_evt.thread = fe.thread
   372|         0|            0|            0|  0.00%|
   373|         0|            0|            0|  0.00%|        # output top-level memory events
   374|         0|            0|            0|  0.00%|        for mem_record in mem_records:
   375|         0|            0|            0|  0.00%|            if not mem_record[1]:
   376|         0|            0|            0|  0.00%|                rel_start_us = mem_record[0].start_us() - trace_start_us
   377|         0|            0|            0|  0.00%|                max_evt_id += 1
   378|         0|            0|            0|  0.00%|                fe = FunctionEvent(
   379|         0|            0|            0|  0.00%|                    id=max_evt_id,
   380|         0|            0|            0|  0.00%|                    name=MEMORY_EVENT_NAME,
   381|         0|            0|            0|  0.00%|                    trace_name=None,  # not outputting in the trace
   382|         0|            0|            0|  0.00%|                    thread=mem_record[0].start_thread_id(),
   383|         0|            0|            0|  0.00%|                    start_us=rel_start_us,
   384|         0|            0|            0|  0.00%|                    end_us=rel_start_us,  # no duration
   385|         0|            0|            0|  0.00%|                    fwd_thread=mem_record[0].start_thread_id(),
   386|         0|            0|            0|  0.00%|                    input_shapes=[],
   387|         0|            0|            0|  0.00%|                    stack=[],
   388|         0|            0|            0|  0.00%|                    scope=0,  # RecordScope::FUNCTION
   389|         0|            0|            0|  0.00%|                    cpu_memory_usage=_cpu_memory_usage(mem_record[0]),
   390|         0|            0|            0|  0.00%|                    cuda_memory_usage=_cuda_memory_usage(mem_record[0]),
   391|         0|            0|            0|  0.00%|                    is_async=False,
   392|         0|            0|            0|  0.00%|                    sequence_nr=-1,
   393|         0|            0|            0|  0.00%|                    device_type=DeviceType.CPU,
   394|         0|            0|            0|  0.00%|                    device_index=0,
   395|         0|            0|            0|  0.00%|                )
   396|         0|            0|            0|  0.00%|                function_events.append(fe)
   397|         0|            0|            0|  0.00%|
   398|         0|            0|            0|  0.00%|        function_events.sort(key=lambda evt: [evt.time_range.start, -evt.time_range.end])
   399|         0|            0|            0|  0.00%|        return function_events
   400|         0|            0|            0|  0.00%|
   401|         0|            0|            0|  0.00%|
   402|         0|            0|            0|  0.00%|class record_function(ContextDecorator):
   403|         0|            0|            0|  0.00%|    """Context manager/function decorator that adds a label to a block of
   404|         0|            0|            0|  0.00%|    Python code (or function) when running autograd profiler. It is
   405|         0|            0|            0|  0.00%|    useful when tracing the code profile.
   406|         0|            0|            0|  0.00%|
   407|         0|            0|            0|  0.00%|    Args:
   408|         0|            0|            0|  0.00%|        name (str): Label assigned to the block of code.
   409|         0|            0|            0|  0.00%|        node_id (int): ID of node, for distributed profiling. Unset in
   410|         0|            0|            0|  0.00%|        non-distributed cases.
   411|         0|            0|            0|  0.00%|
   412|         0|            0|            0|  0.00%|    Example:
   413|         0|            0|            0|  0.00%|        >>> x = torch.randn((1, 1), requires_grad=True)
   414|         0|            0|            0|  0.00%|        >>> with torch.autograd.profiler.profile() as prof:
   415|         0|            0|            0|  0.00%|        ...     y = x ** 2
   416|         0|            0|            0|  0.00%|        ...     with torch.autograd.profiler.record_function("label-z"): # label the block
   417|         0|            0|            0|  0.00%|        ...         z = y ** 3
   418|         0|            0|            0|  0.00%|        ...     y.backward()
   419|         0|            0|            0|  0.00%|        ...
   420|         0|            0|            0|  0.00%|        >>> # NOTE: some columns were removed for brevity
   421|         0|            0|            0|  0.00%|        >>> print(prof.key_averages().table(sort_by="self_cpu_time_total"))
   422|         0|            0|            0|  0.00%|        -----------------------------------  ---------------  ---------------  ---------------
   423|         0|            0|            0|  0.00%|        Name                                 Self CPU total %  CPU time avg     Number of Calls
   424|         0|            0|            0|  0.00%|        -----------------------------------  ---------------  ---------------  ---------------
   425|         0|            0|            0|  0.00%|        pow                                  60.77%           47.470us         3
   426|         0|            0|            0|  0.00%|        mul                                  21.73%           25.465us         2
   427|         0|            0|            0|  0.00%|        PowBackward0                         12.03%           121.891us        1
   428|         0|            0|            0|  0.00%|        torch::autograd::AccumulateGrad      2.70%            6.324us          1
   429|         0|            0|            0|  0.00%|        label-z                              2.13%            12.421us         1
   430|         0|            0|            0|  0.00%|        torch::autograd::GraphRoot           0.64%            1.503us          1
   431|         0|            0|            0|  0.00%|        -----------------------------------  ---------------  ---------------  ---------------
   432|         0|            0|            0|  0.00%|        Self CPU time total: 234.344us
   433|         0|            0|            0|  0.00%|        CUDA time total: 0.000us
   434|         0|            0|            0|  0.00%|
   435|         0|            0|            0|  0.00%|    """
   436|       576|   0.00119805|  2.07995e-06|  0.00%|    def __init__(self, name: str, args: Optional[str] = None):
   437|       576|    0.0015471|  2.68593e-06|  0.00%|        self.name: str = name
   438|       576|   0.00112343|   1.9504e-06|  0.00%|        self.args: Optional[str] = args
   439|         0|            0|            0|  0.00%|        # Whether or not we should run record function's end callbacks when exiting.
   440|       576|   0.00103307|  1.79352e-06|  0.00%|        self.run_callbacks_on_exit: bool = True
   441|         0|            0|            0|  0.00%|        # Stores underlying RecordFunction as a tensor. TODO: move to custom
   442|         0|            0|            0|  0.00%|        # class (https://github.com/pytorch/pytorch/issues/35026).
   443|       576|   0.00587726|  1.02036e-05|  0.01%|        self.handle: torch.Tensor = torch.zeros(1)
   444|         0|            0|            0|  0.00%|
   445|       576|   0.00105047|  1.82374e-06|  0.00%|    def __enter__(self):
   446|       576|     0.005831|  1.01233e-05|  0.01%|        self.handle = torch.ops.profiler._record_function_enter(self.name, self.args)
(call)|       576|   0.00896788|  1.55692e-05|  0.01%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_ops.py:138 __call__
   447|       576|   0.00111461|  1.93508e-06|  0.00%|        return self
   448|         0|            0|            0|  0.00%|
   449|       576|   0.00102806|  1.78483e-06|  0.00%|    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any):
   450|       576|   0.00126052|   2.1884e-06|  0.00%|        if self.run_callbacks_on_exit:
   451|       576|   0.00466013|   8.0905e-06|  0.00%|            torch.ops.profiler._record_function_exit(self.handle)
(call)|       576|   0.00514126|   8.9258e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_ops.py:138 __call__
   452|         0|            0|            0|  0.00%|
   453|         0|            0|            0|  0.00%|    def _call_end_callbacks_on_future(self, fut: Future[Any]) -> Future[Any]:
   454|         0|            0|            0|  0.00%|        """
   455|         0|            0|            0|  0.00%|        _call_end_callbacks_on_future is meant to be used for profiling async
   456|         0|            0|            0|  0.00%|        calls that return a future. Calling this function will extend recording
   457|         0|            0|            0|  0.00%|        beyond this scope, until the future is satisfied. It is useful for profiling
   458|         0|            0|            0|  0.00%|        the end to end time of asynchronous calls. This function should only be called
   459|         0|            0|            0|  0.00%|        once to attach the callback onto the future, and will throw if called multiple
   460|         0|            0|            0|  0.00%|        times.
   461|         0|            0|            0|  0.00%|
   462|         0|            0|            0|  0.00%|        Args:
   463|         0|            0|            0|  0.00%|            fut: (torch._C.Future): future for which to schedule
   464|         0|            0|            0|  0.00%|            callback for.
   465|         0|            0|            0|  0.00%|
   466|         0|            0|            0|  0.00%|        Returns:
   467|         0|            0|            0|  0.00%|            A future that completes with the value of the passed in future when
   468|         0|            0|            0|  0.00%|            the profiling callbacks have ran.
   469|         0|            0|            0|  0.00%|
   470|         0|            0|            0|  0.00%|        """
   471|         0|            0|            0|  0.00%|        # Throw if we have already attached a callback onto the future.
   472|         0|            0|            0|  0.00%|        if not self.run_callbacks_on_exit:
   473|         0|            0|            0|  0.00%|            raise RuntimeError("_call_end_callbacks_on_future can only be called once.")
   474|         0|            0|            0|  0.00%|
   475|         0|            0|            0|  0.00%|        # We are scheduling to run this RecordFunction's end callbacks when the
   476|         0|            0|            0|  0.00%|        # passed in future completes, so don't run end callbacks on exit.
   477|         0|            0|            0|  0.00%|        self.run_callbacks_on_exit = False
   478|         0|            0|            0|  0.00%|        profiled_future = torch.ops.profiler._call_end_callbacks_on_jit_fut(self.handle, fut)
   479|         0|            0|            0|  0.00%|        return profiled_future
   480|         0|            0|            0|  0.00%|
   481|         0|            0|            0|  0.00%|
   482|         0|            0|            0|  0.00%|class emit_nvtx(object):
   483|         0|            0|            0|  0.00%|    """Context manager that makes every autograd operation emit an NVTX range.
   484|         0|            0|            0|  0.00%|
   485|         0|            0|            0|  0.00%|    It is useful when running the program under nvprof::
   486|         0|            0|            0|  0.00%|
   487|         0|            0|            0|  0.00%|        nvprof --profile-from-start off -o trace_name.prof -- <regular command here>
   488|         0|            0|            0|  0.00%|
   489|         0|            0|            0|  0.00%|    Unfortunately, there's no way to force nvprof to flush the data it collected
   490|         0|            0|            0|  0.00%|    to disk, so for CUDA profiling one has to use this context manager to annotate
   491|         0|            0|            0|  0.00%|    nvprof traces and wait for the process to exit before inspecting them.
   492|         0|            0|            0|  0.00%|    Then, either NVIDIA Visual Profiler (nvvp) can be used to visualize the timeline, or
   493|         0|            0|            0|  0.00%|    :func:`torch.autograd.profiler.load_nvprof` can load the results for inspection
   494|         0|            0|            0|  0.00%|    e.g. in Python REPL.
   495|         0|            0|            0|  0.00%|
   496|         0|            0|            0|  0.00%|    .. warning:
   497|         0|            0|            0|  0.00%|        This context manager should not be called recursively, i.e. at most one
   498|         0|            0|            0|  0.00%|        instance should be enabled at any given time.
   499|         0|            0|            0|  0.00%|
   500|         0|            0|            0|  0.00%|    Args:
   501|         0|            0|            0|  0.00%|        enabled (bool, optional, default=True): Setting ``enabled=False`` makes this context manager a no-op.
   502|         0|            0|            0|  0.00%|            Default: ``True``.
   503|         0|            0|            0|  0.00%|        record_shapes (bool, optional, default=False): If ``record_shapes=True``, the nvtx range wrapping
   504|         0|            0|            0|  0.00%|            each autograd op will append information about the sizes of Tensor arguments received
   505|         0|            0|            0|  0.00%|            by that op, in the following format:
   506|         0|            0|            0|  0.00%|            ``[[arg0.size(0), arg0.size(1), ...], [arg1.size(0), arg1.size(1), ...], ...]``
   507|         0|            0|            0|  0.00%|            Non-tensor arguments will be represented by ``[]``.
   508|         0|            0|            0|  0.00%|            Arguments will be listed in the order they are received by the backend op.
   509|         0|            0|            0|  0.00%|            Please note that this order may not match the order in which those arguments were passed
   510|         0|            0|            0|  0.00%|            on the Python side.  Also note that shape recording may increase the overhead of nvtx range creation.
   511|         0|            0|            0|  0.00%|
   512|         0|            0|            0|  0.00%|    Example:
   513|         0|            0|            0|  0.00%|        >>> with torch.cuda.profiler.profile():
   514|         0|            0|            0|  0.00%|        ...     model(x) # Warmup CUDA memory allocator and profiler
   515|         0|            0|            0|  0.00%|        ...     with torch.autograd.profiler.emit_nvtx():
   516|         0|            0|            0|  0.00%|        ...         model(x)
   517|         0|            0|            0|  0.00%|
   518|         0|            0|            0|  0.00%|    **Forward-backward correlation**
   519|         0|            0|            0|  0.00%|
   520|         0|            0|            0|  0.00%|    When viewing a profile created using :class:`emit_nvtx` in the Nvidia Visual Profiler,
   521|         0|            0|            0|  0.00%|    correlating each backward-pass op with the corresponding forward-pass op can be difficult.
   522|         0|            0|            0|  0.00%|    To ease this task, :class:`emit_nvtx` appends sequence number information to the ranges it
   523|         0|            0|            0|  0.00%|    generates.
   524|         0|            0|            0|  0.00%|
   525|         0|            0|            0|  0.00%|    During the forward pass, each function range is decorated with ``seq=<N>``.  ``seq`` is a running
   526|         0|            0|            0|  0.00%|    counter, incremented each time a new backward Function object is created and stashed for backward.
   527|         0|            0|            0|  0.00%|    Thus, the ``seq=<N>`` annotation associated with each forward function range tells you that
   528|         0|            0|            0|  0.00%|    if a backward Function object is created by this forward function,
   529|         0|            0|            0|  0.00%|    the backward object will receive sequence number N.
   530|         0|            0|            0|  0.00%|    During the backward pass, the top-level range wrapping each C++ backward Function's
   531|         0|            0|            0|  0.00%|    ``apply()`` call is decorated with ``stashed seq=<M>``.  ``M`` is the sequence number that
   532|         0|            0|            0|  0.00%|    the backward object was created with.  By comparing ``stashed seq`` numbers in backward with ``seq``
   533|         0|            0|            0|  0.00%|    numbers in forward, you can track down which forward op created each backward Function.
   534|         0|            0|            0|  0.00%|
   535|         0|            0|            0|  0.00%|    Any functions executed during the backward pass are also decorated with ``seq=<N>``.  During
   536|         0|            0|            0|  0.00%|    default backward (with ``create_graph=False``) this information is irrelevant, and in fact,
   537|         0|            0|            0|  0.00%|    ``N`` may simply be 0 for all such functions.  Only the top-level ranges associated with
   538|         0|            0|            0|  0.00%|    backward Function objects' ``apply()`` methods are useful, as a way to correlate these Function
   539|         0|            0|            0|  0.00%|    objects with the earlier forward pass.
   540|         0|            0|            0|  0.00%|
   541|         0|            0|            0|  0.00%|    **Double-backward**
   542|         0|            0|            0|  0.00%|
   543|         0|            0|            0|  0.00%|    If, on the other hand, a backward pass with ``create_graph=True`` is underway (in other words,
   544|         0|            0|            0|  0.00%|    if you are setting up for a double-backward), each function's execution during backward
   545|         0|            0|            0|  0.00%|    is given a nonzero, useful ``seq=<N>``.  Those functions may themselves create Function objects
   546|         0|            0|            0|  0.00%|    to be executed later during double-backward, just as the original functions in the forward pass did.
   547|         0|            0|            0|  0.00%|    The relationship between backward and double-backward is conceptually the same as the relationship
   548|         0|            0|            0|  0.00%|    between forward and backward: The functions still emit current-sequence-number-tagged ranges,
   549|         0|            0|            0|  0.00%|    the Function objects they create still stash those sequence numbers, and during the eventual
   550|         0|            0|            0|  0.00%|    double-backward, the Function objects' ``apply()`` ranges are still tagged with ``stashed seq``
   551|         0|            0|            0|  0.00%|    numbers, which can be compared to `seq` numbers from the backward pass.
   552|         0|            0|            0|  0.00%|
   553|         0|            0|            0|  0.00%|    .. warning:
   554|         0|            0|            0|  0.00%|        The sequence number is thread-local, and some forward functions don't create an associated
   555|         0|            0|            0|  0.00%|        backward Function object (instead delegating that to sub-functions further down the call chain).
   556|         0|            0|            0|  0.00%|        For these reasons, the correspondence of stashed sequence numbers in
   557|         0|            0|            0|  0.00%|        backward Function ``apply()`` ranges with `seq` numbers in forward-pass ranges is
   558|         0|            0|            0|  0.00%|        not guaranteed to be 1 to 1.  The sequence numbers alone may not be enough to fully
   559|         0|            0|            0|  0.00%|        disambiguate which forward function created which
   560|         0|            0|            0|  0.00%|        backward Function object.  You may need to make a judgment based on analytic knowledge of what
   561|         0|            0|            0|  0.00%|        the expected correspondence should be.
   562|         0|            0|            0|  0.00%|    """
   563|         0|            0|            0|  0.00%|    def __init__(self, enabled=True, record_shapes=False):
   564|         0|            0|            0|  0.00%|        self.enabled = enabled
   565|         0|            0|            0|  0.00%|        self.entered = False
   566|         0|            0|            0|  0.00%|        self.record_shapes = record_shapes
   567|         0|            0|            0|  0.00%|
   568|         0|            0|            0|  0.00%|    def __enter__(self):
   569|         0|            0|            0|  0.00%|        if not self.enabled:
   570|         0|            0|            0|  0.00%|            return
   571|         0|            0|            0|  0.00%|        if self.entered:
   572|         0|            0|            0|  0.00%|            raise RuntimeError("NVTX annotation context manager is not reentrant")
   573|         0|            0|            0|  0.00%|        self.entered = True
   574|         0|            0|            0|  0.00%|        torch.cuda.synchronize()
   575|         0|            0|            0|  0.00%|        _enable_profiler(
   576|         0|            0|            0|  0.00%|            ProfilerConfig(
   577|         0|            0|            0|  0.00%|                ProfilerState.NVTX,
   578|         0|            0|            0|  0.00%|                self.record_shapes,
   579|         0|            0|            0|  0.00%|                False,
   580|         0|            0|            0|  0.00%|                False,
   581|         0|            0|            0|  0.00%|                False,
   582|         0|            0|            0|  0.00%|                False,
   583|         0|            0|            0|  0.00%|                _ExperimentalConfig()),
   584|         0|            0|            0|  0.00%|            set()
   585|         0|            0|            0|  0.00%|        )
   586|         0|            0|            0|  0.00%|        return self
   587|         0|            0|            0|  0.00%|
   588|         0|            0|            0|  0.00%|    def __exit__(self, exc_type, exc_val, exc_tb):
   589|         0|            0|            0|  0.00%|        if not self.enabled:
   590|         0|            0|            0|  0.00%|            return
   591|         0|            0|            0|  0.00%|        torch.cuda.synchronize()
   592|         0|            0|            0|  0.00%|        _disable_profiler()
   593|         0|            0|            0|  0.00%|        return False
   594|         0|            0|            0|  0.00%|
   595|         0|            0|            0|  0.00%|
   596|         0|            0|            0|  0.00%|def load_nvprof(path):
   597|         0|            0|            0|  0.00%|    """Opens an nvprof trace file and parses autograd annotations.
   598|         0|            0|            0|  0.00%|
   599|         0|            0|            0|  0.00%|    Args:
   600|         0|            0|            0|  0.00%|        path (str): path to nvprof trace
   601|         0|            0|            0|  0.00%|    """
   602|         0|            0|            0|  0.00%|    return EventList(parse_nvprof_trace(path))
   603|         0|            0|            0|  0.00%|
   604|         0|            0|            0|  0.00%|
   605|         0|            0|            0|  0.00%|class EnforceUnique(object):
   606|         0|            0|            0|  0.00%|    """Raises an error if a key is seen more than once."""
   607|         0|            0|            0|  0.00%|    def __init__(self):
   608|         0|            0|            0|  0.00%|        self.seen = set()
   609|         0|            0|            0|  0.00%|
   610|         0|            0|            0|  0.00%|    def see(self, *key):
   611|         0|            0|            0|  0.00%|        if key in self.seen:
   612|         0|            0|            0|  0.00%|            raise RuntimeError('duplicate key: ' + str(key))
   613|         0|            0|            0|  0.00%|        self.seen.add(key)
   614|         0|            0|            0|  0.00%|
   615|         0|            0|            0|  0.00%|
   616|         0|            0|            0|  0.00%|def parse_nvprof_trace(path):
   617|         0|            0|            0|  0.00%|    import sqlite3
   618|         0|            0|            0|  0.00%|    conn = sqlite3.connect(path)
   619|         0|            0|            0|  0.00%|    conn.row_factory = sqlite3.Row
   620|         0|            0|            0|  0.00%|
   621|         0|            0|            0|  0.00%|    # Parse strings table
   622|         0|            0|            0|  0.00%|    strings = {}
   623|         0|            0|            0|  0.00%|    for r in conn.execute("SELECT _id_ as id, value FROM StringTable"):
   624|         0|            0|            0|  0.00%|        strings[r["id"]] = torch._C._demangle(r["value"])
   625|         0|            0|            0|  0.00%|
   626|         0|            0|            0|  0.00%|    # First, find all functions and create FunctionEvents for them
   627|         0|            0|            0|  0.00%|    marker_query = """
   628|         0|            0|            0|  0.00%|    SELECT
   629|         0|            0|            0|  0.00%|        start.id AS marker_id, start.name, start.timestamp AS start_time, end.timestamp AS end_time
   630|         0|            0|            0|  0.00%|    FROM
   631|         0|            0|            0|  0.00%|        CUPTI_ACTIVITY_KIND_MARKER AS start INNER JOIN CUPTI_ACTIVITY_KIND_MARKER AS end
   632|         0|            0|            0|  0.00%|        ON start.id = end.id
   633|         0|            0|            0|  0.00%|    WHERE
   634|         0|            0|            0|  0.00%|        start.name != 0 AND end.name = 0
   635|         0|            0|            0|  0.00%|    """
   636|         0|            0|            0|  0.00%|    functions = []
   637|         0|            0|            0|  0.00%|    functions_map = {}
   638|         0|            0|            0|  0.00%|    unique = EnforceUnique()
   639|         0|            0|            0|  0.00%|    for row in conn.execute(marker_query):
   640|         0|            0|            0|  0.00%|        unique.see(row['marker_id'])
   641|         0|            0|            0|  0.00%|        evt = FunctionEvent(id=row['marker_id'],
   642|         0|            0|            0|  0.00%|                            node_id=0,  # missing a node_id when calling FunctionEvent. This is just to ensure
   643|         0|            0|            0|  0.00%|                                        # that pytorch doesn't crash when creating a FunctionEvent() object
   644|         0|            0|            0|  0.00%|                            name=strings[row['name']],
   645|         0|            0|            0|  0.00%|                            start_us=row['start_time'],
   646|         0|            0|            0|  0.00%|                            end_us=row['end_time'],
   647|         0|            0|            0|  0.00%|                            thread=0)  # TODO: find in sqlite database
   648|         0|            0|            0|  0.00%|        functions.append(evt)
   649|         0|            0|            0|  0.00%|        functions_map[evt.id] = evt
   650|         0|            0|            0|  0.00%|
   651|         0|            0|            0|  0.00%|    # Now, correlate all kernels with FunctionEvents
   652|         0|            0|            0|  0.00%|    kernel_query = """
   653|         0|            0|            0|  0.00%|    SELECT
   654|         0|            0|            0|  0.00%|        start.id AS marker_id, start.name, start.timestamp, end.timestamp,
   655|         0|            0|            0|  0.00%|        runtime._id_ AS runtime_id, runtime.cbid, runtime.start AS runtime_start, runtime.end AS runtime_end,
   656|         0|            0|            0|  0.00%|        kernel.start AS kernel_start, kernel.end AS kernel_end, kernel.name AS kernel_name
   657|         0|            0|            0|  0.00%|    FROM
   658|         0|            0|            0|  0.00%|        CUPTI_ACTIVITY_KIND_MARKER AS start
   659|         0|            0|            0|  0.00%|        INNER JOIN CUPTI_ACTIVITY_KIND_MARKER AS end
   660|         0|            0|            0|  0.00%|            ON start.id = end.id
   661|         0|            0|            0|  0.00%|        INNER JOIN CUPTI_ACTIVITY_KIND_RUNTIME as runtime
   662|         0|            0|            0|  0.00%|            ON (start.timestamp < runtime.start AND runtime.end < end.timestamp)
   663|         0|            0|            0|  0.00%|        INNER JOIN CUPTI_ACTIVITY_KIND_CONCURRENT_KERNEL AS kernel
   664|         0|            0|            0|  0.00%|            ON kernel.correlationId = runtime.correlationId
   665|         0|            0|            0|  0.00%|    """
   666|         0|            0|            0|  0.00%|    unique = EnforceUnique()
   667|         0|            0|            0|  0.00%|    for row in conn.execute(kernel_query):
   668|         0|            0|            0|  0.00%|        unique.see(row['marker_id'], row['runtime_id'])
   669|         0|            0|            0|  0.00%|        # 211 is cudaKernelLaunch for cuda >= 9.2
   670|         0|            0|            0|  0.00%|        assert (row['cbid'] == 211)
   671|         0|            0|            0|  0.00%|        evt = functions_map[row['marker_id']]
   672|         0|            0|            0|  0.00%|        evt.append_kernel(row['kernel_name'],
   673|         0|            0|            0|  0.00%|                          0,
   674|         0|            0|            0|  0.00%|                          row['kernel_end'] - row['kernel_start'])
   675|         0|            0|            0|  0.00%|
   676|         0|            0|            0|  0.00%|    functions.sort(key=lambda evt: evt.time_range.start)
   677|         0|            0|            0|  0.00%|    return functions
   678|         0|            0|            0|  0.00%|
   679|         0|            0|            0|  0.00%|
   680|         0|            0|            0|  0.00%|def kineto_step():
   681|         0|            0|            0|  0.00%|    """ Notify kineto so it is aware of iteration boundaries for asynchronous
   682|         0|            0|            0|  0.00%|        trace requests.
   683|         0|            0|            0|  0.00%|    """
   684|         0|            0|            0|  0.00%|    _kineto_step()
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_ops.py
File duration: 0.0141091s (0.01%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import torch._C
     2|         0|            0|            0|  0.00%|
     3|         0|            0|            0|  0.00%|import contextlib
     4|         0|            0|            0|  0.00%|import ctypes
     5|         0|            0|            0|  0.00%|import sys
     6|         0|            0|            0|  0.00%|import types
     7|         0|            0|            0|  0.00%|
     8|         0|            0|            0|  0.00%|import torch.jit
     9|         0|            0|            0|  0.00%|import torch._utils_internal
    10|         0|            0|            0|  0.00%|
    11|         0|            0|            0|  0.00%|# Query `hasattr` only once.
    12|         0|            0|            0|  0.00%|_SET_GLOBAL_FLAGS = hasattr(sys, 'getdlopenflags') and hasattr(sys, 'setdlopenflags')
    13|         0|            0|            0|  0.00%|
    14|         0|            0|            0|  0.00%|
    15|         0|            0|            0|  0.00%|@contextlib.contextmanager
    16|         0|            0|            0|  0.00%|def dl_open_guard():
    17|         0|            0|            0|  0.00%|    """
    18|         0|            0|            0|  0.00%|    Context manager to set the RTLD_GLOBAL dynamic linker flag while we open a
    19|         0|            0|            0|  0.00%|    shared library to load custom operators.
    20|         0|            0|            0|  0.00%|    """
    21|         0|            0|            0|  0.00%|    if _SET_GLOBAL_FLAGS:
    22|         0|            0|            0|  0.00%|        old_flags = sys.getdlopenflags()
    23|         0|            0|            0|  0.00%|        sys.setdlopenflags(old_flags | ctypes.RTLD_GLOBAL)
    24|         0|            0|            0|  0.00%|    yield
    25|         0|            0|            0|  0.00%|    if _SET_GLOBAL_FLAGS:
    26|         0|            0|            0|  0.00%|        sys.setdlopenflags(old_flags)
    27|         0|            0|            0|  0.00%|
    28|         0|            0|            0|  0.00%|# Each OpOverload object contains pointer to a a specific operator overload, a pointer to the parent `OpOverloadPacket` object.
    29|         0|            0|            0|  0.00%|# You can obtain an OpOverload object through attribute query on OpOverloadPacket.
    30|         0|            0|            0|  0.00%|class OpOverload:
    31|         0|            0|            0|  0.00%|    def __init__(self, overloadpacket, op, schema):
    32|         0|            0|            0|  0.00%|        self._op = op
    33|         0|            0|            0|  0.00%|        self._schema = schema
    34|         0|            0|            0|  0.00%|        self._overloadpacket = overloadpacket
    35|         0|            0|            0|  0.00%|        self._overloadname = 'default' if schema.overload_name == '' else schema.overload_name
    36|         0|            0|            0|  0.00%|        self.__name__ = "{}.{}".format(self._schema.name.split("::")[1], self._overloadname)
    37|         0|            0|            0|  0.00%|        self.__module__ = overloadpacket.__module__
    38|         0|            0|            0|  0.00%|        op.__module__ = overloadpacket.__module__
    39|         0|            0|            0|  0.00%|
    40|         0|            0|            0|  0.00%|    # it's a no-op since OpOverload object is immutable and must be unique for a given op overload.
    41|         0|            0|            0|  0.00%|    def __deepcopy__(self, memo=None):
    42|         0|            0|            0|  0.00%|        return self
    43|         0|            0|            0|  0.00%|
    44|         0|            0|            0|  0.00%|    def __repr__(self):
    45|         0|            0|            0|  0.00%|        return "<OpOverload(op='{}.{}', overload='{}')>".format(*self._schema.name.split("::"), self._overloadname)
    46|         0|            0|            0|  0.00%|
    47|         0|            0|            0|  0.00%|    def __call__(self, *args, **kwargs):
    48|         0|            0|            0|  0.00%|        return self._op(*args, **kwargs or {})
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|    def __getattr__(self, key):
    51|         0|            0|            0|  0.00%|        return getattr(self._op, key)
    52|         0|            0|            0|  0.00%|
    53|         0|            0|            0|  0.00%|    def __hash__(self):
    54|         0|            0|            0|  0.00%|        return hash(self._op)
    55|         0|            0|            0|  0.00%|
    56|         0|            0|            0|  0.00%|    # `my_namespace.my_op_name.overload_name`
    57|         0|            0|            0|  0.00%|    def __str__(self):
    58|         0|            0|            0|  0.00%|        return "{}.{}.{}".format(*self._schema.name.split("::"), self._overloadname)
    59|         0|            0|            0|  0.00%|
    60|         0|            0|            0|  0.00%|    @property
    61|         0|            0|            0|  0.00%|    def overloadpacket(self):
    62|         0|            0|            0|  0.00%|        return self._overloadpacket
    63|         0|            0|            0|  0.00%|
    64|         0|            0|            0|  0.00%|    @property
    65|         0|            0|            0|  0.00%|    def op(self):
    66|         0|            0|            0|  0.00%|        return self._op
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|    # TODO: add more methods to expose information about input and output arguments
    69|         0|            0|            0|  0.00%|
    70|         0|            0|            0|  0.00%|# OpOverloadPacket class contains pointer to a base unresolved operator that doesn't correspond to a specific operator
    71|         0|            0|            0|  0.00%|# You can obtain an OpOverload object through attribute query.
    72|         0|            0|            0|  0.00%|class OpOverloadPacket:
    73|         0|            0|            0|  0.00%|    def __init__(self, qualified_op_name, op_name, op, overload_names):
    74|         0|            0|            0|  0.00%|        # These attributes are accessible on the object through the properties
    75|         0|            0|            0|  0.00%|        # defined below but are immutable
    76|         0|            0|            0|  0.00%|        self._qualified_op_name = qualified_op_name
    77|         0|            0|            0|  0.00%|        self.__name__ = op_name
    78|         0|            0|            0|  0.00%|        self._op = op
    79|         0|            0|            0|  0.00%|        self._overload_names = overload_names
    80|         0|            0|            0|  0.00%|
    81|         0|            0|            0|  0.00%|    # it's a no-op since OpOverloadPacket object is immutable and must be unique for a given op.
    82|         0|            0|            0|  0.00%|    def __deepcopy__(self, memo=None):
    83|         0|            0|            0|  0.00%|        return self
    84|         0|            0|            0|  0.00%|
    85|         0|            0|            0|  0.00%|    def __repr__(self):
    86|         0|            0|            0|  0.00%|        return "<OpOverloadPacket(op='{}.{}')>".format(*self._qualified_op_name.split("::"))
    87|         0|            0|            0|  0.00%|
    88|         0|            0|            0|  0.00%|    def __hash__(self):
    89|         0|            0|            0|  0.00%|        return hash(self._op)
    90|         0|            0|            0|  0.00%|
    91|         0|            0|            0|  0.00%|    def __str__(self):
    92|         0|            0|            0|  0.00%|        return "{}.{}".format(*self._qualified_op_name.split("::"))
    93|         0|            0|            0|  0.00%|
    94|         0|            0|            0|  0.00%|    @property
    95|         0|            0|            0|  0.00%|    def op(self):
    96|         0|            0|            0|  0.00%|        return self._op
    97|         0|            0|            0|  0.00%|
    98|         0|            0|            0|  0.00%|    def __getattr__(self, key):
    99|         0|            0|            0|  0.00%|        # It is not a valid op_name when __file__ is passed in
   100|         0|            0|            0|  0.00%|        if key == '__file__':
   101|         0|            0|            0|  0.00%|            return 'torch.ops'
   102|         0|            0|            0|  0.00%|
   103|         0|            0|            0|  0.00%|        # ensure that query for dunder attributes that does not exist on
   104|         0|            0|            0|  0.00%|        # opoverloadpacket but instead exists on the self._op object does not unnecessarily call
   105|         0|            0|            0|  0.00%|        # `_get_operation_overload` (which is an expensive operation).
   106|         0|            0|            0|  0.00%|        # This is done to prevent any potential slowdown. This list can be extended
   107|         0|            0|            0|  0.00%|        # if there exists other attributes like `__name__` that only exist on self._op and not on the
   108|         0|            0|            0|  0.00%|        # opoverloadpacket.
   109|         0|            0|            0|  0.00%|        # This is ok since we are guaranteed that an overload name for an aten op can't start with '__'
   110|         0|            0|            0|  0.00%|        try:
   111|         0|            0|            0|  0.00%|            if key.startswith('__'):
   112|         0|            0|            0|  0.00%|                return getattr(self._op, key)
   113|         0|            0|            0|  0.00%|        except AttributeError:
   114|         0|            0|            0|  0.00%|            # for consistency because it seems weird to
   115|         0|            0|            0|  0.00%|            # throw an attribute error with a message containing
   116|         0|            0|            0|  0.00%|            # an object name different from the one the attribute
   117|         0|            0|            0|  0.00%|            # query was performed on.
   118|         0|            0|            0|  0.00%|            raise AttributeError("'{}' can't have an overload name beginning with '__' and the "
   119|         0|            0|            0|  0.00%|                                 "underlying op {} has no attribute {} either."
   120|         0|            0|            0|  0.00%|                                 .format(str(self), str(self._op), key)) from None
   121|         0|            0|            0|  0.00%|
   122|         0|            0|            0|  0.00%|        try:
   123|         0|            0|            0|  0.00%|            # This is ok since we are guaranteed that an overload name for an aten op can't be 'default'
   124|         0|            0|            0|  0.00%|            use_key = '' if key == 'default' else key
   125|         0|            0|            0|  0.00%|            # TODO: disallow access to overloads registered by JIT
   126|         0|            0|            0|  0.00%|            op_ = torch._C._get_operation_overload(
   127|         0|            0|            0|  0.00%|                self._qualified_op_name, use_key)
   128|         0|            0|            0|  0.00%|            schema = torch._C._get_schema(self._qualified_op_name, use_key)
   129|         0|            0|            0|  0.00%|            overload = OpOverload(self, op_, schema)
   130|         0|            0|            0|  0.00%|            # cache the overload object
   131|         0|            0|            0|  0.00%|            setattr(self, key, overload)
   132|         0|            0|            0|  0.00%|            return overload
   133|         0|            0|            0|  0.00%|        except RuntimeError:
   134|         0|            0|            0|  0.00%|            raise AttributeError(
   135|         0|            0|            0|  0.00%|                "The underlying op of '{}' has no overload name '{}'".format(str(self), key)
   136|         0|            0|            0|  0.00%|            ) from None
   137|         0|            0|            0|  0.00%|
   138|      1152|   0.00193954|  1.68362e-06|  0.00%|    def __call__(self, *args, **kwargs):
   139|         0|            0|            0|  0.00%|        # overloading __call__ to ensure torch.ops.foo.bar()
   140|         0|            0|            0|  0.00%|        # is still callable from JIT
   141|         0|            0|            0|  0.00%|        # We save the function ptr as the `op` attribute on
   142|         0|            0|            0|  0.00%|        # OpOverloadPacket to access it here.
   143|      1152|    0.0121696|  1.05639e-05|  0.01%|        return self._op(*args, **kwargs or {})
   144|         0|            0|            0|  0.00%|
   145|         0|            0|            0|  0.00%|    # TODO: use this to make a __dir__
   146|         0|            0|            0|  0.00%|    def overloads(self):
   147|         0|            0|            0|  0.00%|        return [n if n else "default" for n in self._overload_names]
   148|         0|            0|            0|  0.00%|
   149|         0|            0|            0|  0.00%|# Resolution of torch.fn is different from torch.ops.aten.fn
   150|         0|            0|            0|  0.00%|# torch.fn uses the Python argparser, matches with the
   151|         0|            0|            0|  0.00%|# appropriate schema, and calls into the unboxed version of the method
   152|         0|            0|            0|  0.00%|# torch.ops.aten.fn resolution is done via the mechanism defined in JIT.
   153|         0|            0|            0|  0.00%|# JIT creates a stack of all the overloads and then tries to match the
   154|         0|            0|            0|  0.00%|# correct one at runtime and always calls into the boxed version of the method
   155|         0|            0|            0|  0.00%|# Autograd codegen creates VariableType, TracerType,
   156|         0|            0|            0|  0.00%|# inplace or view type and python bindings.
   157|         0|            0|            0|  0.00%|# Aten codegen generates tensor methods for the the tensor class.
   158|         0|            0|            0|  0.00%|
   159|         0|            0|            0|  0.00%|# _OpNamespace is a subclass of ModuleType because the torch script
   160|         0|            0|            0|  0.00%|# allows attribute lookups on modules only. Since we want torch.ops.foo.bar()
   161|         0|            0|            0|  0.00%|# to work from script, we need to ensure ops and foo are modules
   162|         0|            0|            0|  0.00%|
   163|         0|            0|            0|  0.00%|
   164|         0|            0|            0|  0.00%|class _OpNamespace(types.ModuleType):
   165|         0|            0|            0|  0.00%|    """
   166|         0|            0|            0|  0.00%|    An op namespace to dynamically bind Operators into Python.
   167|         0|            0|            0|  0.00%|
   168|         0|            0|            0|  0.00%|    Say a user has created a custom Operator called "my_namespace::my_op". To
   169|         0|            0|            0|  0.00%|    call this op, the user will write torch.ops.my_namespace.my_op(...).
   170|         0|            0|            0|  0.00%|    At startup, this operation will not yet be bound into Python. Instead, the
   171|         0|            0|            0|  0.00%|    following sequence of magic tricks will occur:
   172|         0|            0|            0|  0.00%|    1. `torch.ops.my_namespace` will invoke the `__getattr__` magic method
   173|         0|            0|            0|  0.00%|       on the `torch.ops` object, which will create a new `_OpNamespace`
   174|         0|            0|            0|  0.00%|       object called `my_namespace` and set it as an attribute on the `ops`
   175|         0|            0|            0|  0.00%|       object.
   176|         0|            0|            0|  0.00%|    2. `torch.ops.my_namespace.my_op` will then invoke `__getattr__` on
   177|         0|            0|            0|  0.00%|       the `my_namespace` object, which will retrieve the operation via
   178|         0|            0|            0|  0.00%|       `torch.get_operation`, a function bound from C++, and then in a similar
   179|         0|            0|            0|  0.00%|       fashion bind this new object onto the `my_namespace` object.
   180|         0|            0|            0|  0.00%|    3. `torch.ops.my_namespace.my_op(...)` then calls this new operation
   181|         0|            0|            0|  0.00%|        and subsequent accesses will incur no further lookup (the namespace and
   182|         0|            0|            0|  0.00%|        operation will already exist).
   183|         0|            0|            0|  0.00%|    """
   184|         0|            0|            0|  0.00%|    def __init__(self, name):
   185|         0|            0|            0|  0.00%|        super(_OpNamespace, self).__init__('torch.ops.' + name)
   186|         0|            0|            0|  0.00%|        self.name = name
   187|         0|            0|            0|  0.00%|
   188|         0|            0|            0|  0.00%|    def __getattr__(self, op_name):
   189|         0|            0|            0|  0.00%|        # It is not a valid op_name when __file__ is passed in
   190|         0|            0|            0|  0.00%|        if op_name == '__file__':
   191|         0|            0|            0|  0.00%|            return 'torch.ops'
   192|         0|            0|            0|  0.00%|
   193|         0|            0|            0|  0.00%|        # Get the op `my_namespace::my_op` if available. This will also check
   194|         0|            0|            0|  0.00%|        # for overloads and raise an exception if there are more than one.
   195|         0|            0|            0|  0.00%|        namespace_name = self.name
   196|         0|            0|            0|  0.00%|        qualified_op_name = '{}::{}'.format(namespace_name, op_name)
   197|         0|            0|            0|  0.00%|        try:
   198|         0|            0|            0|  0.00%|            op, overload_names = torch._C._jit_get_operation(qualified_op_name)
   199|         0|            0|            0|  0.00%|        except RuntimeError as e:
   200|         0|            0|            0|  0.00%|            # Turn this into AttributeError so getattr(obj, key, default)
   201|         0|            0|            0|  0.00%|            # works (this is called by TorchScript with __origin__)
   202|         0|            0|            0|  0.00%|            raise AttributeError(f"'_OpNamespace' object has no attribute '{op_name}'") from e
   203|         0|            0|            0|  0.00%|
   204|         0|            0|            0|  0.00%|        # let the script frontend know that op is identical to the builtin op
   205|         0|            0|            0|  0.00%|        # with qualified_op_name
   206|         0|            0|            0|  0.00%|        torch.jit._builtins._register_builtin(op, qualified_op_name)
   207|         0|            0|            0|  0.00%|        op.__module__ = self.__module__ + "." + namespace_name
   208|         0|            0|            0|  0.00%|        opoverloadpacket = OpOverloadPacket(qualified_op_name, op_name, op, overload_names)
   209|         0|            0|            0|  0.00%|        opoverloadpacket.__module__ = self.__module__ + "." + namespace_name
   210|         0|            0|            0|  0.00%|        # cache the opoverloadpacket to ensure that each op corresponds to
   211|         0|            0|            0|  0.00%|        # a unique OpOverloadPacket object
   212|         0|            0|            0|  0.00%|        setattr(self, op_name, opoverloadpacket)
   213|         0|            0|            0|  0.00%|        return opoverloadpacket
   214|         0|            0|            0|  0.00%|
   215|         0|            0|            0|  0.00%|
   216|         0|            0|            0|  0.00%|class _Ops(types.ModuleType):
   217|         0|            0|            0|  0.00%|    __file__ = '_ops.py'
   218|         0|            0|            0|  0.00%|
   219|         0|            0|            0|  0.00%|    def __init__(self):
   220|         0|            0|            0|  0.00%|        super(_Ops, self).__init__('torch.ops')
   221|         0|            0|            0|  0.00%|        self.loaded_libraries = set()
   222|         0|            0|            0|  0.00%|
   223|         0|            0|            0|  0.00%|    def __getattr__(self, name):
   224|         0|            0|            0|  0.00%|        # Here we are creating `torch.ops.my_namespace`
   225|         0|            0|            0|  0.00%|        namespace = _OpNamespace(name)
   226|         0|            0|            0|  0.00%|        setattr(self, name, namespace)
   227|         0|            0|            0|  0.00%|        return namespace
   228|         0|            0|            0|  0.00%|
   229|         0|            0|            0|  0.00%|    def load_library(self, path):
   230|         0|            0|            0|  0.00%|        """
   231|         0|            0|            0|  0.00%|        Loads a shared library from the given path into the current process.
   232|         0|            0|            0|  0.00%|
   233|         0|            0|            0|  0.00%|        The library being loaded may run global initialization code to register
   234|         0|            0|            0|  0.00%|        custom operators with the PyTorch JIT runtime. This allows dynamically
   235|         0|            0|            0|  0.00%|        loading custom operators. For this, you should compile your operator
   236|         0|            0|            0|  0.00%|        and the static registration code into a shared library object, and then
   237|         0|            0|            0|  0.00%|        call ``torch.ops.load_library('path/to/libcustom.so')`` to load the
   238|         0|            0|            0|  0.00%|        shared object.
   239|         0|            0|            0|  0.00%|
   240|         0|            0|            0|  0.00%|        After the library is loaded, it is added to the
   241|         0|            0|            0|  0.00%|        ``torch.ops.loaded_libraries`` attribute, a set that may be inspected
   242|         0|            0|            0|  0.00%|        for the paths of all libraries loaded using this function.
   243|         0|            0|            0|  0.00%|
   244|         0|            0|            0|  0.00%|        Args:
   245|         0|            0|            0|  0.00%|            path (str): A path to a shared library to load.
   246|         0|            0|            0|  0.00%|        """
   247|         0|            0|            0|  0.00%|        if sys.executable == "torch_deploy":
   248|         0|            0|            0|  0.00%|            return
   249|         0|            0|            0|  0.00%|
   250|         0|            0|            0|  0.00%|        path = torch._utils_internal.resolve_library_path(path)
   251|         0|            0|            0|  0.00%|        with dl_open_guard():
   252|         0|            0|            0|  0.00%|            # Import the shared library into the process, thus running its
   253|         0|            0|            0|  0.00%|            # static (global) initialization code in order to register custom
   254|         0|            0|            0|  0.00%|            # operators with the JIT.
   255|         0|            0|            0|  0.00%|            ctypes.CDLL(path)
   256|         0|            0|            0|  0.00%|        self.loaded_libraries.add(path)
   257|         0|            0|            0|  0.00%|
   258|         0|            0|            0|  0.00%|
   259|         0|            0|            0|  0.00%|# The ops "namespace"
   260|         0|            0|            0|  0.00%|ops = _Ops()
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/_jit_internal.py
File duration: 0.0108981s (0.01%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|"""
     2|         0|            0|            0|  0.00%|The weak_script annotation needs to be here instead of inside torch/jit/ so it
     3|         0|            0|            0|  0.00%|can be used in other places in torch/ (namely torch.nn) without running into
     4|         0|            0|            0|  0.00%|circular dependency problems
     5|         0|            0|            0|  0.00%|"""
     6|         0|            0|            0|  0.00%|
     7|         0|            0|            0|  0.00%|import contextlib
     8|         0|            0|            0|  0.00%|import collections
     9|         0|            0|            0|  0.00%|import enum
    10|         0|            0|            0|  0.00%|import inspect
    11|         0|            0|            0|  0.00%|import ast
    12|         0|            0|            0|  0.00%|import weakref
    13|         0|            0|            0|  0.00%|import warnings
    14|         0|            0|            0|  0.00%|from textwrap import dedent
    15|         0|            0|            0|  0.00%|import torch
    16|         0|            0|            0|  0.00%|import sys
    17|         0|            0|            0|  0.00%|import builtins
    18|         0|            0|            0|  0.00%|import typing
    19|         0|            0|            0|  0.00%|import io
    20|         0|            0|            0|  0.00%|import pickle
    21|         0|            0|            0|  0.00%|import threading
    22|         0|            0|            0|  0.00%|# This is needed. `torch._jit_internal` is imported before `torch.distributed.__init__`.
    23|         0|            0|            0|  0.00%|# Explicitly ask to import `torch.distributed.__init__` first.
    24|         0|            0|            0|  0.00%|# Otherwise, "AttributeError: module 'torch' has no attribute 'distributed'" is raised.
    25|         0|            0|            0|  0.00%|import torch.distributed.rpc
    26|         0|            0|            0|  0.00%|from torch._C import Future as CFuture
    27|         0|            0|            0|  0.00%|from torch._sources import get_source_lines_and_file, parse_def, fake_range
    28|         0|            0|            0|  0.00%|from torch.futures import Future
    29|         0|            0|            0|  0.00%|import torch.package._mangling as package_mangling
    30|         0|            0|            0|  0.00%|from typing import Any, Callable, Dict, Generic, List, Optional, Tuple, Type, TypeVar, Union  # noqa: F401
    31|         0|            0|            0|  0.00%|
    32|         0|            0|            0|  0.00%|if sys.version_info[:2] > (3, 7):
    33|         0|            0|            0|  0.00%|    from typing import Final
    34|         0|            0|            0|  0.00%|else:
    35|         0|            0|            0|  0.00%|    from typing_extensions import Final
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|LockType: Type
    38|         0|            0|            0|  0.00%|try:
    39|         0|            0|            0|  0.00%|    import _thread
    40|         0|            0|            0|  0.00%|    LockType = _thread.LockType
    41|         0|            0|            0|  0.00%|except ImportError:
    42|         0|            0|            0|  0.00%|    import _dummy_thread
    43|         0|            0|            0|  0.00%|    LockType = _dummy_thread.LockType
    44|         0|            0|            0|  0.00%|
    45|         0|            0|            0|  0.00%|# Wrapper functions that can call either of 2 functions depending on a boolean
    46|         0|            0|            0|  0.00%|# argument
    47|         0|            0|            0|  0.00%|boolean_dispatched: 'weakref.WeakKeyDictionary[Callable, Dict[str, Callable]]' = weakref.WeakKeyDictionary()  # noqa: T484
    48|         0|            0|            0|  0.00%|
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|def createResolutionCallbackFromEnv(lookup_base):
    51|         0|            0|            0|  0.00%|    """
    52|         0|            0|            0|  0.00%|    Creates a resolution callback that will look up qualified names in an
    53|         0|            0|            0|  0.00%|    environment, starting with `lookup_base` for the base of any qualified
    54|         0|            0|            0|  0.00%|    names, then proceeding down the lookup chain with the resolved object.
    55|         0|            0|            0|  0.00%|
    56|         0|            0|            0|  0.00%|    You should not use this directly, it should only be used from the other
    57|         0|            0|            0|  0.00%|    createResolutionCallbackFrom* functions.
    58|         0|            0|            0|  0.00%|    """
    59|         0|            0|            0|  0.00%|    def lookupInModule(qualified_name, module):
    60|         0|            0|            0|  0.00%|        if '.' in qualified_name:
    61|         0|            0|            0|  0.00%|            parts = qualified_name.split('.')
    62|         0|            0|            0|  0.00%|            base = parts[0]
    63|         0|            0|            0|  0.00%|            remaining_pieces = '.'.join(parts[1:])
    64|         0|            0|            0|  0.00%|            module_value = getattr(module, base)
    65|         0|            0|            0|  0.00%|            return lookupInModule(remaining_pieces, module_value)
    66|         0|            0|            0|  0.00%|        else:
    67|         0|            0|            0|  0.00%|            return getattr(module, qualified_name)
    68|         0|            0|            0|  0.00%|
    69|         0|            0|            0|  0.00%|    def parseNestedExpr(expr, module) -> Tuple[Any, int]:
    70|         0|            0|            0|  0.00%|        i = 0
    71|         0|            0|            0|  0.00%|        while i < len(expr) and expr[i] not in (',', '[', ']'):
    72|         0|            0|            0|  0.00%|            i += 1
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|        # Special case logic for the empty Tuple as a subscript (used
    75|         0|            0|            0|  0.00%|        # in the type annotation `Tuple[()]`)
    76|         0|            0|            0|  0.00%|        if expr[:i] == '()':
    77|         0|            0|            0|  0.00%|            return (), i
    78|         0|            0|            0|  0.00%|
    79|         0|            0|            0|  0.00%|        base = lookupInModule(expr[:i].strip(), module)
    80|         0|            0|            0|  0.00%|        assert base is not None, f"Unresolvable type {expr[:i]}"
    81|         0|            0|            0|  0.00%|        if i == len(expr) or expr[i] != '[':
    82|         0|            0|            0|  0.00%|            return base, i
    83|         0|            0|            0|  0.00%|
    84|         0|            0|            0|  0.00%|        assert expr[i] == '['
    85|         0|            0|            0|  0.00%|        parts = []
    86|         0|            0|            0|  0.00%|        while expr[i] != ']':
    87|         0|            0|            0|  0.00%|            part_len = 0
    88|         0|            0|            0|  0.00%|            i += 1
    89|         0|            0|            0|  0.00%|            part, part_len = parseNestedExpr(expr[i:], module)
    90|         0|            0|            0|  0.00%|            parts.append(part)
    91|         0|            0|            0|  0.00%|            i += part_len
    92|         0|            0|            0|  0.00%|        if len(parts) > 1:
    93|         0|            0|            0|  0.00%|            return base[tuple(parts)], i + 1
    94|         0|            0|            0|  0.00%|        else:
    95|         0|            0|            0|  0.00%|            return base[parts[0]], i + 1
    96|         0|            0|            0|  0.00%|
    97|         0|            0|            0|  0.00%|    def parseExpr(expr, module):
    98|         0|            0|            0|  0.00%|        try:
    99|         0|            0|            0|  0.00%|            value, len_parsed = parseNestedExpr(expr, module)
   100|         0|            0|            0|  0.00%|            assert len_parsed == len(expr), "whole expression was not parsed, falling back to c++ parser"
   101|         0|            0|            0|  0.00%|            return value
   102|         0|            0|            0|  0.00%|        except Exception:
   103|         0|            0|            0|  0.00%|            """
   104|         0|            0|            0|  0.00%|            The python resolver fails in several cases in known unit tests, and is intended
   105|         0|            0|            0|  0.00%|            to fall back gracefully to the c++ resolver in general.  For example, python 2 style
   106|         0|            0|            0|  0.00%|            annotations which are frequent in our unit tests often fail with types e.g. int not
   107|         0|            0|            0|  0.00%|            resolvable from the calling frame.
   108|         0|            0|            0|  0.00%|            """
   109|         0|            0|            0|  0.00%|            return None
   110|         0|            0|            0|  0.00%|
   111|         0|            0|            0|  0.00%|    return lambda expr: parseExpr(expr, lookup_base)
   112|         0|            0|            0|  0.00%|
   113|         0|            0|            0|  0.00%|
   114|         0|            0|            0|  0.00%|def createResolutionCallbackFromFrame(frames_up: int = 0):
   115|         0|            0|            0|  0.00%|    """
   116|         0|            0|            0|  0.00%|    Creates a function which, given a string variable name,
   117|         0|            0|            0|  0.00%|    returns the value of the variable in the scope of the caller of
   118|         0|            0|            0|  0.00%|    the function which called createResolutionCallbackFromFrame (by default).
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|    This is used to enable access in-scope Python variables inside
   121|         0|            0|            0|  0.00%|    TorchScript fragments.
   122|         0|            0|            0|  0.00%|
   123|         0|            0|            0|  0.00%|    frames_up is number of additional frames to go up on the stack.
   124|         0|            0|            0|  0.00%|    The default value is 0, which correspond to the frame of the caller
   125|         0|            0|            0|  0.00%|    of createResolutionCallbackFromFrame. Also for example, if frames_up is set
   126|         0|            0|            0|  0.00%|    to 1, then the frame of the caller's caller of createResolutionCallbackFromFrame
   127|         0|            0|            0|  0.00%|    will be taken.
   128|         0|            0|            0|  0.00%|
   129|         0|            0|            0|  0.00%|    For example, the following program prints 2::
   130|         0|            0|            0|  0.00%|
   131|         0|            0|            0|  0.00%|        def bar():
   132|         0|            0|            0|  0.00%|            cb = createResolutionCallbackFromFrame(1)
   133|         0|            0|            0|  0.00%|            print(cb("foo"))
   134|         0|            0|            0|  0.00%|
   135|         0|            0|            0|  0.00%|        def baz():
   136|         0|            0|            0|  0.00%|            foo = 2
   137|         0|            0|            0|  0.00%|            bar()
   138|         0|            0|            0|  0.00%|
   139|         0|            0|            0|  0.00%|        baz()
   140|         0|            0|            0|  0.00%|    """
   141|         0|            0|            0|  0.00%|    frame = inspect.currentframe()
   142|         0|            0|            0|  0.00%|    i = 0
   143|         0|            0|            0|  0.00%|    while i < frames_up + 1:
   144|         0|            0|            0|  0.00%|        assert frame is not None
   145|         0|            0|            0|  0.00%|        frame = frame.f_back
   146|         0|            0|            0|  0.00%|        i += 1
   147|         0|            0|            0|  0.00%|
   148|         0|            0|            0|  0.00%|    assert frame is not None
   149|         0|            0|            0|  0.00%|    f_locals = frame.f_locals
   150|         0|            0|            0|  0.00%|    f_globals = frame.f_globals
   151|         0|            0|            0|  0.00%|
   152|         0|            0|            0|  0.00%|    class env(object):
   153|         0|            0|            0|  0.00%|        def __getattr__(self, key):
   154|         0|            0|            0|  0.00%|            if key in f_locals:
   155|         0|            0|            0|  0.00%|                return f_locals[key]
   156|         0|            0|            0|  0.00%|            elif key in f_globals:
   157|         0|            0|            0|  0.00%|                return f_globals[key]
   158|         0|            0|            0|  0.00%|            elif key in dir(builtins):
   159|         0|            0|            0|  0.00%|                return getattr(builtins, key)
   160|         0|            0|            0|  0.00%|
   161|         0|            0|            0|  0.00%|    return createResolutionCallbackFromEnv(env())
   162|         0|            0|            0|  0.00%|
   163|         0|            0|            0|  0.00%|
   164|         0|            0|            0|  0.00%|def get_closure(fn):
   165|         0|            0|            0|  0.00%|    """
   166|         0|            0|            0|  0.00%|    Get a dictionary of closed over variables from a function
   167|         0|            0|            0|  0.00%|    """
   168|         0|            0|            0|  0.00%|    captures = {}
   169|         0|            0|            0|  0.00%|    captures.update(fn.__globals__)
   170|         0|            0|            0|  0.00%|
   171|         0|            0|            0|  0.00%|    for index, captured_name in enumerate(fn.__code__.co_freevars):
   172|         0|            0|            0|  0.00%|        captures[captured_name] = fn.__closure__[index].cell_contents
   173|         0|            0|            0|  0.00%|
   174|         0|            0|            0|  0.00%|    return captures
   175|         0|            0|            0|  0.00%|
   176|         0|            0|            0|  0.00%|# [local resolution in python]
   177|         0|            0|            0|  0.00%|# Depending on where a variable is defined, and where it is used, we may
   178|         0|            0|            0|  0.00%|# or may not be able to recover its value when recursively compiling a
   179|         0|            0|            0|  0.00%|# script function. Remember in the general case, a module or function is
   180|         0|            0|            0|  0.00%|# first defined and then later scripted. This means we do not have a
   181|         0|            0|            0|  0.00%|# chance to capture the active frames when the function is defined. Hence any
   182|         0|            0|            0|  0.00%|# name resolution has to happen later on the created closure. The way
   183|         0|            0|            0|  0.00%|# python captures type annotations restricts what we can recover. The
   184|         0|            0|            0|  0.00%|# follow example illustrates the different cases:
   185|         0|            0|            0|  0.00%|#
   186|         0|            0|            0|  0.00%|#         class MyGlobalClass:
   187|         0|            0|            0|  0.00%|#         ...
   188|         0|            0|            0|  0.00%|#         def my_local_scope():
   189|         0|            0|            0|  0.00%|#             @torch.jit.script
   190|         0|            0|            0|  0.00%|#             class MyClass:
   191|         0|            0|            0|  0.00%|#                 ...
   192|         0|            0|            0|  0.00%|#             @torch.jit.script
   193|         0|            0|            0|  0.00%|#             class MyClassUsedAsVar:
   194|         0|            0|            0|  0.00%|#                 ...
   195|         0|            0|            0|  0.00%|#             def eg(x: MyClass, y: MyGlobalClass):
   196|         0|            0|            0|  0.00%|#                 a_local_capture : Foo
   197|         0|            0|            0|  0.00%|#                 return MyClassUsedAsVar(x)
   198|         0|            0|            0|  0.00%|#
   199|         0|            0|            0|  0.00%|# MyGlobalClass is defined in the __globals__ dictionary of function
   200|         0|            0|            0|  0.00%|# 'eg', so it is always recoverable. my_local_scope introduces a new local
   201|         0|            0|            0|  0.00%|# variable scope in the function. Classes defined here are only visible as
   202|         0|            0|            0|  0.00%|# local variables. For the case of MyClassUsedAsVar, it is captured
   203|         0|            0|            0|  0.00%|# because it is used as a variable inside the body of the function, and we
   204|         0|            0|            0|  0.00%|# can resolve it using the captures returned from `get_closure`. However,
   205|         0|            0|            0|  0.00%|# the type annotations are not captured by the closure. In Python
   206|         0|            0|            0|  0.00%|# 3.0--3.9, the _value_ of MyClass and MyGlobalClass will be available as
   207|         0|            0|            0|  0.00%|# annotations on `eg``, but starting in Python 4.0, they will represented as
   208|         0|            0|            0|  0.00%|# strings and no longer present. Furthermore, since the body of `eg` does
   209|         0|            0|            0|  0.00%|# not reference those names, they do not appear in the list of closed over
   210|         0|            0|            0|  0.00%|# variables. In Python 2.x, type annotations are in comments, leading to a
   211|         0|            0|            0|  0.00%|# similar situation where their definitions are not available. We anticipate
   212|         0|            0|            0|  0.00%|# that most users will not run into this issue because their modules and
   213|         0|            0|            0|  0.00%|# functions will be defined at a global scope like MyGlobalClass. In cases
   214|         0|            0|            0|  0.00%|# where they are not, it is possible to work around issues by declaring the
   215|         0|            0|            0|  0.00%|# values global in the function.
   216|         0|            0|            0|  0.00%|# In Python 3.9 declaring class as global will make it invisible to
   217|         0|            0|            0|  0.00%|# `inspect.getsource`, see https://bugs.python.org/issue42666 .
   218|         0|            0|            0|  0.00%|# This could be worked around by manualy adding it to `global()` dictionary.
   219|         0|            0|            0|  0.00%|
   220|         0|            0|            0|  0.00%|
   221|         0|            0|            0|  0.00%|
   222|         0|            0|            0|  0.00%|def createResolutionCallbackFromClosure(fn):
   223|         0|            0|            0|  0.00%|    """
   224|         0|            0|            0|  0.00%|    Create a resolutionCallback by introspecting the function instead of
   225|         0|            0|            0|  0.00%|    looking up the stack for the enclosing scope
   226|         0|            0|            0|  0.00%|    """
   227|         0|            0|            0|  0.00%|    closure = get_closure(fn)
   228|         0|            0|            0|  0.00%|
   229|         0|            0|            0|  0.00%|    class closure_lookup(object):
   230|         0|            0|            0|  0.00%|        # This is a class since `closure` is a dict and it's easier in
   231|         0|            0|            0|  0.00%|        # `env_helper` if everything just works with `getattr` calls
   232|         0|            0|            0|  0.00%|        def __getattr__(self, key):
   233|         0|            0|            0|  0.00%|            if key in closure:
   234|         0|            0|            0|  0.00%|                return closure[key]
   235|         0|            0|            0|  0.00%|            elif hasattr(typing, key):
   236|         0|            0|            0|  0.00%|                return getattr(typing, key)
   237|         0|            0|            0|  0.00%|            elif hasattr(builtins, key):
   238|         0|            0|            0|  0.00%|                return getattr(builtins, key)
   239|         0|            0|            0|  0.00%|            return None
   240|         0|            0|            0|  0.00%|
   241|         0|            0|            0|  0.00%|    return createResolutionCallbackFromEnv(closure_lookup())
   242|         0|            0|            0|  0.00%|
   243|         0|            0|            0|  0.00%|
   244|         0|            0|            0|  0.00%|def can_compile_class(cls) -> bool:
   245|         0|            0|            0|  0.00%|    # If any of the functions on a type don't have a code object, this type can't
   246|         0|            0|            0|  0.00%|    # be compiled and is probably a builtin / bound from C
   247|         0|            0|            0|  0.00%|    if is_ignored_fn(cls):
   248|         0|            0|            0|  0.00%|        return False
   249|         0|            0|            0|  0.00%|
   250|         0|            0|            0|  0.00%|    # Ignore the following list of built-in classes.
   251|         0|            0|            0|  0.00%|    ignored_builtin_classes = (torch.nn.Module, tuple, list, Exception)
   252|         0|            0|            0|  0.00%|    if issubclass(cls, ignored_builtin_classes):
   253|         0|            0|            0|  0.00%|        return False
   254|         0|            0|            0|  0.00%|
   255|         0|            0|            0|  0.00%|    names = cls.__dict__
   256|         0|            0|            0|  0.00%|    fns = [getattr(cls, name) for name in names if inspect.isroutine(getattr(cls, name, None))]
   257|         0|            0|            0|  0.00%|    has_code = [hasattr(fn, '__code__') for fn in fns]
   258|         0|            0|            0|  0.00%|    return all(has_code)
   259|         0|            0|            0|  0.00%|
   260|         0|            0|            0|  0.00%|
   261|         0|            0|            0|  0.00%|def get_callable_argument_names(fn) -> List[str]:
   262|         0|            0|            0|  0.00%|    """
   263|         0|            0|            0|  0.00%|    Gets names of all POSITIONAL_OR_KEYWORD arguments for callable `fn`.
   264|         0|            0|            0|  0.00%|    Returns an empty list when other types of arguments are present.
   265|         0|            0|            0|  0.00%|
   266|         0|            0|            0|  0.00%|    This is used by `torch.jit.trace` to assign meaningful argument names to
   267|         0|            0|            0|  0.00%|    traced functions and modules.
   268|         0|            0|            0|  0.00%|
   269|         0|            0|            0|  0.00%|    Args:
   270|         0|            0|            0|  0.00%|        fn: A callable.
   271|         0|            0|            0|  0.00%|    Returns:
   272|         0|            0|            0|  0.00%|        Argument names: List[str]
   273|         0|            0|            0|  0.00%|    """
   274|         0|            0|            0|  0.00%|    # inspect.signature may fail, give up in that case.
   275|         0|            0|            0|  0.00%|    try:
   276|         0|            0|            0|  0.00%|        callable_signature = inspect.signature(fn)
   277|         0|            0|            0|  0.00%|    except Exception:
   278|         0|            0|            0|  0.00%|        return []
   279|         0|            0|            0|  0.00%|
   280|         0|            0|            0|  0.00%|    argument_names = []
   281|         0|            0|            0|  0.00%|    for name, param in callable_signature.parameters.items():
   282|         0|            0|            0|  0.00%|        # All four other types of arguments do not map to individual values
   283|         0|            0|            0|  0.00%|        # with a keyword as name.
   284|         0|            0|            0|  0.00%|        if not param.kind == param.POSITIONAL_OR_KEYWORD:
   285|         0|            0|            0|  0.00%|            return []
   286|         0|            0|            0|  0.00%|
   287|         0|            0|            0|  0.00%|        argument_names.append(name)
   288|         0|            0|            0|  0.00%|
   289|         0|            0|            0|  0.00%|    return argument_names
   290|         0|            0|            0|  0.00%|
   291|         0|            0|            0|  0.00%|
   292|         0|            0|            0|  0.00%|def get_annotation_str(annotation):
   293|         0|            0|            0|  0.00%|    """
   294|         0|            0|            0|  0.00%|    Convert an AST node containing a type annotation to the string present in the source
   295|         0|            0|            0|  0.00%|    that represents the same annotation.
   296|         0|            0|            0|  0.00%|    """
   297|         0|            0|            0|  0.00%|    if isinstance(annotation, ast.Name):
   298|         0|            0|            0|  0.00%|        return annotation.id
   299|         0|            0|            0|  0.00%|    elif isinstance(annotation, ast.Attribute):
   300|         0|            0|            0|  0.00%|        return '.'.join([get_annotation_str(annotation.value), annotation.attr])
   301|         0|            0|            0|  0.00%|    elif isinstance(annotation, ast.Subscript):
   302|         0|            0|            0|  0.00%|        # In Python3.9+ subscript indicies are not wrapped in ast.Index
   303|         0|            0|            0|  0.00%|        subscript_slice = annotation.slice if sys.version_info >= (3, 9) else annotation.slice.value  # type: ignore[attr-defined]
   304|         0|            0|            0|  0.00%|        return f"{get_annotation_str(annotation.value)}[{get_annotation_str(subscript_slice)}]"
   305|         0|            0|            0|  0.00%|    elif isinstance(annotation, ast.Tuple):
   306|         0|            0|            0|  0.00%|        return ','.join([get_annotation_str(elt) for elt in annotation.elts])
   307|         0|            0|            0|  0.00%|    elif isinstance(annotation, ast.Constant) or isinstance(annotation, ast.NameConstant):
   308|         0|            0|            0|  0.00%|        return f"{annotation.value}"
   309|         0|            0|            0|  0.00%|
   310|         0|            0|            0|  0.00%|    # If an AST node is not handled here, it's probably handled in ScriptTypeParser.
   311|         0|            0|            0|  0.00%|    return None
   312|         0|            0|            0|  0.00%|
   313|         0|            0|            0|  0.00%|
   314|         0|            0|            0|  0.00%|def get_type_hint_captures(fn):
   315|         0|            0|            0|  0.00%|    """
   316|         0|            0|            0|  0.00%|    Get a dictionary containing type resolution mappings necessary to resolve types
   317|         0|            0|            0|  0.00%|    for the literal annotations on 'fn'. These are not considered to be closed-over by fn
   318|         0|            0|            0|  0.00%|    and must be obtained separately (e.g. using this function).
   319|         0|            0|            0|  0.00%|
   320|         0|            0|            0|  0.00%|    Args:
   321|         0|            0|            0|  0.00%|        fn: A callable.
   322|         0|            0|            0|  0.00%|    Returns:
   323|         0|            0|            0|  0.00%|        A Dict[str, Any] containing a mapping from the literal annotations used on
   324|         0|            0|            0|  0.00%|        fn to the Python objects they refer to.
   325|         0|            0|            0|  0.00%|    """
   326|         0|            0|            0|  0.00%|    # Gather a dictionary of parameter name -> type, skipping any parameters whose annotated
   327|         0|            0|            0|  0.00%|    # types are strings. These are only understood by TorchScript in the context of a type annotation
   328|         0|            0|            0|  0.00%|    # that refers to a class in its own definition, but trying to include a mapping for this in the result
   329|         0|            0|            0|  0.00%|    # function would cause infinite recursion because the class is currently being compiled.
   330|         0|            0|            0|  0.00%|    # In addition, there is logic in ScriptTypeParser to handle this.
   331|         0|            0|            0|  0.00%|    signature = inspect.signature(fn)
   332|         0|            0|            0|  0.00%|    name_to_type = {
   333|         0|            0|            0|  0.00%|        name: parameter.annotation
   334|         0|            0|            0|  0.00%|        for name, parameter in signature.parameters.items()
   335|         0|            0|            0|  0.00%|        if parameter.annotation is not inspect.Parameter.empty and not isinstance(parameter.annotation, str)
   336|         0|            0|            0|  0.00%|    }
   337|         0|            0|            0|  0.00%|
   338|         0|            0|            0|  0.00%|    # Then, get the literal type annotations from the function declaration
   339|         0|            0|            0|  0.00%|    # by source inspection. This accounts for the case in which aliases are used
   340|         0|            0|            0|  0.00%|    # to annotate the arguments (e.g device_t = torch.device, and then d: device_t).
   341|         0|            0|            0|  0.00%|    src = inspect.getsource(fn)
   342|         0|            0|            0|  0.00%|
   343|         0|            0|            0|  0.00%|    # frontend.py cannot be used here because it includes _jit_internal, so use ast instead.
   344|         0|            0|            0|  0.00%|    a = ast.parse(dedent(src))
   345|         0|            0|            0|  0.00%|    if len(a.body) != 1 or not isinstance(a.body[0], ast.FunctionDef):
   346|         0|            0|            0|  0.00%|        raise RuntimeError(f"Expected {fn} to be a function")
   347|         0|            0|            0|  0.00%|    f = a.body[0]
   348|         0|            0|            0|  0.00%|
   349|         0|            0|            0|  0.00%|    # Prepare a dictionary of source annotation -> type, which will be the final result of this function,
   350|         0|            0|            0|  0.00%|    # by using the parsed AST (f) to reconstruct source annotations as strings for each parameter and mapping
   351|         0|            0|            0|  0.00%|    # them to the type object corresponding to the annotation via name_to_type using the parameter name.
   352|         0|            0|            0|  0.00%|    annotation_to_type = {}
   353|         0|            0|            0|  0.00%|
   354|         0|            0|            0|  0.00%|    for arg in f.args.args:
   355|         0|            0|            0|  0.00%|        # Get the source type annotation string for this argument if possible.
   356|         0|            0|            0|  0.00%|        arg_annotation_str = get_annotation_str(arg.annotation) if arg.annotation else None
   357|         0|            0|            0|  0.00%|
   358|         0|            0|            0|  0.00%|        # If the argument has no annotation or get_annotation_str cannot convert it to a string,
   359|         0|            0|            0|  0.00%|        # arg_annotation_str will be None. Skip this arg; ScriptTypeParser will probably handle
   360|         0|            0|            0|  0.00%|        # this in the latter case.
   361|         0|            0|            0|  0.00%|        if arg_annotation_str is None:
   362|         0|            0|            0|  0.00%|            continue
   363|         0|            0|            0|  0.00%|
   364|         0|            0|            0|  0.00%|        # Insert {arg_annotation_str: type} into annotation_to_type if possible. One reason arg_name may not
   365|         0|            0|            0|  0.00%|        # be present in name_to_type is that the annotation itself is a string and not a type object
   366|         0|            0|            0|  0.00%|        # (common for self-refential annotations in classes). Once again, let ScriptTypeParser handle this.
   367|         0|            0|            0|  0.00%|        arg_name = arg.arg
   368|         0|            0|            0|  0.00%|        if arg_name in name_to_type:
   369|         0|            0|            0|  0.00%|            annotation_to_type[arg_annotation_str] = name_to_type[arg_name]
   370|         0|            0|            0|  0.00%|
   371|         0|            0|            0|  0.00%|    # If there is a valid return annotation, include it in annotation_to_type. As with argument annotations,
   372|         0|            0|            0|  0.00%|    # the literal annotation has to be convertible to a string by get_annotation_str, and the actual type
   373|         0|            0|            0|  0.00%|    # of the annotation cannot be a string.
   374|         0|            0|            0|  0.00%|    literal_return_annotation = get_annotation_str(f.returns)
   375|         0|            0|            0|  0.00%|    valid_literal_annotation = literal_return_annotation is not None
   376|         0|            0|            0|  0.00%|    return_annotation = signature.return_annotation
   377|         0|            0|            0|  0.00%|    valid_return_annotation_type = return_annotation is not inspect.Parameter.empty and not isinstance(return_annotation, str)
   378|         0|            0|            0|  0.00%|    if valid_literal_annotation and valid_return_annotation_type:
   379|         0|            0|            0|  0.00%|        annotation_to_type[literal_return_annotation] = return_annotation
   380|         0|            0|            0|  0.00%|
   381|         0|            0|            0|  0.00%|    return annotation_to_type
   382|         0|            0|            0|  0.00%|
   383|         0|            0|            0|  0.00%|
   384|         0|            0|            0|  0.00%|def createResolutionCallbackForClassMethods(cls):
   385|         0|            0|            0|  0.00%|    """
   386|         0|            0|            0|  0.00%|    This looks at all the methods defined in a class and pulls their closed-over
   387|         0|            0|            0|  0.00%|    variables into a dictionary and uses that to resolve variables.
   388|         0|            0|            0|  0.00%|    """
   389|         0|            0|            0|  0.00%|    # cls is a type here, so `ismethod` is false since the methods on the type
   390|         0|            0|            0|  0.00%|    # aren't bound to anything, so Python treats them as regular functions
   391|         0|            0|            0|  0.00%|    fns = [getattr(cls, name) for name in cls.__dict__ if inspect.isroutine(getattr(cls, name))]
   392|         0|            0|            0|  0.00%|    captures = {}
   393|         0|            0|            0|  0.00%|
   394|         0|            0|            0|  0.00%|    for fn in fns:
   395|         0|            0|            0|  0.00%|        captures.update(get_closure(fn))
   396|         0|            0|            0|  0.00%|        captures.update(get_type_hint_captures(fn))
   397|         0|            0|            0|  0.00%|
   398|         0|            0|            0|  0.00%|    def lookup_in_class(key):
   399|         0|            0|            0|  0.00%|        if key in captures:
   400|         0|            0|            0|  0.00%|            return captures[key]
   401|         0|            0|            0|  0.00%|        else:
   402|         0|            0|            0|  0.00%|            return getattr(builtins, key, None)
   403|         0|            0|            0|  0.00%|
   404|         0|            0|            0|  0.00%|    return lookup_in_class
   405|         0|            0|            0|  0.00%|
   406|         0|            0|            0|  0.00%|
   407|         0|            0|            0|  0.00%|def boolean_dispatch(arg_name, arg_index, default, if_true, if_false, module_name, func_name):
   408|         0|            0|            0|  0.00%|    """
   409|         0|            0|            0|  0.00%|    Dispatches to either of 2 script functions based on a boolean argument.
   410|         0|            0|            0|  0.00%|    In TorchScript, the boolean argument must be constant so that the correct
   411|         0|            0|            0|  0.00%|    function to use can be determined at compile time.
   412|         0|            0|            0|  0.00%|    """
   413|         0|            0|            0|  0.00%|    def fn(*args, **kwargs):
   414|         0|            0|            0|  0.00%|        dispatch_flag = False
   415|         0|            0|            0|  0.00%|        if arg_name in kwargs:
   416|         0|            0|            0|  0.00%|            dispatch_flag = kwargs[arg_name]
   417|         0|            0|            0|  0.00%|        elif arg_index < len(args):
   418|         0|            0|            0|  0.00%|            dispatch_flag = args[arg_index]
   419|         0|            0|            0|  0.00%|
   420|         0|            0|            0|  0.00%|        if dispatch_flag:
   421|         0|            0|            0|  0.00%|            return if_true(*args, **kwargs)
   422|         0|            0|            0|  0.00%|        else:
   423|         0|            0|            0|  0.00%|            return if_false(*args, **kwargs)
   424|         0|            0|            0|  0.00%|
   425|         0|            0|            0|  0.00%|    if if_true.__doc__ is None and if_false.__doc__ is not None:
   426|         0|            0|            0|  0.00%|        doc = if_false.__doc__
   427|         0|            0|            0|  0.00%|        if_true.__doc__ = doc
   428|         0|            0|            0|  0.00%|    elif if_false.__doc__ is None and if_true.__doc__ is not None:
   429|         0|            0|            0|  0.00%|        doc = if_true.__doc__
   430|         0|            0|            0|  0.00%|        if_false.__doc__ = doc
   431|         0|            0|            0|  0.00%|    elif if_false.__doc__ is None and if_true.__doc__ is None:
   432|         0|            0|            0|  0.00%|        # neither function has a docstring
   433|         0|            0|            0|  0.00%|        doc = None
   434|         0|            0|            0|  0.00%|    else:
   435|         0|            0|            0|  0.00%|        raise RuntimeError("only one function can have a docstring")
   436|         0|            0|            0|  0.00%|    fn.__doc__ = doc
   437|         0|            0|            0|  0.00%|
   438|         0|            0|            0|  0.00%|    if module_name is not None:
   439|         0|            0|            0|  0.00%|        fn.__module__ = module_name
   440|         0|            0|            0|  0.00%|    if func_name is not None:
   441|         0|            0|            0|  0.00%|        fn.__name__ = func_name
   442|         0|            0|            0|  0.00%|
   443|         0|            0|            0|  0.00%|    boolean_dispatched[fn] = {
   444|         0|            0|            0|  0.00%|        "if_true": if_true,
   445|         0|            0|            0|  0.00%|        "if_false": if_false,
   446|         0|            0|            0|  0.00%|        "index": arg_index,
   447|         0|            0|            0|  0.00%|        "default": default,
   448|         0|            0|            0|  0.00%|        "arg_name": arg_name
   449|         0|            0|            0|  0.00%|    }
   450|         0|            0|            0|  0.00%|    return fn
   451|         0|            0|            0|  0.00%|
   452|         0|            0|            0|  0.00%|
   453|         0|            0|            0|  0.00%|class FunctionModifiers(object):
   454|         0|            0|            0|  0.00%|    """
   455|         0|            0|            0|  0.00%|    Used to denote the behavior of a function in TorchScript. See export() and
   456|         0|            0|            0|  0.00%|    ignore() for details.
   457|         0|            0|            0|  0.00%|    """
   458|         0|            0|            0|  0.00%|    UNUSED = "unused (ignored and replaced with raising of an exception)"
   459|         0|            0|            0|  0.00%|    IGNORE = "ignore (leave as a call to Python, cannot be torch.jit.save'd)"
   460|         0|            0|            0|  0.00%|    EXPORT = "export (compile this function even if nothing calls it)"
   461|         0|            0|            0|  0.00%|    DEFAULT = "default (compile if called from a exported function / forward)"
   462|         0|            0|            0|  0.00%|    COPY_TO_SCRIPT_WRAPPER = \
   463|         0|            0|            0|  0.00%|        "if this method is not scripted, copy the python method onto the scripted model"
   464|         0|            0|            0|  0.00%|
   465|         0|            0|            0|  0.00%|
   466|         0|            0|            0|  0.00%|def export(fn):
   467|         0|            0|            0|  0.00%|    """
   468|         0|            0|            0|  0.00%|    This decorator indicates that a method on an ``nn.Module`` is used as an entry point into a
   469|         0|            0|            0|  0.00%|    :class:`ScriptModule` and should be compiled.
   470|         0|            0|            0|  0.00%|
   471|         0|            0|            0|  0.00%|    ``forward`` implicitly is assumed to be an entry point, so it does not need this decorator.
   472|         0|            0|            0|  0.00%|    Functions and methods called from ``forward`` are compiled as they are seen
   473|         0|            0|            0|  0.00%|    by the compiler, so they do not need this decorator either.
   474|         0|            0|            0|  0.00%|
   475|         0|            0|            0|  0.00%|    Example (using ``@torch.jit.export`` on a method):
   476|         0|            0|            0|  0.00%|
   477|         0|            0|            0|  0.00%|    .. testcode::
   478|         0|            0|            0|  0.00%|
   479|         0|            0|            0|  0.00%|        import torch
   480|         0|            0|            0|  0.00%|        import torch.nn as nn
   481|         0|            0|            0|  0.00%|
   482|         0|            0|            0|  0.00%|        class MyModule(nn.Module):
   483|         0|            0|            0|  0.00%|            def implicitly_compiled_method(self, x):
   484|         0|            0|            0|  0.00%|                return x + 99
   485|         0|            0|            0|  0.00%|
   486|         0|            0|            0|  0.00%|            # `forward` is implicitly decorated with `@torch.jit.export`,
   487|         0|            0|            0|  0.00%|            # so adding it here would have no effect
   488|         0|            0|            0|  0.00%|            def forward(self, x):
   489|         0|            0|            0|  0.00%|                return x + 10
   490|         0|            0|            0|  0.00%|
   491|         0|            0|            0|  0.00%|            @torch.jit.export
   492|         0|            0|            0|  0.00%|            def another_forward(self, x):
   493|         0|            0|            0|  0.00%|                # When the compiler sees this call, it will compile
   494|         0|            0|            0|  0.00%|                # `implicitly_compiled_method`
   495|         0|            0|            0|  0.00%|                return self.implicitly_compiled_method(x)
   496|         0|            0|            0|  0.00%|
   497|         0|            0|            0|  0.00%|            def unused_method(self, x):
   498|         0|            0|            0|  0.00%|                return x - 20
   499|         0|            0|            0|  0.00%|
   500|         0|            0|            0|  0.00%|        # `m` will contain compiled methods:
   501|         0|            0|            0|  0.00%|        #     `forward`
   502|         0|            0|            0|  0.00%|        #     `another_forward`
   503|         0|            0|            0|  0.00%|        #     `implicitly_compiled_method`
   504|         0|            0|            0|  0.00%|        # `unused_method` will not be compiled since it was not called from
   505|         0|            0|            0|  0.00%|        # any compiled methods and wasn't decorated with `@torch.jit.export`
   506|         0|            0|            0|  0.00%|        m = torch.jit.script(MyModule())
   507|         0|            0|            0|  0.00%|    """
   508|         0|            0|            0|  0.00%|    fn._torchscript_modifier = FunctionModifiers.EXPORT
   509|         0|            0|            0|  0.00%|    return fn
   510|         0|            0|            0|  0.00%|
   511|         0|            0|            0|  0.00%|
   512|         0|            0|            0|  0.00%|def unused(fn):
   513|         0|            0|            0|  0.00%|    """
   514|         0|            0|            0|  0.00%|    This decorator indicates to the compiler that a function or method should
   515|         0|            0|            0|  0.00%|    be ignored and replaced with the raising of an exception. This allows you
   516|         0|            0|            0|  0.00%|    to leave code in your model that is not yet TorchScript compatible and still
   517|         0|            0|            0|  0.00%|    export your model.
   518|         0|            0|            0|  0.00%|
   519|         0|            0|            0|  0.00%|        Example (using ``@torch.jit.unused`` on a method)::
   520|         0|            0|            0|  0.00%|
   521|         0|            0|            0|  0.00%|            import torch
   522|         0|            0|            0|  0.00%|            import torch.nn as nn
   523|         0|            0|            0|  0.00%|
   524|         0|            0|            0|  0.00%|            class MyModule(nn.Module):
   525|         0|            0|            0|  0.00%|                def __init__(self, use_memory_efficient):
   526|         0|            0|            0|  0.00%|                    super(MyModule, self).__init__()
   527|         0|            0|            0|  0.00%|                    self.use_memory_efficient = use_memory_efficient
   528|         0|            0|            0|  0.00%|
   529|         0|            0|            0|  0.00%|                @torch.jit.unused
   530|         0|            0|            0|  0.00%|                def memory_efficient(self, x):
   531|         0|            0|            0|  0.00%|                    import pdb
   532|         0|            0|            0|  0.00%|                    pdb.set_trace()
   533|         0|            0|            0|  0.00%|                    return x + 10
   534|         0|            0|            0|  0.00%|
   535|         0|            0|            0|  0.00%|                def forward(self, x):
   536|         0|            0|            0|  0.00%|                    # Use not-yet-scriptable memory efficient mode
   537|         0|            0|            0|  0.00%|                    if self.use_memory_efficient:
   538|         0|            0|            0|  0.00%|                        return self.memory_efficient(x)
   539|         0|            0|            0|  0.00%|                    else:
   540|         0|            0|            0|  0.00%|                        return x + 10
   541|         0|            0|            0|  0.00%|
   542|         0|            0|            0|  0.00%|            m = torch.jit.script(MyModule(use_memory_efficient=False))
   543|         0|            0|            0|  0.00%|            m.save("m.pt")
   544|         0|            0|            0|  0.00%|
   545|         0|            0|            0|  0.00%|            m = torch.jit.script(MyModule(use_memory_efficient=True))
   546|         0|            0|            0|  0.00%|            # exception raised
   547|         0|            0|            0|  0.00%|            m(torch.rand(100))
   548|         0|            0|            0|  0.00%|    """
   549|         0|            0|            0|  0.00%|    if isinstance(fn, property):
   550|         0|            0|            0|  0.00%|        prop = fn
   551|         0|            0|            0|  0.00%|        setattr(prop.fget, "_torchscript_modifier", FunctionModifiers.UNUSED)  # noqa: B010
   552|         0|            0|            0|  0.00%|
   553|         0|            0|            0|  0.00%|        if prop.fset:
   554|         0|            0|            0|  0.00%|            setattr(prop.fset, "_torchscript_modifier", FunctionModifiers.UNUSED)  # noqa: B010
   555|         0|            0|            0|  0.00%|
   556|         0|            0|            0|  0.00%|        return prop
   557|         0|            0|            0|  0.00%|
   558|         0|            0|            0|  0.00%|    fn._torchscript_modifier = FunctionModifiers.UNUSED
   559|         0|            0|            0|  0.00%|    return fn
   560|         0|            0|            0|  0.00%|
   561|         0|            0|            0|  0.00%|# No op context manager from python side
   562|         0|            0|            0|  0.00%|class _IgnoreContextManager(contextlib.AbstractContextManager):
   563|         0|            0|            0|  0.00%|    def __init__(self, **kwargs):
   564|         0|            0|            0|  0.00%|        pass
   565|         0|            0|            0|  0.00%|
   566|         0|            0|            0|  0.00%|    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:
   567|         0|            0|            0|  0.00%|        pass
   568|         0|            0|            0|  0.00%|
   569|         0|            0|            0|  0.00%|def ignore(drop=False, **kwargs):
   570|         0|            0|            0|  0.00%|    """
   571|         0|            0|            0|  0.00%|    This decorator indicates to the compiler that a function or method should
   572|         0|            0|            0|  0.00%|    be ignored and left as a Python function. This allows you to leave code in
   573|         0|            0|            0|  0.00%|    your model that is not yet TorchScript compatible. If called from TorchScript,
   574|         0|            0|            0|  0.00%|    ignored functions will dispatch the call to the Python interpreter. Models with ignored
   575|         0|            0|            0|  0.00%|    functions cannot be exported; use :func:`@torch.jit.unused <torch.jit.unused>` instead.
   576|         0|            0|            0|  0.00%|
   577|         0|            0|            0|  0.00%|    Example (using ``@torch.jit.ignore`` on a method)::
   578|         0|            0|            0|  0.00%|
   579|         0|            0|            0|  0.00%|        import torch
   580|         0|            0|            0|  0.00%|        import torch.nn as nn
   581|         0|            0|            0|  0.00%|
   582|         0|            0|            0|  0.00%|        class MyModule(nn.Module):
   583|         0|            0|            0|  0.00%|            @torch.jit.ignore
   584|         0|            0|            0|  0.00%|            def debugger(self, x):
   585|         0|            0|            0|  0.00%|                import pdb
   586|         0|            0|            0|  0.00%|                pdb.set_trace()
   587|         0|            0|            0|  0.00%|
   588|         0|            0|            0|  0.00%|            def forward(self, x):
   589|         0|            0|            0|  0.00%|                x += 10
   590|         0|            0|            0|  0.00%|                # The compiler would normally try to compile `debugger`,
   591|         0|            0|            0|  0.00%|                # but since it is `@ignore`d, it will be left as a call
   592|         0|            0|            0|  0.00%|                # to Python
   593|         0|            0|            0|  0.00%|                self.debugger(x)
   594|         0|            0|            0|  0.00%|                return x
   595|         0|            0|            0|  0.00%|
   596|         0|            0|            0|  0.00%|        m = torch.jit.script(MyModule())
   597|         0|            0|            0|  0.00%|
   598|         0|            0|            0|  0.00%|        # Error! The call `debugger` cannot be saved since it calls into Python
   599|         0|            0|            0|  0.00%|        m.save("m.pt")
   600|         0|            0|            0|  0.00%|
   601|         0|            0|            0|  0.00%|    Example (using ``@torch.jit.ignore(drop=True)`` on a method):
   602|         0|            0|            0|  0.00%|
   603|         0|            0|            0|  0.00%|    .. testcode::
   604|         0|            0|            0|  0.00%|
   605|         0|            0|            0|  0.00%|        import torch
   606|         0|            0|            0|  0.00%|        import torch.nn as nn
   607|         0|            0|            0|  0.00%|
   608|         0|            0|            0|  0.00%|        class MyModule(nn.Module):
   609|         0|            0|            0|  0.00%|            @torch.jit.ignore(drop=True)
   610|         0|            0|            0|  0.00%|            def training_method(self, x):
   611|         0|            0|            0|  0.00%|                import pdb
   612|         0|            0|            0|  0.00%|                pdb.set_trace()
   613|         0|            0|            0|  0.00%|
   614|         0|            0|            0|  0.00%|            def forward(self, x):
   615|         0|            0|            0|  0.00%|                if self.training:
   616|         0|            0|            0|  0.00%|                    self.training_method(x)
   617|         0|            0|            0|  0.00%|                return x
   618|         0|            0|            0|  0.00%|
   619|         0|            0|            0|  0.00%|        m = torch.jit.script(MyModule())
   620|         0|            0|            0|  0.00%|
   621|         0|            0|            0|  0.00%|        # This is OK since `training_method` is not saved, the call is replaced
   622|         0|            0|            0|  0.00%|        # with a `raise`.
   623|         0|            0|            0|  0.00%|        m.save("m.pt")
   624|         0|            0|            0|  0.00%|
   625|         0|            0|            0|  0.00%|    .. testcleanup::
   626|         0|            0|            0|  0.00%|
   627|         0|            0|            0|  0.00%|        import os
   628|         0|            0|            0|  0.00%|        os.remove('m.pt')
   629|         0|            0|            0|  0.00%|    """
   630|         0|            0|            0|  0.00%|
   631|         0|            0|            0|  0.00%|    if callable(drop):
   632|         0|            0|            0|  0.00%|        # used without any args, so drop is actually a function
   633|         0|            0|            0|  0.00%|        #   @torch.jit.ignore
   634|         0|            0|            0|  0.00%|        #   def fn(...):
   635|         0|            0|            0|  0.00%|        fn = drop
   636|         0|            0|            0|  0.00%|        fn._torchscript_modifier = FunctionModifiers.IGNORE
   637|         0|            0|            0|  0.00%|        return fn
   638|         0|            0|            0|  0.00%|
   639|         0|            0|            0|  0.00%|    if not isinstance(drop, bool):
   640|         0|            0|            0|  0.00%|        raise RuntimeError("Argument to @torch.jit.ignore must be a bool or "
   641|         0|            0|            0|  0.00%|                           f"a function but got {drop}")
   642|         0|            0|            0|  0.00%|
   643|         0|            0|            0|  0.00%|    # for backwards compat
   644|         0|            0|            0|  0.00%|    drop_on_export = kwargs.pop("drop_on_export", None)
   645|         0|            0|            0|  0.00%|    if drop_on_export:
   646|         0|            0|            0|  0.00%|        warnings.warn("ignore(drop_on_export=True) has been deprecated. TorchScript will now drop the function "
   647|         0|            0|            0|  0.00%|                      "call on compilation. Use torch.jit.unused now. {}", category=FutureWarning)
   648|         0|            0|            0|  0.00%|
   649|         0|            0|            0|  0.00%|        drop = drop_on_export
   650|         0|            0|            0|  0.00%|    elif drop:
   651|         0|            0|            0|  0.00%|        warnings.warn("ignore(True) has been deprecated. TorchScript will now drop the function "
   652|         0|            0|            0|  0.00%|                      "call on compilation. Use torch.jit.unused now. {}", category=FutureWarning)
   653|         0|            0|            0|  0.00%|
   654|         0|            0|            0|  0.00%|    def decorator(fn):
   655|         0|            0|            0|  0.00%|        if drop:
   656|         0|            0|            0|  0.00%|            fn._torchscript_modifier = FunctionModifiers.UNUSED
   657|         0|            0|            0|  0.00%|        else:
   658|         0|            0|            0|  0.00%|            fn._torchscript_modifier = FunctionModifiers.IGNORE
   659|         0|            0|            0|  0.00%|        return fn
   660|         0|            0|            0|  0.00%|    return decorator
   661|         0|            0|            0|  0.00%|
   662|         0|            0|            0|  0.00%|
   663|         0|            0|            0|  0.00%|def _copy_to_script_wrapper(fn):
   664|         0|            0|            0|  0.00%|    fn._torchscript_modifier = FunctionModifiers.COPY_TO_SCRIPT_WRAPPER
   665|         0|            0|            0|  0.00%|    return fn
   666|         0|            0|            0|  0.00%|
   667|         0|            0|            0|  0.00%|def module_has_exports(mod):
   668|         0|            0|            0|  0.00%|    for name in dir(mod):
   669|         0|            0|            0|  0.00%|        if hasattr(mod, name):
   670|         0|            0|            0|  0.00%|            item = getattr(mod, name)
   671|         0|            0|            0|  0.00%|            if callable(item):
   672|         0|            0|            0|  0.00%|                if get_torchscript_modifier(item) is FunctionModifiers.EXPORT:
   673|         0|            0|            0|  0.00%|                    return True
   674|         0|            0|            0|  0.00%|    return False
   675|         0|            0|            0|  0.00%|
   676|         0|            0|            0|  0.00%|
   677|         0|            0|            0|  0.00%|# WARNING: should_drop is currently being used by our JIT code coverage plug-in to mark JIT'd code as covered. If you
   678|         0|            0|            0|  0.00%|# rename this function, please update references in tools/coverage_plugins_package/src/coverage_plugins/jit_plugin.py to
   679|         0|            0|            0|  0.00%|# allow JIT'd code to still be covered.
   680|         0|            0|            0|  0.00%|def should_drop(fn) -> bool:
   681|         0|            0|            0|  0.00%|    attr = get_torchscript_modifier(fn)
   682|         0|            0|            0|  0.00%|    if attr is None:
   683|         0|            0|            0|  0.00%|        return False
   684|         0|            0|            0|  0.00%|    return attr is FunctionModifiers.UNUSED
   685|         0|            0|            0|  0.00%|
   686|         0|            0|            0|  0.00%|
   687|         0|            0|            0|  0.00%|def is_ignored_fn(fn) -> bool:
   688|         0|            0|            0|  0.00%|    mod = get_torchscript_modifier(fn)
   689|         0|            0|            0|  0.00%|    return mod is FunctionModifiers.UNUSED or mod is FunctionModifiers.IGNORE
   690|         0|            0|            0|  0.00%|
   691|         0|            0|            0|  0.00%|
   692|         0|            0|            0|  0.00%|def is_static_fn(cls, fn) -> bool:
   693|         0|            0|            0|  0.00%|    return isinstance(inspect.getattr_static(cls, fn, default=None), staticmethod)
   694|         0|            0|            0|  0.00%|
   695|         0|            0|            0|  0.00%|def get_static_fn(cls, fn):
   696|         0|            0|            0|  0.00%|    return inspect.getattr_static(cls, fn).__func__
   697|         0|            0|            0|  0.00%|
   698|         0|            0|            0|  0.00%|
   699|         0|            0|            0|  0.00%|def get_torchscript_modifier(fn):
   700|         0|            0|            0|  0.00%|    if not callable(fn):
   701|         0|            0|            0|  0.00%|        return None
   702|         0|            0|            0|  0.00%|    if hasattr(fn, '__func__'):
   703|         0|            0|            0|  0.00%|        fn = fn.__func__
   704|         0|            0|            0|  0.00%|    return getattr(fn, '_torchscript_modifier', FunctionModifiers.DEFAULT)
   705|         0|            0|            0|  0.00%|
   706|         0|            0|            0|  0.00%|def copy_torchscript_modifier(orig, new) -> None:
   707|         0|            0|            0|  0.00%|    attr = get_torchscript_modifier(orig)
   708|         0|            0|            0|  0.00%|    if attr is None:
   709|         0|            0|            0|  0.00%|        return
   710|         0|            0|            0|  0.00%|    new._torchscript_modifier = attr
   711|         0|            0|            0|  0.00%|
   712|         0|            0|            0|  0.00%|# overloading registration
   713|         0|            0|            0|  0.00%|# overloads get registered in this file, and compiled in torch/jit/__init__.py
   714|         0|            0|            0|  0.00%|# so that they can be imported in nn/functional.py without an import cycle
   715|         0|            0|            0|  0.00%|
   716|         0|            0|            0|  0.00%|# qualified_name => list[overload_functions]
   717|         0|            0|            0|  0.00%|_overloaded_fns : Dict[str, List[Callable]] = {}  # noqa: T484
   718|         0|            0|            0|  0.00%|
   719|         0|            0|            0|  0.00%|
   720|         0|            0|            0|  0.00%|_OVERLOAD_EXAMPLE = '''
   721|         0|            0|            0|  0.00%|Example usage of overload function:
   722|         0|            0|            0|  0.00%|@torch.jit._overload
   723|         0|            0|            0|  0.00%|def my_function(x: type0) -> type0: # decl 1
   724|         0|            0|            0|  0.00%|    pass
   725|         0|            0|            0|  0.00%|
   726|         0|            0|            0|  0.00%|@torch.jit._overload
   727|         0|            0|            0|  0.00%|def my_function(x: type1) -> type1: # decl 2
   728|         0|            0|            0|  0.00%|    pass
   729|         0|            0|            0|  0.00%|
   730|         0|            0|            0|  0.00%|def my_function(x):                 # implementation
   731|         0|            0|            0|  0.00%|    if isinstance(x, type0):
   732|         0|            0|            0|  0.00%|        return x
   733|         0|            0|            0|  0.00%|    elif isinstance(x, type1):
   734|         0|            0|            0|  0.00%|        return x
   735|         0|            0|            0|  0.00%|'''
   736|         0|            0|            0|  0.00%|
   737|         0|            0|            0|  0.00%|def get_overload_no_implementation_error_message(kind, obj):
   738|         0|            0|            0|  0.00%|    sourcelines, file_lineno, filename = get_source_lines_and_file(obj)
   739|         0|            0|            0|  0.00%|    return (
   740|         0|            0|            0|  0.00%|        f'Implementation for the {kind} "{_qualified_name(obj)}" is missing. Please make '
   741|         0|            0|            0|  0.00%|        f'sure a definition is provided and defined after all overload declarations.\n'
   742|         0|            0|            0|  0.00%|        f'File "{filename}", line {file_lineno}:\n' + ''.join(sourcelines) + "\n" + _OVERLOAD_EXAMPLE
   743|         0|            0|            0|  0.00%|    )
   744|         0|            0|            0|  0.00%|
   745|         0|            0|            0|  0.00%|def _check_overload_body(func):
   746|         0|            0|            0|  0.00%|    try:
   747|         0|            0|            0|  0.00%|        parsed_def = parse_def(func)
   748|         0|            0|            0|  0.00%|    except OSError as e:
   749|         0|            0|            0|  0.00%|        # Parsing the function definition can raise an OSError if source is unavailable.
   750|         0|            0|            0|  0.00%|        # Since this is just an initial check, just raise a warning if this is the case.
   751|         0|            0|            0|  0.00%|        warnings.warn(f"Unable to retrieve source for @torch.jit._overload function: {func}.")
   752|         0|            0|            0|  0.00%|        return
   753|         0|            0|            0|  0.00%|
   754|         0|            0|            0|  0.00%|    body = parsed_def.ast.body[0].body
   755|         0|            0|            0|  0.00%|
   756|         0|            0|            0|  0.00%|    def is_pass(x):
   757|         0|            0|            0|  0.00%|        return isinstance(x, ast.Pass)
   758|         0|            0|            0|  0.00%|
   759|         0|            0|            0|  0.00%|    def is_ellipsis(x):
   760|         0|            0|            0|  0.00%|        return isinstance(x, ast.Expr) and isinstance(x.value, ast.Ellipsis)
   761|         0|            0|            0|  0.00%|
   762|         0|            0|            0|  0.00%|    if len(body) != 1 or not (is_pass(body[0]) or is_ellipsis(body[0])):
   763|         0|            0|            0|  0.00%|        msg = "Only `pass` statement or `...` can be the body of overload declaration:\n"
   764|         0|            0|            0|  0.00%|        msg += '\n'.join(parsed_def.source.split("\n")[:3])
   765|         0|            0|            0|  0.00%|        msg += " <- Expecting `pass` or `...` here!\n" + _OVERLOAD_EXAMPLE
   766|         0|            0|            0|  0.00%|        raise RuntimeError(msg)
   767|         0|            0|            0|  0.00%|
   768|         0|            0|            0|  0.00%|def _overload(func):
   769|         0|            0|            0|  0.00%|    _check_overload_body(func)
   770|         0|            0|            0|  0.00%|    qual_name = _qualified_name(func)
   771|         0|            0|            0|  0.00%|    global _overloaded_fns
   772|         0|            0|            0|  0.00%|    fn_overload_list = _overloaded_fns.get(qual_name)
   773|         0|            0|            0|  0.00%|    if fn_overload_list is None:
   774|         0|            0|            0|  0.00%|        fn_overload_list = []
   775|         0|            0|            0|  0.00%|        _overloaded_fns[qual_name] = fn_overload_list
   776|         0|            0|            0|  0.00%|    fn_overload_list.append(func)
   777|         0|            0|            0|  0.00%|    return func
   778|         0|            0|            0|  0.00%|
   779|         0|            0|            0|  0.00%|def _get_fn_overloads(qual_name):
   780|         0|            0|            0|  0.00%|    return _overloaded_fns.get(qual_name)
   781|         0|            0|            0|  0.00%|
   782|         0|            0|            0|  0.00%|def _clear_fn_overloads(qual_name) -> None:
   783|         0|            0|            0|  0.00%|    del _overloaded_fns[qual_name]
   784|         0|            0|            0|  0.00%|
   785|         0|            0|            0|  0.00%|def get_class_name_lineno(method) -> Tuple[str, int]:
   786|         0|            0|            0|  0.00%|    current_frame = inspect.currentframe()
   787|         0|            0|            0|  0.00%|
   788|         0|            0|            0|  0.00%|    # one for the get_class_name call, one for _overload_method call
   789|         0|            0|            0|  0.00%|    for i in range(2):
   790|         0|            0|            0|  0.00%|        assert current_frame is not None  # assert current frame is not an Optional[FrameType]
   791|         0|            0|            0|  0.00%|        current_frame = current_frame.f_back
   792|         0|            0|            0|  0.00%|
   793|         0|            0|            0|  0.00%|    assert current_frame is not None  # same here
   794|         0|            0|            0|  0.00%|    class_name = current_frame.f_code.co_name
   795|         0|            0|            0|  0.00%|    line_no = current_frame.f_code.co_firstlineno
   796|         0|            0|            0|  0.00%|    return class_name, line_no
   797|         0|            0|            0|  0.00%|
   798|         0|            0|            0|  0.00%|# At the the point the decorator is applied to class methods the method
   799|         0|            0|            0|  0.00%|# has no reference to its owning class. _qualified_name would not include
   800|         0|            0|            0|  0.00%|# the class it is defined in, so any methods with the same name in the same file
   801|         0|            0|            0|  0.00%|# would have the same _qualified_name, even if they were defined in different
   802|         0|            0|            0|  0.00%|# classes. This problem only exists in python 2.
   803|         0|            0|            0|  0.00%|# We get around this problem by looking at the stack frame and identifying
   804|         0|            0|            0|  0.00%|# the class name, and throwing an error whenever overloads are used
   805|         0|            0|            0|  0.00%|# when modules of the same name are in the same file
   806|         0|            0|            0|  0.00%|
   807|         0|            0|            0|  0.00%|# qualified_name => class name => list[overload_functions]
   808|         0|            0|            0|  0.00%|_overloaded_methods : Dict[str, Dict[str, List[Callable]]] = {}  # noqa: T484
   809|         0|            0|            0|  0.00%|
   810|         0|            0|            0|  0.00%|
   811|         0|            0|            0|  0.00%|# (qualified_name, class name) => class_fileno
   812|         0|            0|            0|  0.00%|_overloaded_method_class_fileno = {}
   813|         0|            0|            0|  0.00%|
   814|         0|            0|            0|  0.00%|def _overload_method(func):
   815|         0|            0|            0|  0.00%|    _check_overload_body(func)
   816|         0|            0|            0|  0.00%|    qual_name = _qualified_name(func)
   817|         0|            0|            0|  0.00%|    global _overloaded_methods
   818|         0|            0|            0|  0.00%|    class_name_map = _overloaded_methods.get(qual_name, None)
   819|         0|            0|            0|  0.00%|    if class_name_map is None:
   820|         0|            0|            0|  0.00%|        class_name_map = {}
   821|         0|            0|            0|  0.00%|        _overloaded_methods[qual_name] = class_name_map
   822|         0|            0|            0|  0.00%|
   823|         0|            0|            0|  0.00%|    class_name, line_no = get_class_name_lineno(func)
   824|         0|            0|            0|  0.00%|    method_overloads = class_name_map.get(class_name, None)
   825|         0|            0|            0|  0.00%|    if method_overloads is None:
   826|         0|            0|            0|  0.00%|        method_overloads = []
   827|         0|            0|            0|  0.00%|        class_name_map[class_name] = method_overloads
   828|         0|            0|            0|  0.00%|        _overloaded_method_class_fileno[(qual_name, class_name)] = line_no
   829|         0|            0|            0|  0.00%|    else:
   830|         0|            0|            0|  0.00%|        existing_lineno = _overloaded_method_class_fileno[(qual_name, class_name)]
   831|         0|            0|            0|  0.00%|        if existing_lineno != line_no:
   832|         0|            0|            0|  0.00%|            raise RuntimeError("Cannot currently overload the same method name in two different"
   833|         0|            0|            0|  0.00%|                               " classes with the same name in the same module")
   834|         0|            0|            0|  0.00%|
   835|         0|            0|            0|  0.00%|    method_overloads.append(func)
   836|         0|            0|            0|  0.00%|    return func
   837|         0|            0|            0|  0.00%|
   838|         0|            0|            0|  0.00%|def _get_overloaded_methods(method, mod_class):
   839|         0|            0|            0|  0.00%|    # TODO: __name__ not set for submodules in recursive script
   840|         0|            0|            0|  0.00%|    if not hasattr(method, "__name__"):
   841|         0|            0|            0|  0.00%|        return None
   842|         0|            0|            0|  0.00%|    qual_name = _qualified_name(method)
   843|         0|            0|            0|  0.00%|    class_name_map = _overloaded_methods.get(qual_name, None)
   844|         0|            0|            0|  0.00%|    if class_name_map is None:
   845|         0|            0|            0|  0.00%|        return None
   846|         0|            0|            0|  0.00%|    overloads = class_name_map.get(mod_class.__name__, None)
   847|         0|            0|            0|  0.00%|    if overloads is None:
   848|         0|            0|            0|  0.00%|        return None
   849|         0|            0|            0|  0.00%|
   850|         0|            0|            0|  0.00%|    method_line_no = get_source_lines_and_file(method)[1]
   851|         0|            0|            0|  0.00%|    mod_class_fileno = get_source_lines_and_file(mod_class)[1]
   852|         0|            0|            0|  0.00%|    mod_end_fileno = mod_class_fileno + len(get_source_lines_and_file(mod_class)[0])
   853|         0|            0|            0|  0.00%|    if not (method_line_no >= mod_class_fileno and method_line_no <= mod_end_fileno):
   854|         0|            0|            0|  0.00%|        raise Exception("Overloads are not useable when a module is redeclared within the same file: " + str(method))
   855|         0|            0|            0|  0.00%|    return overloads
   856|         0|            0|            0|  0.00%|
   857|         0|            0|            0|  0.00%|
   858|         0|            0|            0|  0.00%|def is_tuple(ann) -> bool:
   859|         0|            0|            0|  0.00%|    if ann is Tuple:
   860|         0|            0|            0|  0.00%|        raise_error_container_parameter_missing("Tuple")
   861|         0|            0|            0|  0.00%|
   862|         0|            0|            0|  0.00%|    # For some reason Python 3.7 violates the Type[A, B].__origin__ == Type rule
   863|         0|            0|            0|  0.00%|    if not hasattr(ann, '__module__'):
   864|         0|            0|            0|  0.00%|        return False
   865|         0|            0|            0|  0.00%|    return ann.__module__ == 'typing' and \
   866|         0|            0|            0|  0.00%|        (getattr(ann, '__origin__', None) is Tuple or
   867|         0|            0|            0|  0.00%|            getattr(ann, '__origin__', None) is tuple)
   868|         0|            0|            0|  0.00%|
   869|         0|            0|            0|  0.00%|def is_list(ann) -> bool:
   870|         0|            0|            0|  0.00%|    if ann is List:
   871|         0|            0|            0|  0.00%|        raise_error_container_parameter_missing("List")
   872|         0|            0|            0|  0.00%|
   873|         0|            0|            0|  0.00%|    if not hasattr(ann, '__module__'):
   874|         0|            0|            0|  0.00%|        return False
   875|         0|            0|            0|  0.00%|    return ann.__module__ == 'typing' and \
   876|         0|            0|            0|  0.00%|        (getattr(ann, '__origin__', None) is List or
   877|         0|            0|            0|  0.00%|            getattr(ann, '__origin__', None) is list)
   878|         0|            0|            0|  0.00%|
   879|         0|            0|            0|  0.00%|def is_dict(ann) -> bool:
   880|         0|            0|            0|  0.00%|    if ann is Dict:
   881|         0|            0|            0|  0.00%|        raise_error_container_parameter_missing("Dict")
   882|         0|            0|            0|  0.00%|
   883|         0|            0|            0|  0.00%|    if not hasattr(ann, '__module__'):
   884|         0|            0|            0|  0.00%|        return False
   885|         0|            0|            0|  0.00%|    return ann.__module__ == 'typing' and \
   886|         0|            0|            0|  0.00%|        (getattr(ann, '__origin__', None) is Dict or
   887|         0|            0|            0|  0.00%|            getattr(ann, '__origin__', None) is dict)
   888|         0|            0|            0|  0.00%|
   889|         0|            0|            0|  0.00%|def is_union(ann):
   890|         0|            0|            0|  0.00%|    if ann is Union:
   891|         0|            0|            0|  0.00%|        raise_error_container_parameter_missing("Union")
   892|         0|            0|            0|  0.00%|
   893|         0|            0|            0|  0.00%|    return (hasattr(ann, '__module__') and
   894|         0|            0|            0|  0.00%|            ann.__module__ == 'typing' and
   895|         0|            0|            0|  0.00%|            (getattr(ann, '__origin__', None) is Union))
   896|         0|            0|            0|  0.00%|
   897|         0|            0|            0|  0.00%|def is_optional(ann):
   898|         0|            0|            0|  0.00%|    if ann is Optional:
   899|         0|            0|            0|  0.00%|        raise_error_container_parameter_missing("Optional")
   900|         0|            0|            0|  0.00%|
   901|         0|            0|            0|  0.00%|    def is_optional_as_optional(ann):
   902|         0|            0|            0|  0.00%|        return (hasattr(ann, '__module__') and
   903|         0|            0|            0|  0.00%|                ann.__module__ == 'typing' and
   904|         0|            0|            0|  0.00%|                (getattr(ann, '__origin__', None) is Optional))
   905|         0|            0|            0|  0.00%|
   906|         0|            0|            0|  0.00%|    def is_union_as_optional(ann):
   907|         0|            0|            0|  0.00%|        ann_args = ann.__args__
   908|         0|            0|            0|  0.00%|        return len(ann_args) == 2 and None in ann_args
   909|         0|            0|            0|  0.00%|
   910|         0|            0|            0|  0.00%|    return is_optional_as_optional(ann) or (is_union(ann) and is_union_as_optional(ann))
   911|         0|            0|            0|  0.00%|
   912|         0|            0|            0|  0.00%|def is_future(ann) -> bool:
   913|         0|            0|            0|  0.00%|    if ann is Future:
   914|         0|            0|            0|  0.00%|        raise RuntimeError(
   915|         0|            0|            0|  0.00%|            "Attempted to use Future without a "
   916|         0|            0|            0|  0.00%|            "contained type. Please add a contained type, e.g. "
   917|         0|            0|            0|  0.00%|            "Future[int]"
   918|         0|            0|            0|  0.00%|        )
   919|         0|            0|            0|  0.00%|    return getattr(ann, "__origin__", None) is Future
   920|         0|            0|            0|  0.00%|
   921|         0|            0|            0|  0.00%|if torch.distributed.rpc.is_available():
   922|         0|            0|            0|  0.00%|    from torch.distributed.rpc import RRef
   923|         0|            0|            0|  0.00%|    from torch._C._distributed_rpc import PyRRef
   924|         0|            0|            0|  0.00%|
   925|         0|            0|            0|  0.00%|    def is_rref(ann) -> bool:
   926|         0|            0|            0|  0.00%|        if ann is RRef:
   927|         0|            0|            0|  0.00%|            raise RuntimeError(
   928|         0|            0|            0|  0.00%|                "Attempted to use RRef without a "
   929|         0|            0|            0|  0.00%|                "contained type. Please add a contained type, e.g. "
   930|         0|            0|            0|  0.00%|                "RRef[int]"
   931|         0|            0|            0|  0.00%|            )
   932|         0|            0|            0|  0.00%|        return getattr(ann, "__origin__", None) is RRef
   933|         0|            0|            0|  0.00%|
   934|         0|            0|            0|  0.00%|    def is_rref_instance(obj) -> bool:
   935|         0|            0|            0|  0.00%|        return isinstance(obj, PyRRef)
   936|         0|            0|            0|  0.00%|
   937|         0|            0|            0|  0.00%|else:
   938|         0|            0|            0|  0.00%|    def is_rref_instance(obj) -> bool:
   939|         0|            0|            0|  0.00%|        # If the RPC module doesn't exist then RRefs don't exist either.
   940|         0|            0|            0|  0.00%|        return False
   941|         0|            0|            0|  0.00%|
   942|         0|            0|            0|  0.00%|def is_final(ann) -> bool:
   943|         0|            0|            0|  0.00%|    return ann.__module__ in {'typing', 'typing_extensions'} and \
   944|         0|            0|            0|  0.00%|        (getattr(ann, '__origin__', None) is Final or isinstance(ann, type(Final)))
   945|         0|            0|            0|  0.00%|
   946|         0|            0|            0|  0.00%|# allows BroadcastingList instance to be subscriptable
   947|         0|            0|            0|  0.00%|class BroadcastingListCls(object):
   948|         0|            0|            0|  0.00%|    def __getitem__(self, types):
   949|         0|            0|            0|  0.00%|        return
   950|         0|            0|            0|  0.00%|
   951|         0|            0|            0|  0.00%|# mypy doesn't support parameters on types, so we have to explicitly type each
   952|         0|            0|            0|  0.00%|# list size
   953|         0|            0|            0|  0.00%|BroadcastingList1 = BroadcastingListCls()
   954|         0|            0|            0|  0.00%|for i in range(2, 7):
   955|         0|            0|            0|  0.00%|    globals()[f"BroadcastingList{i}"] = BroadcastingList1
   956|         0|            0|            0|  0.00%|
   957|         0|            0|            0|  0.00%|
   958|      2898|   0.00494957|  1.70793e-06|  0.00%|def is_scripting() -> bool:
   959|         0|            0|            0|  0.00%|    r"""
   960|         0|            0|            0|  0.00%|    Function that returns True when in compilation and False otherwise. This
   961|         0|            0|            0|  0.00%|    is useful especially with the @unused decorator to leave code in your
   962|         0|            0|            0|  0.00%|    model that is not yet TorchScript compatible.
   963|         0|            0|            0|  0.00%|    .. testcode::
   964|         0|            0|            0|  0.00%|
   965|         0|            0|            0|  0.00%|        import torch
   966|         0|            0|            0|  0.00%|
   967|         0|            0|            0|  0.00%|        @torch.jit.unused
   968|         0|            0|            0|  0.00%|        def unsupported_linear_op(x):
   969|         0|            0|            0|  0.00%|            return x
   970|         0|            0|            0|  0.00%|
   971|         0|            0|            0|  0.00%|        def linear(x):
   972|         0|            0|            0|  0.00%|           if torch.jit.is_scripting():
   973|         0|            0|            0|  0.00%|              return torch.linear(x)
   974|         0|            0|            0|  0.00%|           else:
   975|         0|            0|            0|  0.00%|              return unsupported_linear_op(x)
   976|         0|            0|            0|  0.00%|    """
   977|      2898|   0.00594854|  2.05264e-06|  0.01%|    return False
   978|         0|            0|            0|  0.00%|
   979|         0|            0|            0|  0.00%|
   980|         0|            0|            0|  0.00%|# Retrieves a fully-qualified name (module hierarchy + classname) for a given obj.
   981|         0|            0|            0|  0.00%|def _qualified_name(obj, mangle_name=True) -> str:
   982|         0|            0|            0|  0.00%|    # This special case allows us to override the qualified name on a type.
   983|         0|            0|            0|  0.00%|    # It's currently used in conjunction with tracing, where we create a
   984|         0|            0|            0|  0.00%|    # fake module to filter only supported attributes. However, since this
   985|         0|            0|            0|  0.00%|    # new type is defined as a local class, we need a mechanism to override
   986|         0|            0|            0|  0.00%|    # its qualname so it appears correctly in the TorchScript system. This,
   987|         0|            0|            0|  0.00%|    # we set '_jit_override_qualname' with the original traced module's
   988|         0|            0|            0|  0.00%|    # qualified name, which is picked up here
   989|         0|            0|            0|  0.00%|    if hasattr(obj, '_jit_override_qualname'):
   990|         0|            0|            0|  0.00%|        return obj._jit_override_qualname
   991|         0|            0|            0|  0.00%|    # short-circuit in cases where the object already has a known qualified name
   992|         0|            0|            0|  0.00%|    if isinstance(obj, torch._C.ScriptFunction):
   993|         0|            0|            0|  0.00%|        return obj.qualified_name
   994|         0|            0|            0|  0.00%|
   995|         0|            0|            0|  0.00%|    if getattr(obj, "__name__", None):
   996|         0|            0|            0|  0.00%|        name = obj.__name__
   997|         0|            0|            0|  0.00%|    # Enum classes do not have `__name__` attr, instead they have `name`.
   998|         0|            0|            0|  0.00%|    elif isinstance(obj, enum.Enum):
   999|         0|            0|            0|  0.00%|        name = obj.name
  1000|         0|            0|            0|  0.00%|    else:
  1001|         0|            0|            0|  0.00%|        raise RuntimeError("Could not get name of python class object")
  1002|         0|            0|            0|  0.00%|
  1003|         0|            0|            0|  0.00%|
  1004|         0|            0|            0|  0.00%|    if name == '<lambda>':
  1005|         0|            0|            0|  0.00%|        name = '_lambda'  # make name a valid identifier
  1006|         0|            0|            0|  0.00%|
  1007|         0|            0|            0|  0.00%|    module_name = obj.__module__
  1008|         0|            0|            0|  0.00%|
  1009|         0|            0|            0|  0.00%|    # If the module is actually a torchbind module, then we should short circuit
  1010|         0|            0|            0|  0.00%|    if module_name == "torch._classes":
  1011|         0|            0|            0|  0.00%|        return obj.qualified_name
  1012|         0|            0|            0|  0.00%|
  1013|         0|            0|            0|  0.00%|    # The Python docs are very clear that `__module__` can be None, but I can't
  1014|         0|            0|            0|  0.00%|    # figure out when it actually would be.
  1015|         0|            0|            0|  0.00%|    if module_name is None:
  1016|         0|            0|            0|  0.00%|        raise RuntimeError(f"Could not get qualified name for class '{name}': "
  1017|         0|            0|            0|  0.00%|                           "__module__ can't be None.")
  1018|         0|            0|            0|  0.00%|
  1019|         0|            0|            0|  0.00%|    # if getattr(sys.modules[module_name], name) is not obj:
  1020|         0|            0|            0|  0.00%|    #     raise RuntimeError(f"Could not get qualified name for class '{name}': "
  1021|         0|            0|            0|  0.00%|    #                        f"the attr {name} on module {module_name} is not the the class")
  1022|         0|            0|            0|  0.00%|
  1023|         0|            0|            0|  0.00%|    # torch.package and TorchScript have separate mangling schemes to avoid
  1024|         0|            0|            0|  0.00%|    # name collisions from multiple packages. To avoid them interfering with
  1025|         0|            0|            0|  0.00%|    # each other, normalize the package manging here.
  1026|         0|            0|            0|  0.00%|    if package_mangling.is_mangled(module_name):
  1027|         0|            0|            0|  0.00%|        module_name = module_name.replace("<", "_")
  1028|         0|            0|            0|  0.00%|        module_name = module_name.replace(">", "_")
  1029|         0|            0|            0|  0.00%|
  1030|         0|            0|            0|  0.00%|    # The PythonExceptionValue C++ class in torch/csrc/jit/python/python_sugared_value.h
  1031|         0|            0|            0|  0.00%|    # does not need mangle the python class name.
  1032|         0|            0|            0|  0.00%|    if mangle_name:
  1033|         0|            0|            0|  0.00%|        # __main__ is a builtin module, so rewrite it to "__torch__".
  1034|         0|            0|            0|  0.00%|        if module_name == "__main__":
  1035|         0|            0|            0|  0.00%|            module_name = "__torch__"
  1036|         0|            0|            0|  0.00%|        else:
  1037|         0|            0|            0|  0.00%|            # Everything else gets a "__torch__" prefix to avoid name collisions
  1038|         0|            0|            0|  0.00%|            # with the names of user values.
  1039|         0|            0|            0|  0.00%|            module_name = "__torch__." + module_name
  1040|         0|            0|            0|  0.00%|
  1041|         0|            0|            0|  0.00%|    if "." in name:
  1042|         0|            0|            0|  0.00%|        raise RuntimeError(f"Could not get qualified name for class '{name}': "
  1043|         0|            0|            0|  0.00%|                           f"'{name}' is not a valid identifier")
  1044|         0|            0|            0|  0.00%|
  1045|         0|            0|            0|  0.00%|    return module_name + "." + name
  1046|         0|            0|            0|  0.00%|
  1047|         0|            0|            0|  0.00%|
  1048|         0|            0|            0|  0.00%|def _try_get_dispatched_fn(fn):
  1049|         0|            0|            0|  0.00%|    if not callable(fn):
  1050|         0|            0|            0|  0.00%|        return None
  1051|         0|            0|            0|  0.00%|    return boolean_dispatched.get(fn)
  1052|         0|            0|            0|  0.00%|
  1053|         0|            0|            0|  0.00%|
  1054|         0|            0|            0|  0.00%|def _get_named_tuple_properties(obj):
  1055|         0|            0|            0|  0.00%|    assert issubclass(obj, tuple) and hasattr(obj, '_fields')
  1056|         0|            0|            0|  0.00%|    if hasattr(obj, "_field_defaults"):
  1057|         0|            0|            0|  0.00%|        defaults = [obj._field_defaults[field]
  1058|         0|            0|            0|  0.00%|                    for field in obj._fields
  1059|         0|            0|            0|  0.00%|                    if field in obj._field_defaults]
  1060|         0|            0|            0|  0.00%|    else:
  1061|         0|            0|            0|  0.00%|        defaults = []
  1062|         0|            0|            0|  0.00%|    annotations = []
  1063|         0|            0|            0|  0.00%|    has_annotations = hasattr(obj, '__annotations__')
  1064|         0|            0|            0|  0.00%|    for field in obj._fields:
  1065|         0|            0|            0|  0.00%|        if has_annotations and field in obj.__annotations__:
  1066|         0|            0|            0|  0.00%|            the_type = torch.jit.annotations.ann_to_type(obj.__annotations__[field], fake_range())
  1067|         0|            0|            0|  0.00%|            annotations.append(the_type)
  1068|         0|            0|            0|  0.00%|        else:
  1069|         0|            0|            0|  0.00%|            annotations.append(torch._C.TensorType.getInferred())
  1070|         0|            0|            0|  0.00%|    return type(obj).__name__, obj._fields, annotations, defaults
  1071|         0|            0|            0|  0.00%|
  1072|         0|            0|            0|  0.00%|
  1073|         0|            0|            0|  0.00%|def _create_named_tuple(t, unqual_name: str, field_names: List[str], defaults: Tuple[Any, ...]):
  1074|         0|            0|            0|  0.00%|    # mypy: namedtuple() expects a string literal as the first argument
  1075|         0|            0|            0|  0.00%|    if sys.version_info < (3, 7, 0):
  1076|         0|            0|            0|  0.00%|        TupleType = collections.namedtuple(unqual_name, field_names)  # type: ignore[no-redef, misc]
  1077|         0|            0|            0|  0.00%|        TupleType.__new__.__defaults__ = defaults    # type: ignore[attr-defined]
  1078|         0|            0|            0|  0.00%|    else:
  1079|         0|            0|            0|  0.00%|        TupleType = collections.namedtuple(unqual_name, field_names, defaults=defaults)  # type: ignore[call-arg, no-redef, misc]
  1080|         0|            0|            0|  0.00%|    return TupleType(*t)
  1081|         0|            0|            0|  0.00%|
  1082|         0|            0|            0|  0.00%|@contextlib.contextmanager
  1083|         0|            0|            0|  0.00%|def _disable_emit_hooks():
  1084|         0|            0|            0|  0.00%|    hooks = torch._C._jit_get_emit_hooks()
  1085|         0|            0|            0|  0.00%|    torch._C._jit_set_emit_hooks(None, None)
  1086|         0|            0|            0|  0.00%|    yield
  1087|         0|            0|            0|  0.00%|    torch._C._jit_set_emit_hooks(hooks[0], hooks[1])
  1088|         0|            0|            0|  0.00%|
  1089|         0|            0|            0|  0.00%|
  1090|         0|            0|            0|  0.00%|def _disable_emit_hooks_decorator(_DecoratorContextManager) -> None:  # noqa: F811
  1091|         0|            0|            0|  0.00%|    def __enter__(self) -> None:
  1092|         0|            0|            0|  0.00%|        self.hooks = torch._C._jit_get_emit_hooks()
  1093|         0|            0|            0|  0.00%|        torch._C._jit_set_emit_hooks(None, None)
  1094|         0|            0|            0|  0.00%|
  1095|         0|            0|            0|  0.00%|    def __exit__(self, *args) -> None:
  1096|         0|            0|            0|  0.00%|        torch._C._jit_set_emit_hooks(self.hooks[0], self.hooks[1])
  1097|         0|            0|            0|  0.00%|
  1098|         0|            0|            0|  0.00%|def _is_exception(obj) -> bool:
  1099|         0|            0|            0|  0.00%|    if not inspect.isclass(obj):
  1100|         0|            0|            0|  0.00%|        return False
  1101|         0|            0|            0|  0.00%|    return issubclass(obj, Exception)
  1102|         0|            0|            0|  0.00%|
  1103|         0|            0|            0|  0.00%|def raise_error_container_parameter_missing(target_type) -> None:
  1104|         0|            0|            0|  0.00%|    if target_type == 'Dict':
  1105|         0|            0|            0|  0.00%|        raise RuntimeError(
  1106|         0|            0|            0|  0.00%|            "Attempted to use Dict without "
  1107|         0|            0|            0|  0.00%|            "contained types. Please add contained type, e.g. "
  1108|         0|            0|            0|  0.00%|            "Dict[int, int]"
  1109|         0|            0|            0|  0.00%|        )
  1110|         0|            0|            0|  0.00%|    raise RuntimeError(
  1111|         0|            0|            0|  0.00%|        f"Attempted to use {target_type} without a "
  1112|         0|            0|            0|  0.00%|        "contained type. Please add a contained type, e.g. "
  1113|         0|            0|            0|  0.00%|        f"{target_type}[int]"
  1114|         0|            0|            0|  0.00%|    )
  1115|         0|            0|            0|  0.00%|
  1116|         0|            0|            0|  0.00%|
  1117|         0|            0|            0|  0.00%|def get_origin(target_type):
  1118|         0|            0|            0|  0.00%|    return getattr(target_type, "__origin__", None)
  1119|         0|            0|            0|  0.00%|
  1120|         0|            0|            0|  0.00%|
  1121|         0|            0|            0|  0.00%|def get_args(target_type):
  1122|         0|            0|            0|  0.00%|    return getattr(target_type, "__args__", None)
  1123|         0|            0|            0|  0.00%|
  1124|         0|            0|            0|  0.00%|
  1125|         0|            0|            0|  0.00%|def check_args_exist(target_type) -> None:
  1126|         0|            0|            0|  0.00%|    if target_type is List or target_type is list:
  1127|         0|            0|            0|  0.00%|        raise_error_container_parameter_missing("List")
  1128|         0|            0|            0|  0.00%|    elif target_type is Tuple or target_type is tuple:
  1129|         0|            0|            0|  0.00%|        raise_error_container_parameter_missing("Tuple")
  1130|         0|            0|            0|  0.00%|    elif target_type is Dict or target_type is dict:
  1131|         0|            0|            0|  0.00%|        raise_error_container_parameter_missing("Dict")
  1132|         0|            0|            0|  0.00%|    elif target_type is None or target_type is Optional:
  1133|         0|            0|            0|  0.00%|        raise_error_container_parameter_missing("Optional")
  1134|         0|            0|            0|  0.00%|
  1135|         0|            0|            0|  0.00%|
  1136|         0|            0|            0|  0.00%|def check_empty_containers(obj) -> None:
  1137|         0|            0|            0|  0.00%|    if obj == [] or obj == {} or obj == ():
  1138|         0|            0|            0|  0.00%|        warnings.warn("The inner type of a container is lost when "
  1139|         0|            0|            0|  0.00%|                      "calling torch.jit.isinstance in eager mode. For "
  1140|         0|            0|            0|  0.00%|                      "example, List[int] would become list and "
  1141|         0|            0|            0|  0.00%|                      "therefore falsely return True for List[float] or"
  1142|         0|            0|            0|  0.00%|                      " List[str].")
  1143|         0|            0|            0|  0.00%|
  1144|         0|            0|            0|  0.00%|
  1145|         0|            0|            0|  0.00%|# supports List/Dict/Tuple and Optional types
  1146|         0|            0|            0|  0.00%|# TODO support future
  1147|         0|            0|            0|  0.00%|def container_checker(obj, target_type) -> bool:
  1148|         0|            0|            0|  0.00%|    origin_type = get_origin(target_type)
  1149|         0|            0|            0|  0.00%|    check_args_exist(target_type)
  1150|         0|            0|            0|  0.00%|    if origin_type is list or origin_type is List:
  1151|         0|            0|            0|  0.00%|        check_empty_containers(obj)
  1152|         0|            0|            0|  0.00%|        if not isinstance(obj, list):
  1153|         0|            0|            0|  0.00%|            return False
  1154|         0|            0|            0|  0.00%|        arg_type = get_args(target_type)[0]
  1155|         0|            0|            0|  0.00%|        arg_origin = get_origin(arg_type)
  1156|         0|            0|            0|  0.00%|        for el in obj:
  1157|         0|            0|            0|  0.00%|            # check if nested container, ex: List[List[str]]
  1158|         0|            0|            0|  0.00%|            if arg_origin:  # processes nested container, ex: List[List[str]]
  1159|         0|            0|            0|  0.00%|                if not container_checker(el, arg_type):
  1160|         0|            0|            0|  0.00%|                    return False
  1161|         0|            0|            0|  0.00%|            elif not isinstance(el, arg_type):
  1162|         0|            0|            0|  0.00%|                return False
  1163|         0|            0|            0|  0.00%|        return True
  1164|         0|            0|            0|  0.00%|    elif origin_type is Dict or origin_type is dict:
  1165|         0|            0|            0|  0.00%|        check_empty_containers(obj)
  1166|         0|            0|            0|  0.00%|        if not isinstance(obj, dict):
  1167|         0|            0|            0|  0.00%|            return False
  1168|         0|            0|            0|  0.00%|        key_type = get_args(target_type)[0]
  1169|         0|            0|            0|  0.00%|        val_type = get_args(target_type)[1]
  1170|         0|            0|            0|  0.00%|        for key, val in obj.items():
  1171|         0|            0|            0|  0.00%|            # check if keys are of right type
  1172|         0|            0|            0|  0.00%|            if not isinstance(key, key_type):
  1173|         0|            0|            0|  0.00%|                return False
  1174|         0|            0|            0|  0.00%|            val_origin = get_origin(val_type)
  1175|         0|            0|            0|  0.00%|            if val_origin:
  1176|         0|            0|            0|  0.00%|                if not container_checker(val, val_type):
  1177|         0|            0|            0|  0.00%|                    return False
  1178|         0|            0|            0|  0.00%|            elif not isinstance(val, val_type):
  1179|         0|            0|            0|  0.00%|                return False
  1180|         0|            0|            0|  0.00%|        return True
  1181|         0|            0|            0|  0.00%|    elif origin_type is Tuple or origin_type is tuple:
  1182|         0|            0|            0|  0.00%|        check_empty_containers(obj)
  1183|         0|            0|            0|  0.00%|        if not isinstance(obj, tuple):
  1184|         0|            0|            0|  0.00%|            return False
  1185|         0|            0|            0|  0.00%|        arg_types = get_args(target_type)
  1186|         0|            0|            0|  0.00%|        if len(obj) != len(arg_types):
  1187|         0|            0|            0|  0.00%|            return False
  1188|         0|            0|            0|  0.00%|        for el, el_type in zip(obj, arg_types):
  1189|         0|            0|            0|  0.00%|            el_origin = get_origin(el_type)
  1190|         0|            0|            0|  0.00%|            if el_origin:
  1191|         0|            0|            0|  0.00%|                if not container_checker(el, el_type):
  1192|         0|            0|            0|  0.00%|                    return False
  1193|         0|            0|            0|  0.00%|            elif not isinstance(el, el_type):
  1194|         0|            0|            0|  0.00%|                return False
  1195|         0|            0|            0|  0.00%|        return True
  1196|         0|            0|            0|  0.00%|    elif origin_type is Union:  # also handles Optional
  1197|         0|            0|            0|  0.00%|        if obj is None:  # check before recursion because None is always fine
  1198|         0|            0|            0|  0.00%|            return True
  1199|         0|            0|            0|  0.00%|        inner_types = get_args(target_type)
  1200|         0|            0|            0|  0.00%|        for t in inner_types:
  1201|         0|            0|            0|  0.00%|            t_origin = get_origin(t)
  1202|         0|            0|            0|  0.00%|            if (t_origin):
  1203|         0|            0|            0|  0.00%|                return container_checker(obj, t)
  1204|         0|            0|            0|  0.00%|            elif isinstance(obj, t):
  1205|         0|            0|            0|  0.00%|                return True
  1206|         0|            0|            0|  0.00%|    return False
  1207|         0|            0|            0|  0.00%|
  1208|         0|            0|            0|  0.00%|
  1209|         0|            0|            0|  0.00%|def _isinstance(obj, target_type) -> bool:
  1210|         0|            0|            0|  0.00%|    if isinstance(target_type, collections.abc.Container):
  1211|         0|            0|            0|  0.00%|        if not isinstance(target_type, tuple):
  1212|         0|            0|            0|  0.00%|            raise RuntimeError("The second argument to "
  1213|         0|            0|            0|  0.00%|                               "`torch.jit.isinstance` must be a type "
  1214|         0|            0|            0|  0.00%|                               "or a tuple of types")
  1215|         0|            0|            0|  0.00%|        for t_type in target_type:
  1216|         0|            0|            0|  0.00%|            if _isinstance(obj, t_type):
  1217|         0|            0|            0|  0.00%|                return True
  1218|         0|            0|            0|  0.00%|        return False
  1219|         0|            0|            0|  0.00%|
  1220|         0|            0|            0|  0.00%|    origin_type = get_origin(target_type)
  1221|         0|            0|            0|  0.00%|    if origin_type:
  1222|         0|            0|            0|  0.00%|        return container_checker(obj, target_type)
  1223|         0|            0|            0|  0.00%|
  1224|         0|            0|            0|  0.00%|    # Check to handle non-typed optional origin returns as none instead
  1225|         0|            0|            0|  0.00%|    #    of as optional in 3.7-3.8
  1226|         0|            0|            0|  0.00%|    check_args_exist(target_type)
  1227|         0|            0|            0|  0.00%|
  1228|         0|            0|            0|  0.00%|    # handle non-containers
  1229|         0|            0|            0|  0.00%|    return isinstance(obj, target_type)
  1230|         0|            0|            0|  0.00%|
  1231|         0|            0|            0|  0.00%|
  1232|         0|            0|            0|  0.00%|class _TensorExtractor(pickle.Pickler):
  1233|         0|            0|            0|  0.00%|    def __init__(self, *args, tensors: List[torch.Tensor], **kwargs):
  1234|         0|            0|            0|  0.00%|        super().__init__(*args, **kwargs)
  1235|         0|            0|            0|  0.00%|        self.tensors = tensors
  1236|         0|            0|            0|  0.00%|
  1237|         0|            0|            0|  0.00%|    def persistent_id(self, obj):
  1238|         0|            0|            0|  0.00%|        if isinstance(obj, torch.Tensor):
  1239|         0|            0|            0|  0.00%|            self.tensors.append(obj)
  1240|         0|            0|            0|  0.00%|            return ""
  1241|         0|            0|            0|  0.00%|        # Since we just want to extract tensors, we don't mind if an object is
  1242|         0|            0|            0|  0.00%|        # unpicklable if it doesn't contain tensors, as we can just ignore/skip
  1243|         0|            0|            0|  0.00%|        # it. To play it safe, we only do so for common objects that we're sure
  1244|         0|            0|            0|  0.00%|        # don't contain tensors. Feel free to add new types here. Note also that
  1245|         0|            0|            0|  0.00%|        # even if a type isn't listed here this won't block users, since thet
  1246|         0|            0|            0|  0.00%|        # can just add a __getstate__ or __reduce__ method to their class.
  1247|         0|            0|            0|  0.00%|        if isinstance(obj, LockType):
  1248|         0|            0|            0|  0.00%|            return ""
  1249|         0|            0|            0|  0.00%|        # Futures and RRefs don't technically contain a value, they just offer
  1250|         0|            0|            0|  0.00%|        # the means to access a value.
  1251|         0|            0|            0|  0.00%|        if isinstance(obj, CFuture) or is_rref_instance(obj):
  1252|         0|            0|            0|  0.00%|            return ""
  1253|         0|            0|            0|  0.00%|        if isinstance(obj, torch.cuda.Event):
  1254|         0|            0|            0|  0.00%|            return ""
  1255|         0|            0|            0|  0.00%|        if isinstance(obj, threading.Thread):
  1256|         0|            0|            0|  0.00%|            return ""
  1257|         0|            0|            0|  0.00%|        return None
  1258|         0|            0|            0|  0.00%|
  1259|         0|            0|            0|  0.00%|
  1260|         0|            0|            0|  0.00%|def _extract_tensors(obj):
  1261|         0|            0|            0|  0.00%|    r"""
  1262|         0|            0|            0|  0.00%|    This function is exclusively called from C++.
  1263|         0|            0|            0|  0.00%|    See ``torch/csrc/jit/python/python_ivalue.h``.
  1264|         0|            0|            0|  0.00%|
  1265|         0|            0|            0|  0.00%|    It extracts the tensors contained in the given object, through pickling.
  1266|         0|            0|            0|  0.00%|    """
  1267|         0|            0|            0|  0.00%|    tensors: List[torch.Tensor] = []
  1268|         0|            0|            0|  0.00%|    extractor = _TensorExtractor(io.BytesIO(), protocol=-1, tensors=tensors)
  1269|         0|            0|            0|  0.00%|    extractor.dump(obj)
  1270|         0|            0|            0|  0.00%|    return tensors
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/cuda/__init__.py
File duration: 0.00218296s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|r"""
     2|         0|            0|            0|  0.00%|This package adds support for CUDA tensor types, that implement the same
     3|         0|            0|            0|  0.00%|function as CPU tensors, but they utilize GPUs for computation.
     4|         0|            0|            0|  0.00%|
     5|         0|            0|            0|  0.00%|It is lazily initialized, so you can always import it, and use
     6|         0|            0|            0|  0.00%|:func:`is_available()` to determine if your system supports CUDA.
     7|         0|            0|            0|  0.00%|
     8|         0|            0|            0|  0.00%|:ref:`cuda-semantics` has more details about working with CUDA.
     9|         0|            0|            0|  0.00%|"""
    10|         0|            0|            0|  0.00%|
    11|         0|            0|            0|  0.00%|import contextlib
    12|         0|            0|            0|  0.00%|import os
    13|         0|            0|            0|  0.00%|import torch
    14|         0|            0|            0|  0.00%|from torch.types import Device
    15|         0|            0|            0|  0.00%|import traceback
    16|         0|            0|            0|  0.00%|import warnings
    17|         0|            0|            0|  0.00%|import threading
    18|         0|            0|            0|  0.00%|from typing import List, Optional, Tuple, Union, Any
    19|         0|            0|            0|  0.00%|from ._utils import _get_device_index, _dummy_type
    20|         0|            0|            0|  0.00%|from .._utils import classproperty
    21|         0|            0|            0|  0.00%|from .graphs import CUDAGraph, graph_pool_handle, graph, \
    22|         0|            0|            0|  0.00%|    make_graphed_callables, is_current_stream_capturing
    23|         0|            0|            0|  0.00%|from .streams import ExternalStream, Stream, Event
    24|         0|            0|            0|  0.00%|from .. import device as _device
    25|         0|            0|            0|  0.00%|import torch._C
    26|         0|            0|            0|  0.00%|
    27|         0|            0|            0|  0.00%|try:
    28|         0|            0|            0|  0.00%|    from torch._C import _cudart  # type: ignore[attr-defined]
    29|         0|            0|            0|  0.00%|except ImportError:
    30|         0|            0|            0|  0.00%|    _cudart = None
    31|         0|            0|            0|  0.00%|
    32|         0|            0|            0|  0.00%|_initialized = False
    33|         0|            0|            0|  0.00%|_tls = threading.local()
    34|         0|            0|            0|  0.00%|_initialization_lock = threading.Lock()
    35|         0|            0|            0|  0.00%|_queued_calls = []  # don't invoke these until initialization occurs
    36|         0|            0|            0|  0.00%|_is_in_bad_fork = getattr(torch._C, "_cuda_isInBadFork", lambda: False)
    37|         0|            0|            0|  0.00%|_device_t = Union[_device, str, int, None]
    38|         0|            0|            0|  0.00%|
    39|         0|            0|            0|  0.00%|
    40|         0|            0|            0|  0.00%|class _LazySeedTracker:
    41|         0|            0|            0|  0.00%|    # Since seeding is memory-less, only track the latest seed.
    42|         0|            0|            0|  0.00%|    # Note: `manual_seed_all` followed by `manual_seed` overwrites
    43|         0|            0|            0|  0.00%|    # the seed on current device. We track the order of **latest**
    44|         0|            0|            0|  0.00%|    # calls between these two API.
    45|         0|            0|            0|  0.00%|    def __init__(self):
    46|         0|            0|            0|  0.00%|        self.manual_seed_all_cb = None
    47|         0|            0|            0|  0.00%|        self.manual_seed_cb = None
    48|         0|            0|            0|  0.00%|        self.call_order = []
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|    def queue_seed_all(self, cb, traceback):
    51|         0|            0|            0|  0.00%|        self.manual_seed_all_cb = (cb, traceback)
    52|         0|            0|            0|  0.00%|        # update seed_all to be latest
    53|         0|            0|            0|  0.00%|        self.call_order = [self.manual_seed_cb, self.manual_seed_all_cb]
    54|         0|            0|            0|  0.00%|
    55|         0|            0|            0|  0.00%|    def queue_seed(self, cb, traceback):
    56|         0|            0|            0|  0.00%|        self.manual_seed_cb = (cb, traceback)
    57|         0|            0|            0|  0.00%|        # update seed to be latest
    58|         0|            0|            0|  0.00%|        self.call_order = [self.manual_seed_all_cb, self.manual_seed_cb]
    59|         0|            0|            0|  0.00%|
    60|         0|            0|            0|  0.00%|    def get_calls(self) -> List:
    61|         0|            0|            0|  0.00%|        return self.call_order
    62|         0|            0|            0|  0.00%|
    63|         0|            0|            0|  0.00%|
    64|         0|            0|            0|  0.00%|_lazy_seed_tracker = _LazySeedTracker()
    65|         0|            0|            0|  0.00%|
    66|         0|            0|            0|  0.00%|# Define dummy _CudaDeviceProperties type if PyTorch was compiled without CUDA
    67|         0|            0|            0|  0.00%|if hasattr(torch._C, '_CudaDeviceProperties'):
    68|         0|            0|            0|  0.00%|    _CudaDeviceProperties = torch._C._CudaDeviceProperties
    69|         0|            0|            0|  0.00%|else:
    70|         0|            0|            0|  0.00%|    _CudaDeviceProperties = _dummy_type('_CudaDeviceProperties')  # type: ignore[assignment, misc]
    71|         0|            0|            0|  0.00%|
    72|         0|            0|            0|  0.00%|# Global variables dynamically populated by native code
    73|         0|            0|            0|  0.00%|has_magma: bool = False
    74|         0|            0|            0|  0.00%|has_half: bool = False
    75|         0|            0|            0|  0.00%|default_generators: Tuple[torch._C.Generator] = ()  # type: ignore[assignment]
    76|         0|            0|            0|  0.00%|
    77|       289|  0.000466824|  1.61531e-06|  0.00%|def is_available() -> bool:
    78|         0|            0|            0|  0.00%|    r"""Returns a bool indicating if CUDA is currently available."""
    79|       289|  0.000896931|  3.10357e-06|  0.00%|    if not hasattr(torch._C, '_cuda_getDeviceCount'):
    80|         0|            0|            0|  0.00%|        return False
    81|         0|            0|            0|  0.00%|    # This function never throws and returns 0 if driver is missing or can't
    82|         0|            0|            0|  0.00%|    # be initialized
    83|       289|  0.000772715|  2.67375e-06|  0.00%|    return torch._C._cuda_getDeviceCount() > 0
    84|         0|            0|            0|  0.00%|
    85|         0|            0|            0|  0.00%|def is_bf16_supported():
    86|         0|            0|            0|  0.00%|    r"""Returns a bool indicating if the current CUDA device supports dtype bfloat16"""
    87|         0|            0|            0|  0.00%|    cu_vers = torch.version.cuda
    88|         0|            0|            0|  0.00%|    if cu_vers is not None:
    89|         0|            0|            0|  0.00%|        cuda_maj_decide = int(cu_vers.split('.')[0]) >= 11
    90|         0|            0|            0|  0.00%|
    91|         0|            0|            0|  0.00%|    else:
    92|         0|            0|            0|  0.00%|        cuda_maj_decide = False
    93|         0|            0|            0|  0.00%|    return torch.cuda.get_device_properties(torch.cuda.current_device()).major >= 8 and cuda_maj_decide
    94|         0|            0|            0|  0.00%|
    95|         0|            0|            0|  0.00%|def _sleep(cycles):
    96|         0|            0|            0|  0.00%|    torch._C._cuda_sleep(cycles)
    97|         0|            0|            0|  0.00%|
    98|         0|            0|            0|  0.00%|
    99|         0|            0|            0|  0.00%|def _check_capability():
   100|         0|            0|            0|  0.00%|    incorrect_binary_warn = """
   101|         0|            0|            0|  0.00%|    Found GPU%d %s which requires CUDA_VERSION >= %d to
   102|         0|            0|            0|  0.00%|     work properly, but your PyTorch was compiled
   103|         0|            0|            0|  0.00%|     with CUDA_VERSION %d. Please install the correct PyTorch binary
   104|         0|            0|            0|  0.00%|     using instructions from https://pytorch.org
   105|         0|            0|            0|  0.00%|    """
   106|         0|            0|            0|  0.00%|
   107|         0|            0|            0|  0.00%|    old_gpu_warn = """
   108|         0|            0|            0|  0.00%|    Found GPU%d %s which is of cuda capability %d.%d.
   109|         0|            0|            0|  0.00%|    PyTorch no longer supports this GPU because it is too old.
   110|         0|            0|            0|  0.00%|    The minimum cuda capability supported by this library is %d.%d.
   111|         0|            0|            0|  0.00%|    """
   112|         0|            0|            0|  0.00%|
   113|         0|            0|            0|  0.00%|    if torch.version.cuda is not None:  # on ROCm we don't want this check
   114|         0|            0|            0|  0.00%|        CUDA_VERSION = torch._C._cuda_getCompiledVersion()
   115|         0|            0|            0|  0.00%|        for d in range(device_count()):
   116|         0|            0|            0|  0.00%|            capability = get_device_capability(d)
   117|         0|            0|            0|  0.00%|            major = capability[0]
   118|         0|            0|            0|  0.00%|            minor = capability[1]
   119|         0|            0|            0|  0.00%|            name = get_device_name(d)
   120|         0|            0|            0|  0.00%|            current_arch = major * 10 + minor
   121|         0|            0|            0|  0.00%|            min_arch = min((int(arch.split("_")[1]) for arch in torch.cuda.get_arch_list()), default=35)
   122|         0|            0|            0|  0.00%|            if current_arch < min_arch:
   123|         0|            0|            0|  0.00%|                warnings.warn(old_gpu_warn % (d, name, major, minor, min_arch // 10, min_arch % 10))
   124|         0|            0|            0|  0.00%|            elif CUDA_VERSION <= 9000 and major >= 7 and minor >= 5:
   125|         0|            0|            0|  0.00%|                warnings.warn(incorrect_binary_warn % (d, name, 10000, CUDA_VERSION))
   126|         0|            0|            0|  0.00%|
   127|         0|            0|            0|  0.00%|def _check_cubins():
   128|         0|            0|            0|  0.00%|    incompatible_device_warn = """
   129|         0|            0|            0|  0.00%|{} with CUDA capability sm_{} is not compatible with the current PyTorch installation.
   130|         0|            0|            0|  0.00%|The current PyTorch install supports CUDA capabilities {}.
   131|         0|            0|            0|  0.00%|If you want to use the {} GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/
   132|         0|            0|            0|  0.00%|"""
   133|         0|            0|            0|  0.00%|    if torch.version.cuda is None:  # on ROCm we don't want this check
   134|         0|            0|            0|  0.00%|        return
   135|         0|            0|            0|  0.00%|    arch_list = get_arch_list()
   136|         0|            0|            0|  0.00%|    if len(arch_list) == 0:
   137|         0|            0|            0|  0.00%|        return
   138|         0|            0|            0|  0.00%|    supported_sm = [int(arch.split('_')[1]) for arch in arch_list if 'sm_' in arch]
   139|         0|            0|            0|  0.00%|    for idx in range(device_count()):
   140|         0|            0|            0|  0.00%|        cap_major, cap_minor = get_device_capability(idx)
   141|         0|            0|            0|  0.00%|        # NVIDIA GPU compute architectures are backward compatible within major version
   142|         0|            0|            0|  0.00%|        supported = any([sm // 10 == cap_major for sm in supported_sm])
   143|         0|            0|            0|  0.00%|        if not supported:
   144|         0|            0|            0|  0.00%|            device_name = get_device_name(idx)
   145|         0|            0|            0|  0.00%|            capability = cap_major * 10 + cap_minor
   146|         0|            0|            0|  0.00%|            warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
   147|         0|            0|            0|  0.00%|
   148|         0|            0|            0|  0.00%|
   149|         1|  3.57628e-06|  3.57628e-06|  0.00%|def is_initialized():
   150|         0|            0|            0|  0.00%|    r"""Returns whether PyTorch's CUDA state has been initialized."""
   151|         1|  3.33786e-06|  3.33786e-06|  0.00%|    return _initialized and not _is_in_bad_fork()
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|
   154|         1|  2.86102e-06|  2.86102e-06|  0.00%|def _lazy_call(callable, **kwargs):
   155|         1|  1.21593e-05|  1.21593e-05|  0.00%|    if is_initialized():
(call)|         1|  6.91414e-06|  6.91414e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:149 is_initialized
   156|         1|  8.82149e-06|  8.82149e-06|  0.00%|        callable()
(call)|         1|   5.4121e-05|   5.4121e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/cuda/random.py:108 cb
   157|         0|            0|            0|  0.00%|    else:
   158|         0|            0|            0|  0.00%|        # TODO(torch_deploy): this accesses linecache, which attempts to read the
   159|         0|            0|            0|  0.00%|        # file system to get traceback info. Patch linecache or do something
   160|         0|            0|            0|  0.00%|        # else here if this ends up being important.
   161|         0|            0|            0|  0.00%|        global _lazy_seed_tracker
   162|         0|            0|            0|  0.00%|        if kwargs.get("seed_all", False):
   163|         0|            0|            0|  0.00%|            _lazy_seed_tracker.queue_seed_all(callable, traceback.format_stack())
   164|         0|            0|            0|  0.00%|        elif kwargs.get("seed", False):
   165|         0|            0|            0|  0.00%|            _lazy_seed_tracker.queue_seed(callable, traceback.format_stack())
   166|         0|            0|            0|  0.00%|        else:
   167|         0|            0|            0|  0.00%|            # Don't store the actual traceback to avoid memory cycle
   168|         0|            0|            0|  0.00%|            _queued_calls.append((callable, traceback.format_stack()))
   169|         0|            0|            0|  0.00%|
   170|         0|            0|            0|  0.00%|_lazy_call(_check_capability)
   171|         0|            0|            0|  0.00%|_lazy_call(_check_cubins)
   172|         0|            0|            0|  0.00%|
   173|         0|            0|            0|  0.00%|
   174|         0|            0|            0|  0.00%|class DeferredCudaCallError(Exception):
   175|         0|            0|            0|  0.00%|    pass
   176|         0|            0|            0|  0.00%|
   177|         0|            0|            0|  0.00%|
   178|         0|            0|            0|  0.00%|def init():
   179|         0|            0|            0|  0.00%|    r"""Initialize PyTorch's CUDA state.  You may need to call
   180|         0|            0|            0|  0.00%|    this explicitly if you are interacting with PyTorch via
   181|         0|            0|            0|  0.00%|    its C API, as Python bindings for CUDA functionality will not
   182|         0|            0|            0|  0.00%|    be available until this initialization takes place.  Ordinary users
   183|         0|            0|            0|  0.00%|    should not need this, as all of PyTorch's CUDA methods
   184|         0|            0|            0|  0.00%|    automatically initialize CUDA state on-demand.
   185|         0|            0|            0|  0.00%|
   186|         0|            0|            0|  0.00%|    Does nothing if the CUDA state is already initialized.
   187|         0|            0|            0|  0.00%|    """
   188|         0|            0|            0|  0.00%|    _lazy_init()
   189|         0|            0|            0|  0.00%|
   190|         0|            0|            0|  0.00%|
   191|         0|            0|            0|  0.00%|def _lazy_init():
   192|         0|            0|            0|  0.00%|    global _initialized, _queued_calls
   193|         0|            0|            0|  0.00%|    if is_initialized() or hasattr(_tls, 'is_initializing'):
   194|         0|            0|            0|  0.00%|        return
   195|         0|            0|            0|  0.00%|    with _initialization_lock:
   196|         0|            0|            0|  0.00%|        # We be double-checked locking, boys!  This is OK because
   197|         0|            0|            0|  0.00%|        # the above test was GIL protected anyway.  The inner test
   198|         0|            0|            0|  0.00%|        # is for when a thread blocked on some other thread which was
   199|         0|            0|            0|  0.00%|        # doing the initialization; when they get the lock, they will
   200|         0|            0|            0|  0.00%|        # find there is nothing left to do.
   201|         0|            0|            0|  0.00%|        if is_initialized():
   202|         0|            0|            0|  0.00%|            return
   203|         0|            0|            0|  0.00%|        # It is important to prevent other threads from entering _lazy_init
   204|         0|            0|            0|  0.00%|        # immediately, while we are still guaranteed to have the GIL, because some
   205|         0|            0|            0|  0.00%|        # of the C calls we make below will release the GIL
   206|         0|            0|            0|  0.00%|        if _is_in_bad_fork():
   207|         0|            0|            0|  0.00%|            raise RuntimeError(
   208|         0|            0|            0|  0.00%|                "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "
   209|         0|            0|            0|  0.00%|                "multiprocessing, you must use the 'spawn' start method")
   210|         0|            0|            0|  0.00%|        if not hasattr(torch._C, '_cuda_getDeviceCount'):
   211|         0|            0|            0|  0.00%|            raise AssertionError("Torch not compiled with CUDA enabled")
   212|         0|            0|            0|  0.00%|        if _cudart is None:
   213|         0|            0|            0|  0.00%|            raise AssertionError(
   214|         0|            0|            0|  0.00%|                "libcudart functions unavailable. It looks like you have a broken build?")
   215|         0|            0|            0|  0.00%|        # This function throws if there's a driver initialization error, no GPUs
   216|         0|            0|            0|  0.00%|        # are found or any other error occurs
   217|         0|            0|            0|  0.00%|        torch._C._cuda_init()
   218|         0|            0|            0|  0.00%|        # Some of the queued calls may reentrantly call _lazy_init();
   219|         0|            0|            0|  0.00%|        # we need to just return without initializing in that case.
   220|         0|            0|            0|  0.00%|        # However, we must not let any *other* threads in!
   221|         0|            0|            0|  0.00%|        _tls.is_initializing = True
   222|         0|            0|            0|  0.00%|
   223|         0|            0|            0|  0.00%|        for calls in _lazy_seed_tracker.get_calls():
   224|         0|            0|            0|  0.00%|            if calls:
   225|         0|            0|            0|  0.00%|                _queued_calls.append(calls)
   226|         0|            0|            0|  0.00%|
   227|         0|            0|            0|  0.00%|        try:
   228|         0|            0|            0|  0.00%|            for queued_call, orig_traceback in _queued_calls:
   229|         0|            0|            0|  0.00%|                try:
   230|         0|            0|            0|  0.00%|                    queued_call()
   231|         0|            0|            0|  0.00%|                except Exception as e:
   232|         0|            0|            0|  0.00%|                    msg = (f"CUDA call failed lazily at initialization with error: {str(e)}\n\n"
   233|         0|            0|            0|  0.00%|                           f"CUDA call was originally invoked at:\n\n{orig_traceback}")
   234|         0|            0|            0|  0.00%|                    raise DeferredCudaCallError(msg) from e
   235|         0|            0|            0|  0.00%|        finally:
   236|         0|            0|            0|  0.00%|            delattr(_tls, 'is_initializing')
   237|         0|            0|            0|  0.00%|        _initialized = True
   238|         0|            0|            0|  0.00%|
   239|         0|            0|            0|  0.00%|
   240|         0|            0|            0|  0.00%|def cudart():
   241|         0|            0|            0|  0.00%|    _lazy_init()
   242|         0|            0|            0|  0.00%|    return _cudart
   243|         0|            0|            0|  0.00%|
   244|         0|            0|            0|  0.00%|
   245|         0|            0|            0|  0.00%|class cudaStatus(object):
   246|         0|            0|            0|  0.00%|    SUCCESS: int = 0
   247|         0|            0|            0|  0.00%|    ERROR_NOT_READY: int = 34
   248|         0|            0|            0|  0.00%|
   249|         0|            0|            0|  0.00%|class CudaError(RuntimeError):
   250|         0|            0|            0|  0.00%|    def __init__(self, code: int) -> None:
   251|         0|            0|            0|  0.00%|        msg = _cudart.cudaGetErrorString(_cudart.cudaError(code))
   252|         0|            0|            0|  0.00%|        super(CudaError, self).__init__('{0} ({1})'.format(msg, code))
   253|         0|            0|            0|  0.00%|
   254|         0|            0|            0|  0.00%|
   255|         0|            0|            0|  0.00%|def check_error(res: int) -> None:
   256|         0|            0|            0|  0.00%|    if res != _cudart.cudaError.success:
   257|         0|            0|            0|  0.00%|        raise CudaError(res)
   258|         0|            0|            0|  0.00%|
   259|         0|            0|            0|  0.00%|
   260|         0|            0|            0|  0.00%|class device(object):
   261|         0|            0|            0|  0.00%|    r"""Context-manager that changes the selected device.
   262|         0|            0|            0|  0.00%|
   263|         0|            0|            0|  0.00%|    Args:
   264|         0|            0|            0|  0.00%|        device (torch.device or int): device index to select. It's a no-op if
   265|         0|            0|            0|  0.00%|            this argument is a negative integer or ``None``.
   266|         0|            0|            0|  0.00%|    """
   267|         0|            0|            0|  0.00%|
   268|         0|            0|            0|  0.00%|    def __init__(self, device: Any):
   269|         0|            0|            0|  0.00%|        self.idx = _get_device_index(device, optional=True)
   270|         0|            0|            0|  0.00%|        self.prev_idx = -1
   271|         0|            0|            0|  0.00%|
   272|         0|            0|            0|  0.00%|    def __enter__(self):
   273|         0|            0|            0|  0.00%|        if self.idx == -1:
   274|         0|            0|            0|  0.00%|            return
   275|         0|            0|            0|  0.00%|        self.prev_idx = torch.cuda.current_device()
   276|         0|            0|            0|  0.00%|        if self.prev_idx != self.idx:
   277|         0|            0|            0|  0.00%|            torch.cuda.set_device(self.idx)
   278|         0|            0|            0|  0.00%|        if not torch.jit.is_scripting():
   279|         0|            0|            0|  0.00%|            _lazy_init()
   280|         0|            0|            0|  0.00%|
   281|         0|            0|            0|  0.00%|    def __exit__(self, type: Any, value: Any, traceback: Any):
   282|         0|            0|            0|  0.00%|        if self.prev_idx != self.idx:
   283|         0|            0|            0|  0.00%|            torch.cuda.set_device(self.prev_idx)
   284|         0|            0|            0|  0.00%|        return False
   285|         0|            0|            0|  0.00%|
   286|         0|            0|            0|  0.00%|
   287|         0|            0|            0|  0.00%|class device_of(device):
   288|         0|            0|            0|  0.00%|    r"""Context-manager that changes the current device to that of given object.
   289|         0|            0|            0|  0.00%|
   290|         0|            0|            0|  0.00%|    You can use both tensors and storages as arguments. If a given object is
   291|         0|            0|            0|  0.00%|    not allocated on a GPU, this is a no-op.
   292|         0|            0|            0|  0.00%|
   293|         0|            0|            0|  0.00%|    Args:
   294|         0|            0|            0|  0.00%|        obj (Tensor or Storage): object allocated on the selected device.
   295|         0|            0|            0|  0.00%|    """
   296|         0|            0|            0|  0.00%|
   297|         0|            0|            0|  0.00%|    def __init__(self, obj):
   298|         0|            0|            0|  0.00%|        idx = obj.get_device() if obj.is_cuda else -1
   299|         0|            0|            0|  0.00%|        super(device_of, self).__init__(idx)
   300|         0|            0|            0|  0.00%|
   301|         0|            0|            0|  0.00%|
   302|         0|            0|            0|  0.00%|def set_device(device: _device_t) -> None:
   303|         0|            0|            0|  0.00%|    r"""Sets the current device.
   304|         0|            0|            0|  0.00%|
   305|         0|            0|            0|  0.00%|    Usage of this function is discouraged in favor of :any:`device`. In most
   306|         0|            0|            0|  0.00%|    cases it's better to use ``CUDA_VISIBLE_DEVICES`` environmental variable.
   307|         0|            0|            0|  0.00%|
   308|         0|            0|            0|  0.00%|    Args:
   309|         0|            0|            0|  0.00%|        device (torch.device or int): selected device. This function is a no-op
   310|         0|            0|            0|  0.00%|            if this argument is negative.
   311|         0|            0|            0|  0.00%|    """
   312|         0|            0|            0|  0.00%|    device = _get_device_index(device)
   313|         0|            0|            0|  0.00%|    if device >= 0:
   314|         0|            0|            0|  0.00%|        torch._C._cuda_setDevice(device)
   315|         0|            0|            0|  0.00%|
   316|         0|            0|            0|  0.00%|
   317|         0|            0|            0|  0.00%|def get_device_name(device: Optional[_device_t] = None) -> str:
   318|         0|            0|            0|  0.00%|    r"""Gets the name of a device.
   319|         0|            0|            0|  0.00%|
   320|         0|            0|            0|  0.00%|    Args:
   321|         0|            0|            0|  0.00%|        device (torch.device or int, optional): device for which to return the
   322|         0|            0|            0|  0.00%|            name. This function is a no-op if this argument is a negative
   323|         0|            0|            0|  0.00%|            integer. It uses the current device, given by :func:`~torch.cuda.current_device`,
   324|         0|            0|            0|  0.00%|            if :attr:`device` is ``None`` (default).
   325|         0|            0|            0|  0.00%|
   326|         0|            0|            0|  0.00%|    Returns:
   327|         0|            0|            0|  0.00%|        str: the name of the device
   328|         0|            0|            0|  0.00%|    """
   329|         0|            0|            0|  0.00%|    return get_device_properties(device).name
   330|         0|            0|            0|  0.00%|
   331|         0|            0|            0|  0.00%|
   332|         0|            0|            0|  0.00%|def get_device_capability(device: Optional[_device_t] = None) -> Tuple[int, int]:
   333|         0|            0|            0|  0.00%|    r"""Gets the cuda capability of a device.
   334|         0|            0|            0|  0.00%|
   335|         0|            0|            0|  0.00%|    Args:
   336|         0|            0|            0|  0.00%|        device (torch.device or int, optional): device for which to return the
   337|         0|            0|            0|  0.00%|            device capability. This function is a no-op if this argument is
   338|         0|            0|            0|  0.00%|            a negative integer. It uses the current device, given by
   339|         0|            0|            0|  0.00%|            :func:`~torch.cuda.current_device`, if :attr:`device` is ``None``
   340|         0|            0|            0|  0.00%|            (default).
   341|         0|            0|            0|  0.00%|
   342|         0|            0|            0|  0.00%|    Returns:
   343|         0|            0|            0|  0.00%|        tuple(int, int): the major and minor cuda capability of the device
   344|         0|            0|            0|  0.00%|    """
   345|         0|            0|            0|  0.00%|    prop = get_device_properties(device)
   346|         0|            0|            0|  0.00%|    return prop.major, prop.minor
   347|         0|            0|            0|  0.00%|
   348|         0|            0|            0|  0.00%|
   349|         0|            0|            0|  0.00%|def get_device_properties(device: _device_t) -> _CudaDeviceProperties:
   350|         0|            0|            0|  0.00%|    r"""Gets the properties of a device.
   351|         0|            0|            0|  0.00%|
   352|         0|            0|            0|  0.00%|    Args:
   353|         0|            0|            0|  0.00%|        device (torch.device or int or str): device for which to return the
   354|         0|            0|            0|  0.00%|            properties of the device.
   355|         0|            0|            0|  0.00%|
   356|         0|            0|            0|  0.00%|    Returns:
   357|         0|            0|            0|  0.00%|        _CudaDeviceProperties: the properties of the device
   358|         0|            0|            0|  0.00%|    """
   359|         0|            0|            0|  0.00%|    _lazy_init()  # will define _get_device_properties
   360|         0|            0|            0|  0.00%|    device = _get_device_index(device, optional=True)
   361|         0|            0|            0|  0.00%|    if device < 0 or device >= device_count():
   362|         0|            0|            0|  0.00%|        raise AssertionError("Invalid device id")
   363|         0|            0|            0|  0.00%|    return _get_device_properties(device)  # type: ignore[name-defined]
   364|         0|            0|            0|  0.00%|
   365|         0|            0|            0|  0.00%|def can_device_access_peer(device: _device_t, peer_device: _device_t) -> bool:
   366|         0|            0|            0|  0.00%|    r"""Checks if peer access between two devices is possible.
   367|         0|            0|            0|  0.00%|    """
   368|         0|            0|            0|  0.00%|    _lazy_init()
   369|         0|            0|            0|  0.00%|    device = _get_device_index(device, optional=True)
   370|         0|            0|            0|  0.00%|    peer_device = _get_device_index(peer_device)
   371|         0|            0|            0|  0.00%|    if device < 0 or device >= device_count():
   372|         0|            0|            0|  0.00%|        raise AssertionError("Invalid device id")
   373|         0|            0|            0|  0.00%|    if peer_device < 0 or peer_device >= device_count():
   374|         0|            0|            0|  0.00%|        raise AssertionError("Invalid peer device id")
   375|         0|            0|            0|  0.00%|    return torch._C._cuda_canDeviceAccessPeer(device, peer_device)
   376|         0|            0|            0|  0.00%|
   377|         0|            0|            0|  0.00%|
   378|         0|            0|            0|  0.00%|class StreamContext(object):
   379|         0|            0|            0|  0.00%|    r"""Context-manager that selects a given stream.
   380|         0|            0|            0|  0.00%|
   381|         0|            0|            0|  0.00%|    All CUDA kernels queued within its context will be enqueued on a selected
   382|         0|            0|            0|  0.00%|    stream.
   383|         0|            0|            0|  0.00%|
   384|         0|            0|            0|  0.00%|    Args:
   385|         0|            0|            0|  0.00%|        Stream (Stream): selected stream. This manager is a no-op if it's
   386|         0|            0|            0|  0.00%|            ``None``.
   387|         0|            0|            0|  0.00%|    .. note:: Streams are per-device.
   388|         0|            0|            0|  0.00%|    """
   389|         0|            0|            0|  0.00%|    cur_stream : Optional['torch.cuda.Stream']
   390|         0|            0|            0|  0.00%|
   391|         0|            0|            0|  0.00%|    def __init__(self, stream: Optional['torch.cuda.Stream']):
   392|         0|            0|            0|  0.00%|        self.stream = stream
   393|         0|            0|            0|  0.00%|        self.idx = _get_device_index(None, True)
   394|         0|            0|            0|  0.00%|        if not torch.jit.is_scripting():
   395|         0|            0|            0|  0.00%|            if self.idx is None:
   396|         0|            0|            0|  0.00%|                self.idx = -1
   397|         0|            0|            0|  0.00%|
   398|         0|            0|            0|  0.00%|        self.src_prev_stream = None if not torch.jit.is_scripting() else torch.cuda.default_stream(None)
   399|         0|            0|            0|  0.00%|        self.dst_prev_stream = None if not torch.jit.is_scripting() else torch.cuda.default_stream(None)
   400|         0|            0|            0|  0.00%|
   401|         0|            0|            0|  0.00%|    def __enter__(self):
   402|         0|            0|            0|  0.00%|        # Local cur_stream variable for type refinement
   403|         0|            0|            0|  0.00%|        cur_stream = self.stream
   404|         0|            0|            0|  0.00%|        # Return if stream is None or CUDA device not available
   405|         0|            0|            0|  0.00%|        if cur_stream is None or self.idx == -1:
   406|         0|            0|            0|  0.00%|            return
   407|         0|            0|            0|  0.00%|        self.src_prev_stream = torch.cuda.current_stream(None)
   408|         0|            0|            0|  0.00%|
   409|         0|            0|            0|  0.00%|        # If the stream is not on the current device, then
   410|         0|            0|            0|  0.00%|        # set the current stream on the device
   411|         0|            0|            0|  0.00%|        if self.src_prev_stream.device != cur_stream.device:
   412|         0|            0|            0|  0.00%|            with device(cur_stream.device):
   413|         0|            0|            0|  0.00%|                self.dst_prev_stream = torch.cuda.current_stream(cur_stream.device)
   414|         0|            0|            0|  0.00%|        torch.cuda.set_stream(cur_stream)
   415|         0|            0|            0|  0.00%|
   416|         0|            0|            0|  0.00%|    def __exit__(self, type: Any, value: Any, traceback: Any):
   417|         0|            0|            0|  0.00%|        # Local cur_stream variable for type refinement
   418|         0|            0|            0|  0.00%|        cur_stream = self.stream
   419|         0|            0|            0|  0.00%|        # If stream is None or no CUDA device available, return
   420|         0|            0|            0|  0.00%|        if cur_stream is None or self.idx == -1:
   421|         0|            0|            0|  0.00%|            return
   422|         0|            0|            0|  0.00%|
   423|         0|            0|            0|  0.00%|        # Reset the stream on the original device
   424|         0|            0|            0|  0.00%|        # and destination device
   425|         0|            0|            0|  0.00%|        if self.src_prev_stream.device != cur_stream.device:  # type: ignore[union-attr]
   426|         0|            0|            0|  0.00%|            torch.cuda.set_stream(self.dst_prev_stream)  # type: ignore[arg-type]
   427|         0|            0|            0|  0.00%|        torch.cuda.set_stream(self.src_prev_stream)  # type: ignore[arg-type]
   428|         0|            0|            0|  0.00%|
   429|         0|            0|            0|  0.00%|def stream(stream: Optional['torch.cuda.Stream']) -> StreamContext:
   430|         0|            0|            0|  0.00%|    r"""Wrapper around the Context-manager StreamContext that
   431|         0|            0|            0|  0.00%|    selects a given stream.
   432|         0|            0|            0|  0.00%|
   433|         0|            0|            0|  0.00%|    Arguments:
   434|         0|            0|            0|  0.00%|        stream (Stream): selected stream. This manager is a no-op if it's
   435|         0|            0|            0|  0.00%|            ``None``.
   436|         0|            0|            0|  0.00%|    ..Note:: In eager mode stream is of type Stream class while in JIT it is
   437|         0|            0|            0|  0.00%|    an object of the custom class ``torch.classes.cuda.Stream``.
   438|         0|            0|            0|  0.00%|    """
   439|         0|            0|            0|  0.00%|    return StreamContext(stream)
   440|         0|            0|            0|  0.00%|
   441|         0|            0|            0|  0.00%|def set_stream(stream: Stream):
   442|         0|            0|            0|  0.00%|    r"""Sets the current stream.This is a wrapper API to set the stream.
   443|         0|            0|            0|  0.00%|        Usage of this function is discouraged in favor of the ``stream``
   444|         0|            0|            0|  0.00%|        context manager.
   445|         0|            0|            0|  0.00%|
   446|         0|            0|            0|  0.00%|    Args:
   447|         0|            0|            0|  0.00%|        stream (Stream): selected stream. This function is a no-op
   448|         0|            0|            0|  0.00%|            if this argument is ``None``.
   449|         0|            0|            0|  0.00%|    """
   450|         0|            0|            0|  0.00%|    if stream is None:
   451|         0|            0|            0|  0.00%|        return
   452|         0|            0|            0|  0.00%|    torch._C._cuda_setStream(stream._cdata)
   453|         0|            0|            0|  0.00%|
   454|         1|  4.05312e-06|  4.05312e-06|  0.00%|def device_count() -> int:
   455|         0|            0|            0|  0.00%|    r"""Returns the number of GPUs available."""
   456|         1|  8.82149e-06|  8.82149e-06|  0.00%|    if is_available():
(call)|         1|  1.09673e-05|  1.09673e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:77 is_available
   457|         1|  2.86102e-06|  2.86102e-06|  0.00%|        return torch._C._cuda_getDeviceCount()
   458|         0|            0|            0|  0.00%|    else:
   459|         0|            0|            0|  0.00%|        return 0
   460|         0|            0|            0|  0.00%|
   461|         0|            0|            0|  0.00%|def get_arch_list() -> List[str]:
   462|         0|            0|            0|  0.00%|    r"""Returns list CUDA architectures this library was compiled for."""
   463|         0|            0|            0|  0.00%|    if not is_available():
   464|         0|            0|            0|  0.00%|        return []
   465|         0|            0|            0|  0.00%|    arch_flags = torch._C._cuda_getArchFlags()
   466|         0|            0|            0|  0.00%|    if arch_flags is None:
   467|         0|            0|            0|  0.00%|        return []
   468|         0|            0|            0|  0.00%|    return arch_flags.split()
   469|         0|            0|            0|  0.00%|
   470|         0|            0|            0|  0.00%|def get_gencode_flags() -> str:
   471|         0|            0|            0|  0.00%|    r"""Returns NVCC gencode flags this library was compiled with."""
   472|         0|            0|            0|  0.00%|    arch_list = get_arch_list()
   473|         0|            0|            0|  0.00%|    if len(arch_list) == 0:
   474|         0|            0|            0|  0.00%|        return ""
   475|         0|            0|            0|  0.00%|    arch_list_ = [arch.split("_") for arch in arch_list]
   476|         0|            0|            0|  0.00%|    return " ".join([f"-gencode compute=compute_{arch},code={kind}_{arch}" for (kind, arch) in arch_list_])
   477|         0|            0|            0|  0.00%|
   478|         0|            0|            0|  0.00%|
   479|         0|            0|            0|  0.00%|
   480|         0|            0|            0|  0.00%|def current_device() -> int:
   481|         0|            0|            0|  0.00%|    r"""Returns the index of a currently selected device."""
   482|         0|            0|            0|  0.00%|    _lazy_init()
   483|         0|            0|            0|  0.00%|    return torch._C._cuda_getDevice()
   484|         0|            0|            0|  0.00%|
   485|         0|            0|            0|  0.00%|
   486|         0|            0|            0|  0.00%|def synchronize(device: _device_t = None) -> None:
   487|         0|            0|            0|  0.00%|    r"""Waits for all kernels in all streams on a CUDA device to complete.
   488|         0|            0|            0|  0.00%|
   489|         0|            0|            0|  0.00%|    Args:
   490|         0|            0|            0|  0.00%|        device (torch.device or int, optional): device for which to synchronize.
   491|         0|            0|            0|  0.00%|            It uses the current device, given by :func:`~torch.cuda.current_device`,
   492|         0|            0|            0|  0.00%|            if :attr:`device` is ``None`` (default).
   493|         0|            0|            0|  0.00%|    """
   494|         0|            0|            0|  0.00%|    _lazy_init()
   495|         0|            0|            0|  0.00%|    with torch.cuda.device(device):
   496|         0|            0|            0|  0.00%|        return torch._C._cuda_synchronize()
   497|         0|            0|            0|  0.00%|
   498|         0|            0|            0|  0.00%|
   499|         0|            0|            0|  0.00%|def ipc_collect():
   500|         0|            0|            0|  0.00%|    r"""Force collects GPU memory after it has been released by CUDA IPC.
   501|         0|            0|            0|  0.00%|
   502|         0|            0|            0|  0.00%|    .. note::
   503|         0|            0|            0|  0.00%|        Checks if any sent CUDA tensors could be cleaned from the memory. Force
   504|         0|            0|            0|  0.00%|        closes shared memory file used for reference counting if there is no
   505|         0|            0|            0|  0.00%|        active counters. Useful when the producer process stopped actively sending
   506|         0|            0|            0|  0.00%|        tensors and want to release unused memory.
   507|         0|            0|            0|  0.00%|    """
   508|         0|            0|            0|  0.00%|    _lazy_init()
   509|         0|            0|            0|  0.00%|    return torch._C._cuda_ipc_collect()
   510|         0|            0|            0|  0.00%|
   511|         0|            0|            0|  0.00%|
   512|         0|            0|            0|  0.00%|def current_stream(device: Optional[_device_t] = None) -> Stream:
   513|         0|            0|            0|  0.00%|    r"""Returns the currently selected :class:`Stream` for a given device.
   514|         0|            0|            0|  0.00%|
   515|         0|            0|            0|  0.00%|    Args:
   516|         0|            0|            0|  0.00%|        device (torch.device or int, optional): selected device. Returns
   517|         0|            0|            0|  0.00%|            the currently selected :class:`Stream` for the current device, given
   518|         0|            0|            0|  0.00%|            by :func:`~torch.cuda.current_device`, if :attr:`device` is ``None``
   519|         0|            0|            0|  0.00%|            (default).
   520|         0|            0|            0|  0.00%|    """
   521|         0|            0|            0|  0.00%|    _lazy_init()
   522|         0|            0|            0|  0.00%|    return Stream(_cdata=torch._C._cuda_getCurrentStream(
   523|         0|            0|            0|  0.00%|        _get_device_index(device, optional=True)))
   524|         0|            0|            0|  0.00%|
   525|         0|            0|            0|  0.00%|
   526|         0|            0|            0|  0.00%|def default_stream(device: Optional[_device_t] = None) -> Stream:
   527|         0|            0|            0|  0.00%|    r"""Returns the default :class:`Stream` for a given device.
   528|         0|            0|            0|  0.00%|
   529|         0|            0|            0|  0.00%|    Args:
   530|         0|            0|            0|  0.00%|        device (torch.device or int, optional): selected device. Returns
   531|         0|            0|            0|  0.00%|            the default :class:`Stream` for the current device, given by
   532|         0|            0|            0|  0.00%|            :func:`~torch.cuda.current_device`, if :attr:`device` is ``None``
   533|         0|            0|            0|  0.00%|            (default).
   534|         0|            0|            0|  0.00%|    """
   535|         0|            0|            0|  0.00%|    _lazy_init()
   536|         0|            0|            0|  0.00%|    return Stream(_cdata=torch._C._cuda_getDefaultStream(
   537|         0|            0|            0|  0.00%|        _get_device_index(device, optional=True)))
   538|         0|            0|            0|  0.00%|
   539|         0|            0|            0|  0.00%|
   540|         0|            0|            0|  0.00%|def current_blas_handle():
   541|         0|            0|            0|  0.00%|    r"""Returns cublasHandle_t pointer to current cuBLAS handle"""
   542|         0|            0|            0|  0.00%|    _lazy_init()
   543|         0|            0|            0|  0.00%|    return torch._C._cuda_getCurrentBlasHandle()
   544|         0|            0|            0|  0.00%|
   545|         0|            0|            0|  0.00%|def set_sync_debug_mode(debug_mode: Union[int, str]) -> None:
   546|         0|            0|            0|  0.00%|    r"""Sets the debug mode for cuda synchronizing operations.
   547|         0|            0|            0|  0.00%|
   548|         0|            0|            0|  0.00%|    Args:
   549|         0|            0|            0|  0.00%|        debug_mode(str or int): if "default" or 0, don't error or warn on synchronizing operations,
   550|         0|            0|            0|  0.00%|            if "warn" or 1, warn on synchronizing operations, if "error" or 2, error out synchronizing operations.
   551|         0|            0|            0|  0.00%|
   552|         0|            0|            0|  0.00%|    Warning:
   553|         0|            0|            0|  0.00%|        This is an experimental feature, and not all synchronizing operations will trigger warning or error. In
   554|         0|            0|            0|  0.00%|        particular, operations in torch.distributed and torch.sparse namespaces are not covered yet.
   555|         0|            0|            0|  0.00%|    """
   556|         0|            0|            0|  0.00%|
   557|         0|            0|            0|  0.00%|    _lazy_init()
   558|         0|            0|            0|  0.00%|    if isinstance(debug_mode, str):
   559|         0|            0|            0|  0.00%|        if debug_mode == "default":
   560|         0|            0|            0|  0.00%|            debug_mode = 0
   561|         0|            0|            0|  0.00%|        elif debug_mode == "warn":
   562|         0|            0|            0|  0.00%|            debug_mode = 1
   563|         0|            0|            0|  0.00%|        elif debug_mode == "error":
   564|         0|            0|            0|  0.00%|            debug_mode = 2
   565|         0|            0|            0|  0.00%|        else:
   566|         0|            0|            0|  0.00%|            raise RuntimeError("invalid value of debug_mode, expected one of `default`, `warn`, `error`")
   567|         0|            0|            0|  0.00%|
   568|         0|            0|            0|  0.00%|    torch._C._cuda_set_sync_debug_mode(debug_mode)
   569|         0|            0|            0|  0.00%|
   570|         0|            0|            0|  0.00%|def get_sync_debug_mode() -> int:
   571|         0|            0|            0|  0.00%|    r"""Returns current value of debug mode for cuda synchronizing operations."""
   572|         0|            0|            0|  0.00%|
   573|         0|            0|            0|  0.00%|    _lazy_init()
   574|         0|            0|            0|  0.00%|    return torch._C._cuda_get_sync_debug_mode()
   575|         0|            0|            0|  0.00%|
   576|         0|            0|            0|  0.00%|
   577|         0|            0|            0|  0.00%|def memory_usage(device: Optional[Union[Device, int]] = None) -> int:
   578|         0|            0|            0|  0.00%|    r"""Returns the percent of time over the past sample period during which global (device)
   579|         0|            0|            0|  0.00%|    memory was being read or written. as given by `nvidia-smi`.
   580|         0|            0|            0|  0.00%|
   581|         0|            0|            0|  0.00%|    Args:
   582|         0|            0|            0|  0.00%|        device (torch.device or int, optional): selected device. Returns
   583|         0|            0|            0|  0.00%|            statistic for the current device, given by :func:`~torch.cuda.current_device`,
   584|         0|            0|            0|  0.00%|            if :attr:`device` is ``None`` (default).
   585|         0|            0|            0|  0.00%|
   586|         0|            0|            0|  0.00%|    Warning: Each sample period may be between 1 second and 1/6 second,
   587|         0|            0|            0|  0.00%|    depending on the product being queried.
   588|         0|            0|            0|  0.00%|    """
   589|         0|            0|            0|  0.00%|    try:
   590|         0|            0|            0|  0.00%|        import pynvml  # type: ignore[import]
   591|         0|            0|            0|  0.00%|    except ModuleNotFoundError:
   592|         0|            0|            0|  0.00%|        raise ModuleNotFoundError("pynvml module not found, please install pynvml")
   593|         0|            0|            0|  0.00%|    from pynvml import NVMLError_DriverNotLoaded
   594|         0|            0|            0|  0.00%|    try:
   595|         0|            0|            0|  0.00%|        pynvml.nvmlInit()
   596|         0|            0|            0|  0.00%|    except NVMLError_DriverNotLoaded:
   597|         0|            0|            0|  0.00%|        raise RuntimeError("cuda driver can't be loaded, is cuda enabled?")
   598|         0|            0|            0|  0.00%|    device = _get_device_index(device, optional=True)
   599|         0|            0|            0|  0.00%|    handle = pynvml.nvmlDeviceGetHandleByIndex(device)
   600|         0|            0|            0|  0.00%|    return pynvml.nvmlDeviceGetUtilizationRates(handle).memory
   601|         0|            0|            0|  0.00%|
   602|         0|            0|            0|  0.00%|
   603|         0|            0|            0|  0.00%|def utilization(device: Optional[Union[Device, int]] = None) -> int:
   604|         0|            0|            0|  0.00%|    r"""Returns the percent of time over the past sample period during which one or
   605|         0|            0|            0|  0.00%|    more kernels was executing on the GPU as given by `nvidia-smi`.
   606|         0|            0|            0|  0.00%|
   607|         0|            0|            0|  0.00%|    Args:
   608|         0|            0|            0|  0.00%|        device (torch.device or int, optional): selected device. Returns
   609|         0|            0|            0|  0.00%|            statistic for the current device, given by :func:`~torch.cuda.current_device`,
   610|         0|            0|            0|  0.00%|            if :attr:`device` is ``None`` (default).
   611|         0|            0|            0|  0.00%|
   612|         0|            0|            0|  0.00%|    Warning: Each sample period may be between 1 second and 1/6 second,
   613|         0|            0|            0|  0.00%|    depending on the product being queried.
   614|         0|            0|            0|  0.00%|    """
   615|         0|            0|            0|  0.00%|    try:
   616|         0|            0|            0|  0.00%|        import pynvml  # type: ignore[import]
   617|         0|            0|            0|  0.00%|    except ModuleNotFoundError:
   618|         0|            0|            0|  0.00%|        raise ModuleNotFoundError("pynvml module not found, please install pynvml")
   619|         0|            0|            0|  0.00%|    from pynvml import NVMLError_DriverNotLoaded
   620|         0|            0|            0|  0.00%|    try:
   621|         0|            0|            0|  0.00%|        pynvml.nvmlInit()
   622|         0|            0|            0|  0.00%|    except NVMLError_DriverNotLoaded:
   623|         0|            0|            0|  0.00%|        raise RuntimeError("cuda driver can't be loaded, is cuda enabled?")
   624|         0|            0|            0|  0.00%|    device = _get_device_index(device, optional=True)
   625|         0|            0|            0|  0.00%|    handle = pynvml.nvmlDeviceGetHandleByIndex(device)
   626|         0|            0|            0|  0.00%|    return pynvml.nvmlDeviceGetUtilizationRates(handle).gpu
   627|         0|            0|            0|  0.00%|
   628|         0|            0|            0|  0.00%|
   629|         0|            0|            0|  0.00%|from .memory import *  # noqa: F403
   630|         0|            0|            0|  0.00%|
   631|         0|            0|            0|  0.00%|
   632|         0|            0|            0|  0.00%|from .random import *  # noqa: F403
   633|         0|            0|            0|  0.00%|
   634|         0|            0|            0|  0.00%|################################################################################
   635|         0|            0|            0|  0.00%|# Define Storage and Tensor classes
   636|         0|            0|            0|  0.00%|################################################################################
   637|         0|            0|            0|  0.00%|
   638|         0|            0|            0|  0.00%|@staticmethod  # type: ignore[misc]
   639|         0|            0|            0|  0.00%|def _lazy_new(cls, *args, **kwargs):
   640|         0|            0|            0|  0.00%|    _lazy_init()
   641|         0|            0|            0|  0.00%|    # We may need to call lazy init again if we are a forked child
   642|         0|            0|            0|  0.00%|    # del _CudaBase.__new__
   643|         0|            0|            0|  0.00%|    return super(_CudaBase, cls).__new__(cls, *args, **kwargs)
   644|         0|            0|            0|  0.00%|
   645|         0|            0|            0|  0.00%|
   646|         0|            0|            0|  0.00%|class _CudaBase(object):
   647|         0|            0|            0|  0.00%|    is_cuda = True
   648|         0|            0|            0|  0.00%|    is_sparse = False
   649|         0|            0|            0|  0.00%|
   650|         0|            0|            0|  0.00%|    def type(self, *args, **kwargs):
   651|         0|            0|            0|  0.00%|        # We could use a Protocol here to tell mypy that self has `get_device` method
   652|         0|            0|            0|  0.00%|        # but it is only available in the typing module on Python >= 3.8
   653|         0|            0|            0|  0.00%|        # or on typing_extensions module on Python >= 3.6
   654|         0|            0|            0|  0.00%|        with device(self.get_device()):  # type: ignore[attr-defined]
   655|         0|            0|            0|  0.00%|            return super(_CudaBase, self).type(*args, **kwargs)  # type: ignore[misc]
   656|         0|            0|            0|  0.00%|
   657|         0|            0|            0|  0.00%|    __new__ = _lazy_new
   658|         0|            0|            0|  0.00%|
   659|         0|            0|            0|  0.00%|from torch.storage import _LegacyStorage
   660|         0|            0|            0|  0.00%|
   661|         0|            0|            0|  0.00%|class _CudaLegacyStorage(_LegacyStorage):
   662|         0|            0|            0|  0.00%|    @classmethod
   663|         0|            0|            0|  0.00%|    def from_buffer(cls, *args, **kwargs):
   664|         0|            0|            0|  0.00%|        raise RuntimeError('from_buffer: Not available for CUDA storage')
   665|         0|            0|            0|  0.00%|
   666|         0|            0|            0|  0.00%|    @classmethod
   667|         0|            0|            0|  0.00%|    def _new_with_weak_ptr(cls, *args, **kwargs):
   668|         0|            0|            0|  0.00%|        raise RuntimeError('_new_with_weak_ptr: Not available for CUDA storage')
   669|         0|            0|            0|  0.00%|
   670|         0|            0|            0|  0.00%|    @classmethod
   671|         0|            0|            0|  0.00%|    def _new_shared_filename(cls, manager, obj, size, *, device=None, dtype=None):
   672|         0|            0|            0|  0.00%|        raise RuntimeError('_new_shared_filename: Not available for CUDA storage')
   673|         0|            0|            0|  0.00%|
   674|         0|            0|            0|  0.00%|class ByteStorage(_CudaLegacyStorage):
   675|         0|            0|            0|  0.00%|    @classproperty
   676|         0|            0|            0|  0.00%|    def dtype(self):
   677|         0|            0|            0|  0.00%|        return torch.uint8
   678|         0|            0|            0|  0.00%|
   679|         0|            0|            0|  0.00%|class DoubleStorage(_CudaLegacyStorage):
   680|         0|            0|            0|  0.00%|    @classproperty
   681|         0|            0|            0|  0.00%|    def dtype(self):
   682|         0|            0|            0|  0.00%|        return torch.double
   683|         0|            0|            0|  0.00%|
   684|         0|            0|            0|  0.00%|class FloatStorage(_CudaLegacyStorage):
   685|         0|            0|            0|  0.00%|    @classproperty
   686|         0|            0|            0|  0.00%|    def dtype(self):
   687|         0|            0|            0|  0.00%|        return torch.float
   688|         0|            0|            0|  0.00%|
   689|         0|            0|            0|  0.00%|class HalfStorage(_CudaLegacyStorage):
   690|         0|            0|            0|  0.00%|    @classproperty
   691|         0|            0|            0|  0.00%|    def dtype(self):
   692|         0|            0|            0|  0.00%|        return torch.half
   693|         0|            0|            0|  0.00%|
   694|         0|            0|            0|  0.00%|class LongStorage(_CudaLegacyStorage):
   695|         0|            0|            0|  0.00%|    @classproperty
   696|         0|            0|            0|  0.00%|    def dtype(self):
   697|         0|            0|            0|  0.00%|        return torch.long
   698|         0|            0|            0|  0.00%|
   699|         0|            0|            0|  0.00%|class IntStorage(_CudaLegacyStorage):
   700|         0|            0|            0|  0.00%|    @classproperty
   701|         0|            0|            0|  0.00%|    def dtype(self):
   702|         0|            0|            0|  0.00%|        return torch.int
   703|         0|            0|            0|  0.00%|
   704|         0|            0|            0|  0.00%|class ShortStorage(_CudaLegacyStorage):
   705|         0|            0|            0|  0.00%|    @classproperty
   706|         0|            0|            0|  0.00%|    def dtype(self):
   707|         0|            0|            0|  0.00%|        return torch.short
   708|         0|            0|            0|  0.00%|
   709|         0|            0|            0|  0.00%|class CharStorage(_CudaLegacyStorage):
   710|         0|            0|            0|  0.00%|    @classproperty
   711|         0|            0|            0|  0.00%|    def dtype(self):
   712|         0|            0|            0|  0.00%|        return torch.int8
   713|         0|            0|            0|  0.00%|
   714|         0|            0|            0|  0.00%|class BoolStorage(_CudaLegacyStorage):
   715|         0|            0|            0|  0.00%|    @classproperty
   716|         0|            0|            0|  0.00%|    def dtype(self):
   717|         0|            0|            0|  0.00%|        return torch.bool
   718|         0|            0|            0|  0.00%|
   719|         0|            0|            0|  0.00%|class BFloat16Storage(_CudaLegacyStorage):
   720|         0|            0|            0|  0.00%|    @classproperty
   721|         0|            0|            0|  0.00%|    def dtype(self):
   722|         0|            0|            0|  0.00%|        return torch.bfloat16
   723|         0|            0|            0|  0.00%|
   724|         0|            0|            0|  0.00%|class ComplexDoubleStorage(_CudaLegacyStorage):
   725|         0|            0|            0|  0.00%|    @classproperty
   726|         0|            0|            0|  0.00%|    def dtype(self):
   727|         0|            0|            0|  0.00%|        return torch.cdouble
   728|         0|            0|            0|  0.00%|
   729|         0|            0|            0|  0.00%|class ComplexFloatStorage(_CudaLegacyStorage):
   730|         0|            0|            0|  0.00%|    @classproperty
   731|         0|            0|            0|  0.00%|    def dtype(self):
   732|         0|            0|            0|  0.00%|        return torch.cfloat
   733|         0|            0|            0|  0.00%|
   734|         0|            0|            0|  0.00%|del _LegacyStorage
   735|         0|            0|            0|  0.00%|del _CudaLegacyStorage
   736|         0|            0|            0|  0.00%|
   737|         0|            0|            0|  0.00%|torch._storage_classes.add(DoubleStorage)
   738|         0|            0|            0|  0.00%|torch._storage_classes.add(FloatStorage)
   739|         0|            0|            0|  0.00%|torch._storage_classes.add(LongStorage)
   740|         0|            0|            0|  0.00%|torch._storage_classes.add(IntStorage)
   741|         0|            0|            0|  0.00%|torch._storage_classes.add(ShortStorage)
   742|         0|            0|            0|  0.00%|torch._storage_classes.add(CharStorage)
   743|         0|            0|            0|  0.00%|torch._storage_classes.add(ByteStorage)
   744|         0|            0|            0|  0.00%|torch._storage_classes.add(HalfStorage)
   745|         0|            0|            0|  0.00%|torch._storage_classes.add(BoolStorage)
   746|         0|            0|            0|  0.00%|torch._storage_classes.add(BFloat16Storage)
   747|         0|            0|            0|  0.00%|torch._storage_classes.add(ComplexDoubleStorage)
   748|         0|            0|            0|  0.00%|torch._storage_classes.add(ComplexFloatStorage)
   749|         0|            0|            0|  0.00%|
   750|         0|            0|            0|  0.00%|from . import sparse
   751|         0|            0|            0|  0.00%|from . import profiler
   752|         0|            0|            0|  0.00%|from . import nvtx
   753|         0|            0|            0|  0.00%|from . import amp
   754|         0|            0|            0|  0.00%|from . import jiterator
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/cuda/graphs.py
File duration: 0.00100851s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import gc
     2|         0|            0|            0|  0.00%|import torch
     3|         0|            0|            0|  0.00%|
     4|         0|            0|            0|  0.00%|from ._utils import _dummy_type
     5|         0|            0|            0|  0.00%|
     6|         0|            0|            0|  0.00%|
     7|         0|            0|            0|  0.00%|if not hasattr(torch._C, '_CudaStreamBase'):
     8|         0|            0|            0|  0.00%|    # Define dummy base classes
     9|         0|            0|            0|  0.00%|    torch._C.__dict__['_CUDAGraph'] = _dummy_type('_CUDAGraph')
    10|         0|            0|            0|  0.00%|    torch._C.__dict__['_graph_pool_handle'] = _dummy_type('_graph_pool_handle')
    11|         0|            0|            0|  0.00%|    torch._C.__dict__['_cuda_isCurrentStreamCapturing'] = _dummy_type('_cuda_isCurrentStreamCapturing')
    12|         0|            0|            0|  0.00%|
    13|         0|            0|            0|  0.00%|from torch._C import _CUDAGraph  # noqa: F401
    14|         0|            0|            0|  0.00%|from torch._C import _graph_pool_handle
    15|         0|            0|            0|  0.00%|from torch._C import _cuda_isCurrentStreamCapturing
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|
    18|       288|  0.000422955|  1.46859e-06|  0.00%|def is_current_stream_capturing():
    19|         0|            0|            0|  0.00%|    r"""
    20|         0|            0|            0|  0.00%|    Returns True if CUDA graph capture is underway on the current CUDA stream, False otherwise.
    21|         0|            0|            0|  0.00%|
    22|         0|            0|            0|  0.00%|    If a CUDA context does not exist on the current device, returns False without initializing the context.
    23|         0|            0|            0|  0.00%|    """
    24|       288|  0.000585556|  2.03318e-06|  0.00%|    return _cuda_isCurrentStreamCapturing()
    25|         0|            0|            0|  0.00%|
    26|         0|            0|            0|  0.00%|# Python shim helps Sphinx process docstrings more reliably.
    27|         0|            0|            0|  0.00%|def graph_pool_handle():
    28|         0|            0|            0|  0.00%|    r"""
    29|         0|            0|            0|  0.00%|    Returns an opaque token representing the id of a graph memory pool.
    30|         0|            0|            0|  0.00%|    See :ref:`Graph memory management<graph-memory-management>`.
    31|         0|            0|            0|  0.00%|
    32|         0|            0|            0|  0.00%|    .. warning::
    33|         0|            0|            0|  0.00%|        This API is in beta and may change in future releases.
    34|         0|            0|            0|  0.00%|    """
    35|         0|            0|            0|  0.00%|    return _graph_pool_handle()
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|
    38|         0|            0|            0|  0.00%|# Python shim helps Sphinx process docstrings more reliably.
    39|         0|            0|            0|  0.00%|class CUDAGraph(torch._C._CUDAGraph):
    40|         0|            0|            0|  0.00%|    r"""
    41|         0|            0|            0|  0.00%|    Wrapper around a CUDA graph.
    42|         0|            0|            0|  0.00%|
    43|         0|            0|            0|  0.00%|    .. warning::
    44|         0|            0|            0|  0.00%|        This API is in beta and may change in future releases.
    45|         0|            0|            0|  0.00%|    """
    46|         0|            0|            0|  0.00%|    def __new__(cls):
    47|         0|            0|            0|  0.00%|        return super(CUDAGraph, cls).__new__(cls)
    48|         0|            0|            0|  0.00%|
    49|         0|            0|            0|  0.00%|    def __init__(self):
    50|         0|            0|            0|  0.00%|        super(CUDAGraph, self).__init__()
    51|         0|            0|            0|  0.00%|
    52|         0|            0|            0|  0.00%|    def capture_begin(self, pool=None):
    53|         0|            0|            0|  0.00%|        r"""
    54|         0|            0|            0|  0.00%|        Begins capturing CUDA work on the current stream.
    55|         0|            0|            0|  0.00%|
    56|         0|            0|            0|  0.00%|        Typically, you shouldn't call ``capture_begin`` yourself.
    57|         0|            0|            0|  0.00%|        Use :class:`~torch.cuda.graph` or :func:`~torch.cuda.make_graphed_callables`,
    58|         0|            0|            0|  0.00%|        which call ``capture_begin`` internally.
    59|         0|            0|            0|  0.00%|
    60|         0|            0|            0|  0.00%|        Arguments:
    61|         0|            0|            0|  0.00%|            pool (optional): Token (returned by :func:`~torch.cuda.graph_pool_handle` or
    62|         0|            0|            0|  0.00%|                :meth:`other_Graph_instance.pool()<torch.cuda.CUDAGraph.pool>`) that hints this graph may share memory
    63|         0|            0|            0|  0.00%|                with the indicated pool.  See :ref:`Graph memory management<graph-memory-management>`.
    64|         0|            0|            0|  0.00%|        """
    65|         0|            0|            0|  0.00%|        # I'm not sure if pybind11 converts a None arg to the default defined on the C++ side,
    66|         0|            0|            0|  0.00%|        # so I'm not taking any chances.
    67|         0|            0|            0|  0.00%|        if pool is None:
    68|         0|            0|            0|  0.00%|            super(CUDAGraph, self).capture_begin()
    69|         0|            0|            0|  0.00%|        else:
    70|         0|            0|            0|  0.00%|            super(CUDAGraph, self).capture_begin(pool)
    71|         0|            0|            0|  0.00%|
    72|         0|            0|            0|  0.00%|    def capture_end(self):
    73|         0|            0|            0|  0.00%|        r"""
    74|         0|            0|            0|  0.00%|        Ends CUDA graph capture on the current stream.
    75|         0|            0|            0|  0.00%|        After ``capture_end``, ``replay`` may be called on this instance.
    76|         0|            0|            0|  0.00%|
    77|         0|            0|            0|  0.00%|        Typically, you shouldn't call ``capture_end`` yourself.
    78|         0|            0|            0|  0.00%|        Use :class:`~torch.cuda.graph` or :func:`~torch.cuda.make_graphed_callables`,
    79|         0|            0|            0|  0.00%|        which call ``capture_end`` internally.
    80|         0|            0|            0|  0.00%|        """
    81|         0|            0|            0|  0.00%|        super(CUDAGraph, self).capture_end()
    82|         0|            0|            0|  0.00%|
    83|         0|            0|            0|  0.00%|    def replay(self):
    84|         0|            0|            0|  0.00%|        r"""
    85|         0|            0|            0|  0.00%|        Replays the CUDA work captured by this graph.
    86|         0|            0|            0|  0.00%|        """
    87|         0|            0|            0|  0.00%|        super(CUDAGraph, self).replay()
    88|         0|            0|            0|  0.00%|
    89|         0|            0|            0|  0.00%|    def reset(self):
    90|         0|            0|            0|  0.00%|        r"""
    91|         0|            0|            0|  0.00%|        Deletes the graph currently held by this instance.
    92|         0|            0|            0|  0.00%|        """
    93|         0|            0|            0|  0.00%|        super(CUDAGraph, self).reset()
    94|         0|            0|            0|  0.00%|
    95|         0|            0|            0|  0.00%|    def pool(self):
    96|         0|            0|            0|  0.00%|        r"""
    97|         0|            0|            0|  0.00%|        Returns an opaque token representing the id of this graph's memory pool.
    98|         0|            0|            0|  0.00%|        This id can optionally be passed to another graph's ``capture_begin``,
    99|         0|            0|            0|  0.00%|        which hints the other graph may share the same memory pool.
   100|         0|            0|            0|  0.00%|        """
   101|         0|            0|            0|  0.00%|        return super(CUDAGraph, self).pool()
   102|         0|            0|            0|  0.00%|
   103|         0|            0|            0|  0.00%|
   104|         0|            0|            0|  0.00%|class graph(object):
   105|         0|            0|            0|  0.00%|    r"""
   106|         0|            0|            0|  0.00%|    Context-manager that captures CUDA work into a :class:`torch.cuda.CUDAGraph`
   107|         0|            0|            0|  0.00%|    object for later replay.
   108|         0|            0|            0|  0.00%|
   109|         0|            0|            0|  0.00%|    See :ref:`CUDA Graphs <cuda-graph-semantics>` for a general introduction,
   110|         0|            0|            0|  0.00%|    detailed use, and constraints.
   111|         0|            0|            0|  0.00%|
   112|         0|            0|            0|  0.00%|    Arguments:
   113|         0|            0|            0|  0.00%|        cuda_graph (torch.cuda.CUDAGraph): Graph object used for capture.
   114|         0|            0|            0|  0.00%|        pool (optional): Opaque token (returned by a call to :func:`~torch.cuda.graph_pool_handle()` or
   115|         0|            0|            0|  0.00%|            :meth:`other_Graph_instance.pool()<torch.cuda.CUDAGraph.pool>`) hinting this graph's capture
   116|         0|            0|            0|  0.00%|            may share memory from the specified pool. See :ref:`Graph memory management<graph-memory-management>`.
   117|         0|            0|            0|  0.00%|        stream (torch.cuda.Stream, optional): If supplied, will be set as the current stream in the context.
   118|         0|            0|            0|  0.00%|            If not supplied, ``graph`` sets its own internal side stream as the current stream in the context.
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|    .. note::
   121|         0|            0|            0|  0.00%|        For effective memory sharing, if you pass a ``pool`` used by a previous capture and the previous capture
   122|         0|            0|            0|  0.00%|        used an explicit ``stream`` argument, you should pass the same ``stream`` argument to this capture.
   123|         0|            0|            0|  0.00%|
   124|         0|            0|            0|  0.00%|    .. warning::
   125|         0|            0|            0|  0.00%|        This API is in beta and may change in future releases.
   126|         0|            0|            0|  0.00%|    """
   127|         0|            0|            0|  0.00%|    default_capture_stream = None
   128|         0|            0|            0|  0.00%|
   129|         0|            0|            0|  0.00%|    def __init__(self,
   130|         0|            0|            0|  0.00%|                 cuda_graph,
   131|         0|            0|            0|  0.00%|                 pool=None,
   132|         0|            0|            0|  0.00%|                 stream=None):
   133|         0|            0|            0|  0.00%|        # Lazy-init of default_capture_stream helps avoid circular-import errors.
   134|         0|            0|            0|  0.00%|        # Not thread safe, but graphs already have the general (explicitly documented)
   135|         0|            0|            0|  0.00%|        # restriction that only one capture may be underway at a time in the process.
   136|         0|            0|            0|  0.00%|        if self.__class__.default_capture_stream is None:
   137|         0|            0|            0|  0.00%|            self.__class__.default_capture_stream = torch.cuda.Stream()
   138|         0|            0|            0|  0.00%|
   139|         0|            0|            0|  0.00%|        self.pool = () if pool is None else (pool,)
   140|         0|            0|            0|  0.00%|        self.capture_stream = stream if stream is not None else self.__class__.default_capture_stream
   141|         0|            0|            0|  0.00%|        assert self.capture_stream is not None
   142|         0|            0|            0|  0.00%|        self.stream_ctx = torch.cuda.stream(self.capture_stream)
   143|         0|            0|            0|  0.00%|        self.cuda_graph = cuda_graph
   144|         0|            0|            0|  0.00%|
   145|         0|            0|            0|  0.00%|    def __enter__(self):
   146|         0|            0|            0|  0.00%|        # Free as much memory as we can for the graph
   147|         0|            0|            0|  0.00%|        torch.cuda.synchronize()
   148|         0|            0|            0|  0.00%|        gc.collect()
   149|         0|            0|            0|  0.00%|        torch.cuda.empty_cache()
   150|         0|            0|            0|  0.00%|
   151|         0|            0|            0|  0.00%|        # Stackoverflow seems comfortable with this pattern
   152|         0|            0|            0|  0.00%|        # https://stackoverflow.com/questions/26635684/calling-enter-and-exit-manually#39172487
   153|         0|            0|            0|  0.00%|        self.stream_ctx.__enter__()
   154|         0|            0|            0|  0.00%|
   155|         0|            0|            0|  0.00%|        self.cuda_graph.capture_begin(*self.pool)
   156|         0|            0|            0|  0.00%|
   157|         0|            0|            0|  0.00%|
   158|         0|            0|            0|  0.00%|    def __exit__(self, exc_type, exc_value, traceback):
   159|         0|            0|            0|  0.00%|        self.cuda_graph.capture_end()
   160|         0|            0|            0|  0.00%|        self.stream_ctx.__exit__(exc_type, exc_value, traceback)
   161|         0|            0|            0|  0.00%|        # returning None should propagate exceptions from either capture_end or stream_ctx.__exit__()
   162|         0|            0|            0|  0.00%|
   163|         0|            0|            0|  0.00%|
   164|         0|            0|            0|  0.00%|def make_graphed_callables(callables, sample_args):
   165|         0|            0|            0|  0.00%|    r"""
   166|         0|            0|            0|  0.00%|    Accepts callables (functions or :class:`nn.Module<torch.nn.Module>`\ s)
   167|         0|            0|            0|  0.00%|    and returns graphed versions.
   168|         0|            0|            0|  0.00%|
   169|         0|            0|            0|  0.00%|    Each graphed callable's forward pass runs its source callable's
   170|         0|            0|            0|  0.00%|    forward CUDA work as a CUDA graph inside a single autograd node.
   171|         0|            0|            0|  0.00%|
   172|         0|            0|            0|  0.00%|    The graphed callable's forward pass also appends
   173|         0|            0|            0|  0.00%|    a backward node to the autograd graph. During backward, this node runs the
   174|         0|            0|            0|  0.00%|    callable's backward work as a CUDA graph.
   175|         0|            0|            0|  0.00%|
   176|         0|            0|            0|  0.00%|    Therefore, each graphed callable should be a drop-in replacement for its source callable
   177|         0|            0|            0|  0.00%|    in an autograd-enabled training loop.
   178|         0|            0|            0|  0.00%|
   179|         0|            0|            0|  0.00%|    See :ref:`Partial-network capture<partial-network-capture>` for detailed use and constraints.
   180|         0|            0|            0|  0.00%|
   181|         0|            0|            0|  0.00%|    If you pass a tuple of several callables, their captures will use the same memory pool.
   182|         0|            0|            0|  0.00%|    See :ref:`Graph memory management<graph-memory-management>` for when this is appropriate.
   183|         0|            0|            0|  0.00%|
   184|         0|            0|            0|  0.00%|    Arguments:
   185|         0|            0|            0|  0.00%|        callables (torch.nn.Module or Python function, or tuple of these): Callable or callables to graph.
   186|         0|            0|            0|  0.00%|            See :ref:`Graph memory management<graph-memory-management>` for when passing a tuple of callables
   187|         0|            0|            0|  0.00%|            is appropriate.  If you pass a tuple of callables, their order in the tuple must be the same order
   188|         0|            0|            0|  0.00%|            they'll run in the live workload.
   189|         0|            0|            0|  0.00%|        sample_args (tuple of Tensors, or tuple of tuples of Tensors): Samples args for each callable.
   190|         0|            0|            0|  0.00%|            If a single callable was passed, ``sample_args`` must be a single tuple of argument Tensors.
   191|         0|            0|            0|  0.00%|            If a tuple of callables was passed, ``sample_args`` must be tuple of tuples of argument Tensors.
   192|         0|            0|            0|  0.00%|
   193|         0|            0|            0|  0.00%|    .. note::
   194|         0|            0|            0|  0.00%|        The ``requires_grad`` state of each Tensor in ``sample_args`` must match the state
   195|         0|            0|            0|  0.00%|        that's expected for the corresponding real input in the training loop.
   196|         0|            0|            0|  0.00%|
   197|         0|            0|            0|  0.00%|    .. warning::
   198|         0|            0|            0|  0.00%|        This API is in beta and may change in future releases.
   199|         0|            0|            0|  0.00%|
   200|         0|            0|            0|  0.00%|    .. warning::
   201|         0|            0|            0|  0.00%|        ``sample_args`` for each callable must be a tuple of Tensors. Other types and keyword args
   202|         0|            0|            0|  0.00%|        are not allowed.
   203|         0|            0|            0|  0.00%|
   204|         0|            0|            0|  0.00%|    .. warning::
   205|         0|            0|            0|  0.00%|        Returned callables do not support higher order differentiation (e.g., double backward).
   206|         0|            0|            0|  0.00%|
   207|         0|            0|            0|  0.00%|    .. warning::
   208|         0|            0|            0|  0.00%|        In any :class:`~torch.nn.Module` passed to :func:`~make_graphed_callables`, only parameters
   209|         0|            0|            0|  0.00%|        may be trainable. Buffers must have ``requires_grad=False``.
   210|         0|            0|            0|  0.00%|
   211|         0|            0|            0|  0.00%|    .. warning::
   212|         0|            0|            0|  0.00%|        After you pass a :class:`torch.nn.Module` through :func:`~make_graphed_callables`,
   213|         0|            0|            0|  0.00%|        you may not add or remove any of that Module's parameters or buffers.
   214|         0|            0|            0|  0.00%|
   215|         0|            0|            0|  0.00%|    .. warning::
   216|         0|            0|            0|  0.00%|        :class:`torch.nn.Module`\s passed to :func:`~torch.cuda.make_graphed_callables` must not have module hooks
   217|         0|            0|            0|  0.00%|        registered on them at the time they are passed. However, registering hooks on modules *after* passing them
   218|         0|            0|            0|  0.00%|        through :func:`~torch.cuda.make_graphed_callables` is allowed.
   219|         0|            0|            0|  0.00%|
   220|         0|            0|            0|  0.00%|    .. warning::
   221|         0|            0|            0|  0.00%|        When running a graphed callable, you must pass its arguments in the same order and format
   222|         0|            0|            0|  0.00%|        they appeared in that callable's ``sample_args``.
   223|         0|            0|            0|  0.00%|
   224|         0|            0|            0|  0.00%|    .. warning::
   225|         0|            0|            0|  0.00%|        All Tensor outputs of graphed callables must require grad.
   226|         0|            0|            0|  0.00%|    """
   227|         0|            0|            0|  0.00%|    just_one_callable = False
   228|         0|            0|            0|  0.00%|
   229|         0|            0|            0|  0.00%|    if not isinstance(callables, tuple):
   230|         0|            0|            0|  0.00%|        just_one_callable = True
   231|         0|            0|            0|  0.00%|        callables = (callables,)
   232|         0|            0|            0|  0.00%|        sample_args = (sample_args,)
   233|         0|            0|            0|  0.00%|
   234|         0|            0|            0|  0.00%|    for c, args in zip(callables, sample_args):
   235|         0|            0|            0|  0.00%|        if isinstance(c, torch.nn.Module):
   236|         0|            0|            0|  0.00%|            assert len(c._backward_hooks) == 0 and len(c._forward_hooks) == 0 and len(c._forward_pre_hooks) == 0, \
   237|         0|            0|            0|  0.00%|                "Modules must not have hooks registered at the time they are passed. However, registering hooks " + \
   238|         0|            0|            0|  0.00%|                "on modules after passing them through make_graphed_callables is allowed."
   239|         0|            0|            0|  0.00%|            assert all(b.requires_grad is False for b in c.buffers()), "In any :class:`~torch.nn.Module` passed to " + \
   240|         0|            0|            0|  0.00%|                ":func:`~make_graphed_callables`, only parameters may be trainable. All buffers must have " + \
   241|         0|            0|            0|  0.00%|                "``requires_grad=False``."
   242|         0|            0|            0|  0.00%|        assert all(isinstance(arg, torch.Tensor) for arg in args), "In the beta API, sample_args " + \
   243|         0|            0|            0|  0.00%|            "for each callable must be a tuple of Tensors. Other types and keyword args are not allowed."
   244|         0|            0|            0|  0.00%|
   245|         0|            0|            0|  0.00%|
   246|         0|            0|            0|  0.00%|    # If a callable is an nn.Module, its graph's full input surface is the args the user explicitly
   247|         0|            0|            0|  0.00%|    # passes to forward (ie, its sample_args) AND the module's parameter attributes.
   248|         0|            0|            0|  0.00%|    per_callable_len_user_args = [len(args) for args in sample_args]
   249|         0|            0|            0|  0.00%|    per_callable_module_params = [tuple(c.parameters()) if isinstance(c, torch.nn.Module) else ()
   250|         0|            0|            0|  0.00%|                                  for c in callables]
   251|         0|            0|            0|  0.00%|    per_callable_static_input_surfaces = [sample_args[i] + per_callable_module_params[i]
   252|         0|            0|            0|  0.00%|                                          for i in range(len(callables))]
   253|         0|            0|            0|  0.00%|
   254|         0|            0|            0|  0.00%|    fwd_graphs = [torch.cuda.CUDAGraph() for _ in range(len(callables))]
   255|         0|            0|            0|  0.00%|    bwd_graphs = [torch.cuda.CUDAGraph() for _ in range(len(callables))]
   256|         0|            0|            0|  0.00%|
   257|         0|            0|            0|  0.00%|    mempool = graph_pool_handle()
   258|         0|            0|            0|  0.00%|
   259|         0|            0|            0|  0.00%|    # Warmup
   260|         0|            0|            0|  0.00%|    # Hopefully prevents cudnn benchmarking and other lazy-initialization cuda work
   261|         0|            0|            0|  0.00%|    # from ending up in any captures.
   262|         0|            0|            0|  0.00%|    torch.cuda.synchronize()
   263|         0|            0|            0|  0.00%|    with torch.cuda.stream(torch.cuda.Stream()):
   264|         0|            0|            0|  0.00%|        for func, args, static_input_surface in zip(callables,
   265|         0|            0|            0|  0.00%|                                                    sample_args,
   266|         0|            0|            0|  0.00%|                                                    per_callable_static_input_surfaces):
   267|         0|            0|            0|  0.00%|            for _ in range(3):
   268|         0|            0|            0|  0.00%|                outputs = func(*args)
   269|         0|            0|            0|  0.00%|                outputs = (outputs,) if isinstance(outputs, torch.Tensor) else outputs
   270|         0|            0|            0|  0.00%|                grad_inputs = torch.autograd.grad(outputs=outputs,
   271|         0|            0|            0|  0.00%|                                                  inputs=tuple(i for i in static_input_surface if i.requires_grad),
   272|         0|            0|            0|  0.00%|                                                  grad_outputs=tuple(torch.empty_like(o) for o in outputs),
   273|         0|            0|            0|  0.00%|                                                  only_inputs=True,
   274|         0|            0|            0|  0.00%|                                                  allow_unused=False)
   275|         0|            0|            0|  0.00%|            del outputs, grad_inputs
   276|         0|            0|            0|  0.00%|    torch.cuda.synchronize()
   277|         0|            0|            0|  0.00%|
   278|         0|            0|            0|  0.00%|    # All captures here share a mempool. To avoid replays corrupting each other's memory,
   279|         0|            0|            0|  0.00%|    # the safest approach is to capture all passes in the same order they'll run:
   280|         0|            0|            0|  0.00%|    # fwd 1, fwd 2, ... fwd N, then bwd N, bwd N-1, ... bwd 1.
   281|         0|            0|            0|  0.00%|
   282|         0|            0|            0|  0.00%|    # Capture forward graphs
   283|         0|            0|            0|  0.00%|    per_callable_static_outputs = []
   284|         0|            0|            0|  0.00%|    per_callable_output_was_tensor = []
   285|         0|            0|            0|  0.00%|    for func, args, fwd_graph in zip(callables,
   286|         0|            0|            0|  0.00%|                                     sample_args,
   287|         0|            0|            0|  0.00%|                                     fwd_graphs):
   288|         0|            0|            0|  0.00%|        with torch.cuda.graph(fwd_graph, pool=mempool):
   289|         0|            0|            0|  0.00%|            outputs = func(*args)
   290|         0|            0|            0|  0.00%|
   291|         0|            0|            0|  0.00%|        # Assumes model output is a tensor or tuple of tensors
   292|         0|            0|            0|  0.00%|        if isinstance(outputs, torch.Tensor):
   293|         0|            0|            0|  0.00%|            per_callable_output_was_tensor.append(True)
   294|         0|            0|            0|  0.00%|            outputs = (outputs,)
   295|         0|            0|            0|  0.00%|        else:
   296|         0|            0|            0|  0.00%|            per_callable_output_was_tensor.append(False)
   297|         0|            0|            0|  0.00%|
   298|         0|            0|            0|  0.00%|        per_callable_static_outputs.append(outputs)
   299|         0|            0|            0|  0.00%|
   300|         0|            0|            0|  0.00%|    # Capture backward graphs in reverse order
   301|         0|            0|            0|  0.00%|    per_callable_static_grad_outputs = []
   302|         0|            0|            0|  0.00%|    per_callable_static_grad_inputs = []
   303|         0|            0|            0|  0.00%|    for static_input_surface, static_outputs, bwd_graph, module_params in \
   304|         0|            0|            0|  0.00%|            zip(reversed(per_callable_static_input_surfaces),
   305|         0|            0|            0|  0.00%|                reversed(per_callable_static_outputs),
   306|         0|            0|            0|  0.00%|                reversed(bwd_graphs),
   307|         0|            0|            0|  0.00%|                reversed(per_callable_module_params)):
   308|         0|            0|            0|  0.00%|
   309|         0|            0|            0|  0.00%|        # For now, assumes all static_outputs require grad
   310|         0|            0|            0|  0.00%|        assert all(o.requires_grad for o in static_outputs), "Outputs of graphed callables must require grad."
   311|         0|            0|            0|  0.00%|        static_grad_outputs = tuple(torch.empty_like(o) for o in static_outputs)
   312|         0|            0|            0|  0.00%|
   313|         0|            0|            0|  0.00%|        with torch.cuda.graph(bwd_graph, pool=mempool):
   314|         0|            0|            0|  0.00%|            grad_inputs = torch.autograd.grad(outputs=static_outputs,
   315|         0|            0|            0|  0.00%|                                              inputs=tuple(i for i in static_input_surface if i.requires_grad),
   316|         0|            0|            0|  0.00%|                                              grad_outputs=static_grad_outputs,
   317|         0|            0|            0|  0.00%|                                              only_inputs=True,
   318|         0|            0|            0|  0.00%|                                              allow_unused=False)
   319|         0|            0|            0|  0.00%|
   320|         0|            0|            0|  0.00%|        # Constructs a tuple suitable for returning from Graphed.backward:
   321|         0|            0|            0|  0.00%|        # Pads out the actually-needed grads with Nones in gradient slots for inputs that don't require grad.
   322|         0|            0|            0|  0.00%|        # I couldn't think of a slick one-liner for this pattern.
   323|         0|            0|            0|  0.00%|        static_grad_inputs = []
   324|         0|            0|            0|  0.00%|        grad_idx = 0
   325|         0|            0|            0|  0.00%|        for arg in static_input_surface:
   326|         0|            0|            0|  0.00%|            if arg.requires_grad:
   327|         0|            0|            0|  0.00%|                static_grad_inputs.append(grad_inputs[grad_idx])
   328|         0|            0|            0|  0.00%|                grad_idx += 1
   329|         0|            0|            0|  0.00%|            else:
   330|         0|            0|            0|  0.00%|                static_grad_inputs.append(None)  # type: ignore[arg-type]
   331|         0|            0|            0|  0.00%|        static_grad_inputs = tuple(static_grad_inputs)  # type: ignore[assignment]
   332|         0|            0|            0|  0.00%|
   333|         0|            0|            0|  0.00%|        per_callable_static_grad_outputs.append(static_grad_outputs)
   334|         0|            0|            0|  0.00%|        per_callable_static_grad_inputs.append(static_grad_inputs)
   335|         0|            0|            0|  0.00%|
   336|         0|            0|            0|  0.00%|    # Reverses the most recent two lists
   337|         0|            0|            0|  0.00%|    per_callable_static_grad_outputs = list(reversed(per_callable_static_grad_outputs))
   338|         0|            0|            0|  0.00%|    per_callable_static_grad_inputs = list(reversed(per_callable_static_grad_inputs))
   339|         0|            0|            0|  0.00%|    # Now for every per_callable list, per_callable_*[i] holds the stuff for the ith callable.
   340|         0|            0|            0|  0.00%|
   341|         0|            0|            0|  0.00%|    def make_graphed_autograd_function(fwd_graph,
   342|         0|            0|            0|  0.00%|                                       bwd_graph,
   343|         0|            0|            0|  0.00%|                                       module_params,
   344|         0|            0|            0|  0.00%|                                       len_user_args,
   345|         0|            0|            0|  0.00%|                                       output_was_tensor,
   346|         0|            0|            0|  0.00%|                                       static_input_surface,
   347|         0|            0|            0|  0.00%|                                       static_outputs,
   348|         0|            0|            0|  0.00%|                                       static_grad_outputs,
   349|         0|            0|            0|  0.00%|                                       static_grad_inputs):
   350|         0|            0|            0|  0.00%|        class Graphed(torch.autograd.Function):
   351|         0|            0|            0|  0.00%|            @staticmethod
   352|         0|            0|            0|  0.00%|            def forward(ctx, *inputs):
   353|         0|            0|            0|  0.00%|                # At this stage, only the user args may (potentially) be new tensors.
   354|         0|            0|            0|  0.00%|                for i in range(len_user_args):
   355|         0|            0|            0|  0.00%|                    if static_input_surface[i].data_ptr() != inputs[i].data_ptr():
   356|         0|            0|            0|  0.00%|                        static_input_surface[i].copy_(inputs[i])
   357|         0|            0|            0|  0.00%|                fwd_graph.replay()
   358|         0|            0|            0|  0.00%|                assert isinstance(static_outputs, tuple)
   359|         0|            0|            0|  0.00%|                return tuple(o.detach() for o in static_outputs)
   360|         0|            0|            0|  0.00%|
   361|         0|            0|            0|  0.00%|            @staticmethod
   362|         0|            0|            0|  0.00%|            @torch.autograd.function.once_differentiable
   363|         0|            0|            0|  0.00%|            def backward(ctx, *grads):
   364|         0|            0|            0|  0.00%|                for g, grad in zip(static_grad_outputs, grads):
   365|         0|            0|            0|  0.00%|                    if g is None:
   366|         0|            0|            0|  0.00%|                        assert grad is None
   367|         0|            0|            0|  0.00%|                    else:
   368|         0|            0|            0|  0.00%|                        # don't copy if autograd gods have been kind and the
   369|         0|            0|            0|  0.00%|                        # incoming grad is already in the right place
   370|         0|            0|            0|  0.00%|                        if g.data_ptr() != grad.data_ptr():
   371|         0|            0|            0|  0.00%|                            g.copy_(grad)
   372|         0|            0|            0|  0.00%|                bwd_graph.replay()
   373|         0|            0|            0|  0.00%|
   374|         0|            0|            0|  0.00%|                # Input args that didn't require grad expect a None gradient.
   375|         0|            0|            0|  0.00%|                assert isinstance(static_grad_inputs, tuple)
   376|         0|            0|            0|  0.00%|                return tuple(b.detach() if b is not None else b for b in static_grad_inputs)
   377|         0|            0|            0|  0.00%|
   378|         0|            0|            0|  0.00%|        def functionalized(*user_args):
   379|         0|            0|            0|  0.00%|            # Runs the autograd function with inputs == all inputs to the graph that might require grad
   380|         0|            0|            0|  0.00%|            # (explicit user args + module parameters)
   381|         0|            0|            0|  0.00%|            # Assumes module params didn't change since capture.
   382|         0|            0|            0|  0.00%|            out = Graphed.apply(*(user_args + module_params))
   383|         0|            0|            0|  0.00%|            return out[0] if output_was_tensor else out
   384|         0|            0|            0|  0.00%|
   385|         0|            0|            0|  0.00%|        return functionalized
   386|         0|            0|            0|  0.00%|
   387|         0|            0|            0|  0.00%|    # Put together the final graphed callables
   388|         0|            0|            0|  0.00%|    ret = []
   389|         0|            0|            0|  0.00%|    for i, func in enumerate(callables):
   390|         0|            0|            0|  0.00%|        graphed = make_graphed_autograd_function(fwd_graphs[i],
   391|         0|            0|            0|  0.00%|                                                 bwd_graphs[i],
   392|         0|            0|            0|  0.00%|                                                 per_callable_module_params[i],
   393|         0|            0|            0|  0.00%|                                                 per_callable_len_user_args[i],
   394|         0|            0|            0|  0.00%|                                                 per_callable_output_was_tensor[i],
   395|         0|            0|            0|  0.00%|                                                 per_callable_static_input_surfaces[i],
   396|         0|            0|            0|  0.00%|                                                 per_callable_static_outputs[i],
   397|         0|            0|            0|  0.00%|                                                 per_callable_static_grad_outputs[i],
   398|         0|            0|            0|  0.00%|                                                 per_callable_static_grad_inputs[i])
   399|         0|            0|            0|  0.00%|
   400|         0|            0|            0|  0.00%|        if isinstance(func, torch.nn.Module):
   401|         0|            0|            0|  0.00%|            def make_graphed_forward(func, graph_training_state, graphed, orig_fwd):
   402|         0|            0|            0|  0.00%|                def new_fwd(*user_args):
   403|         0|            0|            0|  0.00%|                    # If the module's training-or-eval state matches what we graphed,
   404|         0|            0|            0|  0.00%|                    # run the graph, otherwise run the original forward method
   405|         0|            0|            0|  0.00%|                    if func.training == graph_training_state:
   406|         0|            0|            0|  0.00%|                        return graphed(*user_args)
   407|         0|            0|            0|  0.00%|                    else:
   408|         0|            0|            0|  0.00%|                        return orig_fwd(*user_args)
   409|         0|            0|            0|  0.00%|                return new_fwd
   410|         0|            0|            0|  0.00%|            func.forward = make_graphed_forward(func, func.training, graphed, func.forward)  # type: ignore[assignment]
   411|         0|            0|            0|  0.00%|            ret.append(func)
   412|         0|            0|            0|  0.00%|        else:
   413|         0|            0|            0|  0.00%|            ret.append(graphed)
   414|         0|            0|            0|  0.00%|
   415|         0|            0|            0|  0.00%|    if just_one_callable:
   416|         0|            0|            0|  0.00%|        return ret[0]
   417|         0|            0|            0|  0.00%|
   418|         0|            0|            0|  0.00%|    return tuple(ret)
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/time.py
File duration: 0.000996828s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|#!/usr/bin/env python
     2|         0|            0|            0|  0.00%|
     3|         0|            0|            0|  0.00%|"""Time humanizing functions.
     4|         0|            0|            0|  0.00%|
     5|         0|            0|            0|  0.00%|These are largely borrowed from Django's `contrib.humanize`.
     6|         0|            0|            0|  0.00%|"""
     7|         0|            0|            0|  0.00%|
     8|         0|            0|            0|  0.00%|import datetime as dt
     9|         0|            0|            0|  0.00%|import math
    10|         0|            0|            0|  0.00%|from enum import Enum
    11|         0|            0|            0|  0.00%|from functools import total_ordering
    12|         0|            0|            0|  0.00%|
    13|         0|            0|            0|  0.00%|from .i18n import _gettext as _
    14|         0|            0|            0|  0.00%|from .i18n import _ngettext
    15|         0|            0|            0|  0.00%|from .number import intcomma
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|__all__ = [
    18|         0|            0|            0|  0.00%|    "naturaldelta",
    19|         0|            0|            0|  0.00%|    "naturaltime",
    20|         0|            0|            0|  0.00%|    "naturalday",
    21|         0|            0|            0|  0.00%|    "naturaldate",
    22|         0|            0|            0|  0.00%|    "precisedelta",
    23|         0|            0|            0|  0.00%|]
    24|         0|            0|            0|  0.00%|
    25|         0|            0|            0|  0.00%|
    26|         0|            0|            0|  0.00%|@total_ordering
    27|         0|            0|            0|  0.00%|class Unit(Enum):
    28|         0|            0|            0|  0.00%|    MICROSECONDS = 0
    29|         0|            0|            0|  0.00%|    MILLISECONDS = 1
    30|         0|            0|            0|  0.00%|    SECONDS = 2
    31|         0|            0|            0|  0.00%|    MINUTES = 3
    32|         0|            0|            0|  0.00%|    HOURS = 4
    33|         0|            0|            0|  0.00%|    DAYS = 5
    34|         0|            0|            0|  0.00%|    MONTHS = 6
    35|         0|            0|            0|  0.00%|    YEARS = 7
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|    def __lt__(self, other):
    38|         0|            0|            0|  0.00%|        if self.__class__ is other.__class__:
    39|         0|            0|            0|  0.00%|            return self.value < other.value
    40|         0|            0|            0|  0.00%|        return NotImplemented
    41|         0|            0|            0|  0.00%|
    42|         0|            0|            0|  0.00%|
    43|         1|  2.38419e-06|  2.38419e-06|  0.00%|def _now():
    44|         1|  9.05991e-06|  9.05991e-06|  0.00%|    return dt.datetime.now()
    45|         0|            0|            0|  0.00%|
    46|         0|            0|            0|  0.00%|
    47|         1|  3.33786e-06|  3.33786e-06|  0.00%|def _abs_timedelta(delta):
    48|         0|            0|            0|  0.00%|    """Return an "absolute" value for a timedelta, always representing a time distance.
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|    Args:
    51|         0|            0|            0|  0.00%|        delta (datetime.timedelta): Input timedelta.
    52|         0|            0|            0|  0.00%|
    53|         0|            0|            0|  0.00%|    Returns:
    54|         0|            0|            0|  0.00%|        datetime.timedelta: Absolute timedelta.
    55|         0|            0|            0|  0.00%|    """
    56|         1|  3.33786e-06|  3.33786e-06|  0.00%|    if delta.days < 0:
    57|         0|            0|            0|  0.00%|        now = _now()
    58|         0|            0|            0|  0.00%|        return now - (now + delta)
    59|         1|   2.6226e-06|   2.6226e-06|  0.00%|    return delta
    60|         0|            0|            0|  0.00%|
    61|         0|            0|            0|  0.00%|
    62|         1|  6.67572e-06|  6.67572e-06|  0.00%|def _date_and_delta(value, *, now=None):
    63|         0|            0|            0|  0.00%|    """Turn a value into a date and a timedelta which represents how long ago it was.
    64|         0|            0|            0|  0.00%|
    65|         0|            0|            0|  0.00%|    If that's not possible, return `(None, value)`.
    66|         0|            0|            0|  0.00%|    """
    67|         1|  3.33786e-06|  3.33786e-06|  0.00%|    if not now:
    68|         1|  1.00136e-05|  1.00136e-05|  0.00%|        now = _now()
(call)|         1|  1.14441e-05|  1.14441e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/time.py:43 _now
    69|         1|  4.29153e-06|  4.29153e-06|  0.00%|    if isinstance(value, dt.datetime):
    70|         0|            0|            0|  0.00%|        date = value
    71|         0|            0|            0|  0.00%|        delta = now - value
    72|         1|  2.86102e-06|  2.86102e-06|  0.00%|    elif isinstance(value, dt.timedelta):
    73|         1|  3.57628e-06|  3.57628e-06|  0.00%|        date = now - value
    74|         1|  2.86102e-06|  2.86102e-06|  0.00%|        delta = value
    75|         0|            0|            0|  0.00%|    else:
    76|         0|            0|            0|  0.00%|        try:
    77|         0|            0|            0|  0.00%|            value = int(value)
    78|         0|            0|            0|  0.00%|            delta = dt.timedelta(seconds=value)
    79|         0|            0|            0|  0.00%|            date = now - delta
    80|         0|            0|            0|  0.00%|        except (ValueError, TypeError):
    81|         0|            0|            0|  0.00%|            return None, value
    82|         1|  9.05991e-06|  9.05991e-06|  0.00%|    return date, _abs_timedelta(delta)
(call)|         1|  9.29832e-06|  9.29832e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/time.py:47 _abs_timedelta
    83|         0|            0|            0|  0.00%|
    84|         0|            0|            0|  0.00%|
    85|         0|            0|            0|  0.00%|def naturaldelta(
    86|         0|            0|            0|  0.00%|    value,
    87|         0|            0|            0|  0.00%|    months=True,
    88|         0|            0|            0|  0.00%|    minimum_unit="seconds",
    89|         0|            0|            0|  0.00%|) -> str:
    90|         0|            0|            0|  0.00%|    """Return a natural representation of a timedelta or number of seconds.
    91|         0|            0|            0|  0.00%|
    92|         0|            0|            0|  0.00%|    This is similar to `naturaltime`, but does not add tense to the result.
    93|         0|            0|            0|  0.00%|
    94|         0|            0|            0|  0.00%|    Args:
    95|         0|            0|            0|  0.00%|        value (datetime.timedelta or int): A timedelta or a number of seconds.
    96|         0|            0|            0|  0.00%|        months (bool): If `True`, then a number of months (based on 30.5 days) will be
    97|         0|            0|            0|  0.00%|            used for fuzziness between years.
    98|         0|            0|            0|  0.00%|        minimum_unit (str): The lowest unit that can be used.
    99|         0|            0|            0|  0.00%|        when (datetime.datetime): Removed in version 4.0; If you need to
   100|         0|            0|            0|  0.00%|            construct a timedelta, do it inline as the first argument.
   101|         0|            0|            0|  0.00%|
   102|         0|            0|            0|  0.00%|    Returns:
   103|         0|            0|            0|  0.00%|        str (str or `value`): A natural representation of the amount of time
   104|         0|            0|            0|  0.00%|            elapsed unless `value` is not datetime.timedelta or cannot be
   105|         0|            0|            0|  0.00%|            converted to int. In that case, a `value` is returned unchanged.
   106|         0|            0|            0|  0.00%|
   107|         0|            0|            0|  0.00%|    Raises:
   108|         0|            0|            0|  0.00%|        OverflowError: If `value` is too large to convert to datetime.timedelta.
   109|         0|            0|            0|  0.00%|
   110|         0|            0|            0|  0.00%|    Examples
   111|         0|            0|            0|  0.00%|        Compare two timestamps in a custom local timezone::
   112|         0|            0|            0|  0.00%|
   113|         0|            0|            0|  0.00%|        import datetime as dt
   114|         0|            0|            0|  0.00%|        from dateutil.tz import gettz
   115|         0|            0|            0|  0.00%|
   116|         0|            0|            0|  0.00%|        berlin = gettz("Europe/Berlin")
   117|         0|            0|            0|  0.00%|        now = dt.datetime.now(tz=berlin)
   118|         0|            0|            0|  0.00%|        later = now + dt.timedelta(minutes=30)
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|        assert naturaldelta(later - now) == "30 minutes"
   121|         0|            0|            0|  0.00%|    """
   122|         0|            0|            0|  0.00%|    tmp = Unit[minimum_unit.upper()]
   123|         0|            0|            0|  0.00%|    if tmp not in (Unit.SECONDS, Unit.MILLISECONDS, Unit.MICROSECONDS):
   124|         0|            0|            0|  0.00%|        raise ValueError(f"Minimum unit '{minimum_unit}' not supported")
   125|         0|            0|            0|  0.00%|    minimum_unit = tmp
   126|         0|            0|            0|  0.00%|
   127|         0|            0|            0|  0.00%|    if isinstance(value, dt.timedelta):
   128|         0|            0|            0|  0.00%|        delta = value
   129|         0|            0|            0|  0.00%|    else:
   130|         0|            0|            0|  0.00%|        try:
   131|         0|            0|            0|  0.00%|            value = int(value)
   132|         0|            0|            0|  0.00%|            delta = dt.timedelta(seconds=value)
   133|         0|            0|            0|  0.00%|        except (ValueError, TypeError):
   134|         0|            0|            0|  0.00%|            return value
   135|         0|            0|            0|  0.00%|
   136|         0|            0|            0|  0.00%|    use_months = months
   137|         0|            0|            0|  0.00%|
   138|         0|            0|            0|  0.00%|    seconds = abs(delta.seconds)
   139|         0|            0|            0|  0.00%|    days = abs(delta.days)
   140|         0|            0|            0|  0.00%|    years = days // 365
   141|         0|            0|            0|  0.00%|    days = days % 365
   142|         0|            0|            0|  0.00%|    months = int(days // 30.5)
   143|         0|            0|            0|  0.00%|
   144|         0|            0|            0|  0.00%|    if not years and days < 1:
   145|         0|            0|            0|  0.00%|        if seconds == 0:
   146|         0|            0|            0|  0.00%|            if minimum_unit == Unit.MICROSECONDS and delta.microseconds < 1000:
   147|         0|            0|            0|  0.00%|                return (
   148|         0|            0|            0|  0.00%|                    _ngettext("%d microsecond", "%d microseconds", delta.microseconds)
   149|         0|            0|            0|  0.00%|                    % delta.microseconds
   150|         0|            0|            0|  0.00%|                )
   151|         0|            0|            0|  0.00%|            elif minimum_unit == Unit.MILLISECONDS or (
   152|         0|            0|            0|  0.00%|                minimum_unit == Unit.MICROSECONDS
   153|         0|            0|            0|  0.00%|                and 1000 <= delta.microseconds < 1_000_000
   154|         0|            0|            0|  0.00%|            ):
   155|         0|            0|            0|  0.00%|                milliseconds = delta.microseconds / 1000
   156|         0|            0|            0|  0.00%|                return (
   157|         0|            0|            0|  0.00%|                    _ngettext("%d millisecond", "%d milliseconds", milliseconds)
   158|         0|            0|            0|  0.00%|                    % milliseconds
   159|         0|            0|            0|  0.00%|                )
   160|         0|            0|            0|  0.00%|            return _("a moment")
   161|         0|            0|            0|  0.00%|        elif seconds == 1:
   162|         0|            0|            0|  0.00%|            return _("a second")
   163|         0|            0|            0|  0.00%|        elif seconds < 60:
   164|         0|            0|            0|  0.00%|            return _ngettext("%d second", "%d seconds", seconds) % seconds
   165|         0|            0|            0|  0.00%|        elif 60 <= seconds < 120:
   166|         0|            0|            0|  0.00%|            return _("a minute")
   167|         0|            0|            0|  0.00%|        elif 120 <= seconds < 3600:
   168|         0|            0|            0|  0.00%|            minutes = seconds // 60
   169|         0|            0|            0|  0.00%|            return _ngettext("%d minute", "%d minutes", minutes) % minutes
   170|         0|            0|            0|  0.00%|        elif 3600 <= seconds < 3600 * 2:
   171|         0|            0|            0|  0.00%|            return _("an hour")
   172|         0|            0|            0|  0.00%|        elif 3600 < seconds:
   173|         0|            0|            0|  0.00%|            hours = seconds // 3600
   174|         0|            0|            0|  0.00%|            return _ngettext("%d hour", "%d hours", hours) % hours
   175|         0|            0|            0|  0.00%|    elif years == 0:
   176|         0|            0|            0|  0.00%|        if days == 1:
   177|         0|            0|            0|  0.00%|            return _("a day")
   178|         0|            0|            0|  0.00%|        if not use_months:
   179|         0|            0|            0|  0.00%|            return _ngettext("%d day", "%d days", days) % days
   180|         0|            0|            0|  0.00%|        else:
   181|         0|            0|            0|  0.00%|            if not months:
   182|         0|            0|            0|  0.00%|                return _ngettext("%d day", "%d days", days) % days
   183|         0|            0|            0|  0.00%|            elif months == 1:
   184|         0|            0|            0|  0.00%|                return _("a month")
   185|         0|            0|            0|  0.00%|            else:
   186|         0|            0|            0|  0.00%|                return _ngettext("%d month", "%d months", months) % months
   187|         0|            0|            0|  0.00%|    elif years == 1:
   188|         0|            0|            0|  0.00%|        if not months and not days:
   189|         0|            0|            0|  0.00%|            return _("a year")
   190|         0|            0|            0|  0.00%|        elif not months:
   191|         0|            0|            0|  0.00%|            return _ngettext("1 year, %d day", "1 year, %d days", days) % days
   192|         0|            0|            0|  0.00%|        elif use_months:
   193|         0|            0|            0|  0.00%|            if months == 1:
   194|         0|            0|            0|  0.00%|                return _("1 year, 1 month")
   195|         0|            0|            0|  0.00%|            else:
   196|         0|            0|            0|  0.00%|                return (
   197|         0|            0|            0|  0.00%|                    _ngettext("1 year, %d month", "1 year, %d months", months) % months
   198|         0|            0|            0|  0.00%|                )
   199|         0|            0|            0|  0.00%|        else:
   200|         0|            0|            0|  0.00%|            return _ngettext("1 year, %d day", "1 year, %d days", days) % days
   201|         0|            0|            0|  0.00%|    else:
   202|         0|            0|            0|  0.00%|        return _ngettext("%s year", "%s years", years) % intcomma(years)
   203|         0|            0|            0|  0.00%|
   204|         0|            0|            0|  0.00%|
   205|         0|            0|            0|  0.00%|def naturaltime(
   206|         0|            0|            0|  0.00%|    value,
   207|         0|            0|            0|  0.00%|    future=False,
   208|         0|            0|            0|  0.00%|    months=True,
   209|         0|            0|            0|  0.00%|    minimum_unit="seconds",
   210|         0|            0|            0|  0.00%|    when=None,
   211|         0|            0|            0|  0.00%|) -> str:
   212|         0|            0|            0|  0.00%|    """Return a natural representation of a time in a resolution that makes sense.
   213|         0|            0|            0|  0.00%|
   214|         0|            0|            0|  0.00%|    This is more or less compatible with Django's `naturaltime` filter.
   215|         0|            0|            0|  0.00%|
   216|         0|            0|            0|  0.00%|    Args:
   217|         0|            0|            0|  0.00%|        value (datetime.datetime, int): A `datetime` or a number of seconds.
   218|         0|            0|            0|  0.00%|        future (bool): Ignored for `datetime`s, where the tense is always figured out
   219|         0|            0|            0|  0.00%|            based on the current time. For integers, the return value will be past tense
   220|         0|            0|            0|  0.00%|            by default, unless future is `True`.
   221|         0|            0|            0|  0.00%|        months (bool): If `True`, then a number of months (based on 30.5 days) will be
   222|         0|            0|            0|  0.00%|            used for fuzziness between years.
   223|         0|            0|            0|  0.00%|        minimum_unit (str): The lowest unit that can be used.
   224|         0|            0|            0|  0.00%|        when (datetime.datetime): Point in time relative to which _value_ is
   225|         0|            0|            0|  0.00%|            interpreted.  Defaults to the current time in the local timezone.
   226|         0|            0|            0|  0.00%|
   227|         0|            0|            0|  0.00%|    Returns:
   228|         0|            0|            0|  0.00%|        str: A natural representation of the input in a resolution that makes sense.
   229|         0|            0|            0|  0.00%|    """
   230|         0|            0|            0|  0.00%|    now = when or _now()
   231|         0|            0|            0|  0.00%|    date, delta = _date_and_delta(value, now=now)
   232|         0|            0|            0|  0.00%|    if date is None:
   233|         0|            0|            0|  0.00%|        return value
   234|         0|            0|            0|  0.00%|    # determine tense by value only if datetime/timedelta were passed
   235|         0|            0|            0|  0.00%|    if isinstance(value, (dt.datetime, dt.timedelta)):
   236|         0|            0|            0|  0.00%|        future = date > now
   237|         0|            0|            0|  0.00%|
   238|         0|            0|            0|  0.00%|    ago = _("%s from now") if future else _("%s ago")
   239|         0|            0|            0|  0.00%|    delta = naturaldelta(delta, months, minimum_unit)
   240|         0|            0|            0|  0.00%|
   241|         0|            0|            0|  0.00%|    if delta == _("a moment"):
   242|         0|            0|            0|  0.00%|        return _("now")
   243|         0|            0|            0|  0.00%|
   244|         0|            0|            0|  0.00%|    return ago % delta
   245|         0|            0|            0|  0.00%|
   246|         0|            0|            0|  0.00%|
   247|         0|            0|            0|  0.00%|def naturalday(value, format="%b %d") -> str:
   248|         0|            0|            0|  0.00%|    """Return a natural day.
   249|         0|            0|            0|  0.00%|
   250|         0|            0|            0|  0.00%|    For date values that are tomorrow, today or yesterday compared to
   251|         0|            0|            0|  0.00%|    present day return representing string. Otherwise, return a string
   252|         0|            0|            0|  0.00%|    formatted according to `format`.
   253|         0|            0|            0|  0.00%|
   254|         0|            0|            0|  0.00%|    """
   255|         0|            0|            0|  0.00%|    try:
   256|         0|            0|            0|  0.00%|        value = dt.date(value.year, value.month, value.day)
   257|         0|            0|            0|  0.00%|    except AttributeError:
   258|         0|            0|            0|  0.00%|        # Passed value wasn't date-ish
   259|         0|            0|            0|  0.00%|        return value
   260|         0|            0|            0|  0.00%|    except (OverflowError, ValueError):
   261|         0|            0|            0|  0.00%|        # Date arguments out of range
   262|         0|            0|            0|  0.00%|        return value
   263|         0|            0|            0|  0.00%|    delta = value - dt.date.today()
   264|         0|            0|            0|  0.00%|    if delta.days == 0:
   265|         0|            0|            0|  0.00%|        return _("today")
   266|         0|            0|            0|  0.00%|    elif delta.days == 1:
   267|         0|            0|            0|  0.00%|        return _("tomorrow")
   268|         0|            0|            0|  0.00%|    elif delta.days == -1:
   269|         0|            0|            0|  0.00%|        return _("yesterday")
   270|         0|            0|            0|  0.00%|    return value.strftime(format)
   271|         0|            0|            0|  0.00%|
   272|         0|            0|            0|  0.00%|
   273|         0|            0|            0|  0.00%|def naturaldate(value) -> str:
   274|         0|            0|            0|  0.00%|    """Like `naturalday`, but append a year for dates more than ~five months away."""
   275|         0|            0|            0|  0.00%|    try:
   276|         0|            0|            0|  0.00%|        value = dt.date(value.year, value.month, value.day)
   277|         0|            0|            0|  0.00%|    except AttributeError:
   278|         0|            0|            0|  0.00%|        # Passed value wasn't date-ish
   279|         0|            0|            0|  0.00%|        return value
   280|         0|            0|            0|  0.00%|    except (OverflowError, ValueError):
   281|         0|            0|            0|  0.00%|        # Date arguments out of range
   282|         0|            0|            0|  0.00%|        return value
   283|         0|            0|            0|  0.00%|    delta = _abs_timedelta(value - dt.date.today())
   284|         0|            0|            0|  0.00%|    if delta.days >= 5 * 365 / 12:
   285|         0|            0|            0|  0.00%|        return naturalday(value, "%b %d %Y")
   286|         0|            0|            0|  0.00%|    return naturalday(value)
   287|         0|            0|            0|  0.00%|
   288|         0|            0|            0|  0.00%|
   289|         5|  1.26362e-05|  2.52724e-06|  0.00%|def _quotient_and_remainder(value, divisor, unit, minimum_unit, suppress):
   290|         0|            0|            0|  0.00%|    """Divide `value` by `divisor` returning the quotient and remainder.
   291|         0|            0|            0|  0.00%|
   292|         0|            0|            0|  0.00%|    If `unit` is `minimum_unit`, makes the quotient a float number and the remainder
   293|         0|            0|            0|  0.00%|    will be zero. The rational is that if `unit` is the unit of the quotient, we cannot
   294|         0|            0|            0|  0.00%|    represent the remainder because it would require a unit smaller than the
   295|         0|            0|            0|  0.00%|    `minimum_unit`.
   296|         0|            0|            0|  0.00%|
   297|         0|            0|            0|  0.00%|    >>> from humanize.time import _quotient_and_remainder, Unit
   298|         0|            0|            0|  0.00%|    >>> _quotient_and_remainder(36, 24, Unit.DAYS, Unit.DAYS, [])
   299|         0|            0|            0|  0.00%|    (1.5, 0)
   300|         0|            0|            0|  0.00%|
   301|         0|            0|            0|  0.00%|    If unit is in `suppress`, the quotient will be zero and the remainder will be the
   302|         0|            0|            0|  0.00%|    initial value. The idea is that if we cannot use `unit`, we are forced to use a
   303|         0|            0|            0|  0.00%|    lower unit so we cannot do the division.
   304|         0|            0|            0|  0.00%|
   305|         0|            0|            0|  0.00%|    >>> _quotient_and_remainder(36, 24, Unit.DAYS, Unit.HOURS, [Unit.DAYS])
   306|         0|            0|            0|  0.00%|    (0, 36)
   307|         0|            0|            0|  0.00%|
   308|         0|            0|            0|  0.00%|    In other case return quotient and remainder as `divmod` would do it.
   309|         0|            0|            0|  0.00%|
   310|         0|            0|            0|  0.00%|    >>> _quotient_and_remainder(36, 24, Unit.DAYS, Unit.HOURS, [])
   311|         0|            0|            0|  0.00%|    (1, 12)
   312|         0|            0|            0|  0.00%|
   313|         0|            0|            0|  0.00%|    """
   314|         5|  1.12057e-05|  2.24113e-06|  0.00%|    if unit == minimum_unit:
   315|         0|            0|            0|  0.00%|        return (value / divisor, 0)
   316|         5|  2.71797e-05|  5.43594e-06|  0.00%|    elif unit in suppress:
(call)|         5|  1.45435e-05|  2.90871e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/enum.py:641 __hash__
   317|         1|  1.90735e-06|  1.90735e-06|  0.00%|        return (0, value)
   318|         0|            0|            0|  0.00%|    else:
   319|         4|  1.07288e-05|  2.68221e-06|  0.00%|        return divmod(value, divisor)
   320|         0|            0|            0|  0.00%|
   321|         0|            0|            0|  0.00%|
   322|         3|  8.34465e-06|  2.78155e-06|  0.00%|def _carry(value1, value2, ratio, unit, min_unit, suppress):
   323|         0|            0|            0|  0.00%|    """Return a tuple with two values.
   324|         0|            0|            0|  0.00%|
   325|         0|            0|            0|  0.00%|    If the unit is in `suppress`, multiply `value1` by `ratio` and add it to `value2`
   326|         0|            0|            0|  0.00%|    (carry to right). The idea is that if we cannot represent `value1` we need to
   327|         0|            0|            0|  0.00%|    represent it in a lower unit.
   328|         0|            0|            0|  0.00%|
   329|         0|            0|            0|  0.00%|    >>> from humanize.time import _carry, Unit
   330|         0|            0|            0|  0.00%|    >>> _carry(2, 6, 24, Unit.DAYS, Unit.SECONDS, [Unit.DAYS])
   331|         0|            0|            0|  0.00%|    (0, 54)
   332|         0|            0|            0|  0.00%|
   333|         0|            0|            0|  0.00%|    If the unit is the minimum unit, `value2` is divided by `ratio` and added to
   334|         0|            0|            0|  0.00%|    `value1` (carry to left). We assume that `value2` has a lower unit so we need to
   335|         0|            0|            0|  0.00%|    carry it to `value1`.
   336|         0|            0|            0|  0.00%|
   337|         0|            0|            0|  0.00%|    >>> _carry(2, 6, 24, Unit.DAYS, Unit.DAYS, [])
   338|         0|            0|            0|  0.00%|    (2.25, 0)
   339|         0|            0|            0|  0.00%|
   340|         0|            0|            0|  0.00%|    Otherwise, just return the same input:
   341|         0|            0|            0|  0.00%|
   342|         0|            0|            0|  0.00%|    >>> _carry(2, 6, 24, Unit.DAYS, Unit.SECONDS, [])
   343|         0|            0|            0|  0.00%|    (2, 6)
   344|         0|            0|            0|  0.00%|    """
   345|         3|  7.39098e-06|  2.46366e-06|  0.00%|    if unit == min_unit:
   346|         1|  2.38419e-06|  2.38419e-06|  0.00%|        return (value1 + value2 / ratio, 0)
   347|         2|  1.21593e-05|  6.07967e-06|  0.00%|    elif unit in suppress:
(call)|         2|   6.4373e-06|  3.21865e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/enum.py:641 __hash__
   348|         1|  2.14577e-06|  2.14577e-06|  0.00%|        return (0, value2 + value1 * ratio)
   349|         0|            0|            0|  0.00%|    else:
   350|         1|   2.6226e-06|   2.6226e-06|  0.00%|        return (value1, value2)
   351|         0|            0|            0|  0.00%|
   352|         0|            0|            0|  0.00%|
   353|         1|  7.15256e-06|  7.15256e-06|  0.00%|def _suitable_minimum_unit(min_unit, suppress):
   354|         0|            0|            0|  0.00%|    """Return a minimum unit suitable that is not suppressed.
   355|         0|            0|            0|  0.00%|
   356|         0|            0|            0|  0.00%|    If not suppressed, return the same unit:
   357|         0|            0|            0|  0.00%|
   358|         0|            0|            0|  0.00%|    >>> from humanize.time import _suitable_minimum_unit, Unit
   359|         0|            0|            0|  0.00%|    >>> _suitable_minimum_unit(Unit.HOURS, []).name
   360|         0|            0|            0|  0.00%|    'HOURS'
   361|         0|            0|            0|  0.00%|
   362|         0|            0|            0|  0.00%|    But if suppressed, find a unit greather than the original one that is not
   363|         0|            0|            0|  0.00%|    suppressed:
   364|         0|            0|            0|  0.00%|
   365|         0|            0|            0|  0.00%|    >>> _suitable_minimum_unit(Unit.HOURS, [Unit.HOURS]).name
   366|         0|            0|            0|  0.00%|    'DAYS'
   367|         0|            0|            0|  0.00%|
   368|         0|            0|            0|  0.00%|    >>> _suitable_minimum_unit(Unit.HOURS, [Unit.HOURS, Unit.DAYS]).name
   369|         0|            0|            0|  0.00%|    'MONTHS'
   370|         0|            0|            0|  0.00%|    """
   371|         1|  3.33786e-06|  3.33786e-06|  0.00%|    if min_unit in suppress:
   372|         0|            0|            0|  0.00%|        for unit in Unit:
   373|         0|            0|            0|  0.00%|            if unit > min_unit and unit not in suppress:
   374|         0|            0|            0|  0.00%|                return unit
   375|         0|            0|            0|  0.00%|
   376|         0|            0|            0|  0.00%|        raise ValueError(
   377|         0|            0|            0|  0.00%|            "Minimum unit is suppressed and no suitable replacement was found"
   378|         0|            0|            0|  0.00%|        )
   379|         0|            0|            0|  0.00%|
   380|         1|   2.6226e-06|   2.6226e-06|  0.00%|    return min_unit
   381|         0|            0|            0|  0.00%|
   382|         0|            0|            0|  0.00%|
   383|         1|  4.76837e-06|  4.76837e-06|  0.00%|def _suppress_lower_units(min_unit, suppress):
   384|         0|            0|            0|  0.00%|    """Extend suppressed units (if any) with all units lower than the minimum unit.
   385|         0|            0|            0|  0.00%|
   386|         0|            0|            0|  0.00%|    >>> from humanize.time import _suppress_lower_units, Unit
   387|         0|            0|            0|  0.00%|    >>> [x.name for x in sorted(_suppress_lower_units(Unit.SECONDS, [Unit.DAYS]))]
   388|         0|            0|            0|  0.00%|    ['MICROSECONDS', 'MILLISECONDS', 'DAYS']
   389|         0|            0|            0|  0.00%|    """
   390|         1|   3.8147e-06|   3.8147e-06|  0.00%|    suppress = set(suppress)
   391|         3|   2.6226e-05|  8.74201e-06|  0.00%|    for u in Unit:
(call)|         1|  8.10623e-06|  8.10623e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/enum.py:346 __iter__
(call)|         3|  1.21593e-05|  4.05312e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/enum.py:347 <genexpr>
   392|         3|  7.86781e-06|   2.6226e-06|  0.00%|        if u == min_unit:
   393|         1|   6.4373e-06|   6.4373e-06|  0.00%|            break
(call)|         1|  2.38419e-06|  2.38419e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/enum.py:347 <genexpr>
   394|         2|   1.4782e-05|  7.39098e-06|  0.00%|        suppress.add(u)
(call)|         2|  9.29832e-06|  4.64916e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/enum.py:641 __hash__
   395|         0|            0|            0|  0.00%|
   396|         1|  2.86102e-06|  2.86102e-06|  0.00%|    return suppress
   397|         0|            0|            0|  0.00%|
   398|         0|            0|            0|  0.00%|
   399|         1|   1.4782e-05|   1.4782e-05|  0.00%|def precisedelta(value, minimum_unit="seconds", suppress=(), format="%0.2f") -> str:
   400|         0|            0|            0|  0.00%|    """Return a precise representation of a timedelta.
   401|         0|            0|            0|  0.00%|
   402|         0|            0|            0|  0.00%|    ```pycon
   403|         0|            0|            0|  0.00%|    >>> import datetime as dt
   404|         0|            0|            0|  0.00%|    >>> from humanize.time import precisedelta
   405|         0|            0|            0|  0.00%|
   406|         0|            0|            0|  0.00%|    >>> delta = dt.timedelta(seconds=3633, days=2, microseconds=123000)
   407|         0|            0|            0|  0.00%|    >>> precisedelta(delta)
   408|         0|            0|            0|  0.00%|    '2 days, 1 hour and 33.12 seconds'
   409|         0|            0|            0|  0.00%|
   410|         0|            0|            0|  0.00%|    ```
   411|         0|            0|            0|  0.00%|
   412|         0|            0|            0|  0.00%|    A custom `format` can be specified to control how the fractional part
   413|         0|            0|            0|  0.00%|    is represented:
   414|         0|            0|            0|  0.00%|
   415|         0|            0|            0|  0.00%|    ```pycon
   416|         0|            0|            0|  0.00%|    >>> precisedelta(delta, format="%0.4f")
   417|         0|            0|            0|  0.00%|    '2 days, 1 hour and 33.1230 seconds'
   418|         0|            0|            0|  0.00%|
   419|         0|            0|            0|  0.00%|    ```
   420|         0|            0|            0|  0.00%|
   421|         0|            0|            0|  0.00%|    Instead, the `minimum_unit` can be changed to have a better resolution;
   422|         0|            0|            0|  0.00%|    the function will still readjust the unit to use the greatest of the
   423|         0|            0|            0|  0.00%|    units that does not lose precision.
   424|         0|            0|            0|  0.00%|
   425|         0|            0|            0|  0.00%|    For example setting microseconds but still representing the date with milliseconds:
   426|         0|            0|            0|  0.00%|
   427|         0|            0|            0|  0.00%|    ```pycon
   428|         0|            0|            0|  0.00%|    >>> precisedelta(delta, minimum_unit="microseconds")
   429|         0|            0|            0|  0.00%|    '2 days, 1 hour, 33 seconds and 123 milliseconds'
   430|         0|            0|            0|  0.00%|
   431|         0|            0|            0|  0.00%|    ```
   432|         0|            0|            0|  0.00%|
   433|         0|            0|            0|  0.00%|    If desired, some units can be suppressed: you will not see them represented and the
   434|         0|            0|            0|  0.00%|    time of the other units will be adjusted to keep representing the same timedelta:
   435|         0|            0|            0|  0.00%|
   436|         0|            0|            0|  0.00%|    ```pycon
   437|         0|            0|            0|  0.00%|    >>> precisedelta(delta, suppress=['days'])
   438|         0|            0|            0|  0.00%|    '49 hours and 33.12 seconds'
   439|         0|            0|            0|  0.00%|
   440|         0|            0|            0|  0.00%|    ```
   441|         0|            0|            0|  0.00%|
   442|         0|            0|            0|  0.00%|    Note that microseconds precision is lost if the seconds and all
   443|         0|            0|            0|  0.00%|    the units below are suppressed:
   444|         0|            0|            0|  0.00%|
   445|         0|            0|            0|  0.00%|    ```pycon
   446|         0|            0|            0|  0.00%|    >>> delta = dt.timedelta(seconds=90, microseconds=100)
   447|         0|            0|            0|  0.00%|    >>> precisedelta(delta, suppress=['seconds', 'milliseconds', 'microseconds'])
   448|         0|            0|            0|  0.00%|    '1.50 minutes'
   449|         0|            0|            0|  0.00%|
   450|         0|            0|            0|  0.00%|    ```
   451|         0|            0|            0|  0.00%|
   452|         0|            0|            0|  0.00%|    If the delta is too small to be represented with the minimum unit,
   453|         0|            0|            0|  0.00%|    a value of zero will be returned:
   454|         0|            0|            0|  0.00%|
   455|         0|            0|            0|  0.00%|    ```pycon
   456|         0|            0|            0|  0.00%|    >>> delta = dt.timedelta(seconds=1)
   457|         0|            0|            0|  0.00%|    >>> precisedelta(delta, minimum_unit="minutes")
   458|         0|            0|            0|  0.00%|    '0.02 minutes'
   459|         0|            0|            0|  0.00%|
   460|         0|            0|            0|  0.00%|    >>> delta = dt.timedelta(seconds=0.1)
   461|         0|            0|            0|  0.00%|    >>> precisedelta(delta, minimum_unit="minutes")
   462|         0|            0|            0|  0.00%|    '0 minutes'
   463|         0|            0|            0|  0.00%|
   464|         0|            0|            0|  0.00%|    ```
   465|         0|            0|            0|  0.00%|    """
   466|         1|  2.19345e-05|  2.19345e-05|  0.00%|    date, delta = _date_and_delta(value)
(call)|         1|  6.34193e-05|  6.34193e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/time.py:62 _date_and_delta
   467|         1|  7.39098e-06|  7.39098e-06|  0.00%|    if date is None:
   468|         0|            0|            0|  0.00%|        return value
   469|         0|            0|            0|  0.00%|
   470|         3|  1.88351e-05|  6.27836e-06|  0.00%|    suppress = [Unit[s.upper()] for s in suppress]
(call)|         1|  5.72205e-06|  5.72205e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/time.py:470 <listcomp>
   471|         0|            0|            0|  0.00%|
   472|         0|            0|            0|  0.00%|    # Find a suitable minimum unit (it can be greater the one that the
   473|         0|            0|            0|  0.00%|    # user gave us if it is suppressed).
   474|         1|  1.62125e-05|  1.62125e-05|  0.00%|    min_unit = Unit[minimum_unit.upper()]
(call)|         1|   1.3113e-05|   1.3113e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/enum.py:343 __getitem__
   475|         1|  1.45435e-05|  1.45435e-05|  0.00%|    min_unit = _suitable_minimum_unit(min_unit, suppress)
(call)|         1|   1.3113e-05|   1.3113e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/time.py:353 _suitable_minimum_unit
   476|         1|  3.38554e-05|  3.38554e-05|  0.00%|    del minimum_unit
   477|         0|            0|            0|  0.00%|
   478|         0|            0|            0|  0.00%|    # Expand the suppressed units list/set to include all the units
   479|         0|            0|            0|  0.00%|    # that are below the minimum unit
   480|         1|  3.09944e-05|  3.09944e-05|  0.00%|    suppress = _suppress_lower_units(min_unit, suppress)
(call)|         1|  9.87053e-05|  9.87053e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/time.py:383 _suppress_lower_units
   481|         0|            0|            0|  0.00%|
   482|         0|            0|            0|  0.00%|    # handy aliases
   483|         1|  8.10623e-06|  8.10623e-06|  0.00%|    days = delta.days
   484|         1|  7.62939e-06|  7.62939e-06|  0.00%|    secs = delta.seconds
   485|         1|  6.91414e-06|  6.91414e-06|  0.00%|    usecs = delta.microseconds
   486|         0|            0|            0|  0.00%|
   487|         2|  6.55651e-05|  3.27826e-05|  0.00%|    MICROSECONDS, MILLISECONDS, SECONDS, MINUTES, HOURS, DAYS, MONTHS, YEARS = list(
(call)|         2|  9.29832e-06|  4.64916e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/enum.py:349 __len__
(call)|         1|  5.48363e-06|  5.48363e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/enum.py:346 __iter__
(call)|         9|  3.19481e-05|  3.54979e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/enum.py:347 <genexpr>
   488|         1|   6.4373e-06|   6.4373e-06|  0.00%|        Unit
   489|         0|            0|            0|  0.00%|    )
   490|         0|            0|            0|  0.00%|
   491|         0|            0|            0|  0.00%|    # Given DAYS compute YEARS and the remainder of DAYS as follows:
   492|         0|            0|            0|  0.00%|    #   if YEARS is the minimum unit, we cannot use DAYS so
   493|         0|            0|            0|  0.00%|    #   we will use a float for YEARS and 0 for DAYS:
   494|         0|            0|            0|  0.00%|    #       years, days = years/days, 0
   495|         0|            0|            0|  0.00%|    #
   496|         0|            0|            0|  0.00%|    #   if YEARS is suppressed, use DAYS:
   497|         0|            0|            0|  0.00%|    #       years, days = 0, days
   498|         0|            0|            0|  0.00%|    #
   499|         0|            0|            0|  0.00%|    #   otherwise:
   500|         0|            0|            0|  0.00%|    #       years, days = divmod(years, days)
   501|         0|            0|            0|  0.00%|    #
   502|         0|            0|            0|  0.00%|    # The same applies for months, hours, minutes and milliseconds below
   503|         1|  1.26362e-05|  1.26362e-05|  0.00%|    years, days = _quotient_and_remainder(days, 365, YEARS, min_unit, suppress)
(call)|         1|  2.31266e-05|  2.31266e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/time.py:289 _quotient_and_remainder
   504|         1|  1.16825e-05|  1.16825e-05|  0.00%|    months, days = _quotient_and_remainder(days, 30.5, MONTHS, min_unit, suppress)
(call)|         1|  1.50204e-05|  1.50204e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/time.py:289 _quotient_and_remainder
   505|         0|            0|            0|  0.00%|
   506|         0|            0|            0|  0.00%|    # If DAYS is not in suppress, we can represent the days but
   507|         0|            0|            0|  0.00%|    # if it is a suppressed unit, we need to carry it to a lower unit,
   508|         0|            0|            0|  0.00%|    # seconds in this case.
   509|         0|            0|            0|  0.00%|    #
   510|         0|            0|            0|  0.00%|    # The same applies for secs and usecs below
   511|         1|  1.54972e-05|  1.54972e-05|  0.00%|    days, secs = _carry(days, secs, 24 * 3600, DAYS, min_unit, suppress)
(call)|         1|  2.16961e-05|  2.16961e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/time.py:322 _carry
   512|         0|            0|            0|  0.00%|
   513|         1|  1.07288e-05|  1.07288e-05|  0.00%|    hours, secs = _quotient_and_remainder(secs, 3600, HOURS, min_unit, suppress)
(call)|         1|  1.35899e-05|  1.35899e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/time.py:289 _quotient_and_remainder
   514|         1|  1.09673e-05|  1.09673e-05|  0.00%|    minutes, secs = _quotient_and_remainder(secs, 60, MINUTES, min_unit, suppress)
(call)|         1|   1.3113e-05|   1.3113e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/time.py:289 _quotient_and_remainder
   515|         0|            0|            0|  0.00%|
   516|         1|  1.28746e-05|  1.28746e-05|  0.00%|    secs, usecs = _carry(secs, usecs, 1e6, SECONDS, min_unit, suppress)
(call)|         1|  6.19888e-06|  6.19888e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/time.py:322 _carry
   517|         0|            0|            0|  0.00%|
   518|         2|  1.81198e-05|  9.05991e-06|  0.00%|    msecs, usecs = _quotient_and_remainder(
(call)|         1|  1.33514e-05|  1.33514e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/time.py:289 _quotient_and_remainder
   519|         1|  5.48363e-06|  5.48363e-06|  0.00%|        usecs, 1000, MILLISECONDS, min_unit, suppress
   520|         0|            0|            0|  0.00%|    )
   521|         0|            0|            0|  0.00%|
   522|         0|            0|            0|  0.00%|    # if _unused != 0 we had lost some precision
   523|         1|  1.07288e-05|  1.07288e-05|  0.00%|    usecs, _unused = _carry(usecs, 0, 1, MICROSECONDS, min_unit, suppress)
(call)|         1|  1.35899e-05|  1.35899e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/time.py:322 _carry
   524|         0|            0|            0|  0.00%|
   525|         1|  5.24521e-06|  5.24521e-06|  0.00%|    fmts = [
   526|         1|  7.39098e-06|  7.39098e-06|  0.00%|        ("%d year", "%d years", years),
   527|         1|  5.24521e-06|  5.24521e-06|  0.00%|        ("%d month", "%d months", months),
   528|         1|  5.48363e-06|  5.48363e-06|  0.00%|        ("%d day", "%d days", days),
   529|         1|  5.24521e-06|  5.24521e-06|  0.00%|        ("%d hour", "%d hours", hours),
   530|         1|  5.00679e-06|  5.00679e-06|  0.00%|        ("%d minute", "%d minutes", minutes),
   531|         1|  4.76837e-06|  4.76837e-06|  0.00%|        ("%d second", "%d seconds", secs),
   532|         1|  5.24521e-06|  5.24521e-06|  0.00%|        ("%d millisecond", "%d milliseconds", msecs),
   533|         1|  5.00679e-06|  5.00679e-06|  0.00%|        ("%d microsecond", "%d microseconds", usecs),
   534|         0|            0|            0|  0.00%|    ]
   535|         0|            0|            0|  0.00%|
   536|         1|  4.76837e-06|  4.76837e-06|  0.00%|    texts = []
   537|         6|  6.19888e-05|  1.03315e-05|  0.00%|    for unit, fmt in zip(reversed(Unit), fmts):
(call)|         1|  9.05991e-06|  9.05991e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/enum.py:365 __reversed__
(call)|         6|  2.47955e-05|  4.13259e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/enum.py:366 <genexpr>
   538|         6|  2.19345e-05|  3.65575e-06|  0.00%|        singular_txt, plural_txt, value = fmt
   539|         6|  2.28882e-05|   3.8147e-06|  0.00%|        if value > 0 or (not texts and unit == min_unit):
   540|         2|  0.000133038|  6.65188e-05|  0.00%|            fmt_txt = _ngettext(singular_txt, plural_txt, value)
(call)|         2|   9.2268e-05|   4.6134e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/i18n.py:106 _ngettext
   541|         2|  1.14441e-05|  5.72205e-06|  0.00%|            if unit == min_unit and math.modf(value)[0] > 0:
   542|         1|  5.72205e-06|  5.72205e-06|  0.00%|                fmt_txt = fmt_txt.replace("%d", format)
   543|         1|  4.76837e-06|  4.76837e-06|  0.00%|            elif unit == YEARS:
   544|         0|            0|            0|  0.00%|                fmt_txt = fmt_txt.replace("%d", "%s")
   545|         0|            0|            0|  0.00%|                texts.append(fmt_txt % intcomma(value))
   546|         0|            0|            0|  0.00%|                continue
   547|         0|            0|            0|  0.00%|
   548|         2|  1.52588e-05|  7.62939e-06|  0.00%|            texts.append(fmt_txt % value)
   549|         0|            0|            0|  0.00%|
   550|         6|  2.36034e-05|  3.93391e-06|  0.00%|        if unit == min_unit:
   551|         1|  9.77516e-06|  9.77516e-06|  0.00%|            break
(call)|         1|   2.6226e-06|   2.6226e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/enum.py:366 <genexpr>
   552|         0|            0|            0|  0.00%|
   553|         1|  4.76837e-06|  4.76837e-06|  0.00%|    if len(texts) == 1:
   554|         0|            0|            0|  0.00%|        return texts[0]
   555|         0|            0|            0|  0.00%|
   556|         1|  5.72205e-06|  5.72205e-06|  0.00%|    head = ", ".join(texts[:-1])
   557|         1|  4.52995e-06|  4.52995e-06|  0.00%|    tail = texts[-1]
   558|         0|            0|            0|  0.00%|
   559|         1|  1.40667e-05|  1.40667e-05|  0.00%|    return _("%s and %s") % (head, tail)
(call)|         1|  3.48091e-05|  3.48091e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/i18n.py:69 _gettext
File: /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/logging/__init__.py
File duration: 0.000246763s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|# Copyright 2001-2017 by Vinay Sajip. All Rights Reserved.
     2|         0|            0|            0|  0.00%|#
     3|         0|            0|            0|  0.00%|# Permission to use, copy, modify, and distribute this software and its
     4|         0|            0|            0|  0.00%|# documentation for any purpose and without fee is hereby granted,
     5|         0|            0|            0|  0.00%|# provided that the above copyright notice appear in all copies and that
     6|         0|            0|            0|  0.00%|# both that copyright notice and this permission notice appear in
     7|         0|            0|            0|  0.00%|# supporting documentation, and that the name of Vinay Sajip
     8|         0|            0|            0|  0.00%|# not be used in advertising or publicity pertaining to distribution
     9|         0|            0|            0|  0.00%|# of the software without specific, written prior permission.
    10|         0|            0|            0|  0.00%|# VINAY SAJIP DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING
    11|         0|            0|            0|  0.00%|# ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL
    12|         0|            0|            0|  0.00%|# VINAY SAJIP BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR
    13|         0|            0|            0|  0.00%|# ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER
    14|         0|            0|            0|  0.00%|# IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
    15|         0|            0|            0|  0.00%|# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|"""
    18|         0|            0|            0|  0.00%|Logging package for Python. Based on PEP 282 and comments thereto in
    19|         0|            0|            0|  0.00%|comp.lang.python.
    20|         0|            0|            0|  0.00%|
    21|         0|            0|            0|  0.00%|Copyright (C) 2001-2017 Vinay Sajip. All Rights Reserved.
    22|         0|            0|            0|  0.00%|
    23|         0|            0|            0|  0.00%|To use, simply 'import logging' and log away!
    24|         0|            0|            0|  0.00%|"""
    25|         0|            0|            0|  0.00%|
    26|         0|            0|            0|  0.00%|import sys, os, time, io, re, traceback, warnings, weakref, collections.abc
    27|         0|            0|            0|  0.00%|
    28|         0|            0|            0|  0.00%|from string import Template
    29|         0|            0|            0|  0.00%|from string import Formatter as StrFormatter
    30|         0|            0|            0|  0.00%|
    31|         0|            0|            0|  0.00%|
    32|         0|            0|            0|  0.00%|__all__ = ['BASIC_FORMAT', 'BufferingFormatter', 'CRITICAL', 'DEBUG', 'ERROR',
    33|         0|            0|            0|  0.00%|           'FATAL', 'FileHandler', 'Filter', 'Formatter', 'Handler', 'INFO',
    34|         0|            0|            0|  0.00%|           'LogRecord', 'Logger', 'LoggerAdapter', 'NOTSET', 'NullHandler',
    35|         0|            0|            0|  0.00%|           'StreamHandler', 'WARN', 'WARNING', 'addLevelName', 'basicConfig',
    36|         0|            0|            0|  0.00%|           'captureWarnings', 'critical', 'debug', 'disable', 'error',
    37|         0|            0|            0|  0.00%|           'exception', 'fatal', 'getLevelName', 'getLogger', 'getLoggerClass',
    38|         0|            0|            0|  0.00%|           'info', 'log', 'makeLogRecord', 'setLoggerClass', 'shutdown',
    39|         0|            0|            0|  0.00%|           'warn', 'warning', 'getLogRecordFactory', 'setLogRecordFactory',
    40|         0|            0|            0|  0.00%|           'lastResort', 'raiseExceptions']
    41|         0|            0|            0|  0.00%|
    42|         0|            0|            0|  0.00%|import threading
    43|         0|            0|            0|  0.00%|
    44|         0|            0|            0|  0.00%|__author__  = "Vinay Sajip <vinay_sajip@red-dove.com>"
    45|         0|            0|            0|  0.00%|__status__  = "production"
    46|         0|            0|            0|  0.00%|# The following module attributes are no longer updated.
    47|         0|            0|            0|  0.00%|__version__ = "0.5.1.2"
    48|         0|            0|            0|  0.00%|__date__    = "07 February 2010"
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
    51|         0|            0|            0|  0.00%|#   Miscellaneous module data
    52|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
    53|         0|            0|            0|  0.00%|
    54|         0|            0|            0|  0.00%|#
    55|         0|            0|            0|  0.00%|#_startTime is used as the base when calculating the relative time of events
    56|         0|            0|            0|  0.00%|#
    57|         0|            0|            0|  0.00%|_startTime = time.time()
    58|         0|            0|            0|  0.00%|
    59|         0|            0|            0|  0.00%|#
    60|         0|            0|            0|  0.00%|#raiseExceptions is used to see if exceptions during handling should be
    61|         0|            0|            0|  0.00%|#propagated
    62|         0|            0|            0|  0.00%|#
    63|         0|            0|            0|  0.00%|raiseExceptions = True
    64|         0|            0|            0|  0.00%|
    65|         0|            0|            0|  0.00%|#
    66|         0|            0|            0|  0.00%|# If you don't want threading information in the log, set this to zero
    67|         0|            0|            0|  0.00%|#
    68|         0|            0|            0|  0.00%|logThreads = True
    69|         0|            0|            0|  0.00%|
    70|         0|            0|            0|  0.00%|#
    71|         0|            0|            0|  0.00%|# If you don't want multiprocessing information in the log, set this to zero
    72|         0|            0|            0|  0.00%|#
    73|         0|            0|            0|  0.00%|logMultiprocessing = True
    74|         0|            0|            0|  0.00%|
    75|         0|            0|            0|  0.00%|#
    76|         0|            0|            0|  0.00%|# If you don't want process information in the log, set this to zero
    77|         0|            0|            0|  0.00%|#
    78|         0|            0|            0|  0.00%|logProcesses = True
    79|         0|            0|            0|  0.00%|
    80|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
    81|         0|            0|            0|  0.00%|#   Level related stuff
    82|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
    83|         0|            0|            0|  0.00%|#
    84|         0|            0|            0|  0.00%|# Default levels and level names, these can be replaced with any positive set
    85|         0|            0|            0|  0.00%|# of values having corresponding names. There is a pseudo-level, NOTSET, which
    86|         0|            0|            0|  0.00%|# is only really there as a lower limit for user-defined levels. Handlers and
    87|         0|            0|            0|  0.00%|# loggers are initialized with NOTSET so that they will log all messages, even
    88|         0|            0|            0|  0.00%|# at user-defined levels.
    89|         0|            0|            0|  0.00%|#
    90|         0|            0|            0|  0.00%|
    91|         0|            0|            0|  0.00%|CRITICAL = 50
    92|         0|            0|            0|  0.00%|FATAL = CRITICAL
    93|         0|            0|            0|  0.00%|ERROR = 40
    94|         0|            0|            0|  0.00%|WARNING = 30
    95|         0|            0|            0|  0.00%|WARN = WARNING
    96|         0|            0|            0|  0.00%|INFO = 20
    97|         0|            0|            0|  0.00%|DEBUG = 10
    98|         0|            0|            0|  0.00%|NOTSET = 0
    99|         0|            0|            0|  0.00%|
   100|         0|            0|            0|  0.00%|_levelToName = {
   101|         0|            0|            0|  0.00%|    CRITICAL: 'CRITICAL',
   102|         0|            0|            0|  0.00%|    ERROR: 'ERROR',
   103|         0|            0|            0|  0.00%|    WARNING: 'WARNING',
   104|         0|            0|            0|  0.00%|    INFO: 'INFO',
   105|         0|            0|            0|  0.00%|    DEBUG: 'DEBUG',
   106|         0|            0|            0|  0.00%|    NOTSET: 'NOTSET',
   107|         0|            0|            0|  0.00%|}
   108|         0|            0|            0|  0.00%|_nameToLevel = {
   109|         0|            0|            0|  0.00%|    'CRITICAL': CRITICAL,
   110|         0|            0|            0|  0.00%|    'FATAL': FATAL,
   111|         0|            0|            0|  0.00%|    'ERROR': ERROR,
   112|         0|            0|            0|  0.00%|    'WARN': WARNING,
   113|         0|            0|            0|  0.00%|    'WARNING': WARNING,
   114|         0|            0|            0|  0.00%|    'INFO': INFO,
   115|         0|            0|            0|  0.00%|    'DEBUG': DEBUG,
   116|         0|            0|            0|  0.00%|    'NOTSET': NOTSET,
   117|         0|            0|            0|  0.00%|}
   118|         0|            0|            0|  0.00%|
   119|         0|            0|            0|  0.00%|def getLevelName(level):
   120|         0|            0|            0|  0.00%|    """
   121|         0|            0|            0|  0.00%|    Return the textual representation of logging level 'level'.
   122|         0|            0|            0|  0.00%|
   123|         0|            0|            0|  0.00%|    If the level is one of the predefined levels (CRITICAL, ERROR, WARNING,
   124|         0|            0|            0|  0.00%|    INFO, DEBUG) then you get the corresponding string. If you have
   125|         0|            0|            0|  0.00%|    associated levels with names using addLevelName then the name you have
   126|         0|            0|            0|  0.00%|    associated with 'level' is returned.
   127|         0|            0|            0|  0.00%|
   128|         0|            0|            0|  0.00%|    If a numeric value corresponding to one of the defined levels is passed
   129|         0|            0|            0|  0.00%|    in, the corresponding string representation is returned.
   130|         0|            0|            0|  0.00%|
   131|         0|            0|            0|  0.00%|    Otherwise, the string "Level %s" % level is returned.
   132|         0|            0|            0|  0.00%|    """
   133|         0|            0|            0|  0.00%|    # See Issues #22386, #27937 and #29220 for why it's this way
   134|         0|            0|            0|  0.00%|    result = _levelToName.get(level)
   135|         0|            0|            0|  0.00%|    if result is not None:
   136|         0|            0|            0|  0.00%|        return result
   137|         0|            0|            0|  0.00%|    result = _nameToLevel.get(level)
   138|         0|            0|            0|  0.00%|    if result is not None:
   139|         0|            0|            0|  0.00%|        return result
   140|         0|            0|            0|  0.00%|    return "Level %s" % level
   141|         0|            0|            0|  0.00%|
   142|         0|            0|            0|  0.00%|def addLevelName(level, levelName):
   143|         0|            0|            0|  0.00%|    """
   144|         0|            0|            0|  0.00%|    Associate 'levelName' with 'level'.
   145|         0|            0|            0|  0.00%|
   146|         0|            0|            0|  0.00%|    This is used when converting levels to text during message formatting.
   147|         0|            0|            0|  0.00%|    """
   148|         0|            0|            0|  0.00%|    _acquireLock()
   149|         0|            0|            0|  0.00%|    try:    #unlikely to cause an exception, but you never know...
   150|         0|            0|            0|  0.00%|        _levelToName[level] = levelName
   151|         0|            0|            0|  0.00%|        _nameToLevel[levelName] = level
   152|         0|            0|            0|  0.00%|    finally:
   153|         0|            0|            0|  0.00%|        _releaseLock()
   154|         0|            0|            0|  0.00%|
   155|         0|            0|            0|  0.00%|if hasattr(sys, '_getframe'):
   156|         0|            0|            0|  0.00%|    currentframe = lambda: sys._getframe(3)
   157|         0|            0|            0|  0.00%|else: #pragma: no cover
   158|         0|            0|            0|  0.00%|    def currentframe():
   159|         0|            0|            0|  0.00%|        """Return the frame object for the caller's stack frame."""
   160|         0|            0|            0|  0.00%|        try:
   161|         0|            0|            0|  0.00%|            raise Exception
   162|         0|            0|            0|  0.00%|        except Exception:
   163|         0|            0|            0|  0.00%|            return sys.exc_info()[2].tb_frame.f_back
   164|         0|            0|            0|  0.00%|
   165|         0|            0|            0|  0.00%|#
   166|         0|            0|            0|  0.00%|# _srcfile is used when walking the stack to check when we've got the first
   167|         0|            0|            0|  0.00%|# caller stack frame, by skipping frames whose filename is that of this
   168|         0|            0|            0|  0.00%|# module's source. It therefore should contain the filename of this module's
   169|         0|            0|            0|  0.00%|# source file.
   170|         0|            0|            0|  0.00%|#
   171|         0|            0|            0|  0.00%|# Ordinarily we would use __file__ for this, but frozen modules don't always
   172|         0|            0|            0|  0.00%|# have __file__ set, for some reason (see Issue #21736). Thus, we get the
   173|         0|            0|            0|  0.00%|# filename from a handy code object from a function defined in this module.
   174|         0|            0|            0|  0.00%|# (There's no particular reason for picking addLevelName.)
   175|         0|            0|            0|  0.00%|#
   176|         0|            0|            0|  0.00%|
   177|         0|            0|            0|  0.00%|_srcfile = os.path.normcase(addLevelName.__code__.co_filename)
   178|         0|            0|            0|  0.00%|
   179|         0|            0|            0|  0.00%|# _srcfile is only used in conjunction with sys._getframe().
   180|         0|            0|            0|  0.00%|# To provide compatibility with older versions of Python, set _srcfile
   181|         0|            0|            0|  0.00%|# to None if _getframe() is not available; this value will prevent
   182|         0|            0|            0|  0.00%|# findCaller() from being called. You can also do this if you want to avoid
   183|         0|            0|            0|  0.00%|# the overhead of fetching caller information, even when _getframe() is
   184|         0|            0|            0|  0.00%|# available.
   185|         0|            0|            0|  0.00%|#if not hasattr(sys, '_getframe'):
   186|         0|            0|            0|  0.00%|#    _srcfile = None
   187|         0|            0|            0|  0.00%|
   188|         0|            0|            0|  0.00%|
   189|         0|            0|            0|  0.00%|def _checkLevel(level):
   190|         0|            0|            0|  0.00%|    if isinstance(level, int):
   191|         0|            0|            0|  0.00%|        rv = level
   192|         0|            0|            0|  0.00%|    elif str(level) == level:
   193|         0|            0|            0|  0.00%|        if level not in _nameToLevel:
   194|         0|            0|            0|  0.00%|            raise ValueError("Unknown level: %r" % level)
   195|         0|            0|            0|  0.00%|        rv = _nameToLevel[level]
   196|         0|            0|            0|  0.00%|    else:
   197|         0|            0|            0|  0.00%|        raise TypeError("Level not an integer or a valid string: %r" % level)
   198|         0|            0|            0|  0.00%|    return rv
   199|         0|            0|            0|  0.00%|
   200|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
   201|         0|            0|            0|  0.00%|#   Thread-related stuff
   202|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
   203|         0|            0|            0|  0.00%|
   204|         0|            0|            0|  0.00%|#
   205|         0|            0|            0|  0.00%|#_lock is used to serialize access to shared data structures in this module.
   206|         0|            0|            0|  0.00%|#This needs to be an RLock because fileConfig() creates and configures
   207|         0|            0|            0|  0.00%|#Handlers, and so might arbitrary user threads. Since Handler code updates the
   208|         0|            0|            0|  0.00%|#shared dictionary _handlers, it needs to acquire the lock. But if configuring,
   209|         0|            0|            0|  0.00%|#the lock would already have been acquired - so we need an RLock.
   210|         0|            0|            0|  0.00%|#The same argument applies to Loggers and Manager.loggerDict.
   211|         0|            0|            0|  0.00%|#
   212|         0|            0|            0|  0.00%|_lock = threading.RLock()
   213|         0|            0|            0|  0.00%|
   214|         0|            0|            0|  0.00%|def _acquireLock():
   215|         0|            0|            0|  0.00%|    """
   216|         0|            0|            0|  0.00%|    Acquire the module-level lock for serializing access to shared data.
   217|         0|            0|            0|  0.00%|
   218|         0|            0|            0|  0.00%|    This should be released with _releaseLock().
   219|         0|            0|            0|  0.00%|    """
   220|         0|            0|            0|  0.00%|    if _lock:
   221|         0|            0|            0|  0.00%|        _lock.acquire()
   222|         0|            0|            0|  0.00%|
   223|         0|            0|            0|  0.00%|def _releaseLock():
   224|         0|            0|            0|  0.00%|    """
   225|         0|            0|            0|  0.00%|    Release the module-level lock acquired by calling _acquireLock().
   226|         0|            0|            0|  0.00%|    """
   227|         0|            0|            0|  0.00%|    if _lock:
   228|         0|            0|            0|  0.00%|        _lock.release()
   229|         0|            0|            0|  0.00%|
   230|         0|            0|            0|  0.00%|
   231|         0|            0|            0|  0.00%|# Prevent a held logging lock from blocking a child from logging.
   232|         0|            0|            0|  0.00%|
   233|         0|            0|            0|  0.00%|if not hasattr(os, 'register_at_fork'):  # Windows and friends.
   234|         0|            0|            0|  0.00%|    def _register_at_fork_reinit_lock(instance):
   235|         0|            0|            0|  0.00%|        pass  # no-op when os.register_at_fork does not exist.
   236|         0|            0|            0|  0.00%|else:
   237|         0|            0|            0|  0.00%|    # A collection of instances with a createLock method (logging.Handler)
   238|         0|            0|            0|  0.00%|    # to be called in the child after forking.  The weakref avoids us keeping
   239|         0|            0|            0|  0.00%|    # discarded Handler instances alive.  A set is used to avoid accumulating
   240|         0|            0|            0|  0.00%|    # duplicate registrations as createLock() is responsible for registering
   241|         0|            0|            0|  0.00%|    # a new Handler instance with this set in the first place.
   242|         0|            0|            0|  0.00%|    _at_fork_reinit_lock_weakset = weakref.WeakSet()
   243|         0|            0|            0|  0.00%|
   244|         0|            0|            0|  0.00%|    def _register_at_fork_reinit_lock(instance):
   245|         0|            0|            0|  0.00%|        _acquireLock()
   246|         0|            0|            0|  0.00%|        try:
   247|         0|            0|            0|  0.00%|            _at_fork_reinit_lock_weakset.add(instance)
   248|         0|            0|            0|  0.00%|        finally:
   249|         0|            0|            0|  0.00%|            _releaseLock()
   250|         0|            0|            0|  0.00%|
   251|         0|            0|            0|  0.00%|    def _after_at_fork_child_reinit_locks():
   252|         0|            0|            0|  0.00%|        # _acquireLock() was called in the parent before forking.
   253|         0|            0|            0|  0.00%|        for handler in _at_fork_reinit_lock_weakset:
   254|         0|            0|            0|  0.00%|            try:
   255|         0|            0|            0|  0.00%|                handler.createLock()
   256|         0|            0|            0|  0.00%|            except Exception as err:
   257|         0|            0|            0|  0.00%|                # Similar to what PyErr_WriteUnraisable does.
   258|         0|            0|            0|  0.00%|                print("Ignoring exception from logging atfork", instance,
   259|         0|            0|            0|  0.00%|                      "._reinit_lock() method:", err, file=sys.stderr)
   260|         0|            0|            0|  0.00%|        _releaseLock()  # Acquired by os.register_at_fork(before=.
   261|         0|            0|            0|  0.00%|
   262|         0|            0|            0|  0.00%|
   263|         0|            0|            0|  0.00%|    os.register_at_fork(before=_acquireLock,
   264|         0|            0|            0|  0.00%|                        after_in_child=_after_at_fork_child_reinit_locks,
   265|         0|            0|            0|  0.00%|                        after_in_parent=_releaseLock)
   266|         0|            0|            0|  0.00%|
   267|         0|            0|            0|  0.00%|
   268|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
   269|         0|            0|            0|  0.00%|#   The logging record
   270|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
   271|         0|            0|            0|  0.00%|
   272|         0|            0|            0|  0.00%|class LogRecord(object):
   273|         0|            0|            0|  0.00%|    """
   274|         0|            0|            0|  0.00%|    A LogRecord instance represents an event being logged.
   275|         0|            0|            0|  0.00%|
   276|         0|            0|            0|  0.00%|    LogRecord instances are created every time something is logged. They
   277|         0|            0|            0|  0.00%|    contain all the information pertinent to the event being logged. The
   278|         0|            0|            0|  0.00%|    main information passed in is in msg and args, which are combined
   279|         0|            0|            0|  0.00%|    using str(msg) % args to create the message field of the record. The
   280|         0|            0|            0|  0.00%|    record also includes information such as when the record was created,
   281|         0|            0|            0|  0.00%|    the source line where the logging call was made, and any exception
   282|         0|            0|            0|  0.00%|    information to be logged.
   283|         0|            0|            0|  0.00%|    """
   284|         0|            0|            0|  0.00%|    def __init__(self, name, level, pathname, lineno,
   285|         0|            0|            0|  0.00%|                 msg, args, exc_info, func=None, sinfo=None, **kwargs):
   286|         0|            0|            0|  0.00%|        """
   287|         0|            0|            0|  0.00%|        Initialize a logging record with interesting information.
   288|         0|            0|            0|  0.00%|        """
   289|         0|            0|            0|  0.00%|        ct = time.time()
   290|         0|            0|            0|  0.00%|        self.name = name
   291|         0|            0|            0|  0.00%|        self.msg = msg
   292|         0|            0|            0|  0.00%|        #
   293|         0|            0|            0|  0.00%|        # The following statement allows passing of a dictionary as a sole
   294|         0|            0|            0|  0.00%|        # argument, so that you can do something like
   295|         0|            0|            0|  0.00%|        #  logging.debug("a %(a)d b %(b)s", {'a':1, 'b':2})
   296|         0|            0|            0|  0.00%|        # Suggested by Stefan Behnel.
   297|         0|            0|            0|  0.00%|        # Note that without the test for args[0], we get a problem because
   298|         0|            0|            0|  0.00%|        # during formatting, we test to see if the arg is present using
   299|         0|            0|            0|  0.00%|        # 'if self.args:'. If the event being logged is e.g. 'Value is %d'
   300|         0|            0|            0|  0.00%|        # and if the passed arg fails 'if self.args:' then no formatting
   301|         0|            0|            0|  0.00%|        # is done. For example, logger.warning('Value is %d', 0) would log
   302|         0|            0|            0|  0.00%|        # 'Value is %d' instead of 'Value is 0'.
   303|         0|            0|            0|  0.00%|        # For the use case of passing a dictionary, this should not be a
   304|         0|            0|            0|  0.00%|        # problem.
   305|         0|            0|            0|  0.00%|        # Issue #21172: a request was made to relax the isinstance check
   306|         0|            0|            0|  0.00%|        # to hasattr(args[0], '__getitem__'). However, the docs on string
   307|         0|            0|            0|  0.00%|        # formatting still seem to suggest a mapping object is required.
   308|         0|            0|            0|  0.00%|        # Thus, while not removing the isinstance check, it does now look
   309|         0|            0|            0|  0.00%|        # for collections.abc.Mapping rather than, as before, dict.
   310|         0|            0|            0|  0.00%|        if (args and len(args) == 1 and isinstance(args[0], collections.abc.Mapping)
   311|         0|            0|            0|  0.00%|            and args[0]):
   312|         0|            0|            0|  0.00%|            args = args[0]
   313|         0|            0|            0|  0.00%|        self.args = args
   314|         0|            0|            0|  0.00%|        self.levelname = getLevelName(level)
   315|         0|            0|            0|  0.00%|        self.levelno = level
   316|         0|            0|            0|  0.00%|        self.pathname = pathname
   317|         0|            0|            0|  0.00%|        try:
   318|         0|            0|            0|  0.00%|            self.filename = os.path.basename(pathname)
   319|         0|            0|            0|  0.00%|            self.module = os.path.splitext(self.filename)[0]
   320|         0|            0|            0|  0.00%|        except (TypeError, ValueError, AttributeError):
   321|         0|            0|            0|  0.00%|            self.filename = pathname
   322|         0|            0|            0|  0.00%|            self.module = "Unknown module"
   323|         0|            0|            0|  0.00%|        self.exc_info = exc_info
   324|         0|            0|            0|  0.00%|        self.exc_text = None      # used to cache the traceback text
   325|         0|            0|            0|  0.00%|        self.stack_info = sinfo
   326|         0|            0|            0|  0.00%|        self.lineno = lineno
   327|         0|            0|            0|  0.00%|        self.funcName = func
   328|         0|            0|            0|  0.00%|        self.created = ct
   329|         0|            0|            0|  0.00%|        self.msecs = (ct - int(ct)) * 1000
   330|         0|            0|            0|  0.00%|        self.relativeCreated = (self.created - _startTime) * 1000
   331|         0|            0|            0|  0.00%|        if logThreads:
   332|         0|            0|            0|  0.00%|            self.thread = threading.get_ident()
   333|         0|            0|            0|  0.00%|            self.threadName = threading.current_thread().name
   334|         0|            0|            0|  0.00%|        else: # pragma: no cover
   335|         0|            0|            0|  0.00%|            self.thread = None
   336|         0|            0|            0|  0.00%|            self.threadName = None
   337|         0|            0|            0|  0.00%|        if not logMultiprocessing: # pragma: no cover
   338|         0|            0|            0|  0.00%|            self.processName = None
   339|         0|            0|            0|  0.00%|        else:
   340|         0|            0|            0|  0.00%|            self.processName = 'MainProcess'
   341|         0|            0|            0|  0.00%|            mp = sys.modules.get('multiprocessing')
   342|         0|            0|            0|  0.00%|            if mp is not None:
   343|         0|            0|            0|  0.00%|                # Errors may occur if multiprocessing has not finished loading
   344|         0|            0|            0|  0.00%|                # yet - e.g. if a custom import hook causes third-party code
   345|         0|            0|            0|  0.00%|                # to run when multiprocessing calls import. See issue 8200
   346|         0|            0|            0|  0.00%|                # for an example
   347|         0|            0|            0|  0.00%|                try:
   348|         0|            0|            0|  0.00%|                    self.processName = mp.current_process().name
   349|         0|            0|            0|  0.00%|                except Exception: #pragma: no cover
   350|         0|            0|            0|  0.00%|                    pass
   351|         0|            0|            0|  0.00%|        if logProcesses and hasattr(os, 'getpid'):
   352|         0|            0|            0|  0.00%|            self.process = os.getpid()
   353|         0|            0|            0|  0.00%|        else:
   354|         0|            0|            0|  0.00%|            self.process = None
   355|         0|            0|            0|  0.00%|
   356|         0|            0|            0|  0.00%|    def __repr__(self):
   357|         0|            0|            0|  0.00%|        return '<LogRecord: %s, %s, %s, %s, "%s">'%(self.name, self.levelno,
   358|         0|            0|            0|  0.00%|            self.pathname, self.lineno, self.msg)
   359|         0|            0|            0|  0.00%|
   360|         0|            0|            0|  0.00%|    def getMessage(self):
   361|         0|            0|            0|  0.00%|        """
   362|         0|            0|            0|  0.00%|        Return the message for this LogRecord.
   363|         0|            0|            0|  0.00%|
   364|         0|            0|            0|  0.00%|        Return the message for this LogRecord after merging any user-supplied
   365|         0|            0|            0|  0.00%|        arguments with the message.
   366|         0|            0|            0|  0.00%|        """
   367|         0|            0|            0|  0.00%|        msg = str(self.msg)
   368|         0|            0|            0|  0.00%|        if self.args:
   369|         0|            0|            0|  0.00%|            msg = msg % self.args
   370|         0|            0|            0|  0.00%|        return msg
   371|         0|            0|            0|  0.00%|
   372|         0|            0|            0|  0.00%|#
   373|         0|            0|            0|  0.00%|#   Determine which class to use when instantiating log records.
   374|         0|            0|            0|  0.00%|#
   375|         0|            0|            0|  0.00%|_logRecordFactory = LogRecord
   376|         0|            0|            0|  0.00%|
   377|         0|            0|            0|  0.00%|def setLogRecordFactory(factory):
   378|         0|            0|            0|  0.00%|    """
   379|         0|            0|            0|  0.00%|    Set the factory to be used when instantiating a log record.
   380|         0|            0|            0|  0.00%|
   381|         0|            0|            0|  0.00%|    :param factory: A callable which will be called to instantiate
   382|         0|            0|            0|  0.00%|    a log record.
   383|         0|            0|            0|  0.00%|    """
   384|         0|            0|            0|  0.00%|    global _logRecordFactory
   385|         0|            0|            0|  0.00%|    _logRecordFactory = factory
   386|         0|            0|            0|  0.00%|
   387|         0|            0|            0|  0.00%|def getLogRecordFactory():
   388|         0|            0|            0|  0.00%|    """
   389|         0|            0|            0|  0.00%|    Return the factory to be used when instantiating a log record.
   390|         0|            0|            0|  0.00%|    """
   391|         0|            0|            0|  0.00%|
   392|         0|            0|            0|  0.00%|    return _logRecordFactory
   393|         0|            0|            0|  0.00%|
   394|         0|            0|            0|  0.00%|def makeLogRecord(dict):
   395|         0|            0|            0|  0.00%|    """
   396|         0|            0|            0|  0.00%|    Make a LogRecord whose attributes are defined by the specified dictionary,
   397|         0|            0|            0|  0.00%|    This function is useful for converting a logging event received over
   398|         0|            0|            0|  0.00%|    a socket connection (which is sent as a dictionary) into a LogRecord
   399|         0|            0|            0|  0.00%|    instance.
   400|         0|            0|            0|  0.00%|    """
   401|         0|            0|            0|  0.00%|    rv = _logRecordFactory(None, None, "", 0, "", (), None, None)
   402|         0|            0|            0|  0.00%|    rv.__dict__.update(dict)
   403|         0|            0|            0|  0.00%|    return rv
   404|         0|            0|            0|  0.00%|
   405|         0|            0|            0|  0.00%|
   406|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
   407|         0|            0|            0|  0.00%|#   Formatter classes and functions
   408|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
   409|         0|            0|            0|  0.00%|_str_formatter = StrFormatter()
   410|         0|            0|            0|  0.00%|del StrFormatter
   411|         0|            0|            0|  0.00%|
   412|         0|            0|            0|  0.00%|
   413|         0|            0|            0|  0.00%|class PercentStyle(object):
   414|         0|            0|            0|  0.00%|
   415|         0|            0|            0|  0.00%|    default_format = '%(message)s'
   416|         0|            0|            0|  0.00%|    asctime_format = '%(asctime)s'
   417|         0|            0|            0|  0.00%|    asctime_search = '%(asctime)'
   418|         0|            0|            0|  0.00%|    validation_pattern = re.compile(r'%\(\w+\)[#0+ -]*(\*|\d+)?(\.(\*|\d+))?[diouxefgcrsa%]', re.I)
   419|         0|            0|            0|  0.00%|
   420|         0|            0|            0|  0.00%|    def __init__(self, fmt):
   421|         0|            0|            0|  0.00%|        self._fmt = fmt or self.default_format
   422|         0|            0|            0|  0.00%|
   423|         0|            0|            0|  0.00%|    def usesTime(self):
   424|         0|            0|            0|  0.00%|        return self._fmt.find(self.asctime_search) >= 0
   425|         0|            0|            0|  0.00%|
   426|         0|            0|            0|  0.00%|    def validate(self):
   427|         0|            0|            0|  0.00%|        """Validate the input format, ensure it matches the correct style"""
   428|         0|            0|            0|  0.00%|        if not self.validation_pattern.search(self._fmt):
   429|         0|            0|            0|  0.00%|            raise ValueError("Invalid format '%s' for '%s' style" % (self._fmt, self.default_format[0]))
   430|         0|            0|            0|  0.00%|
   431|         0|            0|            0|  0.00%|    def _format(self, record):
   432|         0|            0|            0|  0.00%|        return self._fmt % record.__dict__
   433|         0|            0|            0|  0.00%|
   434|         0|            0|            0|  0.00%|    def format(self, record):
   435|         0|            0|            0|  0.00%|        try:
   436|         0|            0|            0|  0.00%|            return self._format(record)
   437|         0|            0|            0|  0.00%|        except KeyError as e:
   438|         0|            0|            0|  0.00%|            raise ValueError('Formatting field not found in record: %s' % e)
   439|         0|            0|            0|  0.00%|
   440|         0|            0|            0|  0.00%|
   441|         0|            0|            0|  0.00%|class StrFormatStyle(PercentStyle):
   442|         0|            0|            0|  0.00%|    default_format = '{message}'
   443|         0|            0|            0|  0.00%|    asctime_format = '{asctime}'
   444|         0|            0|            0|  0.00%|    asctime_search = '{asctime'
   445|         0|            0|            0|  0.00%|
   446|         0|            0|            0|  0.00%|    fmt_spec = re.compile(r'^(.?[<>=^])?[+ -]?#?0?(\d+|{\w+})?[,_]?(\.(\d+|{\w+}))?[bcdefgnosx%]?$', re.I)
   447|         0|            0|            0|  0.00%|    field_spec = re.compile(r'^(\d+|\w+)(\.\w+|\[[^]]+\])*$')
   448|         0|            0|            0|  0.00%|
   449|         0|            0|            0|  0.00%|    def _format(self, record):
   450|         0|            0|            0|  0.00%|        return self._fmt.format(**record.__dict__)
   451|         0|            0|            0|  0.00%|
   452|         0|            0|            0|  0.00%|    def validate(self):
   453|         0|            0|            0|  0.00%|        """Validate the input format, ensure it is the correct string formatting style"""
   454|         0|            0|            0|  0.00%|        fields = set()
   455|         0|            0|            0|  0.00%|        try:
   456|         0|            0|            0|  0.00%|            for _, fieldname, spec, conversion in _str_formatter.parse(self._fmt):
   457|         0|            0|            0|  0.00%|                if fieldname:
   458|         0|            0|            0|  0.00%|                    if not self.field_spec.match(fieldname):
   459|         0|            0|            0|  0.00%|                        raise ValueError('invalid field name/expression: %r' % fieldname)
   460|         0|            0|            0|  0.00%|                    fields.add(fieldname)
   461|         0|            0|            0|  0.00%|                if conversion and conversion not in 'rsa':
   462|         0|            0|            0|  0.00%|                    raise ValueError('invalid conversion: %r' % conversion)
   463|         0|            0|            0|  0.00%|                if spec and not self.fmt_spec.match(spec):
   464|         0|            0|            0|  0.00%|                    raise ValueError('bad specifier: %r' % spec)
   465|         0|            0|            0|  0.00%|        except ValueError as e:
   466|         0|            0|            0|  0.00%|            raise ValueError('invalid format: %s' % e)
   467|         0|            0|            0|  0.00%|        if not fields:
   468|         0|            0|            0|  0.00%|            raise ValueError('invalid format: no fields')
   469|         0|            0|            0|  0.00%|
   470|         0|            0|            0|  0.00%|
   471|         0|            0|            0|  0.00%|class StringTemplateStyle(PercentStyle):
   472|         0|            0|            0|  0.00%|    default_format = '${message}'
   473|         0|            0|            0|  0.00%|    asctime_format = '${asctime}'
   474|         0|            0|            0|  0.00%|    asctime_search = '${asctime}'
   475|         0|            0|            0|  0.00%|
   476|         0|            0|            0|  0.00%|    def __init__(self, fmt):
   477|         0|            0|            0|  0.00%|        self._fmt = fmt or self.default_format
   478|         0|            0|            0|  0.00%|        self._tpl = Template(self._fmt)
   479|         0|            0|            0|  0.00%|
   480|         0|            0|            0|  0.00%|    def usesTime(self):
   481|         0|            0|            0|  0.00%|        fmt = self._fmt
   482|         0|            0|            0|  0.00%|        return fmt.find('$asctime') >= 0 or fmt.find(self.asctime_format) >= 0
   483|         0|            0|            0|  0.00%|
   484|         0|            0|            0|  0.00%|    def validate(self):
   485|         0|            0|            0|  0.00%|        pattern = Template.pattern
   486|         0|            0|            0|  0.00%|        fields = set()
   487|         0|            0|            0|  0.00%|        for m in pattern.finditer(self._fmt):
   488|         0|            0|            0|  0.00%|            d = m.groupdict()
   489|         0|            0|            0|  0.00%|            if d['named']:
   490|         0|            0|            0|  0.00%|                fields.add(d['named'])
   491|         0|            0|            0|  0.00%|            elif d['braced']:
   492|         0|            0|            0|  0.00%|                fields.add(d['braced'])
   493|         0|            0|            0|  0.00%|            elif m.group(0) == '$':
   494|         0|            0|            0|  0.00%|                raise ValueError('invalid format: bare \'$\' not allowed')
   495|         0|            0|            0|  0.00%|        if not fields:
   496|         0|            0|            0|  0.00%|            raise ValueError('invalid format: no fields')
   497|         0|            0|            0|  0.00%|
   498|         0|            0|            0|  0.00%|    def _format(self, record):
   499|         0|            0|            0|  0.00%|        return self._tpl.substitute(**record.__dict__)
   500|         0|            0|            0|  0.00%|
   501|         0|            0|            0|  0.00%|
   502|         0|            0|            0|  0.00%|BASIC_FORMAT = "%(levelname)s:%(name)s:%(message)s"
   503|         0|            0|            0|  0.00%|
   504|         0|            0|            0|  0.00%|_STYLES = {
   505|         0|            0|            0|  0.00%|    '%': (PercentStyle, BASIC_FORMAT),
   506|         0|            0|            0|  0.00%|    '{': (StrFormatStyle, '{levelname}:{name}:{message}'),
   507|         0|            0|            0|  0.00%|    '$': (StringTemplateStyle, '${levelname}:${name}:${message}'),
   508|         0|            0|            0|  0.00%|}
   509|         0|            0|            0|  0.00%|
   510|         0|            0|            0|  0.00%|class Formatter(object):
   511|         0|            0|            0|  0.00%|    """
   512|         0|            0|            0|  0.00%|    Formatter instances are used to convert a LogRecord to text.
   513|         0|            0|            0|  0.00%|
   514|         0|            0|            0|  0.00%|    Formatters need to know how a LogRecord is constructed. They are
   515|         0|            0|            0|  0.00%|    responsible for converting a LogRecord to (usually) a string which can
   516|         0|            0|            0|  0.00%|    be interpreted by either a human or an external system. The base Formatter
   517|         0|            0|            0|  0.00%|    allows a formatting string to be specified. If none is supplied, the
   518|         0|            0|            0|  0.00%|    the style-dependent default value, "%(message)s", "{message}", or
   519|         0|            0|            0|  0.00%|    "${message}", is used.
   520|         0|            0|            0|  0.00%|
   521|         0|            0|            0|  0.00%|    The Formatter can be initialized with a format string which makes use of
   522|         0|            0|            0|  0.00%|    knowledge of the LogRecord attributes - e.g. the default value mentioned
   523|         0|            0|            0|  0.00%|    above makes use of the fact that the user's message and arguments are pre-
   524|         0|            0|            0|  0.00%|    formatted into a LogRecord's message attribute. Currently, the useful
   525|         0|            0|            0|  0.00%|    attributes in a LogRecord are described by:
   526|         0|            0|            0|  0.00%|
   527|         0|            0|            0|  0.00%|    %(name)s            Name of the logger (logging channel)
   528|         0|            0|            0|  0.00%|    %(levelno)s         Numeric logging level for the message (DEBUG, INFO,
   529|         0|            0|            0|  0.00%|                        WARNING, ERROR, CRITICAL)
   530|         0|            0|            0|  0.00%|    %(levelname)s       Text logging level for the message ("DEBUG", "INFO",
   531|         0|            0|            0|  0.00%|                        "WARNING", "ERROR", "CRITICAL")
   532|         0|            0|            0|  0.00%|    %(pathname)s        Full pathname of the source file where the logging
   533|         0|            0|            0|  0.00%|                        call was issued (if available)
   534|         0|            0|            0|  0.00%|    %(filename)s        Filename portion of pathname
   535|         0|            0|            0|  0.00%|    %(module)s          Module (name portion of filename)
   536|         0|            0|            0|  0.00%|    %(lineno)d          Source line number where the logging call was issued
   537|         0|            0|            0|  0.00%|                        (if available)
   538|         0|            0|            0|  0.00%|    %(funcName)s        Function name
   539|         0|            0|            0|  0.00%|    %(created)f         Time when the LogRecord was created (time.time()
   540|         0|            0|            0|  0.00%|                        return value)
   541|         0|            0|            0|  0.00%|    %(asctime)s         Textual time when the LogRecord was created
   542|         0|            0|            0|  0.00%|    %(msecs)d           Millisecond portion of the creation time
   543|         0|            0|            0|  0.00%|    %(relativeCreated)d Time in milliseconds when the LogRecord was created,
   544|         0|            0|            0|  0.00%|                        relative to the time the logging module was loaded
   545|         0|            0|            0|  0.00%|                        (typically at application startup time)
   546|         0|            0|            0|  0.00%|    %(thread)d          Thread ID (if available)
   547|         0|            0|            0|  0.00%|    %(threadName)s      Thread name (if available)
   548|         0|            0|            0|  0.00%|    %(process)d         Process ID (if available)
   549|         0|            0|            0|  0.00%|    %(message)s         The result of record.getMessage(), computed just as
   550|         0|            0|            0|  0.00%|                        the record is emitted
   551|         0|            0|            0|  0.00%|    """
   552|         0|            0|            0|  0.00%|
   553|         0|            0|            0|  0.00%|    converter = time.localtime
   554|         0|            0|            0|  0.00%|
   555|         0|            0|            0|  0.00%|    def __init__(self, fmt=None, datefmt=None, style='%', validate=True):
   556|         0|            0|            0|  0.00%|        """
   557|         0|            0|            0|  0.00%|        Initialize the formatter with specified format strings.
   558|         0|            0|            0|  0.00%|
   559|         0|            0|            0|  0.00%|        Initialize the formatter either with the specified format string, or a
   560|         0|            0|            0|  0.00%|        default as described above. Allow for specialized date formatting with
   561|         0|            0|            0|  0.00%|        the optional datefmt argument. If datefmt is omitted, you get an
   562|         0|            0|            0|  0.00%|        ISO8601-like (or RFC 3339-like) format.
   563|         0|            0|            0|  0.00%|
   564|         0|            0|            0|  0.00%|        Use a style parameter of '%', '{' or '$' to specify that you want to
   565|         0|            0|            0|  0.00%|        use one of %-formatting, :meth:`str.format` (``{}``) formatting or
   566|         0|            0|            0|  0.00%|        :class:`string.Template` formatting in your format string.
   567|         0|            0|            0|  0.00%|
   568|         0|            0|            0|  0.00%|        .. versionchanged:: 3.2
   569|         0|            0|            0|  0.00%|           Added the ``style`` parameter.
   570|         0|            0|            0|  0.00%|        """
   571|         0|            0|            0|  0.00%|        if style not in _STYLES:
   572|         0|            0|            0|  0.00%|            raise ValueError('Style must be one of: %s' % ','.join(
   573|         0|            0|            0|  0.00%|                             _STYLES.keys()))
   574|         0|            0|            0|  0.00%|        self._style = _STYLES[style][0](fmt)
   575|         0|            0|            0|  0.00%|        if validate:
   576|         0|            0|            0|  0.00%|            self._style.validate()
   577|         0|            0|            0|  0.00%|
   578|         0|            0|            0|  0.00%|        self._fmt = self._style._fmt
   579|         0|            0|            0|  0.00%|        self.datefmt = datefmt
   580|         0|            0|            0|  0.00%|
   581|         0|            0|            0|  0.00%|    default_time_format = '%Y-%m-%d %H:%M:%S'
   582|         0|            0|            0|  0.00%|    default_msec_format = '%s,%03d'
   583|         0|            0|            0|  0.00%|
   584|         0|            0|            0|  0.00%|    def formatTime(self, record, datefmt=None):
   585|         0|            0|            0|  0.00%|        """
   586|         0|            0|            0|  0.00%|        Return the creation time of the specified LogRecord as formatted text.
   587|         0|            0|            0|  0.00%|
   588|         0|            0|            0|  0.00%|        This method should be called from format() by a formatter which
   589|         0|            0|            0|  0.00%|        wants to make use of a formatted time. This method can be overridden
   590|         0|            0|            0|  0.00%|        in formatters to provide for any specific requirement, but the
   591|         0|            0|            0|  0.00%|        basic behaviour is as follows: if datefmt (a string) is specified,
   592|         0|            0|            0|  0.00%|        it is used with time.strftime() to format the creation time of the
   593|         0|            0|            0|  0.00%|        record. Otherwise, an ISO8601-like (or RFC 3339-like) format is used.
   594|         0|            0|            0|  0.00%|        The resulting string is returned. This function uses a user-configurable
   595|         0|            0|            0|  0.00%|        function to convert the creation time to a tuple. By default,
   596|         0|            0|            0|  0.00%|        time.localtime() is used; to change this for a particular formatter
   597|         0|            0|            0|  0.00%|        instance, set the 'converter' attribute to a function with the same
   598|         0|            0|            0|  0.00%|        signature as time.localtime() or time.gmtime(). To change it for all
   599|         0|            0|            0|  0.00%|        formatters, for example if you want all logging times to be shown in GMT,
   600|         0|            0|            0|  0.00%|        set the 'converter' attribute in the Formatter class.
   601|         0|            0|            0|  0.00%|        """
   602|         0|            0|            0|  0.00%|        ct = self.converter(record.created)
   603|         0|            0|            0|  0.00%|        if datefmt:
   604|         0|            0|            0|  0.00%|            s = time.strftime(datefmt, ct)
   605|         0|            0|            0|  0.00%|        else:
   606|         0|            0|            0|  0.00%|            t = time.strftime(self.default_time_format, ct)
   607|         0|            0|            0|  0.00%|            s = self.default_msec_format % (t, record.msecs)
   608|         0|            0|            0|  0.00%|        return s
   609|         0|            0|            0|  0.00%|
   610|         0|            0|            0|  0.00%|    def formatException(self, ei):
   611|         0|            0|            0|  0.00%|        """
   612|         0|            0|            0|  0.00%|        Format and return the specified exception information as a string.
   613|         0|            0|            0|  0.00%|
   614|         0|            0|            0|  0.00%|        This default implementation just uses
   615|         0|            0|            0|  0.00%|        traceback.print_exception()
   616|         0|            0|            0|  0.00%|        """
   617|         0|            0|            0|  0.00%|        sio = io.StringIO()
   618|         0|            0|            0|  0.00%|        tb = ei[2]
   619|         0|            0|            0|  0.00%|        # See issues #9427, #1553375. Commented out for now.
   620|         0|            0|            0|  0.00%|        #if getattr(self, 'fullstack', False):
   621|         0|            0|            0|  0.00%|        #    traceback.print_stack(tb.tb_frame.f_back, file=sio)
   622|         0|            0|            0|  0.00%|        traceback.print_exception(ei[0], ei[1], tb, None, sio)
   623|         0|            0|            0|  0.00%|        s = sio.getvalue()
   624|         0|            0|            0|  0.00%|        sio.close()
   625|         0|            0|            0|  0.00%|        if s[-1:] == "\n":
   626|         0|            0|            0|  0.00%|            s = s[:-1]
   627|         0|            0|            0|  0.00%|        return s
   628|         0|            0|            0|  0.00%|
   629|         0|            0|            0|  0.00%|    def usesTime(self):
   630|         0|            0|            0|  0.00%|        """
   631|         0|            0|            0|  0.00%|        Check if the format uses the creation time of the record.
   632|         0|            0|            0|  0.00%|        """
   633|         0|            0|            0|  0.00%|        return self._style.usesTime()
   634|         0|            0|            0|  0.00%|
   635|         0|            0|            0|  0.00%|    def formatMessage(self, record):
   636|         0|            0|            0|  0.00%|        return self._style.format(record)
   637|         0|            0|            0|  0.00%|
   638|         0|            0|            0|  0.00%|    def formatStack(self, stack_info):
   639|         0|            0|            0|  0.00%|        """
   640|         0|            0|            0|  0.00%|        This method is provided as an extension point for specialized
   641|         0|            0|            0|  0.00%|        formatting of stack information.
   642|         0|            0|            0|  0.00%|
   643|         0|            0|            0|  0.00%|        The input data is a string as returned from a call to
   644|         0|            0|            0|  0.00%|        :func:`traceback.print_stack`, but with the last trailing newline
   645|         0|            0|            0|  0.00%|        removed.
   646|         0|            0|            0|  0.00%|
   647|         0|            0|            0|  0.00%|        The base implementation just returns the value passed in.
   648|         0|            0|            0|  0.00%|        """
   649|         0|            0|            0|  0.00%|        return stack_info
   650|         0|            0|            0|  0.00%|
   651|         0|            0|            0|  0.00%|    def format(self, record):
   652|         0|            0|            0|  0.00%|        """
   653|         0|            0|            0|  0.00%|        Format the specified record as text.
   654|         0|            0|            0|  0.00%|
   655|         0|            0|            0|  0.00%|        The record's attribute dictionary is used as the operand to a
   656|         0|            0|            0|  0.00%|        string formatting operation which yields the returned string.
   657|         0|            0|            0|  0.00%|        Before formatting the dictionary, a couple of preparatory steps
   658|         0|            0|            0|  0.00%|        are carried out. The message attribute of the record is computed
   659|         0|            0|            0|  0.00%|        using LogRecord.getMessage(). If the formatting string uses the
   660|         0|            0|            0|  0.00%|        time (as determined by a call to usesTime(), formatTime() is
   661|         0|            0|            0|  0.00%|        called to format the event time. If there is exception information,
   662|         0|            0|            0|  0.00%|        it is formatted using formatException() and appended to the message.
   663|         0|            0|            0|  0.00%|        """
   664|         0|            0|            0|  0.00%|        record.message = record.getMessage()
   665|         0|            0|            0|  0.00%|        if self.usesTime():
   666|         0|            0|            0|  0.00%|            record.asctime = self.formatTime(record, self.datefmt)
   667|         0|            0|            0|  0.00%|        s = self.formatMessage(record)
   668|         0|            0|            0|  0.00%|        if record.exc_info:
   669|         0|            0|            0|  0.00%|            # Cache the traceback text to avoid converting it multiple times
   670|         0|            0|            0|  0.00%|            # (it's constant anyway)
   671|         0|            0|            0|  0.00%|            if not record.exc_text:
   672|         0|            0|            0|  0.00%|                record.exc_text = self.formatException(record.exc_info)
   673|         0|            0|            0|  0.00%|        if record.exc_text:
   674|         0|            0|            0|  0.00%|            if s[-1:] != "\n":
   675|         0|            0|            0|  0.00%|                s = s + "\n"
   676|         0|            0|            0|  0.00%|            s = s + record.exc_text
   677|         0|            0|            0|  0.00%|        if record.stack_info:
   678|         0|            0|            0|  0.00%|            if s[-1:] != "\n":
   679|         0|            0|            0|  0.00%|                s = s + "\n"
   680|         0|            0|            0|  0.00%|            s = s + self.formatStack(record.stack_info)
   681|         0|            0|            0|  0.00%|        return s
   682|         0|            0|            0|  0.00%|
   683|         0|            0|            0|  0.00%|#
   684|         0|            0|            0|  0.00%|#   The default formatter to use when no other is specified
   685|         0|            0|            0|  0.00%|#
   686|         0|            0|            0|  0.00%|_defaultFormatter = Formatter()
   687|         0|            0|            0|  0.00%|
   688|         0|            0|            0|  0.00%|class BufferingFormatter(object):
   689|         0|            0|            0|  0.00%|    """
   690|         0|            0|            0|  0.00%|    A formatter suitable for formatting a number of records.
   691|         0|            0|            0|  0.00%|    """
   692|         0|            0|            0|  0.00%|    def __init__(self, linefmt=None):
   693|         0|            0|            0|  0.00%|        """
   694|         0|            0|            0|  0.00%|        Optionally specify a formatter which will be used to format each
   695|         0|            0|            0|  0.00%|        individual record.
   696|         0|            0|            0|  0.00%|        """
   697|         0|            0|            0|  0.00%|        if linefmt:
   698|         0|            0|            0|  0.00%|            self.linefmt = linefmt
   699|         0|            0|            0|  0.00%|        else:
   700|         0|            0|            0|  0.00%|            self.linefmt = _defaultFormatter
   701|         0|            0|            0|  0.00%|
   702|         0|            0|            0|  0.00%|    def formatHeader(self, records):
   703|         0|            0|            0|  0.00%|        """
   704|         0|            0|            0|  0.00%|        Return the header string for the specified records.
   705|         0|            0|            0|  0.00%|        """
   706|         0|            0|            0|  0.00%|        return ""
   707|         0|            0|            0|  0.00%|
   708|         0|            0|            0|  0.00%|    def formatFooter(self, records):
   709|         0|            0|            0|  0.00%|        """
   710|         0|            0|            0|  0.00%|        Return the footer string for the specified records.
   711|         0|            0|            0|  0.00%|        """
   712|         0|            0|            0|  0.00%|        return ""
   713|         0|            0|            0|  0.00%|
   714|         0|            0|            0|  0.00%|    def format(self, records):
   715|         0|            0|            0|  0.00%|        """
   716|         0|            0|            0|  0.00%|        Format the specified records and return the result as a string.
   717|         0|            0|            0|  0.00%|        """
   718|         0|            0|            0|  0.00%|        rv = ""
   719|         0|            0|            0|  0.00%|        if len(records) > 0:
   720|         0|            0|            0|  0.00%|            rv = rv + self.formatHeader(records)
   721|         0|            0|            0|  0.00%|            for record in records:
   722|         0|            0|            0|  0.00%|                rv = rv + self.linefmt.format(record)
   723|         0|            0|            0|  0.00%|            rv = rv + self.formatFooter(records)
   724|         0|            0|            0|  0.00%|        return rv
   725|         0|            0|            0|  0.00%|
   726|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
   727|         0|            0|            0|  0.00%|#   Filter classes and functions
   728|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
   729|         0|            0|            0|  0.00%|
   730|         0|            0|            0|  0.00%|class Filter(object):
   731|         0|            0|            0|  0.00%|    """
   732|         0|            0|            0|  0.00%|    Filter instances are used to perform arbitrary filtering of LogRecords.
   733|         0|            0|            0|  0.00%|
   734|         0|            0|            0|  0.00%|    Loggers and Handlers can optionally use Filter instances to filter
   735|         0|            0|            0|  0.00%|    records as desired. The base filter class only allows events which are
   736|         0|            0|            0|  0.00%|    below a certain point in the logger hierarchy. For example, a filter
   737|         0|            0|            0|  0.00%|    initialized with "A.B" will allow events logged by loggers "A.B",
   738|         0|            0|            0|  0.00%|    "A.B.C", "A.B.C.D", "A.B.D" etc. but not "A.BB", "B.A.B" etc. If
   739|         0|            0|            0|  0.00%|    initialized with the empty string, all events are passed.
   740|         0|            0|            0|  0.00%|    """
   741|         0|            0|            0|  0.00%|    def __init__(self, name=''):
   742|         0|            0|            0|  0.00%|        """
   743|         0|            0|            0|  0.00%|        Initialize a filter.
   744|         0|            0|            0|  0.00%|
   745|         0|            0|            0|  0.00%|        Initialize with the name of the logger which, together with its
   746|         0|            0|            0|  0.00%|        children, will have its events allowed through the filter. If no
   747|         0|            0|            0|  0.00%|        name is specified, allow every event.
   748|         0|            0|            0|  0.00%|        """
   749|         0|            0|            0|  0.00%|        self.name = name
   750|         0|            0|            0|  0.00%|        self.nlen = len(name)
   751|         0|            0|            0|  0.00%|
   752|         0|            0|            0|  0.00%|    def filter(self, record):
   753|         0|            0|            0|  0.00%|        """
   754|         0|            0|            0|  0.00%|        Determine if the specified record is to be logged.
   755|         0|            0|            0|  0.00%|
   756|         0|            0|            0|  0.00%|        Is the specified record to be logged? Returns 0 for no, nonzero for
   757|         0|            0|            0|  0.00%|        yes. If deemed appropriate, the record may be modified in-place.
   758|         0|            0|            0|  0.00%|        """
   759|         0|            0|            0|  0.00%|        if self.nlen == 0:
   760|         0|            0|            0|  0.00%|            return True
   761|         0|            0|            0|  0.00%|        elif self.name == record.name:
   762|         0|            0|            0|  0.00%|            return True
   763|         0|            0|            0|  0.00%|        elif record.name.find(self.name, 0, self.nlen) != 0:
   764|         0|            0|            0|  0.00%|            return False
   765|         0|            0|            0|  0.00%|        return (record.name[self.nlen] == ".")
   766|         0|            0|            0|  0.00%|
   767|         0|            0|            0|  0.00%|class Filterer(object):
   768|         0|            0|            0|  0.00%|    """
   769|         0|            0|            0|  0.00%|    A base class for loggers and handlers which allows them to share
   770|         0|            0|            0|  0.00%|    common code.
   771|         0|            0|            0|  0.00%|    """
   772|         0|            0|            0|  0.00%|    def __init__(self):
   773|         0|            0|            0|  0.00%|        """
   774|         0|            0|            0|  0.00%|        Initialize the list of filters to be an empty list.
   775|         0|            0|            0|  0.00%|        """
   776|         0|            0|            0|  0.00%|        self.filters = []
   777|         0|            0|            0|  0.00%|
   778|         0|            0|            0|  0.00%|    def addFilter(self, filter):
   779|         0|            0|            0|  0.00%|        """
   780|         0|            0|            0|  0.00%|        Add the specified filter to this handler.
   781|         0|            0|            0|  0.00%|        """
   782|         0|            0|            0|  0.00%|        if not (filter in self.filters):
   783|         0|            0|            0|  0.00%|            self.filters.append(filter)
   784|         0|            0|            0|  0.00%|
   785|         0|            0|            0|  0.00%|    def removeFilter(self, filter):
   786|         0|            0|            0|  0.00%|        """
   787|         0|            0|            0|  0.00%|        Remove the specified filter from this handler.
   788|         0|            0|            0|  0.00%|        """
   789|         0|            0|            0|  0.00%|        if filter in self.filters:
   790|         0|            0|            0|  0.00%|            self.filters.remove(filter)
   791|         0|            0|            0|  0.00%|
   792|         0|            0|            0|  0.00%|    def filter(self, record):
   793|         0|            0|            0|  0.00%|        """
   794|         0|            0|            0|  0.00%|        Determine if a record is loggable by consulting all the filters.
   795|         0|            0|            0|  0.00%|
   796|         0|            0|            0|  0.00%|        The default is to allow the record to be logged; any filter can veto
   797|         0|            0|            0|  0.00%|        this and the record is then dropped. Returns a zero value if a record
   798|         0|            0|            0|  0.00%|        is to be dropped, else non-zero.
   799|         0|            0|            0|  0.00%|
   800|         0|            0|            0|  0.00%|        .. versionchanged:: 3.2
   801|         0|            0|            0|  0.00%|
   802|         0|            0|            0|  0.00%|           Allow filters to be just callables.
   803|         0|            0|            0|  0.00%|        """
   804|         0|            0|            0|  0.00%|        rv = True
   805|         0|            0|            0|  0.00%|        for f in self.filters:
   806|         0|            0|            0|  0.00%|            if hasattr(f, 'filter'):
   807|         0|            0|            0|  0.00%|                result = f.filter(record)
   808|         0|            0|            0|  0.00%|            else:
   809|         0|            0|            0|  0.00%|                result = f(record) # assume callable - will raise if not
   810|         0|            0|            0|  0.00%|            if not result:
   811|         0|            0|            0|  0.00%|                rv = False
   812|         0|            0|            0|  0.00%|                break
   813|         0|            0|            0|  0.00%|        return rv
   814|         0|            0|            0|  0.00%|
   815|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
   816|         0|            0|            0|  0.00%|#   Handler classes and functions
   817|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
   818|         0|            0|            0|  0.00%|
   819|         0|            0|            0|  0.00%|_handlers = weakref.WeakValueDictionary()  #map of handler names to handlers
   820|         0|            0|            0|  0.00%|_handlerList = [] # added to allow handlers to be removed in reverse of order initialized
   821|         0|            0|            0|  0.00%|
   822|         0|            0|            0|  0.00%|def _removeHandlerRef(wr):
   823|         0|            0|            0|  0.00%|    """
   824|         0|            0|            0|  0.00%|    Remove a handler reference from the internal cleanup list.
   825|         0|            0|            0|  0.00%|    """
   826|         0|            0|            0|  0.00%|    # This function can be called during module teardown, when globals are
   827|         0|            0|            0|  0.00%|    # set to None. It can also be called from another thread. So we need to
   828|         0|            0|            0|  0.00%|    # pre-emptively grab the necessary globals and check if they're None,
   829|         0|            0|            0|  0.00%|    # to prevent race conditions and failures during interpreter shutdown.
   830|         0|            0|            0|  0.00%|    acquire, release, handlers = _acquireLock, _releaseLock, _handlerList
   831|         0|            0|            0|  0.00%|    if acquire and release and handlers:
   832|         0|            0|            0|  0.00%|        acquire()
   833|         0|            0|            0|  0.00%|        try:
   834|         0|            0|            0|  0.00%|            if wr in handlers:
   835|         0|            0|            0|  0.00%|                handlers.remove(wr)
   836|         0|            0|            0|  0.00%|        finally:
   837|         0|            0|            0|  0.00%|            release()
   838|         0|            0|            0|  0.00%|
   839|         0|            0|            0|  0.00%|def _addHandlerRef(handler):
   840|         0|            0|            0|  0.00%|    """
   841|         0|            0|            0|  0.00%|    Add a handler to the internal cleanup list using a weak reference.
   842|         0|            0|            0|  0.00%|    """
   843|         0|            0|            0|  0.00%|    _acquireLock()
   844|         0|            0|            0|  0.00%|    try:
   845|         0|            0|            0|  0.00%|        _handlerList.append(weakref.ref(handler, _removeHandlerRef))
   846|         0|            0|            0|  0.00%|    finally:
   847|         0|            0|            0|  0.00%|        _releaseLock()
   848|         0|            0|            0|  0.00%|
   849|         0|            0|            0|  0.00%|class Handler(Filterer):
   850|         0|            0|            0|  0.00%|    """
   851|         0|            0|            0|  0.00%|    Handler instances dispatch logging events to specific destinations.
   852|         0|            0|            0|  0.00%|
   853|         0|            0|            0|  0.00%|    The base handler class. Acts as a placeholder which defines the Handler
   854|         0|            0|            0|  0.00%|    interface. Handlers can optionally use Formatter instances to format
   855|         0|            0|            0|  0.00%|    records as desired. By default, no formatter is specified; in this case,
   856|         0|            0|            0|  0.00%|    the 'raw' message as determined by record.message is logged.
   857|         0|            0|            0|  0.00%|    """
   858|         0|            0|            0|  0.00%|    def __init__(self, level=NOTSET):
   859|         0|            0|            0|  0.00%|        """
   860|         0|            0|            0|  0.00%|        Initializes the instance - basically setting the formatter to None
   861|         0|            0|            0|  0.00%|        and the filter list to empty.
   862|         0|            0|            0|  0.00%|        """
   863|         0|            0|            0|  0.00%|        Filterer.__init__(self)
   864|         0|            0|            0|  0.00%|        self._name = None
   865|         0|            0|            0|  0.00%|        self.level = _checkLevel(level)
   866|         0|            0|            0|  0.00%|        self.formatter = None
   867|         0|            0|            0|  0.00%|        # Add the handler to the global _handlerList (for cleanup on shutdown)
   868|         0|            0|            0|  0.00%|        _addHandlerRef(self)
   869|         0|            0|            0|  0.00%|        self.createLock()
   870|         0|            0|            0|  0.00%|
   871|         0|            0|            0|  0.00%|    def get_name(self):
   872|         0|            0|            0|  0.00%|        return self._name
   873|         0|            0|            0|  0.00%|
   874|         0|            0|            0|  0.00%|    def set_name(self, name):
   875|         0|            0|            0|  0.00%|        _acquireLock()
   876|         0|            0|            0|  0.00%|        try:
   877|         0|            0|            0|  0.00%|            if self._name in _handlers:
   878|         0|            0|            0|  0.00%|                del _handlers[self._name]
   879|         0|            0|            0|  0.00%|            self._name = name
   880|         0|            0|            0|  0.00%|            if name:
   881|         0|            0|            0|  0.00%|                _handlers[name] = self
   882|         0|            0|            0|  0.00%|        finally:
   883|         0|            0|            0|  0.00%|            _releaseLock()
   884|         0|            0|            0|  0.00%|
   885|         0|            0|            0|  0.00%|    name = property(get_name, set_name)
   886|         0|            0|            0|  0.00%|
   887|         0|            0|            0|  0.00%|    def createLock(self):
   888|         0|            0|            0|  0.00%|        """
   889|         0|            0|            0|  0.00%|        Acquire a thread lock for serializing access to the underlying I/O.
   890|         0|            0|            0|  0.00%|        """
   891|         0|            0|            0|  0.00%|        self.lock = threading.RLock()
   892|         0|            0|            0|  0.00%|        _register_at_fork_reinit_lock(self)
   893|         0|            0|            0|  0.00%|
   894|         0|            0|            0|  0.00%|    def acquire(self):
   895|         0|            0|            0|  0.00%|        """
   896|         0|            0|            0|  0.00%|        Acquire the I/O thread lock.
   897|         0|            0|            0|  0.00%|        """
   898|         0|            0|            0|  0.00%|        if self.lock:
   899|         0|            0|            0|  0.00%|            self.lock.acquire()
   900|         0|            0|            0|  0.00%|
   901|         0|            0|            0|  0.00%|    def release(self):
   902|         0|            0|            0|  0.00%|        """
   903|         0|            0|            0|  0.00%|        Release the I/O thread lock.
   904|         0|            0|            0|  0.00%|        """
   905|         0|            0|            0|  0.00%|        if self.lock:
   906|         0|            0|            0|  0.00%|            self.lock.release()
   907|         0|            0|            0|  0.00%|
   908|         0|            0|            0|  0.00%|    def setLevel(self, level):
   909|         0|            0|            0|  0.00%|        """
   910|         0|            0|            0|  0.00%|        Set the logging level of this handler.  level must be an int or a str.
   911|         0|            0|            0|  0.00%|        """
   912|         0|            0|            0|  0.00%|        self.level = _checkLevel(level)
   913|         0|            0|            0|  0.00%|
   914|         0|            0|            0|  0.00%|    def format(self, record):
   915|         0|            0|            0|  0.00%|        """
   916|         0|            0|            0|  0.00%|        Format the specified record.
   917|         0|            0|            0|  0.00%|
   918|         0|            0|            0|  0.00%|        If a formatter is set, use it. Otherwise, use the default formatter
   919|         0|            0|            0|  0.00%|        for the module.
   920|         0|            0|            0|  0.00%|        """
   921|         0|            0|            0|  0.00%|        if self.formatter:
   922|         0|            0|            0|  0.00%|            fmt = self.formatter
   923|         0|            0|            0|  0.00%|        else:
   924|         0|            0|            0|  0.00%|            fmt = _defaultFormatter
   925|         0|            0|            0|  0.00%|        return fmt.format(record)
   926|         0|            0|            0|  0.00%|
   927|         0|            0|            0|  0.00%|    def emit(self, record):
   928|         0|            0|            0|  0.00%|        """
   929|         0|            0|            0|  0.00%|        Do whatever it takes to actually log the specified logging record.
   930|         0|            0|            0|  0.00%|
   931|         0|            0|            0|  0.00%|        This version is intended to be implemented by subclasses and so
   932|         0|            0|            0|  0.00%|        raises a NotImplementedError.
   933|         0|            0|            0|  0.00%|        """
   934|         0|            0|            0|  0.00%|        raise NotImplementedError('emit must be implemented '
   935|         0|            0|            0|  0.00%|                                  'by Handler subclasses')
   936|         0|            0|            0|  0.00%|
   937|         0|            0|            0|  0.00%|    def handle(self, record):
   938|         0|            0|            0|  0.00%|        """
   939|         0|            0|            0|  0.00%|        Conditionally emit the specified logging record.
   940|         0|            0|            0|  0.00%|
   941|         0|            0|            0|  0.00%|        Emission depends on filters which may have been added to the handler.
   942|         0|            0|            0|  0.00%|        Wrap the actual emission of the record with acquisition/release of
   943|         0|            0|            0|  0.00%|        the I/O thread lock. Returns whether the filter passed the record for
   944|         0|            0|            0|  0.00%|        emission.
   945|         0|            0|            0|  0.00%|        """
   946|         0|            0|            0|  0.00%|        rv = self.filter(record)
   947|         0|            0|            0|  0.00%|        if rv:
   948|         0|            0|            0|  0.00%|            self.acquire()
   949|         0|            0|            0|  0.00%|            try:
   950|         0|            0|            0|  0.00%|                self.emit(record)
   951|         0|            0|            0|  0.00%|            finally:
   952|         0|            0|            0|  0.00%|                self.release()
   953|         0|            0|            0|  0.00%|        return rv
   954|         0|            0|            0|  0.00%|
   955|         0|            0|            0|  0.00%|    def setFormatter(self, fmt):
   956|         0|            0|            0|  0.00%|        """
   957|         0|            0|            0|  0.00%|        Set the formatter for this handler.
   958|         0|            0|            0|  0.00%|        """
   959|         0|            0|            0|  0.00%|        self.formatter = fmt
   960|         0|            0|            0|  0.00%|
   961|         0|            0|            0|  0.00%|    def flush(self):
   962|         0|            0|            0|  0.00%|        """
   963|         0|            0|            0|  0.00%|        Ensure all logging output has been flushed.
   964|         0|            0|            0|  0.00%|
   965|         0|            0|            0|  0.00%|        This version does nothing and is intended to be implemented by
   966|         0|            0|            0|  0.00%|        subclasses.
   967|         0|            0|            0|  0.00%|        """
   968|         0|            0|            0|  0.00%|        pass
   969|         0|            0|            0|  0.00%|
   970|         0|            0|            0|  0.00%|    def close(self):
   971|         0|            0|            0|  0.00%|        """
   972|         0|            0|            0|  0.00%|        Tidy up any resources used by the handler.
   973|         0|            0|            0|  0.00%|
   974|         0|            0|            0|  0.00%|        This version removes the handler from an internal map of handlers,
   975|         0|            0|            0|  0.00%|        _handlers, which is used for handler lookup by name. Subclasses
   976|         0|            0|            0|  0.00%|        should ensure that this gets called from overridden close()
   977|         0|            0|            0|  0.00%|        methods.
   978|         0|            0|            0|  0.00%|        """
   979|         0|            0|            0|  0.00%|        #get the module data lock, as we're updating a shared structure.
   980|         0|            0|            0|  0.00%|        _acquireLock()
   981|         0|            0|            0|  0.00%|        try:    #unlikely to raise an exception, but you never know...
   982|         0|            0|            0|  0.00%|            if self._name and self._name in _handlers:
   983|         0|            0|            0|  0.00%|                del _handlers[self._name]
   984|         0|            0|            0|  0.00%|        finally:
   985|         0|            0|            0|  0.00%|            _releaseLock()
   986|         0|            0|            0|  0.00%|
   987|         0|            0|            0|  0.00%|    def handleError(self, record):
   988|         0|            0|            0|  0.00%|        """
   989|         0|            0|            0|  0.00%|        Handle errors which occur during an emit() call.
   990|         0|            0|            0|  0.00%|
   991|         0|            0|            0|  0.00%|        This method should be called from handlers when an exception is
   992|         0|            0|            0|  0.00%|        encountered during an emit() call. If raiseExceptions is false,
   993|         0|            0|            0|  0.00%|        exceptions get silently ignored. This is what is mostly wanted
   994|         0|            0|            0|  0.00%|        for a logging system - most users will not care about errors in
   995|         0|            0|            0|  0.00%|        the logging system, they are more interested in application errors.
   996|         0|            0|            0|  0.00%|        You could, however, replace this with a custom handler if you wish.
   997|         0|            0|            0|  0.00%|        The record which was being processed is passed in to this method.
   998|         0|            0|            0|  0.00%|        """
   999|         0|            0|            0|  0.00%|        if raiseExceptions and sys.stderr:  # see issue 13807
  1000|         0|            0|            0|  0.00%|            t, v, tb = sys.exc_info()
  1001|         0|            0|            0|  0.00%|            try:
  1002|         0|            0|            0|  0.00%|                sys.stderr.write('--- Logging error ---\n')
  1003|         0|            0|            0|  0.00%|                traceback.print_exception(t, v, tb, None, sys.stderr)
  1004|         0|            0|            0|  0.00%|                sys.stderr.write('Call stack:\n')
  1005|         0|            0|            0|  0.00%|                # Walk the stack frame up until we're out of logging,
  1006|         0|            0|            0|  0.00%|                # so as to print the calling context.
  1007|         0|            0|            0|  0.00%|                frame = tb.tb_frame
  1008|         0|            0|            0|  0.00%|                while (frame and os.path.dirname(frame.f_code.co_filename) ==
  1009|         0|            0|            0|  0.00%|                       __path__[0]):
  1010|         0|            0|            0|  0.00%|                    frame = frame.f_back
  1011|         0|            0|            0|  0.00%|                if frame:
  1012|         0|            0|            0|  0.00%|                    traceback.print_stack(frame, file=sys.stderr)
  1013|         0|            0|            0|  0.00%|                else:
  1014|         0|            0|            0|  0.00%|                    # couldn't find the right stack frame, for some reason
  1015|         0|            0|            0|  0.00%|                    sys.stderr.write('Logged from file %s, line %s\n' % (
  1016|         0|            0|            0|  0.00%|                                     record.filename, record.lineno))
  1017|         0|            0|            0|  0.00%|                # Issue 18671: output logging message and arguments
  1018|         0|            0|            0|  0.00%|                try:
  1019|         0|            0|            0|  0.00%|                    sys.stderr.write('Message: %r\n'
  1020|         0|            0|            0|  0.00%|                                     'Arguments: %s\n' % (record.msg,
  1021|         0|            0|            0|  0.00%|                                                          record.args))
  1022|         0|            0|            0|  0.00%|                except RecursionError:  # See issue 36272
  1023|         0|            0|            0|  0.00%|                    raise
  1024|         0|            0|            0|  0.00%|                except Exception:
  1025|         0|            0|            0|  0.00%|                    sys.stderr.write('Unable to print the message and arguments'
  1026|         0|            0|            0|  0.00%|                                     ' - possible formatting error.\nUse the'
  1027|         0|            0|            0|  0.00%|                                     ' traceback above to help find the error.\n'
  1028|         0|            0|            0|  0.00%|                                    )
  1029|         0|            0|            0|  0.00%|            except OSError: #pragma: no cover
  1030|         0|            0|            0|  0.00%|                pass    # see issue 5971
  1031|         0|            0|            0|  0.00%|            finally:
  1032|         0|            0|            0|  0.00%|                del t, v, tb
  1033|         0|            0|            0|  0.00%|
  1034|         0|            0|            0|  0.00%|    def __repr__(self):
  1035|         0|            0|            0|  0.00%|        level = getLevelName(self.level)
  1036|         0|            0|            0|  0.00%|        return '<%s (%s)>' % (self.__class__.__name__, level)
  1037|         0|            0|            0|  0.00%|
  1038|         0|            0|            0|  0.00%|class StreamHandler(Handler):
  1039|         0|            0|            0|  0.00%|    """
  1040|         0|            0|            0|  0.00%|    A handler class which writes logging records, appropriately formatted,
  1041|         0|            0|            0|  0.00%|    to a stream. Note that this class does not close the stream, as
  1042|         0|            0|            0|  0.00%|    sys.stdout or sys.stderr may be used.
  1043|         0|            0|            0|  0.00%|    """
  1044|         0|            0|            0|  0.00%|
  1045|         0|            0|            0|  0.00%|    terminator = '\n'
  1046|         0|            0|            0|  0.00%|
  1047|         0|            0|            0|  0.00%|    def __init__(self, stream=None):
  1048|         0|            0|            0|  0.00%|        """
  1049|         0|            0|            0|  0.00%|        Initialize the handler.
  1050|         0|            0|            0|  0.00%|
  1051|         0|            0|            0|  0.00%|        If stream is not specified, sys.stderr is used.
  1052|         0|            0|            0|  0.00%|        """
  1053|         0|            0|            0|  0.00%|        Handler.__init__(self)
  1054|         0|            0|            0|  0.00%|        if stream is None:
  1055|         0|            0|            0|  0.00%|            stream = sys.stderr
  1056|         0|            0|            0|  0.00%|        self.stream = stream
  1057|         0|            0|            0|  0.00%|
  1058|         0|            0|            0|  0.00%|    def flush(self):
  1059|         0|            0|            0|  0.00%|        """
  1060|         0|            0|            0|  0.00%|        Flushes the stream.
  1061|         0|            0|            0|  0.00%|        """
  1062|         0|            0|            0|  0.00%|        self.acquire()
  1063|         0|            0|            0|  0.00%|        try:
  1064|         0|            0|            0|  0.00%|            if self.stream and hasattr(self.stream, "flush"):
  1065|         0|            0|            0|  0.00%|                self.stream.flush()
  1066|         0|            0|            0|  0.00%|        finally:
  1067|         0|            0|            0|  0.00%|            self.release()
  1068|         0|            0|            0|  0.00%|
  1069|         0|            0|            0|  0.00%|    def emit(self, record):
  1070|         0|            0|            0|  0.00%|        """
  1071|         0|            0|            0|  0.00%|        Emit a record.
  1072|         0|            0|            0|  0.00%|
  1073|         0|            0|            0|  0.00%|        If a formatter is specified, it is used to format the record.
  1074|         0|            0|            0|  0.00%|        The record is then written to the stream with a trailing newline.  If
  1075|         0|            0|            0|  0.00%|        exception information is present, it is formatted using
  1076|         0|            0|            0|  0.00%|        traceback.print_exception and appended to the stream.  If the stream
  1077|         0|            0|            0|  0.00%|        has an 'encoding' attribute, it is used to determine how to do the
  1078|         0|            0|            0|  0.00%|        output to the stream.
  1079|         0|            0|            0|  0.00%|        """
  1080|         0|            0|            0|  0.00%|        try:
  1081|         0|            0|            0|  0.00%|            msg = self.format(record)
  1082|         0|            0|            0|  0.00%|            stream = self.stream
  1083|         0|            0|            0|  0.00%|            # issue 35046: merged two stream.writes into one.
  1084|         0|            0|            0|  0.00%|            stream.write(msg + self.terminator)
  1085|         0|            0|            0|  0.00%|            self.flush()
  1086|         0|            0|            0|  0.00%|        except RecursionError:  # See issue 36272
  1087|         0|            0|            0|  0.00%|            raise
  1088|         0|            0|            0|  0.00%|        except Exception:
  1089|         0|            0|            0|  0.00%|            self.handleError(record)
  1090|         0|            0|            0|  0.00%|
  1091|         0|            0|            0|  0.00%|    def setStream(self, stream):
  1092|         0|            0|            0|  0.00%|        """
  1093|         0|            0|            0|  0.00%|        Sets the StreamHandler's stream to the specified value,
  1094|         0|            0|            0|  0.00%|        if it is different.
  1095|         0|            0|            0|  0.00%|
  1096|         0|            0|            0|  0.00%|        Returns the old stream, if the stream was changed, or None
  1097|         0|            0|            0|  0.00%|        if it wasn't.
  1098|         0|            0|            0|  0.00%|        """
  1099|         0|            0|            0|  0.00%|        if stream is self.stream:
  1100|         0|            0|            0|  0.00%|            result = None
  1101|         0|            0|            0|  0.00%|        else:
  1102|         0|            0|            0|  0.00%|            result = self.stream
  1103|         0|            0|            0|  0.00%|            self.acquire()
  1104|         0|            0|            0|  0.00%|            try:
  1105|         0|            0|            0|  0.00%|                self.flush()
  1106|         0|            0|            0|  0.00%|                self.stream = stream
  1107|         0|            0|            0|  0.00%|            finally:
  1108|         0|            0|            0|  0.00%|                self.release()
  1109|         0|            0|            0|  0.00%|        return result
  1110|         0|            0|            0|  0.00%|
  1111|         0|            0|            0|  0.00%|    def __repr__(self):
  1112|         0|            0|            0|  0.00%|        level = getLevelName(self.level)
  1113|         0|            0|            0|  0.00%|        name = getattr(self.stream, 'name', '')
  1114|         0|            0|            0|  0.00%|        #  bpo-36015: name can be an int
  1115|         0|            0|            0|  0.00%|        name = str(name)
  1116|         0|            0|            0|  0.00%|        if name:
  1117|         0|            0|            0|  0.00%|            name += ' '
  1118|         0|            0|            0|  0.00%|        return '<%s %s(%s)>' % (self.__class__.__name__, name, level)
  1119|         0|            0|            0|  0.00%|
  1120|         0|            0|            0|  0.00%|
  1121|         0|            0|            0|  0.00%|class FileHandler(StreamHandler):
  1122|         0|            0|            0|  0.00%|    """
  1123|         0|            0|            0|  0.00%|    A handler class which writes formatted logging records to disk files.
  1124|         0|            0|            0|  0.00%|    """
  1125|         0|            0|            0|  0.00%|    def __init__(self, filename, mode='a', encoding=None, delay=False):
  1126|         0|            0|            0|  0.00%|        """
  1127|         0|            0|            0|  0.00%|        Open the specified file and use it as the stream for logging.
  1128|         0|            0|            0|  0.00%|        """
  1129|         0|            0|            0|  0.00%|        # Issue #27493: add support for Path objects to be passed in
  1130|         0|            0|            0|  0.00%|        filename = os.fspath(filename)
  1131|         0|            0|            0|  0.00%|        #keep the absolute path, otherwise derived classes which use this
  1132|         0|            0|            0|  0.00%|        #may come a cropper when the current directory changes
  1133|         0|            0|            0|  0.00%|        self.baseFilename = os.path.abspath(filename)
  1134|         0|            0|            0|  0.00%|        self.mode = mode
  1135|         0|            0|            0|  0.00%|        self.encoding = encoding
  1136|         0|            0|            0|  0.00%|        self.delay = delay
  1137|         0|            0|            0|  0.00%|        if delay:
  1138|         0|            0|            0|  0.00%|            #We don't open the stream, but we still need to call the
  1139|         0|            0|            0|  0.00%|            #Handler constructor to set level, formatter, lock etc.
  1140|         0|            0|            0|  0.00%|            Handler.__init__(self)
  1141|         0|            0|            0|  0.00%|            self.stream = None
  1142|         0|            0|            0|  0.00%|        else:
  1143|         0|            0|            0|  0.00%|            StreamHandler.__init__(self, self._open())
  1144|         0|            0|            0|  0.00%|
  1145|         0|            0|            0|  0.00%|    def close(self):
  1146|         0|            0|            0|  0.00%|        """
  1147|         0|            0|            0|  0.00%|        Closes the stream.
  1148|         0|            0|            0|  0.00%|        """
  1149|         0|            0|            0|  0.00%|        self.acquire()
  1150|         0|            0|            0|  0.00%|        try:
  1151|         0|            0|            0|  0.00%|            try:
  1152|         0|            0|            0|  0.00%|                if self.stream:
  1153|         0|            0|            0|  0.00%|                    try:
  1154|         0|            0|            0|  0.00%|                        self.flush()
  1155|         0|            0|            0|  0.00%|                    finally:
  1156|         0|            0|            0|  0.00%|                        stream = self.stream
  1157|         0|            0|            0|  0.00%|                        self.stream = None
  1158|         0|            0|            0|  0.00%|                        if hasattr(stream, "close"):
  1159|         0|            0|            0|  0.00%|                            stream.close()
  1160|         0|            0|            0|  0.00%|            finally:
  1161|         0|            0|            0|  0.00%|                # Issue #19523: call unconditionally to
  1162|         0|            0|            0|  0.00%|                # prevent a handler leak when delay is set
  1163|         0|            0|            0|  0.00%|                StreamHandler.close(self)
  1164|         0|            0|            0|  0.00%|        finally:
  1165|         0|            0|            0|  0.00%|            self.release()
  1166|         0|            0|            0|  0.00%|
  1167|         0|            0|            0|  0.00%|    def _open(self):
  1168|         0|            0|            0|  0.00%|        """
  1169|         0|            0|            0|  0.00%|        Open the current base file with the (original) mode and encoding.
  1170|         0|            0|            0|  0.00%|        Return the resulting stream.
  1171|         0|            0|            0|  0.00%|        """
  1172|         0|            0|            0|  0.00%|        return open(self.baseFilename, self.mode, encoding=self.encoding)
  1173|         0|            0|            0|  0.00%|
  1174|         0|            0|            0|  0.00%|    def emit(self, record):
  1175|         0|            0|            0|  0.00%|        """
  1176|         0|            0|            0|  0.00%|        Emit a record.
  1177|         0|            0|            0|  0.00%|
  1178|         0|            0|            0|  0.00%|        If the stream was not opened because 'delay' was specified in the
  1179|         0|            0|            0|  0.00%|        constructor, open it before calling the superclass's emit.
  1180|         0|            0|            0|  0.00%|        """
  1181|         0|            0|            0|  0.00%|        if self.stream is None:
  1182|         0|            0|            0|  0.00%|            self.stream = self._open()
  1183|         0|            0|            0|  0.00%|        StreamHandler.emit(self, record)
  1184|         0|            0|            0|  0.00%|
  1185|         0|            0|            0|  0.00%|    def __repr__(self):
  1186|         0|            0|            0|  0.00%|        level = getLevelName(self.level)
  1187|         0|            0|            0|  0.00%|        return '<%s %s (%s)>' % (self.__class__.__name__, self.baseFilename, level)
  1188|         0|            0|            0|  0.00%|
  1189|         0|            0|            0|  0.00%|
  1190|         0|            0|            0|  0.00%|class _StderrHandler(StreamHandler):
  1191|         0|            0|            0|  0.00%|    """
  1192|         0|            0|            0|  0.00%|    This class is like a StreamHandler using sys.stderr, but always uses
  1193|         0|            0|            0|  0.00%|    whatever sys.stderr is currently set to rather than the value of
  1194|         0|            0|            0|  0.00%|    sys.stderr at handler construction time.
  1195|         0|            0|            0|  0.00%|    """
  1196|         0|            0|            0|  0.00%|    def __init__(self, level=NOTSET):
  1197|         0|            0|            0|  0.00%|        """
  1198|         0|            0|            0|  0.00%|        Initialize the handler.
  1199|         0|            0|            0|  0.00%|        """
  1200|         0|            0|            0|  0.00%|        Handler.__init__(self, level)
  1201|         0|            0|            0|  0.00%|
  1202|         0|            0|            0|  0.00%|    @property
  1203|         0|            0|            0|  0.00%|    def stream(self):
  1204|         0|            0|            0|  0.00%|        return sys.stderr
  1205|         0|            0|            0|  0.00%|
  1206|         0|            0|            0|  0.00%|
  1207|         0|            0|            0|  0.00%|_defaultLastResort = _StderrHandler(WARNING)
  1208|         0|            0|            0|  0.00%|lastResort = _defaultLastResort
  1209|         0|            0|            0|  0.00%|
  1210|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
  1211|         0|            0|            0|  0.00%|#   Manager classes and functions
  1212|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
  1213|         0|            0|            0|  0.00%|
  1214|         0|            0|            0|  0.00%|class PlaceHolder(object):
  1215|         0|            0|            0|  0.00%|    """
  1216|         0|            0|            0|  0.00%|    PlaceHolder instances are used in the Manager logger hierarchy to take
  1217|         0|            0|            0|  0.00%|    the place of nodes for which no loggers have been defined. This class is
  1218|         0|            0|            0|  0.00%|    intended for internal use only and not as part of the public API.
  1219|         0|            0|            0|  0.00%|    """
  1220|         0|            0|            0|  0.00%|    def __init__(self, alogger):
  1221|         0|            0|            0|  0.00%|        """
  1222|         0|            0|            0|  0.00%|        Initialize with the specified logger being a child of this placeholder.
  1223|         0|            0|            0|  0.00%|        """
  1224|         0|            0|            0|  0.00%|        self.loggerMap = { alogger : None }
  1225|         0|            0|            0|  0.00%|
  1226|         0|            0|            0|  0.00%|    def append(self, alogger):
  1227|         0|            0|            0|  0.00%|        """
  1228|         0|            0|            0|  0.00%|        Add the specified logger as a child of this placeholder.
  1229|         0|            0|            0|  0.00%|        """
  1230|         0|            0|            0|  0.00%|        if alogger not in self.loggerMap:
  1231|         0|            0|            0|  0.00%|            self.loggerMap[alogger] = None
  1232|         0|            0|            0|  0.00%|
  1233|         0|            0|            0|  0.00%|#
  1234|         0|            0|            0|  0.00%|#   Determine which class to use when instantiating loggers.
  1235|         0|            0|            0|  0.00%|#
  1236|         0|            0|            0|  0.00%|
  1237|         0|            0|            0|  0.00%|def setLoggerClass(klass):
  1238|         0|            0|            0|  0.00%|    """
  1239|         0|            0|            0|  0.00%|    Set the class to be used when instantiating a logger. The class should
  1240|         0|            0|            0|  0.00%|    define __init__() such that only a name argument is required, and the
  1241|         0|            0|            0|  0.00%|    __init__() should call Logger.__init__()
  1242|         0|            0|            0|  0.00%|    """
  1243|         0|            0|            0|  0.00%|    if klass != Logger:
  1244|         0|            0|            0|  0.00%|        if not issubclass(klass, Logger):
  1245|         0|            0|            0|  0.00%|            raise TypeError("logger not derived from logging.Logger: "
  1246|         0|            0|            0|  0.00%|                            + klass.__name__)
  1247|         0|            0|            0|  0.00%|    global _loggerClass
  1248|         0|            0|            0|  0.00%|    _loggerClass = klass
  1249|         0|            0|            0|  0.00%|
  1250|         0|            0|            0|  0.00%|def getLoggerClass():
  1251|         0|            0|            0|  0.00%|    """
  1252|         0|            0|            0|  0.00%|    Return the class to be used when instantiating a logger.
  1253|         0|            0|            0|  0.00%|    """
  1254|         0|            0|            0|  0.00%|    return _loggerClass
  1255|         0|            0|            0|  0.00%|
  1256|         0|            0|            0|  0.00%|class Manager(object):
  1257|         0|            0|            0|  0.00%|    """
  1258|         0|            0|            0|  0.00%|    There is [under normal circumstances] just one Manager instance, which
  1259|         0|            0|            0|  0.00%|    holds the hierarchy of loggers.
  1260|         0|            0|            0|  0.00%|    """
  1261|         0|            0|            0|  0.00%|    def __init__(self, rootnode):
  1262|         0|            0|            0|  0.00%|        """
  1263|         0|            0|            0|  0.00%|        Initialize the manager with the root node of the logger hierarchy.
  1264|         0|            0|            0|  0.00%|        """
  1265|         0|            0|            0|  0.00%|        self.root = rootnode
  1266|         0|            0|            0|  0.00%|        self.disable = 0
  1267|         0|            0|            0|  0.00%|        self.emittedNoHandlerWarning = False
  1268|         0|            0|            0|  0.00%|        self.loggerDict = {}
  1269|         0|            0|            0|  0.00%|        self.loggerClass = None
  1270|         0|            0|            0|  0.00%|        self.logRecordFactory = None
  1271|         0|            0|            0|  0.00%|
  1272|         0|            0|            0|  0.00%|    def getLogger(self, name):
  1273|         0|            0|            0|  0.00%|        """
  1274|         0|            0|            0|  0.00%|        Get a logger with the specified name (channel name), creating it
  1275|         0|            0|            0|  0.00%|        if it doesn't yet exist. This name is a dot-separated hierarchical
  1276|         0|            0|            0|  0.00%|        name, such as "a", "a.b", "a.b.c" or similar.
  1277|         0|            0|            0|  0.00%|
  1278|         0|            0|            0|  0.00%|        If a PlaceHolder existed for the specified name [i.e. the logger
  1279|         0|            0|            0|  0.00%|        didn't exist but a child of it did], replace it with the created
  1280|         0|            0|            0|  0.00%|        logger and fix up the parent/child references which pointed to the
  1281|         0|            0|            0|  0.00%|        placeholder to now point to the logger.
  1282|         0|            0|            0|  0.00%|        """
  1283|         0|            0|            0|  0.00%|        rv = None
  1284|         0|            0|            0|  0.00%|        if not isinstance(name, str):
  1285|         0|            0|            0|  0.00%|            raise TypeError('A logger name must be a string')
  1286|         0|            0|            0|  0.00%|        _acquireLock()
  1287|         0|            0|            0|  0.00%|        try:
  1288|         0|            0|            0|  0.00%|            if name in self.loggerDict:
  1289|         0|            0|            0|  0.00%|                rv = self.loggerDict[name]
  1290|         0|            0|            0|  0.00%|                if isinstance(rv, PlaceHolder):
  1291|         0|            0|            0|  0.00%|                    ph = rv
  1292|         0|            0|            0|  0.00%|                    rv = (self.loggerClass or _loggerClass)(name)
  1293|         0|            0|            0|  0.00%|                    rv.manager = self
  1294|         0|            0|            0|  0.00%|                    self.loggerDict[name] = rv
  1295|         0|            0|            0|  0.00%|                    self._fixupChildren(ph, rv)
  1296|         0|            0|            0|  0.00%|                    self._fixupParents(rv)
  1297|         0|            0|            0|  0.00%|            else:
  1298|         0|            0|            0|  0.00%|                rv = (self.loggerClass or _loggerClass)(name)
  1299|         0|            0|            0|  0.00%|                rv.manager = self
  1300|         0|            0|            0|  0.00%|                self.loggerDict[name] = rv
  1301|         0|            0|            0|  0.00%|                self._fixupParents(rv)
  1302|         0|            0|            0|  0.00%|        finally:
  1303|         0|            0|            0|  0.00%|            _releaseLock()
  1304|         0|            0|            0|  0.00%|        return rv
  1305|         0|            0|            0|  0.00%|
  1306|         0|            0|            0|  0.00%|    def setLoggerClass(self, klass):
  1307|         0|            0|            0|  0.00%|        """
  1308|         0|            0|            0|  0.00%|        Set the class to be used when instantiating a logger with this Manager.
  1309|         0|            0|            0|  0.00%|        """
  1310|         0|            0|            0|  0.00%|        if klass != Logger:
  1311|         0|            0|            0|  0.00%|            if not issubclass(klass, Logger):
  1312|         0|            0|            0|  0.00%|                raise TypeError("logger not derived from logging.Logger: "
  1313|         0|            0|            0|  0.00%|                                + klass.__name__)
  1314|         0|            0|            0|  0.00%|        self.loggerClass = klass
  1315|         0|            0|            0|  0.00%|
  1316|         0|            0|            0|  0.00%|    def setLogRecordFactory(self, factory):
  1317|         0|            0|            0|  0.00%|        """
  1318|         0|            0|            0|  0.00%|        Set the factory to be used when instantiating a log record with this
  1319|         0|            0|            0|  0.00%|        Manager.
  1320|         0|            0|            0|  0.00%|        """
  1321|         0|            0|            0|  0.00%|        self.logRecordFactory = factory
  1322|         0|            0|            0|  0.00%|
  1323|         0|            0|            0|  0.00%|    def _fixupParents(self, alogger):
  1324|         0|            0|            0|  0.00%|        """
  1325|         0|            0|            0|  0.00%|        Ensure that there are either loggers or placeholders all the way
  1326|         0|            0|            0|  0.00%|        from the specified logger to the root of the logger hierarchy.
  1327|         0|            0|            0|  0.00%|        """
  1328|         0|            0|            0|  0.00%|        name = alogger.name
  1329|         0|            0|            0|  0.00%|        i = name.rfind(".")
  1330|         0|            0|            0|  0.00%|        rv = None
  1331|         0|            0|            0|  0.00%|        while (i > 0) and not rv:
  1332|         0|            0|            0|  0.00%|            substr = name[:i]
  1333|         0|            0|            0|  0.00%|            if substr not in self.loggerDict:
  1334|         0|            0|            0|  0.00%|                self.loggerDict[substr] = PlaceHolder(alogger)
  1335|         0|            0|            0|  0.00%|            else:
  1336|         0|            0|            0|  0.00%|                obj = self.loggerDict[substr]
  1337|         0|            0|            0|  0.00%|                if isinstance(obj, Logger):
  1338|         0|            0|            0|  0.00%|                    rv = obj
  1339|         0|            0|            0|  0.00%|                else:
  1340|         0|            0|            0|  0.00%|                    assert isinstance(obj, PlaceHolder)
  1341|         0|            0|            0|  0.00%|                    obj.append(alogger)
  1342|         0|            0|            0|  0.00%|            i = name.rfind(".", 0, i - 1)
  1343|         0|            0|            0|  0.00%|        if not rv:
  1344|         0|            0|            0|  0.00%|            rv = self.root
  1345|         0|            0|            0|  0.00%|        alogger.parent = rv
  1346|         0|            0|            0|  0.00%|
  1347|         0|            0|            0|  0.00%|    def _fixupChildren(self, ph, alogger):
  1348|         0|            0|            0|  0.00%|        """
  1349|         0|            0|            0|  0.00%|        Ensure that children of the placeholder ph are connected to the
  1350|         0|            0|            0|  0.00%|        specified logger.
  1351|         0|            0|            0|  0.00%|        """
  1352|         0|            0|            0|  0.00%|        name = alogger.name
  1353|         0|            0|            0|  0.00%|        namelen = len(name)
  1354|         0|            0|            0|  0.00%|        for c in ph.loggerMap.keys():
  1355|         0|            0|            0|  0.00%|            #The if means ... if not c.parent.name.startswith(nm)
  1356|         0|            0|            0|  0.00%|            if c.parent.name[:namelen] != name:
  1357|         0|            0|            0|  0.00%|                alogger.parent = c.parent
  1358|         0|            0|            0|  0.00%|                c.parent = alogger
  1359|         0|            0|            0|  0.00%|
  1360|         0|            0|            0|  0.00%|    def _clear_cache(self):
  1361|         0|            0|            0|  0.00%|        """
  1362|         0|            0|            0|  0.00%|        Clear the cache for all loggers in loggerDict
  1363|         0|            0|            0|  0.00%|        Called when level changes are made
  1364|         0|            0|            0|  0.00%|        """
  1365|         0|            0|            0|  0.00%|
  1366|         0|            0|            0|  0.00%|        _acquireLock()
  1367|         0|            0|            0|  0.00%|        for logger in self.loggerDict.values():
  1368|         0|            0|            0|  0.00%|            if isinstance(logger, Logger):
  1369|         0|            0|            0|  0.00%|                logger._cache.clear()
  1370|         0|            0|            0|  0.00%|        self.root._cache.clear()
  1371|         0|            0|            0|  0.00%|        _releaseLock()
  1372|         0|            0|            0|  0.00%|
  1373|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
  1374|         0|            0|            0|  0.00%|#   Logger classes and functions
  1375|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
  1376|         0|            0|            0|  0.00%|
  1377|         0|            0|            0|  0.00%|class Logger(Filterer):
  1378|         0|            0|            0|  0.00%|    """
  1379|         0|            0|            0|  0.00%|    Instances of the Logger class represent a single logging channel. A
  1380|         0|            0|            0|  0.00%|    "logging channel" indicates an area of an application. Exactly how an
  1381|         0|            0|            0|  0.00%|    "area" is defined is up to the application developer. Since an
  1382|         0|            0|            0|  0.00%|    application can have any number of areas, logging channels are identified
  1383|         0|            0|            0|  0.00%|    by a unique string. Application areas can be nested (e.g. an area
  1384|         0|            0|            0|  0.00%|    of "input processing" might include sub-areas "read CSV files", "read
  1385|         0|            0|            0|  0.00%|    XLS files" and "read Gnumeric files"). To cater for this natural nesting,
  1386|         0|            0|            0|  0.00%|    channel names are organized into a namespace hierarchy where levels are
  1387|         0|            0|            0|  0.00%|    separated by periods, much like the Java or Python package namespace. So
  1388|         0|            0|            0|  0.00%|    in the instance given above, channel names might be "input" for the upper
  1389|         0|            0|            0|  0.00%|    level, and "input.csv", "input.xls" and "input.gnu" for the sub-levels.
  1390|         0|            0|            0|  0.00%|    There is no arbitrary limit to the depth of nesting.
  1391|         0|            0|            0|  0.00%|    """
  1392|         0|            0|            0|  0.00%|    def __init__(self, name, level=NOTSET):
  1393|         0|            0|            0|  0.00%|        """
  1394|         0|            0|            0|  0.00%|        Initialize the logger with a name and an optional level.
  1395|         0|            0|            0|  0.00%|        """
  1396|         0|            0|            0|  0.00%|        Filterer.__init__(self)
  1397|         0|            0|            0|  0.00%|        self.name = name
  1398|         0|            0|            0|  0.00%|        self.level = _checkLevel(level)
  1399|         0|            0|            0|  0.00%|        self.parent = None
  1400|         0|            0|            0|  0.00%|        self.propagate = True
  1401|         0|            0|            0|  0.00%|        self.handlers = []
  1402|         0|            0|            0|  0.00%|        self.disabled = False
  1403|         0|            0|            0|  0.00%|        self._cache = {}
  1404|         0|            0|            0|  0.00%|
  1405|         0|            0|            0|  0.00%|    def setLevel(self, level):
  1406|         0|            0|            0|  0.00%|        """
  1407|         0|            0|            0|  0.00%|        Set the logging level of this logger.  level must be an int or a str.
  1408|         0|            0|            0|  0.00%|        """
  1409|         0|            0|            0|  0.00%|        self.level = _checkLevel(level)
  1410|         0|            0|            0|  0.00%|        self.manager._clear_cache()
  1411|         0|            0|            0|  0.00%|
  1412|         0|            0|            0|  0.00%|    def debug(self, msg, *args, **kwargs):
  1413|         0|            0|            0|  0.00%|        """
  1414|         0|            0|            0|  0.00%|        Log 'msg % args' with severity 'DEBUG'.
  1415|         0|            0|            0|  0.00%|
  1416|         0|            0|            0|  0.00%|        To pass exception information, use the keyword argument exc_info with
  1417|         0|            0|            0|  0.00%|        a true value, e.g.
  1418|         0|            0|            0|  0.00%|
  1419|         0|            0|            0|  0.00%|        logger.debug("Houston, we have a %s", "thorny problem", exc_info=1)
  1420|         0|            0|            0|  0.00%|        """
  1421|         0|            0|            0|  0.00%|        if self.isEnabledFor(DEBUG):
  1422|         0|            0|            0|  0.00%|            self._log(DEBUG, msg, args, **kwargs)
  1423|         0|            0|            0|  0.00%|
  1424|         7|  1.64509e-05|  2.35013e-06|  0.00%|    def info(self, msg, *args, **kwargs):
  1425|         0|            0|            0|  0.00%|        """
  1426|         0|            0|            0|  0.00%|        Log 'msg % args' with severity 'INFO'.
  1427|         0|            0|            0|  0.00%|
  1428|         0|            0|            0|  0.00%|        To pass exception information, use the keyword argument exc_info with
  1429|         0|            0|            0|  0.00%|        a true value, e.g.
  1430|         0|            0|            0|  0.00%|
  1431|         0|            0|            0|  0.00%|        logger.info("Houston, we have a %s", "interesting problem", exc_info=1)
  1432|         0|            0|            0|  0.00%|        """
  1433|         7|  5.05447e-05|  7.22068e-06|  0.00%|        if self.isEnabledFor(INFO):
(call)|         7|  5.67436e-05|  8.10623e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/logging/__init__.py:1677 isEnabledFor
  1434|         0|            0|            0|  0.00%|            self._log(INFO, msg, args, **kwargs)
  1435|         0|            0|            0|  0.00%|
  1436|         0|            0|            0|  0.00%|    def warning(self, msg, *args, **kwargs):
  1437|         0|            0|            0|  0.00%|        """
  1438|         0|            0|            0|  0.00%|        Log 'msg % args' with severity 'WARNING'.
  1439|         0|            0|            0|  0.00%|
  1440|         0|            0|            0|  0.00%|        To pass exception information, use the keyword argument exc_info with
  1441|         0|            0|            0|  0.00%|        a true value, e.g.
  1442|         0|            0|            0|  0.00%|
  1443|         0|            0|            0|  0.00%|        logger.warning("Houston, we have a %s", "bit of a problem", exc_info=1)
  1444|         0|            0|            0|  0.00%|        """
  1445|         0|            0|            0|  0.00%|        if self.isEnabledFor(WARNING):
  1446|         0|            0|            0|  0.00%|            self._log(WARNING, msg, args, **kwargs)
  1447|         0|            0|            0|  0.00%|
  1448|         0|            0|            0|  0.00%|    def warn(self, msg, *args, **kwargs):
  1449|         0|            0|            0|  0.00%|        warnings.warn("The 'warn' method is deprecated, "
  1450|         0|            0|            0|  0.00%|            "use 'warning' instead", DeprecationWarning, 2)
  1451|         0|            0|            0|  0.00%|        self.warning(msg, *args, **kwargs)
  1452|         0|            0|            0|  0.00%|
  1453|         0|            0|            0|  0.00%|    def error(self, msg, *args, **kwargs):
  1454|         0|            0|            0|  0.00%|        """
  1455|         0|            0|            0|  0.00%|        Log 'msg % args' with severity 'ERROR'.
  1456|         0|            0|            0|  0.00%|
  1457|         0|            0|            0|  0.00%|        To pass exception information, use the keyword argument exc_info with
  1458|         0|            0|            0|  0.00%|        a true value, e.g.
  1459|         0|            0|            0|  0.00%|
  1460|         0|            0|            0|  0.00%|        logger.error("Houston, we have a %s", "major problem", exc_info=1)
  1461|         0|            0|            0|  0.00%|        """
  1462|         0|            0|            0|  0.00%|        if self.isEnabledFor(ERROR):
  1463|         0|            0|            0|  0.00%|            self._log(ERROR, msg, args, **kwargs)
  1464|         0|            0|            0|  0.00%|
  1465|         0|            0|            0|  0.00%|    def exception(self, msg, *args, exc_info=True, **kwargs):
  1466|         0|            0|            0|  0.00%|        """
  1467|         0|            0|            0|  0.00%|        Convenience method for logging an ERROR with exception information.
  1468|         0|            0|            0|  0.00%|        """
  1469|         0|            0|            0|  0.00%|        self.error(msg, *args, exc_info=exc_info, **kwargs)
  1470|         0|            0|            0|  0.00%|
  1471|         0|            0|            0|  0.00%|    def critical(self, msg, *args, **kwargs):
  1472|         0|            0|            0|  0.00%|        """
  1473|         0|            0|            0|  0.00%|        Log 'msg % args' with severity 'CRITICAL'.
  1474|         0|            0|            0|  0.00%|
  1475|         0|            0|            0|  0.00%|        To pass exception information, use the keyword argument exc_info with
  1476|         0|            0|            0|  0.00%|        a true value, e.g.
  1477|         0|            0|            0|  0.00%|
  1478|         0|            0|            0|  0.00%|        logger.critical("Houston, we have a %s", "major disaster", exc_info=1)
  1479|         0|            0|            0|  0.00%|        """
  1480|         0|            0|            0|  0.00%|        if self.isEnabledFor(CRITICAL):
  1481|         0|            0|            0|  0.00%|            self._log(CRITICAL, msg, args, **kwargs)
  1482|         0|            0|            0|  0.00%|
  1483|         0|            0|            0|  0.00%|    fatal = critical
  1484|         0|            0|            0|  0.00%|
  1485|         1|  5.96046e-06|  5.96046e-06|  0.00%|    def log(self, level, msg, *args, **kwargs):
  1486|         0|            0|            0|  0.00%|        """
  1487|         0|            0|            0|  0.00%|        Log 'msg % args' with the integer severity 'level'.
  1488|         0|            0|            0|  0.00%|
  1489|         0|            0|            0|  0.00%|        To pass exception information, use the keyword argument exc_info with
  1490|         0|            0|            0|  0.00%|        a true value, e.g.
  1491|         0|            0|            0|  0.00%|
  1492|         0|            0|            0|  0.00%|        logger.log(level, "We have a %s", "mysterious problem", exc_info=1)
  1493|         0|            0|            0|  0.00%|        """
  1494|         1|  6.67572e-06|  6.67572e-06|  0.00%|        if not isinstance(level, int):
  1495|         0|            0|            0|  0.00%|            if raiseExceptions:
  1496|         0|            0|            0|  0.00%|                raise TypeError("level must be an integer")
  1497|         0|            0|            0|  0.00%|            else:
  1498|         0|            0|            0|  0.00%|                return
  1499|         1|  1.19209e-05|  1.19209e-05|  0.00%|        if self.isEnabledFor(level):
(call)|         1|  1.38283e-05|  1.38283e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/logging/__init__.py:1677 isEnabledFor
  1500|         0|            0|            0|  0.00%|            self._log(level, msg, args, **kwargs)
  1501|         0|            0|            0|  0.00%|
  1502|         0|            0|            0|  0.00%|    def findCaller(self, stack_info=False, stacklevel=1):
  1503|         0|            0|            0|  0.00%|        """
  1504|         0|            0|            0|  0.00%|        Find the stack frame of the caller so that we can note the source
  1505|         0|            0|            0|  0.00%|        file name, line number and function name.
  1506|         0|            0|            0|  0.00%|        """
  1507|         0|            0|            0|  0.00%|        f = currentframe()
  1508|         0|            0|            0|  0.00%|        #On some versions of IronPython, currentframe() returns None if
  1509|         0|            0|            0|  0.00%|        #IronPython isn't run with -X:Frames.
  1510|         0|            0|            0|  0.00%|        if f is not None:
  1511|         0|            0|            0|  0.00%|            f = f.f_back
  1512|         0|            0|            0|  0.00%|        orig_f = f
  1513|         0|            0|            0|  0.00%|        while f and stacklevel > 1:
  1514|         0|            0|            0|  0.00%|            f = f.f_back
  1515|         0|            0|            0|  0.00%|            stacklevel -= 1
  1516|         0|            0|            0|  0.00%|        if not f:
  1517|         0|            0|            0|  0.00%|            f = orig_f
  1518|         0|            0|            0|  0.00%|        rv = "(unknown file)", 0, "(unknown function)", None
  1519|         0|            0|            0|  0.00%|        while hasattr(f, "f_code"):
  1520|         0|            0|            0|  0.00%|            co = f.f_code
  1521|         0|            0|            0|  0.00%|            filename = os.path.normcase(co.co_filename)
  1522|         0|            0|            0|  0.00%|            if filename == _srcfile:
  1523|         0|            0|            0|  0.00%|                f = f.f_back
  1524|         0|            0|            0|  0.00%|                continue
  1525|         0|            0|            0|  0.00%|            sinfo = None
  1526|         0|            0|            0|  0.00%|            if stack_info:
  1527|         0|            0|            0|  0.00%|                sio = io.StringIO()
  1528|         0|            0|            0|  0.00%|                sio.write('Stack (most recent call last):\n')
  1529|         0|            0|            0|  0.00%|                traceback.print_stack(f, file=sio)
  1530|         0|            0|            0|  0.00%|                sinfo = sio.getvalue()
  1531|         0|            0|            0|  0.00%|                if sinfo[-1] == '\n':
  1532|         0|            0|            0|  0.00%|                    sinfo = sinfo[:-1]
  1533|         0|            0|            0|  0.00%|                sio.close()
  1534|         0|            0|            0|  0.00%|            rv = (co.co_filename, f.f_lineno, co.co_name, sinfo)
  1535|         0|            0|            0|  0.00%|            break
  1536|         0|            0|            0|  0.00%|        return rv
  1537|         0|            0|            0|  0.00%|
  1538|         0|            0|            0|  0.00%|    def makeRecord(self, name, level, fn, lno, msg, args, exc_info,
  1539|         0|            0|            0|  0.00%|                   func=None, extra=None, sinfo=None):
  1540|         0|            0|            0|  0.00%|        """
  1541|         0|            0|            0|  0.00%|        A factory method which can be overridden in subclasses to create
  1542|         0|            0|            0|  0.00%|        specialized LogRecords.
  1543|         0|            0|            0|  0.00%|        """
  1544|         0|            0|            0|  0.00%|        rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,
  1545|         0|            0|            0|  0.00%|                             sinfo)
  1546|         0|            0|            0|  0.00%|        if extra is not None:
  1547|         0|            0|            0|  0.00%|            for key in extra:
  1548|         0|            0|            0|  0.00%|                if (key in ["message", "asctime"]) or (key in rv.__dict__):
  1549|         0|            0|            0|  0.00%|                    raise KeyError("Attempt to overwrite %r in LogRecord" % key)
  1550|         0|            0|            0|  0.00%|                rv.__dict__[key] = extra[key]
  1551|         0|            0|            0|  0.00%|        return rv
  1552|         0|            0|            0|  0.00%|
  1553|         0|            0|            0|  0.00%|    def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False,
  1554|         0|            0|            0|  0.00%|             stacklevel=1):
  1555|         0|            0|            0|  0.00%|        """
  1556|         0|            0|            0|  0.00%|        Low-level logging routine which creates a LogRecord and then calls
  1557|         0|            0|            0|  0.00%|        all the handlers of this logger to handle the record.
  1558|         0|            0|            0|  0.00%|        """
  1559|         0|            0|            0|  0.00%|        sinfo = None
  1560|         0|            0|            0|  0.00%|        if _srcfile:
  1561|         0|            0|            0|  0.00%|            #IronPython doesn't track Python frames, so findCaller raises an
  1562|         0|            0|            0|  0.00%|            #exception on some versions of IronPython. We trap it here so that
  1563|         0|            0|            0|  0.00%|            #IronPython can use logging.
  1564|         0|            0|            0|  0.00%|            try:
  1565|         0|            0|            0|  0.00%|                fn, lno, func, sinfo = self.findCaller(stack_info, stacklevel)
  1566|         0|            0|            0|  0.00%|            except ValueError: # pragma: no cover
  1567|         0|            0|            0|  0.00%|                fn, lno, func = "(unknown file)", 0, "(unknown function)"
  1568|         0|            0|            0|  0.00%|        else: # pragma: no cover
  1569|         0|            0|            0|  0.00%|            fn, lno, func = "(unknown file)", 0, "(unknown function)"
  1570|         0|            0|            0|  0.00%|        if exc_info:
  1571|         0|            0|            0|  0.00%|            if isinstance(exc_info, BaseException):
  1572|         0|            0|            0|  0.00%|                exc_info = (type(exc_info), exc_info, exc_info.__traceback__)
  1573|         0|            0|            0|  0.00%|            elif not isinstance(exc_info, tuple):
  1574|         0|            0|            0|  0.00%|                exc_info = sys.exc_info()
  1575|         0|            0|            0|  0.00%|        record = self.makeRecord(self.name, level, fn, lno, msg, args,
  1576|         0|            0|            0|  0.00%|                                 exc_info, func, extra, sinfo)
  1577|         0|            0|            0|  0.00%|        self.handle(record)
  1578|         0|            0|            0|  0.00%|
  1579|         0|            0|            0|  0.00%|    def handle(self, record):
  1580|         0|            0|            0|  0.00%|        """
  1581|         0|            0|            0|  0.00%|        Call the handlers for the specified record.
  1582|         0|            0|            0|  0.00%|
  1583|         0|            0|            0|  0.00%|        This method is used for unpickled records received from a socket, as
  1584|         0|            0|            0|  0.00%|        well as those created locally. Logger-level filtering is applied.
  1585|         0|            0|            0|  0.00%|        """
  1586|         0|            0|            0|  0.00%|        if (not self.disabled) and self.filter(record):
  1587|         0|            0|            0|  0.00%|            self.callHandlers(record)
  1588|         0|            0|            0|  0.00%|
  1589|         0|            0|            0|  0.00%|    def addHandler(self, hdlr):
  1590|         0|            0|            0|  0.00%|        """
  1591|         0|            0|            0|  0.00%|        Add the specified handler to this logger.
  1592|         0|            0|            0|  0.00%|        """
  1593|         0|            0|            0|  0.00%|        _acquireLock()
  1594|         0|            0|            0|  0.00%|        try:
  1595|         0|            0|            0|  0.00%|            if not (hdlr in self.handlers):
  1596|         0|            0|            0|  0.00%|                self.handlers.append(hdlr)
  1597|         0|            0|            0|  0.00%|        finally:
  1598|         0|            0|            0|  0.00%|            _releaseLock()
  1599|         0|            0|            0|  0.00%|
  1600|         0|            0|            0|  0.00%|    def removeHandler(self, hdlr):
  1601|         0|            0|            0|  0.00%|        """
  1602|         0|            0|            0|  0.00%|        Remove the specified handler from this logger.
  1603|         0|            0|            0|  0.00%|        """
  1604|         0|            0|            0|  0.00%|        _acquireLock()
  1605|         0|            0|            0|  0.00%|        try:
  1606|         0|            0|            0|  0.00%|            if hdlr in self.handlers:
  1607|         0|            0|            0|  0.00%|                self.handlers.remove(hdlr)
  1608|         0|            0|            0|  0.00%|        finally:
  1609|         0|            0|            0|  0.00%|            _releaseLock()
  1610|         0|            0|            0|  0.00%|
  1611|         0|            0|            0|  0.00%|    def hasHandlers(self):
  1612|         0|            0|            0|  0.00%|        """
  1613|         0|            0|            0|  0.00%|        See if this logger has any handlers configured.
  1614|         0|            0|            0|  0.00%|
  1615|         0|            0|            0|  0.00%|        Loop through all handlers for this logger and its parents in the
  1616|         0|            0|            0|  0.00%|        logger hierarchy. Return True if a handler was found, else False.
  1617|         0|            0|            0|  0.00%|        Stop searching up the hierarchy whenever a logger with the "propagate"
  1618|         0|            0|            0|  0.00%|        attribute set to zero is found - that will be the last logger which
  1619|         0|            0|            0|  0.00%|        is checked for the existence of handlers.
  1620|         0|            0|            0|  0.00%|        """
  1621|         0|            0|            0|  0.00%|        c = self
  1622|         0|            0|            0|  0.00%|        rv = False
  1623|         0|            0|            0|  0.00%|        while c:
  1624|         0|            0|            0|  0.00%|            if c.handlers:
  1625|         0|            0|            0|  0.00%|                rv = True
  1626|         0|            0|            0|  0.00%|                break
  1627|         0|            0|            0|  0.00%|            if not c.propagate:
  1628|         0|            0|            0|  0.00%|                break
  1629|         0|            0|            0|  0.00%|            else:
  1630|         0|            0|            0|  0.00%|                c = c.parent
  1631|         0|            0|            0|  0.00%|        return rv
  1632|         0|            0|            0|  0.00%|
  1633|         0|            0|            0|  0.00%|    def callHandlers(self, record):
  1634|         0|            0|            0|  0.00%|        """
  1635|         0|            0|            0|  0.00%|        Pass a record to all relevant handlers.
  1636|         0|            0|            0|  0.00%|
  1637|         0|            0|            0|  0.00%|        Loop through all handlers for this logger and its parents in the
  1638|         0|            0|            0|  0.00%|        logger hierarchy. If no handler was found, output a one-off error
  1639|         0|            0|            0|  0.00%|        message to sys.stderr. Stop searching up the hierarchy whenever a
  1640|         0|            0|            0|  0.00%|        logger with the "propagate" attribute set to zero is found - that
  1641|         0|            0|            0|  0.00%|        will be the last logger whose handlers are called.
  1642|         0|            0|            0|  0.00%|        """
  1643|         0|            0|            0|  0.00%|        c = self
  1644|         0|            0|            0|  0.00%|        found = 0
  1645|         0|            0|            0|  0.00%|        while c:
  1646|         0|            0|            0|  0.00%|            for hdlr in c.handlers:
  1647|         0|            0|            0|  0.00%|                found = found + 1
  1648|         0|            0|            0|  0.00%|                if record.levelno >= hdlr.level:
  1649|         0|            0|            0|  0.00%|                    hdlr.handle(record)
  1650|         0|            0|            0|  0.00%|            if not c.propagate:
  1651|         0|            0|            0|  0.00%|                c = None    #break out
  1652|         0|            0|            0|  0.00%|            else:
  1653|         0|            0|            0|  0.00%|                c = c.parent
  1654|         0|            0|            0|  0.00%|        if (found == 0):
  1655|         0|            0|            0|  0.00%|            if lastResort:
  1656|         0|            0|            0|  0.00%|                if record.levelno >= lastResort.level:
  1657|         0|            0|            0|  0.00%|                    lastResort.handle(record)
  1658|         0|            0|            0|  0.00%|            elif raiseExceptions and not self.manager.emittedNoHandlerWarning:
  1659|         0|            0|            0|  0.00%|                sys.stderr.write("No handlers could be found for logger"
  1660|         0|            0|            0|  0.00%|                                 " \"%s\"\n" % self.name)
  1661|         0|            0|            0|  0.00%|                self.manager.emittedNoHandlerWarning = True
  1662|         0|            0|            0|  0.00%|
  1663|         0|            0|            0|  0.00%|    def getEffectiveLevel(self):
  1664|         0|            0|            0|  0.00%|        """
  1665|         0|            0|            0|  0.00%|        Get the effective level for this logger.
  1666|         0|            0|            0|  0.00%|
  1667|         0|            0|            0|  0.00%|        Loop through this logger and its parents in the logger hierarchy,
  1668|         0|            0|            0|  0.00%|        looking for a non-zero logging level. Return the first one found.
  1669|         0|            0|            0|  0.00%|        """
  1670|         0|            0|            0|  0.00%|        logger = self
  1671|         0|            0|            0|  0.00%|        while logger:
  1672|         0|            0|            0|  0.00%|            if logger.level:
  1673|         0|            0|            0|  0.00%|                return logger.level
  1674|         0|            0|            0|  0.00%|            logger = logger.parent
  1675|         0|            0|            0|  0.00%|        return NOTSET
  1676|         0|            0|            0|  0.00%|
  1677|         8|   1.5974e-05|  1.99676e-06|  0.00%|    def isEnabledFor(self, level):
  1678|         0|            0|            0|  0.00%|        """
  1679|         0|            0|            0|  0.00%|        Is this logger enabled for level 'level'?
  1680|         0|            0|            0|  0.00%|        """
  1681|         8|  1.85966e-05|  2.32458e-06|  0.00%|        if self.disabled:
  1682|         0|            0|            0|  0.00%|            return False
  1683|         0|            0|            0|  0.00%|
  1684|         8|  1.66893e-05|  2.08616e-06|  0.00%|        try:
  1685|         8|  1.93119e-05|  2.41399e-06|  0.00%|            return self._cache[level]
  1686|         0|            0|            0|  0.00%|        except KeyError:
  1687|         0|            0|            0|  0.00%|            _acquireLock()
  1688|         0|            0|            0|  0.00%|            try:
  1689|         0|            0|            0|  0.00%|                if self.manager.disable >= level:
  1690|         0|            0|            0|  0.00%|                    is_enabled = self._cache[level] = False
  1691|         0|            0|            0|  0.00%|                else:
  1692|         0|            0|            0|  0.00%|                    is_enabled = self._cache[level] = (
  1693|         0|            0|            0|  0.00%|                        level >= self.getEffectiveLevel()
  1694|         0|            0|            0|  0.00%|                    )
  1695|         0|            0|            0|  0.00%|            finally:
  1696|         0|            0|            0|  0.00%|                _releaseLock()
  1697|         0|            0|            0|  0.00%|            return is_enabled
  1698|         0|            0|            0|  0.00%|
  1699|         0|            0|            0|  0.00%|    def getChild(self, suffix):
  1700|         0|            0|            0|  0.00%|        """
  1701|         0|            0|            0|  0.00%|        Get a logger which is a descendant to this one.
  1702|         0|            0|            0|  0.00%|
  1703|         0|            0|            0|  0.00%|        This is a convenience method, such that
  1704|         0|            0|            0|  0.00%|
  1705|         0|            0|            0|  0.00%|        logging.getLogger('abc').getChild('def.ghi')
  1706|         0|            0|            0|  0.00%|
  1707|         0|            0|            0|  0.00%|        is the same as
  1708|         0|            0|            0|  0.00%|
  1709|         0|            0|            0|  0.00%|        logging.getLogger('abc.def.ghi')
  1710|         0|            0|            0|  0.00%|
  1711|         0|            0|            0|  0.00%|        It's useful, for example, when the parent logger is named using
  1712|         0|            0|            0|  0.00%|        __name__ rather than a literal string.
  1713|         0|            0|            0|  0.00%|        """
  1714|         0|            0|            0|  0.00%|        if self.root is not self:
  1715|         0|            0|            0|  0.00%|            suffix = '.'.join((self.name, suffix))
  1716|         0|            0|            0|  0.00%|        return self.manager.getLogger(suffix)
  1717|         0|            0|            0|  0.00%|
  1718|         0|            0|            0|  0.00%|    def __repr__(self):
  1719|         0|            0|            0|  0.00%|        level = getLevelName(self.getEffectiveLevel())
  1720|         0|            0|            0|  0.00%|        return '<%s %s (%s)>' % (self.__class__.__name__, self.name, level)
  1721|         0|            0|            0|  0.00%|
  1722|         0|            0|            0|  0.00%|    def __reduce__(self):
  1723|         0|            0|            0|  0.00%|        # In general, only the root logger will not be accessible via its name.
  1724|         0|            0|            0|  0.00%|        # However, the root logger's class has its own __reduce__ method.
  1725|         0|            0|            0|  0.00%|        if getLogger(self.name) is not self:
  1726|         0|            0|            0|  0.00%|            import pickle
  1727|         0|            0|            0|  0.00%|            raise pickle.PicklingError('logger cannot be pickled')
  1728|         0|            0|            0|  0.00%|        return getLogger, (self.name,)
  1729|         0|            0|            0|  0.00%|
  1730|         0|            0|            0|  0.00%|
  1731|         0|            0|            0|  0.00%|class RootLogger(Logger):
  1732|         0|            0|            0|  0.00%|    """
  1733|         0|            0|            0|  0.00%|    A root logger is not that different to any other logger, except that
  1734|         0|            0|            0|  0.00%|    it must have a logging level and there is only one instance of it in
  1735|         0|            0|            0|  0.00%|    the hierarchy.
  1736|         0|            0|            0|  0.00%|    """
  1737|         0|            0|            0|  0.00%|    def __init__(self, level):
  1738|         0|            0|            0|  0.00%|        """
  1739|         0|            0|            0|  0.00%|        Initialize the logger with the name "root".
  1740|         0|            0|            0|  0.00%|        """
  1741|         0|            0|            0|  0.00%|        Logger.__init__(self, "root", level)
  1742|         0|            0|            0|  0.00%|
  1743|         0|            0|            0|  0.00%|    def __reduce__(self):
  1744|         0|            0|            0|  0.00%|        return getLogger, ()
  1745|         0|            0|            0|  0.00%|
  1746|         0|            0|            0|  0.00%|_loggerClass = Logger
  1747|         0|            0|            0|  0.00%|
  1748|         0|            0|            0|  0.00%|class LoggerAdapter(object):
  1749|         0|            0|            0|  0.00%|    """
  1750|         0|            0|            0|  0.00%|    An adapter for loggers which makes it easier to specify contextual
  1751|         0|            0|            0|  0.00%|    information in logging output.
  1752|         0|            0|            0|  0.00%|    """
  1753|         0|            0|            0|  0.00%|
  1754|         0|            0|            0|  0.00%|    def __init__(self, logger, extra):
  1755|         0|            0|            0|  0.00%|        """
  1756|         0|            0|            0|  0.00%|        Initialize the adapter with a logger and a dict-like object which
  1757|         0|            0|            0|  0.00%|        provides contextual information. This constructor signature allows
  1758|         0|            0|            0|  0.00%|        easy stacking of LoggerAdapters, if so desired.
  1759|         0|            0|            0|  0.00%|
  1760|         0|            0|            0|  0.00%|        You can effectively pass keyword arguments as shown in the
  1761|         0|            0|            0|  0.00%|        following example:
  1762|         0|            0|            0|  0.00%|
  1763|         0|            0|            0|  0.00%|        adapter = LoggerAdapter(someLogger, dict(p1=v1, p2="v2"))
  1764|         0|            0|            0|  0.00%|        """
  1765|         0|            0|            0|  0.00%|        self.logger = logger
  1766|         0|            0|            0|  0.00%|        self.extra = extra
  1767|         0|            0|            0|  0.00%|
  1768|         0|            0|            0|  0.00%|    def process(self, msg, kwargs):
  1769|         0|            0|            0|  0.00%|        """
  1770|         0|            0|            0|  0.00%|        Process the logging message and keyword arguments passed in to
  1771|         0|            0|            0|  0.00%|        a logging call to insert contextual information. You can either
  1772|         0|            0|            0|  0.00%|        manipulate the message itself, the keyword args or both. Return
  1773|         0|            0|            0|  0.00%|        the message and kwargs modified (or not) to suit your needs.
  1774|         0|            0|            0|  0.00%|
  1775|         0|            0|            0|  0.00%|        Normally, you'll only need to override this one method in a
  1776|         0|            0|            0|  0.00%|        LoggerAdapter subclass for your specific needs.
  1777|         0|            0|            0|  0.00%|        """
  1778|         0|            0|            0|  0.00%|        kwargs["extra"] = self.extra
  1779|         0|            0|            0|  0.00%|        return msg, kwargs
  1780|         0|            0|            0|  0.00%|
  1781|         0|            0|            0|  0.00%|    #
  1782|         0|            0|            0|  0.00%|    # Boilerplate convenience methods
  1783|         0|            0|            0|  0.00%|    #
  1784|         0|            0|            0|  0.00%|    def debug(self, msg, *args, **kwargs):
  1785|         0|            0|            0|  0.00%|        """
  1786|         0|            0|            0|  0.00%|        Delegate a debug call to the underlying logger.
  1787|         0|            0|            0|  0.00%|        """
  1788|         0|            0|            0|  0.00%|        self.log(DEBUG, msg, *args, **kwargs)
  1789|         0|            0|            0|  0.00%|
  1790|         0|            0|            0|  0.00%|    def info(self, msg, *args, **kwargs):
  1791|         0|            0|            0|  0.00%|        """
  1792|         0|            0|            0|  0.00%|        Delegate an info call to the underlying logger.
  1793|         0|            0|            0|  0.00%|        """
  1794|         0|            0|            0|  0.00%|        self.log(INFO, msg, *args, **kwargs)
  1795|         0|            0|            0|  0.00%|
  1796|         0|            0|            0|  0.00%|    def warning(self, msg, *args, **kwargs):
  1797|         0|            0|            0|  0.00%|        """
  1798|         0|            0|            0|  0.00%|        Delegate a warning call to the underlying logger.
  1799|         0|            0|            0|  0.00%|        """
  1800|         0|            0|            0|  0.00%|        self.log(WARNING, msg, *args, **kwargs)
  1801|         0|            0|            0|  0.00%|
  1802|         0|            0|            0|  0.00%|    def warn(self, msg, *args, **kwargs):
  1803|         0|            0|            0|  0.00%|        warnings.warn("The 'warn' method is deprecated, "
  1804|         0|            0|            0|  0.00%|            "use 'warning' instead", DeprecationWarning, 2)
  1805|         0|            0|            0|  0.00%|        self.warning(msg, *args, **kwargs)
  1806|         0|            0|            0|  0.00%|
  1807|         0|            0|            0|  0.00%|    def error(self, msg, *args, **kwargs):
  1808|         0|            0|            0|  0.00%|        """
  1809|         0|            0|            0|  0.00%|        Delegate an error call to the underlying logger.
  1810|         0|            0|            0|  0.00%|        """
  1811|         0|            0|            0|  0.00%|        self.log(ERROR, msg, *args, **kwargs)
  1812|         0|            0|            0|  0.00%|
  1813|         0|            0|            0|  0.00%|    def exception(self, msg, *args, exc_info=True, **kwargs):
  1814|         0|            0|            0|  0.00%|        """
  1815|         0|            0|            0|  0.00%|        Delegate an exception call to the underlying logger.
  1816|         0|            0|            0|  0.00%|        """
  1817|         0|            0|            0|  0.00%|        self.log(ERROR, msg, *args, exc_info=exc_info, **kwargs)
  1818|         0|            0|            0|  0.00%|
  1819|         0|            0|            0|  0.00%|    def critical(self, msg, *args, **kwargs):
  1820|         0|            0|            0|  0.00%|        """
  1821|         0|            0|            0|  0.00%|        Delegate a critical call to the underlying logger.
  1822|         0|            0|            0|  0.00%|        """
  1823|         0|            0|            0|  0.00%|        self.log(CRITICAL, msg, *args, **kwargs)
  1824|         0|            0|            0|  0.00%|
  1825|         0|            0|            0|  0.00%|    def log(self, level, msg, *args, **kwargs):
  1826|         0|            0|            0|  0.00%|        """
  1827|         0|            0|            0|  0.00%|        Delegate a log call to the underlying logger, after adding
  1828|         0|            0|            0|  0.00%|        contextual information from this adapter instance.
  1829|         0|            0|            0|  0.00%|        """
  1830|         0|            0|            0|  0.00%|        if self.isEnabledFor(level):
  1831|         0|            0|            0|  0.00%|            msg, kwargs = self.process(msg, kwargs)
  1832|         0|            0|            0|  0.00%|            self.logger.log(level, msg, *args, **kwargs)
  1833|         0|            0|            0|  0.00%|
  1834|         0|            0|            0|  0.00%|    def isEnabledFor(self, level):
  1835|         0|            0|            0|  0.00%|        """
  1836|         0|            0|            0|  0.00%|        Is this logger enabled for level 'level'?
  1837|         0|            0|            0|  0.00%|        """
  1838|         0|            0|            0|  0.00%|        return self.logger.isEnabledFor(level)
  1839|         0|            0|            0|  0.00%|
  1840|         0|            0|            0|  0.00%|    def setLevel(self, level):
  1841|         0|            0|            0|  0.00%|        """
  1842|         0|            0|            0|  0.00%|        Set the specified level on the underlying logger.
  1843|         0|            0|            0|  0.00%|        """
  1844|         0|            0|            0|  0.00%|        self.logger.setLevel(level)
  1845|         0|            0|            0|  0.00%|
  1846|         0|            0|            0|  0.00%|    def getEffectiveLevel(self):
  1847|         0|            0|            0|  0.00%|        """
  1848|         0|            0|            0|  0.00%|        Get the effective level for the underlying logger.
  1849|         0|            0|            0|  0.00%|        """
  1850|         0|            0|            0|  0.00%|        return self.logger.getEffectiveLevel()
  1851|         0|            0|            0|  0.00%|
  1852|         0|            0|            0|  0.00%|    def hasHandlers(self):
  1853|         0|            0|            0|  0.00%|        """
  1854|         0|            0|            0|  0.00%|        See if the underlying logger has any handlers.
  1855|         0|            0|            0|  0.00%|        """
  1856|         0|            0|            0|  0.00%|        return self.logger.hasHandlers()
  1857|         0|            0|            0|  0.00%|
  1858|         0|            0|            0|  0.00%|    def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False):
  1859|         0|            0|            0|  0.00%|        """
  1860|         0|            0|            0|  0.00%|        Low-level log implementation, proxied to allow nested logger adapters.
  1861|         0|            0|            0|  0.00%|        """
  1862|         0|            0|            0|  0.00%|        return self.logger._log(
  1863|         0|            0|            0|  0.00%|            level,
  1864|         0|            0|            0|  0.00%|            msg,
  1865|         0|            0|            0|  0.00%|            args,
  1866|         0|            0|            0|  0.00%|            exc_info=exc_info,
  1867|         0|            0|            0|  0.00%|            extra=extra,
  1868|         0|            0|            0|  0.00%|            stack_info=stack_info,
  1869|         0|            0|            0|  0.00%|        )
  1870|         0|            0|            0|  0.00%|
  1871|         0|            0|            0|  0.00%|    @property
  1872|         0|            0|            0|  0.00%|    def manager(self):
  1873|         0|            0|            0|  0.00%|        return self.logger.manager
  1874|         0|            0|            0|  0.00%|
  1875|         0|            0|            0|  0.00%|    @manager.setter
  1876|         0|            0|            0|  0.00%|    def manager(self, value):
  1877|         0|            0|            0|  0.00%|        self.logger.manager = value
  1878|         0|            0|            0|  0.00%|
  1879|         0|            0|            0|  0.00%|    @property
  1880|         0|            0|            0|  0.00%|    def name(self):
  1881|         0|            0|            0|  0.00%|        return self.logger.name
  1882|         0|            0|            0|  0.00%|
  1883|         0|            0|            0|  0.00%|    def __repr__(self):
  1884|         0|            0|            0|  0.00%|        logger = self.logger
  1885|         0|            0|            0|  0.00%|        level = getLevelName(logger.getEffectiveLevel())
  1886|         0|            0|            0|  0.00%|        return '<%s %s (%s)>' % (self.__class__.__name__, logger.name, level)
  1887|         0|            0|            0|  0.00%|
  1888|         0|            0|            0|  0.00%|root = RootLogger(WARNING)
  1889|         0|            0|            0|  0.00%|Logger.root = root
  1890|         0|            0|            0|  0.00%|Logger.manager = Manager(Logger.root)
  1891|         0|            0|            0|  0.00%|
  1892|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
  1893|         0|            0|            0|  0.00%|# Configuration classes and functions
  1894|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
  1895|         0|            0|            0|  0.00%|
  1896|         0|            0|            0|  0.00%|def basicConfig(**kwargs):
  1897|         0|            0|            0|  0.00%|    """
  1898|         0|            0|            0|  0.00%|    Do basic configuration for the logging system.
  1899|         0|            0|            0|  0.00%|
  1900|         0|            0|            0|  0.00%|    This function does nothing if the root logger already has handlers
  1901|         0|            0|            0|  0.00%|    configured, unless the keyword argument *force* is set to ``True``.
  1902|         0|            0|            0|  0.00%|    It is a convenience method intended for use by simple scripts
  1903|         0|            0|            0|  0.00%|    to do one-shot configuration of the logging package.
  1904|         0|            0|            0|  0.00%|
  1905|         0|            0|            0|  0.00%|    The default behaviour is to create a StreamHandler which writes to
  1906|         0|            0|            0|  0.00%|    sys.stderr, set a formatter using the BASIC_FORMAT format string, and
  1907|         0|            0|            0|  0.00%|    add the handler to the root logger.
  1908|         0|            0|            0|  0.00%|
  1909|         0|            0|            0|  0.00%|    A number of optional keyword arguments may be specified, which can alter
  1910|         0|            0|            0|  0.00%|    the default behaviour.
  1911|         0|            0|            0|  0.00%|
  1912|         0|            0|            0|  0.00%|    filename  Specifies that a FileHandler be created, using the specified
  1913|         0|            0|            0|  0.00%|              filename, rather than a StreamHandler.
  1914|         0|            0|            0|  0.00%|    filemode  Specifies the mode to open the file, if filename is specified
  1915|         0|            0|            0|  0.00%|              (if filemode is unspecified, it defaults to 'a').
  1916|         0|            0|            0|  0.00%|    format    Use the specified format string for the handler.
  1917|         0|            0|            0|  0.00%|    datefmt   Use the specified date/time format.
  1918|         0|            0|            0|  0.00%|    style     If a format string is specified, use this to specify the
  1919|         0|            0|            0|  0.00%|              type of format string (possible values '%', '{', '$', for
  1920|         0|            0|            0|  0.00%|              %-formatting, :meth:`str.format` and :class:`string.Template`
  1921|         0|            0|            0|  0.00%|              - defaults to '%').
  1922|         0|            0|            0|  0.00%|    level     Set the root logger level to the specified level.
  1923|         0|            0|            0|  0.00%|    stream    Use the specified stream to initialize the StreamHandler. Note
  1924|         0|            0|            0|  0.00%|              that this argument is incompatible with 'filename' - if both
  1925|         0|            0|            0|  0.00%|              are present, 'stream' is ignored.
  1926|         0|            0|            0|  0.00%|    handlers  If specified, this should be an iterable of already created
  1927|         0|            0|            0|  0.00%|              handlers, which will be added to the root handler. Any handler
  1928|         0|            0|            0|  0.00%|              in the list which does not have a formatter assigned will be
  1929|         0|            0|            0|  0.00%|              assigned the formatter created in this function.
  1930|         0|            0|            0|  0.00%|    force     If this keyword  is specified as true, any existing handlers
  1931|         0|            0|            0|  0.00%|              attached to the root logger are removed and closed, before
  1932|         0|            0|            0|  0.00%|              carrying out the configuration as specified by the other
  1933|         0|            0|            0|  0.00%|              arguments.
  1934|         0|            0|            0|  0.00%|    Note that you could specify a stream created using open(filename, mode)
  1935|         0|            0|            0|  0.00%|    rather than passing the filename and mode in. However, it should be
  1936|         0|            0|            0|  0.00%|    remembered that StreamHandler does not close its stream (since it may be
  1937|         0|            0|            0|  0.00%|    using sys.stdout or sys.stderr), whereas FileHandler closes its stream
  1938|         0|            0|            0|  0.00%|    when the handler is closed.
  1939|         0|            0|            0|  0.00%|
  1940|         0|            0|            0|  0.00%|    .. versionchanged:: 3.8
  1941|         0|            0|            0|  0.00%|       Added the ``force`` parameter.
  1942|         0|            0|            0|  0.00%|
  1943|         0|            0|            0|  0.00%|    .. versionchanged:: 3.2
  1944|         0|            0|            0|  0.00%|       Added the ``style`` parameter.
  1945|         0|            0|            0|  0.00%|
  1946|         0|            0|            0|  0.00%|    .. versionchanged:: 3.3
  1947|         0|            0|            0|  0.00%|       Added the ``handlers`` parameter. A ``ValueError`` is now thrown for
  1948|         0|            0|            0|  0.00%|       incompatible arguments (e.g. ``handlers`` specified together with
  1949|         0|            0|            0|  0.00%|       ``filename``/``filemode``, or ``filename``/``filemode`` specified
  1950|         0|            0|            0|  0.00%|       together with ``stream``, or ``handlers`` specified together with
  1951|         0|            0|            0|  0.00%|       ``stream``.
  1952|         0|            0|            0|  0.00%|    """
  1953|         0|            0|            0|  0.00%|    # Add thread safety in case someone mistakenly calls
  1954|         0|            0|            0|  0.00%|    # basicConfig() from multiple threads
  1955|         0|            0|            0|  0.00%|    _acquireLock()
  1956|         0|            0|            0|  0.00%|    try:
  1957|         0|            0|            0|  0.00%|        force = kwargs.pop('force', False)
  1958|         0|            0|            0|  0.00%|        if force:
  1959|         0|            0|            0|  0.00%|            for h in root.handlers[:]:
  1960|         0|            0|            0|  0.00%|                root.removeHandler(h)
  1961|         0|            0|            0|  0.00%|                h.close()
  1962|         0|            0|            0|  0.00%|        if len(root.handlers) == 0:
  1963|         0|            0|            0|  0.00%|            handlers = kwargs.pop("handlers", None)
  1964|         0|            0|            0|  0.00%|            if handlers is None:
  1965|         0|            0|            0|  0.00%|                if "stream" in kwargs and "filename" in kwargs:
  1966|         0|            0|            0|  0.00%|                    raise ValueError("'stream' and 'filename' should not be "
  1967|         0|            0|            0|  0.00%|                                     "specified together")
  1968|         0|            0|            0|  0.00%|            else:
  1969|         0|            0|            0|  0.00%|                if "stream" in kwargs or "filename" in kwargs:
  1970|         0|            0|            0|  0.00%|                    raise ValueError("'stream' or 'filename' should not be "
  1971|         0|            0|            0|  0.00%|                                     "specified together with 'handlers'")
  1972|         0|            0|            0|  0.00%|            if handlers is None:
  1973|         0|            0|            0|  0.00%|                filename = kwargs.pop("filename", None)
  1974|         0|            0|            0|  0.00%|                mode = kwargs.pop("filemode", 'a')
  1975|         0|            0|            0|  0.00%|                if filename:
  1976|         0|            0|            0|  0.00%|                    h = FileHandler(filename, mode)
  1977|         0|            0|            0|  0.00%|                else:
  1978|         0|            0|            0|  0.00%|                    stream = kwargs.pop("stream", None)
  1979|         0|            0|            0|  0.00%|                    h = StreamHandler(stream)
  1980|         0|            0|            0|  0.00%|                handlers = [h]
  1981|         0|            0|            0|  0.00%|            dfs = kwargs.pop("datefmt", None)
  1982|         0|            0|            0|  0.00%|            style = kwargs.pop("style", '%')
  1983|         0|            0|            0|  0.00%|            if style not in _STYLES:
  1984|         0|            0|            0|  0.00%|                raise ValueError('Style must be one of: %s' % ','.join(
  1985|         0|            0|            0|  0.00%|                                 _STYLES.keys()))
  1986|         0|            0|            0|  0.00%|            fs = kwargs.pop("format", _STYLES[style][1])
  1987|         0|            0|            0|  0.00%|            fmt = Formatter(fs, dfs, style)
  1988|         0|            0|            0|  0.00%|            for h in handlers:
  1989|         0|            0|            0|  0.00%|                if h.formatter is None:
  1990|         0|            0|            0|  0.00%|                    h.setFormatter(fmt)
  1991|         0|            0|            0|  0.00%|                root.addHandler(h)
  1992|         0|            0|            0|  0.00%|            level = kwargs.pop("level", None)
  1993|         0|            0|            0|  0.00%|            if level is not None:
  1994|         0|            0|            0|  0.00%|                root.setLevel(level)
  1995|         0|            0|            0|  0.00%|            if kwargs:
  1996|         0|            0|            0|  0.00%|                keys = ', '.join(kwargs.keys())
  1997|         0|            0|            0|  0.00%|                raise ValueError('Unrecognised argument(s): %s' % keys)
  1998|         0|            0|            0|  0.00%|    finally:
  1999|         0|            0|            0|  0.00%|        _releaseLock()
  2000|         0|            0|            0|  0.00%|
  2001|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
  2002|         0|            0|            0|  0.00%|# Utility functions at module level.
  2003|         0|            0|            0|  0.00%|# Basically delegate everything to the root logger.
  2004|         0|            0|            0|  0.00%|#---------------------------------------------------------------------------
  2005|         0|            0|            0|  0.00%|
  2006|         0|            0|            0|  0.00%|def getLogger(name=None):
  2007|         0|            0|            0|  0.00%|    """
  2008|         0|            0|            0|  0.00%|    Return a logger with the specified name, creating it if necessary.
  2009|         0|            0|            0|  0.00%|
  2010|         0|            0|            0|  0.00%|    If no name is specified, return the root logger.
  2011|         0|            0|            0|  0.00%|    """
  2012|         0|            0|            0|  0.00%|    if name:
  2013|         0|            0|            0|  0.00%|        return Logger.manager.getLogger(name)
  2014|         0|            0|            0|  0.00%|    else:
  2015|         0|            0|            0|  0.00%|        return root
  2016|         0|            0|            0|  0.00%|
  2017|         0|            0|            0|  0.00%|def critical(msg, *args, **kwargs):
  2018|         0|            0|            0|  0.00%|    """
  2019|         0|            0|            0|  0.00%|    Log a message with severity 'CRITICAL' on the root logger. If the logger
  2020|         0|            0|            0|  0.00%|    has no handlers, call basicConfig() to add a console handler with a
  2021|         0|            0|            0|  0.00%|    pre-defined format.
  2022|         0|            0|            0|  0.00%|    """
  2023|         0|            0|            0|  0.00%|    if len(root.handlers) == 0:
  2024|         0|            0|            0|  0.00%|        basicConfig()
  2025|         0|            0|            0|  0.00%|    root.critical(msg, *args, **kwargs)
  2026|         0|            0|            0|  0.00%|
  2027|         0|            0|            0|  0.00%|fatal = critical
  2028|         0|            0|            0|  0.00%|
  2029|         0|            0|            0|  0.00%|def error(msg, *args, **kwargs):
  2030|         0|            0|            0|  0.00%|    """
  2031|         0|            0|            0|  0.00%|    Log a message with severity 'ERROR' on the root logger. If the logger has
  2032|         0|            0|            0|  0.00%|    no handlers, call basicConfig() to add a console handler with a pre-defined
  2033|         0|            0|            0|  0.00%|    format.
  2034|         0|            0|            0|  0.00%|    """
  2035|         0|            0|            0|  0.00%|    if len(root.handlers) == 0:
  2036|         0|            0|            0|  0.00%|        basicConfig()
  2037|         0|            0|            0|  0.00%|    root.error(msg, *args, **kwargs)
  2038|         0|            0|            0|  0.00%|
  2039|         0|            0|            0|  0.00%|def exception(msg, *args, exc_info=True, **kwargs):
  2040|         0|            0|            0|  0.00%|    """
  2041|         0|            0|            0|  0.00%|    Log a message with severity 'ERROR' on the root logger, with exception
  2042|         0|            0|            0|  0.00%|    information. If the logger has no handlers, basicConfig() is called to add
  2043|         0|            0|            0|  0.00%|    a console handler with a pre-defined format.
  2044|         0|            0|            0|  0.00%|    """
  2045|         0|            0|            0|  0.00%|    error(msg, *args, exc_info=exc_info, **kwargs)
  2046|         0|            0|            0|  0.00%|
  2047|         0|            0|            0|  0.00%|def warning(msg, *args, **kwargs):
  2048|         0|            0|            0|  0.00%|    """
  2049|         0|            0|            0|  0.00%|    Log a message with severity 'WARNING' on the root logger. If the logger has
  2050|         0|            0|            0|  0.00%|    no handlers, call basicConfig() to add a console handler with a pre-defined
  2051|         0|            0|            0|  0.00%|    format.
  2052|         0|            0|            0|  0.00%|    """
  2053|         0|            0|            0|  0.00%|    if len(root.handlers) == 0:
  2054|         0|            0|            0|  0.00%|        basicConfig()
  2055|         0|            0|            0|  0.00%|    root.warning(msg, *args, **kwargs)
  2056|         0|            0|            0|  0.00%|
  2057|         0|            0|            0|  0.00%|def warn(msg, *args, **kwargs):
  2058|         0|            0|            0|  0.00%|    warnings.warn("The 'warn' function is deprecated, "
  2059|         0|            0|            0|  0.00%|        "use 'warning' instead", DeprecationWarning, 2)
  2060|         0|            0|            0|  0.00%|    warning(msg, *args, **kwargs)
  2061|         0|            0|            0|  0.00%|
  2062|         6|  1.93119e-05|  3.21865e-06|  0.00%|def info(msg, *args, **kwargs):
  2063|         0|            0|            0|  0.00%|    """
  2064|         0|            0|            0|  0.00%|    Log a message with severity 'INFO' on the root logger. If the logger has
  2065|         0|            0|            0|  0.00%|    no handlers, call basicConfig() to add a console handler with a pre-defined
  2066|         0|            0|            0|  0.00%|    format.
  2067|         0|            0|            0|  0.00%|    """
  2068|         6|  1.95503e-05|  3.25839e-06|  0.00%|    if len(root.handlers) == 0:
  2069|         0|            0|            0|  0.00%|        basicConfig()
  2070|         6|  4.57764e-05|  7.62939e-06|  0.00%|    root.info(msg, *args, **kwargs)
(call)|         6|  0.000106335|  1.77224e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/logging/__init__.py:1424 info
  2071|         0|            0|            0|  0.00%|
  2072|         0|            0|            0|  0.00%|def debug(msg, *args, **kwargs):
  2073|         0|            0|            0|  0.00%|    """
  2074|         0|            0|            0|  0.00%|    Log a message with severity 'DEBUG' on the root logger. If the logger has
  2075|         0|            0|            0|  0.00%|    no handlers, call basicConfig() to add a console handler with a pre-defined
  2076|         0|            0|            0|  0.00%|    format.
  2077|         0|            0|            0|  0.00%|    """
  2078|         0|            0|            0|  0.00%|    if len(root.handlers) == 0:
  2079|         0|            0|            0|  0.00%|        basicConfig()
  2080|         0|            0|            0|  0.00%|    root.debug(msg, *args, **kwargs)
  2081|         0|            0|            0|  0.00%|
  2082|         0|            0|            0|  0.00%|def log(level, msg, *args, **kwargs):
  2083|         0|            0|            0|  0.00%|    """
  2084|         0|            0|            0|  0.00%|    Log 'msg % args' with the integer severity 'level' on the root logger. If
  2085|         0|            0|            0|  0.00%|    the logger has no handlers, call basicConfig() to add a console handler
  2086|         0|            0|            0|  0.00%|    with a pre-defined format.
  2087|         0|            0|            0|  0.00%|    """
  2088|         0|            0|            0|  0.00%|    if len(root.handlers) == 0:
  2089|         0|            0|            0|  0.00%|        basicConfig()
  2090|         0|            0|            0|  0.00%|    root.log(level, msg, *args, **kwargs)
  2091|         0|            0|            0|  0.00%|
  2092|         0|            0|            0|  0.00%|def disable(level=CRITICAL):
  2093|         0|            0|            0|  0.00%|    """
  2094|         0|            0|            0|  0.00%|    Disable all logging calls of severity 'level' and below.
  2095|         0|            0|            0|  0.00%|    """
  2096|         0|            0|            0|  0.00%|    root.manager.disable = level
  2097|         0|            0|            0|  0.00%|    root.manager._clear_cache()
  2098|         0|            0|            0|  0.00%|
  2099|         0|            0|            0|  0.00%|def shutdown(handlerList=_handlerList):
  2100|         0|            0|            0|  0.00%|    """
  2101|         0|            0|            0|  0.00%|    Perform any cleanup actions in the logging system (e.g. flushing
  2102|         0|            0|            0|  0.00%|    buffers).
  2103|         0|            0|            0|  0.00%|
  2104|         0|            0|            0|  0.00%|    Should be called at application exit.
  2105|         0|            0|            0|  0.00%|    """
  2106|         0|            0|            0|  0.00%|    for wr in reversed(handlerList[:]):
  2107|         0|            0|            0|  0.00%|        #errors might occur, for example, if files are locked
  2108|         0|            0|            0|  0.00%|        #we just ignore them if raiseExceptions is not set
  2109|         0|            0|            0|  0.00%|        try:
  2110|         0|            0|            0|  0.00%|            h = wr()
  2111|         0|            0|            0|  0.00%|            if h:
  2112|         0|            0|            0|  0.00%|                try:
  2113|         0|            0|            0|  0.00%|                    h.acquire()
  2114|         0|            0|            0|  0.00%|                    h.flush()
  2115|         0|            0|            0|  0.00%|                    h.close()
  2116|         0|            0|            0|  0.00%|                except (OSError, ValueError):
  2117|         0|            0|            0|  0.00%|                    # Ignore errors which might be caused
  2118|         0|            0|            0|  0.00%|                    # because handlers have been closed but
  2119|         0|            0|            0|  0.00%|                    # references to them are still around at
  2120|         0|            0|            0|  0.00%|                    # application exit.
  2121|         0|            0|            0|  0.00%|                    pass
  2122|         0|            0|            0|  0.00%|                finally:
  2123|         0|            0|            0|  0.00%|                    h.release()
  2124|         0|            0|            0|  0.00%|        except: # ignore everything, as we're shutting down
  2125|         0|            0|            0|  0.00%|            if raiseExceptions:
  2126|         0|            0|            0|  0.00%|                raise
  2127|         0|            0|            0|  0.00%|            #else, swallow
  2128|         0|            0|            0|  0.00%|
  2129|         0|            0|            0|  0.00%|#Let's try and shutdown automatically on application exit...
  2130|         0|            0|            0|  0.00%|import atexit
  2131|         0|            0|            0|  0.00%|atexit.register(shutdown)
  2132|         0|            0|            0|  0.00%|
  2133|         0|            0|            0|  0.00%|# Null handler
  2134|         0|            0|            0|  0.00%|
  2135|         0|            0|            0|  0.00%|class NullHandler(Handler):
  2136|         0|            0|            0|  0.00%|    """
  2137|         0|            0|            0|  0.00%|    This handler does nothing. It's intended to be used to avoid the
  2138|         0|            0|            0|  0.00%|    "No handlers could be found for logger XXX" one-off warning. This is
  2139|         0|            0|            0|  0.00%|    important for library code, which may contain code to log events. If a user
  2140|         0|            0|            0|  0.00%|    of the library does not configure logging, the one-off warning might be
  2141|         0|            0|            0|  0.00%|    produced; to avoid this, the library developer simply needs to instantiate
  2142|         0|            0|            0|  0.00%|    a NullHandler and add it to the top-level logger of the library module or
  2143|         0|            0|            0|  0.00%|    package.
  2144|         0|            0|            0|  0.00%|    """
  2145|         0|            0|            0|  0.00%|    def handle(self, record):
  2146|         0|            0|            0|  0.00%|        """Stub."""
  2147|         0|            0|            0|  0.00%|
  2148|         0|            0|            0|  0.00%|    def emit(self, record):
  2149|         0|            0|            0|  0.00%|        """Stub."""
  2150|         0|            0|            0|  0.00%|
  2151|         0|            0|            0|  0.00%|    def createLock(self):
  2152|         0|            0|            0|  0.00%|        self.lock = None
  2153|         0|            0|            0|  0.00%|
  2154|         0|            0|            0|  0.00%|# Warnings integration
  2155|         0|            0|            0|  0.00%|
  2156|         0|            0|            0|  0.00%|_warnings_showwarning = None
  2157|         0|            0|            0|  0.00%|
  2158|         0|            0|            0|  0.00%|def _showwarning(message, category, filename, lineno, file=None, line=None):
  2159|         0|            0|            0|  0.00%|    """
  2160|         0|            0|            0|  0.00%|    Implementation of showwarnings which redirects to logging, which will first
  2161|         0|            0|            0|  0.00%|    check to see if the file parameter is None. If a file is specified, it will
  2162|         0|            0|            0|  0.00%|    delegate to the original warnings implementation of showwarning. Otherwise,
  2163|         0|            0|            0|  0.00%|    it will call warnings.formatwarning and will log the resulting string to a
  2164|         0|            0|            0|  0.00%|    warnings logger named "py.warnings" with level logging.WARNING.
  2165|         0|            0|            0|  0.00%|    """
  2166|         0|            0|            0|  0.00%|    if file is not None:
  2167|         0|            0|            0|  0.00%|        if _warnings_showwarning is not None:
  2168|         0|            0|            0|  0.00%|            _warnings_showwarning(message, category, filename, lineno, file, line)
  2169|         0|            0|            0|  0.00%|    else:
  2170|         0|            0|            0|  0.00%|        s = warnings.formatwarning(message, category, filename, lineno, line)
  2171|         0|            0|            0|  0.00%|        logger = getLogger("py.warnings")
  2172|         0|            0|            0|  0.00%|        if not logger.handlers:
  2173|         0|            0|            0|  0.00%|            logger.addHandler(NullHandler())
  2174|         0|            0|            0|  0.00%|        logger.warning("%s", s)
  2175|         0|            0|            0|  0.00%|
  2176|         0|            0|            0|  0.00%|def captureWarnings(capture):
  2177|         0|            0|            0|  0.00%|    """
  2178|         0|            0|            0|  0.00%|    If capture is true, redirect all warnings to the logging package.
  2179|         0|            0|            0|  0.00%|    If capture is False, ensure that warnings are not redirected to logging
  2180|         0|            0|            0|  0.00%|    but to their original destinations.
  2181|         0|            0|            0|  0.00%|    """
  2182|         0|            0|            0|  0.00%|    global _warnings_showwarning
  2183|         0|            0|            0|  0.00%|    if capture:
  2184|         0|            0|            0|  0.00%|        if _warnings_showwarning is None:
  2185|         0|            0|            0|  0.00%|            _warnings_showwarning = warnings.showwarning
  2186|         0|            0|            0|  0.00%|            warnings.showwarning = _showwarning
  2187|         0|            0|            0|  0.00%|    else:
  2188|         0|            0|            0|  0.00%|        if _warnings_showwarning is not None:
  2189|         0|            0|            0|  0.00%|            warnings.showwarning = _warnings_showwarning
  2190|         0|            0|            0|  0.00%|            _warnings_showwarning = None
File: /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/enum.py
File duration: 0.00014925s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import sys
     2|         0|            0|            0|  0.00%|from types import MappingProxyType, DynamicClassAttribute
     3|         0|            0|            0|  0.00%|
     4|         0|            0|            0|  0.00%|
     5|         0|            0|            0|  0.00%|__all__ = [
     6|         0|            0|            0|  0.00%|        'EnumMeta',
     7|         0|            0|            0|  0.00%|        'Enum', 'IntEnum', 'Flag', 'IntFlag',
     8|         0|            0|            0|  0.00%|        'auto', 'unique',
     9|         0|            0|            0|  0.00%|        ]
    10|         0|            0|            0|  0.00%|
    11|         0|            0|            0|  0.00%|
    12|         0|            0|            0|  0.00%|def _is_descriptor(obj):
    13|         0|            0|            0|  0.00%|    """Returns True if obj is a descriptor, False otherwise."""
    14|         0|            0|            0|  0.00%|    return (
    15|         0|            0|            0|  0.00%|            hasattr(obj, '__get__') or
    16|         0|            0|            0|  0.00%|            hasattr(obj, '__set__') or
    17|         0|            0|            0|  0.00%|            hasattr(obj, '__delete__'))
    18|         0|            0|            0|  0.00%|
    19|         0|            0|            0|  0.00%|
    20|         0|            0|            0|  0.00%|def _is_dunder(name):
    21|         0|            0|            0|  0.00%|    """Returns True if a __dunder__ name, False otherwise."""
    22|         0|            0|            0|  0.00%|    return (len(name) > 4 and
    23|         0|            0|            0|  0.00%|            name[:2] == name[-2:] == '__' and
    24|         0|            0|            0|  0.00%|            name[2] != '_' and
    25|         0|            0|            0|  0.00%|            name[-3] != '_')
    26|         0|            0|            0|  0.00%|
    27|         0|            0|            0|  0.00%|
    28|         0|            0|            0|  0.00%|def _is_sunder(name):
    29|         0|            0|            0|  0.00%|    """Returns True if a _sunder_ name, False otherwise."""
    30|         0|            0|            0|  0.00%|    return (len(name) > 2 and
    31|         0|            0|            0|  0.00%|            name[0] == name[-1] == '_' and
    32|         0|            0|            0|  0.00%|            name[1:2] != '_' and
    33|         0|            0|            0|  0.00%|            name[-2:-1] != '_')
    34|         0|            0|            0|  0.00%|
    35|         0|            0|            0|  0.00%|
    36|         0|            0|            0|  0.00%|def _make_class_unpicklable(cls):
    37|         0|            0|            0|  0.00%|    """Make the given class un-picklable."""
    38|         0|            0|            0|  0.00%|    def _break_on_call_reduce(self, proto):
    39|         0|            0|            0|  0.00%|        raise TypeError('%r cannot be pickled' % self)
    40|         0|            0|            0|  0.00%|    cls.__reduce_ex__ = _break_on_call_reduce
    41|         0|            0|            0|  0.00%|    cls.__module__ = '<unknown>'
    42|         0|            0|            0|  0.00%|
    43|         0|            0|            0|  0.00%|_auto_null = object()
    44|         0|            0|            0|  0.00%|class auto:
    45|         0|            0|            0|  0.00%|    """
    46|         0|            0|            0|  0.00%|    Instances are replaced with an appropriate value in Enum class suites.
    47|         0|            0|            0|  0.00%|    """
    48|         0|            0|            0|  0.00%|    value = _auto_null
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|
    51|         0|            0|            0|  0.00%|class _EnumDict(dict):
    52|         0|            0|            0|  0.00%|    """Track enum member order and ensure member names are not reused.
    53|         0|            0|            0|  0.00%|
    54|         0|            0|            0|  0.00%|    EnumMeta will use the names found in self._member_names as the
    55|         0|            0|            0|  0.00%|    enumeration member names.
    56|         0|            0|            0|  0.00%|
    57|         0|            0|            0|  0.00%|    """
    58|         0|            0|            0|  0.00%|    def __init__(self):
    59|         0|            0|            0|  0.00%|        super().__init__()
    60|         0|            0|            0|  0.00%|        self._member_names = []
    61|         0|            0|            0|  0.00%|        self._last_values = []
    62|         0|            0|            0|  0.00%|        self._ignore = []
    63|         0|            0|            0|  0.00%|
    64|         0|            0|            0|  0.00%|    def __setitem__(self, key, value):
    65|         0|            0|            0|  0.00%|        """Changes anything not dundered or not a descriptor.
    66|         0|            0|            0|  0.00%|
    67|         0|            0|            0|  0.00%|        If an enum member name is used twice, an error is raised; duplicate
    68|         0|            0|            0|  0.00%|        values are not checked for.
    69|         0|            0|            0|  0.00%|
    70|         0|            0|            0|  0.00%|        Single underscore (sunder) names are reserved.
    71|         0|            0|            0|  0.00%|
    72|         0|            0|            0|  0.00%|        """
    73|         0|            0|            0|  0.00%|        if _is_sunder(key):
    74|         0|            0|            0|  0.00%|            if key not in (
    75|         0|            0|            0|  0.00%|                    '_order_', '_create_pseudo_member_',
    76|         0|            0|            0|  0.00%|                    '_generate_next_value_', '_missing_', '_ignore_',
    77|         0|            0|            0|  0.00%|                    ):
    78|         0|            0|            0|  0.00%|                raise ValueError('_names_ are reserved for future Enum use')
    79|         0|            0|            0|  0.00%|            if key == '_generate_next_value_':
    80|         0|            0|            0|  0.00%|                setattr(self, '_generate_next_value', value)
    81|         0|            0|            0|  0.00%|            elif key == '_ignore_':
    82|         0|            0|            0|  0.00%|                if isinstance(value, str):
    83|         0|            0|            0|  0.00%|                    value = value.replace(',',' ').split()
    84|         0|            0|            0|  0.00%|                else:
    85|         0|            0|            0|  0.00%|                    value = list(value)
    86|         0|            0|            0|  0.00%|                self._ignore = value
    87|         0|            0|            0|  0.00%|                already = set(value) & set(self._member_names)
    88|         0|            0|            0|  0.00%|                if already:
    89|         0|            0|            0|  0.00%|                    raise ValueError('_ignore_ cannot specify already set names: %r' % (already, ))
    90|         0|            0|            0|  0.00%|        elif _is_dunder(key):
    91|         0|            0|            0|  0.00%|            if key == '__order__':
    92|         0|            0|            0|  0.00%|                key = '_order_'
    93|         0|            0|            0|  0.00%|        elif key in self._member_names:
    94|         0|            0|            0|  0.00%|            # descriptor overwriting an enum?
    95|         0|            0|            0|  0.00%|            raise TypeError('Attempted to reuse key: %r' % key)
    96|         0|            0|            0|  0.00%|        elif key in self._ignore:
    97|         0|            0|            0|  0.00%|            pass
    98|         0|            0|            0|  0.00%|        elif not _is_descriptor(value):
    99|         0|            0|            0|  0.00%|            if key in self:
   100|         0|            0|            0|  0.00%|                # enum overwriting a descriptor?
   101|         0|            0|            0|  0.00%|                raise TypeError('%r already defined as: %r' % (key, self[key]))
   102|         0|            0|            0|  0.00%|            if isinstance(value, auto):
   103|         0|            0|            0|  0.00%|                if value.value == _auto_null:
   104|         0|            0|            0|  0.00%|                    value.value = self._generate_next_value(key, 1, len(self._member_names), self._last_values[:])
   105|         0|            0|            0|  0.00%|                value = value.value
   106|         0|            0|            0|  0.00%|            self._member_names.append(key)
   107|         0|            0|            0|  0.00%|            self._last_values.append(value)
   108|         0|            0|            0|  0.00%|        super().__setitem__(key, value)
   109|         0|            0|            0|  0.00%|
   110|         0|            0|            0|  0.00%|
   111|         0|            0|            0|  0.00%|# Dummy value for Enum as EnumMeta explicitly checks for it, but of course
   112|         0|            0|            0|  0.00%|# until EnumMeta finishes running the first time the Enum class doesn't exist.
   113|         0|            0|            0|  0.00%|# This is also why there are checks in EnumMeta like `if Enum is not None`
   114|         0|            0|            0|  0.00%|Enum = None
   115|         0|            0|            0|  0.00%|
   116|         0|            0|            0|  0.00%|
   117|         0|            0|            0|  0.00%|class EnumMeta(type):
   118|         0|            0|            0|  0.00%|    """Metaclass for Enum"""
   119|         0|            0|            0|  0.00%|    @classmethod
   120|         0|            0|            0|  0.00%|    def __prepare__(metacls, cls, bases):
   121|         0|            0|            0|  0.00%|        # create the namespace dict
   122|         0|            0|            0|  0.00%|        enum_dict = _EnumDict()
   123|         0|            0|            0|  0.00%|        # inherit previous flags and _generate_next_value_ function
   124|         0|            0|            0|  0.00%|        member_type, first_enum = metacls._get_mixins_(bases)
   125|         0|            0|            0|  0.00%|        if first_enum is not None:
   126|         0|            0|            0|  0.00%|            enum_dict['_generate_next_value_'] = getattr(first_enum, '_generate_next_value_', None)
   127|         0|            0|            0|  0.00%|        return enum_dict
   128|         0|            0|            0|  0.00%|
   129|         0|            0|            0|  0.00%|    def __new__(metacls, cls, bases, classdict):
   130|         0|            0|            0|  0.00%|        # an Enum class is final once enumeration items have been defined; it
   131|         0|            0|            0|  0.00%|        # cannot be mixed with other types (int, float, etc.) if it has an
   132|         0|            0|            0|  0.00%|        # inherited __new__ unless a new __new__ is defined (or the resulting
   133|         0|            0|            0|  0.00%|        # class will fail).
   134|         0|            0|            0|  0.00%|        #
   135|         0|            0|            0|  0.00%|        # remove any keys listed in _ignore_
   136|         0|            0|            0|  0.00%|        classdict.setdefault('_ignore_', []).append('_ignore_')
   137|         0|            0|            0|  0.00%|        ignore = classdict['_ignore_']
   138|         0|            0|            0|  0.00%|        for key in ignore:
   139|         0|            0|            0|  0.00%|            classdict.pop(key, None)
   140|         0|            0|            0|  0.00%|        member_type, first_enum = metacls._get_mixins_(bases)
   141|         0|            0|            0|  0.00%|        __new__, save_new, use_args = metacls._find_new_(classdict, member_type,
   142|         0|            0|            0|  0.00%|                                                        first_enum)
   143|         0|            0|            0|  0.00%|
   144|         0|            0|            0|  0.00%|        # save enum items into separate mapping so they don't get baked into
   145|         0|            0|            0|  0.00%|        # the new class
   146|         0|            0|            0|  0.00%|        enum_members = {k: classdict[k] for k in classdict._member_names}
   147|         0|            0|            0|  0.00%|        for name in classdict._member_names:
   148|         0|            0|            0|  0.00%|            del classdict[name]
   149|         0|            0|            0|  0.00%|
   150|         0|            0|            0|  0.00%|        # adjust the sunders
   151|         0|            0|            0|  0.00%|        _order_ = classdict.pop('_order_', None)
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|        # check for illegal enum names (any others?)
   154|         0|            0|            0|  0.00%|        invalid_names = set(enum_members) & {'mro', ''}
   155|         0|            0|            0|  0.00%|        if invalid_names:
   156|         0|            0|            0|  0.00%|            raise ValueError('Invalid enum member name: {0}'.format(
   157|         0|            0|            0|  0.00%|                ','.join(invalid_names)))
   158|         0|            0|            0|  0.00%|
   159|         0|            0|            0|  0.00%|        # create a default docstring if one has not been provided
   160|         0|            0|            0|  0.00%|        if '__doc__' not in classdict:
   161|         0|            0|            0|  0.00%|            classdict['__doc__'] = 'An enumeration.'
   162|         0|            0|            0|  0.00%|
   163|         0|            0|            0|  0.00%|        # create our new Enum type
   164|         0|            0|            0|  0.00%|        enum_class = super().__new__(metacls, cls, bases, classdict)
   165|         0|            0|            0|  0.00%|        enum_class._member_names_ = []               # names in definition order
   166|         0|            0|            0|  0.00%|        enum_class._member_map_ = {}                 # name->value map
   167|         0|            0|            0|  0.00%|        enum_class._member_type_ = member_type
   168|         0|            0|            0|  0.00%|
   169|         0|            0|            0|  0.00%|        # save DynamicClassAttribute attributes from super classes so we know
   170|         0|            0|            0|  0.00%|        # if we can take the shortcut of storing members in the class dict
   171|         0|            0|            0|  0.00%|        dynamic_attributes = {k for c in enum_class.mro()
   172|         0|            0|            0|  0.00%|                              for k, v in c.__dict__.items()
   173|         0|            0|            0|  0.00%|                              if isinstance(v, DynamicClassAttribute)}
   174|         0|            0|            0|  0.00%|
   175|         0|            0|            0|  0.00%|        # Reverse value->name map for hashable values.
   176|         0|            0|            0|  0.00%|        enum_class._value2member_map_ = {}
   177|         0|            0|            0|  0.00%|
   178|         0|            0|            0|  0.00%|        # If a custom type is mixed into the Enum, and it does not know how
   179|         0|            0|            0|  0.00%|        # to pickle itself, pickle.dumps will succeed but pickle.loads will
   180|         0|            0|            0|  0.00%|        # fail.  Rather than have the error show up later and possibly far
   181|         0|            0|            0|  0.00%|        # from the source, sabotage the pickle protocol for this class so
   182|         0|            0|            0|  0.00%|        # that pickle.dumps also fails.
   183|         0|            0|            0|  0.00%|        #
   184|         0|            0|            0|  0.00%|        # However, if the new class implements its own __reduce_ex__, do not
   185|         0|            0|            0|  0.00%|        # sabotage -- it's on them to make sure it works correctly.  We use
   186|         0|            0|            0|  0.00%|        # __reduce_ex__ instead of any of the others as it is preferred by
   187|         0|            0|            0|  0.00%|        # pickle over __reduce__, and it handles all pickle protocols.
   188|         0|            0|            0|  0.00%|        if '__reduce_ex__' not in classdict:
   189|         0|            0|            0|  0.00%|            if member_type is not object:
   190|         0|            0|            0|  0.00%|                methods = ('__getnewargs_ex__', '__getnewargs__',
   191|         0|            0|            0|  0.00%|                        '__reduce_ex__', '__reduce__')
   192|         0|            0|            0|  0.00%|                if not any(m in member_type.__dict__ for m in methods):
   193|         0|            0|            0|  0.00%|                    _make_class_unpicklable(enum_class)
   194|         0|            0|            0|  0.00%|
   195|         0|            0|            0|  0.00%|        # instantiate them, checking for duplicates as we go
   196|         0|            0|            0|  0.00%|        # we instantiate first instead of checking for duplicates first in case
   197|         0|            0|            0|  0.00%|        # a custom __new__ is doing something funky with the values -- such as
   198|         0|            0|            0|  0.00%|        # auto-numbering ;)
   199|         0|            0|            0|  0.00%|        for member_name in classdict._member_names:
   200|         0|            0|            0|  0.00%|            value = enum_members[member_name]
   201|         0|            0|            0|  0.00%|            if not isinstance(value, tuple):
   202|         0|            0|            0|  0.00%|                args = (value, )
   203|         0|            0|            0|  0.00%|            else:
   204|         0|            0|            0|  0.00%|                args = value
   205|         0|            0|            0|  0.00%|            if member_type is tuple:   # special case for tuple enums
   206|         0|            0|            0|  0.00%|                args = (args, )     # wrap it one more time
   207|         0|            0|            0|  0.00%|            if not use_args:
   208|         0|            0|            0|  0.00%|                enum_member = __new__(enum_class)
   209|         0|            0|            0|  0.00%|                if not hasattr(enum_member, '_value_'):
   210|         0|            0|            0|  0.00%|                    enum_member._value_ = value
   211|         0|            0|            0|  0.00%|            else:
   212|         0|            0|            0|  0.00%|                enum_member = __new__(enum_class, *args)
   213|         0|            0|            0|  0.00%|                if not hasattr(enum_member, '_value_'):
   214|         0|            0|            0|  0.00%|                    if member_type is object:
   215|         0|            0|            0|  0.00%|                        enum_member._value_ = value
   216|         0|            0|            0|  0.00%|                    else:
   217|         0|            0|            0|  0.00%|                        enum_member._value_ = member_type(*args)
   218|         0|            0|            0|  0.00%|            value = enum_member._value_
   219|         0|            0|            0|  0.00%|            enum_member._name_ = member_name
   220|         0|            0|            0|  0.00%|            enum_member.__objclass__ = enum_class
   221|         0|            0|            0|  0.00%|            enum_member.__init__(*args)
   222|         0|            0|            0|  0.00%|            # If another member with the same value was already defined, the
   223|         0|            0|            0|  0.00%|            # new member becomes an alias to the existing one.
   224|         0|            0|            0|  0.00%|            for name, canonical_member in enum_class._member_map_.items():
   225|         0|            0|            0|  0.00%|                if canonical_member._value_ == enum_member._value_:
   226|         0|            0|            0|  0.00%|                    enum_member = canonical_member
   227|         0|            0|            0|  0.00%|                    break
   228|         0|            0|            0|  0.00%|            else:
   229|         0|            0|            0|  0.00%|                # Aliases don't appear in member names (only in __members__).
   230|         0|            0|            0|  0.00%|                enum_class._member_names_.append(member_name)
   231|         0|            0|            0|  0.00%|            # performance boost for any member that would not shadow
   232|         0|            0|            0|  0.00%|            # a DynamicClassAttribute
   233|         0|            0|            0|  0.00%|            if member_name not in dynamic_attributes:
   234|         0|            0|            0|  0.00%|                setattr(enum_class, member_name, enum_member)
   235|         0|            0|            0|  0.00%|            # now add to _member_map_
   236|         0|            0|            0|  0.00%|            enum_class._member_map_[member_name] = enum_member
   237|         0|            0|            0|  0.00%|            try:
   238|         0|            0|            0|  0.00%|                # This may fail if value is not hashable. We can't add the value
   239|         0|            0|            0|  0.00%|                # to the map, and by-value lookups for this value will be
   240|         0|            0|            0|  0.00%|                # linear.
   241|         0|            0|            0|  0.00%|                enum_class._value2member_map_[value] = enum_member
   242|         0|            0|            0|  0.00%|            except TypeError:
   243|         0|            0|            0|  0.00%|                pass
   244|         0|            0|            0|  0.00%|
   245|         0|            0|            0|  0.00%|        # double check that repr and friends are not the mixin's or various
   246|         0|            0|            0|  0.00%|        # things break (such as pickle)
   247|         0|            0|            0|  0.00%|        for name in ('__repr__', '__str__', '__format__', '__reduce_ex__'):
   248|         0|            0|            0|  0.00%|            class_method = getattr(enum_class, name)
   249|         0|            0|            0|  0.00%|            obj_method = getattr(member_type, name, None)
   250|         0|            0|            0|  0.00%|            enum_method = getattr(first_enum, name, None)
   251|         0|            0|            0|  0.00%|            if obj_method is not None and obj_method is class_method:
   252|         0|            0|            0|  0.00%|                setattr(enum_class, name, enum_method)
   253|         0|            0|            0|  0.00%|
   254|         0|            0|            0|  0.00%|        # replace any other __new__ with our own (as long as Enum is not None,
   255|         0|            0|            0|  0.00%|        # anyway) -- again, this is to support pickle
   256|         0|            0|            0|  0.00%|        if Enum is not None:
   257|         0|            0|            0|  0.00%|            # if the user defined their own __new__, save it before it gets
   258|         0|            0|            0|  0.00%|            # clobbered in case they subclass later
   259|         0|            0|            0|  0.00%|            if save_new:
   260|         0|            0|            0|  0.00%|                enum_class.__new_member__ = __new__
   261|         0|            0|            0|  0.00%|            enum_class.__new__ = Enum.__new__
   262|         0|            0|            0|  0.00%|
   263|         0|            0|            0|  0.00%|        # py3 support for definition order (helps keep py2/py3 code in sync)
   264|         0|            0|            0|  0.00%|        if _order_ is not None:
   265|         0|            0|            0|  0.00%|            if isinstance(_order_, str):
   266|         0|            0|            0|  0.00%|                _order_ = _order_.replace(',', ' ').split()
   267|         0|            0|            0|  0.00%|            if _order_ != enum_class._member_names_:
   268|         0|            0|            0|  0.00%|                raise TypeError('member order does not match _order_')
   269|         0|            0|            0|  0.00%|
   270|         0|            0|            0|  0.00%|        return enum_class
   271|         0|            0|            0|  0.00%|
   272|         0|            0|            0|  0.00%|    def __bool__(self):
   273|         0|            0|            0|  0.00%|        """
   274|         0|            0|            0|  0.00%|        classes/types should always be True.
   275|         0|            0|            0|  0.00%|        """
   276|         0|            0|            0|  0.00%|        return True
   277|         0|            0|            0|  0.00%|
   278|         0|            0|            0|  0.00%|    def __call__(cls, value, names=None, *, module=None, qualname=None, type=None, start=1):
   279|         0|            0|            0|  0.00%|        """Either returns an existing member, or creates a new enum class.
   280|         0|            0|            0|  0.00%|
   281|         0|            0|            0|  0.00%|        This method is used both when an enum class is given a value to match
   282|         0|            0|            0|  0.00%|        to an enumeration member (i.e. Color(3)) and for the functional API
   283|         0|            0|            0|  0.00%|        (i.e. Color = Enum('Color', names='RED GREEN BLUE')).
   284|         0|            0|            0|  0.00%|
   285|         0|            0|            0|  0.00%|        When used for the functional API:
   286|         0|            0|            0|  0.00%|
   287|         0|            0|            0|  0.00%|        `value` will be the name of the new class.
   288|         0|            0|            0|  0.00%|
   289|         0|            0|            0|  0.00%|        `names` should be either a string of white-space/comma delimited names
   290|         0|            0|            0|  0.00%|        (values will start at `start`), or an iterator/mapping of name, value pairs.
   291|         0|            0|            0|  0.00%|
   292|         0|            0|            0|  0.00%|        `module` should be set to the module this class is being created in;
   293|         0|            0|            0|  0.00%|        if it is not set, an attempt to find that module will be made, but if
   294|         0|            0|            0|  0.00%|        it fails the class will not be picklable.
   295|         0|            0|            0|  0.00%|
   296|         0|            0|            0|  0.00%|        `qualname` should be set to the actual location this class can be found
   297|         0|            0|            0|  0.00%|        at in its module; by default it is set to the global scope.  If this is
   298|         0|            0|            0|  0.00%|        not correct, unpickling will fail in some circumstances.
   299|         0|            0|            0|  0.00%|
   300|         0|            0|            0|  0.00%|        `type`, if set, will be mixed in as the first base class.
   301|         0|            0|            0|  0.00%|
   302|         0|            0|            0|  0.00%|        """
   303|         0|            0|            0|  0.00%|        if names is None:  # simple value lookup
   304|         0|            0|            0|  0.00%|            return cls.__new__(cls, value)
   305|         0|            0|            0|  0.00%|        # otherwise, functional API: we're creating a new Enum type
   306|         0|            0|            0|  0.00%|        return cls._create_(value, names, module=module, qualname=qualname, type=type, start=start)
   307|         0|            0|            0|  0.00%|
   308|         0|            0|            0|  0.00%|    def __contains__(cls, member):
   309|         0|            0|            0|  0.00%|        if not isinstance(member, Enum):
   310|         0|            0|            0|  0.00%|            raise TypeError(
   311|         0|            0|            0|  0.00%|                "unsupported operand type(s) for 'in': '%s' and '%s'" % (
   312|         0|            0|            0|  0.00%|                    type(member).__qualname__, cls.__class__.__qualname__))
   313|         0|            0|            0|  0.00%|        return isinstance(member, cls) and member._name_ in cls._member_map_
   314|         0|            0|            0|  0.00%|
   315|         0|            0|            0|  0.00%|    def __delattr__(cls, attr):
   316|         0|            0|            0|  0.00%|        # nicer error message when someone tries to delete an attribute
   317|         0|            0|            0|  0.00%|        # (see issue19025).
   318|         0|            0|            0|  0.00%|        if attr in cls._member_map_:
   319|         0|            0|            0|  0.00%|            raise AttributeError(
   320|         0|            0|            0|  0.00%|                    "%s: cannot delete Enum member." % cls.__name__)
   321|         0|            0|            0|  0.00%|        super().__delattr__(attr)
   322|         0|            0|            0|  0.00%|
   323|         0|            0|            0|  0.00%|    def __dir__(self):
   324|         0|            0|            0|  0.00%|        return (['__class__', '__doc__', '__members__', '__module__'] +
   325|         0|            0|            0|  0.00%|                self._member_names_)
   326|         0|            0|            0|  0.00%|
   327|         0|            0|            0|  0.00%|    def __getattr__(cls, name):
   328|         0|            0|            0|  0.00%|        """Return the enum member matching `name`
   329|         0|            0|            0|  0.00%|
   330|         0|            0|            0|  0.00%|        We use __getattr__ instead of descriptors or inserting into the enum
   331|         0|            0|            0|  0.00%|        class' __dict__ in order to support `name` and `value` being both
   332|         0|            0|            0|  0.00%|        properties for enum members (which live in the class' __dict__) and
   333|         0|            0|            0|  0.00%|        enum members themselves.
   334|         0|            0|            0|  0.00%|
   335|         0|            0|            0|  0.00%|        """
   336|         0|            0|            0|  0.00%|        if _is_dunder(name):
   337|         0|            0|            0|  0.00%|            raise AttributeError(name)
   338|         0|            0|            0|  0.00%|        try:
   339|         0|            0|            0|  0.00%|            return cls._member_map_[name]
   340|         0|            0|            0|  0.00%|        except KeyError:
   341|         0|            0|            0|  0.00%|            raise AttributeError(name) from None
   342|         0|            0|            0|  0.00%|
   343|         1|  6.19888e-06|  6.19888e-06|  0.00%|    def __getitem__(cls, name):
   344|         1|  6.91414e-06|  6.91414e-06|  0.00%|        return cls._member_map_[name]
   345|         0|            0|            0|  0.00%|
   346|         2|  5.72205e-06|  2.86102e-06|  0.00%|    def __iter__(cls):
   347|        27|  5.43594e-05|  2.01331e-06|  0.00%|        return (cls._member_map_[name] for name in cls._member_names_)
   348|         0|            0|            0|  0.00%|
   349|         2|  4.52995e-06|  2.26498e-06|  0.00%|    def __len__(cls):
   350|         2|  4.76837e-06|  2.38419e-06|  0.00%|        return len(cls._member_names_)
   351|         0|            0|            0|  0.00%|
   352|         0|            0|            0|  0.00%|    @property
   353|         0|            0|            0|  0.00%|    def __members__(cls):
   354|         0|            0|            0|  0.00%|        """Returns a mapping of member name->value.
   355|         0|            0|            0|  0.00%|
   356|         0|            0|            0|  0.00%|        This mapping lists all enum members, including aliases. Note that this
   357|         0|            0|            0|  0.00%|        is a read-only view of the internal mapping.
   358|         0|            0|            0|  0.00%|
   359|         0|            0|            0|  0.00%|        """
   360|         0|            0|            0|  0.00%|        return MappingProxyType(cls._member_map_)
   361|         0|            0|            0|  0.00%|
   362|         0|            0|            0|  0.00%|    def __repr__(cls):
   363|         0|            0|            0|  0.00%|        return "<enum %r>" % cls.__name__
   364|         0|            0|            0|  0.00%|
   365|         1|  4.05312e-06|  4.05312e-06|  0.00%|    def __reversed__(cls):
   366|        14|  3.24249e-05|  2.31607e-06|  0.00%|        return (cls._member_map_[name] for name in reversed(cls._member_names_))
   367|         0|            0|            0|  0.00%|
   368|         0|            0|            0|  0.00%|    def __setattr__(cls, name, value):
   369|         0|            0|            0|  0.00%|        """Block attempts to reassign Enum members.
   370|         0|            0|            0|  0.00%|
   371|         0|            0|            0|  0.00%|        A simple assignment to the class namespace only changes one of the
   372|         0|            0|            0|  0.00%|        several possible ways to get an Enum member from the Enum class,
   373|         0|            0|            0|  0.00%|        resulting in an inconsistent Enumeration.
   374|         0|            0|            0|  0.00%|
   375|         0|            0|            0|  0.00%|        """
   376|         0|            0|            0|  0.00%|        member_map = cls.__dict__.get('_member_map_', {})
   377|         0|            0|            0|  0.00%|        if name in member_map:
   378|         0|            0|            0|  0.00%|            raise AttributeError('Cannot reassign members.')
   379|         0|            0|            0|  0.00%|        super().__setattr__(name, value)
   380|         0|            0|            0|  0.00%|
   381|         0|            0|            0|  0.00%|    def _create_(cls, class_name, names, *, module=None, qualname=None, type=None, start=1):
   382|         0|            0|            0|  0.00%|        """Convenience method to create a new Enum class.
   383|         0|            0|            0|  0.00%|
   384|         0|            0|            0|  0.00%|        `names` can be:
   385|         0|            0|            0|  0.00%|
   386|         0|            0|            0|  0.00%|        * A string containing member names, separated either with spaces or
   387|         0|            0|            0|  0.00%|          commas.  Values are incremented by 1 from `start`.
   388|         0|            0|            0|  0.00%|        * An iterable of member names.  Values are incremented by 1 from `start`.
   389|         0|            0|            0|  0.00%|        * An iterable of (member name, value) pairs.
   390|         0|            0|            0|  0.00%|        * A mapping of member name -> value pairs.
   391|         0|            0|            0|  0.00%|
   392|         0|            0|            0|  0.00%|        """
   393|         0|            0|            0|  0.00%|        metacls = cls.__class__
   394|         0|            0|            0|  0.00%|        bases = (cls, ) if type is None else (type, cls)
   395|         0|            0|            0|  0.00%|        _, first_enum = cls._get_mixins_(bases)
   396|         0|            0|            0|  0.00%|        classdict = metacls.__prepare__(class_name, bases)
   397|         0|            0|            0|  0.00%|
   398|         0|            0|            0|  0.00%|        # special processing needed for names?
   399|         0|            0|            0|  0.00%|        if isinstance(names, str):
   400|         0|            0|            0|  0.00%|            names = names.replace(',', ' ').split()
   401|         0|            0|            0|  0.00%|        if isinstance(names, (tuple, list)) and names and isinstance(names[0], str):
   402|         0|            0|            0|  0.00%|            original_names, names = names, []
   403|         0|            0|            0|  0.00%|            last_values = []
   404|         0|            0|            0|  0.00%|            for count, name in enumerate(original_names):
   405|         0|            0|            0|  0.00%|                value = first_enum._generate_next_value_(name, start, count, last_values[:])
   406|         0|            0|            0|  0.00%|                last_values.append(value)
   407|         0|            0|            0|  0.00%|                names.append((name, value))
   408|         0|            0|            0|  0.00%|
   409|         0|            0|            0|  0.00%|        # Here, names is either an iterable of (name, value) or a mapping.
   410|         0|            0|            0|  0.00%|        for item in names:
   411|         0|            0|            0|  0.00%|            if isinstance(item, str):
   412|         0|            0|            0|  0.00%|                member_name, member_value = item, names[item]
   413|         0|            0|            0|  0.00%|            else:
   414|         0|            0|            0|  0.00%|                member_name, member_value = item
   415|         0|            0|            0|  0.00%|            classdict[member_name] = member_value
   416|         0|            0|            0|  0.00%|        enum_class = metacls.__new__(metacls, class_name, bases, classdict)
   417|         0|            0|            0|  0.00%|
   418|         0|            0|            0|  0.00%|        # TODO: replace the frame hack if a blessed way to know the calling
   419|         0|            0|            0|  0.00%|        # module is ever developed
   420|         0|            0|            0|  0.00%|        if module is None:
   421|         0|            0|            0|  0.00%|            try:
   422|         0|            0|            0|  0.00%|                module = sys._getframe(2).f_globals['__name__']
   423|         0|            0|            0|  0.00%|            except (AttributeError, ValueError, KeyError) as exc:
   424|         0|            0|            0|  0.00%|                pass
   425|         0|            0|            0|  0.00%|        if module is None:
   426|         0|            0|            0|  0.00%|            _make_class_unpicklable(enum_class)
   427|         0|            0|            0|  0.00%|        else:
   428|         0|            0|            0|  0.00%|            enum_class.__module__ = module
   429|         0|            0|            0|  0.00%|        if qualname is not None:
   430|         0|            0|            0|  0.00%|            enum_class.__qualname__ = qualname
   431|         0|            0|            0|  0.00%|
   432|         0|            0|            0|  0.00%|        return enum_class
   433|         0|            0|            0|  0.00%|
   434|         0|            0|            0|  0.00%|    def _convert_(cls, name, module, filter, source=None):
   435|         0|            0|            0|  0.00%|        """
   436|         0|            0|            0|  0.00%|        Create a new Enum subclass that replaces a collection of global constants
   437|         0|            0|            0|  0.00%|        """
   438|         0|            0|            0|  0.00%|        # convert all constants from source (or module) that pass filter() to
   439|         0|            0|            0|  0.00%|        # a new Enum called name, and export the enum and its members back to
   440|         0|            0|            0|  0.00%|        # module;
   441|         0|            0|            0|  0.00%|        # also, replace the __reduce_ex__ method so unpickling works in
   442|         0|            0|            0|  0.00%|        # previous Python versions
   443|         0|            0|            0|  0.00%|        module_globals = vars(sys.modules[module])
   444|         0|            0|            0|  0.00%|        if source:
   445|         0|            0|            0|  0.00%|            source = vars(source)
   446|         0|            0|            0|  0.00%|        else:
   447|         0|            0|            0|  0.00%|            source = module_globals
   448|         0|            0|            0|  0.00%|        # _value2member_map_ is populated in the same order every time
   449|         0|            0|            0|  0.00%|        # for a consistent reverse mapping of number to name when there
   450|         0|            0|            0|  0.00%|        # are multiple names for the same number.
   451|         0|            0|            0|  0.00%|        members = [
   452|         0|            0|            0|  0.00%|                (name, value)
   453|         0|            0|            0|  0.00%|                for name, value in source.items()
   454|         0|            0|            0|  0.00%|                if filter(name)]
   455|         0|            0|            0|  0.00%|        try:
   456|         0|            0|            0|  0.00%|            # sort by value
   457|         0|            0|            0|  0.00%|            members.sort(key=lambda t: (t[1], t[0]))
   458|         0|            0|            0|  0.00%|        except TypeError:
   459|         0|            0|            0|  0.00%|            # unless some values aren't comparable, in which case sort by name
   460|         0|            0|            0|  0.00%|            members.sort(key=lambda t: t[0])
   461|         0|            0|            0|  0.00%|        cls = cls(name, members, module=module)
   462|         0|            0|            0|  0.00%|        cls.__reduce_ex__ = _reduce_ex_by_name
   463|         0|            0|            0|  0.00%|        module_globals.update(cls.__members__)
   464|         0|            0|            0|  0.00%|        module_globals[name] = cls
   465|         0|            0|            0|  0.00%|        return cls
   466|         0|            0|            0|  0.00%|
   467|         0|            0|            0|  0.00%|    def _convert(cls, *args, **kwargs):
   468|         0|            0|            0|  0.00%|        import warnings
   469|         0|            0|            0|  0.00%|        warnings.warn("_convert is deprecated and will be removed in 3.9, use "
   470|         0|            0|            0|  0.00%|                      "_convert_ instead.", DeprecationWarning, stacklevel=2)
   471|         0|            0|            0|  0.00%|        return cls._convert_(*args, **kwargs)
   472|         0|            0|            0|  0.00%|
   473|         0|            0|            0|  0.00%|    @staticmethod
   474|         0|            0|            0|  0.00%|    def _get_mixins_(bases):
   475|         0|            0|            0|  0.00%|        """Returns the type for creating enum members, and the first inherited
   476|         0|            0|            0|  0.00%|        enum class.
   477|         0|            0|            0|  0.00%|
   478|         0|            0|            0|  0.00%|        bases: the tuple of bases that was given to __new__
   479|         0|            0|            0|  0.00%|
   480|         0|            0|            0|  0.00%|        """
   481|         0|            0|            0|  0.00%|        if not bases:
   482|         0|            0|            0|  0.00%|            return object, Enum
   483|         0|            0|            0|  0.00%|
   484|         0|            0|            0|  0.00%|        def _find_data_type(bases):
   485|         0|            0|            0|  0.00%|            for chain in bases:
   486|         0|            0|            0|  0.00%|                for base in chain.__mro__:
   487|         0|            0|            0|  0.00%|                    if base is object:
   488|         0|            0|            0|  0.00%|                        continue
   489|         0|            0|            0|  0.00%|                    elif '__new__' in base.__dict__:
   490|         0|            0|            0|  0.00%|                        if issubclass(base, Enum):
   491|         0|            0|            0|  0.00%|                            continue
   492|         0|            0|            0|  0.00%|                        return base
   493|         0|            0|            0|  0.00%|
   494|         0|            0|            0|  0.00%|        # ensure final parent class is an Enum derivative, find any concrete
   495|         0|            0|            0|  0.00%|        # data type, and check that Enum has no members
   496|         0|            0|            0|  0.00%|        first_enum = bases[-1]
   497|         0|            0|            0|  0.00%|        if not issubclass(first_enum, Enum):
   498|         0|            0|            0|  0.00%|            raise TypeError("new enumerations should be created as "
   499|         0|            0|            0|  0.00%|                    "`EnumName([mixin_type, ...] [data_type,] enum_type)`")
   500|         0|            0|            0|  0.00%|        member_type = _find_data_type(bases) or object
   501|         0|            0|            0|  0.00%|        if first_enum._member_names_:
   502|         0|            0|            0|  0.00%|            raise TypeError("Cannot extend enumerations")
   503|         0|            0|            0|  0.00%|        return member_type, first_enum
   504|         0|            0|            0|  0.00%|
   505|         0|            0|            0|  0.00%|    @staticmethod
   506|         0|            0|            0|  0.00%|    def _find_new_(classdict, member_type, first_enum):
   507|         0|            0|            0|  0.00%|        """Returns the __new__ to be used for creating the enum members.
   508|         0|            0|            0|  0.00%|
   509|         0|            0|            0|  0.00%|        classdict: the class dictionary given to __new__
   510|         0|            0|            0|  0.00%|        member_type: the data type whose __new__ will be used by default
   511|         0|            0|            0|  0.00%|        first_enum: enumeration to check for an overriding __new__
   512|         0|            0|            0|  0.00%|
   513|         0|            0|            0|  0.00%|        """
   514|         0|            0|            0|  0.00%|        # now find the correct __new__, checking to see of one was defined
   515|         0|            0|            0|  0.00%|        # by the user; also check earlier enum classes in case a __new__ was
   516|         0|            0|            0|  0.00%|        # saved as __new_member__
   517|         0|            0|            0|  0.00%|        __new__ = classdict.get('__new__', None)
   518|         0|            0|            0|  0.00%|
   519|         0|            0|            0|  0.00%|        # should __new__ be saved as __new_member__ later?
   520|         0|            0|            0|  0.00%|        save_new = __new__ is not None
   521|         0|            0|            0|  0.00%|
   522|         0|            0|            0|  0.00%|        if __new__ is None:
   523|         0|            0|            0|  0.00%|            # check all possibles for __new_member__ before falling back to
   524|         0|            0|            0|  0.00%|            # __new__
   525|         0|            0|            0|  0.00%|            for method in ('__new_member__', '__new__'):
   526|         0|            0|            0|  0.00%|                for possible in (member_type, first_enum):
   527|         0|            0|            0|  0.00%|                    target = getattr(possible, method, None)
   528|         0|            0|            0|  0.00%|                    if target not in {
   529|         0|            0|            0|  0.00%|                            None,
   530|         0|            0|            0|  0.00%|                            None.__new__,
   531|         0|            0|            0|  0.00%|                            object.__new__,
   532|         0|            0|            0|  0.00%|                            Enum.__new__,
   533|         0|            0|            0|  0.00%|                            }:
   534|         0|            0|            0|  0.00%|                        __new__ = target
   535|         0|            0|            0|  0.00%|                        break
   536|         0|            0|            0|  0.00%|                if __new__ is not None:
   537|         0|            0|            0|  0.00%|                    break
   538|         0|            0|            0|  0.00%|            else:
   539|         0|            0|            0|  0.00%|                __new__ = object.__new__
   540|         0|            0|            0|  0.00%|
   541|         0|            0|            0|  0.00%|        # if a non-object.__new__ is used then whatever value/tuple was
   542|         0|            0|            0|  0.00%|        # assigned to the enum member name will be passed to __new__ and to the
   543|         0|            0|            0|  0.00%|        # new enum member's __init__
   544|         0|            0|            0|  0.00%|        if __new__ is object.__new__:
   545|         0|            0|            0|  0.00%|            use_args = False
   546|         0|            0|            0|  0.00%|        else:
   547|         0|            0|            0|  0.00%|            use_args = True
   548|         0|            0|            0|  0.00%|        return __new__, save_new, use_args
   549|         0|            0|            0|  0.00%|
   550|         0|            0|            0|  0.00%|
   551|         0|            0|            0|  0.00%|class Enum(metaclass=EnumMeta):
   552|         0|            0|            0|  0.00%|    """Generic enumeration.
   553|         0|            0|            0|  0.00%|
   554|         0|            0|            0|  0.00%|    Derive from this class to define new enumerations.
   555|         0|            0|            0|  0.00%|
   556|         0|            0|            0|  0.00%|    """
   557|         0|            0|            0|  0.00%|    def __new__(cls, value):
   558|         0|            0|            0|  0.00%|        # all enum instances are actually created during class construction
   559|         0|            0|            0|  0.00%|        # without calling this method; this method is called by the metaclass'
   560|         0|            0|            0|  0.00%|        # __call__ (i.e. Color(3) ), and by pickle
   561|         0|            0|            0|  0.00%|        if type(value) is cls:
   562|         0|            0|            0|  0.00%|            # For lookups like Color(Color.RED)
   563|         0|            0|            0|  0.00%|            return value
   564|         0|            0|            0|  0.00%|        # by-value search for a matching enum member
   565|         0|            0|            0|  0.00%|        # see if it's in the reverse mapping (for hashable values)
   566|         0|            0|            0|  0.00%|        try:
   567|         0|            0|            0|  0.00%|            return cls._value2member_map_[value]
   568|         0|            0|            0|  0.00%|        except KeyError:
   569|         0|            0|            0|  0.00%|            # Not found, no need to do long O(n) search
   570|         0|            0|            0|  0.00%|            pass
   571|         0|            0|            0|  0.00%|        except TypeError:
   572|         0|            0|            0|  0.00%|            # not there, now do long search -- O(n) behavior
   573|         0|            0|            0|  0.00%|            for member in cls._member_map_.values():
   574|         0|            0|            0|  0.00%|                if member._value_ == value:
   575|         0|            0|            0|  0.00%|                    return member
   576|         0|            0|            0|  0.00%|        # still not found -- try _missing_ hook
   577|         0|            0|            0|  0.00%|        try:
   578|         0|            0|            0|  0.00%|            exc = None
   579|         0|            0|            0|  0.00%|            result = cls._missing_(value)
   580|         0|            0|            0|  0.00%|        except Exception as e:
   581|         0|            0|            0|  0.00%|            exc = e
   582|         0|            0|            0|  0.00%|            result = None
   583|         0|            0|            0|  0.00%|        if isinstance(result, cls):
   584|         0|            0|            0|  0.00%|            return result
   585|         0|            0|            0|  0.00%|        else:
   586|         0|            0|            0|  0.00%|            ve_exc = ValueError("%r is not a valid %s" % (value, cls.__name__))
   587|         0|            0|            0|  0.00%|            if result is None and exc is None:
   588|         0|            0|            0|  0.00%|                raise ve_exc
   589|         0|            0|            0|  0.00%|            elif exc is None:
   590|         0|            0|            0|  0.00%|                exc = TypeError(
   591|         0|            0|            0|  0.00%|                        'error in %s._missing_: returned %r instead of None or a valid member'
   592|         0|            0|            0|  0.00%|                        % (cls.__name__, result)
   593|         0|            0|            0|  0.00%|                        )
   594|         0|            0|            0|  0.00%|            exc.__context__ = ve_exc
   595|         0|            0|            0|  0.00%|            raise exc
   596|         0|            0|            0|  0.00%|
   597|         0|            0|            0|  0.00%|    def _generate_next_value_(name, start, count, last_values):
   598|         0|            0|            0|  0.00%|        for last_value in reversed(last_values):
   599|         0|            0|            0|  0.00%|            try:
   600|         0|            0|            0|  0.00%|                return last_value + 1
   601|         0|            0|            0|  0.00%|            except TypeError:
   602|         0|            0|            0|  0.00%|                pass
   603|         0|            0|            0|  0.00%|        else:
   604|         0|            0|            0|  0.00%|            return start
   605|         0|            0|            0|  0.00%|
   606|         0|            0|            0|  0.00%|    @classmethod
   607|         0|            0|            0|  0.00%|    def _missing_(cls, value):
   608|         0|            0|            0|  0.00%|        raise ValueError("%r is not a valid %s" % (value, cls.__name__))
   609|         0|            0|            0|  0.00%|
   610|         0|            0|            0|  0.00%|    def __repr__(self):
   611|         0|            0|            0|  0.00%|        return "<%s.%s: %r>" % (
   612|         0|            0|            0|  0.00%|                self.__class__.__name__, self._name_, self._value_)
   613|         0|            0|            0|  0.00%|
   614|         0|            0|            0|  0.00%|    def __str__(self):
   615|         0|            0|            0|  0.00%|        return "%s.%s" % (self.__class__.__name__, self._name_)
   616|         0|            0|            0|  0.00%|
   617|         0|            0|            0|  0.00%|    def __dir__(self):
   618|         0|            0|            0|  0.00%|        added_behavior = [
   619|         0|            0|            0|  0.00%|                m
   620|         0|            0|            0|  0.00%|                for cls in self.__class__.mro()
   621|         0|            0|            0|  0.00%|                for m in cls.__dict__
   622|         0|            0|            0|  0.00%|                if m[0] != '_' and m not in self._member_map_
   623|         0|            0|            0|  0.00%|                ]
   624|         0|            0|            0|  0.00%|        return (['__class__', '__doc__', '__module__'] + added_behavior)
   625|         0|            0|            0|  0.00%|
   626|         0|            0|            0|  0.00%|    def __format__(self, format_spec):
   627|         0|            0|            0|  0.00%|        # mixed-in Enums should use the mixed-in type's __format__, otherwise
   628|         0|            0|            0|  0.00%|        # we can get strange results with the Enum name showing up instead of
   629|         0|            0|            0|  0.00%|        # the value
   630|         0|            0|            0|  0.00%|
   631|         0|            0|            0|  0.00%|        # pure Enum branch
   632|         0|            0|            0|  0.00%|        if self._member_type_ is object:
   633|         0|            0|            0|  0.00%|            cls = str
   634|         0|            0|            0|  0.00%|            val = str(self)
   635|         0|            0|            0|  0.00%|        # mix-in branch
   636|         0|            0|            0|  0.00%|        else:
   637|         0|            0|            0|  0.00%|            cls = self._member_type_
   638|         0|            0|            0|  0.00%|            val = self._value_
   639|         0|            0|            0|  0.00%|        return cls.__format__(val, format_spec)
   640|         0|            0|            0|  0.00%|
   641|         9|  1.38283e-05|  1.53648e-06|  0.00%|    def __hash__(self):
   642|         9|  1.64509e-05|  1.82788e-06|  0.00%|        return hash(self._name_)
   643|         0|            0|            0|  0.00%|
   644|         0|            0|            0|  0.00%|    def __reduce_ex__(self, proto):
   645|         0|            0|            0|  0.00%|        return self.__class__, (self._value_, )
   646|         0|            0|            0|  0.00%|
   647|         0|            0|            0|  0.00%|    # DynamicClassAttribute is used to provide access to the `name` and
   648|         0|            0|            0|  0.00%|    # `value` properties of enum members while keeping some measure of
   649|         0|            0|            0|  0.00%|    # protection from modification, while still allowing for an enumeration
   650|         0|            0|            0|  0.00%|    # to have members named `name` and `value`.  This works because enumeration
   651|         0|            0|            0|  0.00%|    # members are not set directly on the enum class -- __getattr__ is
   652|         0|            0|            0|  0.00%|    # used to look them up.
   653|         0|            0|            0|  0.00%|
   654|         0|            0|            0|  0.00%|    @DynamicClassAttribute
   655|         0|            0|            0|  0.00%|    def name(self):
   656|         0|            0|            0|  0.00%|        """The name of the Enum member."""
   657|         0|            0|            0|  0.00%|        return self._name_
   658|         0|            0|            0|  0.00%|
   659|         0|            0|            0|  0.00%|    @DynamicClassAttribute
   660|         0|            0|            0|  0.00%|    def value(self):
   661|         0|            0|            0|  0.00%|        """The value of the Enum member."""
   662|         0|            0|            0|  0.00%|        return self._value_
   663|         0|            0|            0|  0.00%|
   664|         0|            0|            0|  0.00%|
   665|         0|            0|            0|  0.00%|class IntEnum(int, Enum):
   666|         0|            0|            0|  0.00%|    """Enum where members are also (and must be) ints"""
   667|         0|            0|            0|  0.00%|
   668|         0|            0|            0|  0.00%|
   669|         0|            0|            0|  0.00%|def _reduce_ex_by_name(self, proto):
   670|         0|            0|            0|  0.00%|    return self.name
   671|         0|            0|            0|  0.00%|
   672|         0|            0|            0|  0.00%|class Flag(Enum):
   673|         0|            0|            0|  0.00%|    """Support for flags"""
   674|         0|            0|            0|  0.00%|
   675|         0|            0|            0|  0.00%|    def _generate_next_value_(name, start, count, last_values):
   676|         0|            0|            0|  0.00%|        """
   677|         0|            0|            0|  0.00%|        Generate the next value when not given.
   678|         0|            0|            0|  0.00%|
   679|         0|            0|            0|  0.00%|        name: the name of the member
   680|         0|            0|            0|  0.00%|        start: the initial start value or None
   681|         0|            0|            0|  0.00%|        count: the number of existing members
   682|         0|            0|            0|  0.00%|        last_value: the last value assigned or None
   683|         0|            0|            0|  0.00%|        """
   684|         0|            0|            0|  0.00%|        if not count:
   685|         0|            0|            0|  0.00%|            return start if start is not None else 1
   686|         0|            0|            0|  0.00%|        for last_value in reversed(last_values):
   687|         0|            0|            0|  0.00%|            try:
   688|         0|            0|            0|  0.00%|                high_bit = _high_bit(last_value)
   689|         0|            0|            0|  0.00%|                break
   690|         0|            0|            0|  0.00%|            except Exception:
   691|         0|            0|            0|  0.00%|                raise TypeError('Invalid Flag value: %r' % last_value) from None
   692|         0|            0|            0|  0.00%|        return 2 ** (high_bit+1)
   693|         0|            0|            0|  0.00%|
   694|         0|            0|            0|  0.00%|    @classmethod
   695|         0|            0|            0|  0.00%|    def _missing_(cls, value):
   696|         0|            0|            0|  0.00%|        original_value = value
   697|         0|            0|            0|  0.00%|        if value < 0:
   698|         0|            0|            0|  0.00%|            value = ~value
   699|         0|            0|            0|  0.00%|        possible_member = cls._create_pseudo_member_(value)
   700|         0|            0|            0|  0.00%|        if original_value < 0:
   701|         0|            0|            0|  0.00%|            possible_member = ~possible_member
   702|         0|            0|            0|  0.00%|        return possible_member
   703|         0|            0|            0|  0.00%|
   704|         0|            0|            0|  0.00%|    @classmethod
   705|         0|            0|            0|  0.00%|    def _create_pseudo_member_(cls, value):
   706|         0|            0|            0|  0.00%|        """
   707|         0|            0|            0|  0.00%|        Create a composite member iff value contains only members.
   708|         0|            0|            0|  0.00%|        """
   709|         0|            0|            0|  0.00%|        pseudo_member = cls._value2member_map_.get(value, None)
   710|         0|            0|            0|  0.00%|        if pseudo_member is None:
   711|         0|            0|            0|  0.00%|            # verify all bits are accounted for
   712|         0|            0|            0|  0.00%|            _, extra_flags = _decompose(cls, value)
   713|         0|            0|            0|  0.00%|            if extra_flags:
   714|         0|            0|            0|  0.00%|                raise ValueError("%r is not a valid %s" % (value, cls.__name__))
   715|         0|            0|            0|  0.00%|            # construct a singleton enum pseudo-member
   716|         0|            0|            0|  0.00%|            pseudo_member = object.__new__(cls)
   717|         0|            0|            0|  0.00%|            pseudo_member._name_ = None
   718|         0|            0|            0|  0.00%|            pseudo_member._value_ = value
   719|         0|            0|            0|  0.00%|            # use setdefault in case another thread already created a composite
   720|         0|            0|            0|  0.00%|            # with this value
   721|         0|            0|            0|  0.00%|            pseudo_member = cls._value2member_map_.setdefault(value, pseudo_member)
   722|         0|            0|            0|  0.00%|        return pseudo_member
   723|         0|            0|            0|  0.00%|
   724|         0|            0|            0|  0.00%|    def __contains__(self, other):
   725|         0|            0|            0|  0.00%|        if not isinstance(other, self.__class__):
   726|         0|            0|            0|  0.00%|            raise TypeError(
   727|         0|            0|            0|  0.00%|                "unsupported operand type(s) for 'in': '%s' and '%s'" % (
   728|         0|            0|            0|  0.00%|                    type(other).__qualname__, self.__class__.__qualname__))
   729|         0|            0|            0|  0.00%|        return other._value_ & self._value_ == other._value_
   730|         0|            0|            0|  0.00%|
   731|         0|            0|            0|  0.00%|    def __repr__(self):
   732|         0|            0|            0|  0.00%|        cls = self.__class__
   733|         0|            0|            0|  0.00%|        if self._name_ is not None:
   734|         0|            0|            0|  0.00%|            return '<%s.%s: %r>' % (cls.__name__, self._name_, self._value_)
   735|         0|            0|            0|  0.00%|        members, uncovered = _decompose(cls, self._value_)
   736|         0|            0|            0|  0.00%|        return '<%s.%s: %r>' % (
   737|         0|            0|            0|  0.00%|                cls.__name__,
   738|         0|            0|            0|  0.00%|                '|'.join([str(m._name_ or m._value_) for m in members]),
   739|         0|            0|            0|  0.00%|                self._value_,
   740|         0|            0|            0|  0.00%|                )
   741|         0|            0|            0|  0.00%|
   742|         0|            0|            0|  0.00%|    def __str__(self):
   743|         0|            0|            0|  0.00%|        cls = self.__class__
   744|         0|            0|            0|  0.00%|        if self._name_ is not None:
   745|         0|            0|            0|  0.00%|            return '%s.%s' % (cls.__name__, self._name_)
   746|         0|            0|            0|  0.00%|        members, uncovered = _decompose(cls, self._value_)
   747|         0|            0|            0|  0.00%|        if len(members) == 1 and members[0]._name_ is None:
   748|         0|            0|            0|  0.00%|            return '%s.%r' % (cls.__name__, members[0]._value_)
   749|         0|            0|            0|  0.00%|        else:
   750|         0|            0|            0|  0.00%|            return '%s.%s' % (
   751|         0|            0|            0|  0.00%|                    cls.__name__,
   752|         0|            0|            0|  0.00%|                    '|'.join([str(m._name_ or m._value_) for m in members]),
   753|         0|            0|            0|  0.00%|                    )
   754|         0|            0|            0|  0.00%|
   755|         0|            0|            0|  0.00%|    def __bool__(self):
   756|         0|            0|            0|  0.00%|        return bool(self._value_)
   757|         0|            0|            0|  0.00%|
   758|         0|            0|            0|  0.00%|    def __or__(self, other):
   759|         0|            0|            0|  0.00%|        if not isinstance(other, self.__class__):
   760|         0|            0|            0|  0.00%|            return NotImplemented
   761|         0|            0|            0|  0.00%|        return self.__class__(self._value_ | other._value_)
   762|         0|            0|            0|  0.00%|
   763|         0|            0|            0|  0.00%|    def __and__(self, other):
   764|         0|            0|            0|  0.00%|        if not isinstance(other, self.__class__):
   765|         0|            0|            0|  0.00%|            return NotImplemented
   766|         0|            0|            0|  0.00%|        return self.__class__(self._value_ & other._value_)
   767|         0|            0|            0|  0.00%|
   768|         0|            0|            0|  0.00%|    def __xor__(self, other):
   769|         0|            0|            0|  0.00%|        if not isinstance(other, self.__class__):
   770|         0|            0|            0|  0.00%|            return NotImplemented
   771|         0|            0|            0|  0.00%|        return self.__class__(self._value_ ^ other._value_)
   772|         0|            0|            0|  0.00%|
   773|         0|            0|            0|  0.00%|    def __invert__(self):
   774|         0|            0|            0|  0.00%|        members, uncovered = _decompose(self.__class__, self._value_)
   775|         0|            0|            0|  0.00%|        inverted = self.__class__(0)
   776|         0|            0|            0|  0.00%|        for m in self.__class__:
   777|         0|            0|            0|  0.00%|            if m not in members and not (m._value_ & self._value_):
   778|         0|            0|            0|  0.00%|                inverted = inverted | m
   779|         0|            0|            0|  0.00%|        return self.__class__(inverted)
   780|         0|            0|            0|  0.00%|
   781|         0|            0|            0|  0.00%|
   782|         0|            0|            0|  0.00%|class IntFlag(int, Flag):
   783|         0|            0|            0|  0.00%|    """Support for integer-based Flags"""
   784|         0|            0|            0|  0.00%|
   785|         0|            0|            0|  0.00%|    @classmethod
   786|         0|            0|            0|  0.00%|    def _missing_(cls, value):
   787|         0|            0|            0|  0.00%|        if not isinstance(value, int):
   788|         0|            0|            0|  0.00%|            raise ValueError("%r is not a valid %s" % (value, cls.__name__))
   789|         0|            0|            0|  0.00%|        new_member = cls._create_pseudo_member_(value)
   790|         0|            0|            0|  0.00%|        return new_member
   791|         0|            0|            0|  0.00%|
   792|         0|            0|            0|  0.00%|    @classmethod
   793|         0|            0|            0|  0.00%|    def _create_pseudo_member_(cls, value):
   794|         0|            0|            0|  0.00%|        pseudo_member = cls._value2member_map_.get(value, None)
   795|         0|            0|            0|  0.00%|        if pseudo_member is None:
   796|         0|            0|            0|  0.00%|            need_to_create = [value]
   797|         0|            0|            0|  0.00%|            # get unaccounted for bits
   798|         0|            0|            0|  0.00%|            _, extra_flags = _decompose(cls, value)
   799|         0|            0|            0|  0.00%|            # timer = 10
   800|         0|            0|            0|  0.00%|            while extra_flags:
   801|         0|            0|            0|  0.00%|                # timer -= 1
   802|         0|            0|            0|  0.00%|                bit = _high_bit(extra_flags)
   803|         0|            0|            0|  0.00%|                flag_value = 2 ** bit
   804|         0|            0|            0|  0.00%|                if (flag_value not in cls._value2member_map_ and
   805|         0|            0|            0|  0.00%|                        flag_value not in need_to_create
   806|         0|            0|            0|  0.00%|                        ):
   807|         0|            0|            0|  0.00%|                    need_to_create.append(flag_value)
   808|         0|            0|            0|  0.00%|                if extra_flags == -flag_value:
   809|         0|            0|            0|  0.00%|                    extra_flags = 0
   810|         0|            0|            0|  0.00%|                else:
   811|         0|            0|            0|  0.00%|                    extra_flags ^= flag_value
   812|         0|            0|            0|  0.00%|            for value in reversed(need_to_create):
   813|         0|            0|            0|  0.00%|                # construct singleton pseudo-members
   814|         0|            0|            0|  0.00%|                pseudo_member = int.__new__(cls, value)
   815|         0|            0|            0|  0.00%|                pseudo_member._name_ = None
   816|         0|            0|            0|  0.00%|                pseudo_member._value_ = value
   817|         0|            0|            0|  0.00%|                # use setdefault in case another thread already created a composite
   818|         0|            0|            0|  0.00%|                # with this value
   819|         0|            0|            0|  0.00%|                pseudo_member = cls._value2member_map_.setdefault(value, pseudo_member)
   820|         0|            0|            0|  0.00%|        return pseudo_member
   821|         0|            0|            0|  0.00%|
   822|         0|            0|            0|  0.00%|    def __or__(self, other):
   823|         0|            0|            0|  0.00%|        if not isinstance(other, (self.__class__, int)):
   824|         0|            0|            0|  0.00%|            return NotImplemented
   825|         0|            0|            0|  0.00%|        result = self.__class__(self._value_ | self.__class__(other)._value_)
   826|         0|            0|            0|  0.00%|        return result
   827|         0|            0|            0|  0.00%|
   828|         0|            0|            0|  0.00%|    def __and__(self, other):
   829|         0|            0|            0|  0.00%|        if not isinstance(other, (self.__class__, int)):
   830|         0|            0|            0|  0.00%|            return NotImplemented
   831|         0|            0|            0|  0.00%|        return self.__class__(self._value_ & self.__class__(other)._value_)
   832|         0|            0|            0|  0.00%|
   833|         0|            0|            0|  0.00%|    def __xor__(self, other):
   834|         0|            0|            0|  0.00%|        if not isinstance(other, (self.__class__, int)):
   835|         0|            0|            0|  0.00%|            return NotImplemented
   836|         0|            0|            0|  0.00%|        return self.__class__(self._value_ ^ self.__class__(other)._value_)
   837|         0|            0|            0|  0.00%|
   838|         0|            0|            0|  0.00%|    __ror__ = __or__
   839|         0|            0|            0|  0.00%|    __rand__ = __and__
   840|         0|            0|            0|  0.00%|    __rxor__ = __xor__
   841|         0|            0|            0|  0.00%|
   842|         0|            0|            0|  0.00%|    def __invert__(self):
   843|         0|            0|            0|  0.00%|        result = self.__class__(~self._value_)
   844|         0|            0|            0|  0.00%|        return result
   845|         0|            0|            0|  0.00%|
   846|         0|            0|            0|  0.00%|
   847|         0|            0|            0|  0.00%|def _high_bit(value):
   848|         0|            0|            0|  0.00%|    """returns index of highest bit, or -1 if value is zero or negative"""
   849|         0|            0|            0|  0.00%|    return value.bit_length() - 1
   850|         0|            0|            0|  0.00%|
   851|         0|            0|            0|  0.00%|def unique(enumeration):
   852|         0|            0|            0|  0.00%|    """Class decorator for enumerations ensuring unique member values."""
   853|         0|            0|            0|  0.00%|    duplicates = []
   854|         0|            0|            0|  0.00%|    for name, member in enumeration.__members__.items():
   855|         0|            0|            0|  0.00%|        if name != member.name:
   856|         0|            0|            0|  0.00%|            duplicates.append((name, member.name))
   857|         0|            0|            0|  0.00%|    if duplicates:
   858|         0|            0|            0|  0.00%|        alias_details = ', '.join(
   859|         0|            0|            0|  0.00%|                ["%s -> %s" % (alias, name) for (alias, name) in duplicates])
   860|         0|            0|            0|  0.00%|        raise ValueError('duplicate values found in %r: %s' %
   861|         0|            0|            0|  0.00%|                (enumeration, alias_details))
   862|         0|            0|            0|  0.00%|    return enumeration
   863|         0|            0|            0|  0.00%|
   864|         0|            0|            0|  0.00%|def _decompose(flag, value):
   865|         0|            0|            0|  0.00%|    """Extract all members from the value."""
   866|         0|            0|            0|  0.00%|    # _decompose is only called if the value is not named
   867|         0|            0|            0|  0.00%|    not_covered = value
   868|         0|            0|            0|  0.00%|    negative = value < 0
   869|         0|            0|            0|  0.00%|    # issue29167: wrap accesses to _value2member_map_ in a list to avoid race
   870|         0|            0|            0|  0.00%|    #             conditions between iterating over it and having more pseudo-
   871|         0|            0|            0|  0.00%|    #             members added to it
   872|         0|            0|            0|  0.00%|    if negative:
   873|         0|            0|            0|  0.00%|        # only check for named flags
   874|         0|            0|            0|  0.00%|        flags_to_check = [
   875|         0|            0|            0|  0.00%|                (m, v)
   876|         0|            0|            0|  0.00%|                for v, m in list(flag._value2member_map_.items())
   877|         0|            0|            0|  0.00%|                if m.name is not None
   878|         0|            0|            0|  0.00%|                ]
   879|         0|            0|            0|  0.00%|    else:
   880|         0|            0|            0|  0.00%|        # check for named flags and powers-of-two flags
   881|         0|            0|            0|  0.00%|        flags_to_check = [
   882|         0|            0|            0|  0.00%|                (m, v)
   883|         0|            0|            0|  0.00%|                for v, m in list(flag._value2member_map_.items())
   884|         0|            0|            0|  0.00%|                if m.name is not None or _power_of_two(v)
   885|         0|            0|            0|  0.00%|                ]
   886|         0|            0|            0|  0.00%|    members = []
   887|         0|            0|            0|  0.00%|    for member, member_value in flags_to_check:
   888|         0|            0|            0|  0.00%|        if member_value and member_value & value == member_value:
   889|         0|            0|            0|  0.00%|            members.append(member)
   890|         0|            0|            0|  0.00%|            not_covered &= ~member_value
   891|         0|            0|            0|  0.00%|    if not members and value in flag._value2member_map_:
   892|         0|            0|            0|  0.00%|        members.append(flag._value2member_map_[value])
   893|         0|            0|            0|  0.00%|    members.sort(key=lambda m: m._value_, reverse=True)
   894|         0|            0|            0|  0.00%|    if len(members) > 1 and members[0].value == value:
   895|         0|            0|            0|  0.00%|        # we have the breakdown, don't need the value member itself
   896|         0|            0|            0|  0.00%|        members.pop(0)
   897|         0|            0|            0|  0.00%|    return members, not_covered
   898|         0|            0|            0|  0.00%|
   899|         0|            0|            0|  0.00%|def _power_of_two(value):
   900|         0|            0|            0|  0.00%|    if value < 1:
   901|         0|            0|            0|  0.00%|        return False
   902|         0|            0|            0|  0.00%|    return value == 2 ** _high_bit(value)
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/i18n.py
File duration: 9.84669e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|"""Activate, get and deactivate translations."""
     2|         0|            0|            0|  0.00%|import gettext as gettext_module
     3|         0|            0|            0|  0.00%|import os.path
     4|         0|            0|            0|  0.00%|from threading import local
     5|         0|            0|            0|  0.00%|
     6|         0|            0|            0|  0.00%|__all__ = ["activate", "deactivate", "thousands_separator"]
     7|         0|            0|            0|  0.00%|
     8|         0|            0|            0|  0.00%|_TRANSLATIONS = {None: gettext_module.NullTranslations()}
     9|         0|            0|            0|  0.00%|_CURRENT = local()
    10|         0|            0|            0|  0.00%|
    11|         0|            0|            0|  0.00%|
    12|         0|            0|            0|  0.00%|# Mapping of locale to thousands separator
    13|         0|            0|            0|  0.00%|_THOUSANDS_SEPARATOR = {
    14|         0|            0|            0|  0.00%|    "fr_FR": " ",
    15|         0|            0|            0|  0.00%|}
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|
    18|         0|            0|            0|  0.00%|def _get_default_locale_path():
    19|         0|            0|            0|  0.00%|    try:
    20|         0|            0|            0|  0.00%|        if __file__ is None:
    21|         0|            0|            0|  0.00%|            return None
    22|         0|            0|            0|  0.00%|        return os.path.join(os.path.dirname(__file__), "locale")
    23|         0|            0|            0|  0.00%|    except NameError:
    24|         0|            0|            0|  0.00%|        return None
    25|         0|            0|            0|  0.00%|
    26|         0|            0|            0|  0.00%|
    27|         3|  6.91414e-06|  2.30471e-06|  0.00%|def get_translation():
    28|         3|  5.48363e-06|  1.82788e-06|  0.00%|    try:
    29|         3|  1.23978e-05|  4.13259e-06|  0.00%|        return _TRANSLATIONS[_CURRENT.locale]
    30|         3|  6.91414e-06|  2.30471e-06|  0.00%|    except (AttributeError, KeyError):
    31|         3|   6.4373e-06|  2.14577e-06|  0.00%|        return _TRANSLATIONS[None]
    32|         0|            0|            0|  0.00%|
    33|         0|            0|            0|  0.00%|
    34|         0|            0|            0|  0.00%|def activate(locale, path=None):
    35|         0|            0|            0|  0.00%|    """Activate internationalisation.
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|    Set `locale` as current locale. Search for locale in directory `path`.
    38|         0|            0|            0|  0.00%|
    39|         0|            0|            0|  0.00%|    Args:
    40|         0|            0|            0|  0.00%|        locale (str): Language name, e.g. `en_GB`.
    41|         0|            0|            0|  0.00%|        path (str): Path to search for locales.
    42|         0|            0|            0|  0.00%|
    43|         0|            0|            0|  0.00%|    Returns:
    44|         0|            0|            0|  0.00%|        dict: Translations.
    45|         0|            0|            0|  0.00%|
    46|         0|            0|            0|  0.00%|    Raises:
    47|         0|            0|            0|  0.00%|        Exception: If humanize cannot find the locale folder.
    48|         0|            0|            0|  0.00%|    """
    49|         0|            0|            0|  0.00%|    if path is None:
    50|         0|            0|            0|  0.00%|        path = _get_default_locale_path()
    51|         0|            0|            0|  0.00%|
    52|         0|            0|            0|  0.00%|    if path is None:
    53|         0|            0|            0|  0.00%|        raise Exception(
    54|         0|            0|            0|  0.00%|            "Humanize cannot determinate the default location of the 'locale' folder. "
    55|         0|            0|            0|  0.00%|            "You need to pass the path explicitly."
    56|         0|            0|            0|  0.00%|        )
    57|         0|            0|            0|  0.00%|    if locale not in _TRANSLATIONS:
    58|         0|            0|            0|  0.00%|        translation = gettext_module.translation("humanize", path, [locale])
    59|         0|            0|            0|  0.00%|        _TRANSLATIONS[locale] = translation
    60|         0|            0|            0|  0.00%|    _CURRENT.locale = locale
    61|         0|            0|            0|  0.00%|    return _TRANSLATIONS[locale]
    62|         0|            0|            0|  0.00%|
    63|         0|            0|            0|  0.00%|
    64|         0|            0|            0|  0.00%|def deactivate():
    65|         0|            0|            0|  0.00%|    """Deactivate internationalisation."""
    66|         0|            0|            0|  0.00%|    _CURRENT.locale = None
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|
    69|         1|  5.00679e-06|  5.00679e-06|  0.00%|def _gettext(message):
    70|         0|            0|            0|  0.00%|    """Get translation.
    71|         0|            0|            0|  0.00%|
    72|         0|            0|            0|  0.00%|    Args:
    73|         0|            0|            0|  0.00%|        message (str): Text to translate.
    74|         0|            0|            0|  0.00%|
    75|         0|            0|            0|  0.00%|    Returns:
    76|         0|            0|            0|  0.00%|        str: Translated text.
    77|         0|            0|            0|  0.00%|    """
    78|         1|  1.28746e-05|  1.28746e-05|  0.00%|    return get_translation().gettext(message)
(call)|         1|  9.53674e-06|  9.53674e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/i18n.py:27 get_translation
(call)|         1|  7.39098e-06|  7.39098e-06|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/gettext.py:272 gettext
    79|         0|            0|            0|  0.00%|
    80|         0|            0|            0|  0.00%|
    81|         0|            0|            0|  0.00%|def _pgettext(msgctxt, message):
    82|         0|            0|            0|  0.00%|    """Fetches a particular translation.
    83|         0|            0|            0|  0.00%|
    84|         0|            0|            0|  0.00%|    It works with `msgctxt` .po modifiers and allows duplicate keys with different
    85|         0|            0|            0|  0.00%|    translations.
    86|         0|            0|            0|  0.00%|
    87|         0|            0|            0|  0.00%|    Args:
    88|         0|            0|            0|  0.00%|        msgctxt (str): Context of the translation.
    89|         0|            0|            0|  0.00%|        message (str): Text to translate.
    90|         0|            0|            0|  0.00%|
    91|         0|            0|            0|  0.00%|    Returns:
    92|         0|            0|            0|  0.00%|        str: Translated text.
    93|         0|            0|            0|  0.00%|    """
    94|         0|            0|            0|  0.00%|    # This GNU gettext function was added in Python 3.8, so for older versions we
    95|         0|            0|            0|  0.00%|    # reimplement it. It works by joining `msgctx` and `message` by '4' byte.
    96|         0|            0|            0|  0.00%|    try:
    97|         0|            0|            0|  0.00%|        # Python 3.8+
    98|         0|            0|            0|  0.00%|        return get_translation().pgettext(msgctxt, message)
    99|         0|            0|            0|  0.00%|    except AttributeError:
   100|         0|            0|            0|  0.00%|        # Python 3.7 and older
   101|         0|            0|            0|  0.00%|        key = msgctxt + "\x04" + message
   102|         0|            0|            0|  0.00%|        translation = get_translation().gettext(key)
   103|         0|            0|            0|  0.00%|        return message if translation == key else translation
   104|         0|            0|            0|  0.00%|
   105|         0|            0|            0|  0.00%|
   106|         2|  7.86781e-06|  3.93391e-06|  0.00%|def _ngettext(message, plural, num):
   107|         0|            0|            0|  0.00%|    """Plural version of _gettext.
   108|         0|            0|            0|  0.00%|
   109|         0|            0|            0|  0.00%|    Args:
   110|         0|            0|            0|  0.00%|        message (str): Singular text to translate.
   111|         0|            0|            0|  0.00%|        plural (str): Plural text to translate.
   112|         0|            0|            0|  0.00%|        num (str): The number (e.g. item count) to determine translation for the
   113|         0|            0|            0|  0.00%|            respective grammatical number.
   114|         0|            0|            0|  0.00%|
   115|         0|            0|            0|  0.00%|    Returns:
   116|         0|            0|            0|  0.00%|        str: Translated text.
   117|         0|            0|            0|  0.00%|    """
   118|         2|  3.45707e-05|  1.72853e-05|  0.00%|    return get_translation().ngettext(message, plural, num)
(call)|         2|  2.86102e-05|  1.43051e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/humanize/i18n.py:27 get_translation
(call)|         2|  2.12193e-05|  1.06096e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/gettext.py:290 ngettext
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|
   121|         0|            0|            0|  0.00%|def _gettext_noop(message):
   122|         0|            0|            0|  0.00%|    """Mark a string as a translation string without translating it.
   123|         0|            0|            0|  0.00%|
   124|         0|            0|            0|  0.00%|    Example usage:
   125|         0|            0|            0|  0.00%|    ```python
   126|         0|            0|            0|  0.00%|    CONSTANTS = [_gettext_noop('first'), _gettext_noop('second')]
   127|         0|            0|            0|  0.00%|    def num_name(n):
   128|         0|            0|            0|  0.00%|        return _gettext(CONSTANTS[n])
   129|         0|            0|            0|  0.00%|    ```
   130|         0|            0|            0|  0.00%|
   131|         0|            0|            0|  0.00%|    Args:
   132|         0|            0|            0|  0.00%|        message (str): Text to translate in the future.
   133|         0|            0|            0|  0.00%|
   134|         0|            0|            0|  0.00%|    Returns:
   135|         0|            0|            0|  0.00%|        str: Original text, unchanged.
   136|         0|            0|            0|  0.00%|    """
   137|         0|            0|            0|  0.00%|    return message
   138|         0|            0|            0|  0.00%|
   139|         0|            0|            0|  0.00%|
   140|         0|            0|            0|  0.00%|def _ngettext_noop(singular, plural):
   141|         0|            0|            0|  0.00%|    """Mark two strings as pluralized translations without translating them.
   142|         0|            0|            0|  0.00%|
   143|         0|            0|            0|  0.00%|    Example usage:
   144|         0|            0|            0|  0.00%|    ```python
   145|         0|            0|            0|  0.00%|    CONSTANTS = [ngettext_noop('first', 'firsts'), ngettext_noop('second', 'seconds')]
   146|         0|            0|            0|  0.00%|    def num_name(n):
   147|         0|            0|            0|  0.00%|        return _ngettext(*CONSTANTS[n])
   148|         0|            0|            0|  0.00%|    ```
   149|         0|            0|            0|  0.00%|
   150|         0|            0|            0|  0.00%|    Args:
   151|         0|            0|            0|  0.00%|        singular (str): Singular text to translate in the future.
   152|         0|            0|            0|  0.00%|        plural (str): Plural text to translate in the future.
   153|         0|            0|            0|  0.00%|
   154|         0|            0|            0|  0.00%|    Returns:
   155|         0|            0|            0|  0.00%|        tuple: Original text, unchanged.
   156|         0|            0|            0|  0.00%|    """
   157|         0|            0|            0|  0.00%|    return (singular, plural)
   158|         0|            0|            0|  0.00%|
   159|         0|            0|            0|  0.00%|
   160|         0|            0|            0|  0.00%|def thousands_separator() -> str:
   161|         0|            0|            0|  0.00%|    """Return the thousands separator for a locale, default to comma.
   162|         0|            0|            0|  0.00%|
   163|         0|            0|            0|  0.00%|    Returns:
   164|         0|            0|            0|  0.00%|         str: Thousands separator.
   165|         0|            0|            0|  0.00%|    """
   166|         0|            0|            0|  0.00%|    try:
   167|         0|            0|            0|  0.00%|        sep = _THOUSANDS_SEPARATOR[_CURRENT.locale]
   168|         0|            0|            0|  0.00%|    except (AttributeError, KeyError):
   169|         0|            0|            0|  0.00%|        sep = ","
   170|         0|            0|            0|  0.00%|    return sep
File: /apps/open_spiel/open_spiel/python/rl_agent_policy.py
File duration: 9.25064e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|# Copyright 2019 DeepMind Technologies Limited
     2|         0|            0|            0|  0.00%|#
     3|         0|            0|            0|  0.00%|# Licensed under the Apache License, Version 2.0 (the "License");
     4|         0|            0|            0|  0.00%|# you may not use this file except in compliance with the License.
     5|         0|            0|            0|  0.00%|# You may obtain a copy of the License at
     6|         0|            0|            0|  0.00%|#
     7|         0|            0|            0|  0.00%|#      http://www.apache.org/licenses/LICENSE-2.0
     8|         0|            0|            0|  0.00%|#
     9|         0|            0|            0|  0.00%|# Unless required by applicable law or agreed to in writing, software
    10|         0|            0|            0|  0.00%|# distributed under the License is distributed on an "AS IS" BASIS,
    11|         0|            0|            0|  0.00%|# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    12|         0|            0|            0|  0.00%|# See the License for the specific language governing permissions and
    13|         0|            0|            0|  0.00%|# limitations under the License.
    14|         0|            0|            0|  0.00%|"""Joint policy denoted by the RL agents of a game."""
    15|         0|            0|            0|  0.00%|
    16|         0|            0|            0|  0.00%|from typing import Dict
    17|         0|            0|            0|  0.00%|
    18|         0|            0|            0|  0.00%|from open_spiel.python import policy
    19|         0|            0|            0|  0.00%|from open_spiel.python import rl_agent
    20|         0|            0|            0|  0.00%|from open_spiel.python import rl_environment
    21|         0|            0|            0|  0.00%|
    22|         0|            0|            0|  0.00%|
    23|         0|            0|            0|  0.00%|class JointRLAgentPolicy(policy.Policy):
    24|         0|            0|            0|  0.00%|  """Joint policy denoted by the RL agents of a game.
    25|         0|            0|            0|  0.00%|
    26|         0|            0|            0|  0.00%|  Given a list of RL agents of players for a game, this class can be used derive
    27|         0|            0|            0|  0.00%|  the corresponding (joint) policy. In particular, the distribution over
    28|         0|            0|            0|  0.00%|  possible actions will be those that are returned by the step() method of
    29|         0|            0|            0|  0.00%|  the RL agents given the state.
    30|         0|            0|            0|  0.00%|  """
    31|         0|            0|            0|  0.00%|
    32|         1|  3.57628e-06|  3.57628e-06|  0.00%|  def __init__(self, game, agents: Dict[int, rl_agent.AbstractAgent],
    33|         0|            0|            0|  0.00%|               use_observation: bool):
    34|         0|            0|            0|  0.00%|    """Initializes the joint RL agent policy.
    35|         0|            0|            0|  0.00%|
    36|         0|            0|            0|  0.00%|    Args:
    37|         0|            0|            0|  0.00%|      game: The game.
    38|         0|            0|            0|  0.00%|      agents: Dictionary of agents keyed by the player IDs.
    39|         0|            0|            0|  0.00%|      use_observation: If true then observation tensor will be used as the
    40|         0|            0|            0|  0.00%|        `info_state` in the step() calls; otherwise, information state tensor
    41|         0|            0|            0|  0.00%|        will be used. See `use_observation` property of
    42|         0|            0|            0|  0.00%|        rl_environment.Environment.
    43|         0|            0|            0|  0.00%|    """
    44|         1|  1.00136e-05|  1.00136e-05|  0.00%|    player_ids = list(sorted(agents.keys()))
    45|         1|  1.16825e-05|  1.16825e-05|  0.00%|    super().__init__(game, player_ids)
(call)|         1|  1.83582e-05|  1.83582e-05|  0.00%|# /apps/open_spiel/open_spiel/python/policy.py:109 __init__
    46|         1|  3.33786e-06|  3.33786e-06|  0.00%|    self._agents = agents
    47|         1|  3.33786e-06|  3.33786e-06|  0.00%|    self._obs = {
    48|         1|  1.97887e-05|  1.97887e-05|  0.00%|        "info_state": [None] * game.num_players(),
    49|         1|  5.24521e-06|  5.24521e-06|  0.00%|        "legal_actions": [None] * game.num_players()
    50|         0|            0|            0|  0.00%|    }
    51|         1|  3.09944e-06|  3.09944e-06|  0.00%|    self._use_observation = use_observation
    52|         0|            0|            0|  0.00%|
    53|         0|            0|            0|  0.00%|  def action_probabilities(self, state, player_id=None):
    54|         0|            0|            0|  0.00%|    if state.is_simultaneous_node():
    55|         0|            0|            0|  0.00%|      assert player_id is not None, "Player ID should be specified."
    56|         0|            0|            0|  0.00%|    else:
    57|         0|            0|            0|  0.00%|      if player_id is None:
    58|         0|            0|            0|  0.00%|        player_id = state.current_player()
    59|         0|            0|            0|  0.00%|      else:
    60|         0|            0|            0|  0.00%|        assert player_id == state.current_player()
    61|         0|            0|            0|  0.00%|
    62|         0|            0|            0|  0.00%|    # Make sure that player_id is an integer and not an enum as it is used to
    63|         0|            0|            0|  0.00%|    # index lists.
    64|         0|            0|            0|  0.00%|    player_id = int(player_id)
    65|         0|            0|            0|  0.00%|
    66|         0|            0|            0|  0.00%|    legal_actions = state.legal_actions(player_id)
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|    self._obs["current_player"] = player_id
    69|         0|            0|            0|  0.00%|    self._obs["info_state"][player_id] = (
    70|         0|            0|            0|  0.00%|        state.observation_tensor(player_id)
    71|         0|            0|            0|  0.00%|        if self._use_observation else state.information_state_tensor(player_id))
    72|         0|            0|            0|  0.00%|    self._obs["legal_actions"][player_id] = legal_actions
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|    info_state = rl_environment.TimeStep(observations=self._obs, rewards=None, discounts=None, step_type=None)
    75|         0|            0|            0|  0.00%|
    76|         0|            0|            0|  0.00%|    p = self._agents[player_id].step(info_state, is_evaluation=True).probs
    77|         0|            0|            0|  0.00%|    prob_dict = {action: p[action] for action in legal_actions}
    78|         0|            0|            0|  0.00%|
    79|         0|            0|            0|  0.00%|    return prob_dict
    80|         0|            0|            0|  0.00%|
    81|         0|            0|            0|  0.00%|  # UBC added
    82|         1|  3.09944e-06|  3.09944e-06|  0.00%|  def save(self):
    83|         1|  3.33786e-06|  3.33786e-06|  0.00%|    output = dict()
    84|         3|  8.82149e-06|   2.9405e-06|  0.00%|    for player, agent in self._agents.items():
    85|         2|  1.54972e-05|   7.7486e-06|  0.00%|        output[player] = agent.save()
(call)|         2|   0.00172448|  0.000862241|  0.00%|# /apps/open_spiel/open_spiel/python/pytorch/ppo.py:404 save
    86|         1|  1.66893e-06|  1.66893e-06|  0.00%|    return output
    87|         0|            0|            0|  0.00%|
    88|         0|            0|            0|  0.00%|  def restore(self, restore_dict):
    89|         0|            0|            0|  0.00%|    for player, agent in self._agents.items():
    90|         0|            0|            0|  0.00%|        agent.restore(restore_dict[player])
    91|         0|            0|            0|  0.00%|
    92|         0|            0|            0|  0.00%|
    93|         0|            0|            0|  0.00%|class RLAgentPolicy(JointRLAgentPolicy):
    94|         0|            0|            0|  0.00%|  """A policy for a specific agent trained in an RL environment."""
    95|         0|            0|            0|  0.00%|
    96|         0|            0|            0|  0.00%|  def __init__(self, game, agent: rl_agent.AbstractAgent, player_id: int,
    97|         0|            0|            0|  0.00%|               use_observation: bool):
    98|         0|            0|            0|  0.00%|    """Initializes the RL agent policy.
    99|         0|            0|            0|  0.00%|
   100|         0|            0|            0|  0.00%|    Args:
   101|         0|            0|            0|  0.00%|      game: The game.
   102|         0|            0|            0|  0.00%|      agent: RL agent.
   103|         0|            0|            0|  0.00%|      player_id: ID of the player.
   104|         0|            0|            0|  0.00%|      use_observation: See JointRLAgentPolicy above.
   105|         0|            0|            0|  0.00%|    """
   106|         0|            0|            0|  0.00%|    self._player_id = player_id
   107|         0|            0|            0|  0.00%|    super().__init__(game, {player_id: agent}, use_observation)
   108|         0|            0|            0|  0.00%|
   109|         0|            0|            0|  0.00%|  def action_probabilities(self, state, player_id=None):
   110|         0|            0|            0|  0.00%|    return super().action_probabilities(state, self._player_id if player_id is None else player_id)
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/absl/logging/__init__.py
File duration: 9.17912e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|# Copyright 2017 The Abseil Authors.
     2|         0|            0|            0|  0.00%|#
     3|         0|            0|            0|  0.00%|# Licensed under the Apache License, Version 2.0 (the "License");
     4|         0|            0|            0|  0.00%|# you may not use this file except in compliance with the License.
     5|         0|            0|            0|  0.00%|# You may obtain a copy of the License at
     6|         0|            0|            0|  0.00%|#
     7|         0|            0|            0|  0.00%|#      http://www.apache.org/licenses/LICENSE-2.0
     8|         0|            0|            0|  0.00%|#
     9|         0|            0|            0|  0.00%|# Unless required by applicable law or agreed to in writing, software
    10|         0|            0|            0|  0.00%|# distributed under the License is distributed on an "AS IS" BASIS,
    11|         0|            0|            0|  0.00%|# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    12|         0|            0|            0|  0.00%|# See the License for the specific language governing permissions and
    13|         0|            0|            0|  0.00%|# limitations under the License.
    14|         0|            0|            0|  0.00%|
    15|         0|            0|            0|  0.00%|"""Abseil Python logging module implemented on top of standard logging.
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|Simple usage:
    18|         0|            0|            0|  0.00%|
    19|         0|            0|            0|  0.00%|    from absl import logging
    20|         0|            0|            0|  0.00%|
    21|         0|            0|            0|  0.00%|    logging.info('Interesting Stuff')
    22|         0|            0|            0|  0.00%|    logging.info('Interesting Stuff with Arguments: %d', 42)
    23|         0|            0|            0|  0.00%|
    24|         0|            0|            0|  0.00%|    logging.set_verbosity(logging.INFO)
    25|         0|            0|            0|  0.00%|    logging.log(logging.DEBUG, 'This will *not* be printed')
    26|         0|            0|            0|  0.00%|    logging.set_verbosity(logging.DEBUG)
    27|         0|            0|            0|  0.00%|    logging.log(logging.DEBUG, 'This will be printed')
    28|         0|            0|            0|  0.00%|
    29|         0|            0|            0|  0.00%|    logging.warning('Worrying Stuff')
    30|         0|            0|            0|  0.00%|    logging.error('Alarming Stuff')
    31|         0|            0|            0|  0.00%|    logging.fatal('AAAAHHHHH!!!!')  # Process exits.
    32|         0|            0|            0|  0.00%|
    33|         0|            0|            0|  0.00%|Usage note: Do not pre-format the strings in your program code.
    34|         0|            0|            0|  0.00%|Instead, let the logging module perform argument interpolation.
    35|         0|            0|            0|  0.00%|This saves cycles because strings that don't need to be printed
    36|         0|            0|            0|  0.00%|are never formatted.  Note that this module does not attempt to
    37|         0|            0|            0|  0.00%|interpolate arguments when no arguments are given.  In other words
    38|         0|            0|            0|  0.00%|
    39|         0|            0|            0|  0.00%|    logging.info('Interesting Stuff: %s')
    40|         0|            0|            0|  0.00%|
    41|         0|            0|            0|  0.00%|does not raise an exception because logging.info() has only one
    42|         0|            0|            0|  0.00%|argument, the message string.
    43|         0|            0|            0|  0.00%|
    44|         0|            0|            0|  0.00%|"Lazy" evaluation for debugging:
    45|         0|            0|            0|  0.00%|
    46|         0|            0|            0|  0.00%|If you do something like this:
    47|         0|            0|            0|  0.00%|    logging.debug('Thing: %s', thing.ExpensiveOp())
    48|         0|            0|            0|  0.00%|then the ExpensiveOp will be evaluated even if nothing
    49|         0|            0|            0|  0.00%|is printed to the log. To avoid this, use the level_debug() function:
    50|         0|            0|            0|  0.00%|  if logging.level_debug():
    51|         0|            0|            0|  0.00%|    logging.debug('Thing: %s', thing.ExpensiveOp())
    52|         0|            0|            0|  0.00%|
    53|         0|            0|            0|  0.00%|Per file level logging is supported by logging.vlog() and
    54|         0|            0|            0|  0.00%|logging.vlog_is_on(). For example:
    55|         0|            0|            0|  0.00%|
    56|         0|            0|            0|  0.00%|    if logging.vlog_is_on(2):
    57|         0|            0|            0|  0.00%|      logging.vlog(2, very_expensive_debug_message())
    58|         0|            0|            0|  0.00%|
    59|         0|            0|            0|  0.00%|Notes on Unicode:
    60|         0|            0|            0|  0.00%|
    61|         0|            0|            0|  0.00%|The log output is encoded as UTF-8.  Don't pass data in other encodings in
    62|         0|            0|            0|  0.00%|bytes() instances -- instead pass unicode string instances when you need to
    63|         0|            0|            0|  0.00%|(for both the format string and arguments).
    64|         0|            0|            0|  0.00%|
    65|         0|            0|            0|  0.00%|Note on critical and fatal:
    66|         0|            0|            0|  0.00%|Standard logging module defines fatal as an alias to critical, but it's not
    67|         0|            0|            0|  0.00%|documented, and it does NOT actually terminate the program.
    68|         0|            0|            0|  0.00%|This module only defines fatal but not critical, and it DOES terminate the
    69|         0|            0|            0|  0.00%|program.
    70|         0|            0|            0|  0.00%|
    71|         0|            0|            0|  0.00%|The differences in behavior are historical and unfortunate.
    72|         0|            0|            0|  0.00%|"""
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|from __future__ import absolute_import
    75|         0|            0|            0|  0.00%|from __future__ import division
    76|         0|            0|            0|  0.00%|from __future__ import print_function
    77|         0|            0|            0|  0.00%|
    78|         0|            0|            0|  0.00%|import collections
    79|         0|            0|            0|  0.00%|import getpass
    80|         0|            0|            0|  0.00%|import io
    81|         0|            0|            0|  0.00%|import itertools
    82|         0|            0|            0|  0.00%|import logging
    83|         0|            0|            0|  0.00%|import os
    84|         0|            0|            0|  0.00%|import socket
    85|         0|            0|            0|  0.00%|import struct
    86|         0|            0|            0|  0.00%|import sys
    87|         0|            0|            0|  0.00%|import time
    88|         0|            0|            0|  0.00%|import timeit
    89|         0|            0|            0|  0.00%|import traceback
    90|         0|            0|            0|  0.00%|import types
    91|         0|            0|            0|  0.00%|import warnings
    92|         0|            0|            0|  0.00%|
    93|         0|            0|            0|  0.00%|from absl import flags
    94|         0|            0|            0|  0.00%|from absl._collections_abc import abc
    95|         0|            0|            0|  0.00%|from absl.logging import converter
    96|         0|            0|            0|  0.00%|import six
    97|         0|            0|            0|  0.00%|
    98|         0|            0|            0|  0.00%|if six.PY2:
    99|         0|            0|            0|  0.00%|  import thread as _thread_lib  # For .get_ident().
   100|         0|            0|            0|  0.00%|else:
   101|         0|            0|            0|  0.00%|  import threading as _thread_lib  # For .get_ident().
   102|         0|            0|            0|  0.00%|
   103|         0|            0|            0|  0.00%|try:
   104|         0|            0|            0|  0.00%|  from typing import NoReturn
   105|         0|            0|            0|  0.00%|except ImportError:
   106|         0|            0|            0|  0.00%|  pass
   107|         0|            0|            0|  0.00%|
   108|         0|            0|            0|  0.00%|
   109|         0|            0|            0|  0.00%|FLAGS = flags.FLAGS
   110|         0|            0|            0|  0.00%|
   111|         0|            0|            0|  0.00%|
   112|         0|            0|            0|  0.00%|# Logging levels.
   113|         0|            0|            0|  0.00%|FATAL = converter.ABSL_FATAL
   114|         0|            0|            0|  0.00%|ERROR = converter.ABSL_ERROR
   115|         0|            0|            0|  0.00%|WARNING = converter.ABSL_WARNING
   116|         0|            0|            0|  0.00%|WARN = converter.ABSL_WARNING  # Deprecated name.
   117|         0|            0|            0|  0.00%|INFO = converter.ABSL_INFO
   118|         0|            0|            0|  0.00%|DEBUG = converter.ABSL_DEBUG
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|# Regex to match/parse log line prefixes.
   121|         0|            0|            0|  0.00%|ABSL_LOGGING_PREFIX_REGEX = (
   122|         0|            0|            0|  0.00%|    r'^(?P<severity>[IWEF])'
   123|         0|            0|            0|  0.00%|    r'(?P<month>\d\d)(?P<day>\d\d) '
   124|         0|            0|            0|  0.00%|    r'(?P<hour>\d\d):(?P<minute>\d\d):(?P<second>\d\d)'
   125|         0|            0|            0|  0.00%|    r'\.(?P<microsecond>\d\d\d\d\d\d) +'
   126|         0|            0|            0|  0.00%|    r'(?P<thread_id>-?\d+) '
   127|         0|            0|            0|  0.00%|    r'(?P<filename>[a-zA-Z<][\w._<>-]+):(?P<line>\d+)')
   128|         0|            0|            0|  0.00%|
   129|         0|            0|            0|  0.00%|
   130|         0|            0|            0|  0.00%|# Mask to convert integer thread ids to unsigned quantities for logging purposes
   131|         0|            0|            0|  0.00%|_THREAD_ID_MASK = 2 ** (struct.calcsize('L') * 8) - 1
   132|         0|            0|            0|  0.00%|
   133|         0|            0|            0|  0.00%|# Extra property set on the LogRecord created by ABSLLogger when its level is
   134|         0|            0|            0|  0.00%|# CRITICAL/FATAL.
   135|         0|            0|            0|  0.00%|_ABSL_LOG_FATAL = '_absl_log_fatal'
   136|         0|            0|            0|  0.00%|# Extra prefix added to the log message when a non-absl logger logs a
   137|         0|            0|            0|  0.00%|# CRITICAL/FATAL message.
   138|         0|            0|            0|  0.00%|_CRITICAL_PREFIX = 'CRITICAL - '
   139|         0|            0|            0|  0.00%|
   140|         0|            0|            0|  0.00%|# Used by findCaller to skip callers from */logging/__init__.py.
   141|         0|            0|            0|  0.00%|_LOGGING_FILE_PREFIX = os.path.join('logging', '__init__.')
   142|         0|            0|            0|  0.00%|
   143|         0|            0|            0|  0.00%|# The ABSL logger instance, initialized in _initialize().
   144|         0|            0|            0|  0.00%|_absl_logger = None
   145|         0|            0|            0|  0.00%|# The ABSL handler instance, initialized in _initialize().
   146|         0|            0|            0|  0.00%|_absl_handler = None
   147|         0|            0|            0|  0.00%|
   148|         0|            0|            0|  0.00%|
   149|         0|            0|            0|  0.00%|_CPP_NAME_TO_LEVELS = {
   150|         0|            0|            0|  0.00%|    'debug': '0',  # Abseil C++ has no DEBUG level, mapping it to INFO here.
   151|         0|            0|            0|  0.00%|    'info': '0',
   152|         0|            0|            0|  0.00%|    'warning': '1',
   153|         0|            0|            0|  0.00%|    'warn': '1',
   154|         0|            0|            0|  0.00%|    'error': '2',
   155|         0|            0|            0|  0.00%|    'fatal': '3'
   156|         0|            0|            0|  0.00%|}
   157|         0|            0|            0|  0.00%|
   158|         0|            0|            0|  0.00%|_CPP_LEVEL_TO_NAMES = {
   159|         0|            0|            0|  0.00%|    '0': 'info',
   160|         0|            0|            0|  0.00%|    '1': 'warning',
   161|         0|            0|            0|  0.00%|    '2': 'error',
   162|         0|            0|            0|  0.00%|    '3': 'fatal',
   163|         0|            0|            0|  0.00%|}
   164|         0|            0|            0|  0.00%|
   165|         0|            0|            0|  0.00%|
   166|         0|            0|            0|  0.00%|class _VerbosityFlag(flags.Flag):
   167|         0|            0|            0|  0.00%|  """Flag class for -v/--verbosity."""
   168|         0|            0|            0|  0.00%|
   169|         0|            0|            0|  0.00%|  def __init__(self, *args, **kwargs):
   170|         0|            0|            0|  0.00%|    super(_VerbosityFlag, self).__init__(
   171|         0|            0|            0|  0.00%|        flags.IntegerParser(),
   172|         0|            0|            0|  0.00%|        flags.ArgumentSerializer(),
   173|         0|            0|            0|  0.00%|        *args, **kwargs)
   174|         0|            0|            0|  0.00%|
   175|         0|            0|            0|  0.00%|  @property
   176|         0|            0|            0|  0.00%|  def value(self):
   177|         0|            0|            0|  0.00%|    return self._value
   178|         0|            0|            0|  0.00%|
   179|         0|            0|            0|  0.00%|  @value.setter
   180|         0|            0|            0|  0.00%|  def value(self, v):
   181|         0|            0|            0|  0.00%|    self._value = v
   182|         0|            0|            0|  0.00%|    self._update_logging_levels()
   183|         0|            0|            0|  0.00%|
   184|         0|            0|            0|  0.00%|  def _update_logging_levels(self):
   185|         0|            0|            0|  0.00%|    """Updates absl logging levels to the current verbosity.
   186|         0|            0|            0|  0.00%|
   187|         0|            0|            0|  0.00%|    Visibility: module-private
   188|         0|            0|            0|  0.00%|    """
   189|         0|            0|            0|  0.00%|    if not _absl_logger:
   190|         0|            0|            0|  0.00%|      return
   191|         0|            0|            0|  0.00%|
   192|         0|            0|            0|  0.00%|    if self._value <= converter.ABSL_DEBUG:
   193|         0|            0|            0|  0.00%|      standard_verbosity = converter.absl_to_standard(self._value)
   194|         0|            0|            0|  0.00%|    else:
   195|         0|            0|            0|  0.00%|      # --verbosity is set to higher than 1 for vlog.
   196|         0|            0|            0|  0.00%|      standard_verbosity = logging.DEBUG - (self._value - 1)
   197|         0|            0|            0|  0.00%|
   198|         0|            0|            0|  0.00%|    # Also update root level when absl_handler is used.
   199|         0|            0|            0|  0.00%|    if _absl_handler in logging.root.handlers:
   200|         0|            0|            0|  0.00%|      # Make absl logger inherit from the root logger. absl logger might have
   201|         0|            0|            0|  0.00%|      # a non-NOTSET value if logging.set_verbosity() is called at import time.
   202|         0|            0|            0|  0.00%|      _absl_logger.setLevel(logging.NOTSET)
   203|         0|            0|            0|  0.00%|      logging.root.setLevel(standard_verbosity)
   204|         0|            0|            0|  0.00%|    else:
   205|         0|            0|            0|  0.00%|      _absl_logger.setLevel(standard_verbosity)
   206|         0|            0|            0|  0.00%|
   207|         0|            0|            0|  0.00%|
   208|         0|            0|            0|  0.00%|class _LoggerLevelsFlag(flags.Flag):
   209|         0|            0|            0|  0.00%|  """Flag class for --logger_levels."""
   210|         0|            0|            0|  0.00%|
   211|         0|            0|            0|  0.00%|  def __init__(self, *args, **kwargs):
   212|         0|            0|            0|  0.00%|    super(_LoggerLevelsFlag, self).__init__(
   213|         0|            0|            0|  0.00%|        _LoggerLevelsParser(),
   214|         0|            0|            0|  0.00%|        _LoggerLevelsSerializer(),
   215|         0|            0|            0|  0.00%|        *args, **kwargs)
   216|         0|            0|            0|  0.00%|
   217|         0|            0|            0|  0.00%|  @property
   218|         0|            0|            0|  0.00%|  def value(self):
   219|         0|            0|            0|  0.00%|    # For lack of an immutable type, be defensive and return a copy.
   220|         0|            0|            0|  0.00%|    # Modifications to the dict aren't supported and won't have any affect.
   221|         0|            0|            0|  0.00%|    # While Py3 could use MappingProxyType, that isn't deepcopy friendly, so
   222|         0|            0|            0|  0.00%|    # just return a copy.
   223|         0|            0|            0|  0.00%|    return self._value.copy()
   224|         0|            0|            0|  0.00%|
   225|         0|            0|            0|  0.00%|  @value.setter
   226|         0|            0|            0|  0.00%|  def value(self, v):
   227|         0|            0|            0|  0.00%|    self._value = {} if v is None else v
   228|         0|            0|            0|  0.00%|    self._update_logger_levels()
   229|         0|            0|            0|  0.00%|
   230|         0|            0|            0|  0.00%|  def _update_logger_levels(self):
   231|         0|            0|            0|  0.00%|    # Visibility: module-private.
   232|         0|            0|            0|  0.00%|    # This is called by absl.app.run() during initialization.
   233|         0|            0|            0|  0.00%|    for name, level in self._value.items():
   234|         0|            0|            0|  0.00%|      logging.getLogger(name).setLevel(level)
   235|         0|            0|            0|  0.00%|
   236|         0|            0|            0|  0.00%|
   237|         0|            0|            0|  0.00%|class _LoggerLevelsParser(flags.ArgumentParser):
   238|         0|            0|            0|  0.00%|  """Parser for --logger_levels flag."""
   239|         0|            0|            0|  0.00%|
   240|         0|            0|            0|  0.00%|  def parse(self, value):
   241|         0|            0|            0|  0.00%|    if isinstance(value, abc.Mapping):
   242|         0|            0|            0|  0.00%|      return value
   243|         0|            0|            0|  0.00%|
   244|         0|            0|            0|  0.00%|    pairs = [pair.strip() for pair in value.split(',') if pair.strip()]
   245|         0|            0|            0|  0.00%|
   246|         0|            0|            0|  0.00%|    # Preserve the order so that serialization is deterministic.
   247|         0|            0|            0|  0.00%|    levels = collections.OrderedDict()
   248|         0|            0|            0|  0.00%|    for name_level in pairs:
   249|         0|            0|            0|  0.00%|      name, level = name_level.split(':', 1)
   250|         0|            0|            0|  0.00%|      name = name.strip()
   251|         0|            0|            0|  0.00%|      level = level.strip()
   252|         0|            0|            0|  0.00%|      levels[name] = level
   253|         0|            0|            0|  0.00%|    return levels
   254|         0|            0|            0|  0.00%|
   255|         0|            0|            0|  0.00%|
   256|         0|            0|            0|  0.00%|class _LoggerLevelsSerializer(object):
   257|         0|            0|            0|  0.00%|  """Serializer for --logger_levels flag."""
   258|         0|            0|            0|  0.00%|
   259|         0|            0|            0|  0.00%|  def serialize(self, value):
   260|         0|            0|            0|  0.00%|    if isinstance(value, six.string_types):
   261|         0|            0|            0|  0.00%|      return value
   262|         0|            0|            0|  0.00%|    return ','.join(
   263|         0|            0|            0|  0.00%|        '{}:{}'.format(name, level) for name, level in value.items())
   264|         0|            0|            0|  0.00%|
   265|         0|            0|            0|  0.00%|
   266|         0|            0|            0|  0.00%|class _StderrthresholdFlag(flags.Flag):
   267|         0|            0|            0|  0.00%|  """Flag class for --stderrthreshold."""
   268|         0|            0|            0|  0.00%|
   269|         0|            0|            0|  0.00%|  def __init__(self, *args, **kwargs):
   270|         0|            0|            0|  0.00%|    super(_StderrthresholdFlag, self).__init__(
   271|         0|            0|            0|  0.00%|        flags.ArgumentParser(),
   272|         0|            0|            0|  0.00%|        flags.ArgumentSerializer(),
   273|         0|            0|            0|  0.00%|        *args, **kwargs)
   274|         0|            0|            0|  0.00%|
   275|         0|            0|            0|  0.00%|  @property
   276|         0|            0|            0|  0.00%|  def value(self):
   277|         0|            0|            0|  0.00%|    return self._value
   278|         0|            0|            0|  0.00%|
   279|         0|            0|            0|  0.00%|  @value.setter
   280|         0|            0|            0|  0.00%|  def value(self, v):
   281|         0|            0|            0|  0.00%|    if v in _CPP_LEVEL_TO_NAMES:
   282|         0|            0|            0|  0.00%|      # --stderrthreshold also accepts numberic strings whose values are
   283|         0|            0|            0|  0.00%|      # Abseil C++ log levels.
   284|         0|            0|            0|  0.00%|      cpp_value = int(v)
   285|         0|            0|            0|  0.00%|      v = _CPP_LEVEL_TO_NAMES[v]  # Normalize to strings.
   286|         0|            0|            0|  0.00%|    elif v.lower() in _CPP_NAME_TO_LEVELS:
   287|         0|            0|            0|  0.00%|      v = v.lower()
   288|         0|            0|            0|  0.00%|      if v == 'warn':
   289|         0|            0|            0|  0.00%|        v = 'warning'  # Use 'warning' as the canonical name.
   290|         0|            0|            0|  0.00%|      cpp_value = int(_CPP_NAME_TO_LEVELS[v])
   291|         0|            0|            0|  0.00%|    else:
   292|         0|            0|            0|  0.00%|      raise ValueError(
   293|         0|            0|            0|  0.00%|          '--stderrthreshold must be one of (case-insensitive) '
   294|         0|            0|            0|  0.00%|          "'debug', 'info', 'warning', 'error', 'fatal', "
   295|         0|            0|            0|  0.00%|          "or '0', '1', '2', '3', not '%s'" % v)
   296|         0|            0|            0|  0.00%|
   297|         0|            0|            0|  0.00%|    self._value = v
   298|         0|            0|            0|  0.00%|
   299|         0|            0|            0|  0.00%|
   300|         0|            0|            0|  0.00%|flags.DEFINE_boolean('logtostderr',
   301|         0|            0|            0|  0.00%|                     False,
   302|         0|            0|            0|  0.00%|                     'Should only log to stderr?', allow_override_cpp=True)
   303|         0|            0|            0|  0.00%|flags.DEFINE_boolean('alsologtostderr',
   304|         0|            0|            0|  0.00%|                     False,
   305|         0|            0|            0|  0.00%|                     'also log to stderr?', allow_override_cpp=True)
   306|         0|            0|            0|  0.00%|flags.DEFINE_string('log_dir',
   307|         0|            0|            0|  0.00%|                    os.getenv('TEST_TMPDIR', ''),
   308|         0|            0|            0|  0.00%|                    'directory to write logfiles into',
   309|         0|            0|            0|  0.00%|                    allow_override_cpp=True)
   310|         0|            0|            0|  0.00%|flags.DEFINE_flag(_VerbosityFlag(
   311|         0|            0|            0|  0.00%|    'verbosity', -1,
   312|         0|            0|            0|  0.00%|    'Logging verbosity level. Messages logged at this level or lower will '
   313|         0|            0|            0|  0.00%|    'be included. Set to 1 for debug logging. If the flag was not set or '
   314|         0|            0|            0|  0.00%|    'supplied, the value will be changed from the default of -1 (warning) to '
   315|         0|            0|            0|  0.00%|    '0 (info) after flags are parsed.',
   316|         0|            0|            0|  0.00%|    short_name='v', allow_hide_cpp=True))
   317|         0|            0|            0|  0.00%|flags.DEFINE_flag(
   318|         0|            0|            0|  0.00%|    _LoggerLevelsFlag(
   319|         0|            0|            0|  0.00%|        'logger_levels', {},
   320|         0|            0|            0|  0.00%|        'Specify log level of loggers. The format is a CSV list of '
   321|         0|            0|            0|  0.00%|        '`name:level`. Where `name` is the logger name used with '
   322|         0|            0|            0|  0.00%|        '`logging.getLogger()`, and `level` is a level name  (INFO, DEBUG, '
   323|         0|            0|            0|  0.00%|        'etc). e.g. `myapp.foo:INFO,other.logger:DEBUG`'))
   324|         0|            0|            0|  0.00%|flags.DEFINE_flag(_StderrthresholdFlag(
   325|         0|            0|            0|  0.00%|    'stderrthreshold', 'fatal',
   326|         0|            0|            0|  0.00%|    'log messages at this level, or more severe, to stderr in '
   327|         0|            0|            0|  0.00%|    'addition to the logfile.  Possible values are '
   328|         0|            0|            0|  0.00%|    "'debug', 'info', 'warning', 'error', and 'fatal'.  "
   329|         0|            0|            0|  0.00%|    'Obsoletes --alsologtostderr. Using --alsologtostderr '
   330|         0|            0|            0|  0.00%|    'cancels the effect of this flag. Please also note that '
   331|         0|            0|            0|  0.00%|    'this flag is subject to --verbosity and requires logfile '
   332|         0|            0|            0|  0.00%|    'not be stderr.', allow_hide_cpp=True))
   333|         0|            0|            0|  0.00%|flags.DEFINE_boolean('showprefixforinfo', True,
   334|         0|            0|            0|  0.00%|                     'If False, do not prepend prefix to info messages '
   335|         0|            0|            0|  0.00%|                     'when it\'s logged to stderr, '
   336|         0|            0|            0|  0.00%|                     '--verbosity is set to INFO level, '
   337|         0|            0|            0|  0.00%|                     'and python logging is used.')
   338|         0|            0|            0|  0.00%|
   339|         0|            0|            0|  0.00%|
   340|         0|            0|            0|  0.00%|def get_verbosity():
   341|         0|            0|            0|  0.00%|  """Returns the logging verbosity."""
   342|         0|            0|            0|  0.00%|  return FLAGS['verbosity'].value
   343|         0|            0|            0|  0.00%|
   344|         0|            0|            0|  0.00%|
   345|         0|            0|            0|  0.00%|def set_verbosity(v):
   346|         0|            0|            0|  0.00%|  """Sets the logging verbosity.
   347|         0|            0|            0|  0.00%|
   348|         0|            0|            0|  0.00%|  Causes all messages of level <= v to be logged,
   349|         0|            0|            0|  0.00%|  and all messages of level > v to be silently discarded.
   350|         0|            0|            0|  0.00%|
   351|         0|            0|            0|  0.00%|  Args:
   352|         0|            0|            0|  0.00%|    v: int|str, the verbosity level as an integer or string. Legal string values
   353|         0|            0|            0|  0.00%|        are those that can be coerced to an integer as well as case-insensitive
   354|         0|            0|            0|  0.00%|        'debug', 'info', 'warning', 'error', and 'fatal'.
   355|         0|            0|            0|  0.00%|  """
   356|         0|            0|            0|  0.00%|  try:
   357|         0|            0|            0|  0.00%|    new_level = int(v)
   358|         0|            0|            0|  0.00%|  except ValueError:
   359|         0|            0|            0|  0.00%|    new_level = converter.ABSL_NAMES[v.upper()]
   360|         0|            0|            0|  0.00%|  FLAGS.verbosity = new_level
   361|         0|            0|            0|  0.00%|
   362|         0|            0|            0|  0.00%|
   363|         0|            0|            0|  0.00%|def set_stderrthreshold(s):
   364|         0|            0|            0|  0.00%|  """Sets the stderr threshold to the value passed in.
   365|         0|            0|            0|  0.00%|
   366|         0|            0|            0|  0.00%|  Args:
   367|         0|            0|            0|  0.00%|    s: str|int, valid strings values are case-insensitive 'debug',
   368|         0|            0|            0|  0.00%|        'info', 'warning', 'error', and 'fatal'; valid integer values are
   369|         0|            0|            0|  0.00%|        logging.DEBUG|INFO|WARNING|ERROR|FATAL.
   370|         0|            0|            0|  0.00%|
   371|         0|            0|            0|  0.00%|  Raises:
   372|         0|            0|            0|  0.00%|      ValueError: Raised when s is an invalid value.
   373|         0|            0|            0|  0.00%|  """
   374|         0|            0|            0|  0.00%|  if s in converter.ABSL_LEVELS:
   375|         0|            0|            0|  0.00%|    FLAGS.stderrthreshold = converter.ABSL_LEVELS[s]
   376|         0|            0|            0|  0.00%|  elif isinstance(s, str) and s.upper() in converter.ABSL_NAMES:
   377|         0|            0|            0|  0.00%|    FLAGS.stderrthreshold = s
   378|         0|            0|            0|  0.00%|  else:
   379|         0|            0|            0|  0.00%|    raise ValueError(
   380|         0|            0|            0|  0.00%|        'set_stderrthreshold only accepts integer absl logging level '
   381|         0|            0|            0|  0.00%|        'from -3 to 1, or case-insensitive string values '
   382|         0|            0|            0|  0.00%|        "'debug', 'info', 'warning', 'error', and 'fatal'. "
   383|         0|            0|            0|  0.00%|        'But found "{}" ({}).'.format(s, type(s)))
   384|         0|            0|            0|  0.00%|
   385|         0|            0|            0|  0.00%|
   386|         0|            0|            0|  0.00%|def fatal(msg, *args, **kwargs):
   387|         0|            0|            0|  0.00%|  # type: (Any, Any, Any) -> NoReturn
   388|         0|            0|            0|  0.00%|  """Logs a fatal message."""
   389|         0|            0|            0|  0.00%|  log(FATAL, msg, *args, **kwargs)
   390|         0|            0|            0|  0.00%|
   391|         0|            0|            0|  0.00%|
   392|         0|            0|            0|  0.00%|def error(msg, *args, **kwargs):
   393|         0|            0|            0|  0.00%|  """Logs an error message."""
   394|         0|            0|            0|  0.00%|  log(ERROR, msg, *args, **kwargs)
   395|         0|            0|            0|  0.00%|
   396|         0|            0|            0|  0.00%|
   397|         0|            0|            0|  0.00%|def warning(msg, *args, **kwargs):
   398|         0|            0|            0|  0.00%|  """Logs a warning message."""
   399|         0|            0|            0|  0.00%|  log(WARNING, msg, *args, **kwargs)
   400|         0|            0|            0|  0.00%|
   401|         0|            0|            0|  0.00%|
   402|         0|            0|            0|  0.00%|if six.PY2:
   403|         0|            0|            0|  0.00%|  warn = warning  # Deprecated function.
   404|         0|            0|            0|  0.00%|else:
   405|         0|            0|            0|  0.00%|
   406|         0|            0|            0|  0.00%|  def warn(msg, *args, **kwargs):
   407|         0|            0|            0|  0.00%|    """Deprecated, use 'warning' instead."""
   408|         0|            0|            0|  0.00%|    warnings.warn("The 'warn' function is deprecated, use 'warning' instead",
   409|         0|            0|            0|  0.00%|                  DeprecationWarning, 2)
   410|         0|            0|            0|  0.00%|    log(WARNING, msg, *args, **kwargs)
   411|         0|            0|            0|  0.00%|
   412|         0|            0|            0|  0.00%|
   413|         1|  6.67572e-06|  6.67572e-06|  0.00%|def info(msg, *args, **kwargs):
   414|         0|            0|            0|  0.00%|  """Logs an info message."""
   415|         1|  1.33514e-05|  1.33514e-05|  0.00%|  log(INFO, msg, *args, **kwargs)
(call)|         1|  0.000133514|  0.000133514|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/absl/logging/__init__.py:531 log
   416|         0|            0|            0|  0.00%|
   417|         0|            0|            0|  0.00%|
   418|         0|            0|            0|  0.00%|def debug(msg, *args, **kwargs):
   419|         0|            0|            0|  0.00%|  """Logs a debug message."""
   420|         0|            0|            0|  0.00%|  log(DEBUG, msg, *args, **kwargs)
   421|         0|            0|            0|  0.00%|
   422|         0|            0|            0|  0.00%|
   423|         0|            0|            0|  0.00%|def exception(msg, *args):
   424|         0|            0|            0|  0.00%|  """Logs an exception, with traceback and message."""
   425|         0|            0|            0|  0.00%|  error(msg, *args, exc_info=True)
   426|         0|            0|            0|  0.00%|
   427|         0|            0|            0|  0.00%|
   428|         0|            0|            0|  0.00%|# Counter to keep track of number of log entries per token.
   429|         0|            0|            0|  0.00%|_log_counter_per_token = {}
   430|         0|            0|            0|  0.00%|
   431|         0|            0|            0|  0.00%|
   432|         0|            0|            0|  0.00%|def _get_next_log_count_per_token(token):
   433|         0|            0|            0|  0.00%|  """Wrapper for _log_counter_per_token. Thread-safe.
   434|         0|            0|            0|  0.00%|
   435|         0|            0|            0|  0.00%|  Args:
   436|         0|            0|            0|  0.00%|    token: The token for which to look up the count.
   437|         0|            0|            0|  0.00%|
   438|         0|            0|            0|  0.00%|  Returns:
   439|         0|            0|            0|  0.00%|    The number of times this function has been called with
   440|         0|            0|            0|  0.00%|    *token* as an argument (starting at 0).
   441|         0|            0|            0|  0.00%|  """
   442|         0|            0|            0|  0.00%|  # Can't use a defaultdict because defaultdict isn't atomic, whereas
   443|         0|            0|            0|  0.00%|  # setdefault is.
   444|         0|            0|            0|  0.00%|  return next(_log_counter_per_token.setdefault(token, itertools.count()))
   445|         0|            0|            0|  0.00%|
   446|         0|            0|            0|  0.00%|
   447|         0|            0|            0|  0.00%|def log_every_n(level, msg, n, *args):
   448|         0|            0|            0|  0.00%|  """Logs 'msg % args' at level 'level' once per 'n' times.
   449|         0|            0|            0|  0.00%|
   450|         0|            0|            0|  0.00%|  Logs the 1st call, (N+1)st call, (2N+1)st call,  etc.
   451|         0|            0|            0|  0.00%|  Not threadsafe.
   452|         0|            0|            0|  0.00%|
   453|         0|            0|            0|  0.00%|  Args:
   454|         0|            0|            0|  0.00%|    level: int, the absl logging level at which to log.
   455|         0|            0|            0|  0.00%|    msg: str, the message to be logged.
   456|         0|            0|            0|  0.00%|    n: int, the number of times this should be called before it is logged.
   457|         0|            0|            0|  0.00%|    *args: The args to be substituted into the msg.
   458|         0|            0|            0|  0.00%|  """
   459|         0|            0|            0|  0.00%|  count = _get_next_log_count_per_token(get_absl_logger().findCaller())
   460|         0|            0|            0|  0.00%|  log_if(level, msg, not (count % n), *args)
   461|         0|            0|            0|  0.00%|
   462|         0|            0|            0|  0.00%|
   463|         0|            0|            0|  0.00%|# Keeps track of the last log time of the given token.
   464|         0|            0|            0|  0.00%|# Note: must be a dict since set/get is atomic in CPython.
   465|         0|            0|            0|  0.00%|# Note: entries are never released as their number is expected to be low.
   466|         0|            0|            0|  0.00%|_log_timer_per_token = {}
   467|         0|            0|            0|  0.00%|
   468|         0|            0|            0|  0.00%|
   469|         0|            0|            0|  0.00%|def _seconds_have_elapsed(token, num_seconds):
   470|         0|            0|            0|  0.00%|  """Tests if 'num_seconds' have passed since 'token' was requested.
   471|         0|            0|            0|  0.00%|
   472|         0|            0|            0|  0.00%|  Not strictly thread-safe - may log with the wrong frequency if called
   473|         0|            0|            0|  0.00%|  concurrently from multiple threads. Accuracy depends on resolution of
   474|         0|            0|            0|  0.00%|  'timeit.default_timer()'.
   475|         0|            0|            0|  0.00%|
   476|         0|            0|            0|  0.00%|  Always returns True on the first call for a given 'token'.
   477|         0|            0|            0|  0.00%|
   478|         0|            0|            0|  0.00%|  Args:
   479|         0|            0|            0|  0.00%|    token: The token for which to look up the count.
   480|         0|            0|            0|  0.00%|    num_seconds: The number of seconds to test for.
   481|         0|            0|            0|  0.00%|
   482|         0|            0|            0|  0.00%|  Returns:
   483|         0|            0|            0|  0.00%|    Whether it has been >= 'num_seconds' since 'token' was last requested.
   484|         0|            0|            0|  0.00%|  """
   485|         0|            0|            0|  0.00%|  now = timeit.default_timer()
   486|         0|            0|            0|  0.00%|  then = _log_timer_per_token.get(token, None)
   487|         0|            0|            0|  0.00%|  if then is None or (now - then) >= num_seconds:
   488|         0|            0|            0|  0.00%|    _log_timer_per_token[token] = now
   489|         0|            0|            0|  0.00%|    return True
   490|         0|            0|            0|  0.00%|  else:
   491|         0|            0|            0|  0.00%|    return False
   492|         0|            0|            0|  0.00%|
   493|         0|            0|            0|  0.00%|
   494|         0|            0|            0|  0.00%|def log_every_n_seconds(level, msg, n_seconds, *args):
   495|         0|            0|            0|  0.00%|  """Logs 'msg % args' at level 'level' iff 'n_seconds' elapsed since last call.
   496|         0|            0|            0|  0.00%|
   497|         0|            0|            0|  0.00%|  Logs the first call, logs subsequent calls if 'n' seconds have elapsed since
   498|         0|            0|            0|  0.00%|  the last logging call from the same call site (file + line). Not thread-safe.
   499|         0|            0|            0|  0.00%|
   500|         0|            0|            0|  0.00%|  Args:
   501|         0|            0|            0|  0.00%|    level: int, the absl logging level at which to log.
   502|         0|            0|            0|  0.00%|    msg: str, the message to be logged.
   503|         0|            0|            0|  0.00%|    n_seconds: float or int, seconds which should elapse before logging again.
   504|         0|            0|            0|  0.00%|    *args: The args to be substituted into the msg.
   505|         0|            0|            0|  0.00%|  """
   506|         0|            0|            0|  0.00%|  should_log = _seconds_have_elapsed(get_absl_logger().findCaller(), n_seconds)
   507|         0|            0|            0|  0.00%|  log_if(level, msg, should_log, *args)
   508|         0|            0|            0|  0.00%|
   509|         0|            0|            0|  0.00%|
   510|         0|            0|            0|  0.00%|def log_first_n(level, msg, n, *args):
   511|         0|            0|            0|  0.00%|  """Logs 'msg % args' at level 'level' only first 'n' times.
   512|         0|            0|            0|  0.00%|
   513|         0|            0|            0|  0.00%|  Not threadsafe.
   514|         0|            0|            0|  0.00%|
   515|         0|            0|            0|  0.00%|  Args:
   516|         0|            0|            0|  0.00%|    level: int, the absl logging level at which to log.
   517|         0|            0|            0|  0.00%|    msg: str, the message to be logged.
   518|         0|            0|            0|  0.00%|    n: int, the maximal number of times the message is logged.
   519|         0|            0|            0|  0.00%|    *args: The args to be substituted into the msg.
   520|         0|            0|            0|  0.00%|  """
   521|         0|            0|            0|  0.00%|  count = _get_next_log_count_per_token(get_absl_logger().findCaller())
   522|         0|            0|            0|  0.00%|  log_if(level, msg, count < n, *args)
   523|         0|            0|            0|  0.00%|
   524|         0|            0|            0|  0.00%|
   525|         0|            0|            0|  0.00%|def log_if(level, msg, condition, *args):
   526|         0|            0|            0|  0.00%|  """Logs 'msg % args' at level 'level' only if condition is fulfilled."""
   527|         0|            0|            0|  0.00%|  if condition:
   528|         0|            0|            0|  0.00%|    log(level, msg, *args)
   529|         0|            0|            0|  0.00%|
   530|         0|            0|            0|  0.00%|
   531|         1|  6.67572e-06|  6.67572e-06|  0.00%|def log(level, msg, *args, **kwargs):
   532|         0|            0|            0|  0.00%|  """Logs 'msg % args' at absl logging level 'level'.
   533|         0|            0|            0|  0.00%|
   534|         0|            0|            0|  0.00%|  If no args are given just print msg, ignoring any interpolation specifiers.
   535|         0|            0|            0|  0.00%|
   536|         0|            0|            0|  0.00%|  Args:
   537|         0|            0|            0|  0.00%|    level: int, the absl logging level at which to log the message
   538|         0|            0|            0|  0.00%|        (logging.DEBUG|INFO|WARNING|ERROR|FATAL). While some C++ verbose logging
   539|         0|            0|            0|  0.00%|        level constants are also supported, callers should prefer explicit
   540|         0|            0|            0|  0.00%|        logging.vlog() calls for such purpose.
   541|         0|            0|            0|  0.00%|
   542|         0|            0|            0|  0.00%|    msg: str, the message to be logged.
   543|         0|            0|            0|  0.00%|    *args: The args to be substituted into the msg.
   544|         0|            0|            0|  0.00%|    **kwargs: May contain exc_info to add exception traceback to message.
   545|         0|            0|            0|  0.00%|  """
   546|         1|  4.05312e-06|  4.05312e-06|  0.00%|  if level > converter.ABSL_DEBUG:
   547|         0|            0|            0|  0.00%|    # Even though this function supports level that is greater than 1, users
   548|         0|            0|            0|  0.00%|    # should use logging.vlog instead for such cases.
   549|         0|            0|            0|  0.00%|    # Treat this as vlog, 1 is equivalent to DEBUG.
   550|         0|            0|            0|  0.00%|    standard_level = converter.STANDARD_DEBUG - (level - 1)
   551|         0|            0|            0|  0.00%|  else:
   552|         1|   3.8147e-06|   3.8147e-06|  0.00%|    if level < converter.ABSL_FATAL:
   553|         0|            0|            0|  0.00%|      level = converter.ABSL_FATAL
   554|         1|  1.28746e-05|  1.28746e-05|  0.00%|    standard_level = converter.absl_to_standard(level)
(call)|         1|   2.3365e-05|   2.3365e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/absl/logging/converter.py:138 absl_to_standard
   555|         0|            0|            0|  0.00%|
   556|         0|            0|            0|  0.00%|  # Match standard logging's behavior. Before use_absl_handler() and
   557|         0|            0|            0|  0.00%|  # logging is configured, there is no handler attached on _absl_logger nor
   558|         0|            0|            0|  0.00%|  # logging.root. So logs go no where.
   559|         1|  5.48363e-06|  5.48363e-06|  0.00%|  if not logging.root.handlers:
   560|         0|            0|            0|  0.00%|    logging.basicConfig()
   561|         0|            0|            0|  0.00%|
   562|         1|   1.3113e-05|   1.3113e-05|  0.00%|  _absl_logger.log(standard_level, msg, *args, **kwargs)
(call)|         1|  6.41346e-05|  6.41346e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/absl/logging/__init__.py:1118 log
   563|         0|            0|            0|  0.00%|
   564|         0|            0|            0|  0.00%|
   565|         0|            0|            0|  0.00%|def vlog(level, msg, *args, **kwargs):
   566|         0|            0|            0|  0.00%|  """Log 'msg % args' at C++ vlog level 'level'.
   567|         0|            0|            0|  0.00%|
   568|         0|            0|            0|  0.00%|  Args:
   569|         0|            0|            0|  0.00%|    level: int, the C++ verbose logging level at which to log the message,
   570|         0|            0|            0|  0.00%|        e.g. 1, 2, 3, 4... While absl level constants are also supported,
   571|         0|            0|            0|  0.00%|        callers should prefer logging.log|debug|info|... calls for such purpose.
   572|         0|            0|            0|  0.00%|    msg: str, the message to be logged.
   573|         0|            0|            0|  0.00%|    *args: The args to be substituted into the msg.
   574|         0|            0|            0|  0.00%|    **kwargs: May contain exc_info to add exception traceback to message.
   575|         0|            0|            0|  0.00%|  """
   576|         0|            0|            0|  0.00%|  log(level, msg, *args, **kwargs)
   577|         0|            0|            0|  0.00%|
   578|         0|            0|            0|  0.00%|
   579|         0|            0|            0|  0.00%|def vlog_is_on(level):
   580|         0|            0|            0|  0.00%|  """Checks if vlog is enabled for the given level in caller's source file.
   581|         0|            0|            0|  0.00%|
   582|         0|            0|            0|  0.00%|  Args:
   583|         0|            0|            0|  0.00%|    level: int, the C++ verbose logging level at which to log the message,
   584|         0|            0|            0|  0.00%|        e.g. 1, 2, 3, 4... While absl level constants are also supported,
   585|         0|            0|            0|  0.00%|        callers should prefer level_debug|level_info|... calls for
   586|         0|            0|            0|  0.00%|        checking those.
   587|         0|            0|            0|  0.00%|
   588|         0|            0|            0|  0.00%|  Returns:
   589|         0|            0|            0|  0.00%|    True if logging is turned on for that level.
   590|         0|            0|            0|  0.00%|  """
   591|         0|            0|            0|  0.00%|
   592|         0|            0|            0|  0.00%|  if level > converter.ABSL_DEBUG:
   593|         0|            0|            0|  0.00%|    # Even though this function supports level that is greater than 1, users
   594|         0|            0|            0|  0.00%|    # should use logging.vlog instead for such cases.
   595|         0|            0|            0|  0.00%|    # Treat this as vlog, 1 is equivalent to DEBUG.
   596|         0|            0|            0|  0.00%|    standard_level = converter.STANDARD_DEBUG - (level - 1)
   597|         0|            0|            0|  0.00%|  else:
   598|         0|            0|            0|  0.00%|    if level < converter.ABSL_FATAL:
   599|         0|            0|            0|  0.00%|      level = converter.ABSL_FATAL
   600|         0|            0|            0|  0.00%|    standard_level = converter.absl_to_standard(level)
   601|         0|            0|            0|  0.00%|  return _absl_logger.isEnabledFor(standard_level)
   602|         0|            0|            0|  0.00%|
   603|         0|            0|            0|  0.00%|
   604|         0|            0|            0|  0.00%|def flush():
   605|         0|            0|            0|  0.00%|  """Flushes all log files."""
   606|         0|            0|            0|  0.00%|  get_absl_handler().flush()
   607|         0|            0|            0|  0.00%|
   608|         0|            0|            0|  0.00%|
   609|         0|            0|            0|  0.00%|def level_debug():
   610|         0|            0|            0|  0.00%|  """Returns True if debug logging is turned on."""
   611|         0|            0|            0|  0.00%|  return get_verbosity() >= DEBUG
   612|         0|            0|            0|  0.00%|
   613|         0|            0|            0|  0.00%|
   614|         0|            0|            0|  0.00%|def level_info():
   615|         0|            0|            0|  0.00%|  """Returns True if info logging is turned on."""
   616|         0|            0|            0|  0.00%|  return get_verbosity() >= INFO
   617|         0|            0|            0|  0.00%|
   618|         0|            0|            0|  0.00%|
   619|         0|            0|            0|  0.00%|def level_warning():
   620|         0|            0|            0|  0.00%|  """Returns True if warning logging is turned on."""
   621|         0|            0|            0|  0.00%|  return get_verbosity() >= WARNING
   622|         0|            0|            0|  0.00%|
   623|         0|            0|            0|  0.00%|
   624|         0|            0|            0|  0.00%|level_warn = level_warning  # Deprecated function.
   625|         0|            0|            0|  0.00%|
   626|         0|            0|            0|  0.00%|
   627|         0|            0|            0|  0.00%|def level_error():
   628|         0|            0|            0|  0.00%|  """Returns True if error logging is turned on."""
   629|         0|            0|            0|  0.00%|  return get_verbosity() >= ERROR
   630|         0|            0|            0|  0.00%|
   631|         0|            0|            0|  0.00%|
   632|         0|            0|            0|  0.00%|def get_log_file_name(level=INFO):
   633|         0|            0|            0|  0.00%|  """Returns the name of the log file.
   634|         0|            0|            0|  0.00%|
   635|         0|            0|            0|  0.00%|  For Python logging, only one file is used and level is ignored. And it returns
   636|         0|            0|            0|  0.00%|  empty string if it logs to stderr/stdout or the log stream has no `name`
   637|         0|            0|            0|  0.00%|  attribute.
   638|         0|            0|            0|  0.00%|
   639|         0|            0|            0|  0.00%|  Args:
   640|         0|            0|            0|  0.00%|    level: int, the absl.logging level.
   641|         0|            0|            0|  0.00%|
   642|         0|            0|            0|  0.00%|  Raises:
   643|         0|            0|            0|  0.00%|    ValueError: Raised when `level` has an invalid value.
   644|         0|            0|            0|  0.00%|  """
   645|         0|            0|            0|  0.00%|  if level not in converter.ABSL_LEVELS:
   646|         0|            0|            0|  0.00%|    raise ValueError('Invalid absl.logging level {}'.format(level))
   647|         0|            0|            0|  0.00%|  stream = get_absl_handler().python_handler.stream
   648|         0|            0|            0|  0.00%|  if (stream == sys.stderr or stream == sys.stdout or
   649|         0|            0|            0|  0.00%|      not hasattr(stream, 'name')):
   650|         0|            0|            0|  0.00%|    return ''
   651|         0|            0|            0|  0.00%|  else:
   652|         0|            0|            0|  0.00%|    return stream.name
   653|         0|            0|            0|  0.00%|
   654|         0|            0|            0|  0.00%|
   655|         0|            0|            0|  0.00%|def find_log_dir_and_names(program_name=None, log_dir=None):
   656|         0|            0|            0|  0.00%|  """Computes the directory and filename prefix for log file.
   657|         0|            0|            0|  0.00%|
   658|         0|            0|            0|  0.00%|  Args:
   659|         0|            0|            0|  0.00%|    program_name: str|None, the filename part of the path to the program that
   660|         0|            0|            0|  0.00%|        is running without its extension.  e.g: if your program is called
   661|         0|            0|            0|  0.00%|        'usr/bin/foobar.py' this method should probably be called with
   662|         0|            0|            0|  0.00%|        program_name='foobar' However, this is just a convention, you can
   663|         0|            0|            0|  0.00%|        pass in any string you want, and it will be used as part of the
   664|         0|            0|            0|  0.00%|        log filename. If you don't pass in anything, the default behavior
   665|         0|            0|            0|  0.00%|        is as described in the example.  In python standard logging mode,
   666|         0|            0|            0|  0.00%|        the program_name will be prepended with py_ if it is the program_name
   667|         0|            0|            0|  0.00%|        argument is omitted.
   668|         0|            0|            0|  0.00%|    log_dir: str|None, the desired log directory.
   669|         0|            0|            0|  0.00%|
   670|         0|            0|            0|  0.00%|  Returns:
   671|         0|            0|            0|  0.00%|    (log_dir, file_prefix, symlink_prefix)
   672|         0|            0|            0|  0.00%|
   673|         0|            0|            0|  0.00%|  Raises:
   674|         0|            0|            0|  0.00%|    FileNotFoundError: raised in Python 3 when it cannot find a log directory.
   675|         0|            0|            0|  0.00%|    OSError: raised in Python 2 when it cannot find a log directory.
   676|         0|            0|            0|  0.00%|  """
   677|         0|            0|            0|  0.00%|  if not program_name:
   678|         0|            0|            0|  0.00%|    # Strip the extension (foobar.par becomes foobar, and
   679|         0|            0|            0|  0.00%|    # fubar.py becomes fubar). We do this so that the log
   680|         0|            0|            0|  0.00%|    # file names are similar to C++ log file names.
   681|         0|            0|            0|  0.00%|    program_name = os.path.splitext(os.path.basename(sys.argv[0]))[0]
   682|         0|            0|            0|  0.00%|
   683|         0|            0|            0|  0.00%|    # Prepend py_ to files so that python code gets a unique file, and
   684|         0|            0|            0|  0.00%|    # so that C++ libraries do not try to write to the same log files as us.
   685|         0|            0|            0|  0.00%|    program_name = 'py_%s' % program_name
   686|         0|            0|            0|  0.00%|
   687|         0|            0|            0|  0.00%|  actual_log_dir = find_log_dir(log_dir=log_dir)
   688|         0|            0|            0|  0.00%|
   689|         0|            0|            0|  0.00%|  try:
   690|         0|            0|            0|  0.00%|    username = getpass.getuser()
   691|         0|            0|            0|  0.00%|  except KeyError:
   692|         0|            0|            0|  0.00%|    # This can happen, e.g. when running under docker w/o passwd file.
   693|         0|            0|            0|  0.00%|    if hasattr(os, 'getuid'):
   694|         0|            0|            0|  0.00%|      # Windows doesn't have os.getuid
   695|         0|            0|            0|  0.00%|      username = str(os.getuid())
   696|         0|            0|            0|  0.00%|    else:
   697|         0|            0|            0|  0.00%|      username = 'unknown'
   698|         0|            0|            0|  0.00%|  hostname = socket.gethostname()
   699|         0|            0|            0|  0.00%|  file_prefix = '%s.%s.%s.log' % (program_name, hostname, username)
   700|         0|            0|            0|  0.00%|
   701|         0|            0|            0|  0.00%|  return actual_log_dir, file_prefix, program_name
   702|         0|            0|            0|  0.00%|
   703|         0|            0|            0|  0.00%|
   704|         0|            0|            0|  0.00%|def find_log_dir(log_dir=None):
   705|         0|            0|            0|  0.00%|  """Returns the most suitable directory to put log files into.
   706|         0|            0|            0|  0.00%|
   707|         0|            0|            0|  0.00%|  Args:
   708|         0|            0|            0|  0.00%|    log_dir: str|None, if specified, the logfile(s) will be created in that
   709|         0|            0|            0|  0.00%|        directory.  Otherwise if the --log_dir command-line flag is provided,
   710|         0|            0|            0|  0.00%|        the logfile will be created in that directory.  Otherwise the logfile
   711|         0|            0|            0|  0.00%|        will be created in a standard location.
   712|         0|            0|            0|  0.00%|
   713|         0|            0|            0|  0.00%|  Raises:
   714|         0|            0|            0|  0.00%|    FileNotFoundError: raised in Python 3 when it cannot find a log directory.
   715|         0|            0|            0|  0.00%|    OSError: raised in Python 2 when it cannot find a log directory.
   716|         0|            0|            0|  0.00%|  """
   717|         0|            0|            0|  0.00%|  # Get a list of possible log dirs (will try to use them in order).
   718|         0|            0|            0|  0.00%|  if log_dir:
   719|         0|            0|            0|  0.00%|    # log_dir was explicitly specified as an arg, so use it and it alone.
   720|         0|            0|            0|  0.00%|    dirs = [log_dir]
   721|         0|            0|            0|  0.00%|  elif FLAGS['log_dir'].value:
   722|         0|            0|            0|  0.00%|    # log_dir flag was provided, so use it and it alone (this mimics the
   723|         0|            0|            0|  0.00%|    # behavior of the same flag in logging.cc).
   724|         0|            0|            0|  0.00%|    dirs = [FLAGS['log_dir'].value]
   725|         0|            0|            0|  0.00%|  else:
   726|         0|            0|            0|  0.00%|    dirs = ['/tmp/', './']
   727|         0|            0|            0|  0.00%|
   728|         0|            0|            0|  0.00%|  # Find the first usable log dir.
   729|         0|            0|            0|  0.00%|  for d in dirs:
   730|         0|            0|            0|  0.00%|    if os.path.isdir(d) and os.access(d, os.W_OK):
   731|         0|            0|            0|  0.00%|      return d
   732|         0|            0|            0|  0.00%|  exception_class = OSError if six.PY2 else FileNotFoundError
   733|         0|            0|            0|  0.00%|  raise exception_class(
   734|         0|            0|            0|  0.00%|      "Can't find a writable directory for logs, tried %s" % dirs)
   735|         0|            0|            0|  0.00%|
   736|         0|            0|            0|  0.00%|
   737|         0|            0|            0|  0.00%|def get_absl_log_prefix(record):
   738|         0|            0|            0|  0.00%|  """Returns the absl log prefix for the log record.
   739|         0|            0|            0|  0.00%|
   740|         0|            0|            0|  0.00%|  Args:
   741|         0|            0|            0|  0.00%|    record: logging.LogRecord, the record to get prefix for.
   742|         0|            0|            0|  0.00%|  """
   743|         0|            0|            0|  0.00%|  created_tuple = time.localtime(record.created)
   744|         0|            0|            0|  0.00%|  created_microsecond = int(record.created % 1.0 * 1e6)
   745|         0|            0|            0|  0.00%|
   746|         0|            0|            0|  0.00%|  critical_prefix = ''
   747|         0|            0|            0|  0.00%|  level = record.levelno
   748|         0|            0|            0|  0.00%|  if _is_non_absl_fatal_record(record):
   749|         0|            0|            0|  0.00%|    # When the level is FATAL, but not logged from absl, lower the level so
   750|         0|            0|            0|  0.00%|    # it's treated as ERROR.
   751|         0|            0|            0|  0.00%|    level = logging.ERROR
   752|         0|            0|            0|  0.00%|    critical_prefix = _CRITICAL_PREFIX
   753|         0|            0|            0|  0.00%|  severity = converter.get_initial_for_level(level)
   754|         0|            0|            0|  0.00%|
   755|         0|            0|            0|  0.00%|  return '%c%02d%02d %02d:%02d:%02d.%06d %5d %s:%d] %s' % (
   756|         0|            0|            0|  0.00%|      severity,
   757|         0|            0|            0|  0.00%|      created_tuple.tm_mon,
   758|         0|            0|            0|  0.00%|      created_tuple.tm_mday,
   759|         0|            0|            0|  0.00%|      created_tuple.tm_hour,
   760|         0|            0|            0|  0.00%|      created_tuple.tm_min,
   761|         0|            0|            0|  0.00%|      created_tuple.tm_sec,
   762|         0|            0|            0|  0.00%|      created_microsecond,
   763|         0|            0|            0|  0.00%|      _get_thread_id(),
   764|         0|            0|            0|  0.00%|      record.filename,
   765|         0|            0|            0|  0.00%|      record.lineno,
   766|         0|            0|            0|  0.00%|      critical_prefix)
   767|         0|            0|            0|  0.00%|
   768|         0|            0|            0|  0.00%|
   769|         0|            0|            0|  0.00%|def skip_log_prefix(func):
   770|         0|            0|            0|  0.00%|  """Skips reporting the prefix of a given function or name by ABSLLogger.
   771|         0|            0|            0|  0.00%|
   772|         0|            0|            0|  0.00%|  This is a convenience wrapper function / decorator for
   773|         0|            0|            0|  0.00%|  `ABSLLogger.register_frame_to_skip`.
   774|         0|            0|            0|  0.00%|
   775|         0|            0|            0|  0.00%|  If a callable function is provided, only that function will be skipped.
   776|         0|            0|            0|  0.00%|  If a function name is provided, all functions with the same name in the
   777|         0|            0|            0|  0.00%|  file that this is called in will be skipped.
   778|         0|            0|            0|  0.00%|
   779|         0|            0|            0|  0.00%|  This can be used as a decorator of the intended function to be skipped.
   780|         0|            0|            0|  0.00%|
   781|         0|            0|            0|  0.00%|  Args:
   782|         0|            0|            0|  0.00%|    func: Callable function or its name as a string.
   783|         0|            0|            0|  0.00%|
   784|         0|            0|            0|  0.00%|  Returns:
   785|         0|            0|            0|  0.00%|    func (the input, unchanged).
   786|         0|            0|            0|  0.00%|
   787|         0|            0|            0|  0.00%|  Raises:
   788|         0|            0|            0|  0.00%|    ValueError: The input is callable but does not have a function code object.
   789|         0|            0|            0|  0.00%|    TypeError: The input is neither callable nor a string.
   790|         0|            0|            0|  0.00%|  """
   791|         0|            0|            0|  0.00%|  if callable(func):
   792|         0|            0|            0|  0.00%|    func_code = getattr(func, '__code__', None)
   793|         0|            0|            0|  0.00%|    if func_code is None:
   794|         0|            0|            0|  0.00%|      raise ValueError('Input callable does not have a function code object.')
   795|         0|            0|            0|  0.00%|    file_name = func_code.co_filename
   796|         0|            0|            0|  0.00%|    func_name = func_code.co_name
   797|         0|            0|            0|  0.00%|    func_lineno = func_code.co_firstlineno
   798|         0|            0|            0|  0.00%|  elif isinstance(func, six.string_types):
   799|         0|            0|            0|  0.00%|    file_name = get_absl_logger().findCaller()[0]
   800|         0|            0|            0|  0.00%|    func_name = func
   801|         0|            0|            0|  0.00%|    func_lineno = None
   802|         0|            0|            0|  0.00%|  else:
   803|         0|            0|            0|  0.00%|    raise TypeError('Input is neither callable nor a string.')
   804|         0|            0|            0|  0.00%|  ABSLLogger.register_frame_to_skip(file_name, func_name, func_lineno)
   805|         0|            0|            0|  0.00%|  return func
   806|         0|            0|            0|  0.00%|
   807|         0|            0|            0|  0.00%|
   808|         0|            0|            0|  0.00%|def _is_non_absl_fatal_record(log_record):
   809|         0|            0|            0|  0.00%|  return (log_record.levelno >= logging.FATAL and
   810|         0|            0|            0|  0.00%|          not log_record.__dict__.get(_ABSL_LOG_FATAL, False))
   811|         0|            0|            0|  0.00%|
   812|         0|            0|            0|  0.00%|
   813|         0|            0|            0|  0.00%|def _is_absl_fatal_record(log_record):
   814|         0|            0|            0|  0.00%|  return (log_record.levelno >= logging.FATAL and
   815|         0|            0|            0|  0.00%|          log_record.__dict__.get(_ABSL_LOG_FATAL, False))
   816|         0|            0|            0|  0.00%|
   817|         0|            0|            0|  0.00%|
   818|         0|            0|            0|  0.00%|# Indicates if we still need to warn about pre-init logs going to stderr.
   819|         0|            0|            0|  0.00%|_warn_preinit_stderr = True
   820|         0|            0|            0|  0.00%|
   821|         0|            0|            0|  0.00%|
   822|         0|            0|            0|  0.00%|class PythonHandler(logging.StreamHandler):
   823|         0|            0|            0|  0.00%|  """The handler class used by Abseil Python logging implementation."""
   824|         0|            0|            0|  0.00%|
   825|         0|            0|            0|  0.00%|  def __init__(self, stream=None, formatter=None):
   826|         0|            0|            0|  0.00%|    super(PythonHandler, self).__init__(stream)
   827|         0|            0|            0|  0.00%|    self.setFormatter(formatter or PythonFormatter())
   828|         0|            0|            0|  0.00%|
   829|         0|            0|            0|  0.00%|  def start_logging_to_file(self, program_name=None, log_dir=None):
   830|         0|            0|            0|  0.00%|    """Starts logging messages to files instead of standard error."""
   831|         0|            0|            0|  0.00%|    FLAGS.logtostderr = False
   832|         0|            0|            0|  0.00%|
   833|         0|            0|            0|  0.00%|    actual_log_dir, file_prefix, symlink_prefix = find_log_dir_and_names(
   834|         0|            0|            0|  0.00%|        program_name=program_name, log_dir=log_dir)
   835|         0|            0|            0|  0.00%|
   836|         0|            0|            0|  0.00%|    basename = '%s.INFO.%s.%d' % (
   837|         0|            0|            0|  0.00%|        file_prefix,
   838|         0|            0|            0|  0.00%|        time.strftime('%Y%m%d-%H%M%S', time.localtime(time.time())),
   839|         0|            0|            0|  0.00%|        os.getpid())
   840|         0|            0|            0|  0.00%|    filename = os.path.join(actual_log_dir, basename)
   841|         0|            0|            0|  0.00%|
   842|         0|            0|            0|  0.00%|    if six.PY2:
   843|         0|            0|            0|  0.00%|      self.stream = open(filename, 'a')
   844|         0|            0|            0|  0.00%|    else:
   845|         0|            0|            0|  0.00%|      self.stream = open(filename, 'a', encoding='utf-8')
   846|         0|            0|            0|  0.00%|
   847|         0|            0|            0|  0.00%|    # os.symlink is not available on Windows Python 2.
   848|         0|            0|            0|  0.00%|    if getattr(os, 'symlink', None):
   849|         0|            0|            0|  0.00%|      # Create a symlink to the log file with a canonical name.
   850|         0|            0|            0|  0.00%|      symlink = os.path.join(actual_log_dir, symlink_prefix + '.INFO')
   851|         0|            0|            0|  0.00%|      try:
   852|         0|            0|            0|  0.00%|        if os.path.islink(symlink):
   853|         0|            0|            0|  0.00%|          os.unlink(symlink)
   854|         0|            0|            0|  0.00%|        os.symlink(os.path.basename(filename), symlink)
   855|         0|            0|            0|  0.00%|      except EnvironmentError:
   856|         0|            0|            0|  0.00%|        # If it fails, we're sad but it's no error.  Commonly, this
   857|         0|            0|            0|  0.00%|        # fails because the symlink was created by another user and so
   858|         0|            0|            0|  0.00%|        # we can't modify it
   859|         0|            0|            0|  0.00%|        pass
   860|         0|            0|            0|  0.00%|
   861|         0|            0|            0|  0.00%|  def use_absl_log_file(self, program_name=None, log_dir=None):
   862|         0|            0|            0|  0.00%|    """Conditionally logs to files, based on --logtostderr."""
   863|         0|            0|            0|  0.00%|    if FLAGS['logtostderr'].value:
   864|         0|            0|            0|  0.00%|      self.stream = sys.stderr
   865|         0|            0|            0|  0.00%|    else:
   866|         0|            0|            0|  0.00%|      self.start_logging_to_file(program_name=program_name, log_dir=log_dir)
   867|         0|            0|            0|  0.00%|
   868|         0|            0|            0|  0.00%|  def flush(self):
   869|         0|            0|            0|  0.00%|    """Flushes all log files."""
   870|         0|            0|            0|  0.00%|    self.acquire()
   871|         0|            0|            0|  0.00%|    try:
   872|         0|            0|            0|  0.00%|      self.stream.flush()
   873|         0|            0|            0|  0.00%|    except (EnvironmentError, ValueError):
   874|         0|            0|            0|  0.00%|      # A ValueError is thrown if we try to flush a closed file.
   875|         0|            0|            0|  0.00%|      pass
   876|         0|            0|            0|  0.00%|    finally:
   877|         0|            0|            0|  0.00%|      self.release()
   878|         0|            0|            0|  0.00%|
   879|         0|            0|            0|  0.00%|  def _log_to_stderr(self, record):
   880|         0|            0|            0|  0.00%|    """Emits the record to stderr.
   881|         0|            0|            0|  0.00%|
   882|         0|            0|            0|  0.00%|    This temporarily sets the handler stream to stderr, calls
   883|         0|            0|            0|  0.00%|    StreamHandler.emit, then reverts the stream back.
   884|         0|            0|            0|  0.00%|
   885|         0|            0|            0|  0.00%|    Args:
   886|         0|            0|            0|  0.00%|      record: logging.LogRecord, the record to log.
   887|         0|            0|            0|  0.00%|    """
   888|         0|            0|            0|  0.00%|    # emit() is protected by a lock in logging.Handler, so we don't need to
   889|         0|            0|            0|  0.00%|    # protect here again.
   890|         0|            0|            0|  0.00%|    old_stream = self.stream
   891|         0|            0|            0|  0.00%|    self.stream = sys.stderr
   892|         0|            0|            0|  0.00%|    try:
   893|         0|            0|            0|  0.00%|      super(PythonHandler, self).emit(record)
   894|         0|            0|            0|  0.00%|    finally:
   895|         0|            0|            0|  0.00%|      self.stream = old_stream
   896|         0|            0|            0|  0.00%|
   897|         0|            0|            0|  0.00%|  def emit(self, record):
   898|         0|            0|            0|  0.00%|    """Prints a record out to some streams.
   899|         0|            0|            0|  0.00%|
   900|         0|            0|            0|  0.00%|    If FLAGS.logtostderr is set, it will print to sys.stderr ONLY.
   901|         0|            0|            0|  0.00%|    If FLAGS.alsologtostderr is set, it will print to sys.stderr.
   902|         0|            0|            0|  0.00%|    If FLAGS.logtostderr is not set, it will log to the stream
   903|         0|            0|            0|  0.00%|      associated with the current thread.
   904|         0|            0|            0|  0.00%|
   905|         0|            0|            0|  0.00%|    Args:
   906|         0|            0|            0|  0.00%|      record: logging.LogRecord, the record to emit.
   907|         0|            0|            0|  0.00%|    """
   908|         0|            0|            0|  0.00%|    # People occasionally call logging functions at import time before
   909|         0|            0|            0|  0.00%|    # our flags may have even been defined yet, let alone even parsed, as we
   910|         0|            0|            0|  0.00%|    # rely on the C++ side to define some flags for us and app init to
   911|         0|            0|            0|  0.00%|    # deal with parsing.  Match the C++ library behavior of notify and emit
   912|         0|            0|            0|  0.00%|    # such messages to stderr.  It encourages people to clean-up and does
   913|         0|            0|            0|  0.00%|    # not hide the message.
   914|         0|            0|            0|  0.00%|    level = record.levelno
   915|         0|            0|            0|  0.00%|    if not FLAGS.is_parsed():  # Also implies "before flag has been defined".
   916|         0|            0|            0|  0.00%|      global _warn_preinit_stderr
   917|         0|            0|            0|  0.00%|      if _warn_preinit_stderr:
   918|         0|            0|            0|  0.00%|        sys.stderr.write(
   919|         0|            0|            0|  0.00%|            'WARNING: Logging before flag parsing goes to stderr.\n')
   920|         0|            0|            0|  0.00%|        _warn_preinit_stderr = False
   921|         0|            0|            0|  0.00%|      self._log_to_stderr(record)
   922|         0|            0|            0|  0.00%|    elif FLAGS['logtostderr'].value:
   923|         0|            0|            0|  0.00%|      self._log_to_stderr(record)
   924|         0|            0|            0|  0.00%|    else:
   925|         0|            0|            0|  0.00%|      super(PythonHandler, self).emit(record)
   926|         0|            0|            0|  0.00%|      stderr_threshold = converter.string_to_standard(
   927|         0|            0|            0|  0.00%|          FLAGS['stderrthreshold'].value)
   928|         0|            0|            0|  0.00%|      if ((FLAGS['alsologtostderr'].value or level >= stderr_threshold) and
   929|         0|            0|            0|  0.00%|          self.stream != sys.stderr):
   930|         0|            0|            0|  0.00%|        self._log_to_stderr(record)
   931|         0|            0|            0|  0.00%|    # Die when the record is created from ABSLLogger and level is FATAL.
   932|         0|            0|            0|  0.00%|    if _is_absl_fatal_record(record):
   933|         0|            0|            0|  0.00%|      self.flush()  # Flush the log before dying.
   934|         0|            0|            0|  0.00%|
   935|         0|            0|            0|  0.00%|      # In threaded python, sys.exit() from a non-main thread only
   936|         0|            0|            0|  0.00%|      # exits the thread in question.
   937|         0|            0|            0|  0.00%|      os.abort()
   938|         0|            0|            0|  0.00%|
   939|         0|            0|            0|  0.00%|  def close(self):
   940|         0|            0|            0|  0.00%|    """Closes the stream to which we are writing."""
   941|         0|            0|            0|  0.00%|    self.acquire()
   942|         0|            0|            0|  0.00%|    try:
   943|         0|            0|            0|  0.00%|      self.flush()
   944|         0|            0|            0|  0.00%|      try:
   945|         0|            0|            0|  0.00%|        # Do not close the stream if it's sys.stderr|stdout. They may be
   946|         0|            0|            0|  0.00%|        # redirected or overridden to files, which should be managed by users
   947|         0|            0|            0|  0.00%|        # explicitly.
   948|         0|            0|            0|  0.00%|        user_managed = sys.stderr, sys.stdout, sys.__stderr__, sys.__stdout__
   949|         0|            0|            0|  0.00%|        if self.stream not in user_managed and (
   950|         0|            0|            0|  0.00%|            not hasattr(self.stream, 'isatty') or not self.stream.isatty()):
   951|         0|            0|            0|  0.00%|          self.stream.close()
   952|         0|            0|            0|  0.00%|      except ValueError:
   953|         0|            0|            0|  0.00%|        # A ValueError is thrown if we try to run isatty() on a closed file.
   954|         0|            0|            0|  0.00%|        pass
   955|         0|            0|            0|  0.00%|      super(PythonHandler, self).close()
   956|         0|            0|            0|  0.00%|    finally:
   957|         0|            0|            0|  0.00%|      self.release()
   958|         0|            0|            0|  0.00%|
   959|         0|            0|            0|  0.00%|
   960|         0|            0|            0|  0.00%|class ABSLHandler(logging.Handler):
   961|         0|            0|            0|  0.00%|  """Abseil Python logging module's log handler."""
   962|         0|            0|            0|  0.00%|
   963|         0|            0|            0|  0.00%|  def __init__(self, python_logging_formatter):
   964|         0|            0|            0|  0.00%|    super(ABSLHandler, self).__init__()
   965|         0|            0|            0|  0.00%|
   966|         0|            0|            0|  0.00%|    self._python_handler = PythonHandler(formatter=python_logging_formatter)
   967|         0|            0|            0|  0.00%|    self.activate_python_handler()
   968|         0|            0|            0|  0.00%|
   969|         0|            0|            0|  0.00%|  def format(self, record):
   970|         0|            0|            0|  0.00%|    return self._current_handler.format(record)
   971|         0|            0|            0|  0.00%|
   972|         0|            0|            0|  0.00%|  def setFormatter(self, fmt):
   973|         0|            0|            0|  0.00%|    self._current_handler.setFormatter(fmt)
   974|         0|            0|            0|  0.00%|
   975|         0|            0|            0|  0.00%|  def emit(self, record):
   976|         0|            0|            0|  0.00%|    self._current_handler.emit(record)
   977|         0|            0|            0|  0.00%|
   978|         0|            0|            0|  0.00%|  def flush(self):
   979|         0|            0|            0|  0.00%|    self._current_handler.flush()
   980|         0|            0|            0|  0.00%|
   981|         0|            0|            0|  0.00%|  def close(self):
   982|         0|            0|            0|  0.00%|    super(ABSLHandler, self).close()
   983|         0|            0|            0|  0.00%|    self._current_handler.close()
   984|         0|            0|            0|  0.00%|
   985|         0|            0|            0|  0.00%|  def handle(self, record):
   986|         0|            0|            0|  0.00%|    rv = self.filter(record)
   987|         0|            0|            0|  0.00%|    if rv:
   988|         0|            0|            0|  0.00%|      return self._current_handler.handle(record)
   989|         0|            0|            0|  0.00%|    return rv
   990|         0|            0|            0|  0.00%|
   991|         0|            0|            0|  0.00%|  @property
   992|         0|            0|            0|  0.00%|  def python_handler(self):
   993|         0|            0|            0|  0.00%|    return self._python_handler
   994|         0|            0|            0|  0.00%|
   995|         0|            0|            0|  0.00%|  def activate_python_handler(self):
   996|         0|            0|            0|  0.00%|    """Uses the Python logging handler as the current logging handler."""
   997|         0|            0|            0|  0.00%|    self._current_handler = self._python_handler
   998|         0|            0|            0|  0.00%|
   999|         0|            0|            0|  0.00%|  def use_absl_log_file(self, program_name=None, log_dir=None):
  1000|         0|            0|            0|  0.00%|    self._current_handler.use_absl_log_file(program_name, log_dir)
  1001|         0|            0|            0|  0.00%|
  1002|         0|            0|            0|  0.00%|  def start_logging_to_file(self, program_name=None, log_dir=None):
  1003|         0|            0|            0|  0.00%|    self._current_handler.start_logging_to_file(program_name, log_dir)
  1004|         0|            0|            0|  0.00%|
  1005|         0|            0|            0|  0.00%|
  1006|         0|            0|            0|  0.00%|class PythonFormatter(logging.Formatter):
  1007|         0|            0|            0|  0.00%|  """Formatter class used by PythonHandler."""
  1008|         0|            0|            0|  0.00%|
  1009|         0|            0|            0|  0.00%|  def format(self, record):
  1010|         0|            0|            0|  0.00%|    """Appends the message from the record to the results of the prefix.
  1011|         0|            0|            0|  0.00%|
  1012|         0|            0|            0|  0.00%|    Args:
  1013|         0|            0|            0|  0.00%|      record: logging.LogRecord, the record to be formatted.
  1014|         0|            0|            0|  0.00%|
  1015|         0|            0|            0|  0.00%|    Returns:
  1016|         0|            0|            0|  0.00%|      The formatted string representing the record.
  1017|         0|            0|            0|  0.00%|    """
  1018|         0|            0|            0|  0.00%|    if (not FLAGS['showprefixforinfo'].value and
  1019|         0|            0|            0|  0.00%|        FLAGS['verbosity'].value == converter.ABSL_INFO and
  1020|         0|            0|            0|  0.00%|        record.levelno == logging.INFO and
  1021|         0|            0|            0|  0.00%|        _absl_handler.python_handler.stream == sys.stderr):
  1022|         0|            0|            0|  0.00%|      prefix = ''
  1023|         0|            0|            0|  0.00%|    else:
  1024|         0|            0|            0|  0.00%|      prefix = get_absl_log_prefix(record)
  1025|         0|            0|            0|  0.00%|    return prefix + super(PythonFormatter, self).format(record)
  1026|         0|            0|            0|  0.00%|
  1027|         0|            0|            0|  0.00%|
  1028|         0|            0|            0|  0.00%|class ABSLLogger(logging.getLoggerClass()):
  1029|         0|            0|            0|  0.00%|  """A logger that will create LogRecords while skipping some stack frames.
  1030|         0|            0|            0|  0.00%|
  1031|         0|            0|            0|  0.00%|  This class maintains an internal list of filenames and method names
  1032|         0|            0|            0|  0.00%|  for use when determining who called the currently execuing stack
  1033|         0|            0|            0|  0.00%|  frame.  Any method names from specific source files are skipped when
  1034|         0|            0|            0|  0.00%|  walking backwards through the stack.
  1035|         0|            0|            0|  0.00%|
  1036|         0|            0|            0|  0.00%|  Client code should use the register_frame_to_skip method to let the
  1037|         0|            0|            0|  0.00%|  ABSLLogger know which method from which file should be
  1038|         0|            0|            0|  0.00%|  excluded from the walk backwards through the stack.
  1039|         0|            0|            0|  0.00%|  """
  1040|         0|            0|            0|  0.00%|  _frames_to_skip = set()
  1041|         0|            0|            0|  0.00%|
  1042|         0|            0|            0|  0.00%|  def findCaller(self, stack_info=False, stacklevel=1):
  1043|         0|            0|            0|  0.00%|    """Finds the frame of the calling method on the stack.
  1044|         0|            0|            0|  0.00%|
  1045|         0|            0|            0|  0.00%|    This method skips any frames registered with the
  1046|         0|            0|            0|  0.00%|    ABSLLogger and any methods from this file, and whatever
  1047|         0|            0|            0|  0.00%|    method is currently being used to generate the prefix for the log
  1048|         0|            0|            0|  0.00%|    line.  Then it returns the file name, line number, and method name
  1049|         0|            0|            0|  0.00%|    of the calling method.  An optional fourth item may be returned,
  1050|         0|            0|            0|  0.00%|    callers who only need things from the first three are advised to
  1051|         0|            0|            0|  0.00%|    always slice or index the result rather than using direct unpacking
  1052|         0|            0|            0|  0.00%|    assignment.
  1053|         0|            0|            0|  0.00%|
  1054|         0|            0|            0|  0.00%|    Args:
  1055|         0|            0|            0|  0.00%|      stack_info: bool, when True, include the stack trace as a fourth item
  1056|         0|            0|            0|  0.00%|          returned.  On Python 3 there are always four items returned - the
  1057|         0|            0|            0|  0.00%|          fourth will be None when this is False.  On Python 2 the stdlib
  1058|         0|            0|            0|  0.00%|          base class API only returns three items.  We do the same when this
  1059|         0|            0|            0|  0.00%|          new parameter is unspecified or False for compatibility.
  1060|         0|            0|            0|  0.00%|
  1061|         0|            0|            0|  0.00%|    Returns:
  1062|         0|            0|            0|  0.00%|      (filename, lineno, methodname[, sinfo]) of the calling method.
  1063|         0|            0|            0|  0.00%|    """
  1064|         0|            0|            0|  0.00%|    f_to_skip = ABSLLogger._frames_to_skip
  1065|         0|            0|            0|  0.00%|    # Use sys._getframe(2) instead of logging.currentframe(), it's slightly
  1066|         0|            0|            0|  0.00%|    # faster because there is one less frame to traverse.
  1067|         0|            0|            0|  0.00%|    frame = sys._getframe(2)  # pylint: disable=protected-access
  1068|         0|            0|            0|  0.00%|
  1069|         0|            0|            0|  0.00%|    while frame:
  1070|         0|            0|            0|  0.00%|      code = frame.f_code
  1071|         0|            0|            0|  0.00%|      if (_LOGGING_FILE_PREFIX not in code.co_filename and
  1072|         0|            0|            0|  0.00%|          (code.co_filename, code.co_name,
  1073|         0|            0|            0|  0.00%|           code.co_firstlineno) not in f_to_skip and
  1074|         0|            0|            0|  0.00%|          (code.co_filename, code.co_name) not in f_to_skip):
  1075|         0|            0|            0|  0.00%|        if six.PY2 and not stack_info:
  1076|         0|            0|            0|  0.00%|          return (code.co_filename, frame.f_lineno, code.co_name)
  1077|         0|            0|            0|  0.00%|        else:
  1078|         0|            0|            0|  0.00%|          sinfo = None
  1079|         0|            0|            0|  0.00%|          if stack_info:
  1080|         0|            0|            0|  0.00%|            out = io.StringIO()
  1081|         0|            0|            0|  0.00%|            out.write(u'Stack (most recent call last):\n')
  1082|         0|            0|            0|  0.00%|            traceback.print_stack(frame, file=out)
  1083|         0|            0|            0|  0.00%|            sinfo = out.getvalue().rstrip(u'\n')
  1084|         0|            0|            0|  0.00%|          return (code.co_filename, frame.f_lineno, code.co_name, sinfo)
  1085|         0|            0|            0|  0.00%|      frame = frame.f_back
  1086|         0|            0|            0|  0.00%|
  1087|         0|            0|            0|  0.00%|  def critical(self, msg, *args, **kwargs):
  1088|         0|            0|            0|  0.00%|    """Logs 'msg % args' with severity 'CRITICAL'."""
  1089|         0|            0|            0|  0.00%|    self.log(logging.CRITICAL, msg, *args, **kwargs)
  1090|         0|            0|            0|  0.00%|
  1091|         0|            0|            0|  0.00%|  def fatal(self, msg, *args, **kwargs):
  1092|         0|            0|            0|  0.00%|    """Logs 'msg % args' with severity 'FATAL'."""
  1093|         0|            0|            0|  0.00%|    self.log(logging.FATAL, msg, *args, **kwargs)
  1094|         0|            0|            0|  0.00%|
  1095|         0|            0|            0|  0.00%|  def error(self, msg, *args, **kwargs):
  1096|         0|            0|            0|  0.00%|    """Logs 'msg % args' with severity 'ERROR'."""
  1097|         0|            0|            0|  0.00%|    self.log(logging.ERROR, msg, *args, **kwargs)
  1098|         0|            0|            0|  0.00%|
  1099|         0|            0|            0|  0.00%|  def warn(self, msg, *args, **kwargs):
  1100|         0|            0|            0|  0.00%|    """Logs 'msg % args' with severity 'WARN'."""
  1101|         0|            0|            0|  0.00%|    if six.PY3:
  1102|         0|            0|            0|  0.00%|      warnings.warn("The 'warn' method is deprecated, use 'warning' instead",
  1103|         0|            0|            0|  0.00%|                    DeprecationWarning, 2)
  1104|         0|            0|            0|  0.00%|    self.log(logging.WARN, msg, *args, **kwargs)
  1105|         0|            0|            0|  0.00%|
  1106|         0|            0|            0|  0.00%|  def warning(self, msg, *args, **kwargs):
  1107|         0|            0|            0|  0.00%|    """Logs 'msg % args' with severity 'WARNING'."""
  1108|         0|            0|            0|  0.00%|    self.log(logging.WARNING, msg, *args, **kwargs)
  1109|         0|            0|            0|  0.00%|
  1110|         0|            0|            0|  0.00%|  def info(self, msg, *args, **kwargs):
  1111|         0|            0|            0|  0.00%|    """Logs 'msg % args' with severity 'INFO'."""
  1112|         0|            0|            0|  0.00%|    self.log(logging.INFO, msg, *args, **kwargs)
  1113|         0|            0|            0|  0.00%|
  1114|         0|            0|            0|  0.00%|  def debug(self, msg, *args, **kwargs):
  1115|         0|            0|            0|  0.00%|    """Logs 'msg % args' with severity 'DEBUG'."""
  1116|         0|            0|            0|  0.00%|    self.log(logging.DEBUG, msg, *args, **kwargs)
  1117|         0|            0|            0|  0.00%|
  1118|         1|  8.58307e-06|  8.58307e-06|  0.00%|  def log(self, level, msg, *args, **kwargs):
  1119|         0|            0|            0|  0.00%|    """Logs a message at a cetain level substituting in the supplied arguments.
  1120|         0|            0|            0|  0.00%|
  1121|         0|            0|            0|  0.00%|    This method behaves differently in python and c++ modes.
  1122|         0|            0|            0|  0.00%|
  1123|         0|            0|            0|  0.00%|    Args:
  1124|         0|            0|            0|  0.00%|      level: int, the standard logging level at which to log the message.
  1125|         0|            0|            0|  0.00%|      msg: str, the text of the message to log.
  1126|         0|            0|            0|  0.00%|      *args: The arguments to substitute in the message.
  1127|         0|            0|            0|  0.00%|      **kwargs: The keyword arguments to substitute in the message.
  1128|         0|            0|            0|  0.00%|    """
  1129|         1|  4.05312e-06|  4.05312e-06|  0.00%|    if level >= logging.FATAL:
  1130|         0|            0|            0|  0.00%|      # Add property to the LogRecord created by this logger.
  1131|         0|            0|            0|  0.00%|      # This will be used by the ABSLHandler to determine whether it should
  1132|         0|            0|            0|  0.00%|      # treat CRITICAL/FATAL logs as really FATAL.
  1133|         0|            0|            0|  0.00%|      extra = kwargs.setdefault('extra', {})
  1134|         0|            0|            0|  0.00%|      extra[_ABSL_LOG_FATAL] = True
  1135|         1|   1.3113e-05|   1.3113e-05|  0.00%|    super(ABSLLogger, self).log(level, msg, *args, **kwargs)
(call)|         1|  3.83854e-05|  3.83854e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/logging/__init__.py:1485 log
  1136|         0|            0|            0|  0.00%|
  1137|         0|            0|            0|  0.00%|  def handle(self, record):
  1138|         0|            0|            0|  0.00%|    """Calls handlers without checking Logger.disabled.
  1139|         0|            0|            0|  0.00%|
  1140|         0|            0|            0|  0.00%|    Non-root loggers are set to disabled after setup with logging.config if
  1141|         0|            0|            0|  0.00%|    it's not explicitly specified. Historically, absl logging will not be
  1142|         0|            0|            0|  0.00%|    disabled by that. To maintaining this behavior, this function skips
  1143|         0|            0|            0|  0.00%|    checking the Logger.disabled bit.
  1144|         0|            0|            0|  0.00%|
  1145|         0|            0|            0|  0.00%|    This logger can still be disabled by adding a filter that filters out
  1146|         0|            0|            0|  0.00%|    everything.
  1147|         0|            0|            0|  0.00%|
  1148|         0|            0|            0|  0.00%|    Args:
  1149|         0|            0|            0|  0.00%|      record: logging.LogRecord, the record to handle.
  1150|         0|            0|            0|  0.00%|    """
  1151|         0|            0|            0|  0.00%|    if self.filter(record):
  1152|         0|            0|            0|  0.00%|      self.callHandlers(record)
  1153|         0|            0|            0|  0.00%|
  1154|         0|            0|            0|  0.00%|  @classmethod
  1155|         0|            0|            0|  0.00%|  def register_frame_to_skip(cls, file_name, function_name, line_number=None):
  1156|         0|            0|            0|  0.00%|    """Registers a function name to skip when walking the stack.
  1157|         0|            0|            0|  0.00%|
  1158|         0|            0|            0|  0.00%|    The ABSLLogger sometimes skips method calls on the stack
  1159|         0|            0|            0|  0.00%|    to make the log messages meaningful in their appropriate context.
  1160|         0|            0|            0|  0.00%|    This method registers a function from a particular file as one
  1161|         0|            0|            0|  0.00%|    which should be skipped.
  1162|         0|            0|            0|  0.00%|
  1163|         0|            0|            0|  0.00%|    Args:
  1164|         0|            0|            0|  0.00%|      file_name: str, the name of the file that contains the function.
  1165|         0|            0|            0|  0.00%|      function_name: str, the name of the function to skip.
  1166|         0|            0|            0|  0.00%|      line_number: int, if provided, only the function with this starting line
  1167|         0|            0|            0|  0.00%|          number will be skipped. Otherwise, all functions with the same name
  1168|         0|            0|            0|  0.00%|          in the file will be skipped.
  1169|         0|            0|            0|  0.00%|    """
  1170|         0|            0|            0|  0.00%|    if line_number is not None:
  1171|         0|            0|            0|  0.00%|      cls._frames_to_skip.add((file_name, function_name, line_number))
  1172|         0|            0|            0|  0.00%|    else:
  1173|         0|            0|            0|  0.00%|      cls._frames_to_skip.add((file_name, function_name))
  1174|         0|            0|            0|  0.00%|
  1175|         0|            0|            0|  0.00%|
  1176|         0|            0|            0|  0.00%|def _get_thread_id():
  1177|         0|            0|            0|  0.00%|  """Gets id of current thread, suitable for logging as an unsigned quantity.
  1178|         0|            0|            0|  0.00%|
  1179|         0|            0|            0|  0.00%|  If pywrapbase is linked, returns GetTID() for the thread ID to be
  1180|         0|            0|            0|  0.00%|  consistent with C++ logging.  Otherwise, returns the numeric thread id.
  1181|         0|            0|            0|  0.00%|  The quantities are made unsigned by masking with 2*sys.maxint + 1.
  1182|         0|            0|            0|  0.00%|
  1183|         0|            0|            0|  0.00%|  Returns:
  1184|         0|            0|            0|  0.00%|    Thread ID unique to this process (unsigned)
  1185|         0|            0|            0|  0.00%|  """
  1186|         0|            0|            0|  0.00%|  thread_id = _thread_lib.get_ident()
  1187|         0|            0|            0|  0.00%|  return thread_id & _THREAD_ID_MASK
  1188|         0|            0|            0|  0.00%|
  1189|         0|            0|            0|  0.00%|
  1190|         0|            0|            0|  0.00%|def get_absl_logger():
  1191|         0|            0|            0|  0.00%|  """Returns the absl logger instance."""
  1192|         0|            0|            0|  0.00%|  return _absl_logger
  1193|         0|            0|            0|  0.00%|
  1194|         0|            0|            0|  0.00%|
  1195|         0|            0|            0|  0.00%|def get_absl_handler():
  1196|         0|            0|            0|  0.00%|  """Returns the absl handler instance."""
  1197|         0|            0|            0|  0.00%|  return _absl_handler
  1198|         0|            0|            0|  0.00%|
  1199|         0|            0|            0|  0.00%|
  1200|         0|            0|            0|  0.00%|def use_python_logging(quiet=False):
  1201|         0|            0|            0|  0.00%|  """Uses the python implementation of the logging code.
  1202|         0|            0|            0|  0.00%|
  1203|         0|            0|            0|  0.00%|  Args:
  1204|         0|            0|            0|  0.00%|    quiet: No logging message about switching logging type.
  1205|         0|            0|            0|  0.00%|  """
  1206|         0|            0|            0|  0.00%|  get_absl_handler().activate_python_handler()
  1207|         0|            0|            0|  0.00%|  if not quiet:
  1208|         0|            0|            0|  0.00%|    info('Restoring pure python logging')
  1209|         0|            0|            0|  0.00%|
  1210|         0|            0|            0|  0.00%|
  1211|         0|            0|            0|  0.00%|_attempted_to_remove_stderr_stream_handlers = False
  1212|         0|            0|            0|  0.00%|
  1213|         0|            0|            0|  0.00%|
  1214|         0|            0|            0|  0.00%|def use_absl_handler():
  1215|         0|            0|            0|  0.00%|  """Uses the ABSL logging handler for logging.
  1216|         0|            0|            0|  0.00%|
  1217|         0|            0|            0|  0.00%|  This method is called in app.run() so the absl handler is used in absl apps.
  1218|         0|            0|            0|  0.00%|  """
  1219|         0|            0|            0|  0.00%|  global _attempted_to_remove_stderr_stream_handlers
  1220|         0|            0|            0|  0.00%|  if not _attempted_to_remove_stderr_stream_handlers:
  1221|         0|            0|            0|  0.00%|    # The absl handler logs to stderr by default. To prevent double logging to
  1222|         0|            0|            0|  0.00%|    # stderr, the following code tries its best to remove other handlers that
  1223|         0|            0|            0|  0.00%|    # emit to stderr. Those handlers are most commonly added when
  1224|         0|            0|            0|  0.00%|    # logging.info/debug is called before calling use_absl_handler().
  1225|         0|            0|            0|  0.00%|    handlers = [
  1226|         0|            0|            0|  0.00%|        h for h in logging.root.handlers
  1227|         0|            0|            0|  0.00%|        if isinstance(h, logging.StreamHandler) and h.stream == sys.stderr]
  1228|         0|            0|            0|  0.00%|    for h in handlers:
  1229|         0|            0|            0|  0.00%|      logging.root.removeHandler(h)
  1230|         0|            0|            0|  0.00%|    _attempted_to_remove_stderr_stream_handlers = True
  1231|         0|            0|            0|  0.00%|
  1232|         0|            0|            0|  0.00%|  absl_handler = get_absl_handler()
  1233|         0|            0|            0|  0.00%|  if absl_handler not in logging.root.handlers:
  1234|         0|            0|            0|  0.00%|    logging.root.addHandler(absl_handler)
  1235|         0|            0|            0|  0.00%|    FLAGS['verbosity']._update_logging_levels()  # pylint: disable=protected-access
  1236|         0|            0|            0|  0.00%|    FLAGS['logger_levels']._update_logger_levels()  # pylint: disable=protected-access
  1237|         0|            0|            0|  0.00%|
  1238|         0|            0|            0|  0.00%|
  1239|         0|            0|            0|  0.00%|def _initialize():
  1240|         0|            0|            0|  0.00%|  """Initializes loggers and handlers."""
  1241|         0|            0|            0|  0.00%|  global _absl_logger, _absl_handler
  1242|         0|            0|            0|  0.00%|
  1243|         0|            0|            0|  0.00%|  if _absl_logger:
  1244|         0|            0|            0|  0.00%|    return
  1245|         0|            0|            0|  0.00%|
  1246|         0|            0|            0|  0.00%|  original_logger_class = logging.getLoggerClass()
  1247|         0|            0|            0|  0.00%|  logging.setLoggerClass(ABSLLogger)
  1248|         0|            0|            0|  0.00%|  _absl_logger = logging.getLogger('absl')
  1249|         0|            0|            0|  0.00%|  logging.setLoggerClass(original_logger_class)
  1250|         0|            0|            0|  0.00%|
  1251|         0|            0|            0|  0.00%|  python_logging_formatter = PythonFormatter()
  1252|         0|            0|            0|  0.00%|  _absl_handler = ABSLHandler(python_logging_formatter)
  1253|         0|            0|            0|  0.00%|
  1254|         0|            0|            0|  0.00%|
  1255|         0|            0|            0|  0.00%|_initialize()
File: /apps/open_spiel/open_spiel/python/examples/env_and_policy.py
File duration: 6.53267e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|from dataclasses import dataclass
     2|         0|            0|            0|  0.00%|from open_spiel.python.rl_environment import Environment
     3|         0|            0|            0|  0.00%|from open_spiel.python.rl_agent_policy import JointRLAgentPolicy
     4|         0|            0|            0|  0.00%|from typing import List
     5|         0|            0|            0|  0.00%|import pyspiel
     6|         0|            0|            0|  0.00%|
     7|         0|            0|            0|  0.00%|@dataclass
     8|         0|            0|            0|  0.00%|class EnvAndPolicy:
     9|         0|            0|            0|  0.00%|    env: Environment
    10|         0|            0|            0|  0.00%|    agents: List
    11|         0|            0|            0|  0.00%|    game: pyspiel.Game
    12|         0|            0|            0|  0.00%|
    13|         1|  9.77516e-06|  9.77516e-06|  0.00%|    def make_policy(self, agents=None) -> JointRLAgentPolicy:
    14|         1|  2.38419e-05|  2.38419e-05|  0.00%|        if agents is None:
    15|         1|  3.33786e-06|  3.33786e-06|  0.00%|            agents = self.agents
    16|         5|  1.71661e-05|  3.43323e-06|  0.00%|        agent_dict = {agent.player_id: agent for agent in agents}
(call)|         1|  9.29832e-06|  9.29832e-06|  0.00%|# /apps/open_spiel/open_spiel/python/examples/env_and_policy.py:16 <dictcomp>
    17|         1|  1.12057e-05|  1.12057e-05|  0.00%|        return JointRLAgentPolicy(self.game, agent_dict, False)
(call)|         1|  7.84397e-05|  7.84397e-05|  0.00%|# /apps/open_spiel/open_spiel/python/rl_agent_policy.py:32 __init__
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/cuda/random.py
File duration: 5.57899e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import torch
     2|         0|            0|            0|  0.00%|from typing import cast, Iterable, List, Union
     3|         0|            0|            0|  0.00%|from . import _lazy_init, _lazy_call, device_count, current_device
     4|         0|            0|            0|  0.00%|from .. import Tensor
     5|         0|            0|            0|  0.00%|
     6|         0|            0|            0|  0.00%|__all__ = ['get_rng_state', 'get_rng_state_all',
     7|         0|            0|            0|  0.00%|           'set_rng_state', 'set_rng_state_all',
     8|         0|            0|            0|  0.00%|           'manual_seed', 'manual_seed_all',
     9|         0|            0|            0|  0.00%|           'seed', 'seed_all', 'initial_seed']
    10|         0|            0|            0|  0.00%|
    11|         0|            0|            0|  0.00%|
    12|         0|            0|            0|  0.00%|def get_rng_state(device: Union[int, str, torch.device] = 'cuda') -> Tensor:
    13|         0|            0|            0|  0.00%|    r"""Returns the random number generator state of the specified GPU as a ByteTensor.
    14|         0|            0|            0|  0.00%|
    15|         0|            0|            0|  0.00%|    Args:
    16|         0|            0|            0|  0.00%|        device (torch.device or int, optional): The device to return the RNG state of.
    17|         0|            0|            0|  0.00%|            Default: ``'cuda'`` (i.e., ``torch.device('cuda')``, the current CUDA device).
    18|         0|            0|            0|  0.00%|
    19|         0|            0|            0|  0.00%|    .. warning::
    20|         0|            0|            0|  0.00%|        This function eagerly initializes CUDA.
    21|         0|            0|            0|  0.00%|    """
    22|         0|            0|            0|  0.00%|    _lazy_init()
    23|         0|            0|            0|  0.00%|    if isinstance(device, str):
    24|         0|            0|            0|  0.00%|        device = torch.device(device)
    25|         0|            0|            0|  0.00%|    elif isinstance(device, int):
    26|         0|            0|            0|  0.00%|        device = torch.device('cuda', device)
    27|         0|            0|            0|  0.00%|    idx = device.index
    28|         0|            0|            0|  0.00%|    if idx is None:
    29|         0|            0|            0|  0.00%|        idx = current_device()
    30|         0|            0|            0|  0.00%|    default_generator = torch.cuda.default_generators[idx]
    31|         0|            0|            0|  0.00%|    return default_generator.get_state()
    32|         0|            0|            0|  0.00%|
    33|         0|            0|            0|  0.00%|
    34|         0|            0|            0|  0.00%|def get_rng_state_all() -> List[Tensor]:
    35|         0|            0|            0|  0.00%|    r"""Returns a list of ByteTensor representing the random number states of all devices."""
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|    results = []
    38|         0|            0|            0|  0.00%|    for i in range(device_count()):
    39|         0|            0|            0|  0.00%|        results.append(get_rng_state(i))
    40|         0|            0|            0|  0.00%|    return results
    41|         0|            0|            0|  0.00%|
    42|         0|            0|            0|  0.00%|
    43|         0|            0|            0|  0.00%|def set_rng_state(new_state: Tensor, device: Union[int, str, torch.device] = 'cuda') -> None:
    44|         0|            0|            0|  0.00%|    r"""Sets the random number generator state of the specified GPU.
    45|         0|            0|            0|  0.00%|
    46|         0|            0|            0|  0.00%|    Args:
    47|         0|            0|            0|  0.00%|        new_state (torch.ByteTensor): The desired state
    48|         0|            0|            0|  0.00%|        device (torch.device or int, optional): The device to set the RNG state.
    49|         0|            0|            0|  0.00%|            Default: ``'cuda'`` (i.e., ``torch.device('cuda')``, the current CUDA device).
    50|         0|            0|            0|  0.00%|    """
    51|         0|            0|            0|  0.00%|    new_state_copy = new_state.clone(memory_format=torch.contiguous_format)
    52|         0|            0|            0|  0.00%|    if isinstance(device, str):
    53|         0|            0|            0|  0.00%|        device = torch.device(device)
    54|         0|            0|            0|  0.00%|    elif isinstance(device, int):
    55|         0|            0|            0|  0.00%|        device = torch.device('cuda', device)
    56|         0|            0|            0|  0.00%|
    57|         0|            0|            0|  0.00%|    def cb():
    58|         0|            0|            0|  0.00%|        idx = cast(torch.device, device).index
    59|         0|            0|            0|  0.00%|        if idx is None:
    60|         0|            0|            0|  0.00%|            idx = current_device()
    61|         0|            0|            0|  0.00%|        default_generator = torch.cuda.default_generators[idx]
    62|         0|            0|            0|  0.00%|        default_generator.set_state(new_state_copy)
    63|         0|            0|            0|  0.00%|
    64|         0|            0|            0|  0.00%|    _lazy_call(cb)
    65|         0|            0|            0|  0.00%|
    66|         0|            0|            0|  0.00%|
    67|         0|            0|            0|  0.00%|def set_rng_state_all(new_states: Iterable[Tensor]) -> None:
    68|         0|            0|            0|  0.00%|    r"""Sets the random number generator state of all devices.
    69|         0|            0|            0|  0.00%|
    70|         0|            0|            0|  0.00%|    Args:
    71|         0|            0|            0|  0.00%|        new_states (Iterable of torch.ByteTensor): The desired state for each device"""
    72|         0|            0|            0|  0.00%|    for i, state in enumerate(new_states):
    73|         0|            0|            0|  0.00%|        set_rng_state(state, i)
    74|         0|            0|            0|  0.00%|
    75|         0|            0|            0|  0.00%|
    76|         0|            0|            0|  0.00%|def manual_seed(seed: int) -> None:
    77|         0|            0|            0|  0.00%|    r"""Sets the seed for generating random numbers for the current GPU.
    78|         0|            0|            0|  0.00%|    It's safe to call this function if CUDA is not available; in that
    79|         0|            0|            0|  0.00%|    case, it is silently ignored.
    80|         0|            0|            0|  0.00%|
    81|         0|            0|            0|  0.00%|    Args:
    82|         0|            0|            0|  0.00%|        seed (int): The desired seed.
    83|         0|            0|            0|  0.00%|
    84|         0|            0|            0|  0.00%|    .. warning::
    85|         0|            0|            0|  0.00%|        If you are working with a multi-GPU model, this function is insufficient
    86|         0|            0|            0|  0.00%|        to get determinism.  To seed all GPUs, use :func:`manual_seed_all`.
    87|         0|            0|            0|  0.00%|    """
    88|         0|            0|            0|  0.00%|    seed = int(seed)
    89|         0|            0|            0|  0.00%|
    90|         0|            0|            0|  0.00%|    def cb():
    91|         0|            0|            0|  0.00%|        idx = current_device()
    92|         0|            0|            0|  0.00%|        default_generator = torch.cuda.default_generators[idx]
    93|         0|            0|            0|  0.00%|        default_generator.manual_seed(seed)
    94|         0|            0|            0|  0.00%|
    95|         0|            0|            0|  0.00%|    _lazy_call(cb, seed=True)
    96|         0|            0|            0|  0.00%|
    97|         0|            0|            0|  0.00%|
    98|         1|  7.86781e-06|  7.86781e-06|  0.00%|def manual_seed_all(seed: int) -> None:
    99|         0|            0|            0|  0.00%|    r"""Sets the seed for generating random numbers on all GPUs.
   100|         0|            0|            0|  0.00%|    It's safe to call this function if CUDA is not available; in that
   101|         0|            0|            0|  0.00%|    case, it is silently ignored.
   102|         0|            0|            0|  0.00%|
   103|         0|            0|            0|  0.00%|    Args:
   104|         0|            0|            0|  0.00%|        seed (int): The desired seed.
   105|         0|            0|            0|  0.00%|    """
   106|         1|  5.72205e-06|  5.72205e-06|  0.00%|    seed = int(seed)
   107|         0|            0|            0|  0.00%|
   108|         2|  6.19888e-06|  3.09944e-06|  0.00%|    def cb():
   109|         2|  1.21593e-05|  6.07967e-06|  0.00%|        for i in range(device_count()):
(call)|         1|  2.67029e-05|  2.67029e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:454 device_count
   110|         1|  3.57628e-06|  3.57628e-06|  0.00%|            default_generator = torch.cuda.default_generators[i]
   111|         1|  9.05991e-06|  9.05991e-06|  0.00%|            default_generator.manual_seed(seed)
   112|         0|            0|            0|  0.00%|
   113|         1|  1.12057e-05|  1.12057e-05|  0.00%|    _lazy_call(cb, seed_all=True)
(call)|         1|   8.4877e-05|   8.4877e-05|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:154 _lazy_call
   114|         0|            0|            0|  0.00%|
   115|         0|            0|            0|  0.00%|
   116|         0|            0|            0|  0.00%|def seed() -> None:
   117|         0|            0|            0|  0.00%|    r"""Sets the seed for generating random numbers to a random number for the current GPU.
   118|         0|            0|            0|  0.00%|    It's safe to call this function if CUDA is not available; in that
   119|         0|            0|            0|  0.00%|    case, it is silently ignored.
   120|         0|            0|            0|  0.00%|
   121|         0|            0|            0|  0.00%|    .. warning::
   122|         0|            0|            0|  0.00%|        If you are working with a multi-GPU model, this function will only initialize
   123|         0|            0|            0|  0.00%|        the seed on one GPU.  To initialize all GPUs, use :func:`seed_all`.
   124|         0|            0|            0|  0.00%|    """
   125|         0|            0|            0|  0.00%|    def cb():
   126|         0|            0|            0|  0.00%|        idx = current_device()
   127|         0|            0|            0|  0.00%|        default_generator = torch.cuda.default_generators[idx]
   128|         0|            0|            0|  0.00%|        default_generator.seed()
   129|         0|            0|            0|  0.00%|
   130|         0|            0|            0|  0.00%|    _lazy_call(cb)
   131|         0|            0|            0|  0.00%|
   132|         0|            0|            0|  0.00%|
   133|         0|            0|            0|  0.00%|def seed_all() -> None:
   134|         0|            0|            0|  0.00%|    r"""Sets the seed for generating random numbers to a random number on all GPUs.
   135|         0|            0|            0|  0.00%|    It's safe to call this function if CUDA is not available; in that
   136|         0|            0|            0|  0.00%|    case, it is silently ignored.
   137|         0|            0|            0|  0.00%|    """
   138|         0|            0|            0|  0.00%|    def cb():
   139|         0|            0|            0|  0.00%|        random_seed = 0
   140|         0|            0|            0|  0.00%|        seeded = False
   141|         0|            0|            0|  0.00%|        for i in range(device_count()):
   142|         0|            0|            0|  0.00%|            default_generator = torch.cuda.default_generators[i]
   143|         0|            0|            0|  0.00%|            if not seeded:
   144|         0|            0|            0|  0.00%|                default_generator.seed()
   145|         0|            0|            0|  0.00%|                random_seed = default_generator.initial_seed()
   146|         0|            0|            0|  0.00%|                seeded = True
   147|         0|            0|            0|  0.00%|            else:
   148|         0|            0|            0|  0.00%|                default_generator.manual_seed(random_seed)
   149|         0|            0|            0|  0.00%|
   150|         0|            0|            0|  0.00%|    _lazy_call(cb)
   151|         0|            0|            0|  0.00%|
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|def initial_seed() -> int:
   154|         0|            0|            0|  0.00%|    r"""Returns the current random seed of the current GPU.
   155|         0|            0|            0|  0.00%|
   156|         0|            0|            0|  0.00%|    .. warning::
   157|         0|            0|            0|  0.00%|        This function eagerly initializes CUDA.
   158|         0|            0|            0|  0.00%|    """
   159|         0|            0|            0|  0.00%|    _lazy_init()
   160|         0|            0|            0|  0.00%|    idx = current_device()
   161|         0|            0|            0|  0.00%|    default_generator = torch.cuda.default_generators[idx]
   162|         0|            0|            0|  0.00%|    return default_generator.initial_seed()
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/random.py
File duration: 4.31538e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import contextlib
     2|         0|            0|            0|  0.00%|from typing import Generator
     3|         0|            0|            0|  0.00%|import warnings
     4|         0|            0|            0|  0.00%|
     5|         0|            0|            0|  0.00%|from torch._C import default_generator
     6|         0|            0|            0|  0.00%|import torch
     7|         0|            0|            0|  0.00%|
     8|         0|            0|            0|  0.00%|
     9|         0|            0|            0|  0.00%|def set_rng_state(new_state: torch.Tensor) -> None:
    10|         0|            0|            0|  0.00%|    r"""Sets the random number generator state.
    11|         0|            0|            0|  0.00%|
    12|         0|            0|            0|  0.00%|    .. note: This function only works for CPU. For CUDA, please use
    13|         0|            0|            0|  0.00%|             torch.manual_seed(seed), which works for both CPU and CUDA.
    14|         0|            0|            0|  0.00%|
    15|         0|            0|            0|  0.00%|    Args:
    16|         0|            0|            0|  0.00%|        new_state (torch.ByteTensor): The desired state
    17|         0|            0|            0|  0.00%|    """
    18|         0|            0|            0|  0.00%|    default_generator.set_state(new_state)
    19|         0|            0|            0|  0.00%|
    20|         0|            0|            0|  0.00%|
    21|         0|            0|            0|  0.00%|def get_rng_state() -> torch.Tensor:
    22|         0|            0|            0|  0.00%|    r"""Returns the random number generator state as a `torch.ByteTensor`."""
    23|         0|            0|            0|  0.00%|    return default_generator.get_state()
    24|         0|            0|            0|  0.00%|
    25|         0|            0|            0|  0.00%|
    26|         1|  6.91414e-06|  6.91414e-06|  0.00%|def manual_seed(seed) -> torch._C.Generator:
    27|         0|            0|            0|  0.00%|    r"""Sets the seed for generating random numbers. Returns a
    28|         0|            0|            0|  0.00%|    `torch.Generator` object.
    29|         0|            0|            0|  0.00%|
    30|         0|            0|            0|  0.00%|    Args:
    31|         0|            0|            0|  0.00%|        seed (int): The desired seed. Value must be within the inclusive range
    32|         0|            0|            0|  0.00%|            `[-0x8000_0000_0000_0000, 0xffff_ffff_ffff_ffff]`. Otherwise, a RuntimeError
    33|         0|            0|            0|  0.00%|            is raised. Negative inputs are remapped to positive values with the formula
    34|         0|            0|            0|  0.00%|            `0xffff_ffff_ffff_ffff + seed`.
    35|         0|            0|            0|  0.00%|    """
    36|         1|  5.72205e-06|  5.72205e-06|  0.00%|    seed = int(seed)
    37|         1|  5.72205e-06|  5.72205e-06|  0.00%|    import torch.cuda
    38|         0|            0|            0|  0.00%|
    39|         1|  7.39098e-06|  7.39098e-06|  0.00%|    if not torch.cuda._is_in_bad_fork():
    40|         1|  1.07288e-05|  1.07288e-05|  0.00%|        torch.cuda.manual_seed_all(seed)
(call)|         1|  0.000113249|  0.000113249|  0.00%|# /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/torch/cuda/random.py:98 manual_seed_all
    41|         0|            0|            0|  0.00%|
    42|         1|  6.67572e-06|  6.67572e-06|  0.00%|    return default_generator.manual_seed(seed)
    43|         0|            0|            0|  0.00%|
    44|         0|            0|            0|  0.00%|
    45|         0|            0|            0|  0.00%|def seed() -> int:
    46|         0|            0|            0|  0.00%|    r"""Sets the seed for generating random numbers to a non-deterministic
    47|         0|            0|            0|  0.00%|    random number. Returns a 64 bit number used to seed the RNG.
    48|         0|            0|            0|  0.00%|    """
    49|         0|            0|            0|  0.00%|    seed = default_generator.seed()
    50|         0|            0|            0|  0.00%|    import torch.cuda
    51|         0|            0|            0|  0.00%|
    52|         0|            0|            0|  0.00%|    if not torch.cuda._is_in_bad_fork():
    53|         0|            0|            0|  0.00%|        torch.cuda.manual_seed_all(seed)
    54|         0|            0|            0|  0.00%|
    55|         0|            0|            0|  0.00%|    return seed
    56|         0|            0|            0|  0.00%|
    57|         0|            0|            0|  0.00%|
    58|         0|            0|            0|  0.00%|def initial_seed() -> int:
    59|         0|            0|            0|  0.00%|    r"""Returns the initial seed for generating random numbers as a
    60|         0|            0|            0|  0.00%|    Python `long`.
    61|         0|            0|            0|  0.00%|    """
    62|         0|            0|            0|  0.00%|    return default_generator.initial_seed()
    63|         0|            0|            0|  0.00%|
    64|         0|            0|            0|  0.00%|
    65|         0|            0|            0|  0.00%|_fork_rng_warned_already = False
    66|         0|            0|            0|  0.00%|
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|@contextlib.contextmanager
    69|         0|            0|            0|  0.00%|def fork_rng(devices=None, enabled=True, _caller="fork_rng", _devices_kw="devices") -> Generator:
    70|         0|            0|            0|  0.00%|    """
    71|         0|            0|            0|  0.00%|    Forks the RNG, so that when you return, the RNG is reset
    72|         0|            0|            0|  0.00%|    to the state that it was previously in.
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|    Args:
    75|         0|            0|            0|  0.00%|        devices (iterable of CUDA IDs): CUDA devices for which to fork
    76|         0|            0|            0|  0.00%|            the RNG.  CPU RNG state is always forked.  By default, :meth:`fork_rng` operates
    77|         0|            0|            0|  0.00%|            on all devices, but will emit a warning if your machine has a lot
    78|         0|            0|            0|  0.00%|            of devices, since this function will run very slowly in that case.
    79|         0|            0|            0|  0.00%|            If you explicitly specify devices, this warning will be suppressed
    80|         0|            0|            0|  0.00%|        enabled (bool): if ``False``, the RNG is not forked.  This is a convenience
    81|         0|            0|            0|  0.00%|            argument for easily disabling the context manager without having
    82|         0|            0|            0|  0.00%|            to delete it and unindent your Python code under it.
    83|         0|            0|            0|  0.00%|    """
    84|         0|            0|            0|  0.00%|
    85|         0|            0|            0|  0.00%|    import torch.cuda
    86|         0|            0|            0|  0.00%|    global _fork_rng_warned_already
    87|         0|            0|            0|  0.00%|
    88|         0|            0|            0|  0.00%|    # Internal arguments:
    89|         0|            0|            0|  0.00%|    #   _caller: the function which called fork_rng, which the user used
    90|         0|            0|            0|  0.00%|    #   _devices_kw: the devices keyword of _caller
    91|         0|            0|            0|  0.00%|
    92|         0|            0|            0|  0.00%|    if not enabled:
    93|         0|            0|            0|  0.00%|        yield
    94|         0|            0|            0|  0.00%|        return
    95|         0|            0|            0|  0.00%|
    96|         0|            0|            0|  0.00%|    if devices is None:
    97|         0|            0|            0|  0.00%|        num_devices = torch.cuda.device_count()
    98|         0|            0|            0|  0.00%|        if num_devices > 1 and not _fork_rng_warned_already:
    99|         0|            0|            0|  0.00%|            warnings.warn(
   100|         0|            0|            0|  0.00%|                ("CUDA reports that you have {num_devices} available devices, and you "
   101|         0|            0|            0|  0.00%|                 "have used {caller} without explicitly specifying which devices are being used. "
   102|         0|            0|            0|  0.00%|                 "For safety, we initialize *every* CUDA device by default, which "
   103|         0|            0|            0|  0.00%|                 "can be quite slow if you have a lot of GPUs.  If you know that you are only "
   104|         0|            0|            0|  0.00%|                 "making use of a few CUDA devices, set the environment variable CUDA_VISIBLE_DEVICES "
   105|         0|            0|            0|  0.00%|                 "or the '{devices_kw}' keyword argument of {caller} with the set of devices "
   106|         0|            0|            0|  0.00%|                 "you are actually using.  For example, if you are using CPU only, "
   107|         0|            0|            0|  0.00%|                 "set CUDA_VISIBLE_DEVICES= or devices=[]; if you are using "
   108|         0|            0|            0|  0.00%|                 "GPU 0 only, set CUDA_VISIBLE_DEVICES=0 or devices=[0].  To initialize "
   109|         0|            0|            0|  0.00%|                 "all devices and suppress this warning, set the '{devices_kw}' keyword argument "
   110|         0|            0|            0|  0.00%|                 "to `range(torch.cuda.device_count())`."
   111|         0|            0|            0|  0.00%|                 ).format(num_devices=num_devices, caller=_caller, devices_kw=_devices_kw))
   112|         0|            0|            0|  0.00%|            _fork_rng_warned_already = True
   113|         0|            0|            0|  0.00%|        devices = list(range(num_devices))
   114|         0|            0|            0|  0.00%|    else:
   115|         0|            0|            0|  0.00%|        # Protect against user passing us a generator; we need to traverse this
   116|         0|            0|            0|  0.00%|        # multiple times but a generator will be exhausted upon first traversal
   117|         0|            0|            0|  0.00%|        devices = list(devices)
   118|         0|            0|            0|  0.00%|
   119|         0|            0|            0|  0.00%|    cpu_rng_state = torch.get_rng_state()
   120|         0|            0|            0|  0.00%|    gpu_rng_states = []
   121|         0|            0|            0|  0.00%|    for device in devices:
   122|         0|            0|            0|  0.00%|        gpu_rng_states.append(torch.cuda.get_rng_state(device))
   123|         0|            0|            0|  0.00%|
   124|         0|            0|            0|  0.00%|    try:
   125|         0|            0|            0|  0.00%|        yield
   126|         0|            0|            0|  0.00%|    finally:
   127|         0|            0|            0|  0.00%|        torch.set_rng_state(cpu_rng_state)
   128|         0|            0|            0|  0.00%|        for device, gpu_rng_state in zip(devices, gpu_rng_states):
   129|         0|            0|            0|  0.00%|            torch.cuda.set_rng_state(gpu_rng_state, device)
File: /tmp/ipykernel_29043/360000782.py
File duration: 4.31538e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|def prof():
     2|         0|            0|            0|  0.00%|    return run_eval(env_and_policy, num_samples=10_000, report_freq=1000)
     3|         0|            0|            0|  0.00%|
     4|         1|  7.15256e-06|  7.15256e-06|  0.00%|def prof_training():
(call)|         1|      104.375|      104.375|100.00%|# /tmp/ipykernel_29043/360000782.py:4 prof_training
     5|         1|  1.45435e-05|  1.45435e-05|  0.00%|    timesteps = 100_000
     6|         1|  2.14577e-05|  2.14577e-05|  0.00%|    return run_ppo(env_and_policy, 10_000)
(call)|         1|      104.375|      104.375|100.00%|# /apps/open_spiel/open_spiel/python/examples/ppo_utils.py:334 run_ppo
File: /home/ubuntu/.pyenv/versions/3.8.2/lib/python3.8/gettext.py
File duration: 2.86102e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|"""Internationalization and localization support.
     2|         0|            0|            0|  0.00%|
     3|         0|            0|            0|  0.00%|This module provides internationalization (I18N) and localization (L10N)
     4|         0|            0|            0|  0.00%|support for your Python programs by providing an interface to the GNU gettext
     5|         0|            0|            0|  0.00%|message catalog library.
     6|         0|            0|            0|  0.00%|
     7|         0|            0|            0|  0.00%|I18N refers to the operation by which a program is made aware of multiple
     8|         0|            0|            0|  0.00%|languages.  L10N refers to the adaptation of your program, once
     9|         0|            0|            0|  0.00%|internationalized, to the local language and cultural habits.
    10|         0|            0|            0|  0.00%|
    11|         0|            0|            0|  0.00%|"""
    12|         0|            0|            0|  0.00%|
    13|         0|            0|            0|  0.00%|# This module represents the integration of work, contributions, feedback, and
    14|         0|            0|            0|  0.00%|# suggestions from the following people:
    15|         0|            0|            0|  0.00%|#
    16|         0|            0|            0|  0.00%|# Martin von Loewis, who wrote the initial implementation of the underlying
    17|         0|            0|            0|  0.00%|# C-based libintlmodule (later renamed _gettext), along with a skeletal
    18|         0|            0|            0|  0.00%|# gettext.py implementation.
    19|         0|            0|            0|  0.00%|#
    20|         0|            0|            0|  0.00%|# Peter Funk, who wrote fintl.py, a fairly complete wrapper around intlmodule,
    21|         0|            0|            0|  0.00%|# which also included a pure-Python implementation to read .mo files if
    22|         0|            0|            0|  0.00%|# intlmodule wasn't available.
    23|         0|            0|            0|  0.00%|#
    24|         0|            0|            0|  0.00%|# James Henstridge, who also wrote a gettext.py module, which has some
    25|         0|            0|            0|  0.00%|# interesting, but currently unsupported experimental features: the notion of
    26|         0|            0|            0|  0.00%|# a Catalog class and instances, and the ability to add to a catalog file via
    27|         0|            0|            0|  0.00%|# a Python API.
    28|         0|            0|            0|  0.00%|#
    29|         0|            0|            0|  0.00%|# Barry Warsaw integrated these modules, wrote the .install() API and code,
    30|         0|            0|            0|  0.00%|# and conformed all C and Python code to Python's coding standards.
    31|         0|            0|            0|  0.00%|#
    32|         0|            0|            0|  0.00%|# Francois Pinard and Marc-Andre Lemburg also contributed valuably to this
    33|         0|            0|            0|  0.00%|# module.
    34|         0|            0|            0|  0.00%|#
    35|         0|            0|            0|  0.00%|# J. David Ibanez implemented plural forms. Bruno Haible fixed some bugs.
    36|         0|            0|            0|  0.00%|#
    37|         0|            0|            0|  0.00%|# TODO:
    38|         0|            0|            0|  0.00%|# - Lazy loading of .mo files.  Currently the entire catalog is loaded into
    39|         0|            0|            0|  0.00%|#   memory, but that's probably bad for large translated programs.  Instead,
    40|         0|            0|            0|  0.00%|#   the lexical sort of original strings in GNU .mo files should be exploited
    41|         0|            0|            0|  0.00%|#   to do binary searches and lazy initializations.  Or you might want to use
    42|         0|            0|            0|  0.00%|#   the undocumented double-hash algorithm for .mo files with hash tables, but
    43|         0|            0|            0|  0.00%|#   you'll need to study the GNU gettext code to do this.
    44|         0|            0|            0|  0.00%|#
    45|         0|            0|            0|  0.00%|# - Support Solaris .mo file formats.  Unfortunately, we've been unable to
    46|         0|            0|            0|  0.00%|#   find this format documented anywhere.
    47|         0|            0|            0|  0.00%|
    48|         0|            0|            0|  0.00%|
    49|         0|            0|            0|  0.00%|import locale
    50|         0|            0|            0|  0.00%|import os
    51|         0|            0|            0|  0.00%|import re
    52|         0|            0|            0|  0.00%|import sys
    53|         0|            0|            0|  0.00%|
    54|         0|            0|            0|  0.00%|
    55|         0|            0|            0|  0.00%|__all__ = ['NullTranslations', 'GNUTranslations', 'Catalog',
    56|         0|            0|            0|  0.00%|           'find', 'translation', 'install', 'textdomain', 'bindtextdomain',
    57|         0|            0|            0|  0.00%|           'bind_textdomain_codeset',
    58|         0|            0|            0|  0.00%|           'dgettext', 'dngettext', 'gettext', 'lgettext', 'ldgettext',
    59|         0|            0|            0|  0.00%|           'ldngettext', 'lngettext', 'ngettext',
    60|         0|            0|            0|  0.00%|           'pgettext', 'dpgettext', 'npgettext', 'dnpgettext',
    61|         0|            0|            0|  0.00%|           ]
    62|         0|            0|            0|  0.00%|
    63|         0|            0|            0|  0.00%|_default_localedir = os.path.join(sys.base_prefix, 'share', 'locale')
    64|         0|            0|            0|  0.00%|
    65|         0|            0|            0|  0.00%|# Expression parsing for plural form selection.
    66|         0|            0|            0|  0.00%|#
    67|         0|            0|            0|  0.00%|# The gettext library supports a small subset of C syntax.  The only
    68|         0|            0|            0|  0.00%|# incompatible difference is that integer literals starting with zero are
    69|         0|            0|            0|  0.00%|# decimal.
    70|         0|            0|            0|  0.00%|#
    71|         0|            0|            0|  0.00%|# https://www.gnu.org/software/gettext/manual/gettext.html#Plural-forms
    72|         0|            0|            0|  0.00%|# http://git.savannah.gnu.org/cgit/gettext.git/tree/gettext-runtime/intl/plural.y
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|_token_pattern = re.compile(r"""
    75|         0|            0|            0|  0.00%|        (?P<WHITESPACES>[ \t]+)                    | # spaces and horizontal tabs
    76|         0|            0|            0|  0.00%|        (?P<NUMBER>[0-9]+\b)                       | # decimal integer
    77|         0|            0|            0|  0.00%|        (?P<NAME>n\b)                              | # only n is allowed
    78|         0|            0|            0|  0.00%|        (?P<PARENTHESIS>[()])                      |
    79|         0|            0|            0|  0.00%|        (?P<OPERATOR>[-*/%+?:]|[><!]=?|==|&&|\|\|) | # !, *, /, %, +, -, <, >,
    80|         0|            0|            0|  0.00%|                                                     # <=, >=, ==, !=, &&, ||,
    81|         0|            0|            0|  0.00%|                                                     # ? :
    82|         0|            0|            0|  0.00%|                                                     # unary and bitwise ops
    83|         0|            0|            0|  0.00%|                                                     # not allowed
    84|         0|            0|            0|  0.00%|        (?P<INVALID>\w+|.)                           # invalid token
    85|         0|            0|            0|  0.00%|    """, re.VERBOSE|re.DOTALL)
    86|         0|            0|            0|  0.00%|
    87|         0|            0|            0|  0.00%|def _tokenize(plural):
    88|         0|            0|            0|  0.00%|    for mo in re.finditer(_token_pattern, plural):
    89|         0|            0|            0|  0.00%|        kind = mo.lastgroup
    90|         0|            0|            0|  0.00%|        if kind == 'WHITESPACES':
    91|         0|            0|            0|  0.00%|            continue
    92|         0|            0|            0|  0.00%|        value = mo.group(kind)
    93|         0|            0|            0|  0.00%|        if kind == 'INVALID':
    94|         0|            0|            0|  0.00%|            raise ValueError('invalid token in plural form: %s' % value)
    95|         0|            0|            0|  0.00%|        yield value
    96|         0|            0|            0|  0.00%|    yield ''
    97|         0|            0|            0|  0.00%|
    98|         0|            0|            0|  0.00%|def _error(value):
    99|         0|            0|            0|  0.00%|    if value:
   100|         0|            0|            0|  0.00%|        return ValueError('unexpected token in plural form: %s' % value)
   101|         0|            0|            0|  0.00%|    else:
   102|         0|            0|            0|  0.00%|        return ValueError('unexpected end of plural form')
   103|         0|            0|            0|  0.00%|
   104|         0|            0|            0|  0.00%|_binary_ops = (
   105|         0|            0|            0|  0.00%|    ('||',),
   106|         0|            0|            0|  0.00%|    ('&&',),
   107|         0|            0|            0|  0.00%|    ('==', '!='),
   108|         0|            0|            0|  0.00%|    ('<', '>', '<=', '>='),
   109|         0|            0|            0|  0.00%|    ('+', '-'),
   110|         0|            0|            0|  0.00%|    ('*', '/', '%'),
   111|         0|            0|            0|  0.00%|)
   112|         0|            0|            0|  0.00%|_binary_ops = {op: i for i, ops in enumerate(_binary_ops, 1) for op in ops}
   113|         0|            0|            0|  0.00%|_c2py_ops = {'||': 'or', '&&': 'and', '/': '//'}
   114|         0|            0|            0|  0.00%|
   115|         0|            0|            0|  0.00%|def _parse(tokens, priority=-1):
   116|         0|            0|            0|  0.00%|    result = ''
   117|         0|            0|            0|  0.00%|    nexttok = next(tokens)
   118|         0|            0|            0|  0.00%|    while nexttok == '!':
   119|         0|            0|            0|  0.00%|        result += 'not '
   120|         0|            0|            0|  0.00%|        nexttok = next(tokens)
   121|         0|            0|            0|  0.00%|
   122|         0|            0|            0|  0.00%|    if nexttok == '(':
   123|         0|            0|            0|  0.00%|        sub, nexttok = _parse(tokens)
   124|         0|            0|            0|  0.00%|        result = '%s(%s)' % (result, sub)
   125|         0|            0|            0|  0.00%|        if nexttok != ')':
   126|         0|            0|            0|  0.00%|            raise ValueError('unbalanced parenthesis in plural form')
   127|         0|            0|            0|  0.00%|    elif nexttok == 'n':
   128|         0|            0|            0|  0.00%|        result = '%s%s' % (result, nexttok)
   129|         0|            0|            0|  0.00%|    else:
   130|         0|            0|            0|  0.00%|        try:
   131|         0|            0|            0|  0.00%|            value = int(nexttok, 10)
   132|         0|            0|            0|  0.00%|        except ValueError:
   133|         0|            0|            0|  0.00%|            raise _error(nexttok) from None
   134|         0|            0|            0|  0.00%|        result = '%s%d' % (result, value)
   135|         0|            0|            0|  0.00%|    nexttok = next(tokens)
   136|         0|            0|            0|  0.00%|
   137|         0|            0|            0|  0.00%|    j = 100
   138|         0|            0|            0|  0.00%|    while nexttok in _binary_ops:
   139|         0|            0|            0|  0.00%|        i = _binary_ops[nexttok]
   140|         0|            0|            0|  0.00%|        if i < priority:
   141|         0|            0|            0|  0.00%|            break
   142|         0|            0|            0|  0.00%|        # Break chained comparisons
   143|         0|            0|            0|  0.00%|        if i in (3, 4) and j in (3, 4):  # '==', '!=', '<', '>', '<=', '>='
   144|         0|            0|            0|  0.00%|            result = '(%s)' % result
   145|         0|            0|            0|  0.00%|        # Replace some C operators by their Python equivalents
   146|         0|            0|            0|  0.00%|        op = _c2py_ops.get(nexttok, nexttok)
   147|         0|            0|            0|  0.00%|        right, nexttok = _parse(tokens, i + 1)
   148|         0|            0|            0|  0.00%|        result = '%s %s %s' % (result, op, right)
   149|         0|            0|            0|  0.00%|        j = i
   150|         0|            0|            0|  0.00%|    if j == priority == 4:  # '<', '>', '<=', '>='
   151|         0|            0|            0|  0.00%|        result = '(%s)' % result
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|    if nexttok == '?' and priority <= 0:
   154|         0|            0|            0|  0.00%|        if_true, nexttok = _parse(tokens, 0)
   155|         0|            0|            0|  0.00%|        if nexttok != ':':
   156|         0|            0|            0|  0.00%|            raise _error(nexttok)
   157|         0|            0|            0|  0.00%|        if_false, nexttok = _parse(tokens)
   158|         0|            0|            0|  0.00%|        result = '%s if %s else %s' % (if_true, result, if_false)
   159|         0|            0|            0|  0.00%|        if priority == 0:
   160|         0|            0|            0|  0.00%|            result = '(%s)' % result
   161|         0|            0|            0|  0.00%|
   162|         0|            0|            0|  0.00%|    return result, nexttok
   163|         0|            0|            0|  0.00%|
   164|         0|            0|            0|  0.00%|def _as_int(n):
   165|         0|            0|            0|  0.00%|    try:
   166|         0|            0|            0|  0.00%|        i = round(n)
   167|         0|            0|            0|  0.00%|    except TypeError:
   168|         0|            0|            0|  0.00%|        raise TypeError('Plural value must be an integer, got %s' %
   169|         0|            0|            0|  0.00%|                        (n.__class__.__name__,)) from None
   170|         0|            0|            0|  0.00%|    import warnings
   171|         0|            0|            0|  0.00%|    warnings.warn('Plural value must be an integer, got %s' %
   172|         0|            0|            0|  0.00%|                  (n.__class__.__name__,),
   173|         0|            0|            0|  0.00%|                  DeprecationWarning, 4)
   174|         0|            0|            0|  0.00%|    return n
   175|         0|            0|            0|  0.00%|
   176|         0|            0|            0|  0.00%|def c2py(plural):
   177|         0|            0|            0|  0.00%|    """Gets a C expression as used in PO files for plural forms and returns a
   178|         0|            0|            0|  0.00%|    Python function that implements an equivalent expression.
   179|         0|            0|            0|  0.00%|    """
   180|         0|            0|            0|  0.00%|
   181|         0|            0|            0|  0.00%|    if len(plural) > 1000:
   182|         0|            0|            0|  0.00%|        raise ValueError('plural form expression is too long')
   183|         0|            0|            0|  0.00%|    try:
   184|         0|            0|            0|  0.00%|        result, nexttok = _parse(_tokenize(plural))
   185|         0|            0|            0|  0.00%|        if nexttok:
   186|         0|            0|            0|  0.00%|            raise _error(nexttok)
   187|         0|            0|            0|  0.00%|
   188|         0|            0|            0|  0.00%|        depth = 0
   189|         0|            0|            0|  0.00%|        for c in result:
   190|         0|            0|            0|  0.00%|            if c == '(':
   191|         0|            0|            0|  0.00%|                depth += 1
   192|         0|            0|            0|  0.00%|                if depth > 20:
   193|         0|            0|            0|  0.00%|                    # Python compiler limit is about 90.
   194|         0|            0|            0|  0.00%|                    # The most complex example has 2.
   195|         0|            0|            0|  0.00%|                    raise ValueError('plural form expression is too complex')
   196|         0|            0|            0|  0.00%|            elif c == ')':
   197|         0|            0|            0|  0.00%|                depth -= 1
   198|         0|            0|            0|  0.00%|
   199|         0|            0|            0|  0.00%|        ns = {'_as_int': _as_int}
   200|         0|            0|            0|  0.00%|        exec('''if True:
   201|         0|            0|            0|  0.00%|            def func(n):
   202|         0|            0|            0|  0.00%|                if not isinstance(n, int):
   203|         0|            0|            0|  0.00%|                    n = _as_int(n)
   204|         0|            0|            0|  0.00%|                return int(%s)
   205|         0|            0|            0|  0.00%|            ''' % result, ns)
   206|         0|            0|            0|  0.00%|        return ns['func']
   207|         0|            0|            0|  0.00%|    except RecursionError:
   208|         0|            0|            0|  0.00%|        # Recursion error can be raised in _parse() or exec().
   209|         0|            0|            0|  0.00%|        raise ValueError('plural form expression is too complex')
   210|         0|            0|            0|  0.00%|
   211|         0|            0|            0|  0.00%|
   212|         0|            0|            0|  0.00%|def _expand_lang(loc):
   213|         0|            0|            0|  0.00%|    loc = locale.normalize(loc)
   214|         0|            0|            0|  0.00%|    COMPONENT_CODESET   = 1 << 0
   215|         0|            0|            0|  0.00%|    COMPONENT_TERRITORY = 1 << 1
   216|         0|            0|            0|  0.00%|    COMPONENT_MODIFIER  = 1 << 2
   217|         0|            0|            0|  0.00%|    # split up the locale into its base components
   218|         0|            0|            0|  0.00%|    mask = 0
   219|         0|            0|            0|  0.00%|    pos = loc.find('@')
   220|         0|            0|            0|  0.00%|    if pos >= 0:
   221|         0|            0|            0|  0.00%|        modifier = loc[pos:]
   222|         0|            0|            0|  0.00%|        loc = loc[:pos]
   223|         0|            0|            0|  0.00%|        mask |= COMPONENT_MODIFIER
   224|         0|            0|            0|  0.00%|    else:
   225|         0|            0|            0|  0.00%|        modifier = ''
   226|         0|            0|            0|  0.00%|    pos = loc.find('.')
   227|         0|            0|            0|  0.00%|    if pos >= 0:
   228|         0|            0|            0|  0.00%|        codeset = loc[pos:]
   229|         0|            0|            0|  0.00%|        loc = loc[:pos]
   230|         0|            0|            0|  0.00%|        mask |= COMPONENT_CODESET
   231|         0|            0|            0|  0.00%|    else:
   232|         0|            0|            0|  0.00%|        codeset = ''
   233|         0|            0|            0|  0.00%|    pos = loc.find('_')
   234|         0|            0|            0|  0.00%|    if pos >= 0:
   235|         0|            0|            0|  0.00%|        territory = loc[pos:]
   236|         0|            0|            0|  0.00%|        loc = loc[:pos]
   237|         0|            0|            0|  0.00%|        mask |= COMPONENT_TERRITORY
   238|         0|            0|            0|  0.00%|    else:
   239|         0|            0|            0|  0.00%|        territory = ''
   240|         0|            0|            0|  0.00%|    language = loc
   241|         0|            0|            0|  0.00%|    ret = []
   242|         0|            0|            0|  0.00%|    for i in range(mask+1):
   243|         0|            0|            0|  0.00%|        if not (i & ~mask):  # if all components for this combo exist ...
   244|         0|            0|            0|  0.00%|            val = language
   245|         0|            0|            0|  0.00%|            if i & COMPONENT_TERRITORY: val += territory
   246|         0|            0|            0|  0.00%|            if i & COMPONENT_CODESET:   val += codeset
   247|         0|            0|            0|  0.00%|            if i & COMPONENT_MODIFIER:  val += modifier
   248|         0|            0|            0|  0.00%|            ret.append(val)
   249|         0|            0|            0|  0.00%|    ret.reverse()
   250|         0|            0|            0|  0.00%|    return ret
   251|         0|            0|            0|  0.00%|
   252|         0|            0|            0|  0.00%|
   253|         0|            0|            0|  0.00%|
   254|         0|            0|            0|  0.00%|class NullTranslations:
   255|         0|            0|            0|  0.00%|    def __init__(self, fp=None):
   256|         0|            0|            0|  0.00%|        self._info = {}
   257|         0|            0|            0|  0.00%|        self._charset = None
   258|         0|            0|            0|  0.00%|        self._output_charset = None
   259|         0|            0|            0|  0.00%|        self._fallback = None
   260|         0|            0|            0|  0.00%|        if fp is not None:
   261|         0|            0|            0|  0.00%|            self._parse(fp)
   262|         0|            0|            0|  0.00%|
   263|         0|            0|            0|  0.00%|    def _parse(self, fp):
   264|         0|            0|            0|  0.00%|        pass
   265|         0|            0|            0|  0.00%|
   266|         0|            0|            0|  0.00%|    def add_fallback(self, fallback):
   267|         0|            0|            0|  0.00%|        if self._fallback:
   268|         0|            0|            0|  0.00%|            self._fallback.add_fallback(fallback)
   269|         0|            0|            0|  0.00%|        else:
   270|         0|            0|            0|  0.00%|            self._fallback = fallback
   271|         0|            0|            0|  0.00%|
   272|         1|  2.38419e-06|  2.38419e-06|  0.00%|    def gettext(self, message):
   273|         1|  2.86102e-06|  2.86102e-06|  0.00%|        if self._fallback:
   274|         0|            0|            0|  0.00%|            return self._fallback.gettext(message)
   275|         1|  2.14577e-06|  2.14577e-06|  0.00%|        return message
   276|         0|            0|            0|  0.00%|
   277|         0|            0|            0|  0.00%|    def lgettext(self, message):
   278|         0|            0|            0|  0.00%|        import warnings
   279|         0|            0|            0|  0.00%|        warnings.warn('lgettext() is deprecated, use gettext() instead',
   280|         0|            0|            0|  0.00%|                      DeprecationWarning, 2)
   281|         0|            0|            0|  0.00%|        if self._fallback:
   282|         0|            0|            0|  0.00%|            with warnings.catch_warnings():
   283|         0|            0|            0|  0.00%|                warnings.filterwarnings('ignore', r'.*\blgettext\b.*',
   284|         0|            0|            0|  0.00%|                                        DeprecationWarning)
   285|         0|            0|            0|  0.00%|                return self._fallback.lgettext(message)
   286|         0|            0|            0|  0.00%|        if self._output_charset:
   287|         0|            0|            0|  0.00%|            return message.encode(self._output_charset)
   288|         0|            0|            0|  0.00%|        return message.encode(locale.getpreferredencoding())
   289|         0|            0|            0|  0.00%|
   290|         2|  4.29153e-06|  2.14577e-06|  0.00%|    def ngettext(self, msgid1, msgid2, n):
   291|         2|  8.58307e-06|  4.29153e-06|  0.00%|        if self._fallback:
   292|         0|            0|            0|  0.00%|            return self._fallback.ngettext(msgid1, msgid2, n)
   293|         2|  4.05312e-06|  2.02656e-06|  0.00%|        if n == 1:
   294|         1|   2.6226e-06|   2.6226e-06|  0.00%|            return msgid1
   295|         0|            0|            0|  0.00%|        else:
   296|         1|  1.66893e-06|  1.66893e-06|  0.00%|            return msgid2
   297|         0|            0|            0|  0.00%|
   298|         0|            0|            0|  0.00%|    def lngettext(self, msgid1, msgid2, n):
   299|         0|            0|            0|  0.00%|        import warnings
   300|         0|            0|            0|  0.00%|        warnings.warn('lngettext() is deprecated, use ngettext() instead',
   301|         0|            0|            0|  0.00%|                      DeprecationWarning, 2)
   302|         0|            0|            0|  0.00%|        if self._fallback:
   303|         0|            0|            0|  0.00%|            with warnings.catch_warnings():
   304|         0|            0|            0|  0.00%|                warnings.filterwarnings('ignore', r'.*\blngettext\b.*',
   305|         0|            0|            0|  0.00%|                                        DeprecationWarning)
   306|         0|            0|            0|  0.00%|                return self._fallback.lngettext(msgid1, msgid2, n)
   307|         0|            0|            0|  0.00%|        if n == 1:
   308|         0|            0|            0|  0.00%|            tmsg = msgid1
   309|         0|            0|            0|  0.00%|        else:
   310|         0|            0|            0|  0.00%|            tmsg = msgid2
   311|         0|            0|            0|  0.00%|        if self._output_charset:
   312|         0|            0|            0|  0.00%|            return tmsg.encode(self._output_charset)
   313|         0|            0|            0|  0.00%|        return tmsg.encode(locale.getpreferredencoding())
   314|         0|            0|            0|  0.00%|
   315|         0|            0|            0|  0.00%|    def pgettext(self, context, message):
   316|         0|            0|            0|  0.00%|        if self._fallback:
   317|         0|            0|            0|  0.00%|            return self._fallback.pgettext(context, message)
   318|         0|            0|            0|  0.00%|        return message
   319|         0|            0|            0|  0.00%|
   320|         0|            0|            0|  0.00%|    def npgettext(self, context, msgid1, msgid2, n):
   321|         0|            0|            0|  0.00%|        if self._fallback:
   322|         0|            0|            0|  0.00%|            return self._fallback.npgettext(context, msgid1, msgid2, n)
   323|         0|            0|            0|  0.00%|        if n == 1:
   324|         0|            0|            0|  0.00%|            return msgid1
   325|         0|            0|            0|  0.00%|        else:
   326|         0|            0|            0|  0.00%|            return msgid2
   327|         0|            0|            0|  0.00%|
   328|         0|            0|            0|  0.00%|    def info(self):
   329|         0|            0|            0|  0.00%|        return self._info
   330|         0|            0|            0|  0.00%|
   331|         0|            0|            0|  0.00%|    def charset(self):
   332|         0|            0|            0|  0.00%|        return self._charset
   333|         0|            0|            0|  0.00%|
   334|         0|            0|            0|  0.00%|    def output_charset(self):
   335|         0|            0|            0|  0.00%|        import warnings
   336|         0|            0|            0|  0.00%|        warnings.warn('output_charset() is deprecated',
   337|         0|            0|            0|  0.00%|                      DeprecationWarning, 2)
   338|         0|            0|            0|  0.00%|        return self._output_charset
   339|         0|            0|            0|  0.00%|
   340|         0|            0|            0|  0.00%|    def set_output_charset(self, charset):
   341|         0|            0|            0|  0.00%|        import warnings
   342|         0|            0|            0|  0.00%|        warnings.warn('set_output_charset() is deprecated',
   343|         0|            0|            0|  0.00%|                      DeprecationWarning, 2)
   344|         0|            0|            0|  0.00%|        self._output_charset = charset
   345|         0|            0|            0|  0.00%|
   346|         0|            0|            0|  0.00%|    def install(self, names=None):
   347|         0|            0|            0|  0.00%|        import builtins
   348|         0|            0|            0|  0.00%|        builtins.__dict__['_'] = self.gettext
   349|         0|            0|            0|  0.00%|        if names is not None:
   350|         0|            0|            0|  0.00%|            allowed = {'gettext', 'lgettext', 'lngettext',
   351|         0|            0|            0|  0.00%|                       'ngettext', 'npgettext', 'pgettext'}
   352|         0|            0|            0|  0.00%|            for name in allowed & set(names):
   353|         0|            0|            0|  0.00%|                builtins.__dict__[name] = getattr(self, name)
   354|         0|            0|            0|  0.00%|
   355|         0|            0|            0|  0.00%|
   356|         0|            0|            0|  0.00%|class GNUTranslations(NullTranslations):
   357|         0|            0|            0|  0.00%|    # Magic number of .mo files
   358|         0|            0|            0|  0.00%|    LE_MAGIC = 0x950412de
   359|         0|            0|            0|  0.00%|    BE_MAGIC = 0xde120495
   360|         0|            0|            0|  0.00%|
   361|         0|            0|            0|  0.00%|    # The encoding of a msgctxt and a msgid in a .mo file is
   362|         0|            0|            0|  0.00%|    # msgctxt + "\x04" + msgid (gettext version >= 0.15)
   363|         0|            0|            0|  0.00%|    CONTEXT = "%s\x04%s"
   364|         0|            0|            0|  0.00%|
   365|         0|            0|            0|  0.00%|    # Acceptable .mo versions
   366|         0|            0|            0|  0.00%|    VERSIONS = (0, 1)
   367|         0|            0|            0|  0.00%|
   368|         0|            0|            0|  0.00%|    def _get_versions(self, version):
   369|         0|            0|            0|  0.00%|        """Returns a tuple of major version, minor version"""
   370|         0|            0|            0|  0.00%|        return (version >> 16, version & 0xffff)
   371|         0|            0|            0|  0.00%|
   372|         0|            0|            0|  0.00%|    def _parse(self, fp):
   373|         0|            0|            0|  0.00%|        """Override this method to support alternative .mo formats."""
   374|         0|            0|            0|  0.00%|        # Delay struct import for speeding up gettext import when .mo files
   375|         0|            0|            0|  0.00%|        # are not used.
   376|         0|            0|            0|  0.00%|        from struct import unpack
   377|         0|            0|            0|  0.00%|        filename = getattr(fp, 'name', '')
   378|         0|            0|            0|  0.00%|        # Parse the .mo file header, which consists of 5 little endian 32
   379|         0|            0|            0|  0.00%|        # bit words.
   380|         0|            0|            0|  0.00%|        self._catalog = catalog = {}
   381|         0|            0|            0|  0.00%|        self.plural = lambda n: int(n != 1) # germanic plural by default
   382|         0|            0|            0|  0.00%|        buf = fp.read()
   383|         0|            0|            0|  0.00%|        buflen = len(buf)
   384|         0|            0|            0|  0.00%|        # Are we big endian or little endian?
   385|         0|            0|            0|  0.00%|        magic = unpack('<I', buf[:4])[0]
   386|         0|            0|            0|  0.00%|        if magic == self.LE_MAGIC:
   387|         0|            0|            0|  0.00%|            version, msgcount, masteridx, transidx = unpack('<4I', buf[4:20])
   388|         0|            0|            0|  0.00%|            ii = '<II'
   389|         0|            0|            0|  0.00%|        elif magic == self.BE_MAGIC:
   390|         0|            0|            0|  0.00%|            version, msgcount, masteridx, transidx = unpack('>4I', buf[4:20])
   391|         0|            0|            0|  0.00%|            ii = '>II'
   392|         0|            0|            0|  0.00%|        else:
   393|         0|            0|            0|  0.00%|            raise OSError(0, 'Bad magic number', filename)
   394|         0|            0|            0|  0.00%|
   395|         0|            0|            0|  0.00%|        major_version, minor_version = self._get_versions(version)
   396|         0|            0|            0|  0.00%|
   397|         0|            0|            0|  0.00%|        if major_version not in self.VERSIONS:
   398|         0|            0|            0|  0.00%|            raise OSError(0, 'Bad version number ' + str(major_version), filename)
   399|         0|            0|            0|  0.00%|
   400|         0|            0|            0|  0.00%|        # Now put all messages from the .mo file buffer into the catalog
   401|         0|            0|            0|  0.00%|        # dictionary.
   402|         0|            0|            0|  0.00%|        for i in range(0, msgcount):
   403|         0|            0|            0|  0.00%|            mlen, moff = unpack(ii, buf[masteridx:masteridx+8])
   404|         0|            0|            0|  0.00%|            mend = moff + mlen
   405|         0|            0|            0|  0.00%|            tlen, toff = unpack(ii, buf[transidx:transidx+8])
   406|         0|            0|            0|  0.00%|            tend = toff + tlen
   407|         0|            0|            0|  0.00%|            if mend < buflen and tend < buflen:
   408|         0|            0|            0|  0.00%|                msg = buf[moff:mend]
   409|         0|            0|            0|  0.00%|                tmsg = buf[toff:tend]
   410|         0|            0|            0|  0.00%|            else:
   411|         0|            0|            0|  0.00%|                raise OSError(0, 'File is corrupt', filename)
   412|         0|            0|            0|  0.00%|            # See if we're looking at GNU .mo conventions for metadata
   413|         0|            0|            0|  0.00%|            if mlen == 0:
   414|         0|            0|            0|  0.00%|                # Catalog description
   415|         0|            0|            0|  0.00%|                lastk = None
   416|         0|            0|            0|  0.00%|                for b_item in tmsg.split(b'\n'):
   417|         0|            0|            0|  0.00%|                    item = b_item.decode().strip()
   418|         0|            0|            0|  0.00%|                    if not item:
   419|         0|            0|            0|  0.00%|                        continue
   420|         0|            0|            0|  0.00%|                    # Skip over comment lines:
   421|         0|            0|            0|  0.00%|                    if item.startswith('#-#-#-#-#') and item.endswith('#-#-#-#-#'):
   422|         0|            0|            0|  0.00%|                        continue
   423|         0|            0|            0|  0.00%|                    k = v = None
   424|         0|            0|            0|  0.00%|                    if ':' in item:
   425|         0|            0|            0|  0.00%|                        k, v = item.split(':', 1)
   426|         0|            0|            0|  0.00%|                        k = k.strip().lower()
   427|         0|            0|            0|  0.00%|                        v = v.strip()
   428|         0|            0|            0|  0.00%|                        self._info[k] = v
   429|         0|            0|            0|  0.00%|                        lastk = k
   430|         0|            0|            0|  0.00%|                    elif lastk:
   431|         0|            0|            0|  0.00%|                        self._info[lastk] += '\n' + item
   432|         0|            0|            0|  0.00%|                    if k == 'content-type':
   433|         0|            0|            0|  0.00%|                        self._charset = v.split('charset=')[1]
   434|         0|            0|            0|  0.00%|                    elif k == 'plural-forms':
   435|         0|            0|            0|  0.00%|                        v = v.split(';')
   436|         0|            0|            0|  0.00%|                        plural = v[1].split('plural=')[1]
   437|         0|            0|            0|  0.00%|                        self.plural = c2py(plural)
   438|         0|            0|            0|  0.00%|            # Note: we unconditionally convert both msgids and msgstrs to
   439|         0|            0|            0|  0.00%|            # Unicode using the character encoding specified in the charset
   440|         0|            0|            0|  0.00%|            # parameter of the Content-Type header.  The gettext documentation
   441|         0|            0|            0|  0.00%|            # strongly encourages msgids to be us-ascii, but some applications
   442|         0|            0|            0|  0.00%|            # require alternative encodings (e.g. Zope's ZCML and ZPT).  For
   443|         0|            0|            0|  0.00%|            # traditional gettext applications, the msgid conversion will
   444|         0|            0|            0|  0.00%|            # cause no problems since us-ascii should always be a subset of
   445|         0|            0|            0|  0.00%|            # the charset encoding.  We may want to fall back to 8-bit msgids
   446|         0|            0|            0|  0.00%|            # if the Unicode conversion fails.
   447|         0|            0|            0|  0.00%|            charset = self._charset or 'ascii'
   448|         0|            0|            0|  0.00%|            if b'\x00' in msg:
   449|         0|            0|            0|  0.00%|                # Plural forms
   450|         0|            0|            0|  0.00%|                msgid1, msgid2 = msg.split(b'\x00')
   451|         0|            0|            0|  0.00%|                tmsg = tmsg.split(b'\x00')
   452|         0|            0|            0|  0.00%|                msgid1 = str(msgid1, charset)
   453|         0|            0|            0|  0.00%|                for i, x in enumerate(tmsg):
   454|         0|            0|            0|  0.00%|                    catalog[(msgid1, i)] = str(x, charset)
   455|         0|            0|            0|  0.00%|            else:
   456|         0|            0|            0|  0.00%|                catalog[str(msg, charset)] = str(tmsg, charset)
   457|         0|            0|            0|  0.00%|            # advance to next entry in the seek tables
   458|         0|            0|            0|  0.00%|            masteridx += 8
   459|         0|            0|            0|  0.00%|            transidx += 8
   460|         0|            0|            0|  0.00%|
   461|         0|            0|            0|  0.00%|    def lgettext(self, message):
   462|         0|            0|            0|  0.00%|        import warnings
   463|         0|            0|            0|  0.00%|        warnings.warn('lgettext() is deprecated, use gettext() instead',
   464|         0|            0|            0|  0.00%|                      DeprecationWarning, 2)
   465|         0|            0|            0|  0.00%|        missing = object()
   466|         0|            0|            0|  0.00%|        tmsg = self._catalog.get(message, missing)
   467|         0|            0|            0|  0.00%|        if tmsg is missing:
   468|         0|            0|            0|  0.00%|            if self._fallback:
   469|         0|            0|            0|  0.00%|                return self._fallback.lgettext(message)
   470|         0|            0|            0|  0.00%|            tmsg = message
   471|         0|            0|            0|  0.00%|        if self._output_charset:
   472|         0|            0|            0|  0.00%|            return tmsg.encode(self._output_charset)
   473|         0|            0|            0|  0.00%|        return tmsg.encode(locale.getpreferredencoding())
   474|         0|            0|            0|  0.00%|
   475|         0|            0|            0|  0.00%|    def lngettext(self, msgid1, msgid2, n):
   476|         0|            0|            0|  0.00%|        import warnings
   477|         0|            0|            0|  0.00%|        warnings.warn('lngettext() is deprecated, use ngettext() instead',
   478|         0|            0|            0|  0.00%|                      DeprecationWarning, 2)
   479|         0|            0|            0|  0.00%|        try:
   480|         0|            0|            0|  0.00%|            tmsg = self._catalog[(msgid1, self.plural(n))]
   481|         0|            0|            0|  0.00%|        except KeyError:
   482|         0|            0|            0|  0.00%|            if self._fallback:
   483|         0|            0|            0|  0.00%|                return self._fallback.lngettext(msgid1, msgid2, n)
   484|         0|            0|            0|  0.00%|            if n == 1:
   485|         0|            0|            0|  0.00%|                tmsg = msgid1
   486|         0|            0|            0|  0.00%|            else:
   487|         0|            0|            0|  0.00%|                tmsg = msgid2
   488|         0|            0|            0|  0.00%|        if self._output_charset:
   489|         0|            0|            0|  0.00%|            return tmsg.encode(self._output_charset)
   490|         0|            0|            0|  0.00%|        return tmsg.encode(locale.getpreferredencoding())
   491|         0|            0|            0|  0.00%|
   492|         0|            0|            0|  0.00%|    def gettext(self, message):
   493|         0|            0|            0|  0.00%|        missing = object()
   494|         0|            0|            0|  0.00%|        tmsg = self._catalog.get(message, missing)
   495|         0|            0|            0|  0.00%|        if tmsg is missing:
   496|         0|            0|            0|  0.00%|            if self._fallback:
   497|         0|            0|            0|  0.00%|                return self._fallback.gettext(message)
   498|         0|            0|            0|  0.00%|            return message
   499|         0|            0|            0|  0.00%|        return tmsg
   500|         0|            0|            0|  0.00%|
   501|         0|            0|            0|  0.00%|    def ngettext(self, msgid1, msgid2, n):
   502|         0|            0|            0|  0.00%|        try:
   503|         0|            0|            0|  0.00%|            tmsg = self._catalog[(msgid1, self.plural(n))]
   504|         0|            0|            0|  0.00%|        except KeyError:
   505|         0|            0|            0|  0.00%|            if self._fallback:
   506|         0|            0|            0|  0.00%|                return self._fallback.ngettext(msgid1, msgid2, n)
   507|         0|            0|            0|  0.00%|            if n == 1:
   508|         0|            0|            0|  0.00%|                tmsg = msgid1
   509|         0|            0|            0|  0.00%|            else:
   510|         0|            0|            0|  0.00%|                tmsg = msgid2
   511|         0|            0|            0|  0.00%|        return tmsg
   512|         0|            0|            0|  0.00%|
   513|         0|            0|            0|  0.00%|    def pgettext(self, context, message):
   514|         0|            0|            0|  0.00%|        ctxt_msg_id = self.CONTEXT % (context, message)
   515|         0|            0|            0|  0.00%|        missing = object()
   516|         0|            0|            0|  0.00%|        tmsg = self._catalog.get(ctxt_msg_id, missing)
   517|         0|            0|            0|  0.00%|        if tmsg is missing:
   518|         0|            0|            0|  0.00%|            if self._fallback:
   519|         0|            0|            0|  0.00%|                return self._fallback.pgettext(context, message)
   520|         0|            0|            0|  0.00%|            return message
   521|         0|            0|            0|  0.00%|        return tmsg
   522|         0|            0|            0|  0.00%|
   523|         0|            0|            0|  0.00%|    def npgettext(self, context, msgid1, msgid2, n):
   524|         0|            0|            0|  0.00%|        ctxt_msg_id = self.CONTEXT % (context, msgid1)
   525|         0|            0|            0|  0.00%|        try:
   526|         0|            0|            0|  0.00%|            tmsg = self._catalog[ctxt_msg_id, self.plural(n)]
   527|         0|            0|            0|  0.00%|        except KeyError:
   528|         0|            0|            0|  0.00%|            if self._fallback:
   529|         0|            0|            0|  0.00%|                return self._fallback.npgettext(context, msgid1, msgid2, n)
   530|         0|            0|            0|  0.00%|            if n == 1:
   531|         0|            0|            0|  0.00%|                tmsg = msgid1
   532|         0|            0|            0|  0.00%|            else:
   533|         0|            0|            0|  0.00%|                tmsg = msgid2
   534|         0|            0|            0|  0.00%|        return tmsg
   535|         0|            0|            0|  0.00%|
   536|         0|            0|            0|  0.00%|
   537|         0|            0|            0|  0.00%|# Locate a .mo file using the gettext strategy
   538|         0|            0|            0|  0.00%|def find(domain, localedir=None, languages=None, all=False):
   539|         0|            0|            0|  0.00%|    # Get some reasonable defaults for arguments that were not supplied
   540|         0|            0|            0|  0.00%|    if localedir is None:
   541|         0|            0|            0|  0.00%|        localedir = _default_localedir
   542|         0|            0|            0|  0.00%|    if languages is None:
   543|         0|            0|            0|  0.00%|        languages = []
   544|         0|            0|            0|  0.00%|        for envar in ('LANGUAGE', 'LC_ALL', 'LC_MESSAGES', 'LANG'):
   545|         0|            0|            0|  0.00%|            val = os.environ.get(envar)
   546|         0|            0|            0|  0.00%|            if val:
   547|         0|            0|            0|  0.00%|                languages = val.split(':')
   548|         0|            0|            0|  0.00%|                break
   549|         0|            0|            0|  0.00%|        if 'C' not in languages:
   550|         0|            0|            0|  0.00%|            languages.append('C')
   551|         0|            0|            0|  0.00%|    # now normalize and expand the languages
   552|         0|            0|            0|  0.00%|    nelangs = []
   553|         0|            0|            0|  0.00%|    for lang in languages:
   554|         0|            0|            0|  0.00%|        for nelang in _expand_lang(lang):
   555|         0|            0|            0|  0.00%|            if nelang not in nelangs:
   556|         0|            0|            0|  0.00%|                nelangs.append(nelang)
   557|         0|            0|            0|  0.00%|    # select a language
   558|         0|            0|            0|  0.00%|    if all:
   559|         0|            0|            0|  0.00%|        result = []
   560|         0|            0|            0|  0.00%|    else:
   561|         0|            0|            0|  0.00%|        result = None
   562|         0|            0|            0|  0.00%|    for lang in nelangs:
   563|         0|            0|            0|  0.00%|        if lang == 'C':
   564|         0|            0|            0|  0.00%|            break
   565|         0|            0|            0|  0.00%|        mofile = os.path.join(localedir, lang, 'LC_MESSAGES', '%s.mo' % domain)
   566|         0|            0|            0|  0.00%|        if os.path.exists(mofile):
   567|         0|            0|            0|  0.00%|            if all:
   568|         0|            0|            0|  0.00%|                result.append(mofile)
   569|         0|            0|            0|  0.00%|            else:
   570|         0|            0|            0|  0.00%|                return mofile
   571|         0|            0|            0|  0.00%|    return result
   572|         0|            0|            0|  0.00%|
   573|         0|            0|            0|  0.00%|
   574|         0|            0|            0|  0.00%|
   575|         0|            0|            0|  0.00%|# a mapping between absolute .mo file path and Translation object
   576|         0|            0|            0|  0.00%|_translations = {}
   577|         0|            0|            0|  0.00%|_unspecified = ['unspecified']
   578|         0|            0|            0|  0.00%|
   579|         0|            0|            0|  0.00%|def translation(domain, localedir=None, languages=None,
   580|         0|            0|            0|  0.00%|                class_=None, fallback=False, codeset=_unspecified):
   581|         0|            0|            0|  0.00%|    if class_ is None:
   582|         0|            0|            0|  0.00%|        class_ = GNUTranslations
   583|         0|            0|            0|  0.00%|    mofiles = find(domain, localedir, languages, all=True)
   584|         0|            0|            0|  0.00%|    if not mofiles:
   585|         0|            0|            0|  0.00%|        if fallback:
   586|         0|            0|            0|  0.00%|            return NullTranslations()
   587|         0|            0|            0|  0.00%|        from errno import ENOENT
   588|         0|            0|            0|  0.00%|        raise FileNotFoundError(ENOENT,
   589|         0|            0|            0|  0.00%|                                'No translation file found for domain', domain)
   590|         0|            0|            0|  0.00%|    # Avoid opening, reading, and parsing the .mo file after it's been done
   591|         0|            0|            0|  0.00%|    # once.
   592|         0|            0|            0|  0.00%|    result = None
   593|         0|            0|            0|  0.00%|    for mofile in mofiles:
   594|         0|            0|            0|  0.00%|        key = (class_, os.path.abspath(mofile))
   595|         0|            0|            0|  0.00%|        t = _translations.get(key)
   596|         0|            0|            0|  0.00%|        if t is None:
   597|         0|            0|            0|  0.00%|            with open(mofile, 'rb') as fp:
   598|         0|            0|            0|  0.00%|                t = _translations.setdefault(key, class_(fp))
   599|         0|            0|            0|  0.00%|        # Copy the translation object to allow setting fallbacks and
   600|         0|            0|            0|  0.00%|        # output charset. All other instance data is shared with the
   601|         0|            0|            0|  0.00%|        # cached object.
   602|         0|            0|            0|  0.00%|        # Delay copy import for speeding up gettext import when .mo files
   603|         0|            0|            0|  0.00%|        # are not used.
   604|         0|            0|            0|  0.00%|        import copy
   605|         0|            0|            0|  0.00%|        t = copy.copy(t)
   606|         0|            0|            0|  0.00%|        if codeset is not _unspecified:
   607|         0|            0|            0|  0.00%|            import warnings
   608|         0|            0|            0|  0.00%|            warnings.warn('parameter codeset is deprecated',
   609|         0|            0|            0|  0.00%|                          DeprecationWarning, 2)
   610|         0|            0|            0|  0.00%|            if codeset:
   611|         0|            0|            0|  0.00%|                with warnings.catch_warnings():
   612|         0|            0|            0|  0.00%|                    warnings.filterwarnings('ignore', r'.*\bset_output_charset\b.*',
   613|         0|            0|            0|  0.00%|                                            DeprecationWarning)
   614|         0|            0|            0|  0.00%|                    t.set_output_charset(codeset)
   615|         0|            0|            0|  0.00%|        if result is None:
   616|         0|            0|            0|  0.00%|            result = t
   617|         0|            0|            0|  0.00%|        else:
   618|         0|            0|            0|  0.00%|            result.add_fallback(t)
   619|         0|            0|            0|  0.00%|    return result
   620|         0|            0|            0|  0.00%|
   621|         0|            0|            0|  0.00%|
   622|         0|            0|            0|  0.00%|def install(domain, localedir=None, codeset=_unspecified, names=None):
   623|         0|            0|            0|  0.00%|    t = translation(domain, localedir, fallback=True, codeset=codeset)
   624|         0|            0|            0|  0.00%|    t.install(names)
   625|         0|            0|            0|  0.00%|
   626|         0|            0|            0|  0.00%|
   627|         0|            0|            0|  0.00%|
   628|         0|            0|            0|  0.00%|# a mapping b/w domains and locale directories
   629|         0|            0|            0|  0.00%|_localedirs = {}
   630|         0|            0|            0|  0.00%|# a mapping b/w domains and codesets
   631|         0|            0|            0|  0.00%|_localecodesets = {}
   632|         0|            0|            0|  0.00%|# current global domain, `messages' used for compatibility w/ GNU gettext
   633|         0|            0|            0|  0.00%|_current_domain = 'messages'
   634|         0|            0|            0|  0.00%|
   635|         0|            0|            0|  0.00%|
   636|         0|            0|            0|  0.00%|def textdomain(domain=None):
   637|         0|            0|            0|  0.00%|    global _current_domain
   638|         0|            0|            0|  0.00%|    if domain is not None:
   639|         0|            0|            0|  0.00%|        _current_domain = domain
   640|         0|            0|            0|  0.00%|    return _current_domain
   641|         0|            0|            0|  0.00%|
   642|         0|            0|            0|  0.00%|
   643|         0|            0|            0|  0.00%|def bindtextdomain(domain, localedir=None):
   644|         0|            0|            0|  0.00%|    global _localedirs
   645|         0|            0|            0|  0.00%|    if localedir is not None:
   646|         0|            0|            0|  0.00%|        _localedirs[domain] = localedir
   647|         0|            0|            0|  0.00%|    return _localedirs.get(domain, _default_localedir)
   648|         0|            0|            0|  0.00%|
   649|         0|            0|            0|  0.00%|
   650|         0|            0|            0|  0.00%|def bind_textdomain_codeset(domain, codeset=None):
   651|         0|            0|            0|  0.00%|    import warnings
   652|         0|            0|            0|  0.00%|    warnings.warn('bind_textdomain_codeset() is deprecated',
   653|         0|            0|            0|  0.00%|                  DeprecationWarning, 2)
   654|         0|            0|            0|  0.00%|    global _localecodesets
   655|         0|            0|            0|  0.00%|    if codeset is not None:
   656|         0|            0|            0|  0.00%|        _localecodesets[domain] = codeset
   657|         0|            0|            0|  0.00%|    return _localecodesets.get(domain)
   658|         0|            0|            0|  0.00%|
   659|         0|            0|            0|  0.00%|
   660|         0|            0|            0|  0.00%|def dgettext(domain, message):
   661|         0|            0|            0|  0.00%|    try:
   662|         0|            0|            0|  0.00%|        t = translation(domain, _localedirs.get(domain, None))
   663|         0|            0|            0|  0.00%|    except OSError:
   664|         0|            0|            0|  0.00%|        return message
   665|         0|            0|            0|  0.00%|    return t.gettext(message)
   666|         0|            0|            0|  0.00%|
   667|         0|            0|            0|  0.00%|def ldgettext(domain, message):
   668|         0|            0|            0|  0.00%|    import warnings
   669|         0|            0|            0|  0.00%|    warnings.warn('ldgettext() is deprecated, use dgettext() instead',
   670|         0|            0|            0|  0.00%|                  DeprecationWarning, 2)
   671|         0|            0|            0|  0.00%|    codeset = _localecodesets.get(domain)
   672|         0|            0|            0|  0.00%|    try:
   673|         0|            0|            0|  0.00%|        with warnings.catch_warnings():
   674|         0|            0|            0|  0.00%|            warnings.filterwarnings('ignore', r'.*\bparameter codeset\b.*',
   675|         0|            0|            0|  0.00%|                                    DeprecationWarning)
   676|         0|            0|            0|  0.00%|            t = translation(domain, _localedirs.get(domain, None), codeset=codeset)
   677|         0|            0|            0|  0.00%|    except OSError:
   678|         0|            0|            0|  0.00%|        return message.encode(codeset or locale.getpreferredencoding())
   679|         0|            0|            0|  0.00%|    with warnings.catch_warnings():
   680|         0|            0|            0|  0.00%|        warnings.filterwarnings('ignore', r'.*\blgettext\b.*',
   681|         0|            0|            0|  0.00%|                                DeprecationWarning)
   682|         0|            0|            0|  0.00%|        return t.lgettext(message)
   683|         0|            0|            0|  0.00%|
   684|         0|            0|            0|  0.00%|def dngettext(domain, msgid1, msgid2, n):
   685|         0|            0|            0|  0.00%|    try:
   686|         0|            0|            0|  0.00%|        t = translation(domain, _localedirs.get(domain, None))
   687|         0|            0|            0|  0.00%|    except OSError:
   688|         0|            0|            0|  0.00%|        if n == 1:
   689|         0|            0|            0|  0.00%|            return msgid1
   690|         0|            0|            0|  0.00%|        else:
   691|         0|            0|            0|  0.00%|            return msgid2
   692|         0|            0|            0|  0.00%|    return t.ngettext(msgid1, msgid2, n)
   693|         0|            0|            0|  0.00%|
   694|         0|            0|            0|  0.00%|def ldngettext(domain, msgid1, msgid2, n):
   695|         0|            0|            0|  0.00%|    import warnings
   696|         0|            0|            0|  0.00%|    warnings.warn('ldngettext() is deprecated, use dngettext() instead',
   697|         0|            0|            0|  0.00%|                  DeprecationWarning, 2)
   698|         0|            0|            0|  0.00%|    codeset = _localecodesets.get(domain)
   699|         0|            0|            0|  0.00%|    try:
   700|         0|            0|            0|  0.00%|        with warnings.catch_warnings():
   701|         0|            0|            0|  0.00%|            warnings.filterwarnings('ignore', r'.*\bparameter codeset\b.*',
   702|         0|            0|            0|  0.00%|                                    DeprecationWarning)
   703|         0|            0|            0|  0.00%|            t = translation(domain, _localedirs.get(domain, None), codeset=codeset)
   704|         0|            0|            0|  0.00%|    except OSError:
   705|         0|            0|            0|  0.00%|        if n == 1:
   706|         0|            0|            0|  0.00%|            tmsg = msgid1
   707|         0|            0|            0|  0.00%|        else:
   708|         0|            0|            0|  0.00%|            tmsg = msgid2
   709|         0|            0|            0|  0.00%|        return tmsg.encode(codeset or locale.getpreferredencoding())
   710|         0|            0|            0|  0.00%|    with warnings.catch_warnings():
   711|         0|            0|            0|  0.00%|        warnings.filterwarnings('ignore', r'.*\blngettext\b.*',
   712|         0|            0|            0|  0.00%|                                DeprecationWarning)
   713|         0|            0|            0|  0.00%|        return t.lngettext(msgid1, msgid2, n)
   714|         0|            0|            0|  0.00%|
   715|         0|            0|            0|  0.00%|
   716|         0|            0|            0|  0.00%|def dpgettext(domain, context, message):
   717|         0|            0|            0|  0.00%|    try:
   718|         0|            0|            0|  0.00%|        t = translation(domain, _localedirs.get(domain, None))
   719|         0|            0|            0|  0.00%|    except OSError:
   720|         0|            0|            0|  0.00%|        return message
   721|         0|            0|            0|  0.00%|    return t.pgettext(context, message)
   722|         0|            0|            0|  0.00%|
   723|         0|            0|            0|  0.00%|
   724|         0|            0|            0|  0.00%|def dnpgettext(domain, context, msgid1, msgid2, n):
   725|         0|            0|            0|  0.00%|    try:
   726|         0|            0|            0|  0.00%|        t = translation(domain, _localedirs.get(domain, None))
   727|         0|            0|            0|  0.00%|    except OSError:
   728|         0|            0|            0|  0.00%|        if n == 1:
   729|         0|            0|            0|  0.00%|            return msgid1
   730|         0|            0|            0|  0.00%|        else:
   731|         0|            0|            0|  0.00%|            return msgid2
   732|         0|            0|            0|  0.00%|    return t.npgettext(context, msgid1, msgid2, n)
   733|         0|            0|            0|  0.00%|
   734|         0|            0|            0|  0.00%|
   735|         0|            0|            0|  0.00%|def gettext(message):
   736|         0|            0|            0|  0.00%|    return dgettext(_current_domain, message)
   737|         0|            0|            0|  0.00%|
   738|         0|            0|            0|  0.00%|def lgettext(message):
   739|         0|            0|            0|  0.00%|    import warnings
   740|         0|            0|            0|  0.00%|    warnings.warn('lgettext() is deprecated, use gettext() instead',
   741|         0|            0|            0|  0.00%|                  DeprecationWarning, 2)
   742|         0|            0|            0|  0.00%|    with warnings.catch_warnings():
   743|         0|            0|            0|  0.00%|        warnings.filterwarnings('ignore', r'.*\bldgettext\b.*',
   744|         0|            0|            0|  0.00%|                                DeprecationWarning)
   745|         0|            0|            0|  0.00%|        return ldgettext(_current_domain, message)
   746|         0|            0|            0|  0.00%|
   747|         0|            0|            0|  0.00%|def ngettext(msgid1, msgid2, n):
   748|         0|            0|            0|  0.00%|    return dngettext(_current_domain, msgid1, msgid2, n)
   749|         0|            0|            0|  0.00%|
   750|         0|            0|            0|  0.00%|def lngettext(msgid1, msgid2, n):
   751|         0|            0|            0|  0.00%|    import warnings
   752|         0|            0|            0|  0.00%|    warnings.warn('lngettext() is deprecated, use ngettext() instead',
   753|         0|            0|            0|  0.00%|                  DeprecationWarning, 2)
   754|         0|            0|            0|  0.00%|    with warnings.catch_warnings():
   755|         0|            0|            0|  0.00%|        warnings.filterwarnings('ignore', r'.*\bldngettext\b.*',
   756|         0|            0|            0|  0.00%|                                DeprecationWarning)
   757|         0|            0|            0|  0.00%|        return ldngettext(_current_domain, msgid1, msgid2, n)
   758|         0|            0|            0|  0.00%|
   759|         0|            0|            0|  0.00%|
   760|         0|            0|            0|  0.00%|def pgettext(context, message):
   761|         0|            0|            0|  0.00%|    return dpgettext(_current_domain, context, message)
   762|         0|            0|            0|  0.00%|
   763|         0|            0|            0|  0.00%|
   764|         0|            0|            0|  0.00%|def npgettext(context, msgid1, msgid2, n):
   765|         0|            0|            0|  0.00%|    return dnpgettext(_current_domain, context, msgid1, msgid2, n)
   766|         0|            0|            0|  0.00%|
   767|         0|            0|            0|  0.00%|
   768|         0|            0|            0|  0.00%|# dcgettext() has been deemed unnecessary and is not implemented.
   769|         0|            0|            0|  0.00%|
   770|         0|            0|            0|  0.00%|# James Henstridge's Catalog constructor from GNOME gettext.  Documented usage
   771|         0|            0|            0|  0.00%|# was:
   772|         0|            0|            0|  0.00%|#
   773|         0|            0|            0|  0.00%|#    import gettext
   774|         0|            0|            0|  0.00%|#    cat = gettext.Catalog(PACKAGE, localedir=LOCALEDIR)
   775|         0|            0|            0|  0.00%|#    _ = cat.gettext
   776|         0|            0|            0|  0.00%|#    print _('Hello World')
   777|         0|            0|            0|  0.00%|
   778|         0|            0|            0|  0.00%|# The resulting catalog object currently don't support access through a
   779|         0|            0|            0|  0.00%|# dictionary API, which was supported (but apparently unused) in GNOME
   780|         0|            0|            0|  0.00%|# gettext.
   781|         0|            0|            0|  0.00%|
   782|         0|            0|            0|  0.00%|Catalog = translation
File: /home/ubuntu/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/absl/logging/converter.py
File duration: 2.3365e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|# Copyright 2017 The Abseil Authors.
     2|         0|            0|            0|  0.00%|#
     3|         0|            0|            0|  0.00%|# Licensed under the Apache License, Version 2.0 (the "License");
     4|         0|            0|            0|  0.00%|# you may not use this file except in compliance with the License.
     5|         0|            0|            0|  0.00%|# You may obtain a copy of the License at
     6|         0|            0|            0|  0.00%|#
     7|         0|            0|            0|  0.00%|#      http://www.apache.org/licenses/LICENSE-2.0
     8|         0|            0|            0|  0.00%|#
     9|         0|            0|            0|  0.00%|# Unless required by applicable law or agreed to in writing, software
    10|         0|            0|            0|  0.00%|# distributed under the License is distributed on an "AS IS" BASIS,
    11|         0|            0|            0|  0.00%|# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    12|         0|            0|            0|  0.00%|# See the License for the specific language governing permissions and
    13|         0|            0|            0|  0.00%|# limitations under the License.
    14|         0|            0|            0|  0.00%|
    15|         0|            0|            0|  0.00%|"""Module to convert log levels between Abseil Python, C++, and Python standard.
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|This converter has to convert (best effort) between three different
    18|         0|            0|            0|  0.00%|logging level schemes:
    19|         0|            0|            0|  0.00%|  cpp      = The C++ logging level scheme used in Abseil C++.
    20|         0|            0|            0|  0.00%|  absl     = The absl.logging level scheme used in Abseil Python.
    21|         0|            0|            0|  0.00%|  standard = The python standard library logging level scheme.
    22|         0|            0|            0|  0.00%|
    23|         0|            0|            0|  0.00%|Here is a handy ascii chart for easy mental mapping.
    24|         0|            0|            0|  0.00%|
    25|         0|            0|            0|  0.00%|  LEVEL    | cpp |  absl  | standard |
    26|         0|            0|            0|  0.00%|  ---------+-----+--------+----------+
    27|         0|            0|            0|  0.00%|  DEBUG    |  0  |    1   |    10    |
    28|         0|            0|            0|  0.00%|  INFO     |  0  |    0   |    20    |
    29|         0|            0|            0|  0.00%|  WARNING  |  1  |   -1   |    30    |
    30|         0|            0|            0|  0.00%|  ERROR    |  2  |   -2   |    40    |
    31|         0|            0|            0|  0.00%|  CRITICAL |  3  |   -3   |    50    |
    32|         0|            0|            0|  0.00%|  FATAL    |  3  |   -3   |    50    |
    33|         0|            0|            0|  0.00%|
    34|         0|            0|            0|  0.00%|Note: standard logging CRITICAL is mapped to absl/cpp FATAL.
    35|         0|            0|            0|  0.00%|However, only CRITICAL logs from the absl logger (or absl.logging.fatal) will
    36|         0|            0|            0|  0.00%|terminate the program. CRITICAL logs from non-absl loggers are treated as
    37|         0|            0|            0|  0.00%|error logs with a message prefix "CRITICAL - ".
    38|         0|            0|            0|  0.00%|
    39|         0|            0|            0|  0.00%|Converting from standard to absl or cpp is a lossy conversion.
    40|         0|            0|            0|  0.00%|Converting back to standard will lose granularity.  For this reason,
    41|         0|            0|            0|  0.00%|users should always try to convert to standard, the richest
    42|         0|            0|            0|  0.00%|representation, before manipulating the levels, and then only to cpp
    43|         0|            0|            0|  0.00%|or absl if those level schemes are absolutely necessary.
    44|         0|            0|            0|  0.00%|"""
    45|         0|            0|            0|  0.00%|
    46|         0|            0|            0|  0.00%|from __future__ import absolute_import
    47|         0|            0|            0|  0.00%|from __future__ import division
    48|         0|            0|            0|  0.00%|from __future__ import print_function
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|import logging
    51|         0|            0|            0|  0.00%|
    52|         0|            0|            0|  0.00%|STANDARD_CRITICAL = logging.CRITICAL
    53|         0|            0|            0|  0.00%|STANDARD_ERROR = logging.ERROR
    54|         0|            0|            0|  0.00%|STANDARD_WARNING = logging.WARNING
    55|         0|            0|            0|  0.00%|STANDARD_INFO = logging.INFO
    56|         0|            0|            0|  0.00%|STANDARD_DEBUG = logging.DEBUG
    57|         0|            0|            0|  0.00%|
    58|         0|            0|            0|  0.00%|# These levels are also used to define the constants
    59|         0|            0|            0|  0.00%|# FATAL, ERROR, WARNING, INFO, and DEBUG in the
    60|         0|            0|            0|  0.00%|# absl.logging module.
    61|         0|            0|            0|  0.00%|ABSL_FATAL = -3
    62|         0|            0|            0|  0.00%|ABSL_ERROR = -2
    63|         0|            0|            0|  0.00%|ABSL_WARNING = -1
    64|         0|            0|            0|  0.00%|ABSL_WARN = -1  # Deprecated name.
    65|         0|            0|            0|  0.00%|ABSL_INFO = 0
    66|         0|            0|            0|  0.00%|ABSL_DEBUG = 1
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|ABSL_LEVELS = {ABSL_FATAL: 'FATAL',
    69|         0|            0|            0|  0.00%|               ABSL_ERROR: 'ERROR',
    70|         0|            0|            0|  0.00%|               ABSL_WARNING: 'WARNING',
    71|         0|            0|            0|  0.00%|               ABSL_INFO: 'INFO',
    72|         0|            0|            0|  0.00%|               ABSL_DEBUG: 'DEBUG'}
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|# Inverts the ABSL_LEVELS dictionary
    75|         0|            0|            0|  0.00%|ABSL_NAMES = {'FATAL': ABSL_FATAL,
    76|         0|            0|            0|  0.00%|              'ERROR': ABSL_ERROR,
    77|         0|            0|            0|  0.00%|              'WARNING': ABSL_WARNING,
    78|         0|            0|            0|  0.00%|              'WARN': ABSL_WARNING,  # Deprecated name.
    79|         0|            0|            0|  0.00%|              'INFO': ABSL_INFO,
    80|         0|            0|            0|  0.00%|              'DEBUG': ABSL_DEBUG}
    81|         0|            0|            0|  0.00%|
    82|         0|            0|            0|  0.00%|ABSL_TO_STANDARD = {ABSL_FATAL: STANDARD_CRITICAL,
    83|         0|            0|            0|  0.00%|                    ABSL_ERROR: STANDARD_ERROR,
    84|         0|            0|            0|  0.00%|                    ABSL_WARNING: STANDARD_WARNING,
    85|         0|            0|            0|  0.00%|                    ABSL_INFO: STANDARD_INFO,
    86|         0|            0|            0|  0.00%|                    ABSL_DEBUG: STANDARD_DEBUG}
    87|         0|            0|            0|  0.00%|
    88|         0|            0|            0|  0.00%|# Inverts the ABSL_TO_STANDARD
    89|         0|            0|            0|  0.00%|STANDARD_TO_ABSL = dict((v, k) for (k, v) in ABSL_TO_STANDARD.items())
    90|         0|            0|            0|  0.00%|
    91|         0|            0|            0|  0.00%|
    92|         0|            0|            0|  0.00%|def get_initial_for_level(level):
    93|         0|            0|            0|  0.00%|  """Gets the initial that should start the log line for the given level.
    94|         0|            0|            0|  0.00%|
    95|         0|            0|            0|  0.00%|  It returns:
    96|         0|            0|            0|  0.00%|  - 'I' when: level < STANDARD_WARNING.
    97|         0|            0|            0|  0.00%|  - 'W' when: STANDARD_WARNING <= level < STANDARD_ERROR.
    98|         0|            0|            0|  0.00%|  - 'E' when: STANDARD_ERROR <= level < STANDARD_CRITICAL.
    99|         0|            0|            0|  0.00%|  - 'F' when: level >= STANDARD_CRITICAL.
   100|         0|            0|            0|  0.00%|
   101|         0|            0|            0|  0.00%|  Args:
   102|         0|            0|            0|  0.00%|    level: int, a Python standard logging level.
   103|         0|            0|            0|  0.00%|
   104|         0|            0|            0|  0.00%|  Returns:
   105|         0|            0|            0|  0.00%|    The first initial as it would be logged by the C++ logging module.
   106|         0|            0|            0|  0.00%|  """
   107|         0|            0|            0|  0.00%|  if level < STANDARD_WARNING:
   108|         0|            0|            0|  0.00%|    return 'I'
   109|         0|            0|            0|  0.00%|  elif level < STANDARD_ERROR:
   110|         0|            0|            0|  0.00%|    return 'W'
   111|         0|            0|            0|  0.00%|  elif level < STANDARD_CRITICAL:
   112|         0|            0|            0|  0.00%|    return 'E'
   113|         0|            0|            0|  0.00%|  else:
   114|         0|            0|            0|  0.00%|    return 'F'
   115|         0|            0|            0|  0.00%|
   116|         0|            0|            0|  0.00%|
   117|         0|            0|            0|  0.00%|def absl_to_cpp(level):
   118|         0|            0|            0|  0.00%|  """Converts an absl log level to a cpp log level.
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|  Args:
   121|         0|            0|            0|  0.00%|    level: int, an absl.logging level.
   122|         0|            0|            0|  0.00%|
   123|         0|            0|            0|  0.00%|  Raises:
   124|         0|            0|            0|  0.00%|    TypeError: Raised when level is not an integer.
   125|         0|            0|            0|  0.00%|
   126|         0|            0|            0|  0.00%|  Returns:
   127|         0|            0|            0|  0.00%|    The corresponding integer level for use in Abseil C++.
   128|         0|            0|            0|  0.00%|  """
   129|         0|            0|            0|  0.00%|  if not isinstance(level, int):
   130|         0|            0|            0|  0.00%|    raise TypeError('Expect an int level, found {}'.format(type(level)))
   131|         0|            0|            0|  0.00%|  if level >= 0:
   132|         0|            0|            0|  0.00%|    # C++ log levels must be >= 0
   133|         0|            0|            0|  0.00%|    return 0
   134|         0|            0|            0|  0.00%|  else:
   135|         0|            0|            0|  0.00%|    return -level
   136|         0|            0|            0|  0.00%|
   137|         0|            0|            0|  0.00%|
   138|         1|  6.91414e-06|  6.91414e-06|  0.00%|def absl_to_standard(level):
   139|         0|            0|            0|  0.00%|  """Converts an integer level from the absl value to the standard value.
   140|         0|            0|            0|  0.00%|
   141|         0|            0|            0|  0.00%|  Args:
   142|         0|            0|            0|  0.00%|    level: int, an absl.logging level.
   143|         0|            0|            0|  0.00%|
   144|         0|            0|            0|  0.00%|  Raises:
   145|         0|            0|            0|  0.00%|    TypeError: Raised when level is not an integer.
   146|         0|            0|            0|  0.00%|
   147|         0|            0|            0|  0.00%|  Returns:
   148|         0|            0|            0|  0.00%|    The corresponding integer level for use in standard logging.
   149|         0|            0|            0|  0.00%|  """
   150|         1|  6.91414e-06|  6.91414e-06|  0.00%|  if not isinstance(level, int):
   151|         0|            0|            0|  0.00%|    raise TypeError('Expect an int level, found {}'.format(type(level)))
   152|         1|  3.33786e-06|  3.33786e-06|  0.00%|  if level < ABSL_FATAL:
   153|         0|            0|            0|  0.00%|    level = ABSL_FATAL
   154|         1|  2.86102e-06|  2.86102e-06|  0.00%|  if level <= ABSL_DEBUG:
   155|         1|  3.33786e-06|  3.33786e-06|  0.00%|    return ABSL_TO_STANDARD[level]
   156|         0|            0|            0|  0.00%|  # Maps to vlog levels.
   157|         0|            0|            0|  0.00%|  return STANDARD_DEBUG - level + 1
   158|         0|            0|            0|  0.00%|
   159|         0|            0|            0|  0.00%|
   160|         0|            0|            0|  0.00%|def string_to_standard(level):
   161|         0|            0|            0|  0.00%|  """Converts a string level to standard logging level value.
   162|         0|            0|            0|  0.00%|
   163|         0|            0|            0|  0.00%|  Args:
   164|         0|            0|            0|  0.00%|    level: str, case-insensitive 'debug', 'info', 'warning', 'error', 'fatal'.
   165|         0|            0|            0|  0.00%|
   166|         0|            0|            0|  0.00%|  Returns:
   167|         0|            0|            0|  0.00%|    The corresponding integer level for use in standard logging.
   168|         0|            0|            0|  0.00%|  """
   169|         0|            0|            0|  0.00%|  return absl_to_standard(ABSL_NAMES.get(level.upper()))
   170|         0|            0|            0|  0.00%|
   171|         0|            0|            0|  0.00%|
   172|         0|            0|            0|  0.00%|def standard_to_absl(level):
   173|         0|            0|            0|  0.00%|  """Converts an integer level from the standard value to the absl value.
   174|         0|            0|            0|  0.00%|
   175|         0|            0|            0|  0.00%|  Args:
   176|         0|            0|            0|  0.00%|    level: int, a Python standard logging level.
   177|         0|            0|            0|  0.00%|
   178|         0|            0|            0|  0.00%|  Raises:
   179|         0|            0|            0|  0.00%|    TypeError: Raised when level is not an integer.
   180|         0|            0|            0|  0.00%|
   181|         0|            0|            0|  0.00%|  Returns:
   182|         0|            0|            0|  0.00%|    The corresponding integer level for use in absl logging.
   183|         0|            0|            0|  0.00%|  """
   184|         0|            0|            0|  0.00%|  if not isinstance(level, int):
   185|         0|            0|            0|  0.00%|    raise TypeError('Expect an int level, found {}'.format(type(level)))
   186|         0|            0|            0|  0.00%|  if level < 0:
   187|         0|            0|            0|  0.00%|    level = 0
   188|         0|            0|            0|  0.00%|  if level < STANDARD_DEBUG:
   189|         0|            0|            0|  0.00%|    # Maps to vlog levels.
   190|         0|            0|            0|  0.00%|    return STANDARD_DEBUG - level + 1
   191|         0|            0|            0|  0.00%|  elif level < STANDARD_INFO:
   192|         0|            0|            0|  0.00%|    return ABSL_DEBUG
   193|         0|            0|            0|  0.00%|  elif level < STANDARD_WARNING:
   194|         0|            0|            0|  0.00%|    return ABSL_INFO
   195|         0|            0|            0|  0.00%|  elif level < STANDARD_ERROR:
   196|         0|            0|            0|  0.00%|    return ABSL_WARNING
   197|         0|            0|            0|  0.00%|  elif level < STANDARD_CRITICAL:
   198|         0|            0|            0|  0.00%|    return ABSL_ERROR
   199|         0|            0|            0|  0.00%|  else:
   200|         0|            0|            0|  0.00%|    return ABSL_FATAL
   201|         0|            0|            0|  0.00%|
   202|         0|            0|            0|  0.00%|
   203|         0|            0|            0|  0.00%|def standard_to_cpp(level):
   204|         0|            0|            0|  0.00%|  """Converts an integer level from the standard value to the cpp value.
   205|         0|            0|            0|  0.00%|
   206|         0|            0|            0|  0.00%|  Args:
   207|         0|            0|            0|  0.00%|    level: int, a Python standard logging level.
   208|         0|            0|            0|  0.00%|
   209|         0|            0|            0|  0.00%|  Raises:
   210|         0|            0|            0|  0.00%|    TypeError: Raised when level is not an integer.
   211|         0|            0|            0|  0.00%|
   212|         0|            0|            0|  0.00%|  Returns:
   213|         0|            0|            0|  0.00%|    The corresponding integer level for use in cpp logging.
   214|         0|            0|            0|  0.00%|  """
   215|         0|            0|            0|  0.00%|  return absl_to_cpp(standard_to_absl(level))
File: /apps/open_spiel/open_spiel/python/policy.py
File duration: 1.83582e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|# Copyright 2019 DeepMind Technologies Limited
     2|         0|            0|            0|  0.00%|#
     3|         0|            0|            0|  0.00%|# Licensed under the Apache License, Version 2.0 (the "License");
     4|         0|            0|            0|  0.00%|# you may not use this file except in compliance with the License.
     5|         0|            0|            0|  0.00%|# You may obtain a copy of the License at
     6|         0|            0|            0|  0.00%|#
     7|         0|            0|            0|  0.00%|#      http://www.apache.org/licenses/LICENSE-2.0
     8|         0|            0|            0|  0.00%|#
     9|         0|            0|            0|  0.00%|# Unless required by applicable law or agreed to in writing, software
    10|         0|            0|            0|  0.00%|# distributed under the License is distributed on an "AS IS" BASIS,
    11|         0|            0|            0|  0.00%|# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    12|         0|            0|            0|  0.00%|# See the License for the specific language governing permissions and
    13|         0|            0|            0|  0.00%|# limitations under the License.
    14|         0|            0|            0|  0.00%|
    15|         0|            0|            0|  0.00%|# Lint as python3
    16|         0|            0|            0|  0.00%|"""Representation of a policy for a game.
    17|         0|            0|            0|  0.00%|
    18|         0|            0|            0|  0.00%|This is a standard representation for passing policies into algorithms,
    19|         0|            0|            0|  0.00%|with currently the following implementations:
    20|         0|            0|            0|  0.00%|
    21|         0|            0|            0|  0.00%|  TabularPolicy - an explicit policy per state, stored in an array
    22|         0|            0|            0|  0.00%|    of shape `(num_states, num_actions)`, convenient for tabular policy
    23|         0|            0|            0|  0.00%|    solution methods.
    24|         0|            0|            0|  0.00%|  UniformRandomPolicy - a uniform distribution over all legal actions for
    25|         0|            0|            0|  0.00%|    the specified player. This is computed as needed, so can be used for
    26|         0|            0|            0|  0.00%|    games where a tabular policy would be unfeasibly large.
    27|         0|            0|            0|  0.00%|
    28|         0|            0|            0|  0.00%|The main way of using a policy is to call `action_probabilities(state,
    29|         0|            0|            0|  0.00%|player_id`), to obtain a dict of {action: probability}. `TabularPolicy`
    30|         0|            0|            0|  0.00%|objects expose a lower-level interface, which may be more efficient for
    31|         0|            0|            0|  0.00%|some use cases.
    32|         0|            0|            0|  0.00%|"""
    33|         0|            0|            0|  0.00%|
    34|         0|            0|            0|  0.00%|import itertools
    35|         0|            0|            0|  0.00%|from typing import Iterable
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|import numpy as np
    38|         0|            0|            0|  0.00%|
    39|         0|            0|            0|  0.00%|from open_spiel.python.algorithms import get_all_states
    40|         0|            0|            0|  0.00%|import pyspiel
    41|         0|            0|            0|  0.00%|
    42|         0|            0|            0|  0.00%|
    43|         0|            0|            0|  0.00%|def child(state, action):
    44|         0|            0|            0|  0.00%|  """Returns a child state, handling the simultaneous node case."""
    45|         0|            0|            0|  0.00%|  if isinstance(action, Iterable):
    46|         0|            0|            0|  0.00%|    child_state = state.clone()
    47|         0|            0|            0|  0.00%|    child_state.apply_actions(action)
    48|         0|            0|            0|  0.00%|    return child_state
    49|         0|            0|            0|  0.00%|  else:
    50|         0|            0|            0|  0.00%|    return state.child(action)
    51|         0|            0|            0|  0.00%|
    52|         0|            0|            0|  0.00%|
    53|         0|            0|            0|  0.00%|def joint_action_probabilities_aux(state, policy):
    54|         0|            0|            0|  0.00%|  """Auxiliary function for joint_action_probabilities.
    55|         0|            0|            0|  0.00%|
    56|         0|            0|            0|  0.00%|  Args:
    57|         0|            0|            0|  0.00%|    state: a game state at a simultaneous decision node.
    58|         0|            0|            0|  0.00%|    policy: policy that gives the probability distribution over the legal
    59|         0|            0|            0|  0.00%|      actions for each players.
    60|         0|            0|            0|  0.00%|
    61|         0|            0|            0|  0.00%|  Returns:
    62|         0|            0|            0|  0.00%|    actions_per_player: list of list of actions for each player
    63|         0|            0|            0|  0.00%|    probs_per_player: list of list of probabilities do the corresponding action
    64|         0|            0|            0|  0.00%|     in actions_per_player for each player.
    65|         0|            0|            0|  0.00%|  """
    66|         0|            0|            0|  0.00%|  assert state.is_simultaneous_node()
    67|         0|            0|            0|  0.00%|  action_probs_per_player = [
    68|         0|            0|            0|  0.00%|      policy.action_probabilities(state, player)
    69|         0|            0|            0|  0.00%|      for player in range(state.get_game().num_players())
    70|         0|            0|            0|  0.00%|  ]
    71|         0|            0|            0|  0.00%|  actions_per_player = [pi.keys() for pi in action_probs_per_player]
    72|         0|            0|            0|  0.00%|  probs_per_player = [pi.values() for pi in action_probs_per_player]
    73|         0|            0|            0|  0.00%|  return actions_per_player, probs_per_player
    74|         0|            0|            0|  0.00%|
    75|         0|            0|            0|  0.00%|
    76|         0|            0|            0|  0.00%|def joint_action_probabilities(state, policy):
    77|         0|            0|            0|  0.00%|  """Yields action, probability pairs for a joint policy in simultaneous state.
    78|         0|            0|            0|  0.00%|
    79|         0|            0|            0|  0.00%|  Args:
    80|         0|            0|            0|  0.00%|    state: a game state at a simultaneous decision node.
    81|         0|            0|            0|  0.00%|    policy: policy that gives the probability distribution over the legal
    82|         0|            0|            0|  0.00%|      actions for each players.
    83|         0|            0|            0|  0.00%|
    84|         0|            0|            0|  0.00%|  Yields:
    85|         0|            0|            0|  0.00%|    (action, probability) pairs. An action is a tuple of individual
    86|         0|            0|            0|  0.00%|      actions for each player of the game. The probability is a single joint
    87|         0|            0|            0|  0.00%|      probability (product of all the individual probabilities).
    88|         0|            0|            0|  0.00%|  """
    89|         0|            0|            0|  0.00%|  actions_per_player, probs_per_player = joint_action_probabilities_aux(
    90|         0|            0|            0|  0.00%|      state, policy)
    91|         0|            0|            0|  0.00%|  for actions, probs in zip(
    92|         0|            0|            0|  0.00%|      itertools.product(*actions_per_player),
    93|         0|            0|            0|  0.00%|      itertools.product(*probs_per_player)):
    94|         0|            0|            0|  0.00%|    yield actions, np.prod(probs)
    95|         0|            0|            0|  0.00%|
    96|         0|            0|            0|  0.00%|
    97|         0|            0|            0|  0.00%|class Policy:
    98|         0|            0|            0|  0.00%|  """Base class for policies.
    99|         0|            0|            0|  0.00%|
   100|         0|            0|            0|  0.00%|  A policy is something that returns a distribution over possible actions
   101|         0|            0|            0|  0.00%|  given a state of the world.
   102|         0|            0|            0|  0.00%|
   103|         0|            0|            0|  0.00%|  Attributes:
   104|         0|            0|            0|  0.00%|    game: the game for which this policy applies
   105|         0|            0|            0|  0.00%|    player_ids: list of player ids for which this policy applies; each in the
   106|         0|            0|            0|  0.00%|      interval [0..game.num_players()-1].
   107|         0|            0|            0|  0.00%|  """
   108|         0|            0|            0|  0.00%|
   109|         1|  9.05991e-06|  9.05991e-06|  0.00%|  def __init__(self, game, player_ids):
   110|         0|            0|            0|  0.00%|    """Initializes a policy.
   111|         0|            0|            0|  0.00%|
   112|         0|            0|            0|  0.00%|    Args:
   113|         0|            0|            0|  0.00%|      game: the game for which this policy applies
   114|         0|            0|            0|  0.00%|      player_ids: list of player ids for which this policy applies; each should
   115|         0|            0|            0|  0.00%|        be in the range 0..game.num_players()-1.
   116|         0|            0|            0|  0.00%|    """
   117|         1|   6.4373e-06|   6.4373e-06|  0.00%|    self.game = game
   118|         1|  2.86102e-06|  2.86102e-06|  0.00%|    self.player_ids = player_ids
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|  def action_probabilities(self, state, player_id=None):
   121|         0|            0|            0|  0.00%|    """Returns a dictionary {action: prob} for all legal actions.
   122|         0|            0|            0|  0.00%|
   123|         0|            0|            0|  0.00%|    IMPORTANT: We assume the following properties hold:
   124|         0|            0|            0|  0.00%|    - All probabilities are >=0 and sum to 1
   125|         0|            0|            0|  0.00%|    - TLDR: Policy implementations should list the (action, prob) for all legal
   126|         0|            0|            0|  0.00%|      actions, but algorithms should not rely on this (yet).
   127|         0|            0|            0|  0.00%|      Details: Before May 2020, only legal actions were present in the mapping,
   128|         0|            0|            0|  0.00%|      but it did not have to be exhaustive: missing actions were considered to
   129|         0|            0|            0|  0.00%|      be associated to a zero probability.
   130|         0|            0|            0|  0.00%|      For example, a deterministic state-poliy was previously {action: 1.0}.
   131|         0|            0|            0|  0.00%|      Given this change of convention is new and hard to enforce, algorithms
   132|         0|            0|            0|  0.00%|      should not rely on the fact that all legal actions should be present.
   133|         0|            0|            0|  0.00%|
   134|         0|            0|            0|  0.00%|    Args:
   135|         0|            0|            0|  0.00%|      state: A `pyspiel.State` object.
   136|         0|            0|            0|  0.00%|      player_id: Optional, the player id for whom we want an action. Optional
   137|         0|            0|            0|  0.00%|        unless this is a simultaneous state at which multiple players can act.
   138|         0|            0|            0|  0.00%|
   139|         0|            0|            0|  0.00%|    Returns:
   140|         0|            0|            0|  0.00%|      A `dict` of `{action: probability}` for the specified player in the
   141|         0|            0|            0|  0.00%|      supplied state.
   142|         0|            0|            0|  0.00%|    """
   143|         0|            0|            0|  0.00%|    raise NotImplementedError()
   144|         0|            0|            0|  0.00%|
   145|         0|            0|            0|  0.00%|  def __call__(self, state, player_id=None):
   146|         0|            0|            0|  0.00%|    """Turns the policy into a callable.
   147|         0|            0|            0|  0.00%|
   148|         0|            0|            0|  0.00%|    Args:
   149|         0|            0|            0|  0.00%|      state: The current state of the game.
   150|         0|            0|            0|  0.00%|      player_id: Optional, the player id for whom we want an action. Optional
   151|         0|            0|            0|  0.00%|        unless this is a simultaneous state at which multiple players can act.
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|    Returns:
   154|         0|            0|            0|  0.00%|      Dictionary of action: probability.
   155|         0|            0|            0|  0.00%|    """
   156|         0|            0|            0|  0.00%|    return self.action_probabilities(state, player_id)
   157|         0|            0|            0|  0.00%|
   158|         0|            0|            0|  0.00%|  def to_tabular(self, states=None):
   159|         0|            0|            0|  0.00%|    """Returns a new `TabularPolicy` equivalent to this policy.
   160|         0|            0|            0|  0.00%|
   161|         0|            0|            0|  0.00%|    Args:
   162|         0|            0|            0|  0.00%|      states: States of the game that will be used for the tabular policy. If
   163|         0|            0|            0|  0.00%|        None, then get_tabular_policy_states() method will be used to generate
   164|         0|            0|            0|  0.00%|        them.
   165|         0|            0|            0|  0.00%|
   166|         0|            0|            0|  0.00%|    Returns:
   167|         0|            0|            0|  0.00%|      a TabularPolicy.
   168|         0|            0|            0|  0.00%|    """
   169|         0|            0|            0|  0.00%|    states = states or get_tabular_policy_states(self.game)
   170|         0|            0|            0|  0.00%|    tabular_policy = TabularPolicy(self.game, self.player_ids, states=states)
   171|         0|            0|            0|  0.00%|    for index, state in enumerate(tabular_policy.states):
   172|         0|            0|            0|  0.00%|      tabular_policy.action_probability_array[index, :] = 0
   173|         0|            0|            0|  0.00%|      for action, probability in self.action_probabilities(state).items():
   174|         0|            0|            0|  0.00%|        tabular_policy.action_probability_array[index, action] = probability
   175|         0|            0|            0|  0.00%|    return tabular_policy
   176|         0|            0|            0|  0.00%|
   177|         0|            0|            0|  0.00%|
   178|         0|            0|            0|  0.00%|class TabularPolicy(Policy):
   179|         0|            0|            0|  0.00%|  """Policy implementation where the policy is in explicit tabular form.
   180|         0|            0|            0|  0.00%|
   181|         0|            0|            0|  0.00%|  In addition to implementing the `Policy` interface, this class exposes
   182|         0|            0|            0|  0.00%|  details of the policy representation for easy manipulation.
   183|         0|            0|            0|  0.00%|
   184|         0|            0|            0|  0.00%|  The states are guaranteed to be grouped by player, which can simplify
   185|         0|            0|            0|  0.00%|  code for users of this class, i.e. `action_probability_array` contains
   186|         0|            0|            0|  0.00%|  states for player 0 first, followed by states for player 1, etc.
   187|         0|            0|            0|  0.00%|
   188|         0|            0|            0|  0.00%|  The policy uses `state.information_state_string` as the keys if available,
   189|         0|            0|            0|  0.00%|  otherwise `state.observation_string`.
   190|         0|            0|            0|  0.00%|
   191|         0|            0|            0|  0.00%|  Usages:
   192|         0|            0|            0|  0.00%|
   193|         0|            0|            0|  0.00%|  - Set `policy(info_state, action)`:
   194|         0|            0|            0|  0.00%|  ```
   195|         0|            0|            0|  0.00%|  tabular_policy = TabularPolicy(game)
   196|         0|            0|            0|  0.00%|  info_state_str = state.information_state_string(<optional player>)
   197|         0|            0|            0|  0.00%|  state_policy = tabular_policy.policy_for_key(info_state_str)
   198|         0|            0|            0|  0.00%|  state_policy[action] = <value>
   199|         0|            0|            0|  0.00%|  ```
   200|         0|            0|            0|  0.00%|  - Set `policy(info_state)`:
   201|         0|            0|            0|  0.00%|  ```
   202|         0|            0|            0|  0.00%|  tabular_policy = TabularPolicy(game)
   203|         0|            0|            0|  0.00%|  info_state_str = state.information_state_string(<optional player>)
   204|         0|            0|            0|  0.00%|  state_policy = tabular_policy.policy_for_key(info_state_str)
   205|         0|            0|            0|  0.00%|  state_policy[:] = <list or numpy.array>
   206|         0|            0|            0|  0.00%|  ```
   207|         0|            0|            0|  0.00%|
   208|         0|            0|            0|  0.00%|  Attributes:
   209|         0|            0|            0|  0.00%|    action_probability_array: array of shape `(num_states, num_actions)`, where
   210|         0|            0|            0|  0.00%|      `action_probability_array[s, a]` is the probability of choosing action `a`
   211|         0|            0|            0|  0.00%|      when at state `s`.
   212|         0|            0|            0|  0.00%|    state_lookup: `dict` mapping state key string to index into the
   213|         0|            0|            0|  0.00%|      `tabular_policy` array. If information state strings overlap, e.g. for
   214|         0|            0|            0|  0.00%|      different players or if the information state string has imperfect recall,
   215|         0|            0|            0|  0.00%|      then those states will be mapped to the same policy.
   216|         0|            0|            0|  0.00%|    legal_actions_mask: array of shape `(num_states, num_actions)`, each row
   217|         0|            0|            0|  0.00%|      representing which of the possible actions in the game are valid in this
   218|         0|            0|            0|  0.00%|      particular state, containing 1 for valid actions, 0 for invalid actions.
   219|         0|            0|            0|  0.00%|    states_per_player: A `list` per player of the state key strings at which
   220|         0|            0|            0|  0.00%|      they have a decision to make.
   221|         0|            0|            0|  0.00%|    states: A `list` of the states as ordered in the `action_probability_array`.
   222|         0|            0|            0|  0.00%|    state_in: array of shape `(num_states, state_vector_size)` containing the
   223|         0|            0|            0|  0.00%|      normalised vector representation of each information state. Populated only
   224|         0|            0|            0|  0.00%|      for games which support information_state_tensor(), and is None otherwise.
   225|         0|            0|            0|  0.00%|    game_type: The game attributes as returned by `Game::GetType`; used to
   226|         0|            0|            0|  0.00%|      determine whether to use information state or observation as the key in
   227|         0|            0|            0|  0.00%|      the tabular policy.
   228|         0|            0|            0|  0.00%|  """
   229|         0|            0|            0|  0.00%|
   230|         0|            0|            0|  0.00%|  def __init__(self,
   231|         0|            0|            0|  0.00%|               game,
   232|         0|            0|            0|  0.00%|               players=None,
   233|         0|            0|            0|  0.00%|               to_string=lambda s: s.history_str(),
   234|         0|            0|            0|  0.00%|               states=None):
   235|         0|            0|            0|  0.00%|    """Initializes a uniform random policy for all players in the game."""
   236|         0|            0|            0|  0.00%|    players = sorted(players or range(game.num_players()))
   237|         0|            0|            0|  0.00%|    super().__init__(game, players)
   238|         0|            0|            0|  0.00%|    self.game_type = game.get_type()
   239|         0|            0|            0|  0.00%|
   240|         0|            0|            0|  0.00%|    # Get all states in the game at which players have to make decisions unless
   241|         0|            0|            0|  0.00%|    # they are explicitly specified.
   242|         0|            0|            0|  0.00%|    states = states or get_all_states.get_all_states(
   243|         0|            0|            0|  0.00%|        game,
   244|         0|            0|            0|  0.00%|        depth_limit=-1,
   245|         0|            0|            0|  0.00%|        include_terminals=False,
   246|         0|            0|            0|  0.00%|        include_chance_states=False,
   247|         0|            0|            0|  0.00%|        include_mean_field_states=False,
   248|         0|            0|            0|  0.00%|        to_string=to_string)
   249|         0|            0|            0|  0.00%|
   250|         0|            0|            0|  0.00%|    # Assemble legal actions for every valid (state, player) pair, keyed by
   251|         0|            0|            0|  0.00%|    # information state string.
   252|         0|            0|            0|  0.00%|    self.state_lookup = {}
   253|         0|            0|            0|  0.00%|    self.states_per_player = [[] for _ in range(game.num_players())]
   254|         0|            0|            0|  0.00%|    self.states = []
   255|         0|            0|            0|  0.00%|    legal_actions_list = []
   256|         0|            0|            0|  0.00%|    state_in_list = []
   257|         0|            0|            0|  0.00%|    for player in players:
   258|         0|            0|            0|  0.00%|      # States are ordered by their history.
   259|         0|            0|            0|  0.00%|      for _, state in sorted(states.items(), key=lambda pair: pair[0]):
   260|         0|            0|            0|  0.00%|        if state.is_simultaneous_node() or player == state.current_player():
   261|         0|            0|            0|  0.00%|          legal_actions = state.legal_actions_mask(player)
   262|         0|            0|            0|  0.00%|          if any(legal_actions):
   263|         0|            0|            0|  0.00%|            key = self._state_key(state, player)
   264|         0|            0|            0|  0.00%|            if key not in self.state_lookup:
   265|         0|            0|            0|  0.00%|              state_index = len(legal_actions_list)
   266|         0|            0|            0|  0.00%|              self.state_lookup[key] = state_index
   267|         0|            0|            0|  0.00%|              legal_actions_list.append(legal_actions)
   268|         0|            0|            0|  0.00%|              self.states_per_player[player].append(key)
   269|         0|            0|            0|  0.00%|              self.states.append(state)
   270|         0|            0|            0|  0.00%|              if self.game_type.provides_information_state_tensor:
   271|         0|            0|            0|  0.00%|                state_in_list.append(state.information_state_tensor(player))
   272|         0|            0|            0|  0.00%|              elif self.game_type.provides_observation_tensor:
   273|         0|            0|            0|  0.00%|                state_in_list.append(state.observation_tensor(player))
   274|         0|            0|            0|  0.00%|
   275|         0|            0|            0|  0.00%|    # Put legal action masks in a numpy array and create the uniform random
   276|         0|            0|            0|  0.00%|    # policy.
   277|         0|            0|            0|  0.00%|    self.state_in = None
   278|         0|            0|            0|  0.00%|    if state_in_list:
   279|         0|            0|            0|  0.00%|      self.state_in = np.array(state_in_list)
   280|         0|            0|            0|  0.00%|    self.legal_actions_mask = np.array(legal_actions_list)
   281|         0|            0|            0|  0.00%|    self.action_probability_array = (
   282|         0|            0|            0|  0.00%|        self.legal_actions_mask /
   283|         0|            0|            0|  0.00%|        np.sum(self.legal_actions_mask, axis=-1, keepdims=True))
   284|         0|            0|            0|  0.00%|
   285|         0|            0|            0|  0.00%|  def _state_key(self, state, player):
   286|         0|            0|            0|  0.00%|    """Returns the key to use to look up this (state, player) pair."""
   287|         0|            0|            0|  0.00%|    if self.game_type.provides_information_state_string:
   288|         0|            0|            0|  0.00%|      if player is None:
   289|         0|            0|            0|  0.00%|        return state.information_state_string()
   290|         0|            0|            0|  0.00%|      return state.information_state_string(player)
   291|         0|            0|            0|  0.00%|    if self.game_type.provides_observation_string:
   292|         0|            0|            0|  0.00%|      if player is None:
   293|         0|            0|            0|  0.00%|        return state.observation_string()
   294|         0|            0|            0|  0.00%|      return state.observation_string(player)
   295|         0|            0|            0|  0.00%|    return str(state)
   296|         0|            0|            0|  0.00%|
   297|         0|            0|            0|  0.00%|  def action_probabilities(self, state, player_id=None):
   298|         0|            0|            0|  0.00%|    """Returns an {action: probability} dict, covering all legal actions."""
   299|         0|            0|            0|  0.00%|    legal_actions = (
   300|         0|            0|            0|  0.00%|        state.legal_actions()
   301|         0|            0|            0|  0.00%|        if player_id is None else state.legal_actions(player_id))
   302|         0|            0|            0|  0.00%|    if not legal_actions:
   303|         0|            0|            0|  0.00%|      return {0: 1.0}
   304|         0|            0|            0|  0.00%|    probability = self.policy_for_key(self._state_key(state, player_id))
   305|         0|            0|            0|  0.00%|    return {action: probability[action] for action in legal_actions}
   306|         0|            0|            0|  0.00%|
   307|         0|            0|            0|  0.00%|  def state_index(self, state):
   308|         0|            0|            0|  0.00%|    """Returns the index in the TabularPolicy associated to `state`."""
   309|         0|            0|            0|  0.00%|    return self.state_lookup[self._state_key(state, state.current_player())]
   310|         0|            0|            0|  0.00%|
   311|         0|            0|            0|  0.00%|  def policy_for_key(self, key):
   312|         0|            0|            0|  0.00%|    """Returns the policy as a vector given a state key string.
   313|         0|            0|            0|  0.00%|
   314|         0|            0|            0|  0.00%|    Args:
   315|         0|            0|            0|  0.00%|      key: A key for the specified state.
   316|         0|            0|            0|  0.00%|
   317|         0|            0|            0|  0.00%|    Returns:
   318|         0|            0|            0|  0.00%|      A vector of probabilities, one per action. This is a slice of the
   319|         0|            0|            0|  0.00%|      backing policy array, and so slice or index assignment will update the
   320|         0|            0|            0|  0.00%|      policy. For example:
   321|         0|            0|            0|  0.00%|      ```
   322|         0|            0|            0|  0.00%|      tabular_policy.policy_for_key(s)[:] = [0.1, 0.5, 0.4]
   323|         0|            0|            0|  0.00%|      ```
   324|         0|            0|            0|  0.00%|    """
   325|         0|            0|            0|  0.00%|    return self.action_probability_array[self.state_lookup[key]]
   326|         0|            0|            0|  0.00%|
   327|         0|            0|            0|  0.00%|  def to_dict(self):
   328|         0|            0|            0|  0.00%|    """Returns a single dictionary representing the tabular policy.
   329|         0|            0|            0|  0.00%|
   330|         0|            0|            0|  0.00%|    Returns:
   331|         0|            0|            0|  0.00%|      A dictionary of string keys to lists of (action, prob) pairs.
   332|         0|            0|            0|  0.00%|    """
   333|         0|            0|            0|  0.00%|    policy_dict = {}
   334|         0|            0|            0|  0.00%|    num_actions = self.action_probability_array.shape[1]
   335|         0|            0|            0|  0.00%|    for infostate_key, index in self.state_lookup.items():
   336|         0|            0|            0|  0.00%|      probs = self.action_probability_array[index]
   337|         0|            0|            0|  0.00%|      actions_and_probs = [(a, probs[a]) for a in range(num_actions)]
   338|         0|            0|            0|  0.00%|      policy_dict[infostate_key] = actions_and_probs
   339|         0|            0|            0|  0.00%|    return policy_dict
   340|         0|            0|            0|  0.00%|
   341|         0|            0|            0|  0.00%|  def __copy__(self, copy_action_probability_array=True):
   342|         0|            0|            0|  0.00%|    """Returns a shallow copy of self.
   343|         0|            0|            0|  0.00%|
   344|         0|            0|            0|  0.00%|    Most class attributes will be pointers to the copied object's attributes,
   345|         0|            0|            0|  0.00%|    and therefore altering them could lead to unexpected behavioural changes.
   346|         0|            0|            0|  0.00%|    Only action_probability_array is expected to be modified.
   347|         0|            0|            0|  0.00%|
   348|         0|            0|            0|  0.00%|    Args:
   349|         0|            0|            0|  0.00%|      copy_action_probability_array: Whether to also include
   350|         0|            0|            0|  0.00%|        action_probability_array in the copy operation.
   351|         0|            0|            0|  0.00%|
   352|         0|            0|            0|  0.00%|    Returns:
   353|         0|            0|            0|  0.00%|      Copy.
   354|         0|            0|            0|  0.00%|    """
   355|         0|            0|            0|  0.00%|    result = TabularPolicy.__new__(TabularPolicy)
   356|         0|            0|            0|  0.00%|    result.state_lookup = self.state_lookup
   357|         0|            0|            0|  0.00%|    result.game_type = self.game_type
   358|         0|            0|            0|  0.00%|    result.legal_actions_mask = self.legal_actions_mask
   359|         0|            0|            0|  0.00%|    result.state_in = self.state_in
   360|         0|            0|            0|  0.00%|    result.state_lookup = self.state_lookup
   361|         0|            0|            0|  0.00%|    result.states_per_player = self.states_per_player
   362|         0|            0|            0|  0.00%|    result.states = self.states
   363|         0|            0|            0|  0.00%|    result.game = self.game
   364|         0|            0|            0|  0.00%|    result.player_ids = self.player_ids
   365|         0|            0|            0|  0.00%|    if copy_action_probability_array:
   366|         0|            0|            0|  0.00%|      result.action_probability_array = np.copy(self.action_probability_array)
   367|         0|            0|            0|  0.00%|    return result
   368|         0|            0|            0|  0.00%|
   369|         0|            0|            0|  0.00%|  def copy_with_noise(self,
   370|         0|            0|            0|  0.00%|                      alpha=0.0,
   371|         0|            0|            0|  0.00%|                      beta=0.0,
   372|         0|            0|            0|  0.00%|                      random_state=np.random.RandomState()):
   373|         0|            0|            0|  0.00%|    """Returns a copy of this policy perturbed with noise.
   374|         0|            0|            0|  0.00%|
   375|         0|            0|            0|  0.00%|    Generates a new random distribution using a softmax on normal random
   376|         0|            0|            0|  0.00%|    variables with temperature beta, and mixes it with the old distribution
   377|         0|            0|            0|  0.00%|    using 1-alpha * old_distribution + alpha * random_distribution.
   378|         0|            0|            0|  0.00%|    Args:
   379|         0|            0|            0|  0.00%|      alpha: Parameter characterizing the mixture amount between new and old
   380|         0|            0|            0|  0.00%|        distributions. Between 0 and 1.
   381|         0|            0|            0|  0.00%|        alpha = 0: keep old table.
   382|         0|            0|            0|  0.00%|        alpha = 1: keep random table.
   383|         0|            0|            0|  0.00%|      beta: Temperature of the softmax. Makes for more extreme policies.
   384|         0|            0|            0|  0.00%|      random_state: A numpy `RandomState` object. If not provided, a shared
   385|         0|            0|            0|  0.00%|        random state will be used.
   386|         0|            0|            0|  0.00%|
   387|         0|            0|            0|  0.00%|    Returns:
   388|         0|            0|            0|  0.00%|      Perturbed copy.
   389|         0|            0|            0|  0.00%|    """
   390|         0|            0|            0|  0.00%|    copied_instance = self.__copy__(False)
   391|         0|            0|            0|  0.00%|    probability_array = self.action_probability_array
   392|         0|            0|            0|  0.00%|    noise_mask = random_state.normal(size=probability_array.shape)
   393|         0|            0|            0|  0.00%|    noise_mask = np.exp(beta * noise_mask) * self.legal_actions_mask
   394|         0|            0|            0|  0.00%|    noise_mask = noise_mask / (np.sum(noise_mask, axis=1).reshape(-1, 1))
   395|         0|            0|            0|  0.00%|    copied_instance.action_probability_array = (
   396|         0|            0|            0|  0.00%|        1 - alpha) * probability_array + alpha * noise_mask
   397|         0|            0|            0|  0.00%|    return copied_instance
   398|         0|            0|            0|  0.00%|
   399|         0|            0|            0|  0.00%|
   400|         0|            0|            0|  0.00%|class UniformRandomPolicy(Policy):
   401|         0|            0|            0|  0.00%|  """Policy where the action distribution is uniform over all legal actions.
   402|         0|            0|            0|  0.00%|
   403|         0|            0|            0|  0.00%|  This is computed as needed, so can be used for games where a tabular policy
   404|         0|            0|            0|  0.00%|  would be unfeasibly large, but incurs a legal action computation every time.
   405|         0|            0|            0|  0.00%|  """
   406|         0|            0|            0|  0.00%|
   407|         0|            0|            0|  0.00%|  def __init__(self, game):
   408|         0|            0|            0|  0.00%|    """Initializes a uniform random policy for all players in the game."""
   409|         0|            0|            0|  0.00%|    all_players = list(range(game.num_players()))
   410|         0|            0|            0|  0.00%|    super().__init__(game, all_players)
   411|         0|            0|            0|  0.00%|
   412|         0|            0|            0|  0.00%|  def action_probabilities(self, state, player_id=None):
   413|         0|            0|            0|  0.00%|    """Returns a uniform random policy for a player in a state.
   414|         0|            0|            0|  0.00%|
   415|         0|            0|            0|  0.00%|    Args:
   416|         0|            0|            0|  0.00%|      state: A `pyspiel.State` object.
   417|         0|            0|            0|  0.00%|      player_id: Optional, the player id for which we want an action. Optional
   418|         0|            0|            0|  0.00%|        unless this is a simultaneous state at which multiple players can act.
   419|         0|            0|            0|  0.00%|
   420|         0|            0|            0|  0.00%|    Returns:
   421|         0|            0|            0|  0.00%|      A `dict` of `{action: probability}` for the specified player in the
   422|         0|            0|            0|  0.00%|      supplied state. This will contain all legal actions, each with the same
   423|         0|            0|            0|  0.00%|      probability, equal to 1 / num_legal_actions.
   424|         0|            0|            0|  0.00%|    """
   425|         0|            0|            0|  0.00%|    legal_actions = (
   426|         0|            0|            0|  0.00%|        state.legal_actions()
   427|         0|            0|            0|  0.00%|        if player_id is None else state.legal_actions(player_id))
   428|         0|            0|            0|  0.00%|    if not legal_actions:
   429|         0|            0|            0|  0.00%|      return {0: 1.0}
   430|         0|            0|            0|  0.00%|    probability = 1 / len(legal_actions)
   431|         0|            0|            0|  0.00%|    return {action: probability for action in legal_actions}
   432|         0|            0|            0|  0.00%|
   433|         0|            0|            0|  0.00%|
   434|         0|            0|            0|  0.00%|class FirstActionPolicy(Policy):
   435|         0|            0|            0|  0.00%|  """A policy that always takes the lowest-numbered legal action."""
   436|         0|            0|            0|  0.00%|
   437|         0|            0|            0|  0.00%|  def __init__(self, game):
   438|         0|            0|            0|  0.00%|    all_players = list(range(game.num_players()))
   439|         0|            0|            0|  0.00%|    super().__init__(game, all_players)
   440|         0|            0|            0|  0.00%|
   441|         0|            0|            0|  0.00%|  def action_probabilities(self, state, player_id=None):
   442|         0|            0|            0|  0.00%|    legal_actions = (
   443|         0|            0|            0|  0.00%|        state.legal_actions()
   444|         0|            0|            0|  0.00%|        if player_id is None else state.legal_actions(player_id))
   445|         0|            0|            0|  0.00%|    if not legal_actions:
   446|         0|            0|            0|  0.00%|      return {0: 1.0}
   447|         0|            0|            0|  0.00%|    min_action = min(legal_actions)
   448|         0|            0|            0|  0.00%|    return {
   449|         0|            0|            0|  0.00%|        action: 1.0 if action == min_action else 0.0 for action in legal_actions
   450|         0|            0|            0|  0.00%|    }
   451|         0|            0|            0|  0.00%|
   452|         0|            0|            0|  0.00%|
   453|         0|            0|            0|  0.00%|def get_tabular_policy_states(game):
   454|         0|            0|            0|  0.00%|  """Returns the states of the game for a tabular policy."""
   455|         0|            0|            0|  0.00%|  if game.get_type().dynamics == pyspiel.GameType.Dynamics.MEAN_FIELD:
   456|         0|            0|            0|  0.00%|    # TODO(perolat): We use s.observation_string(DEFAULT_MFG_PLAYER) here as the
   457|         0|            0|            0|  0.00%|    # number of history is exponential on the depth of the MFG. What we really
   458|         0|            0|            0|  0.00%|    # need is a representation of the state. For many player Mean Field games,
   459|         0|            0|            0|  0.00%|    # the state will be (x0, x1, x2, ..., xn) and the observation_string(0) will
   460|         0|            0|            0|  0.00%|    # output the string of x0. In that case we would need something like
   461|         0|            0|            0|  0.00%|    # str([observation_string(i) for i in range(num_player)])
   462|         0|            0|            0|  0.00%|    to_string = lambda s: s.observation_string(pyspiel.PlayerId.
   463|         0|            0|            0|  0.00%|                                               DEFAULT_PLAYER_ID)
   464|         0|            0|            0|  0.00%|  else:
   465|         0|            0|            0|  0.00%|    to_string = lambda s: s.history_str()
   466|         0|            0|            0|  0.00%|  return get_all_states.get_all_states(
   467|         0|            0|            0|  0.00%|      game,
   468|         0|            0|            0|  0.00%|      depth_limit=-1,
   469|         0|            0|            0|  0.00%|      include_terminals=False,
   470|         0|            0|            0|  0.00%|      include_chance_states=False,
   471|         0|            0|            0|  0.00%|      include_mean_field_states=False,
   472|         0|            0|            0|  0.00%|      to_string=to_string)
   473|         0|            0|            0|  0.00%|
   474|         0|            0|            0|  0.00%|
   475|         0|            0|            0|  0.00%|def tabular_policy_from_callable(game, callable_policy, players=None):
   476|         0|            0|            0|  0.00%|  """Converts a legacy callable policy into a TabularPolicy.
   477|         0|            0|            0|  0.00%|
   478|         0|            0|            0|  0.00%|  Recommendation - instead of using this to convert your policy for evaluation
   479|         0|            0|            0|  0.00%|  purposes, work directly with a `TabularPolicy` if possible.
   480|         0|            0|            0|  0.00%|  Second choice - work with a `Policy` class and call `to_tabular` as needed.
   481|         0|            0|            0|  0.00%|
   482|         0|            0|            0|  0.00%|  Args:
   483|         0|            0|            0|  0.00%|    game: The game for which we want a TabularPolicy.
   484|         0|            0|            0|  0.00%|    callable_policy: A callable: state -> action probabilities dict or list.
   485|         0|            0|            0|  0.00%|    players: List of players this policy applies to. If `None`, applies to all
   486|         0|            0|            0|  0.00%|      players.
   487|         0|            0|            0|  0.00%|
   488|         0|            0|            0|  0.00%|  Returns:
   489|         0|            0|            0|  0.00%|    A TabularPolicy that materializes the callable policy.
   490|         0|            0|            0|  0.00%|  """
   491|         0|            0|            0|  0.00%|  tabular_policy = TabularPolicy(game, players)
   492|         0|            0|            0|  0.00%|  for state_index, state in enumerate(tabular_policy.states):
   493|         0|            0|            0|  0.00%|    action_probabilities = dict(callable_policy(state))
   494|         0|            0|            0|  0.00%|    infostate_policy = [
   495|         0|            0|            0|  0.00%|        action_probabilities.get(action, 0.)
   496|         0|            0|            0|  0.00%|        for action in range(game.num_distinct_actions())
   497|         0|            0|            0|  0.00%|    ]
   498|         0|            0|            0|  0.00%|    tabular_policy.action_probability_array[state_index, :] = infostate_policy
   499|         0|            0|            0|  0.00%|  return tabular_policy
   500|         0|            0|            0|  0.00%|
   501|         0|            0|            0|  0.00%|
   502|         0|            0|            0|  0.00%|def pyspiel_policy_to_python_policy(game, pyspiel_tabular_policy, players=None):
   503|         0|            0|            0|  0.00%|  """Converts a pyspiel.TabularPolicy to a TabularPolicy.
   504|         0|            0|            0|  0.00%|
   505|         0|            0|            0|  0.00%|  Args:
   506|         0|            0|            0|  0.00%|    game: The OpenSpiel game.
   507|         0|            0|            0|  0.00%|    pyspiel_tabular_policy: Pyspiel tabular policy to copy from.
   508|         0|            0|            0|  0.00%|    players: List of integer player ids to copy policy from. For example,
   509|         0|            0|            0|  0.00%|      `players=[0]` will only copy player 0's policy over into the python policy
   510|         0|            0|            0|  0.00%|      (the other player's policies will be undefined). Default value of `None`
   511|         0|            0|            0|  0.00%|      will copy all players' policies.
   512|         0|            0|            0|  0.00%|
   513|         0|            0|            0|  0.00%|  Returns:
   514|         0|            0|            0|  0.00%|    python_policy
   515|         0|            0|            0|  0.00%|  """
   516|         0|            0|            0|  0.00%|  policy = TabularPolicy(game, players=players)
   517|         0|            0|            0|  0.00%|  for item in pyspiel_tabular_policy.policy_table().items():
   518|         0|            0|            0|  0.00%|    info_state_str, actions_probs = item
   519|         0|            0|            0|  0.00%|    # If requested, only populate a policy for particular players.
   520|         0|            0|            0|  0.00%|    if players is not None and info_state_str not in policy.state_lookup:
   521|         0|            0|            0|  0.00%|      continue
   522|         0|            0|            0|  0.00%|    state_policy = policy.policy_for_key(info_state_str)
   523|         0|            0|            0|  0.00%|    for action, prob in actions_probs:
   524|         0|            0|            0|  0.00%|      state_policy[action] = prob
   525|         0|            0|            0|  0.00%|  return policy
   526|         0|            0|            0|  0.00%|
   527|         0|            0|            0|  0.00%|
   528|         0|            0|            0|  0.00%|def python_policy_to_pyspiel_policy(python_tabular_policy):
   529|         0|            0|            0|  0.00%|  """Converts a TabularPolicy to a pyspiel.TabularPolicy."""
   530|         0|            0|            0|  0.00%|  infostates_to_probabilities = dict()
   531|         0|            0|            0|  0.00%|  for infostate, index in python_tabular_policy.state_lookup.items():
   532|         0|            0|            0|  0.00%|    probs = python_tabular_policy.action_probability_array[index]
   533|         0|            0|            0|  0.00%|    legals = python_tabular_policy.legal_actions_mask[index]
   534|         0|            0|            0|  0.00%|
   535|         0|            0|            0|  0.00%|    action_probs = []
   536|         0|            0|            0|  0.00%|    for action, (prob, is_legal) in enumerate(zip(probs, legals)):
   537|         0|            0|            0|  0.00%|      if is_legal == 1:
   538|         0|            0|            0|  0.00%|        action_probs.append((action, prob))
   539|         0|            0|            0|  0.00%|    infostates_to_probabilities[infostate] = action_probs
   540|         0|            0|            0|  0.00%|  return pyspiel.TabularPolicy(infostates_to_probabilities)
   541|         0|            0|            0|  0.00%|
   542|         0|            0|            0|  0.00%|
   543|         0|            0|            0|  0.00%|def python_policies_to_pyspiel_policies(policies):
   544|         0|            0|            0|  0.00%|  """Same conversion as above (list version).
   545|         0|            0|            0|  0.00%|
   546|         0|            0|            0|  0.00%|  Args:
   547|         0|            0|            0|  0.00%|    policies: a list of python.TabularPolicy
   548|         0|            0|            0|  0.00%|
   549|         0|            0|            0|  0.00%|  Returns:
   550|         0|            0|            0|  0.00%|    a list of pyspiel.TabularPolicy.
   551|         0|            0|            0|  0.00%|  """
   552|         0|            0|            0|  0.00%|  return [python_policy_to_pyspiel_policy(p) for p in policies]
   553|         0|            0|            0|  0.00%|
   554|         0|            0|            0|  0.00%|
   555|         0|            0|            0|  0.00%|def merge_tabular_policies(tabular_policies, game):
   556|         0|            0|            0|  0.00%|  """Merges n_player policies into single joint policy.
   557|         0|            0|            0|  0.00%|
   558|         0|            0|            0|  0.00%|  Missing states are filled with a valid uniform policy.
   559|         0|            0|            0|  0.00%|
   560|         0|            0|            0|  0.00%|  Args:
   561|         0|            0|            0|  0.00%|    tabular_policies: List of python TabularPolicy (one for each player).
   562|         0|            0|            0|  0.00%|    game: The game corresponding to the resulting TabularPolicy.
   563|         0|            0|            0|  0.00%|
   564|         0|            0|            0|  0.00%|  Returns:
   565|         0|            0|            0|  0.00%|    merged_policy: A TabularPolicy with each player i's policy taken from the
   566|         0|            0|            0|  0.00%|      ith joint_policy.
   567|         0|            0|            0|  0.00%|  """
   568|         0|            0|            0|  0.00%|  if len(tabular_policies) != game.num_players():
   569|         0|            0|            0|  0.00%|    raise ValueError("len(tabular_policies) != num_players: %d != %d" %
   570|         0|            0|            0|  0.00%|                     (len(tabular_policies), game.num_players()))
   571|         0|            0|            0|  0.00%|  merged_policy = TabularPolicy(game)
   572|         0|            0|            0|  0.00%|  for p, p_states in enumerate(merged_policy.states_per_player):
   573|         0|            0|            0|  0.00%|    for p_state in p_states:
   574|         0|            0|            0|  0.00%|      to_index = merged_policy.state_lookup[p_state]
   575|         0|            0|            0|  0.00%|      # Only copy if the state exists, otherwise fall back onto uniform.
   576|         0|            0|            0|  0.00%|      if p_state in tabular_policies[p].state_lookup:
   577|         0|            0|            0|  0.00%|        from_index = tabular_policies[p].state_lookup[p_state]
   578|         0|            0|            0|  0.00%|        merged_policy.action_probability_array[to_index] = (
   579|         0|            0|            0|  0.00%|            tabular_policies[p].action_probability_array[from_index])
   580|         0|            0|            0|  0.00%|  return merged_policy
