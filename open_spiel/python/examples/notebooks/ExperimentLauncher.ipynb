{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d1f915-16a6-42e9-b93a-3f44564ef069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from collections import defaultdict\n",
    "import open_spiel.python.examples.ubc_dispatch as dispatch\n",
    "import os\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a963cf68-f084-47bc-86bf-23882e77f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_dir = os.environ[\"CLOCK_AUCTION_CONFIG_DIR\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e41bc-15e4-445d-9c0a-2967c7c907b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sats_games = [os.path.basename(x).replace('.json','') for x in glob.glob(f'{game_dir}/sats*')]\n",
    "# sats_games = ['sats_3regions_3licenses_5types']\n",
    "# sats_games = ['sats_2regions_2licenses_2players_5types']\n",
    "# sats_games = ['rw_game_2_war_speedy_2']\n",
    "sats_games = ['sats_3regions_3licenses_5types']\n",
    "sats_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f2f6e-14f5-4fd5-b926-3504b729bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SATS Games\n",
    "CONFIG = 'aug11'\n",
    "BR_CONFIG = 'aug11'\n",
    "N_SEEDS = 5\n",
    "overrides = f'--overwrite_db True --br_portfolio_path {BR_CONFIG} --eval_every 1000 --eval_zero true --eval_every_early 200 --total_timesteps 1_000_000 --dispatch_br true --br_overrides \"--total_timesteps 10_000\"'\n",
    "for GAME_NAME in sats_games:\n",
    "    dispatch.dispatch_experiments(CONFIG, base_job_name='speedy_war3', game_name=f'{GAME_NAME}', overrides = overrides, n_seeds=N_SEEDS)\n",
    "    # dispatch.dispatch_experiments(CONFIG, base_job_name='sats_games_11_with_require_br', game_name=f'{GAME_NAME}', overrides = overrides + ' --iterate_br false --require_br true', n_seeds=N_SEEDS)\n",
    "    # dispatch.dispatch_experiments(CONFIG, base_job_name='sats_games_11_with_random_ic', game_name=f'{GAME_NAME}', overrides = overrides + ' --random_ic true', n_seeds=N_SEEDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2179215-a8af-4432-a7db-0144903c2bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "albert_games = [os.path.basename(x).replace('.json','') for x in glob.glob(f'{game_dir}/rw*')]\n",
    "# albert_games = ['rw_game_2_settle', 'rw_game_2_settle_spiteful', 'rw_game_2_settle_very_spiteful']\n",
    "# albert_games = ['rw_game_2_settle_spiteful']\n",
    "albert_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ddc1da-5e96-48f2-a6af-6a8cb5bcf73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albert's games without iterate_br\n",
    "CONFIG = 'may17'\n",
    "BR_CONFIG = 'may17'\n",
    "N_SEEDS = 1\n",
    "overrides = f'--overwrite_db True --br_portfolio_path {BR_CONFIG} --eval_every 100_000 --eval_zero true --eval_every_early 20_000 --num_training_episodes 100_000 --br_overrides \"--num_training_episodes 10_000\"'\n",
    "for GAME_NAME in albert_games:\n",
    "    dispatch.dispatch_experiments(CONFIG, base_job_name='adam_test_3', game_name=f'{GAME_NAME}', overrides = overrides, n_seeds=N_SEEDS)\n",
    "    # dispatch.dispatch_experiments(CONFIG, base_job_name='albert_games_revived_3_with_require_br', game_name=f'{GAME_NAME}', overrides = overrides + ' --iterate_br false --require_br true', n_seeds=N_SEEDS)\n",
    "    # dispatch.dispatch_experiments(CONFIG, base_job_name='albert_games_revived_3_with_random_ic', game_name=f'{GAME_NAME}', overrides = overrides + ' --random_ic true', n_seeds=N_SEEDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a4a759-38c6-4876-a965-b8cfff413329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG = 'flatmlp'\n",
    "# GAME_NAME = 'very_large_game_2'\n",
    "# N_SEEDS = 1\n",
    "# overrides = f'--overwrite_db True --br_portfolio_path flatmlp --eval_every 1_000_000 --eval_zero true --num_training_episodes 10_000_000 --br_overrides \"--num_training_episodes 1_000_000\"'\n",
    "# dispatch.dispatch_experiments(CONFIG, base_job_name='april11_flattest_very_large_2', game_name=f'{GAME_NAME}', overrides = overrides, n_seeds=N_SEEDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ea616-82bb-4726-8f0d-1f7cda6ed24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = 'mar17'\n",
    "GAME_NAME = 'large_game_2'\n",
    "N_SEEDS = 5\n",
    "overrides = f'--br_portfolio_path mar17 --eval_every 1_000_000 --num_training_episodes 10_000_000 --br_overrides \"--num_training_episodes 1_000_000\"'\n",
    "\n",
    "# Base\n",
    "dispatch.dispatch_experiments(CONFIG, base_job_name='mar24', game_name=f'{GAME_NAME}', overrides = overrides, n_seeds=N_SEEDS)\n",
    "\n",
    "# Hidden demands  \n",
    "# dispatch.dispatch_experiments(CONFIG, base_job_name='mar19', game_name=f'{GAME_NAME}_hide', overrides = overrides, n_seeds=N_SEEDS)\n",
    "\n",
    "# Reserve prices\n",
    "# TODO: Holding off for now b/c rounds issue\n",
    "# dispatch.dispatch_experiments(CONFIG, base_job_name='mar19', game_name=f'{GAME_NAME}_low_reserve', overrides = overrides, n_seeds=N_SEEDS)\n",
    "# dispatch.dispatch_experiments(CONFIG, base_job_name='mar19', game_name=f'{GAME_NAME}_same_reserve', overrides = overrides, n_seeds=N_SEEDS)\n",
    "\n",
    "# Activity\n",
    "# dispatch.dispatch_experiments(CONFIG, base_job_name='mar19', game_name=f'{GAME_NAME}_no_activity', overrides = overrides, n_seeds=N_SEEDS)\n",
    "# Undersell\n",
    "# dispatch.dispatch_experiments(CONFIG, base_job_name='mar19', game_name=f'{GAME_NAME}_no_undersell', overrides = overrides, n_seeds=N_SEEDS)\n",
    "\n",
    "# Initial pricing experiment, on the base game\n",
    "dispatch.dispatch_experiments(CONFIG, base_job_name='mar24', game_name=f'{GAME_NAME}_pricing05', overrides = overrides, n_seeds=N_SEEDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d200227-7a69-417a-be93-58c262f123b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !squeue --format=\"%.18i %.65j %.2t %.10M %.6D %R\" | grep \"rnrtest\" | awk '{print $1}' | xargs scancel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c26b7-d158-4ece-a72a-c3b2fd47a56f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!squeue --format=\"%.18i %.90j %.2t .%.10M %.6D %R\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee533f-357a-4bbc-956e-1cf136ef9266",
   "metadata": {},
   "outputs": [],
   "source": [
    "!squeue | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26b508d-9ee0-4878-9aa1-68c611ab651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scancel -u ubuntu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee5cc7e-228c-4484-bb31-efb870f59efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !scancel  25809"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeeeeb6-6c6f-4e37-9566-3eb8d73d97d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /shared/outputs/minitest/\n",
    "try:\n",
    "    Experiment.objects.get(name='minitest').delete()\n",
    "except:\n",
    "    pass\n",
    "dispatch.dispatch_experiments('feb2', base_job_name='minitest', game_name='tiny', overrides = '--br_portfolio_path feb2 --eval_every 500 --num_training_episodes 1_000 --br_overrides \"--num_training_episodes 1_000\" --eval_overrides \"--num_samples 100\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ca4c72-ce03-4d1a-8e9d-1abd642e8407",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestResponse.objects.last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1b3451-a927-4467-a90d-077f2de61767",
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiment.objects.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547418d-7d14-404e-ad7f-892180cd6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sacct --starttime 2022-03-11 --format=User,JobID,Jobname,partition,state,time,start,end,elapsed,MaxRss,MaxVMSize,nnodes,ncpus,nodelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc11eb7-da86-46db-9a6b-fe5ac595f1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_spiel.python.examples.ubc_plotting_utils import parse_run\n",
    "from auctions.webutils import *\n",
    "\n",
    "def find_best_checkpoint(run, max_t=None):\n",
    "    ev_df = parse_run(run, max_t)\n",
    "    best_t = ev_df.groupby('t')['ApproxNashConv'].first().idxmin()\n",
    "    nash_conv_by_t = ev_df.groupby('t')['ApproxNashConv'].first()\n",
    "    best_checkpoint = get_checkpoint(run, t=best_t)\n",
    "    return nash_conv_by_t, best_checkpoint, nash_conv_by_t.min()\n",
    "\n",
    "\n",
    "run = EquilibriumSolverRun.objects.last()\n",
    "find_best_checkpoint(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3abf2-1dca-40a7-8c86-f558ac16c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiment.objects.get(name='large_game_2_no_activity.json').delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5184d7b-9f29-48aa-ae93-8920db084b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Game.objects.get(name='large_game_2_pricing_extreme.json').delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e706f461-6a88-4392-bfe4-6187661e1533",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /apps/open_spiel/web/auctions/manage.py nfsp --seed 109 --filename rounds.json --network_config_file mar17/lstm --experiment_name lstmtest --job_name \"lstm_for_greg\" --dispatch_br false --br_portfolio_path feb22 --eval_every 10_000 --num_training_episodes 10_000_000 --br_overrides \"--num_training_episodes 1_000_000\" --report_freq 10_000 --overwrite_db true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b85fe-1070-463b-9b8c-3f3392d9f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(Experiment.objects.all().values_list('name', flat=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d371b8e4-55d3-4859-b28d-ff8ef2098380",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = EquilibriumSolverRun.objects.get(name='large_game_3b_hide-mar17lstm-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cdffb6-5085-4c1b-9d33-1b343934cbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from auctions.webutils import *\n",
    "from open_spiel.python.examples.ubc_plotting_utils import *\n",
    "parse_run(r, conservative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ad314-b27a-41d4-94d6-214cb903b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BREvaluation.objects.filter(best_response__checkpoint__equilibrium_solver_run=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae40c6-7e65-4f2b-8233-3597d7096772",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(BestResponse.objects.filter(checkpoint__equilibrium_solver_run=r).values('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8126fd-9169-41f8-85dc-1cc748b31578",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestResponse.objects.filter(checkpoint=pk)[0].brevaluation.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb37f06-5475-4c99-98db-bbf8f4385198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_spiel.python.examples.ubc_plotting_utils import *\n",
    "parse_run(r, conservative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4a0414-e2de-4a61-84d7-128d9ec1605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BREvaluation.objects.filter(best_response__checkpoint__equilibrium_solver_run=r).values('best_response__name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a64a9d-f0fd-4f83-a7a5-e4533efdef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestResponse.objects.filter(checkpoint__equilibrium_solver_run=r).values('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d30846-58d7-48ea-8c37-26a8e3ff3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['mar24', 'mar22_4']\n",
    "all_scripts = []\n",
    "for e in experiments:\n",
    "    scripts = glob.glob(f'/shared/outputs/{e}/*/evaluations/*.sh')\n",
    "    scripts = [s for s in scripts if 'straightforward' not in s]\n",
    "    scripts = [s for s in scripts if s[-5:] == \"_2.sh\"]\n",
    "    all_scripts += scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add0f96-beb4-4aa2-b729-61c3d03e9746",
   "metadata": {},
   "outputs": [],
   "source": [
    "for script in all_scripts:\n",
    "    parent = Path(script).parent\n",
    "    !cd {parent} && sbatch {script}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19fcfab-57c4-4fea-bebc-a59ecde20baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Evaluation.objects.last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f49bbf-6fcb-438a-a773-7dac9b989148",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.samples['allocations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d2c89-07b8-43c7-ba5d-f8bfcbce3496",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation.objects.last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be1d94a-3886-4c7e-9aec-74dd5ff08c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "x = torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ffdfc7-0d45-4213-91e2-4efb2759f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.pad(x, (0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1220a6ad-d54f-4259-8c48-12f7a6d7ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.pad(input, pad, mode='constant', value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b745d521-0b5b-4c8a-bfb4-3f6ad0f4c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "python /apps/open_spiel/web/auctions/manage.py nfsp --seed 100 --filename sats_5.json --network_config_file flatmlp/mlp --experiment_name test_require_br --job_name \"sats_5_test-flatmlpmlp-100\" --dispatch_br false --dry_run true --overwrite_db True --br_portfolio_path flatmlp --eval_every 1_000_000 --eval_zero false --num_training_episodes 8_000_000 --br_overrides \"--num_training_episodes 1_000_000\" --iterate_br false --require_br true\n",
    "\n",
    "# Get env_and_model\n",
    "\n",
    "\n",
    "# run_nfsp(env_and_model, 10_000, True, False, NullResultSaver(), 1, False, NullDispatcher(), eval_every, eval_every_early, eval_exactly, eval_zero, report_freq, dispatch_br, agent_selector, random_ic=False):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7170f-13f4-4ce5-a820-f262f723198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BREvaluation.objects.filter(best_response__name='straightforward').last().expected_value_cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488facaa-1c0d-4501-ad6f-58bb7a5d951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff4a62-6efa-4c03-97d1-7179df936e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation.objects.last().samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d9147a8-cbcb-46aa-b85c-c58d5ce2a243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluation.objects.filter(\n",
    "                    checkpoint__equilibrium_solver_run__experiment__name='testevolution3',\n",
    "                    checkpoint__equilibrium_solver_run__generation=0,\n",
    "                ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3440a1-8cf7-4b38-ab49-ee35de8e7c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Evaluation: Evaluation for rw_game_2_war_speedy_2-aug11ppo-100 (speedy_war3) Iteration 62464>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluation.objects.last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "100695cb-816a-45bc-977f-4bb15f45f37a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EnvParams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mEnvParams\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EnvParams' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b872bf59-e8f0-4de1-b5b7-4f2fe922383e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/venv/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n",
      "/home/ubuntu/.pyenv/versions/venv/lib/python3.8/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "/home/ubuntu/.pyenv/versions/venv/lib/python3.8/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "[2022-10-04 23:11:24,477] {ubc_utils.py:44} INFO - Setting numpy and torch seed to 1234\n",
      "[2022-10-04 23:11:24,478] {ppo_utils.py:43} INFO - Reading config from /apps/open_spiel/notebooks/configs/aug11/ppo_reward.yml\n",
      "[2022-10-04 23:11:24,480] {ubc_utils.py:130} WARNING - Overriding use_wandb from command line\n",
      "[2022-10-04 23:11:24,480] {ppo.py:77} INFO - Network params: {'num_envs': 8, 'steps_per_batch': 128, 'num_minibatches': 4, 'update_epochs': 4, 'learning_rate': 0.00025, 'num_annealing_updates': None, 'gae': True, 'gamma': 0.99, 'gae_lambda': 0.95, 'normalize_advantages': True, 'clip_coef': 0.2, 'clip_vloss': True, 'agent_fn': 'PPOAgent', 'entropy_coef': 0.01, 'value_coef': 0.5, 'max_grad_norm': 0.5, 'target_kl': None, 'device': 'cuda', 'use_wandb': 1, 'reward_function': 'revenue_sparse_normalized', 'schedule_function': 'linear', 'seed': 1234, 'total_timesteps': 1000000}\n",
      "[2022-10-04 23:11:24,480] {ppo.py:78} INFO - Command line commands {'verbosity': 1, 'settings': None, 'pythonpath': None, 'traceback': False, 'no_color': False, 'force_color': False, 'skip_checks': False, 'total_timesteps': 1000000, 'seed': 1234, 'network_config_file': 'aug11/ppo_reward', 'compute_nash_conv': False, 'device': <function default_device at 0x7f1dfc3b83a0>, 'overwrite_db': 1, 'dry_run': 1, 'output_dir': 'output', 'warn_on_overwrite': False, 'experiment_name': 'testrewardshape', 'job_name': 'parameters-aug11ppo-104', 'filename': 'sats_2regions_2licenses_2players_5types.json', 'game_name': 'python_clock_auction', 'parent_checkpoint_pk': None, 'report_freq': 50000, 'eval_every': 500, 'eval_every_early': None, 'eval_exactly': [], 'eval_zero': 1, 'use_wandb': 1, 'wandb_note': '', 'dispatch_br': 1, 'br_portfolio_path': None, 'br_overrides': '', 'eval_overrides': '', 'pprofile': 0, 'pprofile_file': 'profile.txt', 'cprofile': 0, 'cprofile_file': 'cprofile.txt'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnewmanne\u001b[0m (\u001b[33mubc-algorithms\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.3 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/apps/open_spiel/open_spiel/python/examples/notebooks/wandb/run-20221004_231124-j54pamh3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mzany-vortex-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ubc-algorithms/testrewardshape\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ubc-algorithms/testrewardshape/runs/j54pamh3\u001b[0m\n",
      "[2022-10-04 23:11:26,484] {clock_auction.py:136} INFO - Reading from env variable CLOCK_AUCTION_CONFIG_DIR. If it is not set, there will be trouble.\n",
      "[2022-10-04 23:11:26,484] {clock_auction.py:140} INFO - CLOCK_AUCTION_CONFIG_DIR=/apps/open_spiel/configs\n",
      "[2022-10-04 23:11:26,484] {clock_auction.py:143} INFO - Parsing configuration from /apps/open_spiel/configs/sats_2regions_2licenses_2players_5types.json\n",
      "[2022-10-04 23:11:26,485] {clock_auction.py:207} INFO - Done config parsing\n",
      "[2022-10-04 23:11:26,486] {rl_environment.py:197} INFO - Using game instance: python_clock_auction\n",
      "[2022-10-04 23:11:26,504] {rl_environment.py:197} INFO - Using game instance: python_clock_auction\n",
      "[2022-10-04 23:11:26,505] {rl_environment.py:197} INFO - Using game instance: python_clock_auction\n",
      "[2022-10-04 23:11:26,506] {rl_environment.py:197} INFO - Using game instance: python_clock_auction\n",
      "[2022-10-04 23:11:26,506] {rl_environment.py:197} INFO - Using game instance: python_clock_auction\n",
      "[2022-10-04 23:11:26,507] {rl_environment.py:197} INFO - Using game instance: python_clock_auction\n",
      "[2022-10-04 23:11:26,507] {rl_environment.py:197} INFO - Using game instance: python_clock_auction\n",
      "[2022-10-04 23:11:26,508] {rl_environment.py:197} INFO - Using game instance: python_clock_auction\n",
      "[2022-10-04 23:11:26,508] {rl_environment.py:197} INFO - Using game instance: python_clock_auction\n",
      "[2022-10-04 23:11:30,629] {rl_environment.py:197} INFO - Using game instance: python_clock_auction\n",
      "[2022-10-04 23:11:30,635] {ubc_utils.py:44} INFO - Setting numpy and torch seed to 1234\n",
      "[2022-10-04 23:11:30,635] {ppo_utils.py:214} INFO - Training for 976 updates\n",
      "[2022-10-04 23:11:30,636] {ppo_utils.py:215} INFO - Fixed agents are set(). Learning agents are [0, 1]\n",
      "[2022-10-04 23:11:30,636] {ppo_utils.py:260} INFO - EVALUATION AFTER 128 steps\n",
      "[2022-10-04 23:13:57,352] {ppo_utils.py:244} INFO - Policy has not changed for 5 updates. Stopping training\n",
      "[2022-10-04 23:13:57,352] {ppo_utils.py:250} INFO - Terminating PPO training after 38 updates\n",
      "[2022-10-04 23:13:57,352] {ppo_utils.py:295} INFO - Update 38\n",
      "[2022-10-04 23:13:57,352] {ppo_utils.py:260} INFO - EVALUATION AFTER 4864 steps\n",
      "[2022-10-04 23:13:57,353] {ppo_utils.py:301} INFO - Walltime: 2 minutes and 26.72 seconds\n",
      "[2022-10-04 23:13:57,353] {ppo_utils.py:302} INFO - All done. Goodbye!\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                SPS_0 █▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                SPS_1 ████▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          approx_kl_0 ▁▂▃▄▅▅▅▃▅▄▅█▇█▆▇▆▅▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          approx_kl_1 ▁▁▂▄▆█▇█▇▆▆▇▆▄▄▃▃▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           clipfrac_0 ▁▁▂▃▄▄▃▂▄▅▅█▇▇▅▆▇▅▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           clipfrac_1 ▁▁▁▂▅█▇█▇▆▅▄▆▃▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            entropy_0 ████▇▇▆▆▆▆▆▅▅▅▅▄▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            entropy_1 █████▇▇▇▆▅▅▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: explained_variance_0 ▁▃▄▅▅▅▆▆▆▆▆▆▇▇▇███████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: explained_variance_1 ▁▁▂▄▅▅▅▅▆▆▆▇▇▇▇▇██████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      learning_rate_0 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      learning_rate_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    max_policy_diff_0 ▃▄▅▆▅▆▆▄▇▇▇███▇▆▆▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    max_policy_diff_1 ▂▂▃▄▆▅▆▇▇▆█▆▅▄▄▃▃▂▂▂▂▂▂▁▁▁▂▁▁▁▂▁▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      old_approx_kl_0 ▃▂▅▄▃▄▁▂▅▇▄▇█▅▃▇▄▆▄▃▆▃▂▂▁▁▁▁▁▂▁▁▂▂▂▂▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      old_approx_kl_1 ▂▂▂▅▃▇▄█▅▂▃▃▂▁▅▁▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        policy_loss_0 ▇▄▃▄▂▄▄▇▆▆▇▄▄▄▅▁▃▃▄▆▄▅▆▆█▇▇█████▇██▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        policy_loss_1 ▇▆▅▃▂▁▁▃▄▃▅▅▄▆▄▅▅▇▆▆▇▆▆▇▇▇█▇██▇█▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   total_steps_done_0 ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   total_steps_done_1 ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       updates_done_0 ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       updates_done_1 ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         value_loss_0 █▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         value_loss_1 █▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                SPS_0 267\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                SPS_1 265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          approx_kl_0 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          approx_kl_1 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           clipfrac_0 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           clipfrac_1 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            entropy_0 0.01016\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            entropy_1 0.00556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: explained_variance_0 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: explained_variance_1 0.99705\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      learning_rate_0 0.00025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      learning_rate_1 0.00025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    max_policy_diff_0 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    max_policy_diff_1 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      old_approx_kl_0 -1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      old_approx_kl_1 -4e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        policy_loss_0 -0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        policy_loss_1 -0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   total_steps_done_0 38912\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   total_steps_done_1 38912\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       updates_done_0 37\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       updates_done_1 37\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         value_loss_0 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         value_loss_1 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mzany-vortex-1\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/ubc-algorithms/testrewardshape/runs/j54pamh3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221004_231124-j54pamh3/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python /apps/cluster_open_spiel/web/auctions/manage.py ppo --filename sats_2regions_2licenses_2players_5types.json --network_config_file aug11/ppo_reward --experiment_name testrewardshape --job_name \"parameters-aug11ppo-104\" --overwrite_db True --eval_every 500 --eval_zero true --total_timesteps 1_000_000 --use_wandb true --dry_run true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621a423d-68c3-4749-ae0c-ad40dcbcd32f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
