{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a365473e-8b3b-4d3e-84ab-6dd6bae5d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19443b79-c952-4fc5-b763-c12f4496ecdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "import scipy.stats\n",
    "import time\n",
    "\n",
    "from open_spiel.python.algorithms.exploitability import nash_conv, best_response\n",
    "from open_spiel.python.examples.ubc_plotting_utils import *\n",
    "from open_spiel.python.examples.ubc_sample_game_tree import sample_game_tree, flatten_trees, flatten_tree\n",
    "from open_spiel.python.examples.ubc_clusters import projectPCA, fitGMM\n",
    "from open_spiel.python.examples.ubc_utils import *\n",
    "import open_spiel.python.examples.ubc_dispatch as dispatch\n",
    "from open_spiel.python.visualizations import ubc_treeviz\n",
    "\n",
    "\n",
    "from auctions.webutils import *\n",
    "\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "\n",
    "from open_spiel.python.examples.ubc_cma import *\n",
    "\n",
    "output_notebook()\n",
    "from open_spiel.python.games.clock_auction_base import InformationPolicy, ActivityPolicy, UndersellPolicy, TiebreakingPolicy\n",
    "from open_spiel.python.algorithms.exploitability import nash_conv, best_response\n",
    "from open_spiel.python.examples.ubc_decorators import TakeSingleActionDecorator, TremblingAgentDecorator, ModalAgentDecorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f5b830e-7c84-464c-9d03-dde4bec0ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'oct4_encumberedheuristic_oct4_encumberedheuristic_3_base_undersell_allowed-cfr_port_7_extexternal_plus_full-101'\n",
    "run = EquilibriumSolverRun.objects.get(name=name, experiment__name='oct13_external_heuristics_v1')\n",
    "game, final_checkpoint, policy = get_results(run, load_policy=True)\n",
    "evaluation = final_checkpoint.get_modal_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7893e5-6b3d-4bf3-b744-8d10c7c9e3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "retval = nash_conv(game, policy, return_only_nash_conv=False, restrict_to_heuristics=True)\n",
    "print(retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a68e827f-993b-4195-9d6e-67e5e3a11729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_NashConvReturn(nash_conv=20.24767626552017, player_improvements=array([18.6684278 ,  1.57924847]), br_policies=[<open_spiel.python.algorithms.best_response.BestResponsePolicy object at 0x7fb020bc98e0>, <open_spiel.python.algorithms.best_response.BestResponsePolicy object at 0x7fb020bc9940>])\n",
      "CPU times: user 842 ms, sys: 24.1 ms, total: 866 ms\n",
      "Wall time: 865 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "env_and_policy = make_env_and_policy(game, dict(final_checkpoint.equilibrium_solver_run.config))\n",
    "for agent in env_and_policy.agents:\n",
    "    agent.policy = policy\n",
    "for player in range(game.num_players()):\n",
    "    env_and_policy.agents[player] = ModalAgentDecorator(env_and_policy.agents[player])\n",
    "modal_policy = env_and_policy.make_policy()\n",
    "modal_retval = nash_conv(game, modal_policy, return_only_nash_conv=False, restrict_to_heuristics=True)\n",
    "print(modal_retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eb3a1d95-0b67-4258-b743-a4169fbdc6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_game_tree(game, policy, br_policies=None, fname='treeviz.png', figure_dir='figures/2023-06-27-graphviz'):\n",
    "    node_policy_decorator, edge_policy_decorator = ubc_treeviz.make_policy_decorators(policy, br_policies)\n",
    "    gametree = ubc_treeviz.GameTree(\n",
    "        game,\n",
    "        node_decorator=node_policy_decorator,\n",
    "        edge_decorator=edge_policy_decorator,\n",
    "        group_infosets=False,\n",
    "        group_terminal=False,\n",
    "        group_pubsets=False, \n",
    "        target_pubset='*',\n",
    "        depth_limit=20,\n",
    "        # state_prob_limit=0.001,\n",
    "        action_prob_limit=0.14, \n",
    "        policy=policy,\n",
    "        br_policies=br_policies,\n",
    "    )\n",
    "    \n",
    "    outfile = os.path.join(figure_dir, fname)\n",
    "    gametree.draw(outfile, prog='dot')\n",
    "    print(\"Game tree saved to file\", outfile)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb989631-0725-4f24-a547-e3c4bbad46d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game tree saved to file figures/mixing.pdf\n"
     ]
    }
   ],
   "source": [
    "draw_game_tree(game, policy, fname='mixing.pdf', figure_dir='figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "016016f3-7aec-4b80-a590-3e9fd8b405ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game tree saved to file figures/mixing_br.pdf\n"
     ]
    }
   ],
   "source": [
    "draw_game_tree(game, policy, retval.br_policies, fname='mixing_br.pdf', figure_dir='figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "299e3161-1ce3-4973-a28a-c37db23bd856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game tree saved to file figures/mixing_modal.pdf\n"
     ]
    }
   ],
   "source": [
    "draw_game_tree(game, modal_policy, fname='mixing_modal.pdf', figure_dir='figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "427b0c65-8089-4393-830a-9d93443278f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game tree saved to file figures/mixing_modal_br.pdf\n"
     ]
    }
   ],
   "source": [
    "draw_game_tree(game, modal_policy, modal_retval.br_policies, fname='mixing_modal_br.pdf', figure_dir='figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7d9ea70b-dfff-4c4a-905b-f90295600d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_and_policy = make_env_and_policy(game, dict(final_checkpoint.equilibrium_solver_run.config))\n",
    "# for agent in env_and_policy.agents:\n",
    "#     agent.policy = policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5500c911-421a-4993-b02b-bedd93b3dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BRAgent:\n",
    "\n",
    "    def __init__(self, i, policy):\n",
    "        self.player_id = i\n",
    "        self.policy = policy\n",
    "\n",
    "    def step(self, time_step, is_evaluation=False):\n",
    "        if isinstance(time_step, list):\n",
    "            return [self._act(ts) for ts in time_step]\n",
    "        else:\n",
    "            return self._act(time_step)\n",
    "\n",
    "    def _act(self, time_step):\n",
    "        if time_step.last():\n",
    "            return\n",
    "\n",
    "        state = time_step.observations['state']\n",
    "        # print(time_step)\n",
    "        action_probs = {a: 0.0 for a in time_step.observations['legal_actions'][self.player_id]}\n",
    "        action_probs = {**action_probs, **self.policy.action_probabilities(state)}\n",
    "        # action_probs = defaultdict(float, {a:action_probs[a] for a in action_probs})\n",
    "        action = fast_choice(list(action_probs.keys()), list(action_probs.values())) # TODO: Give rng\n",
    "        probs = np.array(list(action_probs.values())) # TODO: is this indexed right? It's good enough to compute entropies...\n",
    "        # print(probs)\n",
    "        return StepOutput(action=action, probs=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "cece01dd-e7f5-4bae-bf9d-051cbc9ad45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game tree saved to file figures/mixing_modal_br0.pdf\n"
     ]
    }
   ],
   "source": [
    "env_and_policy = make_env_and_policy(game, dict(final_checkpoint.equilibrium_solver_run.config))\n",
    "\n",
    "env_and_policy.agents[0] = BRAgent(0, modal_retval.br_policies[0])\n",
    "env_and_policy.agents[1].policy = policy\n",
    "env_and_policy.agents[1] = ModalAgentDecorator(env_and_policy.agents[1])\n",
    "modal_br_policy_0 = env_and_policy.make_policy()\n",
    "draw_game_tree(game, modal_br_policy_0, fname='mixing_modal_br0.pdf', figure_dir='figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "6a6ad404-5acc-4c2e-b9ea-f8f44b1894e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (804620098.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [217]\u001b[0;36m\u001b[0m\n\u001b[0;31m    modal_br_policy_0._agents[0].\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "modal_br_policy_0._agents[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d2c713-efa9-4d4c-9b58-a7ff960ecfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6584452-1125-4ab7-966a-53da713067b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AuctionParams(opening_prices=[32, 19, 13], licenses=array([1, 1, 1]), license_names=['Ontario', 'Quebec'], activity=[32, 19, 13], num_products=3, increment=0.3, reveal_type_round=-1, skip_single_chance_nodes=True, max_round=10, player_types=defaultdict(<class 'list'>, {0: [{'prob': 0.5, 'bidder': <open_spiel.python.games.clock_auction_bidders.EnumeratedValueBidder object at 0x7f9b511f8640>}, {'prob': 0.5, 'bidder': <open_spiel.python.games.clock_auction_bidders.EnumeratedValueBidder object at 0x7f9b511f8970>}], 1: [{'prob': 0.5, 'bidder': <open_spiel.python.games.clock_auction_bidders.EnumeratedValueBidder object at 0x7f9b511f8c70>}, {'prob': 0.5, 'bidder': <open_spiel.python.games.clock_auction_bidders.EnumeratedValueBidder object at 0x7f9b511f88b0>}]}), all_bids=array([[0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 1]]), bid_to_index={(0, 0, 0): 0, (0, 0, 1): 1, (0, 1, 0): 2, (0, 1, 1): 3, (1, 0, 0): 4, (1, 0, 1): 5, (1, 1, 0): 6, (1, 1, 1): 7}, all_bids_activity=array([ 0, 13, 19, 32, 32, 45, 51, 64]), activity_policy=<ActivityPolicy.ON: 0>, grace_rounds=1, undersell_policy=<UndersellPolicy.UNDERSELL_ALLOWED: 1>, information_policy=<InformationPolicy.SHOW_DEMAND: 0>, tiebreaking_policy=<TiebreakingPolicy.DROP_BY_PLAYER: 0>, agent_memory=10, heuristic_deviations=0, reward_shaping=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.auction_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9599803-de97-4f56-8a8f-fae415302598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  12,  15,  22, 126, 138, 141, 148])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidder = game.auction_params.player_types[0][1]['bidder']\n",
    "bidder.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a9a7f974-df4e-426d-846b-2d7ffdc15b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = game.new_initial_state().child(1).child(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f9d34893-9df9-4f81-8fed-7d1e8afa3db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "br = modal_retval.br_policies[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "44f16c3c-bdfd-462b-8349-2d63fb1383ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br.best_response_action(state.information_state_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f11d1200-d667-4f88-a264-92053f300395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Round: 1\n",
       "  Player 0: regional\n",
       "  Player 1: regional,\n",
       "  0.25),\n",
       " (Round: 1\n",
       "  Player 0: regional\n",
       "  Player 1: regional,\n",
       "  0.25)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br.infosets[state.information_state_string()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "38bb8d5b-1fa0-4bb2-9ac3-7da53482b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = game.new_initial_state().child(1).child(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5c222b65-b121-4bb8-ac8c-1ad1521e791b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21258157399704242"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retval.br_policies[0].q_value(state, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e43ce407-63f2-4f35-ad85-65e7af5df7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1918572017329945"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retval.br_policies[0].q_value(state, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "308e7f8f-66cd-4a45-9145-c62d71b29477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.4"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modal_retval.br_policies[0].q_value(state, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3f06aa1f-7fcd-49f5-9b75-16dc8614c736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.82384615384615"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modal_retval.br_policies[0].q_value(state, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4e3b7634-b77f-43d8-bc93-8f5ab51f6675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.4"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modal_retval.br_policies[0].q_value(state.child(4).child(7), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "494f6735-c22b-4e81-97c7-b1a11b1462db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modal_retval.br_policies[0].best_response_action(state.child(4).child(7).information_state_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ca87344b-8da3-45b4-bb2e-edd6fa9768cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.00020142419021640362, 7: 0.9997985758097836}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.action_probabilities(state.child(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8d7d3e0-96a2-4534-943d-e43a784dbc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 1}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retval.br_policies[0].action_probabilities(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "15a7410d-27ce-4d5e-a6f4-f1e6525ab13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 1}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modal_retval.br_policies[0].action_probabilities(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ece98176-a7fb-4f58-a86b-11a4f3f85b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.        ,  0.        , 28.23021104]),\n",
       " array([1.00000000e-06, 2.32500575e+03, 2.88499425e+03]),\n",
       " 7899,\n",
       " 0.0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy._infostates['p1t0 r2 posted[[32.0, 19.0, 13.0], [32.0, 24.7, 16.9]] sub[[0, 0, 0], [1, 1, 1]] a64 agg[[0, 0, 0], [1, 2, 2]] proc[[0, 0, 0], [1, 1, 1]]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e6665c7d-7671-46d8-ad17-db1820073d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   0.        ,  222.74227128, 1538.08980524]),\n",
       " array([  0.54638362,  17.00922613, 125.44439324]),\n",
       " 3144,\n",
       " 0.0]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy._infostates['p0t1 r3 posted[[32.0, 19.0, 13.0], [41.6, 24.7, 16.9], [54.08, 24.7, 16.9]] sub[[0, 0, 0], [1, 1, 1], [1, 0, 0]] a32 agg[[0, 0, 0], [2, 2, 2], [2, 1, 1]] proc[[0, 0, 0], [1, 1, 1], [1, 0, 0]]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5b2c7aaf-3a56-451e-98b3-7accd70ddfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   0.        ,  222.74227128, 1538.08980524]),\n",
       " array([  0.54638362,  17.00922613, 125.44439324]),\n",
       " 3144,\n",
       " 0.0]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy._infostates['p0t1 r3 posted[[32.0, 19.0, 13.0], [41.6, 24.7, 16.9], [54.08, 24.7, 16.9]] sub[[0, 0, 0], [1, 1, 1], [1, 0, 0]] a32 agg[[0, 0, 0], [2, 2, 2], [2, 1, 1]] proc[[0, 0, 0], [1, 1, 1], [1, 0, 0]]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "72a237dc-3967-4c4b-a7ac-3e0fdae3ada3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0.        ,   0.        , 171.22852131, 213.27940948]),\n",
       " array([4.73341858e-01, 4.16126591e+00, 3.26680556e+03, 3.52055983e+03]),\n",
       " 6860,\n",
       " 0.0]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy._infostates['p1t1 r3 posted[[32.0, 19.0, 13.0], [41.6, 24.7, 16.9], [54.08, 24.7, 16.9]] sub[[0, 0, 0], [1, 1, 1], [1, 1, 1]] a64 agg[[0, 0, 0], [2, 2, 2], [2, 1, 1]] proc[[0, 0, 0], [1, 1, 1], [1, 1, 1]]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6fc5faac-8fdd-4530-ba90-af03ad034a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   0.        , 1742.32433924,    0.        ]),\n",
       " array([ 0.09895434,  0.48343083, 14.41761783]),\n",
       " 1392,\n",
       " 0.0]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy._infostates['p0t1 r4 posted[[32.0, 19.0, 13.0], [41.6, 24.7, 16.9], [54.08, 24.7, 16.9], [54.08, 32.11, 21.97]] sub[[0, 0, 0], [1, 1, 1], [1, 0, 0], [0, 1, 1]] a32 agg[[0, 0, 0], [2, 2, 2], [2, 1, 1], [1, 2, 2]] proc[[0, 0, 0], [1, 1, 1], [1, 0, 0], [0, 1, 1]]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7912ef15-11fb-41e0-8d3c-11825bdb2dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.        , 40.36701648, 46.59125201]),\n",
       " array([ 209.16305937, 1575.53174546, 1794.30519817]),\n",
       " 3586,\n",
       " 0.0]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy._infostates['p1t1 r4 posted[[32.0, 19.0, 13.0], [41.6, 24.7, 16.9], [54.08, 24.7, 16.9], [54.08, 32.11, 21.97]] sub[[0, 0, 0], [1, 1, 1], [1, 1, 1], [1, 1, 1]] a64 agg[[0, 0, 0], [2, 2, 2], [2, 1, 1], [1, 2, 2]] proc[[0, 0, 0], [1, 1, 1], [1, 1, 1], [1, 1, 1]]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "978ed75d-68c8-427d-b312-0e6d63c64034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0.        ,   0.        , 254.28033896]),\n",
       " array([1.000000e-06, 1.000000e-06, 1.000001e+00]),\n",
       " 710,\n",
       " 0.0]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy._infostates['p0t1 r5 posted[[32.0, 19.0, 13.0], [41.6, 24.7, 16.9], [54.08, 24.7, 16.9], [54.08, 32.11, 21.97], [54.08, 41.74, 28.56]] sub[[0, 0, 0], [1, 1, 1], [1, 0, 0], [0, 1, 1], [0, 1, 1]] a32 agg[[0, 0, 0], [2, 2, 2], [2, 1, 1], [1, 2, 2], [1, 2, 2]] proc[[0, 0, 0], [1, 1, 1], [1, 0, 0], [0, 1, 1], [0, 1, 1]]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e590d8f7-2562-4ed6-83f0-e4a961be637f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([3.76600428, 1.67259365, 0.        ]),\n",
       " array([1194.87219609,  540.12780591,   17.000001  ]),\n",
       " 1753,\n",
       " 0.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy._infostates['p1t1 r5 posted[[32.0, 19.0, 13.0], [41.6, 24.7, 16.9], [54.08, 24.7, 16.9], [54.08, 32.11, 21.97], [54.08, 41.74, 28.56]] sub[[0, 0, 0], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]] a64 agg[[0, 0, 0], [2, 2, 2], [2, 1, 1], [1, 2, 2], [1, 2, 2]] proc[[0, 0, 0], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]]']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9ebdbf-06a3-412e-9fb1-3961d7e68478",
   "metadata": {},
   "source": [
    "# Nov 16: check last-iterate policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c69e5be-987f-49a1-8e24-e0c0f9cb564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'oct4_encumberedheuristic_oct4_encumberedheuristic_3_base_undersell_allowed-cfr_port_7_extexternal_plus_full-101'\n",
    "run = EquilibriumSolverRun.objects.get(name=name, experiment__name='oct13_external_heuristics_v1')\n",
    "game, final_checkpoint, policy = get_results(run, load_policy=True)\n",
    "evaluation = final_checkpoint.get_modal_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "131abeaa-ec17-46cf-a706-e3d3c5fbbd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.864280386727655e-10, 3: 0.9728701375001918, 7: 0.027129862313380014}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.0, 3: 0.9788815339915834, 7: 0.02111846600841658}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from open_spiel.python.algorithms.mccfr import REGRET_INDEX, MCCFRSolverBase\n",
    "\n",
    "class CFRLastIteratePolicyWrapper(object):\n",
    "    def __init__(self, policy, player_id):\n",
    "        self.policy = policy\n",
    "        self.player_id = player_id\n",
    "        \n",
    "    def action_probabilities(self, state, player_id=None):\n",
    "        if player_id is None:\n",
    "            player_id = state.current_player()\n",
    "        legal_actions = state.legal_actions()\n",
    "        info_state_key = state.information_state_string(player_id)\n",
    "        retrieved_infostate = self.policy._infostates.get(info_state_key, None)\n",
    "        if retrieved_infostate is None:\n",
    "            return {a: 1 / len(legal_actions) for a in legal_actions}\n",
    "        else:\n",
    "            regrets = retrieved_infostate[REGRET_INDEX]\n",
    "            action_probs = MCCFRSolverBase._regret_matching(None, regrets, len(legal_actions))\n",
    "            return {a: action_probs[i] for i, a in enumerate(legal_actions)}\n",
    "            \n",
    "# test it\n",
    "env_and_policy = make_env_and_policy(game, dict(final_checkpoint.equilibrium_solver_run.config))\n",
    "for agent in env_and_policy.agents:\n",
    "    agent.policy = policy\n",
    "    \n",
    "last_iterate_policy = CFRLastIteratePolicyWrapper(env_and_policy.agents[0].policy, 0)\n",
    "state = game.new_initial_state().child(0).child(0)\n",
    "display(policy.action_probabilities(state))\n",
    "display(last_iterate_policy.action_probabilities(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "274e861f-e474-433d-9ca3-e413ff94c5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_NashConvReturn(nash_conv=20.24767626552017, player_improvements=array([18.6684278 ,  1.57924847]), br_policies=[<open_spiel.python.algorithms.best_response.BestResponsePolicy object at 0x7fb018940850>, <open_spiel.python.algorithms.best_response.BestResponsePolicy object at 0x7fb018530be0>])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = 'oct4_encumberedheuristic_oct4_encumberedheuristic_3_base_undersell_allowed-cfr_port_7_extexternal_plus_full-101'\n",
    "run = EquilibriumSolverRun.objects.get(name=name, experiment__name='oct13_external_heuristics_v1')\n",
    "game, final_checkpoint, policy = get_results(run, load_policy=True)\n",
    "evaluation = final_checkpoint.get_modal_eval()\n",
    "env_and_policy = make_env_and_policy(game, dict(final_checkpoint.equilibrium_solver_run.config))\n",
    "for i, agent in enumerate(env_and_policy.agents):\n",
    "    agent.policy = CFRLastIteratePolicyWrapper(policy, i)\n",
    "\n",
    "for player in range(game.num_players()):\n",
    "    env_and_policy.agents[player] = ModalAgentDecorator(env_and_policy.agents[player])\n",
    "    \n",
    "modal_policy = env_and_policy.make_policy()\n",
    "modal_retval = nash_conv(game, modal_policy, return_only_nash_conv=False, restrict_to_heuristics=True)\n",
    "display(modal_retval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ec1766-5ca4-4140-a17f-00b1c99bf6e0",
   "metadata": {},
   "source": [
    "# Dig into differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b4796ad-dd75-4ab3-b29e-9d52c15d8f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_spiel.python.algorithms.exploitability import _state_values\n",
    "\n",
    "def traverse(state, policy, cfr_policy, br_policies, br_player, follow_br=False, depth=0):\n",
    "    def print_depth(s):\n",
    "        if depth == 0:\n",
    "            prefix = ''\n",
    "        else:\n",
    "            prefix = '--' * (depth-1) + '- '\n",
    "        print(f'{prefix}{s}')\n",
    "        \n",
    "    if state.is_terminal():\n",
    "        player_return = state.returns()[br_player]\n",
    "        print_depth(f'Terminal state: utility = {player_return:.2f}')\n",
    "        return\n",
    "        \n",
    "    # compute values\n",
    "    player_value = _state_values(state, 2, policy)[br_player]\n",
    "    br_value = br_policies[br_player].value(state)\n",
    "    print_depth(f'Values: mode = {player_value:.2f}; BR = {br_value:.2f}')\n",
    "\n",
    "    if state.is_chance_node():\n",
    "        chance_outcomes = state.chance_outcomes()\n",
    "        # print_depth(f'Chance node')\n",
    "        for (action, action_prob) in chance_outcomes:\n",
    "            print_depth(f'Chance action {action} (p={action_prob:.2f}):')\n",
    "            traverse(state.child(action), policy, cfr_policy, br_policies, br_player, follow_br, depth+1)\n",
    "            \n",
    "    else:\n",
    "        player = state.current_player()\n",
    "        action_probs = policy._agents[player].policy.action_probabilities(state)\n",
    "        mode_action = max(action_probs, key=action_probs.get)\n",
    "        infostate_string = state.information_state_string()\n",
    "        regrets, avg_policy, visits, _ = cfr_policy._infostates[infostate_string]\n",
    "        avg_policy_visits = avg_policy.sum().round()\n",
    "        regret_visits = visits - avg_policy_visits\n",
    "        \n",
    "        \n",
    "        if player == br_player:\n",
    "            br_action_probs = br_policies[player].action_probabilities(state)\n",
    "            br_action = max(br_action_probs, key=br_action_probs.get)\n",
    "        \n",
    "            if br_action != mode_action:\n",
    "                print_depth(f'[ BR != mode ({br_action} != {mode_action})')\n",
    "                print_depth(f'[ modal value: {_state_values(state.child(br_action), 2, policy)[br_player]:5.2f}')\n",
    "                print_depth(f'[ CFR stats:')\n",
    "                print_depth(f'[ * regrets: {regrets.round(2)}')\n",
    "                print_depth(f'[ * avg_policy: {avg_policy.round(2)}')\n",
    "                print_depth(f'[ * regret visits: {regret_visits}')\n",
    "                print_depth(f'[ * avg policy visits: {avg_policy_visits}')\n",
    "        \n",
    "        if player == br_player and follow_br:\n",
    "            print_depth(f'P{player} BR action = {br_action} (policy p = {action_probs[br_action]:.2f}; {regret_visits} regret updates; regrets = {regrets.round(2)}):')       \n",
    "            traverse(state.child(br_action), policy, cfr_policy, br_policies, br_player, follow_br, depth+1)\n",
    "            \n",
    "        else:\n",
    "            print_depth(f'P{player} modal action = {mode_action} (p = {action_probs[mode_action]:.2f}; {regret_visits} regret updates; regrets = {regrets.round(2)}):')\n",
    "            traverse(state.child(mode_action), policy, cfr_policy, br_policies, br_player, follow_br, depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "259d1afb-ca82-4d15-89fb-a962e4aa1a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_NashConvReturn(nash_conv=17.431923076923077, player_improvements=array([17.43192308,  0.        ]), br_policies=[<open_spiel.python.algorithms.best_response.BestResponsePolicy object at 0x7f986a47b7f0>, <open_spiel.python.algorithms.best_response.BestResponsePolicy object at 0x7f98658480d0>])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = 'oct4_encumberedheuristic_oct4_encumberedheuristic_3_base_undersell_allowed-cfr_port_7_extexternal_plus_full-101'\n",
    "run = EquilibriumSolverRun.objects.get(name=name, experiment__name='oct13_external_heuristics_v1')\n",
    "game, final_checkpoint, policy = get_results(run, load_policy=True)\n",
    "evaluation = final_checkpoint.get_modal_eval()\n",
    "env_and_policy = make_env_and_policy(game, dict(final_checkpoint.equilibrium_solver_run.config))\n",
    "for player in range(game.num_players()):\n",
    "    env_and_policy.agents[player].policy = policy\n",
    "    env_and_policy.agents[player] = ModalAgentDecorator(env_and_policy.agents[player])\n",
    "    \n",
    "modal_policy = env_and_policy.make_policy()\n",
    "modal_retval = nash_conv(game, modal_policy, return_only_nash_conv=False, restrict_to_heuristics=True)\n",
    "display(modal_retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4dc632f7-cac2-4675-94d4-932a48df21ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: mode = 41.73; BR = 59.16\n",
      "Chance action 0 (p=0.50):\n",
      "- Values: mode = 66.16; BR = 66.16\n",
      "- Chance action 0 (p=0.50):\n",
      "--- Values: mode = 59.92; BR = 59.92\n",
      "--- P0 modal action = 3 (p = 0.97; 5211.0 regret updates; regrets = [  0.   565.46  12.2 ]):\n",
      "----- Values: mode = 59.92; BR = 59.92\n",
      "----- P1 modal action = 7 (p = 1.00; 5244.0 regret updates; regrets = [ 0.   33.68]):\n",
      "------- Values: mode = 59.92; BR = 59.92\n",
      "------- P0 modal action = 3 (p = 1.00; 5173.0 regret updates; regrets = [ 0.   36.55]):\n",
      "--------- Values: mode = 59.92; BR = 59.92\n",
      "--------- P1 modal action = 7 (p = 0.55; 2689.0 regret updates; regrets = [ 0.    0.   28.23]):\n",
      "----------- Values: mode = 59.92; BR = 59.92\n",
      "----------- P0 modal action = 3 (p = 0.99; 1476.0 regret updates; regrets = [ 0.   30.29]):\n",
      "------------- Values: mode = 59.92; BR = 59.92\n",
      "------------- P1 modal action = 4 (p = 1.00; 2689.0 regret updates; regrets = [ 0.   28.76  0.  ]):\n",
      "--------------- Terminal state: utility = 59.92\n",
      "- Chance action 1 (p=0.50):\n",
      "--- Values: mode = 72.40; BR = 72.40\n",
      "--- P0 modal action = 3 (p = 0.97; 5211.0 regret updates; regrets = [  0.   565.46  12.2 ]):\n",
      "----- Values: mode = 72.40; BR = 72.40\n",
      "----- P1 modal action = 7 (p = 0.98; 5207.0 regret updates; regrets = [  0.     0.   380.77]):\n",
      "------- Values: mode = 72.40; BR = 72.40\n",
      "------- P0 modal action = 3 (p = 1.00; 5173.0 regret updates; regrets = [ 0.   36.55]):\n",
      "--------- Values: mode = 72.40; BR = 72.40\n",
      "--------- P1 modal action = 4 (p = 1.00; 2536.0 regret updates; regrets = [ 0.   74.73  0.  ]):\n",
      "----------- Terminal state: utility = 72.40\n",
      "Chance action 1 (p=0.50):\n",
      "- Values: mode = 17.30; BR = 52.17\n",
      "- Chance action 0 (p=0.50):\n",
      "--- Values: mode = 34.60; BR = 34.51\n",
      "--- [ BR != mode (7 != 4)\n",
      "--- [ modal value: 34.32\n",
      "--- [ CFR stats:\n",
      "--- [ * regrets: [  0.   456.54   1.42]\n",
      "--- [ * avg_policy: [8.70000e-01 4.34786e+03 7.38270e+02]\n",
      "--- [ * regret visits: 5240.0\n",
      "--- [ * avg policy visits: 5087.0\n",
      "--- P0 modal action = 4 (p = 0.85; 5240.0 regret updates; regrets = [  0.   456.54   1.42]):\n",
      "----- Values: mode = 34.60; BR = -21.60\n",
      "----- P1 modal action = 7 (p = 1.00; 5244.0 regret updates; regrets = [ 0.   33.68]):\n",
      "------- Values: mode = 34.60; BR = -21.60\n",
      "------- [ BR != mode (3 != 4)\n",
      "------- [ modal value: 33.60\n",
      "------- [ CFR stats:\n",
      "------- [ * regrets: [  0.     0.   372.87]\n",
      "------- [ * avg_policy: [1.44000e+00 2.49100e+01 4.34065e+03]\n",
      "------- [ * regret visits: 5194.0\n",
      "------- [ * avg policy visits: 4367.0\n",
      "------- P0 modal action = 4 (p = 0.99; 5194.0 regret updates; regrets = [  0.     0.   372.87]):\n",
      "--------- Values: mode = 34.60; BR = 34.60\n",
      "--------- P1 modal action = 7 (p = 0.96; 2144.0 regret updates; regrets = [ 0.    0.   63.58]):\n",
      "----------- Values: mode = 34.60; BR = 34.60\n",
      "----------- P0 modal action = 4 (p = 0.99; 5058.0 regret updates; regrets = [  0.    0.  195.4]):\n",
      "------------- Values: mode = 34.60; BR = 34.60\n",
      "------------- P1 modal action = 7 (p = 0.99; 2131.0 regret updates; regrets = [ 0.    0.   60.58]):\n",
      "--------------- Values: mode = 34.60; BR = 34.60\n",
      "--------------- P0 modal action = 4 (p = 0.99; 5000.0 regret updates; regrets = [  0.     0.   141.39]):\n",
      "----------------- Values: mode = 34.60; BR = 34.60\n",
      "----------------- P1 modal action = 7 (p = 0.99; 2118.0 regret updates; regrets = [ 0.    0.   26.36]):\n",
      "------------------- Values: mode = 34.60; BR = 34.60\n",
      "------------------- P0 modal action = 4 (p = 1.00; 4941.0 regret updates; regrets = [ 0.    0.   63.12]):\n",
      "--------------------- Values: mode = 34.60; BR = 34.60\n",
      "--------------------- P1 modal action = 3 (p = 1.00; 2108.0 regret updates; regrets = [0.   8.87 0.  ]):\n",
      "----------------------- Terminal state: utility = 34.60\n",
      "- Chance action 1 (p=0.50):\n",
      "--- Values: mode = 0.00; BR = 69.82\n",
      "--- [ BR != mode (7 != 4)\n",
      "--- [ modal value: -1.06\n",
      "--- [ CFR stats:\n",
      "--- [ * regrets: [  0.   456.54   1.42]\n",
      "--- [ * avg_policy: [8.70000e-01 4.34786e+03 7.38270e+02]\n",
      "--- [ * regret visits: 5240.0\n",
      "--- [ * avg policy visits: 5087.0\n",
      "--- P0 modal action = 4 (p = 0.85; 5240.0 regret updates; regrets = [  0.   456.54   1.42]):\n",
      "----- Values: mode = 0.00; BR = 81.40\n",
      "----- P1 modal action = 7 (p = 0.98; 5207.0 regret updates; regrets = [  0.     0.   380.77]):\n",
      "------- Values: mode = 0.00; BR = 81.40\n",
      "------- [ BR != mode (3 != 4)\n",
      "------- [ modal value: -1.00\n",
      "------- [ CFR stats:\n",
      "------- [ * regrets: [  0.     0.   372.87]\n",
      "------- [ * avg_policy: [1.44000e+00 2.49100e+01 4.34065e+03]\n",
      "------- [ * regret visits: 5194.0\n",
      "------- [ * avg policy visits: 4367.0\n",
      "------- P0 modal action = 4 (p = 0.99; 5194.0 regret updates; regrets = [  0.     0.   372.87]):\n",
      "--------- Values: mode = 0.00; BR = 0.00\n",
      "--------- P1 modal action = 7 (p = 0.99; 2223.0 regret updates; regrets = [  0.     0.     0.   374.07]):\n",
      "----------- Values: mode = 0.00; BR = 0.00\n",
      "----------- P0 modal action = 4 (p = 0.99; 5058.0 regret updates; regrets = [  0.    0.  195.4]):\n",
      "------------- Values: mode = 0.00; BR = 0.00\n",
      "------------- P1 modal action = 7 (p = 0.99; 2209.0 regret updates; regrets = [  0.     0.     0.   318.99]):\n",
      "--------------- Values: mode = 0.00; BR = 0.00\n",
      "--------------- P0 modal action = 4 (p = 0.99; 5000.0 regret updates; regrets = [  0.     0.   141.39]):\n",
      "----------------- Values: mode = 0.00; BR = 0.00\n",
      "----------------- P1 modal action = 7 (p = 0.99; 2198.0 regret updates; regrets = [  0.     0.     0.   242.52]):\n",
      "------------------- Values: mode = 0.00; BR = 0.00\n",
      "------------------- P0 modal action = 4 (p = 1.00; 4941.0 regret updates; regrets = [ 0.    0.   63.12]):\n",
      "--------------------- Values: mode = 0.00; BR = 0.00\n",
      "--------------------- P1 modal action = 7 (p = 0.99; 2188.0 regret updates; regrets = [  0.     0.     0.   222.67]):\n",
      "----------------------- Values: mode = 0.00; BR = 0.00\n",
      "----------------------- P0 modal action = 4 (p = 0.98; 2395.0 regret updates; regrets = [0.   0.   3.78]):\n",
      "------------------------- Values: mode = 0.00; BR = 0.00\n",
      "------------------------- P1 modal action = 7 (p = 1.00; 2178.0 regret updates; regrets = [ 0.    0.    0.   90.74]):\n",
      "--------------------------- Values: mode = 0.00; BR = 0.00\n",
      "--------------------------- P0 modal action = 0 (p = 1.00; 2394.0 regret updates; regrets = [0.]):\n",
      "----------------------------- Values: mode = 0.00; BR = 0.00\n",
      "----------------------------- P1 modal action = 7 (p = 1.00; 2146.0 regret updates; regrets = [ 0.   0.  20.3]):\n",
      "------------------------------- Terminal state: utility = 0.00\n"
     ]
    }
   ],
   "source": [
    "traverse(game.new_initial_state(), modal_policy, modal_policy._agents[0].policy, modal_retval.br_policies, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da53f887-8009-4acc-bc92-2ee8a8ea9df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: mode = 41.73; BR = 59.16\n",
      "Chance action 0 (p=0.50):\n",
      "- Values: mode = 66.16; BR = 66.16\n",
      "- Chance action 0 (p=0.50):\n",
      "--- Values: mode = 59.92; BR = 59.92\n",
      "--- P0 BR action = 3 (policy p = 0.97; 5211.0 regret updates; regrets = [  0.   565.46  12.2 ]):\n",
      "----- Values: mode = 59.92; BR = 59.92\n",
      "----- P1 modal action = 7 (p = 1.00; 5244.0 regret updates; regrets = [ 0.   33.68]):\n",
      "------- Values: mode = 59.92; BR = 59.92\n",
      "------- P0 BR action = 3 (policy p = 1.00; 5173.0 regret updates; regrets = [ 0.   36.55]):\n",
      "--------- Values: mode = 59.92; BR = 59.92\n",
      "--------- P1 modal action = 7 (p = 0.55; 2689.0 regret updates; regrets = [ 0.    0.   28.23]):\n",
      "----------- Values: mode = 59.92; BR = 59.92\n",
      "----------- P0 BR action = 3 (policy p = 0.99; 1476.0 regret updates; regrets = [ 0.   30.29]):\n",
      "------------- Values: mode = 59.92; BR = 59.92\n",
      "------------- P1 modal action = 4 (p = 1.00; 2689.0 regret updates; regrets = [ 0.   28.76  0.  ]):\n",
      "--------------- Terminal state: utility = 59.92\n",
      "- Chance action 1 (p=0.50):\n",
      "--- Values: mode = 72.40; BR = 72.40\n",
      "--- P0 BR action = 3 (policy p = 0.97; 5211.0 regret updates; regrets = [  0.   565.46  12.2 ]):\n",
      "----- Values: mode = 72.40; BR = 72.40\n",
      "----- P1 modal action = 7 (p = 0.98; 5207.0 regret updates; regrets = [  0.     0.   380.77]):\n",
      "------- Values: mode = 72.40; BR = 72.40\n",
      "------- P0 BR action = 3 (policy p = 1.00; 5173.0 regret updates; regrets = [ 0.   36.55]):\n",
      "--------- Values: mode = 72.40; BR = 72.40\n",
      "--------- P1 modal action = 4 (p = 1.00; 2536.0 regret updates; regrets = [ 0.   74.73  0.  ]):\n",
      "----------- Terminal state: utility = 72.40\n",
      "Chance action 1 (p=0.50):\n",
      "- Values: mode = 17.30; BR = 52.17\n",
      "- Chance action 0 (p=0.50):\n",
      "--- Values: mode = 34.60; BR = 34.51\n",
      "--- [ BR != mode (7 != 4)\n",
      "--- [ modal value: 34.32\n",
      "--- [ CFR stats:\n",
      "--- [ * regrets: [  0.   456.54   1.42]\n",
      "--- [ * avg_policy: [8.70000e-01 4.34786e+03 7.38270e+02]\n",
      "--- [ * regret visits: 5240.0\n",
      "--- [ * avg policy visits: 5087.0\n",
      "--- P0 BR action = 7 (policy p = 0.15; 5240.0 regret updates; regrets = [  0.   456.54   1.42]):\n",
      "----- Values: mode = 34.32; BR = 34.51\n",
      "----- P1 modal action = 7 (p = 1.00; 5244.0 regret updates; regrets = [ 0.   33.68]):\n",
      "------- Values: mode = 34.32; BR = 34.51\n",
      "------- [ BR != mode (4 != 7)\n",
      "------- [ modal value: 34.51\n",
      "------- [ CFR stats:\n",
      "------- [ * regrets: [  0.   101.46 380.73]\n",
      "------- [ * avg_policy: [  0.59 147.67 570.74]\n",
      "------- [ * regret visits: 5194.0\n",
      "------- [ * avg policy visits: 719.0\n",
      "------- P0 BR action = 4 (policy p = 0.21; 5194.0 regret updates; regrets = [  0.   101.46 380.73]):\n",
      "--------- Values: mode = 34.51; BR = 34.51\n",
      "--------- P1 modal action = 4 (p = 0.72; 411.0 regret updates; regrets = [ 0.   69.8  23.05]):\n",
      "----------- Values: mode = 34.51; BR = 34.51\n",
      "----------- P0 BR action = 4 (policy p = 0.99; 2190.0 regret updates; regrets = [  0.    0.  103.1]):\n",
      "------------- Values: mode = 34.51; BR = 34.51\n",
      "------------- P1 modal action = 4 (p = 1.00; 75.0 regret updates; regrets = [ 0.   0.  22.1]):\n",
      "--------------- Values: mode = 34.51; BR = 34.51\n",
      "--------------- P0 BR action = 4 (policy p = 1.00; 2185.0 regret updates; regrets = [  0.     0.   213.22]):\n",
      "----------------- Values: mode = 34.51; BR = 34.51\n",
      "----------------- P1 modal action = 4 (p = 0.94; 74.0 regret updates; regrets = [0.   0.   1.86]):\n",
      "------------------- Values: mode = 34.51; BR = 34.51\n",
      "------------------- P0 BR action = 4 (policy p = 1.00; 2060.0 regret updates; regrets = [  0.     0.   115.89]):\n",
      "--------------------- Values: mode = 34.51; BR = 34.51\n",
      "--------------------- P1 modal action = 3 (p = 0.99; 74.0 regret updates; regrets = [0.   4.54 0.  ]):\n",
      "----------------------- Terminal state: utility = 34.51\n",
      "- Chance action 1 (p=0.50):\n",
      "--- Values: mode = 0.00; BR = 69.82\n",
      "--- [ BR != mode (7 != 4)\n",
      "--- [ modal value: -1.06\n",
      "--- [ CFR stats:\n",
      "--- [ * regrets: [  0.   456.54   1.42]\n",
      "--- [ * avg_policy: [8.70000e-01 4.34786e+03 7.38270e+02]\n",
      "--- [ * regret visits: 5240.0\n",
      "--- [ * avg policy visits: 5087.0\n",
      "--- P0 BR action = 7 (policy p = 0.15; 5240.0 regret updates; regrets = [  0.   456.54   1.42]):\n",
      "----- Values: mode = -1.06; BR = 69.82\n",
      "----- P1 modal action = 7 (p = 0.98; 5207.0 regret updates; regrets = [  0.     0.   380.77]):\n",
      "------- Values: mode = -1.06; BR = 69.82\n",
      "------- [ BR != mode (4 != 7)\n",
      "------- [ modal value: -0.10\n",
      "------- [ CFR stats:\n",
      "------- [ * regrets: [  0.   101.46 380.73]\n",
      "------- [ * avg_policy: [  0.59 147.67 570.74]\n",
      "------- [ * regret visits: 5194.0\n",
      "------- [ * avg policy visits: 719.0\n",
      "------- P0 BR action = 4 (policy p = 0.21; 5194.0 regret updates; regrets = [  0.   101.46 380.73]):\n",
      "--------- Values: mode = -0.10; BR = 69.82\n",
      "--------- P1 modal action = 7 (p = 0.90; 447.0 regret updates; regrets = [  0.     4.13 259.45]):\n",
      "----------- Values: mode = -0.10; BR = 69.82\n",
      "----------- [ BR != mode (3 != 4)\n",
      "----------- [ modal value: -1.10\n",
      "----------- [ CFR stats:\n",
      "----------- [ * regrets: [   0.    222.74 1538.09]\n",
      "----------- [ * avg_policy: [  0.55  17.01 125.44]\n",
      "----------- [ * regret visits: 3001.0\n",
      "----------- [ * avg policy visits: 143.0\n",
      "----------- P0 BR action = 3 (policy p = 0.12; 3001.0 regret updates; regrets = [   0.    222.74 1538.09]):\n",
      "------------- Values: mode = -1.10; BR = 69.82\n",
      "------------- P1 modal action = 7 (p = 0.52; 68.0 regret updates; regrets = [  0.     0.   171.23 213.28]):\n",
      "--------------- Values: mode = -1.10; BR = 69.82\n",
      "--------------- [ BR != mode (3 != 4)\n",
      "--------------- [ modal value: 69.82\n",
      "--------------- [ CFR stats:\n",
      "--------------- [ * regrets: [   0.   1742.32    0.  ]\n",
      "--------------- [ * avg_policy: [ 0.1   0.48 14.42]\n",
      "--------------- [ * regret visits: 1377.0\n",
      "--------------- [ * avg policy visits: 15.0\n",
      "--------------- P0 BR action = 3 (policy p = 0.03; 1377.0 regret updates; regrets = [   0.   1742.32    0.  ]):\n",
      "----------------- Values: mode = 69.82; BR = 69.82\n",
      "----------------- P1 modal action = 7 (p = 0.50; 7.0 regret updates; regrets = [ 0.   40.37 46.59]):\n",
      "------------------- Values: mode = 69.82; BR = 69.82\n",
      "------------------- P0 BR action = 4 (policy p = 1.00; 709.0 regret updates; regrets = [  0.     0.   254.28]):\n",
      "--------------------- Values: mode = 69.82; BR = 69.82\n",
      "--------------------- P1 modal action = 0 (p = 0.68; 1.0 regret updates; regrets = [3.77 1.67 0.  ]):\n",
      "----------------------- Terminal state: utility = 69.82\n"
     ]
    }
   ],
   "source": [
    "traverse(game.new_initial_state(), modal_policy, modal_policy._agents[0].policy, modal_retval.br_policies, 0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "758215a6-b9ee-43f0-a722-2cc005e4dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_and_policy = make_env_and_policy(game, dict(final_checkpoint.equilibrium_solver_run.config))\n",
    "for player in range(game.num_players()):\n",
    "    env_and_policy.agents[player].policy = CFRLastIteratePolicyWrapper(policy, player)\n",
    "    env_and_policy.agents[player] = ModalAgentDecorator(env_and_policy.agents[player])\n",
    "    \n",
    "modal_policy = env_and_policy.make_policy()\n",
    "modal_retval = nash_conv(game, modal_policy, return_only_nash_conv=False, restrict_to_heuristics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b6d9fb39-25f1-4e4a-9a87-424ae371a212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: mode = 41.73; BR = 59.16\n",
      "Chance action 0 (p=0.50):\n",
      "- Values: mode = 66.16; BR = 66.16\n",
      "- Chance action 0 (p=0.50):\n",
      "--- Values: mode = 59.92; BR = 59.92\n",
      "--- P0 modal action = 3 (p = 0.98; 5211.0 regret updates; regrets = [  0.   565.46  12.2 ]):\n",
      "----- Values: mode = 59.92; BR = 59.92\n",
      "----- P1 modal action = 7 (p = 1.00; 5244.0 regret updates; regrets = [ 0.   33.68]):\n",
      "------- Values: mode = 59.92; BR = 59.92\n",
      "------- P0 modal action = 3 (p = 1.00; 5173.0 regret updates; regrets = [ 0.   36.55]):\n",
      "--------- Values: mode = 59.92; BR = 59.92\n",
      "--------- P1 modal action = 7 (p = 1.00; 2689.0 regret updates; regrets = [ 0.    0.   28.23]):\n",
      "----------- Values: mode = 59.92; BR = 59.92\n",
      "----------- P0 modal action = 3 (p = 1.00; 1476.0 regret updates; regrets = [ 0.   30.29]):\n",
      "------------- Values: mode = 59.92; BR = 59.92\n",
      "------------- P1 modal action = 4 (p = 1.00; 2689.0 regret updates; regrets = [ 0.   28.76  0.  ]):\n",
      "--------------- Terminal state: utility = 59.92\n",
      "- Chance action 1 (p=0.50):\n",
      "--- Values: mode = 72.40; BR = 72.40\n",
      "--- P0 modal action = 3 (p = 0.98; 5211.0 regret updates; regrets = [  0.   565.46  12.2 ]):\n",
      "----- Values: mode = 72.40; BR = 72.40\n",
      "----- P1 modal action = 7 (p = 1.00; 5207.0 regret updates; regrets = [  0.     0.   380.77]):\n",
      "------- Values: mode = 72.40; BR = 72.40\n",
      "------- P0 modal action = 3 (p = 1.00; 5173.0 regret updates; regrets = [ 0.   36.55]):\n",
      "--------- Values: mode = 72.40; BR = 72.40\n",
      "--------- P1 modal action = 4 (p = 1.00; 2536.0 regret updates; regrets = [ 0.   74.73  0.  ]):\n",
      "----------- Terminal state: utility = 72.40\n",
      "Chance action 1 (p=0.50):\n",
      "- Values: mode = 17.30; BR = 52.17\n",
      "- Chance action 0 (p=0.50):\n",
      "--- Values: mode = 34.60; BR = 34.51\n",
      "--- [ BR != mode (7 != 4)\n",
      "--- [ modal value: 34.32\n",
      "--- [ CFR stats:\n",
      "--- [ * regrets: [  0.   456.54   1.42]\n",
      "--- [ * avg_policy: [8.70000e-01 4.34786e+03 7.38270e+02]\n",
      "--- [ * regret visits: 5240.0\n",
      "--- [ * avg policy visits: 5087.0\n",
      "--- P0 modal action = 4 (p = 1.00; 5240.0 regret updates; regrets = [  0.   456.54   1.42]):\n",
      "----- Values: mode = 34.60; BR = -21.60\n",
      "----- P1 modal action = 7 (p = 1.00; 5244.0 regret updates; regrets = [ 0.   33.68]):\n",
      "------- Values: mode = 34.60; BR = -21.60\n",
      "------- [ BR != mode (3 != 4)\n",
      "------- [ modal value: 33.60\n",
      "------- [ CFR stats:\n",
      "------- [ * regrets: [  0.     0.   372.87]\n",
      "------- [ * avg_policy: [1.44000e+00 2.49100e+01 4.34065e+03]\n",
      "------- [ * regret visits: 5194.0\n",
      "------- [ * avg policy visits: 4367.0\n",
      "------- P0 modal action = 4 (p = 1.00; 5194.0 regret updates; regrets = [  0.     0.   372.87]):\n",
      "--------- Values: mode = 34.60; BR = 34.60\n",
      "--------- P1 modal action = 7 (p = 1.00; 2144.0 regret updates; regrets = [ 0.    0.   63.58]):\n",
      "----------- Values: mode = 34.60; BR = 34.60\n",
      "----------- P0 modal action = 4 (p = 1.00; 5058.0 regret updates; regrets = [  0.    0.  195.4]):\n",
      "------------- Values: mode = 34.60; BR = 34.60\n",
      "------------- P1 modal action = 7 (p = 1.00; 2131.0 regret updates; regrets = [ 0.    0.   60.58]):\n",
      "--------------- Values: mode = 34.60; BR = 34.60\n",
      "--------------- P0 modal action = 4 (p = 1.00; 5000.0 regret updates; regrets = [  0.     0.   141.39]):\n",
      "----------------- Values: mode = 34.60; BR = 34.60\n",
      "----------------- P1 modal action = 7 (p = 1.00; 2118.0 regret updates; regrets = [ 0.    0.   26.36]):\n",
      "------------------- Values: mode = 34.60; BR = 34.60\n",
      "------------------- P0 modal action = 4 (p = 1.00; 4941.0 regret updates; regrets = [ 0.    0.   63.12]):\n",
      "--------------------- Values: mode = 34.60; BR = 34.60\n",
      "--------------------- P1 modal action = 3 (p = 1.00; 2108.0 regret updates; regrets = [0.   8.87 0.  ]):\n",
      "----------------------- Terminal state: utility = 34.60\n",
      "- Chance action 1 (p=0.50):\n",
      "--- Values: mode = 0.00; BR = 69.82\n",
      "--- [ BR != mode (7 != 4)\n",
      "--- [ modal value: -0.28\n",
      "--- [ CFR stats:\n",
      "--- [ * regrets: [  0.   456.54   1.42]\n",
      "--- [ * avg_policy: [8.70000e-01 4.34786e+03 7.38270e+02]\n",
      "--- [ * regret visits: 5240.0\n",
      "--- [ * avg policy visits: 5087.0\n",
      "--- P0 modal action = 4 (p = 1.00; 5240.0 regret updates; regrets = [  0.   456.54   1.42]):\n",
      "----- Values: mode = 0.00; BR = 81.40\n",
      "----- P1 modal action = 7 (p = 1.00; 5207.0 regret updates; regrets = [  0.     0.   380.77]):\n",
      "------- Values: mode = 0.00; BR = 81.40\n",
      "------- [ BR != mode (3 != 4)\n",
      "------- [ modal value: -1.00\n",
      "------- [ CFR stats:\n",
      "------- [ * regrets: [  0.     0.   372.87]\n",
      "------- [ * avg_policy: [1.44000e+00 2.49100e+01 4.34065e+03]\n",
      "------- [ * regret visits: 5194.0\n",
      "------- [ * avg policy visits: 4367.0\n",
      "------- P0 modal action = 4 (p = 1.00; 5194.0 regret updates; regrets = [  0.     0.   372.87]):\n",
      "--------- Values: mode = 0.00; BR = 0.00\n",
      "--------- P1 modal action = 7 (p = 1.00; 2223.0 regret updates; regrets = [  0.     0.     0.   374.07]):\n",
      "----------- Values: mode = 0.00; BR = 0.00\n",
      "----------- P0 modal action = 4 (p = 1.00; 5058.0 regret updates; regrets = [  0.    0.  195.4]):\n",
      "------------- Values: mode = 0.00; BR = 0.00\n",
      "------------- P1 modal action = 7 (p = 1.00; 2209.0 regret updates; regrets = [  0.     0.     0.   318.99]):\n",
      "--------------- Values: mode = 0.00; BR = 0.00\n",
      "--------------- P0 modal action = 4 (p = 1.00; 5000.0 regret updates; regrets = [  0.     0.   141.39]):\n",
      "----------------- Values: mode = 0.00; BR = 0.00\n",
      "----------------- P1 modal action = 7 (p = 1.00; 2198.0 regret updates; regrets = [  0.     0.     0.   242.52]):\n",
      "------------------- Values: mode = 0.00; BR = 0.00\n",
      "------------------- P0 modal action = 4 (p = 1.00; 4941.0 regret updates; regrets = [ 0.    0.   63.12]):\n",
      "--------------------- Values: mode = 0.00; BR = 0.00\n",
      "--------------------- P1 modal action = 7 (p = 1.00; 2188.0 regret updates; regrets = [  0.     0.     0.   222.67]):\n",
      "----------------------- Values: mode = 0.00; BR = 0.00\n",
      "----------------------- P0 modal action = 4 (p = 1.00; 2395.0 regret updates; regrets = [0.   0.   3.78]):\n",
      "------------------------- Values: mode = 0.00; BR = 0.00\n",
      "------------------------- P1 modal action = 7 (p = 1.00; 2178.0 regret updates; regrets = [ 0.    0.    0.   90.74]):\n",
      "--------------------------- Values: mode = 0.00; BR = 0.00\n",
      "--------------------------- P0 modal action = 0 (p = 1.00; 2394.0 regret updates; regrets = [0.]):\n",
      "----------------------------- Values: mode = 0.00; BR = 0.00\n",
      "----------------------------- P1 modal action = 7 (p = 1.00; 2146.0 regret updates; regrets = [ 0.   0.  20.3]):\n",
      "------------------------------- Terminal state: utility = 0.00\n"
     ]
    }
   ],
   "source": [
    "traverse(game.new_initial_state(), modal_policy, modal_policy._agents[0].policy.policy, modal_retval.br_policies, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a9ef3835-3ec2-49e9-848a-46651eb66628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: mode = 41.73; BR = 59.16\n",
      "Chance action 0 (p=0.50):\n",
      "- Values: mode = 66.16; BR = 66.16\n",
      "- Chance action 0 (p=0.50):\n",
      "--- Values: mode = 59.92; BR = 59.92\n",
      "--- P0 BR action = 3 (policy p = 0.98; 5211.0 regret updates; regrets = [  0.   565.46  12.2 ]):\n",
      "----- Values: mode = 59.92; BR = 59.92\n",
      "----- P1 modal action = 7 (p = 1.00; 5244.0 regret updates; regrets = [ 0.   33.68]):\n",
      "------- Values: mode = 59.92; BR = 59.92\n",
      "------- P0 BR action = 3 (policy p = 1.00; 5173.0 regret updates; regrets = [ 0.   36.55]):\n",
      "--------- Values: mode = 59.92; BR = 59.92\n",
      "--------- P1 modal action = 7 (p = 1.00; 2689.0 regret updates; regrets = [ 0.    0.   28.23]):\n",
      "----------- Values: mode = 59.92; BR = 59.92\n",
      "----------- P0 BR action = 3 (policy p = 1.00; 1476.0 regret updates; regrets = [ 0.   30.29]):\n",
      "------------- Values: mode = 59.92; BR = 59.92\n",
      "------------- P1 modal action = 4 (p = 1.00; 2689.0 regret updates; regrets = [ 0.   28.76  0.  ]):\n",
      "--------------- Terminal state: utility = 59.92\n",
      "- Chance action 1 (p=0.50):\n",
      "--- Values: mode = 72.40; BR = 72.40\n",
      "--- P0 BR action = 3 (policy p = 0.98; 5211.0 regret updates; regrets = [  0.   565.46  12.2 ]):\n",
      "----- Values: mode = 72.40; BR = 72.40\n",
      "----- P1 modal action = 7 (p = 1.00; 5207.0 regret updates; regrets = [  0.     0.   380.77]):\n",
      "------- Values: mode = 72.40; BR = 72.40\n",
      "------- P0 BR action = 3 (policy p = 1.00; 5173.0 regret updates; regrets = [ 0.   36.55]):\n",
      "--------- Values: mode = 72.40; BR = 72.40\n",
      "--------- P1 modal action = 4 (p = 1.00; 2536.0 regret updates; regrets = [ 0.   74.73  0.  ]):\n",
      "----------- Terminal state: utility = 72.40\n",
      "Chance action 1 (p=0.50):\n",
      "- Values: mode = 17.30; BR = 52.17\n",
      "- Chance action 0 (p=0.50):\n",
      "--- Values: mode = 34.60; BR = 34.51\n",
      "--- [ BR != mode (7 != 4)\n",
      "--- [ modal value: 34.32\n",
      "--- [ CFR stats:\n",
      "--- [ * regrets: [  0.   456.54   1.42]\n",
      "--- [ * avg_policy: [8.70000e-01 4.34786e+03 7.38270e+02]\n",
      "--- [ * regret visits: 5240.0\n",
      "--- [ * avg policy visits: 5087.0\n",
      "--- P0 BR action = 7 (policy p = 0.00; 5240.0 regret updates; regrets = [  0.   456.54   1.42]):\n",
      "----- Values: mode = 34.32; BR = 34.51\n",
      "----- P1 modal action = 7 (p = 1.00; 5244.0 regret updates; regrets = [ 0.   33.68]):\n",
      "------- Values: mode = 34.32; BR = 34.51\n",
      "------- [ BR != mode (4 != 7)\n",
      "------- [ modal value: 34.51\n",
      "------- [ CFR stats:\n",
      "------- [ * regrets: [  0.   101.46 380.73]\n",
      "------- [ * avg_policy: [  0.59 147.67 570.74]\n",
      "------- [ * regret visits: 5194.0\n",
      "------- [ * avg policy visits: 719.0\n",
      "------- P0 BR action = 4 (policy p = 0.21; 5194.0 regret updates; regrets = [  0.   101.46 380.73]):\n",
      "--------- Values: mode = 34.51; BR = 34.51\n",
      "--------- P1 modal action = 4 (p = 0.75; 411.0 regret updates; regrets = [ 0.   69.8  23.05]):\n",
      "----------- Values: mode = 34.51; BR = 34.51\n",
      "----------- P0 BR action = 4 (policy p = 1.00; 2190.0 regret updates; regrets = [  0.    0.  103.1]):\n",
      "------------- Values: mode = 34.51; BR = 34.51\n",
      "------------- P1 modal action = 4 (p = 1.00; 75.0 regret updates; regrets = [ 0.   0.  22.1]):\n",
      "--------------- Values: mode = 34.51; BR = 34.51\n",
      "--------------- P0 BR action = 4 (policy p = 1.00; 2185.0 regret updates; regrets = [  0.     0.   213.22]):\n",
      "----------------- Values: mode = 34.51; BR = 34.51\n",
      "----------------- P1 modal action = 4 (p = 1.00; 74.0 regret updates; regrets = [0.   0.   1.86]):\n",
      "------------------- Values: mode = 34.51; BR = 34.51\n",
      "------------------- P0 BR action = 4 (policy p = 1.00; 2060.0 regret updates; regrets = [  0.     0.   115.89]):\n",
      "--------------------- Values: mode = 34.51; BR = 34.51\n",
      "--------------------- P1 modal action = 3 (p = 1.00; 74.0 regret updates; regrets = [0.   4.54 0.  ]):\n",
      "----------------------- Terminal state: utility = 34.51\n",
      "- Chance action 1 (p=0.50):\n",
      "--- Values: mode = 0.00; BR = 69.82\n",
      "--- [ BR != mode (7 != 4)\n",
      "--- [ modal value: -0.28\n",
      "--- [ CFR stats:\n",
      "--- [ * regrets: [  0.   456.54   1.42]\n",
      "--- [ * avg_policy: [8.70000e-01 4.34786e+03 7.38270e+02]\n",
      "--- [ * regret visits: 5240.0\n",
      "--- [ * avg policy visits: 5087.0\n",
      "--- P0 BR action = 7 (policy p = 0.00; 5240.0 regret updates; regrets = [  0.   456.54   1.42]):\n",
      "----- Values: mode = -0.28; BR = 69.82\n",
      "----- P1 modal action = 7 (p = 1.00; 5207.0 regret updates; regrets = [  0.     0.   380.77]):\n",
      "------- Values: mode = -0.28; BR = 69.82\n",
      "------- [ BR != mode (4 != 7)\n",
      "------- [ modal value: -0.10\n",
      "------- [ CFR stats:\n",
      "------- [ * regrets: [  0.   101.46 380.73]\n",
      "------- [ * avg_policy: [  0.59 147.67 570.74]\n",
      "------- [ * regret visits: 5194.0\n",
      "------- [ * avg policy visits: 719.0\n",
      "------- P0 BR action = 4 (policy p = 0.21; 5194.0 regret updates; regrets = [  0.   101.46 380.73]):\n",
      "--------- Values: mode = -0.10; BR = 69.82\n",
      "--------- P1 modal action = 7 (p = 0.98; 447.0 regret updates; regrets = [  0.     4.13 259.45]):\n",
      "----------- Values: mode = -0.10; BR = 69.82\n",
      "----------- [ BR != mode (3 != 4)\n",
      "----------- [ modal value: 69.82\n",
      "----------- [ CFR stats:\n",
      "----------- [ * regrets: [   0.    222.74 1538.09]\n",
      "----------- [ * avg_policy: [  0.55  17.01 125.44]\n",
      "----------- [ * regret visits: 3001.0\n",
      "----------- [ * avg policy visits: 143.0\n",
      "----------- P0 BR action = 3 (policy p = 0.13; 3001.0 regret updates; regrets = [   0.    222.74 1538.09]):\n",
      "------------- Values: mode = 69.82; BR = 69.82\n",
      "------------- P1 modal action = 7 (p = 0.55; 68.0 regret updates; regrets = [  0.     0.   171.23 213.28]):\n",
      "--------------- Values: mode = 69.82; BR = 69.82\n",
      "--------------- P0 BR action = 3 (policy p = 1.00; 1377.0 regret updates; regrets = [   0.   1742.32    0.  ]):\n",
      "----------------- Values: mode = 69.82; BR = 69.82\n",
      "----------------- P1 modal action = 7 (p = 0.54; 7.0 regret updates; regrets = [ 0.   40.37 46.59]):\n",
      "------------------- Values: mode = 69.82; BR = 69.82\n",
      "------------------- P0 BR action = 4 (policy p = 1.00; 709.0 regret updates; regrets = [  0.     0.   254.28]):\n",
      "--------------------- Values: mode = 69.82; BR = 69.82\n",
      "--------------------- P1 modal action = 0 (p = 0.69; 1.0 regret updates; regrets = [3.77 1.67 0.  ]):\n",
      "----------------------- Terminal state: utility = 69.82\n"
     ]
    }
   ],
   "source": [
    "traverse(game.new_initial_state(), modal_policy, modal_policy._agents[0].policy.policy, modal_retval.br_policies, 0, follow_br=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d52c6224-3e1e-4a60-8434-abb9ccdeca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [1, 1, 7, 7, 4, 7, 3, 7, 3, 7, 4]\n",
    "state = game.new_initial_state()\n",
    "for a in actions:\n",
    "    state = state.child(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f39a567-b0ca-434f-8384-8db4ffa6dedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1700.       ,     0.       ,  -432.6883076])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_sor_profits = state.bidders[1].bidder.get_profits(state.sor_prices[-1])\n",
    "sor_profits = np.array([all_sor_profits[a] for a in state.legal_actions()])\n",
    "# Rescale sor_profits to be in -1 0\n",
    "normalized_sor_profits = (sor_profits - sor_profits.min()) / (sor_profits.max() - sor_profits.min()) - 1 if sor_profits.max() != sor_profits.min() else np.zeros_like(sor_profits)\n",
    "display(normalized_sor_profits * 1700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29f8ae62-6630-44d9-bad3-fd8b3b24cc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 7]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.legal_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "98e3dcf3-a076-4633-a266-fb1229a06efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0fd2ba93-3a29-4459-b7ff-3fa5f6a895cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [-0.09615384615384615, 0.0, -1.0],\n",
       "             1: [0.0, -0.02498265093684937]})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state._sor_bid_profits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0fcdff8c-c43f-4b61-9c38-f71a7983c258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09615385,  0.        , -1.        ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(state._sor_bid_profits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433a5e09-d157-487d-a735-f4ae71840489",
   "metadata": {},
   "outputs": [],
   "source": [
    "sor_profits = bidder.bidder.get_profits(self.sor_prices[-1])\n",
    "# Rescale sor_profits to be in 0 1\n",
    "normalized_sor_profits = (sor_profits - sor_profits.min()) / (sor_profits.max() - sor_profits.min()) - 1 if sor_profits.max() != sor_profits.min() else np.zeros_like(sor_profits)\n",
    "self._sor_bid_profits[self._cur_player].append(1 - normalized_sor_profits[action])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2abcbcd-f375-45ef-9453-efd7f89127f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20493"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.55 * 0.54 * 0.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "566128e9-a466-405e-805d-dfb8b853270f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'players': [{'type': [{'name': 'local',\n",
       "     'prob': 0.5,\n",
       "     'value': [0, 45, 58, 114, 0, 45, 58, 114],\n",
       "     'budget': 114,\n",
       "     'value_format': 'full'},\n",
       "    {'name': 'regional',\n",
       "     'prob': 0.5,\n",
       "     'value': [0, 12, 15, 22, 126, 138, 141, 148],\n",
       "     'budget': 148,\n",
       "     'value_format': 'full'}]},\n",
       "  {'type': [{'name': 'regional',\n",
       "     'prob': 0.5,\n",
       "     'value': [0, 16, 21, 43, 87, 104, 109, 130],\n",
       "     'budget': 130,\n",
       "     'value_format': 'full'},\n",
       "    {'name': 'regional',\n",
       "     'prob': 0.5,\n",
       "     'value': [0, 15, 20, 38, 181, 197, 201, 219],\n",
       "     'budget': 219,\n",
       "     'value_format': 'full'}]}],\n",
       " 'activity': [32, 19, 13],\n",
       " 'licenses': [1, 1, 1],\n",
       " 'increment': 0.3,\n",
       " 'max_rounds': 10,\n",
       " 'agent_memory': 10,\n",
       " 'license_names': ['Ontario', 'Quebec'],\n",
       " 'opening_price': [32, 19, 13],\n",
       " 'heuristic_only': True,\n",
       " 'fold_randomness': True,\n",
       " 'undersell_policy': 'UNDERSELL_ALLOWED'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.game.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558854a-53d7-4a0e-a54a-58ccbe2361d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
