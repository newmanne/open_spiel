{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pyspiel\n",
    "import open_spiel.python.examples.ubc_utils\n",
    "from open_spiel.python.visualizations import ubc_treeviz\n",
    "from open_spiel.python.examples.ubc_utils import *\n",
    "from auctions.webutils import *\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)\n",
    "import os\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "from open_spiel.python.examples.ubc_cma import *\n",
    "from open_spiel.python.examples.ubc_decorators import TakeSingleActionDecorator, TremblingAgentDecorator, ModalAgentDecorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "DoesNotExist",
     "evalue": "EquilibriumSolverRun matching query does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDoesNotExist\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mEquilibriumSolverRun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjun24_jun24_4_undersell_allowed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m game, checkpoint, policy \u001b[38;5;241m=\u001b[39m get_results(run)\n\u001b[1;32m      4\u001b[0m c \u001b[38;5;241m=\u001b[39m checkpoint\u001b[38;5;241m.\u001b[39mequilibrium_solver_run\u001b[38;5;241m.\u001b[39mconfig\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/django/db/models/manager.py:85\u001b[0m, in \u001b[0;36mBaseManager._get_queryset_methods.<locals>.create_method.<locals>.manager_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmanager_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_queryset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/venv/lib/python3.8/site-packages/django/db/models/query.py:439\u001b[0m, in \u001b[0;36mQuerySet.get\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\u001b[38;5;241m.\u001b[39m_result_cache[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m num:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mDoesNotExist(\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m matching query does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_meta\u001b[38;5;241m.\u001b[39mobject_name\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mMultipleObjectsReturned(\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget() returned more than one \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m -- it returned \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_meta\u001b[38;5;241m.\u001b[39mobject_name,\n\u001b[1;32m    446\u001b[0m         num \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m limit \u001b[38;5;129;01mor\u001b[39;00m num \u001b[38;5;241m<\u001b[39m limit \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmore than \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (limit \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    447\u001b[0m     )\n\u001b[1;32m    448\u001b[0m )\n",
      "\u001b[0;31mDoesNotExist\u001b[0m: EquilibriumSolverRun matching query does not exist."
     ]
    }
   ],
   "source": [
    "run = EquilibriumSolverRun.objects.get(name='jun24_jun24_4_undersell_allowed')\n",
    "game, checkpoint, policy = get_results(run)\n",
    "\n",
    "c = checkpoint.equilibrium_solver_run.config\n",
    "cfr = c.get('solver_type') == 'cfr'\n",
    "\n",
    "env_and_policy = ppo_db_checkpoint_loader(checkpoint, cfr=cfr)\n",
    "for player in range(game.num_players()):\n",
    "    env_and_policy.agents[player] = ModalAgentDecorator(env_and_policy.agents[player])\n",
    "policy = env_and_policy.make_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_spiel.python.algorithms.outcome_sampling_mccfr import OutcomeSamplingSolver\n",
    "\n",
    "game = pyspiel.load_game('python_clock_auction', dict(filename='parameters.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = OutcomeSamplingSolver(game, regret_init='straightforward_clock', regret_init_strength=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p0t0 r1 posted[[100, 100]] sub[[0, 0]] a200 agg[[0, 0]] proc[[0, 0]]': [array([-37.79978426, -37.29978426, -37.29978426,  38.79986186]),\n",
       "  array([1.499999e-06, 2.500010e-01, 2.500010e-01, 5.000005e-01])],\n",
       " 'p1t0 r1 posted[[100, 100]] sub[[0, 0]] a200 agg[[0, 0]] proc[[0, 0]]': [array([7.33334333e-01, 1.00000100e+00, 1.00000000e-06, 2.66667667e-01]),\n",
       "  array([3.69438212e-01, 5.03778834e-01, 1.50377733e-06, 1.34342125e-01])],\n",
       " 'p0t0 r2 posted[[100.0, 110.0]] sub[[1, 1]] a200 agg[[1, 2]] proc[[1, 1]]': [array([-75.59964513, -75.38911881, -74.81017144,  76.59979833]),\n",
       "  array([2.14859883e-06, 2.41812428e-01, 9.06790695e-01, 1.14860097e+00])],\n",
       " 'p1t0 r2 posted[[100.0, 110.0]] sub[[0, 1]] a100 agg[[1, 2]] proc[[0, 1]]': [array([7.91367906e-01, 1.00000100e+00, 1.00000000e-06]),\n",
       "  array([5.12536573e-01, 6.47659417e-01, 1.64765777e-06])],\n",
       " 'p0t0 r3 posted[[100.0, 121.0]] sub[[1, 1]] a200 agg[[1, 2]] proc[[1, 1]]': [array([-150.8487931 , -151.19944245,  152.19974685, -150.5500918 ]),\n",
       "  array([8.27890888e-01, 3.36101258e-06, 2.36101594e+00, 1.53312841e+00])],\n",
       " 'p1t0 r3 posted[[100.0, 121.0]] sub[[0, 1]] a100 agg[[1, 2]] proc[[0, 1]]': [array([8.66825271e-01, 1.00000100e+00, 1.00000000e-06]),\n",
       "  array([6.03577754e-01, 6.96308984e-01, 1.69630729e-06])]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(solver._infostates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Responses + NashConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<open_spiel.python.rl_agent_policy.JointRLAgentPolicy at 0x7faf643df040>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 1.0}\n",
      "{0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 1.0}\n",
      "{0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 1.0, 7: 0.0, 8: 0.0, 9: 0.0}\n",
      "{0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 1.0, 9: 0.0}\n",
      "{0: 0.0, 1: 0.0, 2: 0.0, 5: 0.0, 6: 1.0}\n"
     ]
    }
   ],
   "source": [
    "state = game.new_initial_state().child(0).child(0)\n",
    "\n",
    "print(policy.action_probabilities(state))\n",
    "print(policy.action_probabilities(state.child(9)))\n",
    "print(policy.action_probabilities(state.child(9).child(9)))\n",
    "print(policy.action_probabilities(state.child(9).child(9).child(6)))\n",
    "print(policy.action_probabilities(state.child(9).child(9).child(6).child(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing best-responder...\n",
      "Computing best reponse...\n",
      "110.2971\n",
      "Initializing best-responder...\n",
      "Computing best reponse...\n",
      "214.127\n"
     ]
    }
   ],
   "source": [
    "from open_spiel.python.algorithms.best_response import BestResponsePolicy\n",
    "for player_num in range(game.num_players()):\n",
    "    print(\"Initializing best-responder...\")\n",
    "    br = BestResponsePolicy(game, player_num, policy)\n",
    "    print(\"Computing best reponse...\")\n",
    "    print(br.value(game.new_initial_state()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.963800000000006"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from open_spiel.python.algorithms.exploitability import nash_conv\n",
    "nash_conv(game, policy, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External Sampling CFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = EquilibriumSolverRun.objects.get(name='jun9_jun9_0_base-cfr_outcomemccfr_outcome-101')\n",
    "game, checkpoint, policy = get_results(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_spiel.python.algorithms.external_sampling_mccfr import ExternalSamplingSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = ExternalSamplingSolver(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                            | 0/1000 [00:00<?, ?it/s] 31%|█████████████████████████████████████████████████▌                                                                                                                | 306/1000 [03:28<07:53,  1.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/apps/open_spiel/notebooks/greg/2023-06-15-nash_conv_cfr_performance.ipynb Cell 12\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcfrgpu22/apps/open_spiel/notebooks/greg/2023-06-15-nash_conv_cfr_performance.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m)):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcfrgpu22/apps/open_spiel/notebooks/greg/2023-06-15-nash_conv_cfr_performance.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     solver\u001b[39m.\u001b[39;49miteration()\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/external_sampling_mccfr.py:65\u001b[0m, in \u001b[0;36mExternalSamplingSolver.iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39m\"\"\"Performs one iteration of external sampling.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[39mAn iteration consists of one episode for each player as the update\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39mplayer.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mfor\u001b[39;00m player \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_players):\n\u001b[0;32m---> 65\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_regrets(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_game\u001b[39m.\u001b[39;49mnew_initial_state(), player)\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_average_type \u001b[39m==\u001b[39m AverageType\u001b[39m.\u001b[39mFULL:\n\u001b[1;32m     67\u001b[0m   reach_probs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_players, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/external_sampling_mccfr.py:130\u001b[0m, in \u001b[0;36mExternalSamplingSolver._update_regrets\u001b[0;34m(self, state, player)\u001b[0m\n\u001b[1;32m    128\u001b[0m   outcome \u001b[39m=\u001b[39m fast_choice(outcomes, probs)\n\u001b[1;32m    129\u001b[0m   \u001b[39m# outcome = np.random.choice(outcomes, p=probs)\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_regrets(state\u001b[39m.\u001b[39;49mchild(outcome), player)\n\u001b[1;32m    132\u001b[0m cur_player \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mcurrent_player()\n\u001b[1;32m    133\u001b[0m info_state_key \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39minformation_state_string(cur_player)\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/external_sampling_mccfr.py:130\u001b[0m, in \u001b[0;36mExternalSamplingSolver._update_regrets\u001b[0;34m(self, state, player)\u001b[0m\n\u001b[1;32m    128\u001b[0m   outcome \u001b[39m=\u001b[39m fast_choice(outcomes, probs)\n\u001b[1;32m    129\u001b[0m   \u001b[39m# outcome = np.random.choice(outcomes, p=probs)\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_regrets(state\u001b[39m.\u001b[39;49mchild(outcome), player)\n\u001b[1;32m    132\u001b[0m cur_player \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mcurrent_player()\n\u001b[1;32m    133\u001b[0m info_state_key \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39minformation_state_string(cur_player)\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/external_sampling_mccfr.py:153\u001b[0m, in \u001b[0;36mExternalSamplingSolver._update_regrets\u001b[0;34m(self, state, player)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m   \u001b[39m# Walk over all actions at my node\u001b[39;00m\n\u001b[1;32m    152\u001b[0m   \u001b[39mfor\u001b[39;00m action_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_legal_actions):\n\u001b[0;32m--> 153\u001b[0m     child_values[action_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_regrets(\n\u001b[1;32m    154\u001b[0m         state\u001b[39m.\u001b[39;49mchild(legal_actions[action_idx]), player)\n\u001b[1;32m    155\u001b[0m     value \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m policy[action_idx] \u001b[39m*\u001b[39m child_values[action_idx]\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m cur_player \u001b[39m==\u001b[39m player:\n\u001b[1;32m    158\u001b[0m   \u001b[39m# Update regrets.\u001b[39;00m\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/external_sampling_mccfr.py:148\u001b[0m, in \u001b[0;36mExternalSamplingSolver._update_regrets\u001b[0;34m(self, state, player)\u001b[0m\n\u001b[1;32m    146\u001b[0m   action_idx \u001b[39m=\u001b[39m fast_choice(np\u001b[39m.\u001b[39marange(num_legal_actions), policy)\n\u001b[1;32m    147\u001b[0m   \u001b[39m# action_idx = np.random.choice(np.arange(num_legal_actions), p=policy)\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m   value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_regrets(\n\u001b[1;32m    149\u001b[0m       state\u001b[39m.\u001b[39;49mchild(legal_actions[action_idx]), player)\n\u001b[1;32m    150\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m   \u001b[39m# Walk over all actions at my node\u001b[39;00m\n\u001b[1;32m    152\u001b[0m   \u001b[39mfor\u001b[39;00m action_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_legal_actions):\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/external_sampling_mccfr.py:153\u001b[0m, in \u001b[0;36mExternalSamplingSolver._update_regrets\u001b[0;34m(self, state, player)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m   \u001b[39m# Walk over all actions at my node\u001b[39;00m\n\u001b[1;32m    152\u001b[0m   \u001b[39mfor\u001b[39;00m action_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_legal_actions):\n\u001b[0;32m--> 153\u001b[0m     child_values[action_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_regrets(\n\u001b[1;32m    154\u001b[0m         state\u001b[39m.\u001b[39;49mchild(legal_actions[action_idx]), player)\n\u001b[1;32m    155\u001b[0m     value \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m policy[action_idx] \u001b[39m*\u001b[39m child_values[action_idx]\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m cur_player \u001b[39m==\u001b[39m player:\n\u001b[1;32m    158\u001b[0m   \u001b[39m# Update regrets.\u001b[39;00m\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/external_sampling_mccfr.py:148\u001b[0m, in \u001b[0;36mExternalSamplingSolver._update_regrets\u001b[0;34m(self, state, player)\u001b[0m\n\u001b[1;32m    146\u001b[0m   action_idx \u001b[39m=\u001b[39m fast_choice(np\u001b[39m.\u001b[39marange(num_legal_actions), policy)\n\u001b[1;32m    147\u001b[0m   \u001b[39m# action_idx = np.random.choice(np.arange(num_legal_actions), p=policy)\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m   value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_regrets(\n\u001b[1;32m    149\u001b[0m       state\u001b[39m.\u001b[39;49mchild(legal_actions[action_idx]), player)\n\u001b[1;32m    150\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m   \u001b[39m# Walk over all actions at my node\u001b[39;00m\n\u001b[1;32m    152\u001b[0m   \u001b[39mfor\u001b[39;00m action_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_legal_actions):\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/external_sampling_mccfr.py:160\u001b[0m, in \u001b[0;36mExternalSamplingSolver._update_regrets\u001b[0;34m(self, state, player)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m cur_player \u001b[39m==\u001b[39m player:\n\u001b[1;32m    158\u001b[0m   \u001b[39m# Update regrets.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m   \u001b[39mfor\u001b[39;00m action_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_legal_actions):\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_regret(info_state_key, action_idx,\n\u001b[1;32m    161\u001b[0m                      child_values[action_idx] \u001b[39m-\u001b[39m value)\n\u001b[1;32m    162\u001b[0m \u001b[39m# Simple average does averaging on the opponent node. To do this in a game\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m# with more than two players, we only update the player + 1 mod num_players,\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39m# which reduces to the standard rule in 2 players.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_average_type \u001b[39m==\u001b[39m AverageType\u001b[39m.\u001b[39mSIMPLE \u001b[39mand\u001b[39;00m cur_player \u001b[39m==\u001b[39m (\n\u001b[1;32m    166\u001b[0m     player \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_players:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    solver.iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.08"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 * 3600 * 12 / 1e6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
