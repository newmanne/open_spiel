{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "import scipy.stats\n",
    "import time\n",
    "\n",
    "from open_spiel.python.algorithms.exploitability import nash_conv, best_response\n",
    "from open_spiel.python.examples.ubc_plotting_utils import *\n",
    "from open_spiel.python.examples.ubc_utils import *\n",
    "import open_spiel.python.examples.ubc_dispatch as dispatch\n",
    "\n",
    "from auctions.webutils import *\n",
    "\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "\n",
    "from open_spiel.python.examples.ubc_cma import *\n",
    "\n",
    "from open_spiel.python.games.clock_auction_base import InformationPolicy, ActivityPolicy, UndersellPolicy, TiebreakingPolicy\n",
    "from open_spiel.python.algorithms.exploitability import nash_conv, best_response\n",
    "from open_spiel.python.examples.ubc_decorators import TakeSingleActionDecorator, TremblingAgentDecorator, ModalAgentDecorator\n",
    "\n",
    "plt.style.use('https://raw.githubusercontent.com/gregdeon/plots/main/style.mplstyle')\n",
    "plt.matplotlib.rcParams['figure.dpi'] = 300\n",
    "plt.matplotlib.rcParams['font.size'] = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 runs\n"
     ]
    }
   ],
   "source": [
    "# Load our runs from the \"interesting\" game\n",
    "experiments = [\n",
    "    # 'jan20_story'\n",
    "    'jan20_boring'\n",
    "]\n",
    "\n",
    "runs = []\n",
    "for experiment in experiments:\n",
    "    runs += Experiment.objects.get(name=experiment).equilibriumsolverrun_set.all()\n",
    "print(f\"Found {len(runs)} runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████████████████████████████▉                                                                                                                           | 28/100 [40:57<4:14:58, 212.47s/it]"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "for run in tqdm(runs):    \n",
    "    game = run.game.load_as_spiel()\n",
    "    record = {\n",
    "        'run_name': run.name,\n",
    "        'game_name': run.game.name, \n",
    "        'seed': run.config.get('seed'), \n",
    "        'config': run.get_config_name(),\n",
    "        'alg': get_algorithm_from_run(run),\n",
    "    }\n",
    "    \n",
    "    record.update(get_game_info(game, run.game))  \n",
    "    \n",
    "    record['no_error'] = False\n",
    "    records.append(record) # Put it here so you see the False's in the display\n",
    "        \n",
    "    try:\n",
    "        game, final_checkpoint, policy = get_results(run, load_policy=record['rho'] > 0)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping run {run.name} because of error {e}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # # TODO: In general, remvoe this if\n",
    "        # if not (record['rho'] > 0 and record['config'] == 'cfr_port_10_extexternal_plus_linear' and record['n_types'] == 4):\n",
    "        #     continue\n",
    "        \n",
    "        record['t'] = final_checkpoint.t\n",
    "        record['walltime'] = run.walltime(),\n",
    "        evaluation = final_checkpoint.get_modal_eval()\n",
    "        \n",
    "        record['nash_conv'] = evaluation.nash_conv\n",
    "        record['rewards'] = evaluation.mean_rewards\n",
    "        record['nash_conv_frac'] = evaluation.nash_conv / sum(evaluation.mean_rewards) if not pd.isnull(evaluation.nash_conv) else np.nan\n",
    "        record['heuristic_conv'] = evaluation.heuristic_conv\n",
    "        record['heuristic_conv_frac'] = evaluation.heuristic_conv / sum(evaluation.mean_rewards) if not pd.isnull(evaluation.heuristic_conv) else np.nan\n",
    "\n",
    "        for i in range(game.num_players()):\n",
    "            record[f'rewards_{i}'] = evaluation.mean_rewards[i]\n",
    "            record[f'nc_player_improvements_{i}'] = evaluation.nash_conv_player_improvements[i] if not pd.isnull(evaluation.nash_conv) else np.nan\n",
    "            record[f'nc_player_improvements_frac_{i}'] = (evaluation.nash_conv_player_improvements[i] / evaluation.mean_rewards[i]) if not pd.isnull(evaluation.nash_conv) else np.nan\n",
    "\n",
    "            record[f'hc_player_improvements_{i}'] = evaluation.heuristic_conv_player_improvements[i] if not pd.isnull(evaluation.heuristic_conv) else np.nan\n",
    "            record[f'hc_player_improvements_frac_{i}'] = (evaluation.heuristic_conv_player_improvements[i] / evaluation.mean_rewards[i]) if not pd.isnull(evaluation.heuristic_conv) else np.nan\n",
    "\n",
    "        record.update(**analyze_samples(evaluation.samples, game))\n",
    "\n",
    "        nc = record['nash_conv']\n",
    "        hc = record['heuristic_conv']\n",
    "        # print(f\"NashConv = {(np.nan if pd.isnull(nc) else nc):.2f}; HeuristicConv = {(np.nan if pd.isnull(hc) else hc):.2f}\")\n",
    "        \n",
    "        \n",
    "        ### Parse the straightforward story for the game\n",
    "        straightforward_eval = final_checkpoint.get_straightforward_eval()\n",
    "        straightforward_metrics = analyze_samples(straightforward_eval.samples, game)\n",
    "        record.update({f'straightforward_{k}' : v for k, v in straightforward_metrics.items()})\n",
    "        ### End\n",
    "        \n",
    "        # This is slow. Do you really need to do it for both the rho=0 and rho=1 versions of the game? That's a 2X speedup(!)\n",
    "        if record['rho'] == 0:\n",
    "            record['straightforward_nash_conv'] = get_straightforward_nash_conv(game)       \n",
    "        else:\n",
    "            record['straightforward_nash_conv'] = None\n",
    "           \n",
    "        # Commenting out for mem reasons\n",
    "        if record['rho'] > 0 and record['config'] == 'cfr_port_10_extexternal_plus_linear' and record['n_types'] == 4:\n",
    "            # What happens in the rho = 0 game?\n",
    "            record['rho_0_nash_conv'] = get_modal_nash_conv_new_rho(run.game.load_as_spiel(), policy, dict(final_checkpoint.equilibrium_solver_run.config), rho=0)\n",
    "        \n",
    "        record['no_error'] = True\n",
    "    except Exception as e:\n",
    "        print(f\"Something wrong with {run}. Skipping. {e}\")\n",
    "        # raise e\n",
    "        # break\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "print(len(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50.000000\n",
       "mean      0.004131\n",
       "std       0.016519\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       0.000000\n",
       "max       0.068857\n",
       "Name: rho_0_nash_conv, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\n",
    "    \"\"\" rho > 0 and config == 'cfr_port_10_extexternal_plus_linear' and n_types == 4\n",
    "    \"\"\"\n",
    ")['rho_0_nash_conv'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value_structure  rule       base_game_name  deviations  no_error\n",
       "quasi_linear     base       jan19_0_base    1000        False       20\n",
       "                            jan19_10_base   1000        False       20\n",
       "                            jan19_11_base   1000        False       20\n",
       "                            jan19_12_base   1000        False       20\n",
       "                            jan19_13_base   1000        False       20\n",
       "                            jan19_14_base   1000        False       20\n",
       "                            jan19_15_base   1000        False       15\n",
       "                                                        True         5\n",
       "                            jan19_16_base   1000        False       15\n",
       "                                                        True         5\n",
       "                            jan19_17_base   1000        False       15\n",
       "                                                        True         5\n",
       "                            jan19_18_base   1000        False       15\n",
       "                                                        True         5\n",
       "                            jan19_19_base   1000        False       15\n",
       "                                                        True         5\n",
       "                            jan19_1_base    1000        False       20\n",
       "                            jan19_2_base    1000        False       20\n",
       "                            jan19_3_base    1000        False       20\n",
       "                            jan19_4_base    1000        False       20\n",
       "                            jan19_5_base    1000        False       20\n",
       "                            jan19_6_base    1000        False       20\n",
       "                            jan19_7_base    1000        False       20\n",
       "                            jan19_8_base    1000        False       20\n",
       "                            jan19_9_base    1000        False       20\n",
       "                 tie_break  jan19_0_base    1000        False       20\n",
       "                            jan19_10_base   1000        False       20\n",
       "                            jan19_11_base   1000        False       20\n",
       "                            jan19_12_base   1000        False       20\n",
       "                            jan19_13_base   1000        False       20\n",
       "                            jan19_14_base   1000        False       20\n",
       "                            jan19_15_base   1000        False       15\n",
       "                                                        True         5\n",
       "                            jan19_16_base   1000        False       15\n",
       "                                                        True         5\n",
       "                            jan19_17_base   1000        False       15\n",
       "                                                        True         5\n",
       "                            jan19_18_base   1000        False       15\n",
       "                                                        True         5\n",
       "                            jan19_19_base   1000        False       15\n",
       "                                                        True         5\n",
       "                            jan19_1_base    1000        False       20\n",
       "                            jan19_2_base    1000        False       20\n",
       "                            jan19_3_base    1000        False       20\n",
       "                            jan19_4_base    1000        False       20\n",
       "                            jan19_5_base    1000        False       20\n",
       "                            jan19_6_base    1000        False       20\n",
       "                            jan19_7_base    1000        False       20\n",
       "                            jan19_8_base    1000        False       20\n",
       "                            jan19_9_base    1000        False       20\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(records)\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df[['value_structure', 'rule', 'base_game_name', 'deviations', 'no_error']].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('cached_results_jan19.csv', index=False)\n",
    "df = pd.read_csv('cached_results_jan19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean      14.316057\n",
       "std        3.868249\n",
       "min        6.335326\n",
       "25%       12.607385\n",
       "50%       14.109617\n",
       "75%       17.505699\n",
       "max       20.023663\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4t = df.query('n_types == 4 and rho == 1 and config == \"cfr_port_10_extexternal_plus_linear\"')\n",
    "pd.concat((df4t['rewards_0'], df4t['rewards_1'])).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['straightforward_nash_conv'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nash_conv'].plot(kind='hist')\n",
    "print(df['nash_conv'].isnull().sum())\n",
    "\n",
    "df.query('nash_conv.isnull()')[['value_structure', 'rule', 'base_game_name', 'deviations', 'no_error']].value_counts().sort_index()\n",
    "# Huh???? Why are 0 deviation games showing as null. Is that for real?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = dict()\n",
    "colors = ['red', 'blue', 'magenta', 'green', 'orange', 'brown', 'black', 'navy', 'pink', 'gold', 'darkgreen', 'orangered', 'olive']\n",
    "# for i, v in enumerate(df['variant'].unique()):\n",
    "#     palette[v] = colors[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to a) Remove \"bad\" entries b) Be careful about comparisons that are missing datapoints \n",
    "df_plt = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove bad entries\n",
    "\n",
    "good_thresh = 0.1\n",
    "df_plt = df.query(f'hc_player_improvements_frac_0 < {good_thresh} and hc_player_improvements_frac_1 < {good_thresh}').copy()\n",
    "# df_plt = df.query(f'nash_conv_frac < {good_thresh}')\n",
    "len(df), len(df_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1) Get max/min for each valuation/treatment pairing over each stat\n",
    "\n",
    "# First query down to relevant datapoints. Then groupby rule change and SATS =(game_name) and max/min?\n",
    "metrics = ['total_revenue', 'total_welfare', 'auction_lengths', 'num_lotteries', 'p_lottery', 'exposure_frac']\n",
    "for i in range(2): # TODO:\n",
    "    metrics += [f'p{i}_utility', f'p{i}_payment']\n",
    "\n",
    "\n",
    "df_plt_indexed = df_plt.set_index(['value_structure', 'rule', 'deviations']).sort_index().copy()\n",
    "\n",
    "def make_data_dict(df):\n",
    "    data = dict()\n",
    "    for metric in metrics:\n",
    "        data[f'max_{metric}'] = df.groupby('base_game_name')[metric].max()\n",
    "        data[f'min_{metric}'] = df.groupby('base_game_name')[metric].min()\n",
    "    return pd.DataFrame(data)\n",
    "    \n",
    "for idx, grp_df in df_plt.groupby(['value_structure', 'rule', 'deviations']):\n",
    "    if idx[1] == 'base':\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        data_grp_df = make_data_dict(grp_df)\n",
    "        normalizer_grp_df = df_plt_indexed.loc[(idx[0], 'base')]\n",
    "        data_normalized_df = make_data_dict(normalizer_grp_df)\n",
    "\n",
    "        cmap_norm = plt.matplotlib.colors.TwoSlopeNorm(vmin=0.9, vcenter=1, vmax=1.1)\n",
    "        cmap = plt.cm.get_cmap('RdBu').copy()\n",
    "        cmap.set_bad('magenta')\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        data = (data_grp_df / data_normalized_df).values.T\n",
    "        plt.imshow(data, cmap=cmap, norm=cmap_norm)\n",
    "        plt.title(idx)\n",
    "        plt.yticks(range(len(data_grp_df.columns)), data_grp_df.columns)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(idx, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['rho'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['config'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plt = df.query('rho == 0 and n_types == 1 and config == \"cfr_port_10_extexternal_plus_linear\"')\n",
    "print(len(df_plt))\n",
    "\n",
    "# for metric_name in ['straightforward_auction_lengths', 'straightforward_num_lotteries', 'straightforward_unsold_licenses', 'straightforward_total_revenue', 'straightforward_total_welfare']:\n",
    "for metric_name in ['auction_lengths', 'num_lotteries', 'unsold_licenses', 'total_revenue', 'total_welfare']:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    sns.swarmplot(data=df_plt, x='base_game_name', y=metric_name, hue='tiebreaking_policy', dodge=True, size=4)\n",
    "    # plt.gca(); plt.legend([], [], frameon=False)\n",
    "    plt.title(metric_name)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_types  tiebreaking_policy\n",
       "1        DROP_BY_LICENSE       0.000000\n",
       "         DROP_BY_PLAYER        0.000000\n",
       "4        DROP_BY_PLAYER        0.136661\n",
       "3        DROP_BY_PLAYER        0.343663\n",
       "2        DROP_BY_PLAYER        0.668527\n",
       "3        DROP_BY_LICENSE       1.230711\n",
       "4        DROP_BY_LICENSE       1.837529\n",
       "2        DROP_BY_LICENSE       2.032346\n",
       "Name: straightforward_nash_conv, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### When is nash conv especially high if you just bid straightforwardly?\n",
    "\n",
    "# df.query('rho == 0 and config == \"cfr_port_10_extexternal_plus_linear\"').groupby(['n_types', 'tiebreaking_policy'])['straightforward_nash_conv'].max().sort_values()\n",
    "df.query('rho == 0 and config == \"cfr_port_10_extexternal_plus_linear\"').groupby(['n_types', 'tiebreaking_policy'])['straightforward_nash_conv'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nash_conv'] # Would need to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plt['nash_conv'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # What is the graphical straightforward story?\n",
    "\n",
    "\n",
    "# straightforward_df = df.query('rho == 0 and config == \"cfr_port_10_extexternal_plus_linear\" and seed == 100')\n",
    "# # Group by num types\n",
    "\n",
    "# g = sns.FacetGrid(straightforward_df, row=\"n_types\", sharex=False)\n",
    "# g.map_dataframe(sns.scatterplot, x='straightforward_total_welfare', y='straightforward_total_revenue', hue='tiebreaking_policy', style='n_types')\n",
    "\n",
    "\n",
    "# # sns.scatterplot(data=straightforward_df, x='straightforward_total_welfare', y='straightforward_total_revenue', hue='tiebreaking_policy', style='n_types')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy_df = df.query('rho == 1 and config == \"cfr_port_10_extexternal_plus_linear\"')\n",
    "# print(len(strategy_df))\n",
    "# # 5 games * 5 seeds * 2 tiebreaks * 4 types\n",
    "\n",
    "# # Group by num types\n",
    "# # Trouble: can't see overlapping\n",
    "\n",
    "# g = sns.FacetGrid(strategy_df, row=\"n_types\", sharex=False)\n",
    "# g.map_dataframe(sns.scatterplot, x='total_welfare', y='total_revenue', hue='tiebreaking_policy', style='tiebreaking_policy')\n",
    "# g.add_legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(df, straightforward=False):\n",
    "    sample_idx = df.groupby('n_types')['base_game_name'].unique()\n",
    "    df['sample_id'] = df.apply(lambda row: sample_idx[row['n_types']].tolist().index(row['base_game_name']), axis=1)\n",
    "    # Group by num types\n",
    "\n",
    "    metrics = ['total_revenue', 'total_welfare', 'auction_lengths', 'num_lotteries']\n",
    "    if straightforward:\n",
    "        metrics = [f'straightforward_{m}' for m in metrics]\n",
    "\n",
    "    # Dropping duplicates reduces visual noise. What I'd prefer to do though is drop any row entirely if it isn't an extremal point of it's sample_id for at least one metric\n",
    "    df = df[\n",
    "        metrics + ['tiebreaking_policy', 'n_types', 'sample_id']\n",
    "    ].round(1).drop_duplicates()\n",
    "\n",
    "\n",
    "    df = df.melt(\n",
    "        id_vars=['n_types', 'sample_id', 'tiebreaking_policy'],\n",
    "        value_vars=metrics,\n",
    "        var_name='metric',\n",
    "    )\n",
    "\n",
    "    sns.catplot(\n",
    "        data=df, kind=\"swarm\",\n",
    "        col=\"n_types\",\n",
    "        row='metric',\n",
    "        x=\"sample_id\", y=\"value\", hue=\"tiebreaking_policy\", \n",
    "        aspect=.5,\n",
    "        sharey='row'\n",
    "    )\n",
    "\n",
    "make_plots(df.query('rho == 0 and config == \"cfr_port_10_extexternal_plus_linear\" and n_types > 1').copy(), straightforward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(df.query('rho == 1 and config == \"cfr_port_10_extexternal_plus_linear\"').copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(df.query('rho == 1 and config == \"cfr_port_10_extexternal_plus_linear_no_trem\"').copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('jan19_story_with_rho0_ncs_where_relevant_but_missing_other_stuff.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
