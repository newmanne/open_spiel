{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  const JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from open_spiel.python.algorithms.exploitability import nash_conv\n",
    "from open_spiel.python.examples.ubc_decorators import ModalAgentDecorator\n",
    "from open_spiel.python.examples.ubc_plotting_utils import *\n",
    "from open_spiel.python.examples.ubc_utils import *\n",
    "\n",
    "from auctions.webutils import *\n",
    "\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "\n",
    "from open_spiel.python.examples.ubc_cma import *\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 runs\n"
     ]
    }
   ],
   "source": [
    "# load runs from experiments\n",
    "experiments = [\n",
    "    'jan19_story'\n",
    "]\n",
    "\n",
    "runs = []\n",
    "for experiment in experiments:\n",
    "    runs += Experiment.objects.get(name=experiment).equilibriumsolverrun_set.all()\n",
    "print(f\"Found {len(runs)} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_spiel.python.rl_agent import AbstractAgent, StepOutput\n",
    "class StupidAgent(AbstractAgent):\n",
    "\n",
    "    def __init__(self, player_id, game):\n",
    "        self.player_id = player_id\n",
    "        self.num_actions = game.num_distinct_actions()\n",
    "\n",
    "    def step(self, time_step, is_evaluation=False):\n",
    "        if isinstance(time_step, list):\n",
    "            return [self._act(ts) for ts in time_step]\n",
    "        else:\n",
    "            return self._act(time_step)\n",
    "\n",
    "    def _act(self, time_step):\n",
    "        if time_step.last():\n",
    "            return\n",
    "\n",
    "        state = time_step.observations[\"state\"]\n",
    "        profits = state.bidders[self.player_id].bidder.get_profits(state.sor_prices[-1])\n",
    "        legal_actions = time_step.observations[\"legal_actions\"][self.player_id]\n",
    "        legal_profits = [profits[i] for i in legal_actions]\n",
    "        \n",
    "        print('Hi I am a stupid agent')\n",
    "        print(legal_profits)\n",
    "        \n",
    "        action = legal_actions[np.argmin(legal_profits)]\n",
    "\n",
    "        probs = np.zeros(self.num_actions)\n",
    "        probs[action] = 1.0\n",
    "        return StepOutput(action=action, probs=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Belongs in script\n",
    "\n",
    "from open_spiel.python.examples.straightforward_agent import StraightforwardAgent\n",
    "from open_spiel.python.examples.ubc_decorators import TakeSingleActionDecorator\n",
    "\n",
    "def get_nash_conv(game, policy):\n",
    "    worked, time_taken, retval = time_bounded_run(300, nash_conv, game, policy, return_only_nash_conv=False, restrict_to_heuristics=False)\n",
    "    if worked:\n",
    "        return retval\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_straightforward_nash_conv(game):\n",
    "    env_and_policy = make_env_and_policy(game, dict())\n",
    "    for player in range(game.num_players()):\n",
    "        env_and_policy.agents[player] = TakeSingleActionDecorator(StraightforwardAgent(player, game), game.num_distinct_actions())\n",
    "    straightforward_policy = env_and_policy.make_policy()\n",
    "    return get_nash_conv(game, straightforward_policy)\n",
    "    \n",
    "def get_stupid_nash_conv(game):\n",
    "    env_and_policy = make_env_and_policy(game, dict())\n",
    "    for player in range(game.num_players()):\n",
    "        env_and_policy.agents[player] =     (player, game)\n",
    "    straightforward_policy = env_and_policy.make_policy()\n",
    "    return get_nash_conv(game, straightforward_policy)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 1.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_and_policy = make_env_and_policy(game, dict())\n",
    "for player in range(game.num_players()):\n",
    "    env_and_policy.agents[player] = TakeSingleActionDecorator(StupidAgent(player, game), game.num_distinct_actions())\n",
    "straightforward_policy = env_and_policy.make_policy()\n",
    "straightforward_policy.action_probabilities(game.new_initial_state().child(0).child(0))#.child(3).child(3).child(3).child(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(observations={'info_state': [array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.        , 0.25      , 0.5       , 0.75      , 1.        ,\n",
       "       0.        , 0.25      , 0.5       , 0.75      , 1.        ,\n",
       "       0.        , 0.175     , 0.35      , 0.525     , 0.7       ,\n",
       "       0.3       , 0.475     , 0.65      , 0.825     , 1.        ,\n",
       "       0.        , 0.10447761, 0.35820895, 0.6119403 , 0.6865672 ,\n",
       "       0.17910448, 0.5671642 , 0.6567164 , 0.73134327, 0.80597013,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.10447761, 0.20895523, 0.31343284, 0.41791046,\n",
       "       0.17910448, 0.2835821 , 0.3880597 , 0.49253732, 0.5970149 ],\n",
       "      dtype=float32), array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.        , 0.25      , 0.5       , 0.75      , 1.        ,\n",
       "       0.        , 0.25      , 0.5       , 0.75      , 1.        ,\n",
       "       0.        , 0.175     , 0.35      , 0.525     , 0.7       ,\n",
       "       0.3       , 0.475     , 0.65      , 0.825     , 1.        ,\n",
       "       0.        , 0.10447761, 0.3283582 , 0.6865672 , 0.7761194 ,\n",
       "       0.19402985, 0.58208954, 0.74626863, 0.8507463 , 0.9402985 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.10447761, 0.20895523, 0.31343284, 0.41791046,\n",
       "       0.17910448, 0.2835821 , 0.3880597 , 0.49253732, 0.5970149 ],\n",
       "      dtype=float32)], 'legal_actions': [[3], []], 'current_player': 0, 'serialized_state': [], 'info_dict': [{'my_activity': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'sor_exposure': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), 'amount': array([[0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 1.  , 1.  , 1.  , 1.  ],\n",
       "       [0.  , 0.25, 0.5 , 0.75, 1.  , 0.  , 0.25, 0.5 , 0.75, 1.  ]],\n",
       "      dtype=float32), 'activity': array([0.   , 0.175, 0.35 , 0.525, 0.7  , 0.3  , 0.475, 0.65 , 0.825,\n",
       "       1.   ], dtype=float32), 'values': array([0.        , 0.10447761, 0.35820895, 0.6119403 , 0.6865672 ,\n",
       "       0.17910448, 0.5671642 , 0.6567164 , 0.73134327, 0.80597013],\n",
       "      dtype=float32), 'prev_processed': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), 'prev_demanded': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), 'submitted_demand_history': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32), 'processed_demand_history': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32), 'agg_demand_history': array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), 'sor_bundle_prices_history': array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.10447761, 0.20895523, 0.31343284, 0.41791046,\n",
       "        0.17910448, 0.2835821 , 0.3880597 , 0.49253732, 0.5970149 ]],\n",
       "      dtype=float32)}, {'my_activity': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'sor_exposure': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), 'amount': array([[0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 1.  , 1.  , 1.  , 1.  ],\n",
       "       [0.  , 0.25, 0.5 , 0.75, 1.  , 0.  , 0.25, 0.5 , 0.75, 1.  ]],\n",
       "      dtype=float32), 'activity': array([0.   , 0.175, 0.35 , 0.525, 0.7  , 0.3  , 0.475, 0.65 , 0.825,\n",
       "       1.   ], dtype=float32), 'values': array([0.        , 0.10447761, 0.3283582 , 0.6865672 , 0.7761194 ,\n",
       "       0.19402985, 0.58208954, 0.74626863, 0.8507463 , 0.9402985 ],\n",
       "      dtype=float32), 'prev_processed': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), 'prev_demanded': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), 'submitted_demand_history': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32), 'processed_demand_history': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32), 'agg_demand_history': array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), 'sor_bundle_prices_history': array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.10447761, 0.20895523, 0.31343284, 0.41791046,\n",
       "        0.17910448, 0.2835821 , 0.3880597 , 0.49253732, 0.5970149 ]],\n",
       "      dtype=float32)}]}, rewards=[0.0, 0.0], discounts=[1.0, 1.0], step_type=<StepType.MID: 1>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_and_policy.env.envs[0].reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 0.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'info_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m run \u001b[38;5;241m=\u001b[39m runs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m game \u001b[38;5;241m=\u001b[39m run\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mload_as_spiel()\n\u001b[0;32m----> 3\u001b[0m nc \u001b[38;5;241m=\u001b[39m \u001b[43mget_stupid_nash_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mget_stupid_nash_conv\u001b[0;34m(game)\u001b[0m\n\u001b[1;32m     23\u001b[0m     env_and_policy\u001b[38;5;241m.\u001b[39magents[player] \u001b[38;5;241m=\u001b[39m StupidAgent(player, game)\n\u001b[1;32m     24\u001b[0m straightforward_policy \u001b[38;5;241m=\u001b[39m env_and_policy\u001b[38;5;241m.\u001b[39mmake_policy()\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_nash_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstraightforward_policy\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mget_nash_conv\u001b[0;34m(game, policy)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_nash_conv\u001b[39m(game, policy):\n\u001b[0;32m----> 7\u001b[0m     worked, time_taken, retval \u001b[38;5;241m=\u001b[39m \u001b[43mtime_bounded_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnash_conv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_only_nash_conv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestrict_to_heuristics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m worked:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/examples/ubc_utils.py:254\u001b[0m, in \u001b[0;36mtime_bounded_run\u001b[0;34m(t, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m     signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGALRM, signal_handler)\n\u001b[1;32m    253\u001b[0m     signal\u001b[38;5;241m.\u001b[39malarm(t)\n\u001b[0;32m--> 254\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time, result\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SignalTimeout \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/exploitability.py:186\u001b[0m, in \u001b[0;36mnash_conv\u001b[0;34m(game, policy, return_only_nash_conv, use_cpp_br, restrict_to_heuristics)\u001b[0m\n\u001b[1;32m    180\u001b[0m   best_response_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m    181\u001b[0m       pyspiel_best_response\u001b[38;5;241m.\u001b[39mCPPBestResponsePolicy(\n\u001b[1;32m    182\u001b[0m           game, best_responder, policy)\u001b[38;5;241m.\u001b[39mvalue(root_state)\n\u001b[1;32m    183\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m best_responder \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(game\u001b[38;5;241m.\u001b[39mnum_players())\n\u001b[1;32m    184\u001b[0m   ])\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m   best_responders \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    187\u001b[0m     pyspiel_best_response\u001b[38;5;241m.\u001b[39mBestResponsePolicy(\n\u001b[1;32m    188\u001b[0m           game, best_responder, policy, restrict_to_heuristics\u001b[38;5;241m=\u001b[39mrestrict_to_heuristics)\n\u001b[1;32m    189\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m best_responder \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(game\u001b[38;5;241m.\u001b[39mnum_players())\n\u001b[1;32m    190\u001b[0m   ]\n\u001b[1;32m    191\u001b[0m   best_response_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m    192\u001b[0m       best_responder\u001b[38;5;241m.\u001b[39mvalue(root_state) \u001b[38;5;28;01mfor\u001b[39;00m best_responder \u001b[38;5;129;01min\u001b[39;00m best_responders\n\u001b[1;32m    193\u001b[0m   ])\n\u001b[1;32m    194\u001b[0m on_policy_values \u001b[38;5;241m=\u001b[39m _state_values(root_state, game\u001b[38;5;241m.\u001b[39mnum_players(), policy)\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/exploitability.py:187\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    180\u001b[0m   best_response_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m    181\u001b[0m       pyspiel_best_response\u001b[38;5;241m.\u001b[39mCPPBestResponsePolicy(\n\u001b[1;32m    182\u001b[0m           game, best_responder, policy)\u001b[38;5;241m.\u001b[39mvalue(root_state)\n\u001b[1;32m    183\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m best_responder \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(game\u001b[38;5;241m.\u001b[39mnum_players())\n\u001b[1;32m    184\u001b[0m   ])\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m   best_responders \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 187\u001b[0m     \u001b[43mpyspiel_best_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBestResponsePolicy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m          \u001b[49m\u001b[43mgame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_responder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestrict_to_heuristics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestrict_to_heuristics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m best_responder \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(game\u001b[38;5;241m.\u001b[39mnum_players())\n\u001b[1;32m    190\u001b[0m   ]\n\u001b[1;32m    191\u001b[0m   best_response_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m    192\u001b[0m       best_responder\u001b[38;5;241m.\u001b[39mvalue(root_state) \u001b[38;5;28;01mfor\u001b[39;00m best_responder \u001b[38;5;129;01min\u001b[39;00m best_responders\n\u001b[1;32m    193\u001b[0m   ])\n\u001b[1;32m    194\u001b[0m on_policy_values \u001b[38;5;241m=\u001b[39m _state_values(root_state, game\u001b[38;5;241m.\u001b[39mnum_players(), policy)\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/best_response.py:115\u001b[0m, in \u001b[0;36mBestResponsePolicy.__init__\u001b[0;34m(self, game, player_id, policy, root_state, cut_threshold, restrict_to_heuristics)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m root_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m   root_state \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mnew_initial_state()\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfosets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo_sets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cut_threshold \u001b[38;5;241m=\u001b[39m cut_threshold\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/best_response.py:123\u001b[0m, in \u001b[0;36mBestResponsePolicy.info_sets\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m\"\"\"Returns a dict of infostatekey to list of (state, cf_probability).\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m infosets \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_nodes(state):\n\u001b[1;32m    124\u001b[0m   infosets[s\u001b[38;5;241m.\u001b[39minformation_state_string(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_player_id)]\u001b[38;5;241m.\u001b[39mappend((s, p))\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(infosets)\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/best_response.py:135\u001b[0m, in \u001b[0;36mBestResponsePolicy.decision_nodes\u001b[0;34m(self, parent_state)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action, p_action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransitions(parent_state):\n\u001b[1;32m    134\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m p_action \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m state, p_state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_nodes(\n\u001b[1;32m    136\u001b[0m         openspiel_policy\u001b[38;5;241m.\u001b[39mchild(parent_state, action)):\n\u001b[1;32m    137\u001b[0m       \u001b[38;5;28;01myield\u001b[39;00m (state, p_state \u001b[38;5;241m*\u001b[39m p_action)\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/best_response.py:135\u001b[0m, in \u001b[0;36mBestResponsePolicy.decision_nodes\u001b[0;34m(self, parent_state)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action, p_action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransitions(parent_state):\n\u001b[1;32m    134\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m p_action \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m state, p_state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_nodes(\n\u001b[1;32m    136\u001b[0m         openspiel_policy\u001b[38;5;241m.\u001b[39mchild(parent_state, action)):\n\u001b[1;32m    137\u001b[0m       \u001b[38;5;28;01myield\u001b[39;00m (state, p_state \u001b[38;5;241m*\u001b[39m p_action)\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/best_response.py:135\u001b[0m, in \u001b[0;36mBestResponsePolicy.decision_nodes\u001b[0;34m(self, parent_state)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action, p_action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransitions(parent_state):\n\u001b[1;32m    134\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m p_action \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m state, p_state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_nodes(\n\u001b[1;32m    136\u001b[0m         openspiel_policy\u001b[38;5;241m.\u001b[39mchild(parent_state, action)):\n\u001b[1;32m    137\u001b[0m       \u001b[38;5;28;01myield\u001b[39;00m (state, p_state \u001b[38;5;241m*\u001b[39m p_action)\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/best_response.py:133\u001b[0m, in \u001b[0;36mBestResponsePolicy.decision_nodes\u001b[0;34m(self, parent_state)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (parent_state\u001b[38;5;241m.\u001b[39mcurrent_player() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_player_id \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     parent_state\u001b[38;5;241m.\u001b[39mis_simultaneous_node()):\n\u001b[1;32m    132\u001b[0m   \u001b[38;5;28;01myield\u001b[39;00m (parent_state, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action, p_action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent_state\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    134\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m p_action \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m state, p_state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_nodes(\n\u001b[1;32m    136\u001b[0m         openspiel_policy\u001b[38;5;241m.\u001b[39mchild(parent_state, action)):\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/algorithms/best_response.py:173\u001b[0m, in \u001b[0;36mBestResponsePolicy.transitions\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoint_action_probabilities_counterfactual(state)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_policy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems())\n",
      "File \u001b[0;32m/apps/open_spiel/open_spiel/python/rl_agent_policy.py:80\u001b[0m, in \u001b[0;36mJointRLAgentPolicy.action_probabilities\u001b[0;34m(self, state, player_id)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegal_actions\u001b[39m\u001b[38;5;124m\"\u001b[39m][player_id] \u001b[38;5;241m=\u001b[39m legal_actions\n\u001b[1;32m     78\u001b[0m info_state \u001b[38;5;241m=\u001b[39m rl_environment\u001b[38;5;241m.\u001b[39mTimeStep(observations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs, rewards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, discounts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, step_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 80\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agents\u001b[49m\u001b[43m[\u001b[49m\u001b[43mplayer_id\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_evaluation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mprobs\n\u001b[1;32m     81\u001b[0m prob_dict \u001b[38;5;241m=\u001b[39m {action: p[i] \u001b[38;5;28;01mfor\u001b[39;00m i, action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(legal_actions)}\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prob_dict\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mStupidAgent.step\u001b[0;34m(self, time_step, is_evaluation)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_act(ts) \u001b[38;5;28;01mfor\u001b[39;00m ts \u001b[38;5;129;01min\u001b[39;00m time_step]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_act\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mStupidAgent._act\u001b[0;34m(self, time_step)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     18\u001b[0m legal_actions \u001b[38;5;241m=\u001b[39m time_step\u001b[38;5;241m.\u001b[39mobservations[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegal_actions\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplayer_id]\n\u001b[0;32m---> 19\u001b[0m info_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtime_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minfo_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplayer_id]\n\u001b[1;32m     20\u001b[0m profits \u001b[38;5;241m=\u001b[39m info_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msor_bundle_prices_history\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m] \n\u001b[1;32m     21\u001b[0m legal_profits \u001b[38;5;241m=\u001b[39m [profits[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m legal_actions]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'info_dict'"
     ]
    }
   ],
   "source": [
    "run = runs[0]\n",
    "game = run.game.load_as_spiel()\n",
    "nc = get_stupid_nash_conv(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = game.new_initial_state().child(0).child(0)#.child(3).child(3).child(3).child(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = StupidAgent(0, game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m            StupidAgent\n",
      "\u001b[0;31mString form:\u001b[0m     <__main__.StupidAgent object at 0x7f26e22ae2e0>\n",
      "\u001b[0;31mDocstring:\u001b[0m       <no docstring>\n",
      "\u001b[0;31mClass docstring:\u001b[0m Abstract base class for Open Spiel RL agents.\n",
      "\u001b[0;31mInit docstring:\u001b[0m \n",
      "Initializes agent.\n",
      "\n",
      "Args:\n",
      "  player_id: integer, mandatory. Corresponds to the player position in the\n",
      "    game and is used to index the observation list.\n",
      "  session: optional Tensorflow session.\n",
      "  observation_spec: optional dict containing observation specifications.\n",
      "  name: string. Must be used to scope TF variables. Defaults to `agent`.\n",
      "  **agent_specific_kwargs: optional extra args.\n"
     ]
    }
   ],
   "source": [
    "agent??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "iss = state.information_state_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = nc.br_policies[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc.br_policies[1].value(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mbr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m Returns a dict of infostatekey to list of (state, cf_probability).\n",
      "\u001b[0;31mFile:\u001b[0m      /apps/open_spiel/open_spiel/python/algorithms/best_response.py\n",
      "\u001b[0;31mType:\u001b[0m      method\n"
     ]
    }
   ],
   "source": [
    "br.info_sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_and_policy = make_env_and_policy(game, dict())\n",
    "for player in range(game.num_players()):\n",
    "    env_and_policy.agents[player] = TakeSingleActionDecorator(StupidAgent(player, game), game.num_distinct_actions())\n",
    "straightforward_policy = env_and_policy.make_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m      \u001b[0mstraightforward_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mType:\u001b[0m           JointRLAgentPolicy\n",
      "\u001b[0;31mString form:\u001b[0m    <open_spiel.python.rl_agent_policy.JointRLAgentPolicy object at 0x7f265ec44d30>\n",
      "\u001b[0;31mFile:\u001b[0m           /apps/open_spiel/open_spiel/python/rl_agent_policy.py\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Joint policy denoted by the RL agents of a game.\n",
      "\n",
      "Given a list of RL agents of players for a game, this class can be used derive\n",
      "the corresponding (joint) policy. In particular, the distribution over\n",
      "possible actions will be those that are returned by the step() method of\n",
      "the RL agents given the state.\n",
      "\u001b[0;31mInit docstring:\u001b[0m\n",
      "Initializes the joint RL agent policy.\n",
      "\n",
      "Args:\n",
      "  game: The game.\n",
      "  agents: Dictionary of agents keyed by the player IDs.\n",
      "  use_observation: If true then observation tensor will be used as the\n",
      "    `info_state` in the step() calls; otherwise, information state tensor\n",
      "    will be used. See `use_observation` property of\n",
      "    rl_environment.Environment.\n",
      "\u001b[0;31mCall docstring:\u001b[0m\n",
      "Turns the policy into a callable.\n",
      "\n",
      "Args:\n",
      "  state: The current state of the game.\n",
      "  player_id: Optional, the player id for whom we want an action. Optional\n",
      "    unless this is a simultaneous state at which multiple players can act.\n",
      "\n",
      "Returns:\n",
      "  Dictionary of action: probability.\n"
     ]
    }
   ],
   "source": [
    "straightforward_policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'JointRLAgentPolicy' object has no attribute 'agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m ts \u001b[38;5;241m=\u001b[39m env_and_policy\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m----> 2\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[43mstraightforward_policy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241m.\u001b[39mstep(ts)\n\u001b[1;32m      3\u001b[0m ts \u001b[38;5;241m=\u001b[39m env_and_policy\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(step_output[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39maction)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(ts)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'JointRLAgentPolicy' object has no attribute 'agent'"
     ]
    }
   ],
   "source": [
    "ts = env_and_policy.env.reset()\n",
    "step_output = straightforward_policy.step(ts)\n",
    "ts = env_and_policy.env.step(step_output[0].action)[0][0]\n",
    "print(ts)\n",
    "step_output = agent.step(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m            StupidAgent\n",
      "\u001b[0;31mString form:\u001b[0m     <__main__.StupidAgent object at 0x7f270c123160>\n",
      "\u001b[0;31mDocstring:\u001b[0m       <no docstring>\n",
      "\u001b[0;31mClass docstring:\u001b[0m Abstract base class for Open Spiel RL agents.\n",
      "\u001b[0;31mInit docstring:\u001b[0m \n",
      "Initializes agent.\n",
      "\n",
      "Args:\n",
      "  player_id: integer, mandatory. Corresponds to the player position in the\n",
      "    game and is used to index the observation list.\n",
      "  session: optional Tensorflow session.\n",
      "  observation_spec: optional dict containing observation specifications.\n",
      "  name: string. Must be used to scope TF variables. Defaults to `agent`.\n",
      "  **agent_specific_kwargs: optional extra args.\n"
     ]
    }
   ],
   "source": [
    "agent??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ClockAuctionState' object has no attribute 'last'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_initial_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mStupidAgent.step\u001b[0;34m(self, time_step, is_evaluation)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_act(ts) \u001b[38;5;28;01mfor\u001b[39;00m ts \u001b[38;5;129;01min\u001b[39;00m time_step]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_act\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mStupidAgent._act\u001b[0;34m(self, time_step)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_act\u001b[39m(\u001b[38;5;28mself\u001b[39m, time_step):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtime_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast\u001b[49m():\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     legal_actions \u001b[38;5;241m=\u001b[39m time_step\u001b[38;5;241m.\u001b[39mobservations[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegal_actions\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplayer_id]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ClockAuctionState' object has no attribute 'last'"
     ]
    }
   ],
   "source": [
    "agent.step(game.new_initial_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ClockAuctionState' object has no attribute 'last'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_initial_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mStupidAgent.step\u001b[0;34m(self, time_step, is_evaluation)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_act(ts) \u001b[38;5;28;01mfor\u001b[39;00m ts \u001b[38;5;129;01min\u001b[39;00m time_step]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_act\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mStupidAgent._act\u001b[0;34m(self, time_step)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_act\u001b[39m(\u001b[38;5;28mself\u001b[39m, time_step):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtime_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast\u001b[49m():\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     legal_actions \u001b[38;5;241m=\u001b[39m time_step\u001b[38;5;241m.\u001b[39mobservations[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegal_actions\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplayer_id]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ClockAuctionState' object has no attribute 'last'"
     ]
    }
   ],
   "source": [
    "agent.step(game.new_initial_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_NashConvReturn(nash_conv=0.0, player_improvements=array([0., 0.]), br_policies=[<open_spiel.python.algorithms.best_response.BestResponsePolicy object at 0x7f0a6b6b2490>, <open_spiel.python.algorithms.best_response.BestResponsePolicy object at 0x7f0a6b6b24f0>])\n",
      "Something wrong with jan19_jan19_19_base_dev1000_rho0_t4_tie_break-cfr_port_10_extexternal_plus_linear-101 (jan19_story). Skipping. 'info_dict'\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_8528/1951286636.py\", line 51, in <module>\n",
      "    print(get_stupid_nash_conv(game))\n",
      "  File \"/tmp/ipykernel_8528/388578010.py\", line 25, in get_stupid_nash_conv\n",
      "    return get_nash_conv(game, straightforward_policy)\n",
      "  File \"/tmp/ipykernel_8528/388578010.py\", line 7, in get_nash_conv\n",
      "    worked, time_taken, retval = time_bounded_run(300, nash_conv, game, policy, return_only_nash_conv=False, restrict_to_heuristics=False)\n",
      "  File \"/apps/open_spiel/open_spiel/python/examples/ubc_utils.py\", line 255, in time_bounded_run\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/apps/open_spiel/open_spiel/python/algorithms/exploitability.py\", line 186, in nash_conv\n",
      "    best_responders = [\n",
      "  File \"/apps/open_spiel/open_spiel/python/algorithms/exploitability.py\", line 187, in <listcomp>\n",
      "    pyspiel_best_response.BestResponsePolicy(\n",
      "  File \"/apps/open_spiel/open_spiel/python/algorithms/best_response.py\", line 115, in __init__\n",
      "    self.infosets = self.info_sets(root_state)\n",
      "  File \"/apps/open_spiel/open_spiel/python/algorithms/best_response.py\", line 123, in info_sets\n",
      "    for s, p in self.decision_nodes(state):\n",
      "  File \"/apps/open_spiel/open_spiel/python/algorithms/best_response.py\", line 135, in decision_nodes\n",
      "    for state, p_state in self.decision_nodes(\n",
      "  File \"/apps/open_spiel/open_spiel/python/algorithms/best_response.py\", line 135, in decision_nodes\n",
      "    for state, p_state in self.decision_nodes(\n",
      "  File \"/apps/open_spiel/open_spiel/python/algorithms/best_response.py\", line 135, in decision_nodes\n",
      "    for state, p_state in self.decision_nodes(\n",
      "  File \"/apps/open_spiel/open_spiel/python/algorithms/best_response.py\", line 133, in decision_nodes\n",
      "    for action, p_action in self.transitions(parent_state):\n",
      "  File \"/apps/open_spiel/open_spiel/python/algorithms/best_response.py\", line 173, in transitions\n",
      "    return list(self._policy.action_probabilities(state).items())\n",
      "  File \"/apps/open_spiel/open_spiel/python/rl_agent_policy.py\", line 80, in action_probabilities\n",
      "    p = self._agents[player_id].step(info_state, is_evaluation=True).probs\n",
      "  File \"/tmp/ipykernel_8528/4108436015.py\", line 12, in step\n",
      "    return self._act(time_step)\n",
      "  File \"/tmp/ipykernel_8528/4108436015.py\", line 19, in _act\n",
      "    info_dict = time_step.observations[\"info_dict\"][self.player_id]\n",
      "KeyError: 'info_dict'\n",
      "\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "for run in tqdm(runs):    \n",
    "    game = run.game.load_as_spiel()\n",
    "    record = {\n",
    "        'run_name': run.name,\n",
    "        'game_name': run.game.name, \n",
    "        'seed': run.config.get('seed'), \n",
    "        'config': run.get_config_name(),\n",
    "        'alg': get_algorithm_from_run(run),\n",
    "    }\n",
    "    \n",
    "    record.update(get_game_info(game, run.game))  \n",
    "    \n",
    "    record['no_error'] = False\n",
    "    records.append(record) # Put it here so you see the False's in the display\n",
    "        \n",
    "    try:\n",
    "        game, final_checkpoint, policy = get_results(run, load_policy=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping run {run.name} because of error {e}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        record['t'] = final_checkpoint.t\n",
    "        record['walltime'] = run.walltime(),\n",
    "        evaluation = final_checkpoint.get_modal_eval()\n",
    "        \n",
    "        record['nash_conv'] = evaluation.nash_conv\n",
    "        record['rewards'] = evaluation.mean_rewards\n",
    "        record['nash_conv_frac'] = evaluation.nash_conv / sum(evaluation.mean_rewards) if not pd.isnull(evaluation.nash_conv) else np.nan\n",
    "        record['heuristic_conv'] = evaluation.heuristic_conv\n",
    "        record['heuristic_conv_frac'] = evaluation.heuristic_conv / sum(evaluation.mean_rewards) if not pd.isnull(evaluation.heuristic_conv) else np.nan\n",
    "\n",
    "        for i in range(game.num_players()):\n",
    "            record[f'rewards_{i}'] = evaluation.mean_rewards[i]\n",
    "            record[f'nc_player_improvements_{i}'] = evaluation.nash_conv_player_improvements[i] if not pd.isnull(evaluation.nash_conv) else np.nan\n",
    "            record[f'nc_player_improvements_frac_{i}'] = (evaluation.nash_conv_player_improvements[i] / evaluation.mean_rewards[i]) if not pd.isnull(evaluation.nash_conv) else np.nan\n",
    "\n",
    "            record[f'hc_player_improvements_{i}'] = evaluation.heuristic_conv_player_improvements[i] if not pd.isnull(evaluation.heuristic_conv) else np.nan\n",
    "            record[f'hc_player_improvements_frac_{i}'] = (evaluation.heuristic_conv_player_improvements[i] / evaluation.mean_rewards[i]) if not pd.isnull(evaluation.heuristic_conv) else np.nan\n",
    "\n",
    "        record.update(**analyze_samples(evaluation.samples, game))\n",
    "\n",
    "        nc = record['nash_conv']\n",
    "        hc = record['heuristic_conv']\n",
    "        # print(f\"NashConv = {(np.nan if pd.isnull(nc) else nc):.2f}; HeuristicConv = {(np.nan if pd.isnull(hc) else hc):.2f}\")\n",
    "        \n",
    "        \n",
    "        print(get_straightforward_nash_conv(game))\n",
    "        print(get_stupid_nash_conv(game))\n",
    "        \n",
    "        \n",
    "        record['no_error'] = True\n",
    "    except Exception as e:\n",
    "        print(f\"Something wrong with {run}. Skipping. {e}\")\n",
    "        # raise e\n",
    "        # break\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "    break\n",
    "\n",
    "print(len(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "python_clock_auction(filename=jan19/jan19_19_base_dev1000_rho0_t4_tie_break.json)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(records)\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df[['value_structure', 'rule', 'base_game_name', 'deviations', 'no_error']].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['heuristic_conv'].plot(kind='hist')\n",
    "print(df['heuristic_conv'].isnull().sum())\n",
    "\n",
    "df.query('heuristic_conv.isnull()')[['value_structure', 'rule', 'base_game_name', 'deviations', 'no_error']].value_counts().sort_index()\n",
    "# Huh???? Why are 0 deviation games showing as null. Is that for real?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nash_conv'].plot(kind='hist')\n",
    "print(df['nash_conv'].isnull().sum())\n",
    "\n",
    "df.query('nash_conv.isnull()')[['value_structure', 'rule', 'base_game_name', 'deviations', 'no_error']].value_counts().sort_index()\n",
    "# Huh???? Why are 0 deviation games showing as null. Is that for real?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['deviations', 'value_structure'])['auction_lengths'].plot(kind='hist', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = dict()\n",
    "colors = ['red', 'blue', 'magenta', 'green', 'orange', 'brown', 'black', 'navy', 'pink', 'gold', 'darkgreen', 'orangered', 'olive']\n",
    "# for i, v in enumerate(df['variant'].unique()):\n",
    "#     palette[v] = colors[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to a) Remove \"bad\" entries b) Be careful about comparisons that are missing datapoints \n",
    "df_plt = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove bad entries\n",
    "\n",
    "# TODO: generalize to 3+ players\n",
    "\n",
    "good_thresh = 0.1\n",
    "# good_thresh_abs = 5\n",
    "# df_plt = df.query(f'player_improvements_0 < {good_thresh_abs} and player_improvements_1 < {good_thresh_abs}')\n",
    "df_plt = df.query(f'hc_player_improvements_frac_0 < {good_thresh} and hc_player_improvements_frac_1 < {good_thresh}').copy()\n",
    "# df_plt = df.query(f'nash_conv_frac < {good_thresh}')\n",
    "len(df), len(df_plt)\n",
    "\n",
    "#### So many removed... wow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1) Get max/min for each valuation/treatment pairing over each stat\n",
    "\n",
    "# First query down to relevant datapoints. Then groupby rule change and SATS =(game_name) and max/min?\n",
    "metrics = ['total_revenue', 'total_welfare', 'auction_lengths', 'num_lotteries', 'p_lottery', 'exposure_frac']\n",
    "for i in range(2): # TODO:\n",
    "    metrics += [f'p{i}_utility', f'p{i}_payment']\n",
    "\n",
    "\n",
    "df_plt_indexed = df_plt.set_index(['value_structure', 'rule', 'deviations']).sort_index().copy()\n",
    "\n",
    "def make_data_dict(df):\n",
    "    data = dict()\n",
    "    for metric in metrics:\n",
    "        data[f'max_{metric}'] = df.groupby('base_game_name')[metric].max()\n",
    "        data[f'min_{metric}'] = df.groupby('base_game_name')[metric].min()\n",
    "    return pd.DataFrame(data)\n",
    "    \n",
    "for idx, grp_df in df_plt.groupby(['value_structure', 'rule', 'deviations']):\n",
    "    if idx[1] == 'base':\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        data_grp_df = make_data_dict(grp_df)\n",
    "        normalizer_grp_df = df_plt_indexed.loc[(idx[0], 'base')]\n",
    "        data_normalized_df = make_data_dict(normalizer_grp_df)\n",
    "\n",
    "        cmap_norm = plt.matplotlib.colors.TwoSlopeNorm(vmin=0.9, vcenter=1, vmax=1.1)\n",
    "        cmap = plt.cm.get_cmap('RdBu').copy()\n",
    "        cmap.set_bad('magenta')\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        data = (data_grp_df / data_normalized_df).values.T\n",
    "        plt.imshow(data, cmap=cmap, norm=cmap_norm)\n",
    "        plt.title(idx)\n",
    "        plt.yticks(range(len(data_grp_df.columns)), data_grp_df.columns)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(idx, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_name in ['auction_lengths', 'num_lotteries', 'unsold_licenses', 'total_revenue', 'total_welfare']:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    sns.swarmplot(data=df, x='base_game_name', y=metric_name, hue='tiebreaking_policy', dodge=True, size=4)\n",
    "    plt.gca(); plt.legend([], [], frameon=False)\n",
    "    plt.title(metric_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "sns.swarmplot(data=df, x='base_game_name', y='auction_lengths', hue='tiebreaking_policy', dodge=True, size=4)\n",
    "plt.gca(); plt.legend([], [], frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "sns.swarmplot(data=df, x='base_game_name', y='num_lotteries', hue='tiebreaking_policy', dodge=True, size=4)\n",
    "plt.gca(); plt.legend([], [], frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "sns.swarmplot(data=df, x='base_game_name', y='unsold_licenses', hue='tiebreaking_policy', dodge=True, size=4)\n",
    "plt.gca(); plt.legend([], [], frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "sns.swarmplot(data=df, x='base_game_name', y='total_revenue', hue='tiebreaking_policy', dodge=True, size=4)\n",
    "plt.gca(); plt.legend([], [], frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "sns.swarmplot(data=df, x='base_game_name', y='total_welfare', hue='tiebreaking_policy', dodge=True, size=4)\n",
    "plt.gca(); plt.legend([], [], frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.swarmplot(data=df.query('value_structure == \"quasi_linear\"'), x='base_game_name', y='total_welfare', hue='tiebreaking_policy', dodge=True, size=4)\n",
    "plt.gca(); plt.legend([], [], frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to get straightforward eval?\n",
    "\n",
    "records = []\n",
    "for run in tqdm(runs):    \n",
    "    game = run.game.load_as_spiel()\n",
    "    record = {\n",
    "        'run_name': run.name,\n",
    "        'game_name': run.game.name, \n",
    "        'seed': run.config.get('seed'), \n",
    "        'config': run.get_config_name(),\n",
    "        'alg': get_algorithm_from_run(run),\n",
    "    }\n",
    "    \n",
    "    record.update(get_game_info(game, run.game))  \n",
    "    \n",
    "    record['no_error'] = False\n",
    "    records.append(record) # Put it here so you see the False's in the display\n",
    "        \n",
    "    try:\n",
    "        game, final_checkpoint, policy = get_results(run, load_policy=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping run {run.name} because of error {e}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        record['t'] = final_checkpoint.t\n",
    "        record['walltime'] = run.walltime(),\n",
    "        evaluation = final_checkpoint.get_straightforward_eval()\n",
    "        \n",
    "        record['nash_conv'] = evaluation.nash_conv\n",
    "        record['rewards'] = evaluation.mean_rewards\n",
    "        record['nash_conv_frac'] = evaluation.nash_conv / sum(evaluation.mean_rewards) if not pd.isnull(evaluation.nash_conv) else np.nan\n",
    "        record['heuristic_conv'] = evaluation.heuristic_conv\n",
    "        record['heuristic_conv_frac'] = evaluation.heuristic_conv / sum(evaluation.mean_rewards) if not pd.isnull(evaluation.heuristic_conv) else np.nan\n",
    "\n",
    "        for i in range(game.num_players()):\n",
    "            record[f'rewards_{i}'] = evaluation.mean_rewards[i]\n",
    "            record[f'nc_player_improvements_{i}'] = evaluation.nash_conv_player_improvements[i] if not pd.isnull(evaluation.nash_conv) else np.nan\n",
    "            record[f'nc_player_improvements_frac_{i}'] = (evaluation.nash_conv_player_improvements[i] / evaluation.mean_rewards[i]) if not pd.isnull(evaluation.nash_conv) else np.nan\n",
    "\n",
    "            record[f'hc_player_improvements_{i}'] = evaluation.heuristic_conv_player_improvements[i] if not pd.isnull(evaluation.heuristic_conv) else np.nan\n",
    "            record[f'hc_player_improvements_frac_{i}'] = (evaluation.heuristic_conv_player_improvements[i] / evaluation.mean_rewards[i]) if not pd.isnull(evaluation.heuristic_conv) else np.nan\n",
    "\n",
    "        record.update(**analyze_samples(evaluation.samples, game))\n",
    "\n",
    "        nc = record['nash_conv']\n",
    "        hc = record['heuristic_conv']\n",
    "        # print(f\"NashConv = {(np.nan if pd.isnull(nc) else nc):.2f}; HeuristicConv = {(np.nan if pd.isnull(hc) else hc):.2f}\")\n",
    "        \n",
    "        record['no_error'] = True\n",
    "    except Exception as e:\n",
    "        print(f\"Something wrong with {run}. Skipping. {e}\")\n",
    "        # raise e\n",
    "        # break\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "print(len(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(records)\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df[['value_structure', 'rule', 'base_game_name', 'deviations', 'no_error']].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_name in ['auction_lengths', 'num_lotteries', 'unsold_licenses', 'total_revenue', 'total_welfare']:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    sns.swarmplot(data=df, x='base_game_name', y=metric_name, hue='tiebreaking_policy', dodge=True, size=4)\n",
    "    plt.gca(); plt.legend([], [], frameon=False)\n",
    "    plt.title(metric_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nash_conv'] # Would need to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
