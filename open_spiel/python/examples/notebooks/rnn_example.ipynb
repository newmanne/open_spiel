{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f3d175-ac31-413b-8fdc-7c74771da319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eb9c710-ab40-4991-8469-9e3a88374ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuctionAdvantageRNN(nn.Module):\n",
    "    def __init__(self, num_players, num_products, num_actions, hidden_size=128, rnn_model='lstm'):\n",
    "        super(AuctionAdvantageRNN, self).__init__()\n",
    "        input_size = num_players + 1 + 5 * num_products # (prices, demands, processed_demands) for each product\n",
    "        if rnn_model == 'lstm':\n",
    "            self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        elif rnn_model == 'rnn':\n",
    "            self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        else:\n",
    "            raise ValueError('unrecognized RNN model %s' % rnn_model) \n",
    "        self.output_layer = nn.Linear(hidden_size, num_actions)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # assumes x is a packed padded sequence\n",
    "        # TODO: do packing+padding in module?\n",
    "        rnn_outputs, _ = self.rnn(x)\n",
    "        padded_output, output_lens = nn.utils.rnn.pad_packed_sequence(rnn_outputs, batch_first=True)\n",
    "        last_outputs = torch.cat([padded_output[e, i-1, :].unsqueeze(0) for e, i in enumerate(output_lens)])\n",
    "        action_logits = self.output_layer(last_outputs)\n",
    "        return action_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff67afa4-4370-4cc0-9df2-cad1a2646d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AuctionAdvantageRNN(\n",
    "    num_players=3,\n",
    "    num_products=4,\n",
    "    num_actions=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e6d2465-6446-4967-9941-da4cc1321262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_sequences(sequences):\n",
    "    padded_seq_batch = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
    "    sequence_lengths = [len(seq) for seq in sequences]\n",
    "    packed_seq_batch = torch.nn.utils.rnn.pack_padded_sequence(padded_seq_batch, lengths=sequence_lengths, batch_first=True, enforce_sorted=False)\n",
    "    return packed_seq_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86fa5955-d899-4636-b2bc-79815abfb129",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\n",
    "    # first infoset: 1 previous state \n",
    "    torch.tensor([\n",
    "        [100, 100, 50, 70, 100, 110, 50, 2, 1, 2, 1, 1, 2]\n",
    "    ]),\n",
    "    # second infoset: 3 previous states\n",
    "    torch.tensor([\n",
    "        [300, 150, 110, 70, 100, 100, 50, 0, 0, 0, 0, 0, 0,],\n",
    "        [300, 150, 110, 70, 110, 110, 55, 2, 1, 2, 1, 1, 2],\n",
    "        [300, 150, 110, 70, 121, 121, 61, 2, 1, 1, 1, 1, 1],\n",
    "    ]),\n",
    "]\n",
    "\n",
    "packed_sequences = pack_sequences(sequences).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ad6288-b4a6-4d04-a7b8-7bbe6aeaf4fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 24, got 13",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0028f9254acc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/apps/open_spiel/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-abf32616153f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# assumes x is a packed padded sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# TODO: do packing+padding in module?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mrnn_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mpadded_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlast_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpadded_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/open_spiel/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/open_spiel/venv/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m/apps/open_spiel/venv/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    630\u001b[0m                            \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                            ):\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[1;32m    634\u001b[0m                                'Expected hidden[0] size {}, got {}')\n",
      "\u001b[0;32m/apps/open_spiel/venv/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    205\u001b[0m             raise RuntimeError(\n\u001b[1;32m    206\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 207\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 24, got 13"
     ]
    }
   ],
   "source": [
    "model(packed_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59072d71-7a4d-462f-8e10-c864cc52bac8",
   "metadata": {},
   "source": [
    "infostate tensor has:\n",
    "- player number (1-hot encoded)\n",
    "- budget\n",
    "- value for each product\n",
    "- submitted demand for each product x round\n",
    "- processed demand for each product x round\n",
    "- observations for each product x round\n",
    "- prices for each product x round\n",
    "\n",
    "expand into tensor of size (rounds x features), where features for each round are:\n",
    "- player number (1-hot encoded)\n",
    "- budget\n",
    "- value for each product\n",
    "- submitted demand for each product\n",
    "- processed demand for each product\n",
    "- observations for each product\n",
    "- prices for each product\n",
    "\n",
    "so # features = players + 1 + 5*products\n",
    "\n",
    "(don't include any round with all-0 posted prices - these rounds haven't happened yet)\n",
    "\n",
    "(final round will have 0 submitted/processed/observed demands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67cfafbf-7a36-473a-9301-ba1d617e99f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_infostate_tensor(infostate_tensor, num_players, num_products):\n",
    "    offset = 0\n",
    "    \n",
    "    players = infostate_tensor[offset:offset+num_players]\n",
    "    offset += num_players\n",
    "    \n",
    "    budget = infostate_tensor[offset:offset+1]\n",
    "    offset += 1\n",
    "    \n",
    "    values = infostate_tensor[offset:offset+num_products]\n",
    "    offset += num_products\n",
    "    \n",
    "    rounds = len(infostate_tensor[offset:]) // (4 * num_products)\n",
    "    \n",
    "    submitted_demands = infostate_tensor[offset:offset+rounds*num_products].reshape((rounds, num_products))\n",
    "    offset += rounds*num_products\n",
    "    \n",
    "    processed_demands = infostate_tensor[offset:offset+rounds*num_products].reshape((rounds, num_products))\n",
    "    offset += rounds*num_products\n",
    "    \n",
    "    observed_demands = infostate_tensor[offset:offset+rounds*num_products].reshape((rounds, num_products))\n",
    "    offset += rounds*num_products\n",
    "    \n",
    "    prices = infostate_tensor[offset:offset+rounds*num_products].reshape((rounds, num_products))\n",
    "    \n",
    "    expanded_infostate = torch.hstack([\n",
    "        torch.tile(players, (rounds, 1)),\n",
    "        torch.tile(budget, (rounds, 1)),\n",
    "        torch.tile(values, (rounds, 1)),\n",
    "        submitted_demands,\n",
    "        processed_demands,\n",
    "        observed_demands, \n",
    "        prices\n",
    "    ])\n",
    "    return expanded_infostate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "392d58a2-dd03-4100-b813-3663e30a02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "infostate = torch.tensor([\n",
    "    # player (one-hot encoded)\n",
    "    1, 0, 0,\n",
    "    # budget\n",
    "    100,\n",
    "    # values\n",
    "    100, 50,\n",
    "    # submitted demands each round\n",
    "    2, 2, \n",
    "    2, 1,\n",
    "    0, 0,\n",
    "    # processed demands each round\n",
    "    2, 2,\n",
    "    2, 2,\n",
    "    0, 0,\n",
    "    # observed demands each round\n",
    "    6, 6,\n",
    "    6, 3,\n",
    "    0, 0,\n",
    "    # prices\n",
    "    50, 50,\n",
    "    60, 60,\n",
    "    72, 72,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f87e3d1-7c7d-494e-b22a-6c7c3c612ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1,   0,   0, 100, 100,  50,   2,   2,   2,   1,   0,   0,   2,   2,\n",
       "          2,   2,   0,   0,   6,   6,   6,   3,   0,   0,  50,  50,  60,  60,\n",
       "         72,  72])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infostate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "581c2a89-532d-44d8-8ce7-60be691992b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   0,   0, 100, 100,  50,   2,   2,   2,   2,   6,   6,  50,  50],\n",
       "        [  1,   0,   0, 100, 100,  50,   2,   1,   2,   2,   6,   3,  60,  60],\n",
       "        [  1,   0,   0, 100, 100,  50,   0,   0,   0,   0,   0,   0,  72,  72]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expand into (players, budget, values, submitted demands, processed demands, observed demands, prices)\n",
    "expand_infostate_tensor(infostate, num_players=3, num_products=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a87a01e-6d3a-4172-84b8-521e5e9422ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
